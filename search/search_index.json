{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#neuro-py","title":"neuro-py","text":"<p>Analysis of neuroelectrophysiology data in Python.</p> <p></p> CI/CD Package Repository Metadata"},{"location":"#overview","title":"Overview","text":"<p><code>neuro_py</code> is a Python package for analysis of neuroelectrophysiology data. It is built on top of the nelpy package, which provides core data objects. <code>neuro_py</code> provides a set of functions for analysis of freely moving electrophysiology, including behavior tracking utilities, neural ensemble detection, peri-event analyses, robust batch analysis tools, and more. </p> <p>Tutorials are here and more will be added. </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>git clone\ncd neuro_py\npip install -e .\n</code></pre> <p>To sync the <code>nelpy</code> dependency to latest version, use following instead,</p> <pre><code>pip install -e . --force-reinstall --no-cache-dir\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>import neuro_py as npy\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<p>For ease of use, this package uses <code>nelpy</code> core data objects. See nelpy </p>"},{"location":"#testing","title":"Testing","text":"<pre><code>pytest\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.</p> <p>Please make sure to update tests as appropriate.</p>"},{"location":"#authors","title":"Authors","text":"<ul> <li>@ryanharvey1</li> <li>@lolaBerkowitz</li> <li>@kushaangupta</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> neuro_py<ul> <li> behavior</li> <li> detectors</li> <li> ensemble</li> <li> io</li> <li> lfp</li> <li> plotting</li> <li> process</li> <li> raw</li> <li> session</li> <li> spikes</li> <li> stats</li> <li> tuning</li> <li> util</li> </ul> </li> <li>behavior<ul> <li> cheeseboard</li> <li> circle_maze</li> <li> get_trials</li> <li> kinematics</li> <li> linear_positions</li> <li> linearization</li> <li> linearization_pipeline</li> <li> preprocessing</li> <li> well_traversal_classification</li> </ul> </li> <li>detectors<ul> <li> dentate_spike</li> <li> up_down_state</li> </ul> </li> <li>ensemble<ul> <li> assembly</li> <li> assembly_reactivation</li> <li> decoding</li> <li> dynamics</li> <li> explained_variance</li> <li> geometry</li> <li> pairwise_bias_correlation</li> <li> replay</li> <li> similarity_index</li> <li> similaritymat</li> </ul> </li> <li>decoding<ul> <li> bayesian</li> <li> lstm</li> <li> m2mlstm</li> <li> mlp</li> <li> pipeline</li> <li> preprocess</li> <li> transformer</li> </ul> </li> <li>io<ul> <li> loading</li> <li> saving</li> </ul> </li> <li>lfp<ul> <li> CSD</li> <li> preprocessing</li> <li> spectral</li> <li> theta_cycles</li> </ul> </li> <li>plotting<ul> <li> decorators</li> <li> events</li> <li> figure_helpers</li> </ul> </li> <li>process<ul> <li> batch_analysis</li> <li> correlations</li> <li> intervals</li> <li> peri_event</li> <li> precession_utils</li> <li> pychronux</li> <li> utils</li> </ul> </li> <li>raw<ul> <li> preprocessing</li> <li> spike_sorting</li> </ul> </li> <li>session<ul> <li> locate_epochs</li> </ul> </li> <li>spikes<ul> <li> spike_tools</li> </ul> </li> <li>stats<ul> <li> circ_stats</li> <li> regression</li> <li> stats</li> <li> system_identifier</li> </ul> </li> <li>tuning<ul> <li> fields</li> <li> maps</li> </ul> </li> <li>util<ul> <li> array</li> </ul> </li> </ul>"},{"location":"reference/neuro_py/","title":"neuro_py","text":""},{"location":"reference/neuro_py/behavior/","title":"neuro_py.behavior","text":""},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer","title":"<code>HMMLinearizer</code>","text":"<p>Hidden Markov Model for track linearization.</p> <p>This class implements an HMM that infers the most likely position on a track given noisy 2D position measurements. The hidden states represent positions along track segments, and observations are 2D coordinates.</p> <p>The default parameters are optimized for multi-segment classification: - emission_noise=5.0: Good balance for tracking data - transition_smoothness=0.1: Allows segment transitions while maintaining smoothness - use_sparse_transitions=True: Essential for multi-segment classification - n_bins_per_segment=50: Provides good spatial resolution</p> <p>Parameters:</p> Name Type Description Default <code>track_graph</code> <code>TrackGraph</code> <p>The track graph defining the track structure</p> required <code>n_bins_per_segment</code> <code>int</code> <p>Number of position bins per track segment, by default 50</p> <code>50</code> <code>transition_smoothness</code> <code>float</code> <p>Smoothness parameter for state transitions, by default 0.1</p> <code>1.0</code> <code>emission_noise</code> <code>float</code> <p>Standard deviation of emission noise, by default 5.0</p> <code>8.0</code> <code>max_iterations</code> <code>int</code> <p>Maximum iterations for Viterbi algorithm, by default 1000</p> <code>1000</code> <p>Attributes:</p> Name Type Description <code>track_graph</code> <code>TrackGraph</code> <p>The track graph</p> <code>n_states</code> <code>int</code> <p>Total number of hidden states</p> <code>n_segments</code> <code>int</code> <p>Number of track segments</p> <code>n_bins_per_segment</code> <code>int</code> <p>Number of position bins per segment</p> <code>transition_matrix</code> <code>ndarray</code> <p>State transition probability matrix</p> <code>emission_centers</code> <code>ndarray</code> <p>Center positions for each hidden state</p> <code>emission_covariance</code> <code>ndarray</code> <p>Covariance matrix for emission model</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class HMMLinearizer:\n    \"\"\"\n    Hidden Markov Model for track linearization.\n\n    This class implements an HMM that infers the most likely position on a track\n    given noisy 2D position measurements. The hidden states represent positions\n    along track segments, and observations are 2D coordinates.\n\n    The default parameters are optimized for multi-segment classification:\n    - emission_noise=5.0: Good balance for tracking data\n    - transition_smoothness=0.1: Allows segment transitions while maintaining smoothness\n    - use_sparse_transitions=True: Essential for multi-segment classification\n    - n_bins_per_segment=50: Provides good spatial resolution\n\n    Parameters\n    ----------\n    track_graph : TrackGraph\n        The track graph defining the track structure\n    n_bins_per_segment : int, optional\n        Number of position bins per track segment, by default 50\n    transition_smoothness : float, optional\n        Smoothness parameter for state transitions, by default 0.1\n    emission_noise : float, optional\n        Standard deviation of emission noise, by default 5.0\n    max_iterations : int, optional\n        Maximum iterations for Viterbi algorithm, by default 1000\n\n    Attributes\n    ----------\n    track_graph : TrackGraph\n        The track graph\n    n_states : int\n        Total number of hidden states\n    n_segments : int\n        Number of track segments\n    n_bins_per_segment : int\n        Number of position bins per segment\n    transition_matrix : np.ndarray\n        State transition probability matrix\n    emission_centers : np.ndarray\n        Center positions for each hidden state\n    emission_covariance : np.ndarray\n        Covariance matrix for emission model\n    \"\"\"\n\n    def __init__(\n        self,\n        track_graph: \"TrackGraph\",\n        n_bins_per_segment: int = 50,\n        transition_smoothness: float = 1.0,  # Increased for better segment transitions\n        emission_noise: float = 8.0,  # Increased for better coverage of real tracking data\n        max_iterations: int = 1000,\n        # Optimization parameters\n        use_sparse_transitions: bool = True,\n        subsample_positions: bool = False,\n        subsample_factor: int = 5,\n        # Additional optimization parameters\n        use_adaptive_subsampling: bool = True,\n        # Advanced optimization parameters\n        use_batch_processing: bool = False,\n        batch_size: int = 1000,\n        # Performance optimization parameters\n        adaptive_binning: bool = True,  # Reduce bins for large track graphs\n        max_total_states: int = 500,  # Maximum total states to prevent slowdown\n        early_termination: bool = True,  # Stop Viterbi early if convergence detected\n    ):\n        self.track_graph = track_graph\n        self.n_bins_per_segment = n_bins_per_segment\n        self.transition_smoothness = transition_smoothness\n        self.emission_noise = emission_noise\n        self.max_iterations = max_iterations\n\n        # Optimization parameters\n        self.use_sparse_transitions = use_sparse_transitions\n        self.subsample_positions = subsample_positions\n        self.subsample_factor = subsample_factor\n        self.use_adaptive_subsampling = use_adaptive_subsampling\n        self.use_batch_processing = use_batch_processing\n        self.batch_size = batch_size\n\n        # Performance optimization parameters\n        self.adaptive_binning = adaptive_binning\n        self.max_total_states = max_total_states\n        self.early_termination = early_termination\n\n        # Calculate track segment properties\n        self.n_segments = len(track_graph.edges)\n\n        # Adaptive binning: reduce bins for large track graphs\n        if self.adaptive_binning and self.n_segments &gt; 5:\n            # Reduce bins per segment to keep total states manageable\n            max_bins_per_segment = max(10, self.max_total_states // self.n_segments)\n            self.n_bins_per_segment = min(self.n_bins_per_segment, max_bins_per_segment)\n            print(f\"Adaptive binning: reduced to {self.n_bins_per_segment} bins per segment for {self.n_segments} segments\")\n\n        self.segment_lengths = []\n        self.segment_positions = []\n\n        for edge in track_graph.edges:\n            if len(edge) &gt;= 2:\n                # Calculate segment length\n                segment_length = 0\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = track_graph.node_positions[node1]\n                    p2 = track_graph.node_positions[node2]\n                    segment_length += np.linalg.norm(p2 - p1)\n\n                self.segment_lengths.append(segment_length)\n\n                # Generate position bins along this segment\n                positions = []\n                for i in range(self.n_bins_per_segment):\n                    t = i / (self.n_bins_per_segment - 1)  # Parameter along segment\n                    pos = self._interpolate_along_segment(edge, t)\n                    positions.append(pos)\n\n                self.segment_positions.append(np.array(positions))\n            else:\n                # Empty segment\n                self.segment_lengths.append(0)\n                self.segment_positions.append(np.array([]))\n\n        # Total number of states\n        self.n_states = sum(len(positions) for positions in self.segment_positions)\n\n        # Build state mapping\n        self.state_to_segment = []\n        self.state_to_position = []\n        state_idx = 0\n\n        for seg_idx, positions in enumerate(self.segment_positions):\n            for pos_idx, pos in enumerate(positions):\n                self.state_to_segment.append(seg_idx)\n                self.state_to_position.append(pos)\n            state_idx += len(positions)\n\n        self.state_to_segment = np.array(self.state_to_segment)\n        self.state_to_position = np.array(self.state_to_position)\n\n        # Build transition matrix\n        self._build_transition_matrix()\n\n        # Build emission model\n        self._build_emission_model()\n\n    def _interpolate_along_segment(self, edge: List[int], t: float) -&gt; np.ndarray:\n        \"\"\"Interpolate position along a track segment.\"\"\"\n        if len(edge) &lt; 2:\n            return np.array([0, 0])\n\n        # Find which sub-segment we're in\n        total_length = 0\n        segment_lengths = []\n\n        for i in range(len(edge) - 1):\n            node1, node2 = edge[i], edge[i + 1]\n            p1 = self.track_graph.node_positions[node1]\n            p2 = self.track_graph.node_positions[node2]\n            length = np.linalg.norm(p2 - p1)\n            segment_lengths.append(length)\n            total_length += length\n\n        if total_length == 0:\n            return self.track_graph.node_positions[edge[0]]\n\n        # Find target position along the segment\n        target_distance = t * total_length\n        current_distance = 0\n\n        for i in range(len(edge) - 1):\n            node1, node2 = edge[i], edge[i + 1]\n            p1 = self.track_graph.node_positions[node1]\n            p2 = self.track_graph.node_positions[node2]\n            length = segment_lengths[i]\n\n            if current_distance + length &gt;= target_distance:\n                # Interpolate within this sub-segment\n                local_t = (target_distance - current_distance) / length\n                return p1 + local_t * (p2 - p1)\n\n            current_distance += length\n\n        # If we get here, return the last point\n        return self.track_graph.node_positions[edge[-1]]\n\n    def _build_transition_matrix(self):\n        \"\"\"Build transition matrix between states using log-probabilities for numerical stability.\"\"\"\n        if self.use_sparse_transitions and NUMBA_AVAILABLE:\n            # Use Numba-optimized sparse transition matrix building\n            # Create segments_connected matrix for Numba\n            segments_connected = np.zeros(\n                (self.n_segments, self.n_segments), dtype=bool\n            )\n            for i in range(self.n_segments):\n                for j in range(self.n_segments):\n                    segments_connected[i, j] = self._segments_connected(i, j)\n\n            self.transition_matrix = _build_sparse_transition_matrix_numba(\n                self.state_to_segment,\n                self.state_to_position,\n                self.n_states,\n                self.transition_smoothness,\n                segments_connected,\n            )\n        else:\n            # Fallback to original implementation with log-probabilities\n            self.transition_matrix = np.full(\n                (self.n_states, self.n_states), -np.inf\n            )  # Initialize with log(0) = -inf\n\n            for i in range(self.n_states):\n                seg1 = self.state_to_segment[i]\n                pos1 = self.state_to_position[i]\n\n                # Early termination for sparse transitions\n                if self.use_sparse_transitions:\n                    # Only compute transitions to nearby states\n                    nearby_states = []\n\n                    # Same segment transitions\n                    for j in range(self.n_states):\n                        if self.state_to_segment[j] == seg1:\n                            pos_diff = abs(i - j)\n                            if pos_diff &lt;= 3:  # Allow more transitions within segments\n                                nearby_states.append(j)\n\n                    # Inter-segment transitions - allow transitions to connected segments\n                    for j in range(self.n_states):\n                        seg2 = self.state_to_segment[j]\n                        if seg1 != seg2 and self._segments_connected(seg1, seg2):\n                            # Allow transitions to boundary states of connected segments\n                            # For each segment, allow transitions to first and last few states\n                            states_in_seg2 = np.where(self.state_to_segment == seg2)[0]\n                            if len(states_in_seg2) &gt; 0:\n                                # Allow transitions to first 5 and last 5 states of connected segments\n                                boundary_states = np.concatenate(\n                                    [\n                                        states_in_seg2[:5],  # First 5 states\n                                        states_in_seg2[-5:],  # Last 5 states\n                                    ]\n                                )\n                                if j in boundary_states:\n                                    nearby_states.append(j)\n\n                    # Compute transitions only for nearby states\n                    for j in nearby_states:\n                        seg2 = self.state_to_segment[j]\n                        pos2 = self.state_to_position[j]\n                        self.transition_matrix[i, j] = (\n                            self._calculate_transition_probability(\n                                seg1, pos1, seg2, pos2\n                            )\n                        )\n                else:\n                    # Full transition matrix (slower but more accurate)\n                    for j in range(self.n_states):\n                        seg2 = self.state_to_segment[j]\n                        pos2 = self.state_to_position[j]\n                        self.transition_matrix[i, j] = (\n                            self._calculate_transition_probability(\n                                seg1, pos1, seg2, pos2\n                            )\n                        )\n\n            # Normalize rows in log-space\n            for i in range(self.n_states):\n                # Find max log-probability in row for numerical stability\n                max_log_prob = np.max(self.transition_matrix[i])\n\n                # If all transitions are -inf, set uniform distribution\n                if max_log_prob == -np.inf:\n                    uniform_log_prob = np.log(1.0 / self.n_states)\n                    self.transition_matrix[i, :] = uniform_log_prob\n                else:\n                    # Subtract max and normalize\n                    sum_exp = np.sum(np.exp(self.transition_matrix[i] - max_log_prob))\n                    if sum_exp &gt; 0:\n                        log_sum = np.log(sum_exp)\n                        self.transition_matrix[i, :] = (\n                            self.transition_matrix[i, :] - max_log_prob - log_sum\n                        )\n                    else:\n                        # If sum is zero, set uniform distribution\n                        uniform_log_prob = np.log(1.0 / self.n_states)\n                        self.transition_matrix[i, :] = uniform_log_prob\n\n    def _calculate_transition_probability(\n        self, seg1: int, pos1: np.ndarray, seg2: int, pos2: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate transition log-probability between two states.\"\"\"\n        # Distance-based probability\n        distance = np.linalg.norm(pos2 - pos1)\n\n        # Same segment: high probability for nearby positions\n        if seg1 == seg2:\n            # Gaussian kernel for smooth transitions\n            log_prob = -(distance**2) / (2 * self.transition_smoothness**2)\n        else:\n            # Different segments: allow more transitions for real data\n            # Check if segments are connected\n            if self._segments_connected(seg1, seg2):\n                # Increase probability for connected segments - much higher for real data\n                log_prob = np.log(0.8) - (distance**2) / (\n                    2 * self.transition_smoothness**2\n                )\n            else:\n                # Still allow some transitions to unconnected segments\n                log_prob = np.log(0.1) - (distance**2) / (\n                    2 * self.transition_smoothness**2\n                )\n\n        return log_prob\n\n    def _segments_connected(self, seg1: int, seg2: int) -&gt; bool:\n        \"\"\"Check if two segments are connected in the track graph.\"\"\"\n        if seg1 &gt;= len(self.track_graph.edges) or seg2 &gt;= len(self.track_graph.edges):\n            return False\n\n        edge1 = self.track_graph.edges[seg1]\n        edge2 = self.track_graph.edges[seg2]\n\n        if len(edge1) == 0 or len(edge2) == 0:\n            return False\n\n        # Check if segments share any nodes\n        nodes1 = set(edge1)\n        nodes2 = set(edge2)\n        return len(nodes1.intersection(nodes2)) &gt; 0\n\n    def _auto_tune_parameters(self, positions: np.ndarray) -&gt; dict:\n        \"\"\"\n        Automatically tune HMM parameters based on data characteristics.\n        Optimized for real rat tracking data from DeepLabCut.\n\n        Parameters\n        ----------\n        positions : np.ndarray\n            Position data to analyze\n\n        Returns\n        -------\n        dict\n            Optimized parameters\n        \"\"\"\n        # Analyze data characteristics\n        data_range = np.ptp(positions, axis=0)  # Peak-to-peak range\n        data_std = np.std(positions, axis=0)  # Standard deviation\n\n        # Estimate appropriate emission noise based on data spread\n        # For DeepLabCut data, we need higher emission noise to account for tracking errors\n        avg_std = np.mean(data_std)\n        if avg_std &lt; 1.0:\n            emission_noise = 3.0  # Very precise tracking\n        elif avg_std &lt; 3.0:\n            emission_noise = 5.0  # Good tracking\n        elif avg_std &lt; 8.0:\n            emission_noise = 8.0  # Moderate tracking\n        else:\n            emission_noise = 12.0  # Noisy tracking\n\n        # Estimate transition smoothness based on track complexity\n        track_length = 0\n        for edge in self.track_graph.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = self.track_graph.node_positions[node1]\n                    p2 = self.track_graph.node_positions[node2]\n                    track_length += np.linalg.norm(p2 - p1)\n\n        # More aggressive transition smoothness for better segment transitions\n        if track_length &lt; 10:\n            transition_smoothness = 0.5\n        elif track_length &lt; 30:\n            transition_smoothness = 0.8\n        elif track_length &lt; 80:\n            transition_smoothness = 1.2\n        else:\n            transition_smoothness = 1.5\n\n        # Adjust number of bins based on track complexity and data size\n        n_positions = len(positions)\n        if len(self.track_graph.edges) &lt;= 2:\n            n_bins_per_segment = min(40, max(20, n_positions // 100))\n        elif len(self.track_graph.edges) &lt;= 4:\n            n_bins_per_segment = min(60, max(30, n_positions // 80))\n        else:\n            n_bins_per_segment = min(80, max(40, n_positions // 60))\n\n        return {\n            \"n_bins_per_segment\": n_bins_per_segment,\n            \"emission_noise\": emission_noise,\n            \"transition_smoothness\": transition_smoothness,\n            \"use_sparse_transitions\": True,\n        }\n\n    def _build_emission_model(self):\n        \"\"\"Build the emission probability model.\"\"\"\n        # Use the state positions as emission centers\n        self.emission_centers = self.state_to_position\n\n        # Create covariance matrix for emission noise\n        # Use larger noise for better coverage of real tracking data\n        # This is more similar to the original LorenFrankLab approach\n        self.emission_covariance = np.eye(2) * self.emission_noise**2\n\n        # For real tracking data, we need to ensure positions can be assigned to states\n        # even if they're not exactly on the track due to tracking noise\n\n    def _emission_probability(self, observation: np.ndarray, state: int) -&gt; float:\n        \"\"\"Calculate emission probability P(observation | state).\"\"\"\n        center = self.emission_centers[state]\n\n        # Use multivariate normal distribution\n        rv = multivariate_normal(center, self.emission_covariance)\n        return rv.pdf(observation)\n\n    def _emission_probabilities_vectorized(\n        self, observations: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Calculate emission log-probabilities for all observations and states at once.\n        Much faster than calling _emission_probability repeatedly.\n        Uses Numba JIT compilation if available.\n        Returns log-probabilities for numerical stability.\n        \"\"\"\n        if NUMBA_AVAILABLE:\n            if (\n                self.use_batch_processing and len(observations) &gt; 100\n            ):  # Use batch processing for any significant number of observations\n                return _process_batch_emissions(\n                    observations,\n                    self.emission_centers,\n                    self.emission_covariance,\n                    self.batch_size,\n                )\n            else:\n                return _emission_probabilities_numba(\n                    observations, self.emission_centers, self.emission_covariance\n                )\n        else:\n            # Fallback to original implementation with log-probabilities\n            n_observations = len(observations)\n            log_emission_probs = np.zeros((n_observations, self.n_states))\n\n            # Pre-compute constants for Gaussian calculation\n            det_cov = np.linalg.det(self.emission_covariance)\n            inv_cov = np.linalg.inv(self.emission_covariance)\n            log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det_cov)))\n\n            for t in range(n_observations):\n                obs = observations[t]\n                for i in range(self.n_states):\n                    center = self.emission_centers[i]\n                    diff = obs - center\n                    # Manual Gaussian calculation (faster than multivariate_normal)\n                    exponent = -0.5 * diff.T @ inv_cov @ diff\n                    log_emission_probs[t, i] = log_norm_const + exponent\n\n            return log_emission_probs\n\n    def linearize_with_hmm(\n        self, positions: np.ndarray\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Linearize positions using HMM inference.\n\n        Parameters\n        ----------\n        positions : np.ndarray\n            Array of 2D positions (n_positions, 2)\n\n        Returns\n        -------\n        linear_positions : np.ndarray\n            Linearized positions along the track\n        track_segment_ids : np.ndarray\n            Track segment IDs for each position\n        projected_positions : np.ndarray\n            Projected 2D positions on the track\n        \"\"\"\n        n_positions = len(positions)\n\n        # Initialize arrays\n        linear_positions = np.full(n_positions, np.nan)\n        track_segment_ids = np.full(n_positions, -1, dtype=int)\n        projected_positions = np.full((n_positions, 2), np.nan)\n\n        # Handle NaN positions\n        valid_mask = ~np.isnan(positions).any(axis=1)\n        if not np.any(valid_mask):\n            return linear_positions, track_segment_ids, projected_positions\n\n        valid_positions = positions[valid_mask]\n\n        # Check if we should use fast approximate method for very large track graphs\n        if self.n_states &gt; 1000 and len(valid_positions) &gt; 500:\n            print(f\"Using fast approximate HMM for large track graph ({self.n_states} states, {len(valid_positions)} positions)\")\n            return self._linearize_with_fast_approximate_hmm(positions, valid_mask)\n\n        # Subsample positions if requested for speed\n        if self.subsample_positions and len(valid_positions) &gt; 1000:\n            # Adaptive subsampling: use larger factor for bigger datasets\n            if self.use_adaptive_subsampling:\n                adaptive_factor = max(\n                    self.subsample_factor, len(valid_positions) // 2000\n                )\n            else:\n                adaptive_factor = self.subsample_factor\n            subsample_indices = np.arange(0, len(valid_positions), adaptive_factor)\n            subsampled_positions = valid_positions[subsample_indices]\n            original_indices = np.where(valid_mask)[0][subsample_indices]\n        else:\n            subsampled_positions = valid_positions\n            original_indices = np.where(valid_mask)[0]\n\n        # Run Viterbi algorithm to find most likely state sequence\n        state_sequence = self._viterbi(subsampled_positions)\n\n        # Convert states back to linear positions and segment IDs\n        for i, state in enumerate(state_sequence):\n            global_idx = original_indices[i]\n\n            seg_id = self.state_to_segment[state]\n            projected_pos = self.state_to_position[state]\n\n            # Calculate linear position along the track\n            linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n            linear_positions[global_idx] = linear_pos\n            track_segment_ids[global_idx] = seg_id\n            projected_positions[global_idx] = projected_pos\n\n        # Interpolate missing values if subsampling was used\n        if self.subsample_positions and len(original_indices) &lt; n_positions:\n            linear_positions, track_segment_ids, projected_positions = (\n                self._interpolate_missing_values(\n                    linear_positions,\n                    track_segment_ids,\n                    projected_positions,\n                    original_indices,\n                    valid_mask,\n                )\n            )\n\n        return linear_positions, track_segment_ids, projected_positions\n\n    def _linearize_with_fast_approximate_hmm(\n        self, positions: np.ndarray, valid_mask: np.ndarray\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Fast approximate HMM linearization for very large track graphs.\n        Uses simplified approach: project to nearest state and apply temporal smoothing.\n        \"\"\"\n        n_positions = len(positions)\n        linear_positions = np.full(n_positions, np.nan)\n        track_segment_ids = np.full(n_positions, -1, dtype=int)\n        projected_positions = np.full((n_positions, 2), np.nan)\n\n        valid_positions = positions[valid_mask]\n\n        # Step 1: Find nearest state for each position (much faster than full HMM)\n        nearest_states = np.zeros(len(valid_positions), dtype=int)\n        for i, pos in enumerate(valid_positions):\n            # Find nearest emission center\n            distances = np.linalg.norm(self.emission_centers - pos, axis=1)\n            nearest_states[i] = np.argmin(distances)\n\n        # Step 2: Apply simple temporal smoothing (optional)\n        if len(nearest_states) &gt; 1:\n            smoothed_states = self._apply_temporal_smoothing(nearest_states)\n        else:\n            smoothed_states = nearest_states\n\n        # Step 3: Convert states to positions\n        for i, state in enumerate(smoothed_states):\n            global_idx = np.where(valid_mask)[0][i]\n\n            seg_id = self.state_to_segment[state]\n            projected_pos = self.state_to_position[state]\n            linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n            linear_positions[global_idx] = linear_pos\n            track_segment_ids[global_idx] = seg_id\n            projected_positions[global_idx] = projected_pos\n\n        return linear_positions, track_segment_ids, projected_positions\n\n    def _apply_temporal_smoothing(self, states: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Apply simple temporal smoothing to state sequence.\n        Uses a moving average approach to reduce noise.\n        \"\"\"\n        smoothed = states.copy()\n        window_size = min(5, len(states) // 10)  # Adaptive window size\n\n        if window_size &lt; 2:\n            return smoothed\n\n        # Apply moving average smoothing\n        for i in range(len(states)):\n            start = max(0, i - window_size // 2)\n            end = min(len(states), i + window_size // 2 + 1)\n            window_states = states[start:end]\n\n            # Use mode (most common state) in window\n            unique, counts = np.unique(window_states, return_counts=True)\n            smoothed[i] = unique[np.argmax(counts)]\n\n        return smoothed\n\n    def _viterbi(self, observations: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Run Viterbi algorithm to find most likely state sequence.\n        Uses log-probabilities for numerical stability.\n        Vectorized implementation for better performance.\n        Uses Numba JIT compilation if available.\n\n        Parameters\n        ----------\n        observations : np.ndarray\n            Array of observations (n_observations, 2)\n\n        Returns\n        -------\n        np.ndarray\n            Most likely state sequence\n        \"\"\"\n        n_observations = len(observations)\n\n        # Pre-compute log emission probabilities for all observations and states\n        log_emission_probs = self._emission_probabilities_vectorized(observations)\n\n        if NUMBA_AVAILABLE:\n            return _viterbi_numba(\n                log_emission_probs,\n                self.transition_matrix,\n                n_observations,\n                self.n_states,\n            )\n        else:\n            # Fallback to original implementation with log-probabilities\n            # Initialize\n            log_delta = np.zeros((n_observations, self.n_states))\n            psi = np.zeros((n_observations, self.n_states), dtype=int)\n\n            # Initialize with log-emission probabilities of first observation\n            log_initial_probs = log_emission_probs[0]\n\n            # Forward pass (vectorized)\n            for t in range(n_observations):\n                if t == 0:\n                    # Initial log-probabilities\n                    log_delta[t] = log_initial_probs\n                else:\n                    # Vectorized recursion: compute all state transitions at once\n                    # log_delta[t-1] + log_transition_matrix gives us all possible log-transitions\n                    log_transition_probs = (\n                        log_delta[t - 1].reshape(-1, 1) + self.transition_matrix\n                    )\n\n                    # Find maximum log-probability and corresponding previous state for each current state\n                    max_indices = np.argmax(log_transition_probs, axis=0)\n                    max_log_probs = np.max(log_transition_probs, axis=0)\n\n                    # Update log_delta and psi\n                    log_delta[t] = max_log_probs + log_emission_probs[t]\n                    psi[t] = max_indices\n\n            # Backward pass\n            state_sequence = np.zeros(n_observations, dtype=int)\n            state_sequence[-1] = np.argmax(log_delta[-1])\n\n            for t in range(n_observations - 2, -1, -1):\n                state_sequence[t] = psi[t + 1, state_sequence[t + 1]]\n\n            return state_sequence\n\n    def _calculate_linear_position(\n        self, segment_id: int, position: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate linear position along the track for a given segment and position.\"\"\"\n        if segment_id &gt;= len(self.track_graph.edges):\n            return 0.0\n\n        # Calculate cumulative distance to this segment\n        cumulative_distance = 0.0\n\n        for i in range(segment_id):\n            if i &lt; len(self.track_graph.cumulative_distances):\n                # Use the track graph's cumulative distances\n                edge = self.track_graph.edges[i]\n                if len(edge) &gt;= 2:\n                    node1, node2 = edge[0], edge[-1]\n                    cumulative_distance += self.track_graph.edge_distances.get(\n                        (node1, node2), 0\n                    )\n\n        # Add distance within current segment\n        if segment_id &lt; len(self.track_graph.edges):\n            edge = self.track_graph.edges[segment_id]\n            if len(edge) &gt;= 2:\n                # Find closest point on this segment\n                min_distance = np.inf\n                segment_position = 0.0\n\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = self.track_graph.node_positions[node1]\n                    p2 = self.track_graph.node_positions[node2]\n\n                    # Project position onto this line segment\n                    v = p2 - p1\n                    u = position - p1\n                    t = np.dot(u, v) / np.dot(v, v)\n                    t = np.clip(t, 0, 1)\n\n                    projected = p1 + t * v\n                    distance = np.linalg.norm(position - projected)\n\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        segment_position = t * np.linalg.norm(v)\n\n                cumulative_distance += segment_position\n\n        return cumulative_distance\n\n    def _interpolate_missing_values(\n        self,\n        linear_positions: np.ndarray,\n        track_segment_ids: np.ndarray,\n        projected_positions: np.ndarray,\n        original_indices: np.ndarray,\n        valid_mask: np.ndarray,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Interpolate missing values in subsampled linearization results.\n\n        This method fills in the NaN values between linearized points using\n        linear interpolation. For rat tracking data, this provides smooth\n        trajectories while maintaining the speed benefits of subsampling.\n\n        Parameters\n        ----------\n        linear_positions : np.ndarray\n            Array of linear positions with NaN values for missing points\n        track_segment_ids : np.ndarray\n            Array of track segment IDs with -1 for missing points\n        projected_positions : np.ndarray\n            Array of projected 2D positions with NaN values for missing points\n        original_indices : np.ndarray\n            Indices of the original positions that were linearized\n        valid_mask : np.ndarray\n            Boolean mask indicating which original positions are valid (not NaN)\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            Interpolated linear_positions, track_segment_ids, and projected_positions\n        \"\"\"\n        from scipy.interpolate import interp1d\n\n        # Get the valid linearized indices (where we have actual values)\n        valid_linearized = original_indices[\n            ~np.isnan(linear_positions[original_indices])\n        ]\n\n        if len(valid_linearized) &lt; 2:\n            # Not enough points to interpolate\n            return linear_positions, track_segment_ids, projected_positions\n\n        # Get the corresponding values\n        valid_linear = linear_positions[valid_linearized]\n        valid_segments = track_segment_ids[valid_linearized]\n        valid_projected = projected_positions[valid_linearized]\n\n        # Find all missing indices that need interpolation\n        all_valid_indices = np.where(valid_mask)[0]\n        missing_indices = all_valid_indices[\n            ~np.isin(all_valid_indices, valid_linearized)\n        ]\n\n        if len(missing_indices) == 0:\n            return linear_positions, track_segment_ids, projected_positions\n\n        # Sort by index for proper interpolation\n        sort_idx = np.argsort(valid_linearized)\n        sorted_indices = valid_linearized[sort_idx]\n        sorted_linear = valid_linear[sort_idx]\n        sorted_segments = valid_segments[sort_idx]\n        sorted_projected = valid_projected[sort_idx]\n\n        # Interpolate linear positions\n        try:\n            linear_interp = interp1d(\n                sorted_indices,\n                sorted_linear,\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n            linear_positions[missing_indices] = linear_interp(missing_indices)\n        except Exception:\n            # Fallback to nearest neighbor if interpolation fails\n            for idx in missing_indices:\n                # Find closest valid index\n                closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n                linear_positions[idx] = linear_positions[closest_idx]\n\n        # Interpolate segment IDs (use mode/nearest neighbor for categorical data)\n        for idx in missing_indices:\n            # Find the two closest valid indices\n            distances = np.abs(sorted_indices - idx)\n            closest_indices = sorted_indices[np.argsort(distances)[:2]]\n\n            if len(closest_indices) == 1:\n                track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n            else:\n                # Use the closer one, or the one with higher linear position if tied\n                if (\n                    distances[np.argsort(distances)[0]]\n                    &lt; distances[np.argsort(distances)[1]]\n                ):\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                else:\n                    # If equidistant, use the one with higher linear position\n                    if (\n                        linear_positions[closest_indices[0]]\n                        &gt; linear_positions[closest_indices[1]]\n                    ):\n                        track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                    else:\n                        track_segment_ids[idx] = track_segment_ids[closest_indices[1]]\n\n        # Interpolate projected positions\n        try:\n            # Interpolate x and y coordinates separately\n            x_interp = interp1d(\n                sorted_indices,\n                sorted_projected[:, 0],\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n            y_interp = interp1d(\n                sorted_indices,\n                sorted_projected[:, 1],\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n\n            projected_positions[missing_indices, 0] = x_interp(missing_indices)\n            projected_positions[missing_indices, 1] = y_interp(missing_indices)\n        except Exception:\n            # Fallback to nearest neighbor if interpolation fails\n            for idx in missing_indices:\n                closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n                projected_positions[idx] = projected_positions[closest_idx]\n\n        return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._apply_temporal_smoothing","title":"<code>_apply_temporal_smoothing(states)</code>","text":"<p>Apply simple temporal smoothing to state sequence. Uses a moving average approach to reduce noise.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _apply_temporal_smoothing(self, states: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply simple temporal smoothing to state sequence.\n    Uses a moving average approach to reduce noise.\n    \"\"\"\n    smoothed = states.copy()\n    window_size = min(5, len(states) // 10)  # Adaptive window size\n\n    if window_size &lt; 2:\n        return smoothed\n\n    # Apply moving average smoothing\n    for i in range(len(states)):\n        start = max(0, i - window_size // 2)\n        end = min(len(states), i + window_size // 2 + 1)\n        window_states = states[start:end]\n\n        # Use mode (most common state) in window\n        unique, counts = np.unique(window_states, return_counts=True)\n        smoothed[i] = unique[np.argmax(counts)]\n\n    return smoothed\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._auto_tune_parameters","title":"<code>_auto_tune_parameters(positions)</code>","text":"<p>Automatically tune HMM parameters based on data characteristics. Optimized for real rat tracking data from DeepLabCut.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>ndarray</code> <p>Position data to analyze</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Optimized parameters</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _auto_tune_parameters(self, positions: np.ndarray) -&gt; dict:\n    \"\"\"\n    Automatically tune HMM parameters based on data characteristics.\n    Optimized for real rat tracking data from DeepLabCut.\n\n    Parameters\n    ----------\n    positions : np.ndarray\n        Position data to analyze\n\n    Returns\n    -------\n    dict\n        Optimized parameters\n    \"\"\"\n    # Analyze data characteristics\n    data_range = np.ptp(positions, axis=0)  # Peak-to-peak range\n    data_std = np.std(positions, axis=0)  # Standard deviation\n\n    # Estimate appropriate emission noise based on data spread\n    # For DeepLabCut data, we need higher emission noise to account for tracking errors\n    avg_std = np.mean(data_std)\n    if avg_std &lt; 1.0:\n        emission_noise = 3.0  # Very precise tracking\n    elif avg_std &lt; 3.0:\n        emission_noise = 5.0  # Good tracking\n    elif avg_std &lt; 8.0:\n        emission_noise = 8.0  # Moderate tracking\n    else:\n        emission_noise = 12.0  # Noisy tracking\n\n    # Estimate transition smoothness based on track complexity\n    track_length = 0\n    for edge in self.track_graph.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                p1 = self.track_graph.node_positions[node1]\n                p2 = self.track_graph.node_positions[node2]\n                track_length += np.linalg.norm(p2 - p1)\n\n    # More aggressive transition smoothness for better segment transitions\n    if track_length &lt; 10:\n        transition_smoothness = 0.5\n    elif track_length &lt; 30:\n        transition_smoothness = 0.8\n    elif track_length &lt; 80:\n        transition_smoothness = 1.2\n    else:\n        transition_smoothness = 1.5\n\n    # Adjust number of bins based on track complexity and data size\n    n_positions = len(positions)\n    if len(self.track_graph.edges) &lt;= 2:\n        n_bins_per_segment = min(40, max(20, n_positions // 100))\n    elif len(self.track_graph.edges) &lt;= 4:\n        n_bins_per_segment = min(60, max(30, n_positions // 80))\n    else:\n        n_bins_per_segment = min(80, max(40, n_positions // 60))\n\n    return {\n        \"n_bins_per_segment\": n_bins_per_segment,\n        \"emission_noise\": emission_noise,\n        \"transition_smoothness\": transition_smoothness,\n        \"use_sparse_transitions\": True,\n    }\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._build_emission_model","title":"<code>_build_emission_model()</code>","text":"<p>Build the emission probability model.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _build_emission_model(self):\n    \"\"\"Build the emission probability model.\"\"\"\n    # Use the state positions as emission centers\n    self.emission_centers = self.state_to_position\n\n    # Create covariance matrix for emission noise\n    # Use larger noise for better coverage of real tracking data\n    # This is more similar to the original LorenFrankLab approach\n    self.emission_covariance = np.eye(2) * self.emission_noise**2\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._build_transition_matrix","title":"<code>_build_transition_matrix()</code>","text":"<p>Build transition matrix between states using log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _build_transition_matrix(self):\n    \"\"\"Build transition matrix between states using log-probabilities for numerical stability.\"\"\"\n    if self.use_sparse_transitions and NUMBA_AVAILABLE:\n        # Use Numba-optimized sparse transition matrix building\n        # Create segments_connected matrix for Numba\n        segments_connected = np.zeros(\n            (self.n_segments, self.n_segments), dtype=bool\n        )\n        for i in range(self.n_segments):\n            for j in range(self.n_segments):\n                segments_connected[i, j] = self._segments_connected(i, j)\n\n        self.transition_matrix = _build_sparse_transition_matrix_numba(\n            self.state_to_segment,\n            self.state_to_position,\n            self.n_states,\n            self.transition_smoothness,\n            segments_connected,\n        )\n    else:\n        # Fallback to original implementation with log-probabilities\n        self.transition_matrix = np.full(\n            (self.n_states, self.n_states), -np.inf\n        )  # Initialize with log(0) = -inf\n\n        for i in range(self.n_states):\n            seg1 = self.state_to_segment[i]\n            pos1 = self.state_to_position[i]\n\n            # Early termination for sparse transitions\n            if self.use_sparse_transitions:\n                # Only compute transitions to nearby states\n                nearby_states = []\n\n                # Same segment transitions\n                for j in range(self.n_states):\n                    if self.state_to_segment[j] == seg1:\n                        pos_diff = abs(i - j)\n                        if pos_diff &lt;= 3:  # Allow more transitions within segments\n                            nearby_states.append(j)\n\n                # Inter-segment transitions - allow transitions to connected segments\n                for j in range(self.n_states):\n                    seg2 = self.state_to_segment[j]\n                    if seg1 != seg2 and self._segments_connected(seg1, seg2):\n                        # Allow transitions to boundary states of connected segments\n                        # For each segment, allow transitions to first and last few states\n                        states_in_seg2 = np.where(self.state_to_segment == seg2)[0]\n                        if len(states_in_seg2) &gt; 0:\n                            # Allow transitions to first 5 and last 5 states of connected segments\n                            boundary_states = np.concatenate(\n                                [\n                                    states_in_seg2[:5],  # First 5 states\n                                    states_in_seg2[-5:],  # Last 5 states\n                                ]\n                            )\n                            if j in boundary_states:\n                                nearby_states.append(j)\n\n                # Compute transitions only for nearby states\n                for j in nearby_states:\n                    seg2 = self.state_to_segment[j]\n                    pos2 = self.state_to_position[j]\n                    self.transition_matrix[i, j] = (\n                        self._calculate_transition_probability(\n                            seg1, pos1, seg2, pos2\n                        )\n                    )\n            else:\n                # Full transition matrix (slower but more accurate)\n                for j in range(self.n_states):\n                    seg2 = self.state_to_segment[j]\n                    pos2 = self.state_to_position[j]\n                    self.transition_matrix[i, j] = (\n                        self._calculate_transition_probability(\n                            seg1, pos1, seg2, pos2\n                        )\n                    )\n\n        # Normalize rows in log-space\n        for i in range(self.n_states):\n            # Find max log-probability in row for numerical stability\n            max_log_prob = np.max(self.transition_matrix[i])\n\n            # If all transitions are -inf, set uniform distribution\n            if max_log_prob == -np.inf:\n                uniform_log_prob = np.log(1.0 / self.n_states)\n                self.transition_matrix[i, :] = uniform_log_prob\n            else:\n                # Subtract max and normalize\n                sum_exp = np.sum(np.exp(self.transition_matrix[i] - max_log_prob))\n                if sum_exp &gt; 0:\n                    log_sum = np.log(sum_exp)\n                    self.transition_matrix[i, :] = (\n                        self.transition_matrix[i, :] - max_log_prob - log_sum\n                    )\n                else:\n                    # If sum is zero, set uniform distribution\n                    uniform_log_prob = np.log(1.0 / self.n_states)\n                    self.transition_matrix[i, :] = uniform_log_prob\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._calculate_linear_position","title":"<code>_calculate_linear_position(segment_id, position)</code>","text":"<p>Calculate linear position along the track for a given segment and position.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_linear_position(\n    self, segment_id: int, position: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate linear position along the track for a given segment and position.\"\"\"\n    if segment_id &gt;= len(self.track_graph.edges):\n        return 0.0\n\n    # Calculate cumulative distance to this segment\n    cumulative_distance = 0.0\n\n    for i in range(segment_id):\n        if i &lt; len(self.track_graph.cumulative_distances):\n            # Use the track graph's cumulative distances\n            edge = self.track_graph.edges[i]\n            if len(edge) &gt;= 2:\n                node1, node2 = edge[0], edge[-1]\n                cumulative_distance += self.track_graph.edge_distances.get(\n                    (node1, node2), 0\n                )\n\n    # Add distance within current segment\n    if segment_id &lt; len(self.track_graph.edges):\n        edge = self.track_graph.edges[segment_id]\n        if len(edge) &gt;= 2:\n            # Find closest point on this segment\n            min_distance = np.inf\n            segment_position = 0.0\n\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                p1 = self.track_graph.node_positions[node1]\n                p2 = self.track_graph.node_positions[node2]\n\n                # Project position onto this line segment\n                v = p2 - p1\n                u = position - p1\n                t = np.dot(u, v) / np.dot(v, v)\n                t = np.clip(t, 0, 1)\n\n                projected = p1 + t * v\n                distance = np.linalg.norm(position - projected)\n\n                if distance &lt; min_distance:\n                    min_distance = distance\n                    segment_position = t * np.linalg.norm(v)\n\n            cumulative_distance += segment_position\n\n    return cumulative_distance\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._calculate_transition_probability","title":"<code>_calculate_transition_probability(seg1, pos1, seg2, pos2)</code>","text":"<p>Calculate transition log-probability between two states.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_transition_probability(\n    self, seg1: int, pos1: np.ndarray, seg2: int, pos2: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate transition log-probability between two states.\"\"\"\n    # Distance-based probability\n    distance = np.linalg.norm(pos2 - pos1)\n\n    # Same segment: high probability for nearby positions\n    if seg1 == seg2:\n        # Gaussian kernel for smooth transitions\n        log_prob = -(distance**2) / (2 * self.transition_smoothness**2)\n    else:\n        # Different segments: allow more transitions for real data\n        # Check if segments are connected\n        if self._segments_connected(seg1, seg2):\n            # Increase probability for connected segments - much higher for real data\n            log_prob = np.log(0.8) - (distance**2) / (\n                2 * self.transition_smoothness**2\n            )\n        else:\n            # Still allow some transitions to unconnected segments\n            log_prob = np.log(0.1) - (distance**2) / (\n                2 * self.transition_smoothness**2\n            )\n\n    return log_prob\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._emission_probabilities_vectorized","title":"<code>_emission_probabilities_vectorized(observations)</code>","text":"<p>Calculate emission log-probabilities for all observations and states at once. Much faster than calling _emission_probability repeatedly. Uses Numba JIT compilation if available. Returns log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _emission_probabilities_vectorized(\n    self, observations: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculate emission log-probabilities for all observations and states at once.\n    Much faster than calling _emission_probability repeatedly.\n    Uses Numba JIT compilation if available.\n    Returns log-probabilities for numerical stability.\n    \"\"\"\n    if NUMBA_AVAILABLE:\n        if (\n            self.use_batch_processing and len(observations) &gt; 100\n        ):  # Use batch processing for any significant number of observations\n            return _process_batch_emissions(\n                observations,\n                self.emission_centers,\n                self.emission_covariance,\n                self.batch_size,\n            )\n        else:\n            return _emission_probabilities_numba(\n                observations, self.emission_centers, self.emission_covariance\n            )\n    else:\n        # Fallback to original implementation with log-probabilities\n        n_observations = len(observations)\n        log_emission_probs = np.zeros((n_observations, self.n_states))\n\n        # Pre-compute constants for Gaussian calculation\n        det_cov = np.linalg.det(self.emission_covariance)\n        inv_cov = np.linalg.inv(self.emission_covariance)\n        log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det_cov)))\n\n        for t in range(n_observations):\n            obs = observations[t]\n            for i in range(self.n_states):\n                center = self.emission_centers[i]\n                diff = obs - center\n                # Manual Gaussian calculation (faster than multivariate_normal)\n                exponent = -0.5 * diff.T @ inv_cov @ diff\n                log_emission_probs[t, i] = log_norm_const + exponent\n\n        return log_emission_probs\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._emission_probability","title":"<code>_emission_probability(observation, state)</code>","text":"<p>Calculate emission probability P(observation | state).</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _emission_probability(self, observation: np.ndarray, state: int) -&gt; float:\n    \"\"\"Calculate emission probability P(observation | state).\"\"\"\n    center = self.emission_centers[state]\n\n    # Use multivariate normal distribution\n    rv = multivariate_normal(center, self.emission_covariance)\n    return rv.pdf(observation)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._interpolate_along_segment","title":"<code>_interpolate_along_segment(edge, t)</code>","text":"<p>Interpolate position along a track segment.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _interpolate_along_segment(self, edge: List[int], t: float) -&gt; np.ndarray:\n    \"\"\"Interpolate position along a track segment.\"\"\"\n    if len(edge) &lt; 2:\n        return np.array([0, 0])\n\n    # Find which sub-segment we're in\n    total_length = 0\n    segment_lengths = []\n\n    for i in range(len(edge) - 1):\n        node1, node2 = edge[i], edge[i + 1]\n        p1 = self.track_graph.node_positions[node1]\n        p2 = self.track_graph.node_positions[node2]\n        length = np.linalg.norm(p2 - p1)\n        segment_lengths.append(length)\n        total_length += length\n\n    if total_length == 0:\n        return self.track_graph.node_positions[edge[0]]\n\n    # Find target position along the segment\n    target_distance = t * total_length\n    current_distance = 0\n\n    for i in range(len(edge) - 1):\n        node1, node2 = edge[i], edge[i + 1]\n        p1 = self.track_graph.node_positions[node1]\n        p2 = self.track_graph.node_positions[node2]\n        length = segment_lengths[i]\n\n        if current_distance + length &gt;= target_distance:\n            # Interpolate within this sub-segment\n            local_t = (target_distance - current_distance) / length\n            return p1 + local_t * (p2 - p1)\n\n        current_distance += length\n\n    # If we get here, return the last point\n    return self.track_graph.node_positions[edge[-1]]\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._interpolate_missing_values","title":"<code>_interpolate_missing_values(linear_positions, track_segment_ids, projected_positions, original_indices, valid_mask)</code>","text":"<p>Interpolate missing values in subsampled linearization results.</p> <p>This method fills in the NaN values between linearized points using linear interpolation. For rat tracking data, this provides smooth trajectories while maintaining the speed benefits of subsampling.</p> <p>Parameters:</p> Name Type Description Default <code>linear_positions</code> <code>ndarray</code> <p>Array of linear positions with NaN values for missing points</p> required <code>track_segment_ids</code> <code>ndarray</code> <p>Array of track segment IDs with -1 for missing points</p> required <code>projected_positions</code> <code>ndarray</code> <p>Array of projected 2D positions with NaN values for missing points</p> required <code>original_indices</code> <code>ndarray</code> <p>Indices of the original positions that were linearized</p> required <code>valid_mask</code> <code>ndarray</code> <p>Boolean mask indicating which original positions are valid (not NaN)</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Interpolated linear_positions, track_segment_ids, and projected_positions</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _interpolate_missing_values(\n    self,\n    linear_positions: np.ndarray,\n    track_segment_ids: np.ndarray,\n    projected_positions: np.ndarray,\n    original_indices: np.ndarray,\n    valid_mask: np.ndarray,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Interpolate missing values in subsampled linearization results.\n\n    This method fills in the NaN values between linearized points using\n    linear interpolation. For rat tracking data, this provides smooth\n    trajectories while maintaining the speed benefits of subsampling.\n\n    Parameters\n    ----------\n    linear_positions : np.ndarray\n        Array of linear positions with NaN values for missing points\n    track_segment_ids : np.ndarray\n        Array of track segment IDs with -1 for missing points\n    projected_positions : np.ndarray\n        Array of projected 2D positions with NaN values for missing points\n    original_indices : np.ndarray\n        Indices of the original positions that were linearized\n    valid_mask : np.ndarray\n        Boolean mask indicating which original positions are valid (not NaN)\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Interpolated linear_positions, track_segment_ids, and projected_positions\n    \"\"\"\n    from scipy.interpolate import interp1d\n\n    # Get the valid linearized indices (where we have actual values)\n    valid_linearized = original_indices[\n        ~np.isnan(linear_positions[original_indices])\n    ]\n\n    if len(valid_linearized) &lt; 2:\n        # Not enough points to interpolate\n        return linear_positions, track_segment_ids, projected_positions\n\n    # Get the corresponding values\n    valid_linear = linear_positions[valid_linearized]\n    valid_segments = track_segment_ids[valid_linearized]\n    valid_projected = projected_positions[valid_linearized]\n\n    # Find all missing indices that need interpolation\n    all_valid_indices = np.where(valid_mask)[0]\n    missing_indices = all_valid_indices[\n        ~np.isin(all_valid_indices, valid_linearized)\n    ]\n\n    if len(missing_indices) == 0:\n        return linear_positions, track_segment_ids, projected_positions\n\n    # Sort by index for proper interpolation\n    sort_idx = np.argsort(valid_linearized)\n    sorted_indices = valid_linearized[sort_idx]\n    sorted_linear = valid_linear[sort_idx]\n    sorted_segments = valid_segments[sort_idx]\n    sorted_projected = valid_projected[sort_idx]\n\n    # Interpolate linear positions\n    try:\n        linear_interp = interp1d(\n            sorted_indices,\n            sorted_linear,\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n        linear_positions[missing_indices] = linear_interp(missing_indices)\n    except Exception:\n        # Fallback to nearest neighbor if interpolation fails\n        for idx in missing_indices:\n            # Find closest valid index\n            closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n            linear_positions[idx] = linear_positions[closest_idx]\n\n    # Interpolate segment IDs (use mode/nearest neighbor for categorical data)\n    for idx in missing_indices:\n        # Find the two closest valid indices\n        distances = np.abs(sorted_indices - idx)\n        closest_indices = sorted_indices[np.argsort(distances)[:2]]\n\n        if len(closest_indices) == 1:\n            track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n        else:\n            # Use the closer one, or the one with higher linear position if tied\n            if (\n                distances[np.argsort(distances)[0]]\n                &lt; distances[np.argsort(distances)[1]]\n            ):\n                track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n            else:\n                # If equidistant, use the one with higher linear position\n                if (\n                    linear_positions[closest_indices[0]]\n                    &gt; linear_positions[closest_indices[1]]\n                ):\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                else:\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[1]]\n\n    # Interpolate projected positions\n    try:\n        # Interpolate x and y coordinates separately\n        x_interp = interp1d(\n            sorted_indices,\n            sorted_projected[:, 0],\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n        y_interp = interp1d(\n            sorted_indices,\n            sorted_projected[:, 1],\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n\n        projected_positions[missing_indices, 0] = x_interp(missing_indices)\n        projected_positions[missing_indices, 1] = y_interp(missing_indices)\n    except Exception:\n        # Fallback to nearest neighbor if interpolation fails\n        for idx in missing_indices:\n            closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n            projected_positions[idx] = projected_positions[closest_idx]\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._linearize_with_fast_approximate_hmm","title":"<code>_linearize_with_fast_approximate_hmm(positions, valid_mask)</code>","text":"<p>Fast approximate HMM linearization for very large track graphs. Uses simplified approach: project to nearest state and apply temporal smoothing.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _linearize_with_fast_approximate_hmm(\n    self, positions: np.ndarray, valid_mask: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Fast approximate HMM linearization for very large track graphs.\n    Uses simplified approach: project to nearest state and apply temporal smoothing.\n    \"\"\"\n    n_positions = len(positions)\n    linear_positions = np.full(n_positions, np.nan)\n    track_segment_ids = np.full(n_positions, -1, dtype=int)\n    projected_positions = np.full((n_positions, 2), np.nan)\n\n    valid_positions = positions[valid_mask]\n\n    # Step 1: Find nearest state for each position (much faster than full HMM)\n    nearest_states = np.zeros(len(valid_positions), dtype=int)\n    for i, pos in enumerate(valid_positions):\n        # Find nearest emission center\n        distances = np.linalg.norm(self.emission_centers - pos, axis=1)\n        nearest_states[i] = np.argmin(distances)\n\n    # Step 2: Apply simple temporal smoothing (optional)\n    if len(nearest_states) &gt; 1:\n        smoothed_states = self._apply_temporal_smoothing(nearest_states)\n    else:\n        smoothed_states = nearest_states\n\n    # Step 3: Convert states to positions\n    for i, state in enumerate(smoothed_states):\n        global_idx = np.where(valid_mask)[0][i]\n\n        seg_id = self.state_to_segment[state]\n        projected_pos = self.state_to_position[state]\n        linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n        linear_positions[global_idx] = linear_pos\n        track_segment_ids[global_idx] = seg_id\n        projected_positions[global_idx] = projected_pos\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._segments_connected","title":"<code>_segments_connected(seg1, seg2)</code>","text":"<p>Check if two segments are connected in the track graph.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _segments_connected(self, seg1: int, seg2: int) -&gt; bool:\n    \"\"\"Check if two segments are connected in the track graph.\"\"\"\n    if seg1 &gt;= len(self.track_graph.edges) or seg2 &gt;= len(self.track_graph.edges):\n        return False\n\n    edge1 = self.track_graph.edges[seg1]\n    edge2 = self.track_graph.edges[seg2]\n\n    if len(edge1) == 0 or len(edge2) == 0:\n        return False\n\n    # Check if segments share any nodes\n    nodes1 = set(edge1)\n    nodes2 = set(edge2)\n    return len(nodes1.intersection(nodes2)) &gt; 0\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer._viterbi","title":"<code>_viterbi(observations)</code>","text":"<p>Run Viterbi algorithm to find most likely state sequence. Uses log-probabilities for numerical stability. Vectorized implementation for better performance. Uses Numba JIT compilation if available.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ndarray</code> <p>Array of observations (n_observations, 2)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Most likely state sequence</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _viterbi(self, observations: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Run Viterbi algorithm to find most likely state sequence.\n    Uses log-probabilities for numerical stability.\n    Vectorized implementation for better performance.\n    Uses Numba JIT compilation if available.\n\n    Parameters\n    ----------\n    observations : np.ndarray\n        Array of observations (n_observations, 2)\n\n    Returns\n    -------\n    np.ndarray\n        Most likely state sequence\n    \"\"\"\n    n_observations = len(observations)\n\n    # Pre-compute log emission probabilities for all observations and states\n    log_emission_probs = self._emission_probabilities_vectorized(observations)\n\n    if NUMBA_AVAILABLE:\n        return _viterbi_numba(\n            log_emission_probs,\n            self.transition_matrix,\n            n_observations,\n            self.n_states,\n        )\n    else:\n        # Fallback to original implementation with log-probabilities\n        # Initialize\n        log_delta = np.zeros((n_observations, self.n_states))\n        psi = np.zeros((n_observations, self.n_states), dtype=int)\n\n        # Initialize with log-emission probabilities of first observation\n        log_initial_probs = log_emission_probs[0]\n\n        # Forward pass (vectorized)\n        for t in range(n_observations):\n            if t == 0:\n                # Initial log-probabilities\n                log_delta[t] = log_initial_probs\n            else:\n                # Vectorized recursion: compute all state transitions at once\n                # log_delta[t-1] + log_transition_matrix gives us all possible log-transitions\n                log_transition_probs = (\n                    log_delta[t - 1].reshape(-1, 1) + self.transition_matrix\n                )\n\n                # Find maximum log-probability and corresponding previous state for each current state\n                max_indices = np.argmax(log_transition_probs, axis=0)\n                max_log_probs = np.max(log_transition_probs, axis=0)\n\n                # Update log_delta and psi\n                log_delta[t] = max_log_probs + log_emission_probs[t]\n                psi[t] = max_indices\n\n        # Backward pass\n        state_sequence = np.zeros(n_observations, dtype=int)\n        state_sequence[-1] = np.argmax(log_delta[-1])\n\n        for t in range(n_observations - 2, -1, -1):\n            state_sequence[t] = psi[t + 1, state_sequence[t + 1]]\n\n        return state_sequence\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.HMMLinearizer.linearize_with_hmm","title":"<code>linearize_with_hmm(positions)</code>","text":"<p>Linearize positions using HMM inference.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <p>Returns:</p> Name Type Description <code>linear_positions</code> <code>ndarray</code> <p>Linearized positions along the track</p> <code>track_segment_ids</code> <code>ndarray</code> <p>Track segment IDs for each position</p> <code>projected_positions</code> <code>ndarray</code> <p>Projected 2D positions on the track</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def linearize_with_hmm(\n    self, positions: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Linearize positions using HMM inference.\n\n    Parameters\n    ----------\n    positions : np.ndarray\n        Array of 2D positions (n_positions, 2)\n\n    Returns\n    -------\n    linear_positions : np.ndarray\n        Linearized positions along the track\n    track_segment_ids : np.ndarray\n        Track segment IDs for each position\n    projected_positions : np.ndarray\n        Projected 2D positions on the track\n    \"\"\"\n    n_positions = len(positions)\n\n    # Initialize arrays\n    linear_positions = np.full(n_positions, np.nan)\n    track_segment_ids = np.full(n_positions, -1, dtype=int)\n    projected_positions = np.full((n_positions, 2), np.nan)\n\n    # Handle NaN positions\n    valid_mask = ~np.isnan(positions).any(axis=1)\n    if not np.any(valid_mask):\n        return linear_positions, track_segment_ids, projected_positions\n\n    valid_positions = positions[valid_mask]\n\n    # Check if we should use fast approximate method for very large track graphs\n    if self.n_states &gt; 1000 and len(valid_positions) &gt; 500:\n        print(f\"Using fast approximate HMM for large track graph ({self.n_states} states, {len(valid_positions)} positions)\")\n        return self._linearize_with_fast_approximate_hmm(positions, valid_mask)\n\n    # Subsample positions if requested for speed\n    if self.subsample_positions and len(valid_positions) &gt; 1000:\n        # Adaptive subsampling: use larger factor for bigger datasets\n        if self.use_adaptive_subsampling:\n            adaptive_factor = max(\n                self.subsample_factor, len(valid_positions) // 2000\n            )\n        else:\n            adaptive_factor = self.subsample_factor\n        subsample_indices = np.arange(0, len(valid_positions), adaptive_factor)\n        subsampled_positions = valid_positions[subsample_indices]\n        original_indices = np.where(valid_mask)[0][subsample_indices]\n    else:\n        subsampled_positions = valid_positions\n        original_indices = np.where(valid_mask)[0]\n\n    # Run Viterbi algorithm to find most likely state sequence\n    state_sequence = self._viterbi(subsampled_positions)\n\n    # Convert states back to linear positions and segment IDs\n    for i, state in enumerate(state_sequence):\n        global_idx = original_indices[i]\n\n        seg_id = self.state_to_segment[state]\n        projected_pos = self.state_to_position[state]\n\n        # Calculate linear position along the track\n        linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n        linear_positions[global_idx] = linear_pos\n        track_segment_ids[global_idx] = seg_id\n        projected_positions[global_idx] = projected_pos\n\n    # Interpolate missing values if subsampling was used\n    if self.subsample_positions and len(original_indices) &lt; n_positions:\n        linear_positions, track_segment_ids, projected_positions = (\n            self._interpolate_missing_values(\n                linear_positions,\n                track_segment_ids,\n                projected_positions,\n                original_indices,\n                valid_mask,\n            )\n        )\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker","title":"<code>NodePicker</code>","text":"<p>Interactive creation of track graph by looking at video frames.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on, by default None.</p> <code>None</code> <code>basepath</code> <code>str</code> <p>The base path for saving data, by default None.</p> <code>None</code> <code>node_color</code> <code>str</code> <p>The color of the nodes, by default \"#177ee6\".</p> <code>'#177ee6'</code> <code>node_size</code> <code>int</code> <p>The size of the nodes, by default 100.</p> <code>100</code> <code>epoch</code> <code>int</code> <p>The epoch number, by default None.</p> <code>None</code> <code>interval</code> <code>Tuple[float, float]</code> <p>Time interval to process, by default None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on.</p> <code>canvas</code> <code>FigureCanvas</code> <p>The matplotlib figure canvas.</p> <code>cid</code> <code>int</code> <p>The connection id for the event handler.</p> <code>_nodes</code> <code>list</code> <p>The list of node positions.</p> <code>node_color</code> <code>str</code> <p>The color of the nodes.</p> <code>_nodes_plot</code> <code>scatter</code> <p>The scatter plot of the nodes.</p> <code>edges</code> <code>list</code> <p>The list of edges.</p> <code>basepath</code> <code>str</code> <p>The base path for saving data.</p> <code>epoch</code> <code>int</code> <p>The epoch number.</p> <code>use_HMM</code> <code>bool</code> <p>Whether to use the hidden markov model.</p> <p>Methods:</p> Name Description <code>node_positions</code> <p>Get the positions of the nodes.</p> <code>connect</code> <p>Connect the event handlers.</p> <code>disconnect</code> <p>Disconnect the event handlers.</p> <code>process_key</code> <p>Process key press events.</p> <code>click_event</code> <p>Process mouse click events.</p> <code>redraw</code> <p>Redraw the nodes and edges.</p> <code>remove_point</code> <p>Remove a point from the nodes.</p> <code>clear</code> <p>Clear all nodes and edges.</p> <code>format_and_save</code> <p>Format the data and save it to disk.</p> <code>save_nodes_edges</code> <p>Save the nodes and edges to a pickle file.</p> <code>save_nodes_edges_to_behavior</code> <p>Store nodes and edges into behavior file.</p> <p>Examples:</p>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker--in-command-line","title":"in command line","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker--for-a-specific-epoch","title":"for a specific epoch","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session 1\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker--for-a-specific-interval","title":"for a specific interval","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session 0 100\n</code></pre> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class NodePicker:\n    \"\"\"\n    Interactive creation of track graph by looking at video frames.\n\n    Parameters\n    ----------\n    ax : plt.Axes, optional\n        The matplotlib axes to draw on, by default None.\n    basepath : str, optional\n        The base path for saving data, by default None.\n    node_color : str, optional\n        The color of the nodes, by default \"#177ee6\".\n    node_size : int, optional\n        The size of the nodes, by default 100.\n    epoch : int, optional\n        The epoch number, by default None.\n    interval : Tuple[float, float], optional\n        Time interval to process, by default None.\n\n    Attributes\n    ----------\n    ax : plt.Axes\n        The matplotlib axes to draw on.\n    canvas : plt.FigureCanvas\n        The matplotlib figure canvas.\n    cid : int\n        The connection id for the event handler.\n    _nodes : list\n        The list of node positions.\n    node_color : str\n        The color of the nodes.\n    _nodes_plot : plt.scatter\n        The scatter plot of the nodes.\n    edges : list\n        The list of edges.\n    basepath : str\n        The base path for saving data.\n    epoch : int\n        The epoch number.\n    use_HMM : bool\n        Whether to use the hidden markov model.\n\n    Methods\n    -------\n    node_positions\n        Get the positions of the nodes.\n    connect\n        Connect the event handlers.\n    disconnect\n        Disconnect the event handlers.\n    process_key\n        Process key press events.\n    click_event\n        Process mouse click events.\n    redraw\n        Redraw the nodes and edges.\n    remove_point\n        Remove a point from the nodes.\n    clear\n        Clear all nodes and edges.\n    format_and_save\n        Format the data and save it to disk.\n    save_nodes_edges\n        Save the nodes and edges to a pickle file.\n    save_nodes_edges_to_behavior\n        Store nodes and edges into behavior file.\n\n    Examples\n    --------\n    # in command line\n    &gt;&gt;&gt; python linearization.py path/to/session\n\n    # for a specific epoch\n    &gt;&gt;&gt; python linearization.py path/to/session 1\n\n    # for a specific interval\n    &gt;&gt;&gt; python linearization.py path/to/session 0 100\n    \"\"\"\n\n    def __init__(\n        self,\n        ax: Optional[plt.Axes] = None,\n        basepath: Optional[str] = None,\n        node_color: str = \"#177ee6\",\n        node_size: int = 100,\n        epoch: Optional[int] = None,\n        interval: Optional[Tuple[float, float]] = None,\n    ):\n        \"\"\"\n        Initialize the NodePicker.\n\n        Parameters\n        ----------\n        ax : plt.Axes, optional\n            The matplotlib axes to draw on, by default None.\n        basepath : str, optional\n            The base path for saving data, by default None.\n        node_color : str, optional\n            The color of the nodes, by default \"#177ee6\".\n        node_size : int, optional\n            The size of the nodes, by default 100.\n        epoch : int, optional\n            The epoch number, by default None.\n        interval : Tuple[float, float], optional\n            Time interval to process, by default None.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n        self.ax = ax\n        self.canvas = ax.get_figure().canvas\n        self.cid = None\n        self._nodes = []\n        self.node_color = node_color\n        self._nodes_plot = ax.scatter([], [], zorder=5, s=node_size, color=node_color)\n        self.edges = [[]]\n        self.basepath = basepath\n        self.epoch = epoch\n        self.interval = interval\n        self.use_HMM = True\n\n        if self.epoch is not None:\n            self.epoch = int(self.epoch)\n\n        ax.set_title(\n            \"Left click to place node.\\nRight click to remove node.\"\n            \"\\nShift+Left click to clear nodes.\\nCntrl+Left click two nodes to place an edge\"\n            \"\\nEnter to save and exit.\",\n            fontsize=8,\n        )\n\n        self.canvas.draw()\n        self.connect()\n\n    @property\n    def node_positions(self) -&gt; np.ndarray:\n        \"\"\"\n        Get the positions of the nodes.\n\n        Returns\n        -------\n        np.ndarray\n            An array of node positions.\n        \"\"\"\n        return np.asarray(self._nodes)\n\n    def connect(self) -&gt; None:\n        \"\"\"Connect the event handlers.\"\"\"\n        print(\"Connecting to events\")\n        if self.cid is None:\n            self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n            self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n            print(\"Mouse click event connected!\")\n\n    def disconnect(self) -&gt; None:\n        \"\"\"Disconnect the event handlers.\"\"\"\n        if self.cid is not None:\n            self.canvas.mpl_disconnect(self.cid)\n            self.cid = None\n\n    def process_key(self, event: Any) -&gt; None:\n        \"\"\"\n        Process key press events.\n\n        Parameters\n        ----------\n        event : Any\n            The key press event.\n        \"\"\"\n        if event.key == \"enter\":\n            self.format_and_save()\n\n    def click_event(self, event: Any) -&gt; None:\n        \"\"\"\n        Process mouse click events.\n\n        Parameters\n        ----------\n        event : Any\n            The mouse click event.\n        \"\"\"\n        print(\n            f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n        )\n        if not event.inaxes:\n            return\n\n        if event.key is None:  # Regular mouse clicks\n            if event.button == 1:  # Left click\n                self._nodes.append((event.xdata, event.ydata))\n            elif event.button == 3:  # Right click\n                self.remove_point((event.xdata, event.ydata))\n\n        elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n            self.clear()\n\n        elif (\n            event.key == \"control\" and event.button == 1\n        ):  # Ctrl + Left click (Edge creation)\n            if len(self._nodes) == 0:\n                return\n            point = (event.xdata, event.ydata)\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            if len(self.edges[-1]) &lt; 2:\n                self.edges[-1].append(closest_node_ind)\n            else:\n                self.edges.append([closest_node_ind])\n\n        elif event.key == \"enter\":  # Pressing Enter\n            self.format_and_save()\n\n        self.redraw()\n\n    def redraw(self) -&gt; None:\n        \"\"\"Redraw the nodes and edges.\"\"\"\n        # Draw Node Circles\n        if len(self.node_positions) &gt; 0:\n            self._nodes_plot.set_offsets(self.node_positions)\n        else:\n            self._nodes_plot.set_offsets([])\n\n        # Draw Node Numbers\n        for ind, (x, y) in enumerate(self.node_positions):\n            self.ax.text(\n                x,\n                y,\n                ind,\n                zorder=6,\n                fontsize=10,\n                horizontalalignment=\"center\",\n                verticalalignment=\"center\",\n                clip_on=True,\n                bbox=None,\n                transform=self.ax.transData,\n            )\n        # Draw Edges\n        for edge in self.edges:\n            if len(edge) &gt; 1:\n                x1, y1 = self.node_positions[edge[0]]\n                x2, y2 = self.node_positions[edge[1]]\n                self.ax.plot(\n                    [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n                )\n        self.canvas.draw()\n\n    def remove_point(self, point: Tuple[float, float]) -&gt; None:\n        \"\"\"\n        Remove a point from the nodes.\n\n        Parameters\n        ----------\n        point : Tuple[float, float]\n            The point to remove.\n        \"\"\"\n        if len(self._nodes) &gt; 0:\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            self._nodes.pop(closest_node_ind)\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear all nodes and edges.\"\"\"\n        self._nodes = []\n        self.edges = [[]]\n        self.redraw()\n\n    def format_and_save(self) -&gt; None:\n        \"\"\"Format the data and save it to disk.\"\"\"\n        behave_df = load_animal_behavior(self.basepath)\n\n        if self.epoch is not None:\n            epochs = load_epoch(self.basepath)\n\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n                &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n            )\n        elif self.interval is not None:\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= self.interval[0])\n                &amp; (behave_df.time &lt;= self.interval[1])\n            )\n        else:\n            cur_epoch = ~np.isnan(behave_df.x)\n\n        print(\"running linearization...\")\n        track_graph = make_track_graph(self.node_positions, self.edges)\n\n        position = np.vstack(\n            [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n        ).T\n\n        position_df = get_linearized_position(\n            position=position,\n            track_graph=track_graph,\n            edge_order=self.edges,\n            use_HMM=self.use_HMM,\n            show_confirmation_plot=True,\n            # HMM optimization parameters - Updated defaults based on diagnostic results\n            n_bins_per_segment=50,  # Increased from 30 for better accuracy\n            use_sparse_transitions=True,  # Essential for multi-segment classification\n            subsample_positions=False,  # Keep False for accuracy\n            subsample_factor=5,\n            use_adaptive_subsampling=True,\n            # Advanced optimization parameters\n            use_batch_processing=False,\n            batch_size=1000,\n        )\n\n        print(\"saving to disk...\")\n        behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n        behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n        behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n            position_df.projected_x_position.values\n        )\n        behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n            position_df.projected_y_position.values\n        )\n\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n        )\n\n        data = loadmat(filename, simplify_cells=True)\n\n        data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n        data[\"behavior\"][\"states\"] = behave_df.states.values\n        data[\"behavior\"][\"position\"][\"projected_x\"] = (\n            behave_df.projected_x_position.values\n        )\n        data[\"behavior\"][\"position\"][\"projected_y\"] = (\n            behave_df.projected_y_position.values\n        )\n\n        # store nodes and edges within behavior file\n        data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n        savemat(filename, data, long_field_names=True)\n\n        self.save_nodes_edges()\n        self.disconnect()\n\n    def save_nodes_edges(self) -&gt; None:\n        \"\"\"Save the nodes and edges to a pickle file.\"\"\"\n        results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n        save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n        with open(save_file, \"wb\") as f:\n            pickle.dump(results, f)\n\n    def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n        \"\"\"\n        Store nodes and edges into behavior file.\n        Searches to find epochs with valid linearized coords.\n        Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n        Parameters\n        ----------\n        data : dict\n            The behavior data dictionary.\n        behave_df : pd.DataFrame\n            The DataFrame containing behavior data.\n\n        Returns\n        -------\n        dict\n            The updated behavior data dictionary.\n        \"\"\"\n        if self.epoch is None and self.interval is None:\n            # load epochs\n            epochs = load_epoch(self.basepath)\n            # iter over each epoch\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # locate index for given epoch\n                idx = behave_df.time.between(ep.startTime, ep.stopTime)\n                # if linearized is not all nan, add nodes and edges\n                if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                    behave_df[idx].shape[0] != 0\n                ):\n                    # adding nodes and edges\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        elif self.interval is not None:\n            # if interval was used, add nodes and edges just the epochs within that interval\n            epochs = load_epoch(self.basepath)\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # amount of overlap between interval and epoch\n                start_overlap = max(self.interval[0], ep.startTime)\n                end_overlap = min(self.interval[1], ep.stopTime)\n                overlap = max(0, end_overlap - start_overlap)\n\n                # if overlap is greater than 1 second, add nodes and edges\n                if overlap &gt; 1:\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        else:\n            # if epoch was used, add nodes and edges just that that epoch\n            data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n                self.node_positions\n            )\n            data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n        return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.node_positions","title":"<code>node_positions</code>  <code>property</code>","text":"<p>Get the positions of the nodes.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of node positions.</p>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.clear","title":"<code>clear()</code>","text":"<p>Clear all nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clear all nodes and edges.\"\"\"\n    self._nodes = []\n    self.edges = [[]]\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.click_event","title":"<code>click_event(event)</code>","text":"<p>Process mouse click events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The mouse click event.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def click_event(self, event: Any) -&gt; None:\n    \"\"\"\n    Process mouse click events.\n\n    Parameters\n    ----------\n    event : Any\n        The mouse click event.\n    \"\"\"\n    print(\n        f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n    )\n    if not event.inaxes:\n        return\n\n    if event.key is None:  # Regular mouse clicks\n        if event.button == 1:  # Left click\n            self._nodes.append((event.xdata, event.ydata))\n        elif event.button == 3:  # Right click\n            self.remove_point((event.xdata, event.ydata))\n\n    elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n        self.clear()\n\n    elif (\n        event.key == \"control\" and event.button == 1\n    ):  # Ctrl + Left click (Edge creation)\n        if len(self._nodes) == 0:\n            return\n        point = (event.xdata, event.ydata)\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        if len(self.edges[-1]) &lt; 2:\n            self.edges[-1].append(closest_node_ind)\n        else:\n            self.edges.append([closest_node_ind])\n\n    elif event.key == \"enter\":  # Pressing Enter\n        self.format_and_save()\n\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.connect","title":"<code>connect()</code>","text":"<p>Connect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def connect(self) -&gt; None:\n    \"\"\"Connect the event handlers.\"\"\"\n    print(\"Connecting to events\")\n    if self.cid is None:\n        self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n        self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n        print(\"Mouse click event connected!\")\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.disconnect","title":"<code>disconnect()</code>","text":"<p>Disconnect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def disconnect(self) -&gt; None:\n    \"\"\"Disconnect the event handlers.\"\"\"\n    if self.cid is not None:\n        self.canvas.mpl_disconnect(self.cid)\n        self.cid = None\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.format_and_save","title":"<code>format_and_save()</code>","text":"<p>Format the data and save it to disk.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def format_and_save(self) -&gt; None:\n    \"\"\"Format the data and save it to disk.\"\"\"\n    behave_df = load_animal_behavior(self.basepath)\n\n    if self.epoch is not None:\n        epochs = load_epoch(self.basepath)\n\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n            &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n        )\n    elif self.interval is not None:\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= self.interval[0])\n            &amp; (behave_df.time &lt;= self.interval[1])\n        )\n    else:\n        cur_epoch = ~np.isnan(behave_df.x)\n\n    print(\"running linearization...\")\n    track_graph = make_track_graph(self.node_positions, self.edges)\n\n    position = np.vstack(\n        [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n    ).T\n\n    position_df = get_linearized_position(\n        position=position,\n        track_graph=track_graph,\n        edge_order=self.edges,\n        use_HMM=self.use_HMM,\n        show_confirmation_plot=True,\n        # HMM optimization parameters - Updated defaults based on diagnostic results\n        n_bins_per_segment=50,  # Increased from 30 for better accuracy\n        use_sparse_transitions=True,  # Essential for multi-segment classification\n        subsample_positions=False,  # Keep False for accuracy\n        subsample_factor=5,\n        use_adaptive_subsampling=True,\n        # Advanced optimization parameters\n        use_batch_processing=False,\n        batch_size=1000,\n    )\n\n    print(\"saving to disk...\")\n    behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n    behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n    behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n        position_df.projected_x_position.values\n    )\n    behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n        position_df.projected_y_position.values\n    )\n\n    filename = os.path.join(\n        self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n    )\n\n    data = loadmat(filename, simplify_cells=True)\n\n    data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n    data[\"behavior\"][\"states\"] = behave_df.states.values\n    data[\"behavior\"][\"position\"][\"projected_x\"] = (\n        behave_df.projected_x_position.values\n    )\n    data[\"behavior\"][\"position\"][\"projected_y\"] = (\n        behave_df.projected_y_position.values\n    )\n\n    # store nodes and edges within behavior file\n    data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n    savemat(filename, data, long_field_names=True)\n\n    self.save_nodes_edges()\n    self.disconnect()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.process_key","title":"<code>process_key(event)</code>","text":"<p>Process key press events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The key press event.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def process_key(self, event: Any) -&gt; None:\n    \"\"\"\n    Process key press events.\n\n    Parameters\n    ----------\n    event : Any\n        The key press event.\n    \"\"\"\n    if event.key == \"enter\":\n        self.format_and_save()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.redraw","title":"<code>redraw()</code>","text":"<p>Redraw the nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def redraw(self) -&gt; None:\n    \"\"\"Redraw the nodes and edges.\"\"\"\n    # Draw Node Circles\n    if len(self.node_positions) &gt; 0:\n        self._nodes_plot.set_offsets(self.node_positions)\n    else:\n        self._nodes_plot.set_offsets([])\n\n    # Draw Node Numbers\n    for ind, (x, y) in enumerate(self.node_positions):\n        self.ax.text(\n            x,\n            y,\n            ind,\n            zorder=6,\n            fontsize=10,\n            horizontalalignment=\"center\",\n            verticalalignment=\"center\",\n            clip_on=True,\n            bbox=None,\n            transform=self.ax.transData,\n        )\n    # Draw Edges\n    for edge in self.edges:\n        if len(edge) &gt; 1:\n            x1, y1 = self.node_positions[edge[0]]\n            x2, y2 = self.node_positions[edge[1]]\n            self.ax.plot(\n                [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n            )\n    self.canvas.draw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.remove_point","title":"<code>remove_point(point)</code>","text":"<p>Remove a point from the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Tuple[float, float]</code> <p>The point to remove.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def remove_point(self, point: Tuple[float, float]) -&gt; None:\n    \"\"\"\n    Remove a point from the nodes.\n\n    Parameters\n    ----------\n    point : Tuple[float, float]\n        The point to remove.\n    \"\"\"\n    if len(self._nodes) &gt; 0:\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        self._nodes.pop(closest_node_ind)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.save_nodes_edges","title":"<code>save_nodes_edges()</code>","text":"<p>Save the nodes and edges to a pickle file.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def save_nodes_edges(self) -&gt; None:\n    \"\"\"Save the nodes and edges to a pickle file.\"\"\"\n    results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n    save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n    with open(save_file, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.NodePicker.save_nodes_edges_to_behavior","title":"<code>save_nodes_edges_to_behavior(data, behave_df)</code>","text":"<p>Store nodes and edges into behavior file. Searches to find epochs with valid linearized coords. Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>The behavior data dictionary.</p> required <code>behave_df</code> <code>DataFrame</code> <p>The DataFrame containing behavior data.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The updated behavior data dictionary.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n    \"\"\"\n    Store nodes and edges into behavior file.\n    Searches to find epochs with valid linearized coords.\n    Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n    Parameters\n    ----------\n    data : dict\n        The behavior data dictionary.\n    behave_df : pd.DataFrame\n        The DataFrame containing behavior data.\n\n    Returns\n    -------\n    dict\n        The updated behavior data dictionary.\n    \"\"\"\n    if self.epoch is None and self.interval is None:\n        # load epochs\n        epochs = load_epoch(self.basepath)\n        # iter over each epoch\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # locate index for given epoch\n            idx = behave_df.time.between(ep.startTime, ep.stopTime)\n            # if linearized is not all nan, add nodes and edges\n            if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                behave_df[idx].shape[0] != 0\n            ):\n                # adding nodes and edges\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    elif self.interval is not None:\n        # if interval was used, add nodes and edges just the epochs within that interval\n        epochs = load_epoch(self.basepath)\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # amount of overlap between interval and epoch\n            start_overlap = max(self.interval[0], ep.startTime)\n            end_overlap = min(self.interval[1], ep.stopTime)\n            overlap = max(0, end_overlap - start_overlap)\n\n            # if overlap is greater than 1 second, add nodes and edges\n            if overlap &gt; 1:\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    else:\n        # if epoch was used, add nodes and edges just that that epoch\n        data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n            self.node_positions\n        )\n        data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n    return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.TrackGraph","title":"<code>TrackGraph</code>","text":"<p>A simple track graph implementation for linearization.</p> <p>Parameters:</p> Name Type Description Default <code>node_positions</code> <code>ndarray</code> <p>Array of node positions (n_nodes, 2)</p> required <code>edges</code> <code>list</code> <p>List of edge connections between nodes</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class TrackGraph:\n    \"\"\"\n    A simple track graph implementation for linearization.\n\n    Parameters\n    ----------\n    node_positions : np.ndarray\n        Array of node positions (n_nodes, 2)\n    edges : list\n        List of edge connections between nodes\n    \"\"\"\n\n    def __init__(self, node_positions: np.ndarray, edges: List[List[int]]):\n        self.node_positions = np.asarray(node_positions)\n        self.edges = edges\n        self.n_nodes = len(node_positions)\n\n        # Create adjacency matrix\n        self.adjacency_matrix = self._create_adjacency_matrix()\n\n        # Calculate distances between connected nodes\n        self.edge_distances = self._calculate_edge_distances()\n\n        # Calculate cumulative distances for linearization\n        self.cumulative_distances = self._calculate_cumulative_distances()\n\n    def _create_adjacency_matrix(self) -&gt; csr_matrix:\n        \"\"\"Create sparse adjacency matrix from edges.\"\"\"\n        row_indices = []\n        col_indices = []\n\n        for edge in self.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    row_indices.extend([edge[i], edge[i + 1]])\n                    col_indices.extend([edge[i + 1], edge[i]])\n\n        data = np.ones(len(row_indices))\n        return csr_matrix(\n            (data, (row_indices, col_indices)), shape=(self.n_nodes, self.n_nodes)\n        )\n\n    def _calculate_edge_distances(self) -&gt; dict:\n        \"\"\"Calculate distances between connected nodes.\"\"\"\n        distances = {}\n        for edge in self.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    dist = np.linalg.norm(\n                        self.node_positions[node1] - self.node_positions[node2]\n                    )\n                    distances[(node1, node2)] = dist\n                    distances[(node2, node1)] = dist\n        return distances\n\n    def _calculate_cumulative_distances(self) -&gt; np.ndarray:\n        \"\"\"Calculate cumulative distances along the track.\"\"\"\n        # Find the main path through the track\n        # For simplicity, we'll use the first edge as the starting point\n        if not self.edges or len(self.edges[0]) &lt; 2:\n            return np.zeros(self.n_nodes)\n\n        cumulative = np.zeros(self.n_nodes)\n        visited = set()\n\n        # Start from the first edge\n        current_edge = self.edges[0]\n        if len(current_edge) &gt;= 2:\n            for i in range(len(current_edge) - 1):\n                node1, node2 = current_edge[i], current_edge[i + 1]\n                if node1 not in visited:\n                    visited.add(node1)\n                if node2 not in visited:\n                    visited.add(node2)\n                    cumulative[node2] = cumulative[node1] + self.edge_distances.get(\n                        (node1, node2), 0\n                    )\n\n        return cumulative\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.TrackGraph._calculate_cumulative_distances","title":"<code>_calculate_cumulative_distances()</code>","text":"<p>Calculate cumulative distances along the track.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_cumulative_distances(self) -&gt; np.ndarray:\n    \"\"\"Calculate cumulative distances along the track.\"\"\"\n    # Find the main path through the track\n    # For simplicity, we'll use the first edge as the starting point\n    if not self.edges or len(self.edges[0]) &lt; 2:\n        return np.zeros(self.n_nodes)\n\n    cumulative = np.zeros(self.n_nodes)\n    visited = set()\n\n    # Start from the first edge\n    current_edge = self.edges[0]\n    if len(current_edge) &gt;= 2:\n        for i in range(len(current_edge) - 1):\n            node1, node2 = current_edge[i], current_edge[i + 1]\n            if node1 not in visited:\n                visited.add(node1)\n            if node2 not in visited:\n                visited.add(node2)\n                cumulative[node2] = cumulative[node1] + self.edge_distances.get(\n                    (node1, node2), 0\n                )\n\n    return cumulative\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.TrackGraph._calculate_edge_distances","title":"<code>_calculate_edge_distances()</code>","text":"<p>Calculate distances between connected nodes.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_edge_distances(self) -&gt; dict:\n    \"\"\"Calculate distances between connected nodes.\"\"\"\n    distances = {}\n    for edge in self.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                dist = np.linalg.norm(\n                    self.node_positions[node1] - self.node_positions[node2]\n                )\n                distances[(node1, node2)] = dist\n                distances[(node2, node1)] = dist\n    return distances\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.TrackGraph._create_adjacency_matrix","title":"<code>_create_adjacency_matrix()</code>","text":"<p>Create sparse adjacency matrix from edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _create_adjacency_matrix(self) -&gt; csr_matrix:\n    \"\"\"Create sparse adjacency matrix from edges.\"\"\"\n    row_indices = []\n    col_indices = []\n\n    for edge in self.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                row_indices.extend([edge[i], edge[i + 1]])\n                col_indices.extend([edge[i + 1], edge[i]])\n\n    data = np.ones(len(row_indices))\n    return csr_matrix(\n        (data, (row_indices, col_indices)), shape=(self.n_nodes, self.n_nodes)\n    )\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.enter_exit_target","title":"<code>enter_exit_target(position, target, max_distance=1.0)</code>","text":"<p>Marks when a position has reached a target (\"enter\") and when it has left a target (\"exit\").</p> <p>The position is considered to have reached a target when it is less than the <code>max_distance</code> from the target.</p> <p>Enter and exit times are marked as follows:  1: entered the target radius  0: neither -1: exited the target radius</p> <p>Works for 1D position and 2D position.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <code>target</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (1, n_space).</p> required <code>max_distance</code> <code>float</code> <p>How close the position is to the target to be considered at the target, by default 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of two arrays: - The first array contains the enter/exit times. - The second array contains the times when the position is at the target.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def enter_exit_target(\n    position: Union[np.ndarray, list],\n    target: Union[np.ndarray, list],\n    max_distance: float = 1.0,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Marks when a position has reached a target (\"enter\") and when it has left a target (\"exit\").\n\n    The position is considered to have reached a target when it is less than\n    the `max_distance` from the target.\n\n    Enter and exit times are marked as follows:\n     1: entered the target radius\n     0: neither\n    -1: exited the target radius\n\n    Works for 1D position and 2D position.\n\n    Parameters\n    ----------\n    position : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n    target : Union[np.ndarray, list]\n        Array or list of shape (1, n_space).\n    max_distance : float, optional\n        How close the position is to the target to be considered at the target, by default 1.0.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple of two arrays:\n        - The first array contains the enter/exit times.\n        - The second array contains the times when the position is at the target.\n    \"\"\"\n    distance_from_target = paired_distances(position, target)\n    at_target = distance_from_target &lt; max_distance\n    enter_exit = np.r_[0, np.diff(at_target.astype(float))]\n    return enter_exit, at_target\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.enter_exit_target_dio","title":"<code>enter_exit_target_dio(dio_indicator)</code>","text":"<p>Marks when a digital input/output (DIO) indicator has entered or exited a target state.</p> <p>Parameters:</p> Name Type Description Default <code>dio_indicator</code> <code>ndarray</code> <p>Array of DIO indicator values.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing: - enter_exit: np.ndarray     Array indicating enter (1) and exit (-1) events. - at_target: np.ndarray     Array indicating whether the target is active (1) or not (0).</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def enter_exit_target_dio(dio_indicator: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Marks when a digital input/output (DIO) indicator has entered or exited a target state.\n\n    Parameters\n    ----------\n    dio_indicator : np.ndarray\n        Array of DIO indicator values.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing:\n        - enter_exit: np.ndarray\n            Array indicating enter (1) and exit (-1) events.\n        - at_target: np.ndarray\n            Array indicating whether the target is active (1) or not (0).\n    \"\"\"\n    at_target = (dio_indicator &gt; 0).astype(np.float16)\n    enter_exit = np.r_[0, np.diff(at_target)]\n    return enter_exit, at_target\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.filter_tracker_jumps","title":"<code>filter_tracker_jumps(beh_df, max_speed=100)</code>","text":"<p>Filter out tracker jumps (to NaN) in the behavior data.</p> <p>Parameters:</p> Name Type Description Default <code>beh_df</code> <code>DataFrame</code> <p>Behavior data with columns x, y, and timestamps.</p> required <code>max_speed</code> <code>Union[int, float]</code> <p>Maximum allowed speed in cm per second.</p> <code>100</code> <p>Returns:</p> Type Description <code>DataFrame</code> Notes <p>Will force dtypes of x and y to float64</p> Source code in <code>neuro_py/behavior/preprocessing.py</code> <pre><code>def filter_tracker_jumps(\n    beh_df: pd.DataFrame, max_speed: Union[int, float] = 100\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Filter out tracker jumps (to NaN) in the behavior data.\n\n    Parameters\n    ----------\n    beh_df : pd.DataFrame\n        Behavior data with columns x, y, and timestamps.\n    max_speed : Union[int,float], optional\n        Maximum allowed speed in cm per second.\n\n    Returns\n    -------\n    pd.DataFrame\n\n    Notes\n    -----\n    Will force dtypes of x and y to float64\n    \"\"\"\n\n    # Calculate the Euclidean distance between consecutive points\n    beh_df[\"dx\"] = beh_df[\"x\"].diff()\n    beh_df[\"dy\"] = beh_df[\"y\"].diff()\n    beh_df[\"distance\"] = np.sqrt(beh_df[\"dx\"] ** 2 + beh_df[\"dy\"] ** 2)\n\n    # Calculate the time difference between consecutive timestamps\n    beh_df[\"dt\"] = beh_df[\"timestamps\"].diff()\n\n    # Calculate the speed between consecutive points (distance / time)\n    beh_df[\"speed\"] = beh_df[\"distance\"] / beh_df[\"dt\"]\n\n    # Identify the start of each jump\n    # A jump starts when the speed exceeds the threshold, and the previous speed did not\n    jump_starts = (beh_df[\"speed\"] &gt; max_speed) &amp; (\n        beh_df[\"speed\"].shift(1) &lt;= max_speed\n    )\n\n    # Mark x and y as NaN only for the first frame of each jump\n    beh_df.loc[jump_starts, [\"x\", \"y\"]] = np.nan\n\n    beh_df = beh_df.drop(columns=[\"dx\", \"dy\", \"distance\", \"dt\", \"speed\"])\n\n    return beh_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.filter_tracker_jumps_in_file","title":"<code>filter_tracker_jumps_in_file(basepath, epoch_number=None, epoch_interval=None)</code>","text":"<p>Filter out tracker jumps in the behavior data (to NaN) and save the filtered data back to the file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Basepath to the behavior file.</p> required <code>epoch_number</code> <code>int</code> <p>Epoch number to filter the behavior data to.</p> <code>None</code> <code>epoch_interval</code> <code>tuple</code> <p>Epoch interval to filter the behavior data to.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = \"path/to/behavior/file\"\n&gt;&gt;&gt; filter_tracker_jumps_in_file(basepath, epoch_number=1)\n</code></pre> Source code in <code>neuro_py/behavior/preprocessing.py</code> <pre><code>def filter_tracker_jumps_in_file(\n    basepath: str, epoch_number=None, epoch_interval=None\n) -&gt; None:\n    \"\"\"\n    Filter out tracker jumps in the behavior data (to NaN) and save the filtered data back to the file.\n\n    Parameters\n    ----------\n    basepath : str\n        Basepath to the behavior file.\n    epoch_number : int, optional\n        Epoch number to filter the behavior data to.\n    epoch_interval : tuple, optional\n        Epoch interval to filter the behavior data to.\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; basepath = \"path/to/behavior/file\"\n    &gt;&gt;&gt; filter_tracker_jumps_in_file(basepath, epoch_number=1)\n    \"\"\"\n\n    # Load the behavior data\n    file = os.path.join(basepath, os.path.basename(basepath) + \".animal.behavior.mat\")\n\n    behavior = loadmat(file, simplify_cells=True)\n\n    # Filter the behavior data to remove tracker jumps\n    if epoch_number is not None:\n        epoch_df = npy.io.load_epoch(basepath)\n        idx = (\n            behavior[\"behavior\"][\"timestamps\"] &gt; epoch_df.loc[epoch_number].startTime\n        ) &amp; (behavior[\"behavior\"][\"timestamps\"] &lt; epoch_df.loc[epoch_number].stopTime)\n    elif epoch_interval is not None:\n        idx = (behavior[\"behavior\"][\"timestamps\"] &gt; epoch_interval[0]) &amp; (\n            behavior[\"behavior\"][\"timestamps\"] &lt; epoch_interval[1]\n        )\n    else:\n        # bool length of the same length as the number of timestamps\n        idx = np.ones(len(behavior[\"behavior\"][\"timestamps\"]), dtype=bool)\n\n    # Filter the behavior data and add to dataframe\n    x = behavior[\"behavior\"][\"position\"][\"x\"][idx]\n    y = behavior[\"behavior\"][\"position\"][\"y\"][idx]\n    ts = behavior[\"behavior\"][\"timestamps\"][idx]\n    beh_df = pd.DataFrame({\"x\": x, \"y\": y, \"timestamps\": ts})\n\n    # Filter out tracker jumps\n    beh_df = filter_tracker_jumps(beh_df)\n\n    # Save the filtered behavior data back to the file\n    behavior[\"behavior\"][\"position\"][\"x\"][idx] = beh_df.x.values\n    behavior[\"behavior\"][\"position\"][\"y\"][idx] = beh_df.y.values\n\n    savemat(file, behavior, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.find_good_lap_epochs","title":"<code>find_good_lap_epochs(pos, dir_epoch, thres=0.5, binsize=6, min_laps=10)</code>","text":"<p>Find good laps in behavior data</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>AnalogSignalArray</code> <p>A nelpy AnalogSignalArray containing the position data with a single dimension.</p> required <code>dir_epoch</code> <code>EpochArray</code> <p>EpochArray defining the laps to analyze for good laps.</p> required <code>thres</code> <code>float</code> <p>Occupancy threshold to determine good laps, by default 0.5.</p> <code>0.5</code> <code>binsize</code> <code>int</code> <p>Size of the bins for calculating occupancy, by default 6.</p> <code>6</code> <code>min_laps</code> <code>int</code> <p>Minimum number of laps required to consider laps as 'good', by default 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>An EpochArray containing the good laps based on the occupancy threshold. Returns an empty EpochArray if no good laps are found or if the number of laps is less than <code>min_laps</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; good_laps = find_good_lap_epochs(pos, dir_epoch)\n</code></pre> Notes <p>The function calculates the percent occupancy over position bins per lap, and identifies laps that meet the occupancy threshold criteria. The laps that meet this condition are returned as an EpochArray.</p> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def find_good_lap_epochs(\n    pos: nel.AnalogSignalArray,\n    dir_epoch: nel.EpochArray,\n    thres: float = 0.5,\n    binsize: int = 6,\n    min_laps: int = 10,\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Find good laps in behavior data\n\n    Parameters\n    ----------\n    pos : nelpy.AnalogSignalArray\n        A nelpy AnalogSignalArray containing the position data with a single dimension.\n    dir_epoch : nelpy.EpochArray\n        EpochArray defining the laps to analyze for good laps.\n    thres : float, optional\n        Occupancy threshold to determine good laps, by default 0.5.\n    binsize : int, optional\n        Size of the bins for calculating occupancy, by default 6.\n    min_laps : int, optional\n        Minimum number of laps required to consider laps as 'good', by default 10.\n\n    Returns\n    -------\n    nelpy.EpochArray\n        An EpochArray containing the good laps based on the occupancy threshold.\n        Returns an empty EpochArray if no good laps are found or if the number\n        of laps is less than `min_laps`.\n\n    Examples\n    -------\n    &gt;&gt;&gt; good_laps = find_good_lap_epochs(pos, dir_epoch)\n\n    Notes\n    -----\n    The function calculates the percent occupancy over position bins per lap,\n    and identifies laps that meet the occupancy threshold criteria. The laps\n    that meet this condition are returned as an EpochArray.\n    \"\"\"\n    # Ensure the input data is valid\n    if pos.isempty or dir_epoch.isempty:\n        return nel.EpochArray()\n\n    # make bin edges to calc occupancy\n    x_edges = np.arange(np.nanmin(pos.data[0]), np.nanmax(pos.data[0]), binsize)\n    # initialize occupancy matrix (position x time)\n    occ = np.zeros([len(x_edges) - 1, dir_epoch.n_intervals])\n\n    # much faster to not use nelpy objects here, so pull out needed data\n    x_coord = pos.data[0]\n    time = pos.abscissa_vals\n    epochs = dir_epoch.data\n\n    # iterate through laps\n    for i, ep in enumerate(epochs):\n        # bin position per lap\n        occ[:, i], _ = np.histogram(\n            x_coord[(time &gt;= ep[0]) &amp; (time &lt;= ep[1])], bins=x_edges\n        )\n\n    # calc percent occupancy over position bins per lap and find good laps\n    good_laps = np.where(~((np.sum(occ == 0, axis=0) / occ.shape[0]) &gt; thres))[0]\n    # if no good laps, return empty epoch\n    if (len(good_laps) == 0) | (len(good_laps) &lt; min_laps):\n        dir_epoch = nel.EpochArray()\n    else:\n        dir_epoch = dir_epoch[good_laps]\n    return dir_epoch\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.find_last_non_center_well","title":"<code>find_last_non_center_well(segments_df, segment_ind)</code>","text":"<p>Find the last non-center well before the given segment index.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>DataFrame containing segment information.</p> required <code>segment_ind</code> <code>int</code> <p>The segment index to search up to.</p> required <p>Returns:</p> Type Description <code>Union[str, int]</code> <p>The last non-center well before the given segment index. If no non-center wells are found, returns an empty string.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def find_last_non_center_well(\n    segments_df: pd.DataFrame, segment_ind: int\n) -&gt; Union[str, int]:\n    \"\"\"\n    Find the last non-center well before the given segment index.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        DataFrame containing segment information.\n    segment_ind : int\n        The segment index to search up to.\n\n    Returns\n    -------\n    Union[str, int]\n        The last non-center well before the given segment index. If no non-center wells are found,\n        returns an empty string.\n    \"\"\"\n    last_wells = segments_df.iloc[:segment_ind].to_well\n    try:\n        return last_wells[last_wells != \"Center\"].iloc[-1]\n    except IndexError:\n        # There are no non-center wells. Just return current well.\n        return \"\"\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_cheeseboard_trials","title":"<code>get_cheeseboard_trials(basepath, min_distance_from_home=15, max_trial_time=600, min_trial_time=5, kernel_size=2, min_std_away_from_home=6)</code>","text":"<p>Get epochs of cheeseboard trials.</p> <p>This function retrieves epochs for cheeseboard trials based on specified distance and time criteria.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>min_distance_from_home</code> <code>int</code> <p>The minimum distance from home to be considered a trial. Default is 15.</p> <code>15</code> <code>max_trial_time</code> <code>int</code> <p>The maximum duration of a trial in seconds. Default is 600 (10 minutes).</p> <code>600</code> <code>min_trial_time</code> <code>int</code> <p>The minimum duration of a trial in seconds. Default is 5.</p> <code>5</code> <code>kernel_size</code> <code>int</code> <p>The size of the kernel to use for smoothing. Default is 2.</p> <code>2</code> <code>min_std_away_from_home</code> <code>int</code> <p>The minimum standard deviation away from home to be considered a trial. Default is 6.</p> <code>6</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray</code> <p>The position data for the cheeseboard trials.</p> <code>trials</code> <code>EpochArray</code> <p>The epochs of the trials.</p> Notes <p>This function requires the following metadata dependencies:</p> <ul> <li><code>animal.behavior.mat</code>: contains homebox_x and homebox_y coordinates within epochs.</li> </ul> <p>You can label these with <code>label_key_locations_cheeseboard.m</code> or manually.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_cheeseboard_trials(\n    basepath: str,\n    min_distance_from_home: int = 15,\n    max_trial_time: int = 600,  # Default is 60 * 10\n    min_trial_time: int = 5,\n    kernel_size: int = 2,\n    min_std_away_from_home: int = 6,\n) -&gt; Tuple[nel.PositionArray, nel.EpochArray]:\n    \"\"\"\n    Get epochs of cheeseboard trials.\n\n    This function retrieves epochs for cheeseboard trials based on specified\n    distance and time criteria.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    min_distance_from_home : int, optional\n        The minimum distance from home to be considered a trial. Default is 15.\n    max_trial_time : int, optional\n        The maximum duration of a trial in seconds. Default is 600 (10 minutes).\n    min_trial_time : int, optional\n        The minimum duration of a trial in seconds. Default is 5.\n    kernel_size : int, optional\n        The size of the kernel to use for smoothing. Default is 2.\n    min_std_away_from_home : int, optional\n        The minimum standard deviation away from home to be considered a trial.\n        Default is 6.\n\n    Returns\n    -------\n    pos : PositionArray\n        The position data for the cheeseboard trials.\n    trials : EpochArray\n        The epochs of the trials.\n\n    Notes\n    -----\n    This function requires the following metadata dependencies:\n\n    - `animal.behavior.mat`: contains homebox_x and homebox_y coordinates within epochs.\n\n    You can label these with `label_key_locations_cheeseboard.m` or manually.\n    \"\"\"\n\n    # load position and key location metadata\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # load epochs and place in array\n    epoch_df = loading.load_epoch(basepath)\n    epoch = nel.EpochArray(\n        [np.array([epoch_df.startTime, epoch_df.stopTime]).T], label=\"session_epochs\"\n    )\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n    pos = nel.PositionArray(\n        data=position_df_no_nan[[\"x\", \"y\"]].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    # calculate kernel samples size based on sampling rate for x seconds\n    kernel_size = int(pos.fs * kernel_size)\n    # check if even number\n    if kernel_size % 2 == 0:\n        kernel_size += 1\n\n    cheeseboard_idx = np.where(epoch_df.environment == \"cheeseboard\")[0]\n    trials_temp = []\n    stddev = []\n    for idx in cheeseboard_idx:\n        # get homebox location\n        homebox_x = data[\"behavior\"][\"epochs\"][idx][\"homebox_x\"]\n        homebox_y = data[\"behavior\"][\"epochs\"][idx][\"homebox_y\"]\n\n        # get position during epoch\n        current_pos = pos[epoch[int(idx)]]\n        x, y = current_pos.data\n\n        # calculate distance from homebox\n        distance = np.sqrt((x - homebox_x) ** 2 + (y - homebox_y) ** 2)\n\n        # median filter distance to remove noise (jumps in position)\n        distance = medfilt(distance, kernel_size=kernel_size)\n\n        # find intervals where distance is greater than min_distance_from_home\n        dist_intervals = np.array(find_interval((distance &gt; min_distance_from_home)))\n\n        close_distances = distance[distance &lt; min_distance_from_home]\n        for trial in dist_intervals:\n            far_distances = distance[trial[0] : trial[1]].mean()\n\n            stddev.append(\n                (np.abs(far_distances) - np.nanmean(np.abs(close_distances), axis=0))\n                / np.nanstd(np.abs(close_distances), axis=0)\n            )\n\n        # get start and stop times of intervals\n        if len(dist_intervals) &gt; 0:\n            trials_temp.append(current_pos.time[dist_intervals])\n\n    # concatenate trials and place in EpochArray\n    trials = nel.EpochArray(np.vstack(trials_temp))\n\n    # remove trials that are too long or too short\n    trials._data = trials.data[\n        (trials.durations &lt; max_trial_time)\n        &amp; (trials.durations &gt; min_trial_time)\n        &amp; (np.array(stddev) &gt; min_std_away_from_home)\n    ]\n\n    return pos, trials\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_correct_inbound_outbound","title":"<code>get_correct_inbound_outbound(segments_df)</code>","text":"<p>Determine the task type (inbound or outbound), correctness, and turn direction for each segment.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>DataFrame containing segment information.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Updated DataFrame with additional columns for task type, correctness, and turn direction.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def get_correct_inbound_outbound(segments_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Determine the task type (inbound or outbound), correctness, and turn direction for each segment.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        DataFrame containing segment information.\n\n    Returns\n    -------\n    pd.DataFrame\n        Updated DataFrame with additional columns for task type, correctness, and turn direction.\n    \"\"\"\n    n_segments = segments_df.shape[0]\n    task = np.empty((n_segments,), dtype=object)\n    turn = np.empty((n_segments,), dtype=object)\n    is_correct = np.zeros((n_segments,), dtype=bool)\n\n    for segment_ind in np.arange(n_segments):\n        cur_segment = segments_df.iloc[segment_ind]\n        if cur_segment.from_well == \"Center\":\n            task[segment_ind] = \"Outbound\"\n            last_non_center_well = find_last_non_center_well(segments_df, segment_ind)\n            is_correct[segment_ind] = (cur_segment.to_well != last_non_center_well) &amp; (\n                cur_segment.to_well != \"Center\"\n            )\n            if (last_non_center_well != \"\") | ~is_correct[segment_ind]:\n                turn[segment_ind] = last_non_center_well\n            else:\n                is_left_turn = (\n                    (cur_segment.from_well == \"Left\")\n                    &amp; (cur_segment.to_well == \"Center\")\n                ) | (\n                    (cur_segment.from_well == \"Center\")\n                    &amp; (cur_segment.to_well == \"Right\")\n                )\n\n                turn[segment_ind] = \"Left\" if is_left_turn else \"Right\"\n        else:\n            task[segment_ind] = \"Inbound\"\n            is_correct[segment_ind] = segments_df.iloc[segment_ind].to_well == \"Center\"\n            turn[segment_ind] = cur_segment.from_well\n\n    segments_df[\"task\"] = task\n    segments_df[\"is_correct\"] = is_correct\n    segments_df[\"turn\"] = turn\n\n    return segments_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_linear_maze_trials","title":"<code>get_linear_maze_trials(basepath, epoch_input=None)</code>","text":"<p>Get trials for linear maze.</p> <p>Locates inbound and outbound laps for each linear track in the session.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The path to the base directory of the session data.</p> required <code>epoch_input</code> <code>None</code> <p>Deprecated parameter. This is no longer supported.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the linear maze trials.</p> <code>inbound_laps</code> <code>EpochArray or None</code> <p>The epochs corresponding to inbound laps.</p> <code>outbound_laps</code> <code>EpochArray or None</code> <p>The epochs corresponding to outbound laps.</p> Notes <p>If no valid position data is found, None values are returned for all outputs.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_linear_maze_trials(\n    basepath: str, epoch_input: None = None\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[nel.EpochArray, None],\n    Union[nel.EpochArray, None],\n]:\n    \"\"\"Get trials for linear maze.\n\n    Locates inbound and outbound laps for each linear track in the session.\n\n    Parameters\n    ----------\n    basepath : str\n        The path to the base directory of the session data.\n    epoch_input : None, optional\n        Deprecated parameter. This is no longer supported.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the linear maze trials.\n    inbound_laps : EpochArray or None\n        The epochs corresponding to inbound laps.\n    outbound_laps : EpochArray or None\n        The epochs corresponding to outbound laps.\n\n    Notes\n    -----\n    If no valid position data is found, None values are returned for all\n    outputs.\n    \"\"\"\n    if epoch_input is not None:\n        logging.warning(\"epoch_input is no longer supported\")\n\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    if position_df_no_nan.shape[0] == 0:\n        return None, None, None\n\n    if \"linearized\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    epoch_df = loading.load_epoch(basepath)\n    epoch = nel.EpochArray([np.array([epoch_df.startTime, epoch_df.stopTime]).T])\n\n    domain = nel.EpochArray(\n        [np.array([epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]).T]\n    )\n\n    inbound_laps_temp = []\n    outbound_laps_temp = []\n    maze_idx = np.where(epoch_df.environment == \"linear\")[0]\n    for idx in maze_idx:\n        current_position = pos[epoch[int(idx)]]\n\n        # get outbound and inbound epochs\n        outbound_laps, inbound_laps = linear_positions.get_linear_track_lap_epochs(\n            current_position.abscissa_vals, current_position.data[0], newLapThreshold=20\n        )\n        if not inbound_laps.isempty:\n            inbound_laps = linear_positions.find_good_lap_epochs(\n                current_position, inbound_laps, min_laps=5\n            )\n\n        if not outbound_laps.isempty:\n            outbound_laps = linear_positions.find_good_lap_epochs(\n                current_position, outbound_laps, min_laps=5\n            )\n\n        if not inbound_laps.isempty:\n            inbound_laps_temp.append(inbound_laps.data)\n        if not outbound_laps.isempty:\n            outbound_laps_temp.append(outbound_laps.data)\n\n    inbound_laps = nel.EpochArray(np.vstack(inbound_laps_temp), domain=domain)\n    outbound_laps = nel.EpochArray(np.vstack(outbound_laps_temp), domain=domain)\n\n    return pos, inbound_laps, outbound_laps\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_linear_track_lap_epochs","title":"<code>get_linear_track_lap_epochs(ts, x, newLapThreshold=15, good_laps=False, edgethresh=0.1, completeprop=0.2, posbins=50)</code>","text":"<p>Identifies lap epochs on a linear track and classifies them into outbound and inbound directions.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>ndarray</code> <p>Array of timestamps corresponding to position data.</p> required <code>x</code> <code>ndarray</code> <p>Array of position data along the linear track.</p> required <code>newLapThreshold</code> <code>float</code> <p>Minimum distance between laps to define a new lap, by default 15.</p> <code>15</code> <code>good_laps</code> <code>bool</code> <p>If True, filter out laps that do not meet certain quality criteria, by default False.</p> <code>False</code> <code>edgethresh</code> <code>float</code> <p>Threshold proportion of the track edge to identify potential boundary errors, by default 0.1.</p> <code>0.1</code> <code>completeprop</code> <code>float</code> <p>Minimum proportion of the track that must be traversed for a lap to be considered complete, by default 0.2.</p> <code>0.2</code> <code>posbins</code> <code>int</code> <p>Number of bins to divide the track into for analysis, by default 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>Tuple[EpochArray, EpochArray]</code> <p>A tuple containing two nelpy EpochArray objects: - outbound_epochs: Epochs representing outbound runs (towards the far end of the track). - inbound_epochs: Epochs representing inbound runs (back towards the start).</p> Notes <ul> <li>This function calls <code>find_laps</code> to determine the lap structure, then segregates epochs into outbound and inbound directions.</li> <li>The EpochArray objects represent the start and stop timestamps for each identified lap.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; outbound_epochs, inbound_epochs = get_linear_track_lap_epochs(ts, x)\n</code></pre> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def get_linear_track_lap_epochs(\n    ts: np.ndarray,\n    x: np.ndarray,\n    newLapThreshold: float = 15,\n    good_laps: bool = False,\n    edgethresh: float = 0.1,\n    completeprop: float = 0.2,\n    posbins: int = 50,\n) -&gt; Tuple[nel.EpochArray, nel.EpochArray]:\n    \"\"\"\n    Identifies lap epochs on a linear track and classifies them into outbound and inbound directions.\n\n    Parameters\n    ----------\n    ts : np.ndarray\n        Array of timestamps corresponding to position data.\n    x : np.ndarray\n        Array of position data along the linear track.\n    newLapThreshold : float, optional\n        Minimum distance between laps to define a new lap, by default 15.\n    good_laps : bool, optional\n        If True, filter out laps that do not meet certain quality criteria, by default False.\n    edgethresh : float, optional\n        Threshold proportion of the track edge to identify potential boundary errors, by default 0.1.\n    completeprop : float, optional\n        Minimum proportion of the track that must be traversed for a lap to be considered complete, by default 0.2.\n    posbins : int, optional\n        Number of bins to divide the track into for analysis, by default 50.\n\n    Returns\n    -------\n    Tuple[nel.EpochArray, nel.EpochArray]\n        A tuple containing two nelpy EpochArray objects:\n        - outbound_epochs: Epochs representing outbound runs (towards the far end of the track).\n        - inbound_epochs: Epochs representing inbound runs (back towards the start).\n\n    Notes\n    ------\n    - This function calls `find_laps` to determine the lap structure, then segregates epochs into outbound and inbound directions.\n    - The EpochArray objects represent the start and stop timestamps for each identified lap.\n\n    Examples\n    -------\n    &gt;&gt;&gt; outbound_epochs, inbound_epochs = get_linear_track_lap_epochs(ts, x)\n\n    \"\"\"\n    laps = __find_laps(\n        np.array(ts),\n        np.array(x),\n        newLapThreshold=newLapThreshold,\n        good_laps=good_laps,\n        edgethresh=edgethresh,\n        completeprop=completeprop,\n        posbins=posbins,\n    )\n\n    # Handle no laps\n    if len(laps) == 0:\n        return nel.EpochArray(), nel.EpochArray()\n\n    outbound_start = []\n    outbound_stop = []\n    inbound_start = []\n    inbound_stop = []\n\n    for i in range(len(laps) - 1):\n        if laps.iloc[i].direction == 1:\n            outbound_start.append(laps.iloc[i].start_ts)\n            outbound_stop.append(laps.iloc[i + 1].start_ts)\n\n        if laps.iloc[i].direction == -1:\n            inbound_start.append(laps.iloc[i].start_ts)\n            inbound_stop.append(laps.iloc[i + 1].start_ts)\n\n    outbound_epochs = nel.EpochArray([np.array([outbound_start, outbound_stop]).T])\n    inbound_epochs = nel.EpochArray([np.array([inbound_start, inbound_stop]).T])\n\n    return outbound_epochs, inbound_epochs\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_linearized_position","title":"<code>get_linearized_position(position, track_graph, edge_order=None, use_HMM=False, show_confirmation_plot=True, n_bins_per_segment=50, use_sparse_transitions=True, subsample_positions=False, subsample_factor=5, use_adaptive_subsampling=True, use_batch_processing=False, batch_size=1000, auto_tune=True)</code>","text":"<p>Get linearized position along a track.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object</p> required <code>edge_order</code> <code>List[List[int]]</code> <p>Order of edges to traverse, by default None</p> <code>None</code> <code>use_HMM</code> <code>bool</code> <p>Whether to use HMM-based linearization, by default False</p> <code>False</code> <code>show_confirmation_plot</code> <code>bool</code> <p>Whether to show confirmation plot, by default True</p> <code>True</code> <code>n_bins_per_segment</code> <code>int</code> <p>Number of bins per segment for HMM, by default 50</p> <code>50</code> <code>use_sparse_transitions</code> <code>bool</code> <p>Whether to use sparse transitions for HMM, by default True</p> <code>True</code> <code>subsample_positions</code> <code>bool</code> <p>Whether to subsample positions for speed, by default False</p> <code>False</code> <code>subsample_factor</code> <code>int</code> <p>Subsampling factor, by default 5</p> <code>5</code> <code>use_adaptive_subsampling</code> <code>bool</code> <p>Whether to use adaptive subsampling, by default True</p> <code>True</code> <code>use_batch_processing</code> <code>bool</code> <p>Whether to use batch processing, by default False</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Batch size for processing, by default 1000</p> <code>1000</code> <code>auto_tune</code> <code>bool</code> <p>Whether to auto-tune parameters, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with linearization results</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def get_linearized_position(\n    position: np.ndarray,\n    track_graph: TrackGraph,\n    edge_order: Optional[List[List[int]]] = None,\n    use_HMM: bool = False,\n    show_confirmation_plot: bool = True,\n    # HMM optimization parameters - Updated defaults for real data\n    n_bins_per_segment: int = 50,  # Good balance of accuracy and speed\n    use_sparse_transitions: bool = True,  # Essential for multi-segment classification\n    subsample_positions: bool = False,  # Keep False for accuracy\n    subsample_factor: int = 5,\n    use_adaptive_subsampling: bool = True,\n    # Advanced optimization parameters\n    use_batch_processing: bool = False,\n    batch_size: int = 1000,\n    # Auto-tuning parameter\n    auto_tune: bool = True,  # Automatically tune parameters based on data for better results\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Get linearized position along a track.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        Array of 2D positions (n_positions, 2)\n    track_graph : TrackGraph\n        Track graph object\n    edge_order : List[List[int]], optional\n        Order of edges to traverse, by default None\n    use_HMM : bool, optional\n        Whether to use HMM-based linearization, by default False\n    show_confirmation_plot : bool, optional\n        Whether to show confirmation plot, by default True\n    n_bins_per_segment : int, optional\n        Number of bins per segment for HMM, by default 50\n    use_sparse_transitions : bool, optional\n        Whether to use sparse transitions for HMM, by default True\n    subsample_positions : bool, optional\n        Whether to subsample positions for speed, by default False\n    subsample_factor : int, optional\n        Subsampling factor, by default 5\n    use_adaptive_subsampling : bool, optional\n        Whether to use adaptive subsampling, by default True\n    use_batch_processing : bool, optional\n        Whether to use batch processing, by default False\n    batch_size : int, optional\n        Batch size for processing, by default 1000\n    auto_tune : bool, optional\n        Whether to auto-tune parameters, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with linearization results\n    \"\"\"\n    # Auto-adjust parameters for large track graphs\n    n_segments = len(track_graph.edges)\n    if n_segments &gt; 10:\n        # For large track graphs, use more aggressive optimization\n        if n_bins_per_segment &gt; 30:\n            n_bins_per_segment = 30\n            print(f\"Reduced bins per segment to {n_bins_per_segment} for large track graph ({n_segments} segments)\")\n\n        # Enable subsampling for very large datasets\n        if len(position) &gt; 1000 and not subsample_positions:\n            subsample_positions = True\n            subsample_factor = max(3, len(position) // 2000)\n            print(f\"Enabled subsampling with factor {subsample_factor} for large dataset ({len(position)} positions)\")\n\n        # Enable batch processing for large track graphs\n        if not use_batch_processing:\n            use_batch_processing = True\n            print(\"Enabled batch processing for large track graph\")\n\n    if use_HMM:\n        # Use HMM-based linearization\n        hmm_linearizer = HMMLinearizer(\n            track_graph,\n            n_bins_per_segment=n_bins_per_segment,\n            use_sparse_transitions=use_sparse_transitions,\n            subsample_positions=subsample_positions,\n            subsample_factor=subsample_factor,\n            use_adaptive_subsampling=use_adaptive_subsampling,\n            use_batch_processing=use_batch_processing,\n            batch_size=batch_size,\n            adaptive_binning=True,  # Enable adaptive binning for large track graphs\n            max_total_states=500,   # Limit total states for performance\n        )\n\n        # Auto-tune parameters if requested\n        if auto_tune:\n            tuned_params = hmm_linearizer._auto_tune_parameters(position)\n            print(f\"Auto-tuned HMM parameters: {tuned_params}\")\n            # Apply tuned parameters\n            hmm_linearizer.emission_noise = tuned_params.get(\"emission_noise\", hmm_linearizer.emission_noise)\n            hmm_linearizer.transition_smoothness = tuned_params.get(\"transition_smoothness\", hmm_linearizer.transition_smoothness)\n\n        # Perform HMM linearization\n        linear_positions, track_segment_ids, projected_positions = hmm_linearizer.linearize_with_hmm(position)\n\n        # Create DataFrame\n        result_df = pd.DataFrame({\n            \"linear_position\": linear_positions,\n            \"track_segment_id\": track_segment_ids,\n            \"projected_x_position\": projected_positions[:, 0],\n            \"projected_y_position\": projected_positions[:, 1],\n        })\n\n        # Show confirmation plot if requested\n        if show_confirmation_plot:\n            plot_linearization_confirmation(\n                position, result_df, track_graph, title=\"Linearization Confirmation (HMM)\"\n            )\n\n        return result_df\n    else:\n        # Use standard linearization\n        linear_positions, track_segment_ids, projected_positions = project_position_to_track(position, track_graph)\n\n        # Create DataFrame\n        result_df = pd.DataFrame({\n            \"linear_position\": linear_positions,\n            \"track_segment_id\": track_segment_ids,\n            \"projected_x_position\": projected_positions[:, 0],\n            \"projected_y_position\": projected_positions[:, 1],\n        })\n\n        # Show confirmation plot if requested\n        if show_confirmation_plot:\n            plot_linearization_confirmation(\n                position, result_df, track_graph, title=\"Linearization Confirmation (Standard)\"\n            )\n\n        return result_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_openfield_trials","title":"<code>get_openfield_trials(basepath, epoch_type='epochs', spatial_binsize=3, n_time_bins=1, bin_method='dynamic', trial_time_bin_size=60, prop_trial_sampled=0.5, environments=['box', 'bigSquare', 'midSquare', 'bigSquarePlus', 'plus'], minimum_correlation=0.6, method='correlation')</code>","text":"<p>Get epochs of openfield trials.</p> <p>This function identifies trials in an open field environment that meet specific criteria for spatial sampling to assess spatial stability and population correlations.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>epoch_type</code> <code>str</code> <p>The type of epoch to use ('trials' or 'epochs'). Default is 'epochs'.</p> <code>'epochs'</code> <code>spatial_binsize</code> <code>int</code> <p>The size of spatial bins to use for occupancy. Default is 3.</p> <code>3</code> <code>n_time_bins</code> <code>int</code> <p>The number of time bins to use for occupancy for fixed bin method. Default is 1.</p> <code>1</code> <code>bin_method</code> <code>str</code> <p>The method to use for binning time ('dynamic' or 'fixed'). Default is 'dynamic'.</p> <code>'dynamic'</code> <code>trial_time_bin_size</code> <code>Union[int, float]</code> <p>The size of time bins to use for occupancy for dynamic bin method (in seconds). Default is 60.</p> <code>60</code> <code>prop_trial_sampled</code> <code>float</code> <p>The proportion of trials to sample. Default is 0.5.</p> <code>0.5</code> <code>environments</code> <code>List[str]</code> <p>A list of environments to include as open field. Default includes several environments such as 'box' and 'plus'.</p> <code>['box', 'bigSquare', 'midSquare', 'bigSquarePlus', 'plus']</code> <code>minimum_correlation</code> <code>float</code> <p>The minimum correlation between trials to be considered a trial. Default is 0.6.</p> <code>0.6</code> <code>method</code> <code>str</code> <p>The method to use ('correlation' or 'proportion'). Default is 'correlation'. <code>correlation</code> - use correlation between the trial map and the overall map to determine if it is a trial. <code>proportion</code> - use the proportion of the trial map that is sampled to determine if it is a trial</p> <code>'correlation'</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray</code> <p>The position data for the open field trials.</p> <code>trials</code> <code>EpochArray</code> <p>The epochs of the identified trials.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is not 'correlation' or 'proportion'.</p> Notes <p>This function requires the loading of animal behavior and epoch data from the specified base path.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_openfield_trials(\n    basepath: str,\n    epoch_type: str = \"epochs\",\n    spatial_binsize: int = 3,\n    n_time_bins: int = 1,  # for bin_method = \"fixed\", not used for bin_method = \"dynamic\"\n    bin_method: str = \"dynamic\",\n    trial_time_bin_size: Union[\n        int, float\n    ] = 60,  # in seconds for bin_method = \"dynamic\", not used for bin_method = \"fixed\"\n    prop_trial_sampled: float = 0.5,\n    environments: List[str] = [\n        \"box\",\n        \"bigSquare\",\n        \"midSquare\",\n        \"bigSquarePlus\",\n        \"plus\",\n    ],\n    minimum_correlation: float = 0.6,\n    method: str = \"correlation\",\n) -&gt; Tuple[nel.PositionArray, nel.EpochArray]:\n    \"\"\"\n    Get epochs of openfield trials.\n\n    This function identifies trials in an open field environment that meet\n    specific criteria for spatial sampling to assess spatial stability and\n    population correlations.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    epoch_type : str, optional\n        The type of epoch to use ('trials' or 'epochs'). Default is 'epochs'.\n    spatial_binsize : int, optional\n        The size of spatial bins to use for occupancy. Default is 3.\n    n_time_bins : int, optional\n        The number of time bins to use for occupancy for fixed bin method.\n        Default is 1.\n    bin_method : str, optional\n        The method to use for binning time ('dynamic' or 'fixed').\n        Default is 'dynamic'.\n    trial_time_bin_size : Union[int, float], optional\n        The size of time bins to use for occupancy for dynamic bin method\n        (in seconds). Default is 60.\n    prop_trial_sampled : float, optional\n        The proportion of trials to sample. Default is 0.5.\n    environments : List[str], optional\n        A list of environments to include as open field. Default includes\n        several environments such as 'box' and 'plus'.\n    minimum_correlation : float, optional\n        The minimum correlation between trials to be considered a trial.\n        Default is 0.6.\n    method : str, optional\n        The method to use ('correlation' or 'proportion'). Default is\n        'correlation'. `correlation` - use correlation between the trial map and\n        the overall map to determine if it is a trial. `proportion` - use the\n        proportion of the trial map that is sampled to determine if it is a\n        trial\n\n    Returns\n    -------\n    pos : PositionArray\n        The position data for the open field trials.\n    trials : EpochArray\n        The epochs of the identified trials.\n\n    Raises\n    ------\n    ValueError\n        If the method is not 'correlation' or 'proportion'.\n\n    Notes\n    -----\n    This function requires the loading of animal behavior and epoch data\n    from the specified base path.\n    \"\"\"\n\n    def compute_occupancy_2d(\n        pos_run: object, x_edges: list, y_edges: list\n    ) -&gt; np.ndarray:\n        \"\"\"Compute occupancy of 2D position\n\n        Parameters\n        ----------\n        pos_run : object\n            Position data for the run\n        x_edges : list\n            Bin edges of x position\n        y_edges : list\n            Bin edges of y position\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy map of the position\n        \"\"\"\n        occupancy, _, _ = np.histogram2d(\n            pos_run.data[0, :], pos_run.data[1, :], bins=(x_edges, y_edges)\n        )\n        return occupancy / pos_run.fs\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n    pos = nel.PositionArray(\n        data=position_df_no_nan[[\"x\", \"y\"]].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    if pos.isempty:\n        return pos, nel.EpochArray([], label=\"session_epochs\")\n\n    # load epochs and place in array\n    if epoch_type == \"trials\":\n        epoch_df = loading.load_trials(basepath)\n        openfield_idx = np.arange(\n            0, len(epoch_df)\n        )  # assume trials make up all epochs associated with position\n        trialsID = epoch_df.trialsID.values\n    elif epoch_type == \"epochs\":\n        epoch_df = loading.load_epoch(basepath)\n        # find epochs that are these environments\n        openfield_idx = np.where(np.isin(epoch_df.environment, environments))[0]\n\n    epoch = nel.EpochArray([np.array([epoch_df.startTime, epoch_df.stopTime]).T])\n\n    # find epochs that are these environments\n    trials = []\n    if epoch_type == \"trials\":\n        trial_ID = []\n\n    # loop through epochs\n    for idx in openfield_idx:\n        # get position during epoch\n        current_position = pos[epoch[int(idx)]]\n\n        if current_position.isempty:\n            continue\n\n        # get the edges of the position\n        ext_xmin, ext_xmax = (\n            np.floor(np.nanmin(current_position.data[0, :])),\n            np.ceil(np.nanmax(current_position.data[0, :])),\n        )\n        ext_ymin, ext_ymax = (\n            np.floor(np.nanmin(current_position.data[1, :])),\n            np.ceil(np.nanmax(current_position.data[1, :])),\n        )\n        # create bin edges for occupancy map at spatial_binsize\n        x_edges = np.arange(ext_xmin, ext_xmax + spatial_binsize, spatial_binsize)\n        y_edges = np.arange(ext_ymin, ext_ymax + spatial_binsize, spatial_binsize)\n\n        # compute occupancy map and get proportion of environment sampled\n        occupancy = compute_occupancy_2d(current_position, x_edges, y_edges)\n        overall_prop_sampled = sum(occupancy.flatten() &gt; 0) / (\n            (len(x_edges) - 1) * (len(y_edges) - 1)\n        )\n        # create possible trials based on trial_time_bin_size\n        # these will be iterated over to find trials that are sampled enough\n        duration = epoch_df.iloc[idx].stopTime - epoch_df.iloc[idx].startTime\n\n        if bin_method == \"dynamic\":\n            bins = np.linspace(\n                epoch_df.iloc[idx].startTime,\n                epoch_df.iloc[idx].stopTime,\n                int(np.ceil(duration / (trial_time_bin_size))),\n            )\n        elif bin_method == \"fixed\":\n            bins = np.arange(\n                epoch_df.iloc[idx].startTime,\n                epoch_df.iloc[idx].stopTime,\n                int(np.floor(epoch[int(idx)].duration / n_time_bins)),\n            )\n        trials_temp = nel.EpochArray(np.array([bins[:-1], bins[1:]]).T)\n        if epoch_type == \"trials\":\n            temp_ID = trialsID[idx]\n\n        trial_i = 0\n        # loop through possible trials and find when sampled enough\n        for i_interval in range(trials_temp.n_intervals):\n            # compute occupancy map and get proportion of environment sampled for trial\n            trial_occupancy = compute_occupancy_2d(\n                current_position[trials_temp[trial_i : i_interval + 1]],\n                x_edges,\n                y_edges,\n            )\n\n            if method == \"correlation\":\n                # correlate trial_occupancy with overall occupancy\n                r = np.corrcoef(\n                    occupancy.flatten() &gt; 0,\n                    trial_occupancy.flatten() &gt; 0,\n                )[0, 1]\n\n                # if sampled enough, add to trials\n                if r &gt; minimum_correlation:\n                    trials.append(\n                        [\n                            trials_temp[trial_i : i_interval + 1].start,\n                            trials_temp[trial_i : i_interval + 1].stop,\n                        ]\n                    )\n                    if epoch_type == \"trials\":\n                        trial_ID.append(temp_ID + \"_\" + str(idx))\n                    # update trial_i to next interval to start from\n                    trial_i = i_interval + 1\n\n            elif method == \"proportion\":\n                trial_prop_sampled = sum(trial_occupancy.flatten() &gt; 0) / (\n                    (len(x_edges) - 1) * (len(y_edges) - 1)\n                )\n                if trial_prop_sampled &gt; prop_trial_sampled * overall_prop_sampled:\n                    trials.append(\n                        [\n                            trials_temp[trial_i : i_interval + 1].start,\n                            trials_temp[trial_i : i_interval + 1].stop,\n                        ]\n                    )\n                    if epoch_type == \"trials\":\n                        trial_ID.append(temp_ID + \"_\" + str(idx))\n                    # update trial_i to next interval to start from\n                    trial_i = i_interval + 1\n            else:\n                raise ValueError(\"method must be correlation or proportion\")\n\n    # concatenate trials and place in EpochArray\n    if epoch_type == \"trials\":\n        trials = nel.EpochArray(np.vstack(trials), label=np.vstack(trial_ID))\n    else:\n        trials = nel.EpochArray(np.vstack(trials), label=\"session_epochs\")\n\n    return pos, trials\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_speed","title":"<code>get_speed(position, time=None)</code>","text":"<p>Computes the speed from position data.</p> <p>Speed is the magnitude of the velocity vector at each time point. If time is not provided, it assumes a constant time step between position samples.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>An array of position data. This can be 1D (for single-dimensional positions) or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).</p> required <code>time</code> <code>Union[ndarray, None]</code> <p>An array of time values corresponding to the position data. If None, the function assumes a constant time step. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of speed values, where each speed is the magnitude of the velocity at the corresponding time point.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n&gt;&gt;&gt; get_speed(position)\narray([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n</code></pre> <pre><code>&gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n&gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n&gt;&gt;&gt; get_speed(position, time)\narray([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n</code></pre> Source code in <code>neuro_py/behavior/kinematics.py</code> <pre><code>def get_speed(position: np.ndarray, time: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n    \"\"\"\n    Computes the speed from position data.\n\n    Speed is the magnitude of the velocity vector at each time point. If time is\n    not provided, it assumes a constant time step between position samples.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        An array of position data. This can be 1D (for single-dimensional positions)\n        or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).\n    time : Union[np.ndarray, None], optional\n        An array of time values corresponding to the position data. If None,\n        the function assumes a constant time step. Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        An array of speed values, where each speed is the magnitude of the velocity\n        at the corresponding time point.\n\n    Examples\n    --------\n    &gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n    &gt;&gt;&gt; get_speed(position)\n    array([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n\n    &gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n    &gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n    &gt;&gt;&gt; get_speed(position, time)\n    array([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n    \"\"\"\n    velocity = get_velocity(position, time=time)\n    return np.sqrt(np.sum(velocity**2, axis=1))\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_t_maze_trials","title":"<code>get_t_maze_trials(basepath, epoch, bypass_standard_behavior=False)</code>","text":"<p>Get trials for T maze.</p> <p>This function retrieves position data and epochs for right and left trials based on the specified epoch. It checks if the number of outbound laps exceeds the number of inbound laps unless bypassed.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>epoch</code> <code>EpochArray</code> <p>The epoch to get trials for.</p> required <code>bypass_standard_behavior</code> <code>bool</code> <p>If True, allows for more outbound than inbound trials. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the T maze trials.</p> <code>right_epochs</code> <code>EpochArray or None</code> <p>The epochs corresponding to right trials.</p> <code>left_epochs</code> <code>EpochArray or None</code> <p>The epochs corresponding to left trials.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If inbound laps exceed outbound laps and bypass_standard_behavior is False.</p> Notes <p>If there are no valid positions or states in the session data, None is returned for all outputs.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_t_maze_trials(\n    basepath: str, epoch: nel.EpochArray, bypass_standard_behavior: bool = False\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[nel.EpochArray, None],\n    Union[nel.EpochArray, None],\n]:\n    \"\"\"\n    Get trials for T maze.\n\n    This function retrieves position data and epochs for right and left trials\n    based on the specified epoch. It checks if the number of outbound laps exceeds\n    the number of inbound laps unless bypassed.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    epoch : nel.EpochArray\n        The epoch to get trials for.\n    bypass_standard_behavior : bool, optional\n        If True, allows for more outbound than inbound trials. Default is False.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the T maze trials.\n    right_epochs : EpochArray or None\n        The epochs corresponding to right trials.\n    left_epochs : EpochArray or None\n        The epochs corresponding to left trials.\n\n    Raises\n    ------\n    TypeError\n        If inbound laps exceed outbound laps and bypass_standard_behavior is False.\n\n    Notes\n    -----\n    If there are no valid positions or states in the session data, None is returned\n    for all outputs.\n    \"\"\"\n\n    def dissociate_laps_by_states(states, dir_epoch, states_of_interest=[1, 2]):\n        # unique_states = np.unique(states.data[~np.isnan(states.data)])\n        lap_id = []\n        for ep in dir_epoch:\n            state_count = []\n            for us in states_of_interest:\n                state_count.append(np.nansum(states[ep].data == us))\n            lap_id.append(states_of_interest[np.argmax(state_count)])\n        return np.array(lap_id).astype(int)\n\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    if position_df_no_nan.shape[0] == 0:\n        return None, None, None\n\n    if \"linearized\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    if \"states\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    pos = pos[epoch]\n    if pos.isempty:\n        return None, None, None\n\n    states = nel.AnalogSignalArray(\n        data=position_df_no_nan[\"states\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    states = states[epoch]\n\n    # get outbound and inbound epochs\n    outbound_laps, inbound_laps = linear_positions.get_linear_track_lap_epochs(\n        pos.abscissa_vals, pos.data[0], newLapThreshold=20\n    )\n\n    inbound_laps = linear_positions.find_good_lap_epochs(pos, inbound_laps, min_laps=5)\n    outbound_laps = linear_positions.find_good_lap_epochs(\n        pos, outbound_laps, min_laps=5\n    )\n\n    if outbound_laps.isempty:\n        return None, None, None\n\n    if not inbound_laps.isempty:\n        logging.warning(\"inbound_laps should be empty for tmaze\")\n\n    if (\n        inbound_laps.n_intervals &gt; outbound_laps.n_intervals\n    ) and not bypass_standard_behavior:\n        raise TypeError(\"inbound_laps should be less than outbound_laps for tmaze\")\n\n    # locate laps with the majority in state 1 or 2\n    lap_id = dissociate_laps_by_states(states, outbound_laps, states_of_interest=[1, 2])\n\n    right_epochs = nel.EpochArray(data=outbound_laps.data[lap_id == 1, :])\n    left_epochs = nel.EpochArray(data=outbound_laps.data[lap_id == 2, :])\n\n    position_df_no_nan = position_df_no_nan[\n        position_df_no_nan[\"time\"].between(epoch.start, epoch.stop)\n    ]\n    return pos, right_epochs, left_epochs\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_velocity","title":"<code>get_velocity(position, time=None)</code>","text":"<p>Computes the velocity from position data.</p> <p>If time is not provided, it assumes a constant time step between position samples. The velocity is calculated as the gradient of the position with respect to time along the first axis.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>An array of position data. This can be 1D (for single-dimensional positions) or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).</p> required <code>time</code> <code>Union[ndarray, None]</code> <p>An array of time values corresponding to the position data. If None, the function assumes a constant time step. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of velocity values, where each velocity is the rate of change of position with respect to time.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n&gt;&gt;&gt; get_velocity(position)\narray([1., 2., 4., 6., 7.])\n</code></pre> <pre><code>&gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n&gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n&gt;&gt;&gt; get_velocity(position, time)\narray([[1., 1.],\n    [2., 2.],\n    [4., 4.],\n    [6., 6.],\n    [7., 7.]])\n</code></pre> Source code in <code>neuro_py/behavior/kinematics.py</code> <pre><code>def get_velocity(\n    position: np.ndarray, time: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes the velocity from position data.\n\n    If time is not provided, it assumes a constant time step between position\n    samples. The velocity is calculated as the gradient of the position with\n    respect to time along the first axis.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        An array of position data. This can be 1D (for single-dimensional positions)\n        or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).\n    time : Union[np.ndarray, None], optional\n        An array of time values corresponding to the position data. If None,\n        the function assumes a constant time step. Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        An array of velocity values, where each velocity is the rate of change of\n        position with respect to time.\n\n    Examples\n    --------\n    &gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n    &gt;&gt;&gt; get_velocity(position)\n    array([1., 2., 4., 6., 7.])\n\n    &gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n    &gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n    &gt;&gt;&gt; get_velocity(position, time)\n    array([[1., 1.],\n        [2., 2.],\n        [4., 4.],\n        [6., 6.],\n        [7., 7.]])\n    \"\"\"\n    if time is None:\n        time = np.arange(position.shape[0])\n    return np.gradient(position, time, axis=0)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.get_w_maze_trials","title":"<code>get_w_maze_trials(basepath, max_distance_from_well=20, min_distance_traveled=50)</code>","text":"<p>Get trials for W maze.</p> <p>This function retrieves position data and identifies trials for the W maze based on specified distance criteria.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>max_distance_from_well</code> <code>int</code> <p>The maximum distance from the well to be considered a trial. Default is 20.</p> <code>20</code> <code>min_distance_traveled</code> <code>int</code> <p>The minimum distance traveled to be considered a trial. Default is 50.</p> <code>50</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the W maze trials.</p> <code>trials</code> <code>ndarray or None</code> <p>The indices of the trials.</p> <code>right_trials</code> <code>ndarray or None</code> <p>The indices of the right trials.</p> <code>left_trials</code> <code>ndarray or None</code> <p>The indices of the left trials.</p> Notes <p>This function requires the following metadata dependencies:</p> <ul> <li><code>animal.behavior.mat</code>: contains center, left, and right x y coordinates.</li> </ul> <p>You can label these with <code>label_key_locations_wmaze.m</code> or manually.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_w_maze_trials(\n    basepath: str, max_distance_from_well: int = 20, min_distance_traveled: int = 50\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[np.ndarray, None],\n    Union[np.ndarray, None],\n    Union[np.ndarray, None],\n]:\n    \"\"\"\n    Get trials for W maze.\n\n    This function retrieves position data and identifies trials for the W maze\n    based on specified distance criteria.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    max_distance_from_well : int, optional\n        The maximum distance from the well to be considered a trial. Default is 20.\n    min_distance_traveled : int, optional\n        The minimum distance traveled to be considered a trial. Default is 50.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the W maze trials.\n    trials : ndarray or None\n        The indices of the trials.\n    right_trials : ndarray or None\n        The indices of the right trials.\n    left_trials : ndarray or None\n        The indices of the left trials.\n\n    Notes\n    -----\n    This function requires the following metadata dependencies:\n\n    - `animal.behavior.mat`: contains center, left, and right x y coordinates.\n\n    You can label these with `label_key_locations_wmaze.m` or manually.\n    \"\"\"\n\n    # load position and key location metadata\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # load epochs and place in array\n    epoch_df = loading.load_epoch(basepath)\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    wmaze_idx = np.where(epoch_df.environment == \"wmaze\")[0]\n    for idx in wmaze_idx:\n        # get key locations\n        right_x = data[\"behavior\"][\"epochs\"][idx][\"right_x\"]\n        right_y = data[\"behavior\"][\"epochs\"][idx][\"right_y\"]\n\n        center_x = data[\"behavior\"][\"epochs\"][idx][\"center_x\"]\n        center_y = data[\"behavior\"][\"epochs\"][idx][\"center_y\"]\n\n        left_x = data[\"behavior\"][\"epochs\"][idx][\"left_x\"]\n        left_y = data[\"behavior\"][\"epochs\"][idx][\"left_y\"]\n\n        well_locations = np.array(\n            [[center_x, center_y], [left_x, left_y], [right_x, right_y]]\n        )\n\n        current_ts_idx = position_df_no_nan[\"timestamps\"].between(\n            epoch_df.iloc[idx].startTime, epoch_df.iloc[idx].stopTime\n        )\n\n        # temp_df = position_df[~np.isnan(position_df.x)]\n        segments_df, _ = well_traversal_classification.segment_path(\n            position_df_no_nan[\"timestamps\"].values[current_ts_idx],\n            position_df_no_nan[[\"x\", \"y\"]].values[current_ts_idx],\n            well_locations,\n            max_distance_from_well=max_distance_from_well,\n        )\n\n        segments_df = well_traversal_classification.score_inbound_outbound(\n            segments_df, min_distance_traveled=min_distance_traveled\n        )\n        conditions = [\n            \"from_well == 'Center' &amp; to_well == 'Left'\",\n            \"from_well == 'Left' &amp; to_well == 'Center'\",\n            \"from_well == 'Center' &amp; to_well == 'Right'\",\n            \"from_well == 'Right' &amp; to_well == 'Center'\",\n        ]\n        condition_labels = [\n            \"center_left\",\n            \"left_center\",\n            \"center_right\",\n            \"right_center\",\n        ]\n        trajectories = {}\n        for con, con_label in zip(conditions, condition_labels):\n            trajectories[con_label] = nel.EpochArray(\n                np.array(\n                    [segments_df.query(con).start_time, segments_df.query(con).end_time]\n                ).T\n            )\n\n    return pos, trajectories\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.linearize_position","title":"<code>linearize_position(x, y)</code>","text":"<p>Use PCA (a dimensionality reduction technique) to find the direction of maximal variance in our position data, and use this as the new 1D linear track axis.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>x-coordinates of shape (n, 1)</p> required <code>y</code> <code>ndarray</code> <p>y-coordinates of shape (n, 1)</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>Linearized x and y coordinates, both of shape (n, 1).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; linear_x, linear_y = npy.behavior.linearize_position(x, y)\n&gt;&gt;&gt; linear_x\narray([0.        , 1.41421356, 2.82842712, 4.24264069, 5.65685425])\n&gt;&gt;&gt; linear_y\narray([3.92192151e-16, 0.00000000e+00, 9.80480378e-17, 1.96096076e-16, 2.94144113e-16])\n</code></pre> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def linearize_position(x: np.ndarray, y: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Use PCA (a dimensionality reduction technique) to find the direction of maximal variance\n    in our position data, and use this as the new 1D linear track axis.\n\n    Parameters\n    ----------\n    x : numpy.ndarray\n        x-coordinates of shape (n, 1)\n    y : numpy.ndarray\n        y-coordinates of shape (n, 1)\n\n    Returns\n    -------\n    tuple[numpy.ndarray, numpy.ndarray]\n        Linearized x and y coordinates, both of shape (n, 1).\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.array([1, 2, 3, 4, 5])\n    &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5])\n    &gt;&gt;&gt; linear_x, linear_y = npy.behavior.linearize_position(x, y)\n    &gt;&gt;&gt; linear_x\n    array([0.        , 1.41421356, 2.82842712, 4.24264069, 5.65685425])\n    &gt;&gt;&gt; linear_y\n    array([3.92192151e-16, 0.00000000e+00, 9.80480378e-17, 1.96096076e-16, 2.94144113e-16])\n    \"\"\"\n    # locate and remove nans (sklearn pca does not like nans)\n    badidx = (np.isnan(x)) | (np.isnan(y))\n    badidx_pos = np.where(badidx)\n    goodidx_pos = np.where(~badidx)\n    n = len(x)\n\n    x = x[~badidx]\n    y = y[~badidx]\n\n    # perform pca and return the first 2 components\n    pca = PCA(n_components=2)\n    # transform our coords\n    linear = pca.fit_transform(np.array([x, y]).T)\n\n    # add back nans\n    x = np.zeros([n])\n    x[badidx_pos] = np.nan\n    x[goodidx_pos] = linear[:, 0]\n\n    y = np.zeros([n])\n    y[badidx_pos] = np.nan\n    y[goodidx_pos] = linear[:, 1]\n\n    # pca will center data at 0,0... adjust for this here\n    x = x + np.abs(np.nanmin(x))\n    y = y + np.abs(np.nanmin(y))\n\n    return x, y\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.make_track_graph","title":"<code>make_track_graph(node_positions, edges)</code>","text":"<p>Create a track graph from node positions and edges.</p> <p>Parameters:</p> Name Type Description Default <code>node_positions</code> <code>ndarray</code> <p>Array of node positions (n_nodes, 2)</p> required <code>edges</code> <code>list</code> <p>List of edge connections between nodes</p> required <p>Returns:</p> Type Description <code>TrackGraph</code> <p>Track graph object</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def make_track_graph(node_positions: np.ndarray, edges: List[List[int]]) -&gt; TrackGraph:\n    \"\"\"\n    Create a track graph from node positions and edges.\n\n    Parameters\n    ----------\n    node_positions : np.ndarray\n        Array of node positions (n_nodes, 2)\n    edges : list\n        List of edge connections between nodes\n\n    Returns\n    -------\n    TrackGraph\n        Track graph object\n    \"\"\"\n    return TrackGraph(node_positions, edges)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.paired_distances","title":"<code>paired_distances(x, y)</code>","text":"<p>Euclidean distance between x and y at each time point.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <code>y</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of shape (n_time,) containing the distances.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def paired_distances(\n    x: Union[np.ndarray, list], y: Union[np.ndarray, list]\n) -&gt; np.ndarray:\n    \"\"\"\n    Euclidean distance between x and y at each time point.\n\n    Parameters\n    ----------\n    x : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n    y : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n\n    Returns\n    -------\n    np.ndarray\n        Array of shape (n_time,) containing the distances.\n    \"\"\"\n    x, y = np.array(x), np.array(y)\n    x = np.atleast_2d(x).T if x.ndim &lt; 2 else x\n    y = np.atleast_2d(y).T if y.ndim &lt; 2 else y\n    return np.linalg.norm(x - y, axis=1)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.plot_grid_with_circle_and_random_dots","title":"<code>plot_grid_with_circle_and_random_dots()</code>","text":"<p>Plots a 15x15 grid of dots within a circle, highlights 3 randomly chosen dots within the circle, and draws a grey box at the bottom.</p> <p>The function generates a grid of points within a circle of a specified radius and randomly selects three points from within the circle. These points are colored red and slightly enlarged. Additionally, a grey box is drawn at the bottom of the plot.</p> Notes <ul> <li>The grid is plotted on a 15x15 layout, with points that fall within the   circle of radius 6.8 being displayed.</li> <li>The randomly selected points must be at least 4 grid units apart.</li> <li>A grey rectangular box is drawn near the bottom of the plot for aesthetic   purposes.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plot_grid_with_circle_and_random_dots()\n# This will display a plot of a circle containing a grid of dots with\n# 3 randomly chosen dots highlighted in red.\n</code></pre> Source code in <code>neuro_py/behavior/cheeseboard.py</code> <pre><code>def plot_grid_with_circle_and_random_dots():\n    \"\"\"\n    Plots a 15x15 grid of dots within a circle, highlights 3 randomly chosen dots\n    within the circle, and draws a grey box at the bottom.\n\n    The function generates a grid of points within a circle of a specified radius\n    and randomly selects three points from within the circle. These points are\n    colored red and slightly enlarged. Additionally, a grey box is drawn at the\n    bottom of the plot.\n\n    Notes\n    -----\n    - The grid is plotted on a 15x15 layout, with points that fall within the\n      circle of radius 6.8 being displayed.\n    - The randomly selected points must be at least 4 grid units apart.\n    - A grey rectangular box is drawn near the bottom of the plot for aesthetic\n      purposes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; plot_grid_with_circle_and_random_dots()\n    # This will display a plot of a circle containing a grid of dots with\n    # 3 randomly chosen dots highlighted in red.\n    \"\"\"\n    # Create a 15x15 grid of dots within the circle\n    x = np.linspace(-7, 7, 17)\n    y = np.linspace(-7, 7, 17)\n    X, Y = np.meshgrid(x, y)\n\n    # Calculate the circle parameters with an offset\n    radius = 6.8  # Radius of the circle\n    circle_center = (0, 0)  # Center of the circle\n\n    # Create a mask to display only the dots within the circle\n    circle_mask = (X**2 + Y**2) &lt;= radius**2\n\n    # Plot the grid of dots within the circle\n    plt.figure(figsize=(8, 8))\n    plt.plot(X[circle_mask], Y[circle_mask], \"o\", color=\"k\", markersize=6)\n\n    # Plot the circle\n    circle = plt.Circle(circle_center, radius, color=\"black\", fill=False)\n    plt.gca().add_patch(circle)\n\n    # Randomly pick 3 dots within the circle\n    num_dots = 3\n    chosen_indices = np.random.choice(np.sum(circle_mask), size=num_dots, replace=False)\n    chosen_dots = np.argwhere(circle_mask)\n    chosen_dots = chosen_dots[chosen_indices]\n\n    # Ensure minimum separation of 4 dots between the randomly chosen dots\n    min_separation = 4\n    for i in range(num_dots):\n        for j in range(i + 1, num_dots):\n            while np.linalg.norm(chosen_dots[i] - chosen_dots[j]) &lt; min_separation:\n                chosen_indices[j] = np.random.choice(np.sum(circle_mask), size=1)[0]\n                chosen_dots[j] = np.argwhere(circle_mask)[chosen_indices[j]]\n\n    # Color the randomly chosen dots red and make them slightly larger\n    for dot in chosen_dots:\n        plt.plot(X[dot[0], dot[1]], Y[dot[0], dot[1]], \"o\", color=\"red\", markersize=9)\n\n    # Draw a grey box at the bottom\n    plt.fill_between([-1.5, 1.5], -8.5, -6.5, color=\"darkgray\", alpha=1)\n\n    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n    plt.axis(\"off\")\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.plot_linearization_confirmation","title":"<code>plot_linearization_confirmation(original_positions, linearized_df, track_graph, title='Linearization Confirmation', show_plot=True)</code>","text":"<p>Create a confirmation plot showing the linearization results.</p> <p>Parameters:</p> Name Type Description Default <code>original_positions</code> <code>ndarray</code> <p>Original 2D positions (n_positions, 2)</p> required <code>linearized_df</code> <code>DataFrame</code> <p>DataFrame with linearization results from get_linearized_position</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object used for linearization</p> required <code>title</code> <code>str</code> <p>Title for the plot, by default \"Linearization Confirmation\"</p> <code>'Linearization Confirmation'</code> <code>show_plot</code> <code>bool</code> <p>Whether to display the plot, by default True</p> <code>True</code> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def plot_linearization_confirmation(\n    original_positions: np.ndarray,\n    linearized_df: pd.DataFrame,\n    track_graph: TrackGraph,\n    title: str = \"Linearization Confirmation\",\n    show_plot: bool = True,\n) -&gt; None:\n    \"\"\"\n    Create a confirmation plot showing the linearization results.\n\n    Parameters\n    ----------\n    original_positions : np.ndarray\n        Original 2D positions (n_positions, 2)\n    linearized_df : pd.DataFrame\n        DataFrame with linearization results from get_linearized_position\n    track_graph : TrackGraph\n        Track graph object used for linearization\n    title : str, optional\n        Title for the plot, by default \"Linearization Confirmation\"\n    show_plot : bool, optional\n        Whether to display the plot, by default True\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n    fig.suptitle(title, fontsize=16)\n\n    # Create color map for segments\n    unique_segments = sorted(linearized_df[\"track_segment_id\"].unique())\n    if len(unique_segments) &gt; 0:\n        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_segments)))\n        segment_colors = dict(zip(unique_segments, colors))\n    else:\n        segment_colors = {}\n\n    # Plot 1: Original 2D positions with track graph (color coded by segment)\n    ax1 = axes[0, 0]\n\n    # Color code original positions by their corresponding segment\n    if len(segment_colors) &gt; 0:\n        # Get segment IDs for original positions (assuming they correspond to linearized_df order)\n        segment_ids = linearized_df[\"track_segment_id\"].values\n        valid_mask = segment_ids &gt;= 0  # Only plot valid segments\n\n        if np.any(valid_mask):\n            valid_positions = original_positions[valid_mask]\n            valid_segments = segment_ids[valid_mask]\n            colors_for_positions = [\n                segment_colors.get(seg, \"gray\") for seg in valid_segments\n            ]\n\n            ax1.scatter(\n                valid_positions[:, 0],\n                valid_positions[:, 1],\n                c=colors_for_positions,\n                s=1,\n                alpha=0.6,\n            )\n        else:\n            ax1.scatter(\n                original_positions[:, 0],\n                original_positions[:, 1],\n                color=\"lightblue\", \n                s=1,\n                alpha=0.6,\n            )\n    else:\n        ax1.scatter(\n            original_positions[:, 0],\n            original_positions[:, 1],\n            color=\"lightblue\", \n            s=1,\n            alpha=0.6,\n        )\n\n    # Plot track graph nodes and edges with color coding\n    node_positions = track_graph.node_positions\n    ax1.scatter(\n        node_positions[:, 0], node_positions[:, 1], color=\"red\", s=50, zorder=5\n    ) \n\n    # Draw edges with color coding\n    for i, edge in enumerate(track_graph.edges):\n        start_pos = node_positions[edge[0]]\n        end_pos = node_positions[edge[1]]\n        edge_color = segment_colors.get(i, \"black\")\n        ax1.plot(\n            [start_pos[0], end_pos[0]],\n            [start_pos[1], end_pos[1]],\n            color=edge_color,\n            linewidth=3,\n            alpha=0.8,\n        )\n\n    ax1.set_xlabel(\"X Position (cm)\")\n    ax1.set_ylabel(\"Y Position (cm)\")\n    ax1.set_title(\"Original 2D Positions with Track Graph (Color Coded by Segment)\")\n    ax1.grid(True, alpha=0.3)\n    ax1.axis(\"equal\")\n\n    # Plot 2: Projected positions on track (color coded by segment)\n    ax2 = axes[0, 1]\n\n    # Color code projected positions by segment\n    if len(segment_colors) &gt; 0:\n        valid_mask = linearized_df[\"track_segment_id\"] &gt;= 0\n        if np.any(valid_mask):\n            valid_proj_x = linearized_df.loc[valid_mask, \"projected_x_position\"]\n            valid_proj_y = linearized_df.loc[valid_mask, \"projected_y_position\"]\n            valid_segments = linearized_df.loc[valid_mask, \"track_segment_id\"]\n            colors_for_proj = [\n                segment_colors.get(seg, \"gray\") for seg in valid_segments\n            ]\n\n            ax2.scatter(valid_proj_x, valid_proj_y, c=colors_for_proj, s=1, alpha=0.6)\n        else:\n            ax2.scatter(\n                linearized_df[\"projected_x_position\"],\n                linearized_df[\"projected_y_position\"],\n                color=\"green\", \n                s=1,\n                alpha=0.6,\n            )\n    else:\n        ax2.scatter(\n            linearized_df[\"projected_x_position\"],\n            linearized_df[\"projected_y_position\"],\n            color=\"green\", \n            s=1,\n            alpha=0.6,\n        )\n\n    # Plot track graph nodes and edges with color coding\n    ax2.scatter(\n        node_positions[:, 0], node_positions[:, 1], color=\"red\", s=50, zorder=5\n    ) \n\n    # Draw edges with color coding\n    for i, edge in enumerate(track_graph.edges):\n        start_pos = node_positions[edge[0]]\n        end_pos = node_positions[edge[1]]\n        edge_color = segment_colors.get(i, \"black\")\n        ax2.plot(\n            [start_pos[0], end_pos[0]],\n            [start_pos[1], end_pos[1]],\n            color=edge_color,\n            linewidth=3,\n            alpha=0.8,\n        )\n\n    ax2.set_xlabel(\"X Position (cm)\")\n    ax2.set_ylabel(\"Y Position (cm)\")\n    ax2.set_title(\"Projected Positions on Track (Color Coded by Segment)\")\n    ax2.grid(True, alpha=0.3)\n    ax2.axis(\"equal\")\n\n    # Plot 3: Linear position over time (color coded by segment)\n    ax3 = axes[1, 0]\n    time_points = np.arange(len(linearized_df))\n\n    if len(segment_colors) &gt; 0:\n        # Plot each segment separately with different colors using scatter\n        for segment_id in unique_segments:\n            if segment_id &gt;= 0:  # Only plot valid segments\n                segment_mask = linearized_df[\"track_segment_id\"] == segment_id\n                if np.any(segment_mask):\n                    segment_times = time_points[segment_mask]\n                    segment_positions = linearized_df.loc[\n                        segment_mask, \"linear_position\"\n                    ]\n                    # Use the color directly from the colormap, not as a list\n                    segment_color = segment_colors[segment_id]\n                    ax3.scatter(\n                        segment_times,\n                        segment_positions,\n                        color=segment_color, \n                        s=1,\n                        alpha=0.7,\n                    )\n    else:\n        ax3.scatter(\n            time_points,\n            linearized_df[\"linear_position\"],\n            color=\"blue\", \n            s=1,\n            alpha=0.7,\n        )\n\n    ax3.set_xlabel(\"Time Point\")\n    ax3.set_ylabel(\"Linear Position (cm)\")\n    ax3.set_title(\"Linear Position Over Time (Color Coded by Segment)\")\n    ax3.grid(True, alpha=0.3)\n\n    # Plot 4: Track segment distribution (color coded)\n    ax4 = axes[1, 1]\n    segment_counts = linearized_df[\"track_segment_id\"].value_counts().sort_index()\n\n    if len(segment_colors) &gt; 0:\n        # Color code the bars by segment\n        bar_colors = [segment_colors.get(seg, \"gray\") for seg in segment_counts.index]\n        ax4.bar(\n            segment_counts.index, segment_counts.values, alpha=0.7, color=bar_colors\n        )\n    else:\n        ax4.bar(segment_counts.index, segment_counts.values, alpha=0.7, color=\"orange\")\n\n    ax4.set_xlabel(\"Track Segment ID\")\n    ax4.set_ylabel(\"Number of Positions\")\n    ax4.set_title(\"Distribution Across Track Segments (Color Coded)\")\n    ax4.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n\n    if show_plot:\n        plt.show(block=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.project_position_to_track","title":"<code>project_position_to_track(position, track_graph)</code>","text":"<p>Project 2D positions onto the track graph.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object</p> required <p>Returns:</p> Name Type Description <code>linear_position</code> <code>ndarray</code> <p>Linearized positions along the track</p> <code>track_segment_id</code> <code>ndarray</code> <p>Track segment IDs for each position</p> <code>projected_position</code> <code>ndarray</code> <p>Projected 2D positions on the track</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def project_position_to_track(\n    position: np.ndarray, track_graph: TrackGraph\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Project 2D positions onto the track graph.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        Array of 2D positions (n_positions, 2)\n    track_graph : TrackGraph\n        Track graph object\n\n    Returns\n    -------\n    linear_position : np.ndarray\n        Linearized positions along the track\n    track_segment_id : np.ndarray\n        Track segment IDs for each position\n    projected_position : np.ndarray\n        Projected 2D positions on the track\n    \"\"\"\n    n_positions = position.shape[0]\n    linear_position = np.full(n_positions, np.nan)\n    track_segment_id = np.full(n_positions, -1, dtype=int)\n    projected_position = np.full((n_positions, 2), np.nan)\n\n    for i, pos in enumerate(position):\n        # Find closest node\n        distances_to_nodes = np.linalg.norm(track_graph.node_positions - pos, axis=1)\n        closest_node = np.argmin(distances_to_nodes)\n\n        # Find closest edge\n        min_distance = np.inf\n        best_segment = -1\n        best_projection = None\n\n        for edge_idx, edge in enumerate(track_graph.edges):\n            if len(edge) &gt;= 2:\n                for j in range(len(edge) - 1):\n                    node1, node2 = edge[j], edge[j + 1]\n                    p1 = track_graph.node_positions[node1]\n                    p2 = track_graph.node_positions[node2]\n\n                    # Project point onto line segment\n                    v = p2 - p1\n                    u = pos - p1\n                    t = np.dot(u, v) / np.dot(v, v)\n                    t = np.clip(t, 0, 1)\n\n                    projection = p1 + t * v\n                    distance = np.linalg.norm(pos - projection)\n\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        best_segment = edge_idx\n                        best_projection = projection\n\n        if best_segment &gt;= 0 and best_projection is not None:\n            # Calculate linear position\n            edge = track_graph.edges[best_segment]\n            for j in range(len(edge) - 1):\n                node1, node2 = edge[j], edge[j + 1]\n                p1 = track_graph.node_positions[node1]\n                p2 = track_graph.node_positions[node2]\n\n                # Check if projection is on this segment\n                v = p2 - p1\n                u = best_projection - p1\n                t = np.dot(u, v) / np.dot(v, v)\n\n                if 0 &lt;= t &lt;= 1:\n                    # Linear position is cumulative distance to node1 + distance along segment\n                    linear_position[i] = track_graph.cumulative_distances[\n                        node1\n                    ] + t * np.linalg.norm(v)\n                    track_segment_id[i] = best_segment\n                    projected_position[i] = best_projection\n                    break\n\n    return linear_position, track_segment_id, projected_position\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.score_inbound_outbound","title":"<code>score_inbound_outbound(segments_df, min_distance_traveled=50, well_names={1: 'Center', 2: 'Left', 3: 'Right'})</code>","text":"<p>In the alternating arm task, determines whether the trial should be inbound (running to the center arm) or outbound (running to the opposite outer arm as before) and if the trial was performed correctly.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>Output of <code>segment_path</code> function.</p> required <code>min_distance_traveled</code> <code>float</code> <p>Minimum path length (in cm) while outside of the well radius for a segment to be considered as a trial, by default 50.</p> <code>50</code> <code>well_names</code> <code>Dict[int, str]</code> <p>Dictionary mapping well indices to well names, by default {1: \"Center\", 2: \"Left\", 3: \"Right\"}.</p> <code>{1: 'Center', 2: 'Left', 3: 'Right'}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Same as the input dataframe but with the wells labeled (left, right, center) and columns for <code>task</code> (inbound/outbound) and <code>is_correct</code> (True/False).</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def score_inbound_outbound(\n    segments_df: pd.DataFrame,\n    min_distance_traveled: float = 50,\n    well_names: Dict[int, str] = {1: \"Center\", 2: \"Left\", 3: \"Right\"},\n) -&gt; pd.DataFrame:\n    \"\"\"\n    In the alternating arm task, determines whether the trial should be\n    inbound (running to the center arm) or outbound (running to the opposite\n    outer arm as before) and if the trial was performed correctly.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        Output of `segment_path` function.\n    min_distance_traveled : float, optional\n        Minimum path length (in cm) while outside of the well radius for\n        a segment to be considered as a trial, by default 50.\n    well_names : Dict[int, str], optional\n        Dictionary mapping well indices to well names, by default {1: \"Center\", 2: \"Left\", 3: \"Right\"}.\n\n    Returns\n    -------\n    pd.DataFrame\n        Same as the input dataframe but with the wells labeled\n        (left, right, center) and columns for `task` (inbound/outbound) and\n        `is_correct` (True/False).\n    \"\"\"\n    segments_df = (\n        segments_df.copy()\n        .loc[segments_df.distance_traveled &gt; min_distance_traveled]\n        .dropna()\n    )\n    segments_df = segments_df.assign(\n        to_well=lambda df: df.to_well.map(well_names),\n        from_well=lambda df: df.from_well.map(well_names),\n    )\n    return get_correct_inbound_outbound(segments_df)\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.segment_path","title":"<code>segment_path(time, position, well_locations, max_distance_from_well=10)</code>","text":"<p>Label traversals between each well location.</p> <p>Parameters:</p> Name Type Description Default <code>time</code> <code>(ndarray, shape(n_time))</code> <p>Array of time points.</p> required <code>position</code> <code>(ndarray, shape(n_time, n_space))</code> <p>Array of positions at each time point.</p> required <code>well_locations</code> <code>(ndarray, shape(n_wells, n_space))</code> <p>Array of well locations.</p> required <code>max_distance_from_well</code> <code>float</code> <p>The animal is considered at a well location if its position is closer than this value, by default 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <ul> <li>segments_df: DataFrame of shape (n_segments, 6) containing segment information.</li> <li>labeled_segments: DataFrame of shape (n_time,) containing labeled segments.</li> </ul> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def segment_path(\n    time: np.ndarray,\n    position: np.ndarray,\n    well_locations: np.ndarray,\n    max_distance_from_well: float = 10,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Label traversals between each well location.\n\n    Parameters\n    ----------\n    time : np.ndarray, shape (n_time,)\n        Array of time points.\n    position : np.ndarray, shape (n_time, n_space)\n        Array of positions at each time point.\n    well_locations : np.ndarray, shape (n_wells, n_space)\n        Array of well locations.\n    max_distance_from_well : float, optional\n        The animal is considered at a well location if its position is closer\n        than this value, by default 10.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        - segments_df: DataFrame of shape (n_segments, 6) containing segment information.\n        - labeled_segments: DataFrame of shape (n_time,) containing labeled segments.\n    \"\"\"\n\n    well_enter_exit, at_target = np.stack(\n        [\n            enter_exit_target(position, np.atleast_2d(well), max_distance_from_well)\n            for well in well_locations\n        ],\n        axis=1,\n    )\n    n_wells = len(well_locations)\n    well_labels = np.arange(n_wells) + 1\n    well_enter_exit = np.sum(well_enter_exit.T * well_labels, axis=1)\n    shifted_well_enter_exit = shift_well_enters(well_enter_exit)\n    is_segment = ~(np.sum(at_target, axis=0) &gt; 0)\n    labeled_segments, n_segment_labels = label(is_segment)\n    segment_labels = np.arange(n_segment_labels) + 1\n\n    start_time, end_time, duration = [], [], []\n    distance_traveled, from_well, to_well = [], [], []\n\n    for segment_label in segment_labels:\n        is_seg = np.isin(labeled_segments, segment_label)\n        segment_time = time[is_seg]\n        start_time.append(segment_time.min())\n        end_time.append(segment_time.max())\n        duration.append(segment_time.max() - segment_time.min())\n        try:\n            start, _, end = np.unique(shifted_well_enter_exit[is_seg])\n        except ValueError:\n            start, end = np.nan, np.nan\n\n        from_well.append(np.abs(start))\n        to_well.append(np.abs(end))\n        p = position[is_seg]\n        distance_traveled.append(np.sum(paired_distances(p[1:], p[:-1])))\n\n    data = [\n        (\"start_time\", start_time),\n        (\"end_time\", end_time),\n        (\"duration\", duration),\n        (\"from_well\", from_well),\n        (\"to_well\", to_well),\n        (\"distance_traveled\", distance_traveled),\n    ]\n    index = pd.Index(segment_labels, name=\"segment\")\n    return (\n        pd.DataFrame.from_dict(dict(data)).set_index(index),\n        pd.DataFrame(dict(labeled_segments=labeled_segments), index=time),\n    )\n</code></pre>"},{"location":"reference/neuro_py/behavior/#neuro_py.behavior.shift_well_enters","title":"<code>shift_well_enters(enter_exit)</code>","text":"<p>Shifts the enter times back one time point.</p> <p>Parameters:</p> Name Type Description Default <code>enter_exit</code> <code>ndarray</code> <p>Array indicating enter (positive values) and exit (negative values) events.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with enter times shifted back by one time point.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def shift_well_enters(enter_exit: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Shifts the enter times back one time point.\n\n    Parameters\n    ----------\n    enter_exit : np.ndarray\n        Array indicating enter (positive values) and exit (negative values) events.\n\n    Returns\n    -------\n    np.ndarray\n        Array with enter times shifted back by one time point.\n    \"\"\"\n    shifted_enter_exit = enter_exit.copy()\n    old_ind = np.where(enter_exit &gt; 0)[0]  # positive entries are well-entries\n    new_ind = old_ind - 1\n    shifted_enter_exit[new_ind] = enter_exit[old_ind]\n    shifted_enter_exit[old_ind] = 0\n    return shifted_enter_exit\n</code></pre>"},{"location":"reference/neuro_py/behavior/cheeseboard/","title":"neuro_py.behavior.cheeseboard","text":""},{"location":"reference/neuro_py/behavior/cheeseboard/#neuro_py.behavior.cheeseboard.plot_grid_with_circle_and_random_dots","title":"<code>plot_grid_with_circle_and_random_dots()</code>","text":"<p>Plots a 15x15 grid of dots within a circle, highlights 3 randomly chosen dots within the circle, and draws a grey box at the bottom.</p> <p>The function generates a grid of points within a circle of a specified radius and randomly selects three points from within the circle. These points are colored red and slightly enlarged. Additionally, a grey box is drawn at the bottom of the plot.</p> Notes <ul> <li>The grid is plotted on a 15x15 layout, with points that fall within the   circle of radius 6.8 being displayed.</li> <li>The randomly selected points must be at least 4 grid units apart.</li> <li>A grey rectangular box is drawn near the bottom of the plot for aesthetic   purposes.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plot_grid_with_circle_and_random_dots()\n# This will display a plot of a circle containing a grid of dots with\n# 3 randomly chosen dots highlighted in red.\n</code></pre> Source code in <code>neuro_py/behavior/cheeseboard.py</code> <pre><code>def plot_grid_with_circle_and_random_dots():\n    \"\"\"\n    Plots a 15x15 grid of dots within a circle, highlights 3 randomly chosen dots\n    within the circle, and draws a grey box at the bottom.\n\n    The function generates a grid of points within a circle of a specified radius\n    and randomly selects three points from within the circle. These points are\n    colored red and slightly enlarged. Additionally, a grey box is drawn at the\n    bottom of the plot.\n\n    Notes\n    -----\n    - The grid is plotted on a 15x15 layout, with points that fall within the\n      circle of radius 6.8 being displayed.\n    - The randomly selected points must be at least 4 grid units apart.\n    - A grey rectangular box is drawn near the bottom of the plot for aesthetic\n      purposes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; plot_grid_with_circle_and_random_dots()\n    # This will display a plot of a circle containing a grid of dots with\n    # 3 randomly chosen dots highlighted in red.\n    \"\"\"\n    # Create a 15x15 grid of dots within the circle\n    x = np.linspace(-7, 7, 17)\n    y = np.linspace(-7, 7, 17)\n    X, Y = np.meshgrid(x, y)\n\n    # Calculate the circle parameters with an offset\n    radius = 6.8  # Radius of the circle\n    circle_center = (0, 0)  # Center of the circle\n\n    # Create a mask to display only the dots within the circle\n    circle_mask = (X**2 + Y**2) &lt;= radius**2\n\n    # Plot the grid of dots within the circle\n    plt.figure(figsize=(8, 8))\n    plt.plot(X[circle_mask], Y[circle_mask], \"o\", color=\"k\", markersize=6)\n\n    # Plot the circle\n    circle = plt.Circle(circle_center, radius, color=\"black\", fill=False)\n    plt.gca().add_patch(circle)\n\n    # Randomly pick 3 dots within the circle\n    num_dots = 3\n    chosen_indices = np.random.choice(np.sum(circle_mask), size=num_dots, replace=False)\n    chosen_dots = np.argwhere(circle_mask)\n    chosen_dots = chosen_dots[chosen_indices]\n\n    # Ensure minimum separation of 4 dots between the randomly chosen dots\n    min_separation = 4\n    for i in range(num_dots):\n        for j in range(i + 1, num_dots):\n            while np.linalg.norm(chosen_dots[i] - chosen_dots[j]) &lt; min_separation:\n                chosen_indices[j] = np.random.choice(np.sum(circle_mask), size=1)[0]\n                chosen_dots[j] = np.argwhere(circle_mask)[chosen_indices[j]]\n\n    # Color the randomly chosen dots red and make them slightly larger\n    for dot in chosen_dots:\n        plt.plot(X[dot[0], dot[1]], Y[dot[0], dot[1]], \"o\", color=\"red\", markersize=9)\n\n    # Draw a grey box at the bottom\n    plt.fill_between([-1.5, 1.5], -8.5, -6.5, color=\"darkgray\", alpha=1)\n\n    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n    plt.axis(\"off\")\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/","title":"neuro_py.behavior.circle_maze","text":""},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer","title":"<code>CircularTrackLinearizer</code>","text":"<p>Simple GUI for fitting a circle to circular track data and linearizing positions.</p> <p>Usage: - Left click and drag to move the circle center - Right click and drag to resize the circle radius - Press Enter to apply linearization and save results - Press 'r' to reset circle to auto-fit</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>class CircularTrackLinearizer:\n    \"\"\"\n    Simple GUI for fitting a circle to circular track data and linearizing positions.\n\n    Usage:\n    - Left click and drag to move the circle center\n    - Right click and drag to resize the circle radius\n    - Press Enter to apply linearization and save results\n    - Press 'r' to reset circle to auto-fit\n    \"\"\"\n\n    def __init__(self, x_data, y_data, basepath=None, epoch=None, interval=None):\n        self.x_data = np.array(x_data)\n        self.y_data = np.array(y_data)\n        self.basepath = basepath\n        self.epoch = epoch\n        self.interval = interval\n\n        # Remove NaN values for fitting\n        valid_mask = ~(np.isnan(self.x_data) | np.isnan(self.y_data))\n        self.x_valid = self.x_data[valid_mask]\n        self.y_valid = self.y_data[valid_mask]\n\n        # Initial circle parameters (auto-fit)\n        self.reset_circle()\n\n        # Create figure and axis\n        with plt.style.context(\"dark_background\"):\n            self.fig, self.ax = plt.subplots(figsize=(10, 8))\n            self.ax.set_aspect(\"equal\")\n\n            # Plot data points\n            self.data_scatter = self.ax.scatter(\n                self.x_valid,\n                self.y_valid,\n                c=\"lightblue\",\n                s=1,\n                alpha=0.6,\n                label=\"Track data\",\n            )\n\n            # Create circle patch\n            self.circle = Circle(\n                (self.center_x, self.center_y),\n                self.radius,\n                fill=False,\n                color=\"red\",\n                linewidth=2,\n                label=\"Fit circle\",\n            )\n            self.ax.add_patch(self.circle)\n\n            # Add center point\n            self.center_point = self.ax.scatter(\n                [self.center_x],\n                [self.center_y],\n                c=\"red\",\n                s=100,\n                marker=\"x\",\n                linewidth=3,\n                label=\"Center\",\n            )\n\n            # Set up the plot\n            self.ax.legend()\n            self.ax.grid(True, alpha=0.3)\n            self.ax.set_xlabel(\"X Position (cm)\")\n            self.ax.set_ylabel(\"Y Position (cm)\")\n            self.ax.set_title(\n                \"Circular Track Linearization\\n\"\n                \"Left click+drag: move center | Right click+drag: resize radius | Enter: linearize | r: reset\"\n            )\n\n            # Event handling variables\n            self.dragging = False\n            self.drag_mode = None  # 'center' or 'radius'\n            self.last_mouse_pos = None\n\n            # Connect events\n            self.fig.canvas.mpl_connect(\"button_press_event\", self.on_mouse_press)\n            self.fig.canvas.mpl_connect(\"button_release_event\", self.on_mouse_release)\n            self.fig.canvas.mpl_connect(\"motion_notify_event\", self.on_mouse_move)\n            self.fig.canvas.mpl_connect(\"key_press_event\", self.on_key_press)\n\n            plt.show()\n\n    def reset_circle(self):\n        \"\"\"Reset circle to auto-fit the data\"\"\"\n        # Auto-fit circle to data bounds\n        x_center = np.nanmean([np.nanmin(self.x_valid), np.nanmax(self.x_valid)])\n        y_center = np.nanmean([np.nanmin(self.y_valid), np.nanmax(self.y_valid)])\n\n        # Estimate radius as average distance from center to data points\n        distances = np.sqrt(\n            (self.x_valid - x_center) ** 2 + (self.y_valid - y_center) ** 2\n        )\n        radius = np.nanmean(distances)\n\n        self.center_x = x_center\n        self.center_y = y_center\n        self.radius = radius\n\n    def on_mouse_press(self, event):\n        \"\"\"Handle mouse press events\"\"\"\n        if event.inaxes != self.ax:\n            return\n\n        if event.button == 1:  # Left click - move center\n            self.dragging = True\n            self.drag_mode = \"center\"\n            self.last_mouse_pos = (event.xdata, event.ydata)\n        elif event.button == 3:  # Right click - resize radius\n            self.dragging = True\n            self.drag_mode = \"radius\"\n            self.last_mouse_pos = (event.xdata, event.ydata)\n\n    def on_mouse_release(self, event):\n        \"\"\"Handle mouse release events\"\"\"\n        self.dragging = False\n        self.drag_mode = None\n        self.last_mouse_pos = None\n\n    def on_mouse_move(self, event):\n        \"\"\"Handle mouse move events\"\"\"\n        if not self.dragging or event.inaxes != self.ax:\n            return\n\n        if self.drag_mode == \"center\":\n            # Move circle center\n            self.center_x = event.xdata\n            self.center_y = event.ydata\n            self.update_circle()\n\n        elif self.drag_mode == \"radius\":\n            # Resize circle radius based on distance from center\n            if event.xdata is not None and event.ydata is not None:\n                new_radius = np.sqrt(\n                    (event.xdata - self.center_x) ** 2\n                    + (event.ydata - self.center_y) ** 2\n                )\n                self.radius = new_radius\n                self.update_circle()\n\n    def on_key_press(self, event):\n        \"\"\"Handle key press events\"\"\"\n        if event.key == \"enter\":\n            self.linearize_and_save()\n        elif event.key == \"r\":\n            self.reset_circle()\n            self.update_circle()\n\n    def update_circle(self):\n        \"\"\"Update the circle visualization\"\"\"\n        self.circle.center = (self.center_x, self.center_y)\n        self.circle.radius = self.radius\n        self.center_point.set_offsets([[self.center_x, self.center_y]])\n        self.fig.canvas.draw()\n\n        # Update title with current parameters\n        self.ax.set_title(\n            f\"Circular Track Linearization\\n\"\n            f\"Center: ({self.center_x:.1f}, {self.center_y:.1f}), \"\n            f\"Radius: {self.radius:.1f}\\n\"\n            f\"Left click+drag: move center | Right click+drag: resize radius | Enter: linearize | r: reset\"\n        )\n\n    def linearize_positions(self):\n        \"\"\"Linearize positions using the fitted circle\"\"\"\n        # Apply your linearization logic\n        x_centered = self.x_data - self.center_x\n        y_centered = self.y_data - self.center_y\n\n        # Calculate theta (angle)\n        theta = np.arctan2(y_centered, x_centered)\n        theta[theta &lt; 0] += 2 * np.pi\n\n        # Convert to linear position (0 to 2*pi*radius)\n        linear_position = theta * self.radius\n\n        return linear_position, theta, x_centered, y_centered\n\n    def linearize_and_save(self):\n        \"\"\"Apply linearization and save results\"\"\"\n        print(\"Applying linearization...\")\n\n        # Get linearized positions\n        linear_pos, theta, x_centered, y_centered = self.linearize_positions()\n\n        # Create results DataFrame\n        results_df = pd.DataFrame(\n            {\n                \"x_original\": self.x_data,\n                \"y_original\": self.y_data,\n                \"x_centered\": x_centered,\n                \"y_centered\": y_centered,\n                \"theta\": theta,\n                \"linear_position\": linear_pos,\n                \"circle_center_x\": self.center_x,\n                \"circle_center_y\": self.center_y,\n                \"circle_radius\": self.radius,\n            }\n        )\n\n        # Show results plot\n        self.plot_results(results_df)\n\n        # Save results if basepath is provided\n        if self.basepath is not None:\n            self.save_to_behavior_file(results_df)\n\n        print(f\"Linearization complete!\")\n        print(f\"Circle center: ({self.center_x:.2f}, {self.center_y:.2f})\")\n        print(f\"Circle radius: {self.radius:.2f}\")\n        print(\n            f\"Linear position range: {np.nanmin(linear_pos):.2f} to {np.nanmax(linear_pos):.2f}\"\n        )\n\n        return results_df\n\n    def plot_results(self, results_df):\n        \"\"\"Plot linearization results\"\"\"\n        with plt.style.context(\"dark_background\"):\n            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n            fig.suptitle(\"Circular Track Linearization Results\", fontsize=14)\n\n            # Plot 1: Original data with fitted circle\n            ax1 = axes[0, 0]\n            ax1.scatter(\n                results_df[\"x_original\"],\n                results_df[\"y_original\"],\n                c=results_df[\"linear_position\"],\n                s=1,\n                alpha=0.7,\n                cmap=\"viridis\",\n            )\n            circle_plot = Circle(\n                (self.center_x, self.center_y),\n                self.radius,\n                fill=False,\n                color=\"red\",\n                linewidth=2,\n            )\n            ax1.add_patch(circle_plot)\n            ax1.scatter(\n                [self.center_x],\n                [self.center_y],\n                c=\"red\",\n                s=100,\n                marker=\"x\",\n                linewidth=3,\n            )\n            ax1.set_aspect(\"equal\")\n            ax1.set_title(\"Original Data with Fitted Circle\")\n            ax1.set_xlabel(\"X Position (cm)\")\n            ax1.set_ylabel(\"Y Position (cm)\")\n            ax1.grid(True, alpha=0.3)\n\n            # Plot 2: Centered coordinates\n            ax2 = axes[0, 1]\n            ax2.scatter(\n                results_df[\"x_centered\"],\n                results_df[\"y_centered\"],\n                c=results_df[\"linear_position\"],\n                s=1,\n                alpha=0.7,\n                cmap=\"viridis\",\n            )\n            circle_centered = Circle(\n                (0, 0), self.radius, fill=False, color=\"red\", linewidth=2\n            )\n            ax2.add_patch(circle_centered)\n            ax2.scatter([0], [0], c=\"red\", s=100, marker=\"x\", linewidth=3)\n            ax2.set_aspect(\"equal\")\n            ax2.set_title(\"Centered Coordinates\")\n            ax2.set_xlabel(\"X - Center (cm)\")\n            ax2.set_ylabel(\"Y - Center (cm)\")\n            ax2.grid(True, alpha=0.3)\n\n            # Plot 3: Linear position over time\n            ax3 = axes[1, 0]\n            valid_mask = ~np.isnan(results_df[\"linear_position\"])\n            ax3.scatter(\n                np.arange(len(results_df))[valid_mask],\n                results_df[\"linear_position\"][valid_mask],\n                s=1,\n                alpha=0.7,\n                color=\"blue\",\n            )\n            ax3.set_title(\"Linear Position Over Time\")\n            ax3.set_xlabel(\"Time Point\")\n            ax3.set_ylabel(\"Linear Position\")\n            ax3.grid(True, alpha=0.3)\n\n            # Plot 4: Theta (angle) distribution\n            ax4 = axes[1, 1]\n            valid_theta = results_df[\"theta\"][~np.isnan(results_df[\"theta\"])]\n            ax4.hist(valid_theta, bins=50, alpha=0.7, color=\"green\")\n            ax4.set_title(\"Angle (Theta) Distribution\")\n            ax4.set_xlabel(\"Theta (radians)\")\n            ax4.set_ylabel(\"Count\")\n            ax4.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            plt.show()\n\n    def save_to_behavior_file(self, results_df):\n        \"\"\"Save results to behavior file following the same epoch-aware logic as original code\"\"\"\n        try:\n            # Load existing behavior data\n            behave_df = load_animal_behavior(self.basepath)\n\n            # Determine which epochs/intervals to update (same logic as original)\n            if self.epoch is not None:\n                epochs = load_epoch(self.basepath)\n                cur_epoch = (behave_df.time &gt;= epochs.iloc[self.epoch].startTime) &amp; (\n                    behave_df.time &lt;= epochs.iloc[self.epoch].stopTime\n                )\n            elif hasattr(self, \"interval\") and self.interval is not None:\n                cur_epoch = (behave_df.time &gt;= self.interval[0]) &amp; (\n                    behave_df.time &lt;= self.interval[1]\n                )\n            else:\n                cur_epoch = behave_df.index\n\n            print(\"Saving to disk...\")\n\n            # Update only the specified epoch/interval data\n            behave_df.loc[cur_epoch, \"linearized\"] = results_df[\n                \"linear_position\"\n            ].values\n            behave_df.loc[cur_epoch, \"theta\"] = results_df[\"theta\"].values\n            behave_df.loc[cur_epoch, \"x_centered\"] = results_df[\"x_centered\"].values\n            behave_df.loc[cur_epoch, \"y_centered\"] = results_df[\"y_centered\"].values\n\n            # Load the .mat file and update it\n            filename = os.path.join(\n                self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n            )\n\n            if os.path.exists(filename):\n                data = loadmat(filename, simplify_cells=True)\n\n                # Update the linearized data (epoch-aware)\n                data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n                data[\"behavior\"][\"position\"][\"theta\"] = behave_df.theta.values\n                data[\"behavior\"][\"position\"][\"x_centered\"] = behave_df.x_centered.values\n                data[\"behavior\"][\"position\"][\"y_centered\"] = behave_df.y_centered.values\n\n                # Store circle parameters in behavior file (similar to nodes/edges storage)\n                # data = self.save_circle_params_to_behavior(data, behave_df)\n\n                # Save updated data\n                savemat(filename, data, long_field_names=True)\n                print(f\"Results saved to {filename}\")\n            else:\n                print(f\"Behavior file not found: {filename}\")\n\n        except Exception as e:\n            print(f\"Error saving to behavior file: {e}\")\n\n        # Also save as CSV for easy access\n        # csv_filename = os.path.join(self.basepath, \"circular_linearization_results.csv\")\n        # results_df.to_csv(csv_filename, index=False)\n        # print(f\"Results also saved as CSV: {csv_filename}\")\n\n    def save_circle_params_to_behavior(\n        self, data: dict, behave_df: pd.DataFrame\n    ) -&gt; dict:\n        \"\"\"\n        Store circle parameters into behavior file.\n        Similar to save_nodes_edges_to_behavior but for circular track parameters.\n        \"\"\"\n        circle_params = {\n            \"center_x\": self.center_x,\n            \"center_y\": self.center_y,\n            \"radius\": self.radius,\n            \"method\": \"circular_track\",\n        }\n\n        if self.epoch is None and not hasattr(self, \"interval\"):\n            # Load epochs and add to all epochs with valid linearized coords\n            epochs = load_epoch(self.basepath)\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                idx = behave_df.time.between(ep.startTime, ep.stopTime)\n                if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                    behave_df[idx].shape[0] != 0\n                ):\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"circle_params\"] = circle_params\n        elif hasattr(self, \"interval\") and self.interval is not None:\n            # Add to epochs within the interval\n            epochs = load_epoch(self.basepath)\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                start_overlap = max(self.interval[0], ep.startTime)\n                end_overlap = min(self.interval[1], ep.stopTime)\n                overlap = max(0, end_overlap - start_overlap)\n                if overlap &gt; 1:  # If overlap is greater than 1 second\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"circle_params\"] = circle_params\n        elif self.epoch is not None:\n            # Add to specific epoch\n            data[\"behavior\"][\"epochs\"][self.epoch][\"circle_params\"] = circle_params\n        else:\n            pass\n\n        return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.linearize_and_save","title":"<code>linearize_and_save()</code>","text":"<p>Apply linearization and save results</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def linearize_and_save(self):\n    \"\"\"Apply linearization and save results\"\"\"\n    print(\"Applying linearization...\")\n\n    # Get linearized positions\n    linear_pos, theta, x_centered, y_centered = self.linearize_positions()\n\n    # Create results DataFrame\n    results_df = pd.DataFrame(\n        {\n            \"x_original\": self.x_data,\n            \"y_original\": self.y_data,\n            \"x_centered\": x_centered,\n            \"y_centered\": y_centered,\n            \"theta\": theta,\n            \"linear_position\": linear_pos,\n            \"circle_center_x\": self.center_x,\n            \"circle_center_y\": self.center_y,\n            \"circle_radius\": self.radius,\n        }\n    )\n\n    # Show results plot\n    self.plot_results(results_df)\n\n    # Save results if basepath is provided\n    if self.basepath is not None:\n        self.save_to_behavior_file(results_df)\n\n    print(f\"Linearization complete!\")\n    print(f\"Circle center: ({self.center_x:.2f}, {self.center_y:.2f})\")\n    print(f\"Circle radius: {self.radius:.2f}\")\n    print(\n        f\"Linear position range: {np.nanmin(linear_pos):.2f} to {np.nanmax(linear_pos):.2f}\"\n    )\n\n    return results_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.linearize_positions","title":"<code>linearize_positions()</code>","text":"<p>Linearize positions using the fitted circle</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def linearize_positions(self):\n    \"\"\"Linearize positions using the fitted circle\"\"\"\n    # Apply your linearization logic\n    x_centered = self.x_data - self.center_x\n    y_centered = self.y_data - self.center_y\n\n    # Calculate theta (angle)\n    theta = np.arctan2(y_centered, x_centered)\n    theta[theta &lt; 0] += 2 * np.pi\n\n    # Convert to linear position (0 to 2*pi*radius)\n    linear_position = theta * self.radius\n\n    return linear_position, theta, x_centered, y_centered\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.on_key_press","title":"<code>on_key_press(event)</code>","text":"<p>Handle key press events</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def on_key_press(self, event):\n    \"\"\"Handle key press events\"\"\"\n    if event.key == \"enter\":\n        self.linearize_and_save()\n    elif event.key == \"r\":\n        self.reset_circle()\n        self.update_circle()\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.on_mouse_move","title":"<code>on_mouse_move(event)</code>","text":"<p>Handle mouse move events</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def on_mouse_move(self, event):\n    \"\"\"Handle mouse move events\"\"\"\n    if not self.dragging or event.inaxes != self.ax:\n        return\n\n    if self.drag_mode == \"center\":\n        # Move circle center\n        self.center_x = event.xdata\n        self.center_y = event.ydata\n        self.update_circle()\n\n    elif self.drag_mode == \"radius\":\n        # Resize circle radius based on distance from center\n        if event.xdata is not None and event.ydata is not None:\n            new_radius = np.sqrt(\n                (event.xdata - self.center_x) ** 2\n                + (event.ydata - self.center_y) ** 2\n            )\n            self.radius = new_radius\n            self.update_circle()\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.on_mouse_press","title":"<code>on_mouse_press(event)</code>","text":"<p>Handle mouse press events</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def on_mouse_press(self, event):\n    \"\"\"Handle mouse press events\"\"\"\n    if event.inaxes != self.ax:\n        return\n\n    if event.button == 1:  # Left click - move center\n        self.dragging = True\n        self.drag_mode = \"center\"\n        self.last_mouse_pos = (event.xdata, event.ydata)\n    elif event.button == 3:  # Right click - resize radius\n        self.dragging = True\n        self.drag_mode = \"radius\"\n        self.last_mouse_pos = (event.xdata, event.ydata)\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.on_mouse_release","title":"<code>on_mouse_release(event)</code>","text":"<p>Handle mouse release events</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def on_mouse_release(self, event):\n    \"\"\"Handle mouse release events\"\"\"\n    self.dragging = False\n    self.drag_mode = None\n    self.last_mouse_pos = None\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.plot_results","title":"<code>plot_results(results_df)</code>","text":"<p>Plot linearization results</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def plot_results(self, results_df):\n    \"\"\"Plot linearization results\"\"\"\n    with plt.style.context(\"dark_background\"):\n        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n        fig.suptitle(\"Circular Track Linearization Results\", fontsize=14)\n\n        # Plot 1: Original data with fitted circle\n        ax1 = axes[0, 0]\n        ax1.scatter(\n            results_df[\"x_original\"],\n            results_df[\"y_original\"],\n            c=results_df[\"linear_position\"],\n            s=1,\n            alpha=0.7,\n            cmap=\"viridis\",\n        )\n        circle_plot = Circle(\n            (self.center_x, self.center_y),\n            self.radius,\n            fill=False,\n            color=\"red\",\n            linewidth=2,\n        )\n        ax1.add_patch(circle_plot)\n        ax1.scatter(\n            [self.center_x],\n            [self.center_y],\n            c=\"red\",\n            s=100,\n            marker=\"x\",\n            linewidth=3,\n        )\n        ax1.set_aspect(\"equal\")\n        ax1.set_title(\"Original Data with Fitted Circle\")\n        ax1.set_xlabel(\"X Position (cm)\")\n        ax1.set_ylabel(\"Y Position (cm)\")\n        ax1.grid(True, alpha=0.3)\n\n        # Plot 2: Centered coordinates\n        ax2 = axes[0, 1]\n        ax2.scatter(\n            results_df[\"x_centered\"],\n            results_df[\"y_centered\"],\n            c=results_df[\"linear_position\"],\n            s=1,\n            alpha=0.7,\n            cmap=\"viridis\",\n        )\n        circle_centered = Circle(\n            (0, 0), self.radius, fill=False, color=\"red\", linewidth=2\n        )\n        ax2.add_patch(circle_centered)\n        ax2.scatter([0], [0], c=\"red\", s=100, marker=\"x\", linewidth=3)\n        ax2.set_aspect(\"equal\")\n        ax2.set_title(\"Centered Coordinates\")\n        ax2.set_xlabel(\"X - Center (cm)\")\n        ax2.set_ylabel(\"Y - Center (cm)\")\n        ax2.grid(True, alpha=0.3)\n\n        # Plot 3: Linear position over time\n        ax3 = axes[1, 0]\n        valid_mask = ~np.isnan(results_df[\"linear_position\"])\n        ax3.scatter(\n            np.arange(len(results_df))[valid_mask],\n            results_df[\"linear_position\"][valid_mask],\n            s=1,\n            alpha=0.7,\n            color=\"blue\",\n        )\n        ax3.set_title(\"Linear Position Over Time\")\n        ax3.set_xlabel(\"Time Point\")\n        ax3.set_ylabel(\"Linear Position\")\n        ax3.grid(True, alpha=0.3)\n\n        # Plot 4: Theta (angle) distribution\n        ax4 = axes[1, 1]\n        valid_theta = results_df[\"theta\"][~np.isnan(results_df[\"theta\"])]\n        ax4.hist(valid_theta, bins=50, alpha=0.7, color=\"green\")\n        ax4.set_title(\"Angle (Theta) Distribution\")\n        ax4.set_xlabel(\"Theta (radians)\")\n        ax4.set_ylabel(\"Count\")\n        ax4.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        plt.show()\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.reset_circle","title":"<code>reset_circle()</code>","text":"<p>Reset circle to auto-fit the data</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def reset_circle(self):\n    \"\"\"Reset circle to auto-fit the data\"\"\"\n    # Auto-fit circle to data bounds\n    x_center = np.nanmean([np.nanmin(self.x_valid), np.nanmax(self.x_valid)])\n    y_center = np.nanmean([np.nanmin(self.y_valid), np.nanmax(self.y_valid)])\n\n    # Estimate radius as average distance from center to data points\n    distances = np.sqrt(\n        (self.x_valid - x_center) ** 2 + (self.y_valid - y_center) ** 2\n    )\n    radius = np.nanmean(distances)\n\n    self.center_x = x_center\n    self.center_y = y_center\n    self.radius = radius\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.save_circle_params_to_behavior","title":"<code>save_circle_params_to_behavior(data, behave_df)</code>","text":"<p>Store circle parameters into behavior file. Similar to save_nodes_edges_to_behavior but for circular track parameters.</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def save_circle_params_to_behavior(\n    self, data: dict, behave_df: pd.DataFrame\n) -&gt; dict:\n    \"\"\"\n    Store circle parameters into behavior file.\n    Similar to save_nodes_edges_to_behavior but for circular track parameters.\n    \"\"\"\n    circle_params = {\n        \"center_x\": self.center_x,\n        \"center_y\": self.center_y,\n        \"radius\": self.radius,\n        \"method\": \"circular_track\",\n    }\n\n    if self.epoch is None and not hasattr(self, \"interval\"):\n        # Load epochs and add to all epochs with valid linearized coords\n        epochs = load_epoch(self.basepath)\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            idx = behave_df.time.between(ep.startTime, ep.stopTime)\n            if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                behave_df[idx].shape[0] != 0\n            ):\n                data[\"behavior\"][\"epochs\"][epoch_i][\"circle_params\"] = circle_params\n    elif hasattr(self, \"interval\") and self.interval is not None:\n        # Add to epochs within the interval\n        epochs = load_epoch(self.basepath)\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            start_overlap = max(self.interval[0], ep.startTime)\n            end_overlap = min(self.interval[1], ep.stopTime)\n            overlap = max(0, end_overlap - start_overlap)\n            if overlap &gt; 1:  # If overlap is greater than 1 second\n                data[\"behavior\"][\"epochs\"][epoch_i][\"circle_params\"] = circle_params\n    elif self.epoch is not None:\n        # Add to specific epoch\n        data[\"behavior\"][\"epochs\"][self.epoch][\"circle_params\"] = circle_params\n    else:\n        pass\n\n    return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.save_to_behavior_file","title":"<code>save_to_behavior_file(results_df)</code>","text":"<p>Save results to behavior file following the same epoch-aware logic as original code</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def save_to_behavior_file(self, results_df):\n    \"\"\"Save results to behavior file following the same epoch-aware logic as original code\"\"\"\n    try:\n        # Load existing behavior data\n        behave_df = load_animal_behavior(self.basepath)\n\n        # Determine which epochs/intervals to update (same logic as original)\n        if self.epoch is not None:\n            epochs = load_epoch(self.basepath)\n            cur_epoch = (behave_df.time &gt;= epochs.iloc[self.epoch].startTime) &amp; (\n                behave_df.time &lt;= epochs.iloc[self.epoch].stopTime\n            )\n        elif hasattr(self, \"interval\") and self.interval is not None:\n            cur_epoch = (behave_df.time &gt;= self.interval[0]) &amp; (\n                behave_df.time &lt;= self.interval[1]\n            )\n        else:\n            cur_epoch = behave_df.index\n\n        print(\"Saving to disk...\")\n\n        # Update only the specified epoch/interval data\n        behave_df.loc[cur_epoch, \"linearized\"] = results_df[\n            \"linear_position\"\n        ].values\n        behave_df.loc[cur_epoch, \"theta\"] = results_df[\"theta\"].values\n        behave_df.loc[cur_epoch, \"x_centered\"] = results_df[\"x_centered\"].values\n        behave_df.loc[cur_epoch, \"y_centered\"] = results_df[\"y_centered\"].values\n\n        # Load the .mat file and update it\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n        )\n\n        if os.path.exists(filename):\n            data = loadmat(filename, simplify_cells=True)\n\n            # Update the linearized data (epoch-aware)\n            data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n            data[\"behavior\"][\"position\"][\"theta\"] = behave_df.theta.values\n            data[\"behavior\"][\"position\"][\"x_centered\"] = behave_df.x_centered.values\n            data[\"behavior\"][\"position\"][\"y_centered\"] = behave_df.y_centered.values\n\n            # Store circle parameters in behavior file (similar to nodes/edges storage)\n            # data = self.save_circle_params_to_behavior(data, behave_df)\n\n            # Save updated data\n            savemat(filename, data, long_field_names=True)\n            print(f\"Results saved to {filename}\")\n        else:\n            print(f\"Behavior file not found: {filename}\")\n\n    except Exception as e:\n        print(f\"Error saving to behavior file: {e}\")\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.CircularTrackLinearizer.update_circle","title":"<code>update_circle()</code>","text":"<p>Update the circle visualization</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def update_circle(self):\n    \"\"\"Update the circle visualization\"\"\"\n    self.circle.center = (self.center_x, self.center_y)\n    self.circle.radius = self.radius\n    self.center_point.set_offsets([[self.center_x, self.center_y]])\n    self.fig.canvas.draw()\n\n    # Update title with current parameters\n    self.ax.set_title(\n        f\"Circular Track Linearization\\n\"\n        f\"Center: ({self.center_x:.1f}, {self.center_y:.1f}), \"\n        f\"Radius: {self.radius:.1f}\\n\"\n        f\"Left click+drag: move center | Right click+drag: resize radius | Enter: linearize | r: reset\"\n    )\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.load_animal_behavior","title":"<code>load_animal_behavior(basepath)</code>","text":"<p>Load animal behavior data from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the .mat file is located.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the animal behavior data.</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def load_animal_behavior(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load animal behavior data from a .mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the .mat file is located.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the animal behavior data.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = loadmat(filename, simplify_cells=True)\n    df = pd.DataFrame()\n    df[\"time\"] = data[\"behavior\"][\"timestamps\"]\n    try:\n        df[\"states\"] = data[\"behavior\"][\"states\"]\n    except Exception:\n        pass\n    for key in data[\"behavior\"][\"position\"].keys():\n        try:\n            df[key] = data[\"behavior\"][\"position\"][key]\n        except Exception:\n            pass\n    return df\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.load_epoch","title":"<code>load_epoch(basepath)</code>","text":"<p>Load epoch info from cell explorer basename.session and store in a DataFrame.</p> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def load_epoch(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"Load epoch info from cell explorer basename.session and store in a DataFrame.\"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n    data = loadmat(filename, simplify_cells=True)\n    try:\n        return pd.DataFrame(data[\"session\"][\"epochs\"])\n    except Exception:\n        return pd.DataFrame([data[\"session\"][\"epochs\"]])\n</code></pre>"},{"location":"reference/neuro_py/behavior/circle_maze/#neuro_py.behavior.circle_maze.run_circular_linearization","title":"<code>run_circular_linearization(basepath, epoch=None, interval=None)</code>","text":"<p>Run the circular track linearization GUI.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the data directory</p> required <code>epoch</code> <code>int</code> <p>Specific epoch to process</p> <code>None</code> <code>interval</code> <code>tuple</code> <p>Time interval (start, end) to process</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; run_circular_linearization(\"/path/to/data\")\n</code></pre> <p>On particular epoch:</p> <pre><code>&gt;&gt;&gt; run_circular_linearization(\"/path/to/data\", epoch=0)\n</code></pre> <p>On particular time interval:</p> <pre><code>&gt;&gt;&gt; run_circular_linearization(\"/path/to/data\", interval=(0, 100))\n</code></pre> <p>Run the script from the command line:</p> <pre><code>&gt;&gt;&gt; python circle_maze.py /path/to/data\n</code></pre> <p>On particular epoch:</p> <pre><code>&gt;&gt;&gt; python circle_maze.py /path/to/data 0\n</code></pre> <p>On particular time interval:</p> <pre><code>&gt;&gt;&gt; python circle_maze.py /path/to/data 0 100\n</code></pre> Source code in <code>neuro_py/behavior/circle_maze.py</code> <pre><code>def run_circular_linearization(\n    basepath: str,\n    epoch: Optional[int] = None,\n    interval: Optional[Tuple[float, float]] = None,\n):\n    \"\"\"\n    Run the circular track linearization GUI.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the data directory\n    epoch : int, optional\n        Specific epoch to process\n    interval : tuple, optional\n        Time interval (start, end) to process\n\n    Examples\n    --------\n    &gt;&gt;&gt; run_circular_linearization(\"/path/to/data\")\n\n    On particular epoch:\n    &gt;&gt;&gt; run_circular_linearization(\"/path/to/data\", epoch=0)\n\n    On particular time interval:\n    &gt;&gt;&gt; run_circular_linearization(\"/path/to/data\", interval=(0, 100))\n\n    Run the script from the command line:\n\n    &gt;&gt;&gt; python circle_maze.py /path/to/data\n\n    On particular epoch:\n    &gt;&gt;&gt; python circle_maze.py /path/to/data 0\n\n    On particular time interval:\n    &gt;&gt;&gt; python circle_maze.py /path/to/data 0 100\n    \"\"\"\n    print(f\"Loading data from {basepath}\")\n\n    # Load behavior data\n    behave_df = load_animal_behavior(basepath)\n\n    # Filter by epoch or interval if specified\n    if epoch is not None:\n        epochs = load_epoch(basepath)\n        print(f\"Processing epoch {epoch}\")\n        behave_df = behave_df[\n            behave_df[\"time\"].between(\n                epochs.iloc[epoch].startTime, epochs.iloc[epoch].stopTime\n            )\n        ]\n    elif interval is not None:\n        print(f\"Processing interval {interval}\")\n        behave_df = behave_df[behave_df[\"time\"].between(interval[0], interval[1])]\n\n    # Extract x, y coordinates\n    x_data = behave_df[\"x\"].values\n    y_data = behave_df[\"y\"].values\n\n    print(f\"Loaded {len(x_data)} data points\")\n    print(f\"X range: {np.nanmin(x_data):.1f} to {np.nanmax(x_data):.1f}\")\n    print(f\"Y range: {np.nanmin(y_data):.1f} to {np.nanmax(y_data):.1f}\")\n\n    # Create and run the linearization GUI\n    linearizer = CircularTrackLinearizer(\n        x_data, y_data, basepath=basepath, epoch=epoch, interval=interval\n    )\n\n    return linearizer\n</code></pre>"},{"location":"reference/neuro_py/behavior/get_trials/","title":"neuro_py.behavior.get_trials","text":""},{"location":"reference/neuro_py/behavior/get_trials/#neuro_py.behavior.get_trials.get_cheeseboard_trials","title":"<code>get_cheeseboard_trials(basepath, min_distance_from_home=15, max_trial_time=600, min_trial_time=5, kernel_size=2, min_std_away_from_home=6)</code>","text":"<p>Get epochs of cheeseboard trials.</p> <p>This function retrieves epochs for cheeseboard trials based on specified distance and time criteria.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>min_distance_from_home</code> <code>int</code> <p>The minimum distance from home to be considered a trial. Default is 15.</p> <code>15</code> <code>max_trial_time</code> <code>int</code> <p>The maximum duration of a trial in seconds. Default is 600 (10 minutes).</p> <code>600</code> <code>min_trial_time</code> <code>int</code> <p>The minimum duration of a trial in seconds. Default is 5.</p> <code>5</code> <code>kernel_size</code> <code>int</code> <p>The size of the kernel to use for smoothing. Default is 2.</p> <code>2</code> <code>min_std_away_from_home</code> <code>int</code> <p>The minimum standard deviation away from home to be considered a trial. Default is 6.</p> <code>6</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray</code> <p>The position data for the cheeseboard trials.</p> <code>trials</code> <code>EpochArray</code> <p>The epochs of the trials.</p> Notes <p>This function requires the following metadata dependencies:</p> <ul> <li><code>animal.behavior.mat</code>: contains homebox_x and homebox_y coordinates within epochs.</li> </ul> <p>You can label these with <code>label_key_locations_cheeseboard.m</code> or manually.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_cheeseboard_trials(\n    basepath: str,\n    min_distance_from_home: int = 15,\n    max_trial_time: int = 600,  # Default is 60 * 10\n    min_trial_time: int = 5,\n    kernel_size: int = 2,\n    min_std_away_from_home: int = 6,\n) -&gt; Tuple[nel.PositionArray, nel.EpochArray]:\n    \"\"\"\n    Get epochs of cheeseboard trials.\n\n    This function retrieves epochs for cheeseboard trials based on specified\n    distance and time criteria.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    min_distance_from_home : int, optional\n        The minimum distance from home to be considered a trial. Default is 15.\n    max_trial_time : int, optional\n        The maximum duration of a trial in seconds. Default is 600 (10 minutes).\n    min_trial_time : int, optional\n        The minimum duration of a trial in seconds. Default is 5.\n    kernel_size : int, optional\n        The size of the kernel to use for smoothing. Default is 2.\n    min_std_away_from_home : int, optional\n        The minimum standard deviation away from home to be considered a trial.\n        Default is 6.\n\n    Returns\n    -------\n    pos : PositionArray\n        The position data for the cheeseboard trials.\n    trials : EpochArray\n        The epochs of the trials.\n\n    Notes\n    -----\n    This function requires the following metadata dependencies:\n\n    - `animal.behavior.mat`: contains homebox_x and homebox_y coordinates within epochs.\n\n    You can label these with `label_key_locations_cheeseboard.m` or manually.\n    \"\"\"\n\n    # load position and key location metadata\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # load epochs and place in array\n    epoch_df = loading.load_epoch(basepath)\n    epoch = nel.EpochArray(\n        [np.array([epoch_df.startTime, epoch_df.stopTime]).T], label=\"session_epochs\"\n    )\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n    pos = nel.PositionArray(\n        data=position_df_no_nan[[\"x\", \"y\"]].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    # calculate kernel samples size based on sampling rate for x seconds\n    kernel_size = int(pos.fs * kernel_size)\n    # check if even number\n    if kernel_size % 2 == 0:\n        kernel_size += 1\n\n    cheeseboard_idx = np.where(epoch_df.environment == \"cheeseboard\")[0]\n    trials_temp = []\n    stddev = []\n    for idx in cheeseboard_idx:\n        # get homebox location\n        homebox_x = data[\"behavior\"][\"epochs\"][idx][\"homebox_x\"]\n        homebox_y = data[\"behavior\"][\"epochs\"][idx][\"homebox_y\"]\n\n        # get position during epoch\n        current_pos = pos[epoch[int(idx)]]\n        x, y = current_pos.data\n\n        # calculate distance from homebox\n        distance = np.sqrt((x - homebox_x) ** 2 + (y - homebox_y) ** 2)\n\n        # median filter distance to remove noise (jumps in position)\n        distance = medfilt(distance, kernel_size=kernel_size)\n\n        # find intervals where distance is greater than min_distance_from_home\n        dist_intervals = np.array(find_interval((distance &gt; min_distance_from_home)))\n\n        close_distances = distance[distance &lt; min_distance_from_home]\n        for trial in dist_intervals:\n            far_distances = distance[trial[0] : trial[1]].mean()\n\n            stddev.append(\n                (np.abs(far_distances) - np.nanmean(np.abs(close_distances), axis=0))\n                / np.nanstd(np.abs(close_distances), axis=0)\n            )\n\n        # get start and stop times of intervals\n        if len(dist_intervals) &gt; 0:\n            trials_temp.append(current_pos.time[dist_intervals])\n\n    # concatenate trials and place in EpochArray\n    trials = nel.EpochArray(np.vstack(trials_temp))\n\n    # remove trials that are too long or too short\n    trials._data = trials.data[\n        (trials.durations &lt; max_trial_time)\n        &amp; (trials.durations &gt; min_trial_time)\n        &amp; (np.array(stddev) &gt; min_std_away_from_home)\n    ]\n\n    return pos, trials\n</code></pre>"},{"location":"reference/neuro_py/behavior/get_trials/#neuro_py.behavior.get_trials.get_linear_maze_trials","title":"<code>get_linear_maze_trials(basepath, epoch_input=None)</code>","text":"<p>Get trials for linear maze.</p> <p>Locates inbound and outbound laps for each linear track in the session.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The path to the base directory of the session data.</p> required <code>epoch_input</code> <code>None</code> <p>Deprecated parameter. This is no longer supported.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the linear maze trials.</p> <code>inbound_laps</code> <code>EpochArray or None</code> <p>The epochs corresponding to inbound laps.</p> <code>outbound_laps</code> <code>EpochArray or None</code> <p>The epochs corresponding to outbound laps.</p> Notes <p>If no valid position data is found, None values are returned for all outputs.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_linear_maze_trials(\n    basepath: str, epoch_input: None = None\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[nel.EpochArray, None],\n    Union[nel.EpochArray, None],\n]:\n    \"\"\"Get trials for linear maze.\n\n    Locates inbound and outbound laps for each linear track in the session.\n\n    Parameters\n    ----------\n    basepath : str\n        The path to the base directory of the session data.\n    epoch_input : None, optional\n        Deprecated parameter. This is no longer supported.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the linear maze trials.\n    inbound_laps : EpochArray or None\n        The epochs corresponding to inbound laps.\n    outbound_laps : EpochArray or None\n        The epochs corresponding to outbound laps.\n\n    Notes\n    -----\n    If no valid position data is found, None values are returned for all\n    outputs.\n    \"\"\"\n    if epoch_input is not None:\n        logging.warning(\"epoch_input is no longer supported\")\n\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    if position_df_no_nan.shape[0] == 0:\n        return None, None, None\n\n    if \"linearized\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    epoch_df = loading.load_epoch(basepath)\n    epoch = nel.EpochArray([np.array([epoch_df.startTime, epoch_df.stopTime]).T])\n\n    domain = nel.EpochArray(\n        [np.array([epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]).T]\n    )\n\n    inbound_laps_temp = []\n    outbound_laps_temp = []\n    maze_idx = np.where(epoch_df.environment == \"linear\")[0]\n    for idx in maze_idx:\n        current_position = pos[epoch[int(idx)]]\n\n        # get outbound and inbound epochs\n        outbound_laps, inbound_laps = linear_positions.get_linear_track_lap_epochs(\n            current_position.abscissa_vals, current_position.data[0], newLapThreshold=20\n        )\n        if not inbound_laps.isempty:\n            inbound_laps = linear_positions.find_good_lap_epochs(\n                current_position, inbound_laps, min_laps=5\n            )\n\n        if not outbound_laps.isempty:\n            outbound_laps = linear_positions.find_good_lap_epochs(\n                current_position, outbound_laps, min_laps=5\n            )\n\n        if not inbound_laps.isempty:\n            inbound_laps_temp.append(inbound_laps.data)\n        if not outbound_laps.isempty:\n            outbound_laps_temp.append(outbound_laps.data)\n\n    inbound_laps = nel.EpochArray(np.vstack(inbound_laps_temp), domain=domain)\n    outbound_laps = nel.EpochArray(np.vstack(outbound_laps_temp), domain=domain)\n\n    return pos, inbound_laps, outbound_laps\n</code></pre>"},{"location":"reference/neuro_py/behavior/get_trials/#neuro_py.behavior.get_trials.get_openfield_trials","title":"<code>get_openfield_trials(basepath, epoch_type='epochs', spatial_binsize=3, n_time_bins=1, bin_method='dynamic', trial_time_bin_size=60, prop_trial_sampled=0.5, environments=['box', 'bigSquare', 'midSquare', 'bigSquarePlus', 'plus'], minimum_correlation=0.6, method='correlation')</code>","text":"<p>Get epochs of openfield trials.</p> <p>This function identifies trials in an open field environment that meet specific criteria for spatial sampling to assess spatial stability and population correlations.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>epoch_type</code> <code>str</code> <p>The type of epoch to use ('trials' or 'epochs'). Default is 'epochs'.</p> <code>'epochs'</code> <code>spatial_binsize</code> <code>int</code> <p>The size of spatial bins to use for occupancy. Default is 3.</p> <code>3</code> <code>n_time_bins</code> <code>int</code> <p>The number of time bins to use for occupancy for fixed bin method. Default is 1.</p> <code>1</code> <code>bin_method</code> <code>str</code> <p>The method to use for binning time ('dynamic' or 'fixed'). Default is 'dynamic'.</p> <code>'dynamic'</code> <code>trial_time_bin_size</code> <code>Union[int, float]</code> <p>The size of time bins to use for occupancy for dynamic bin method (in seconds). Default is 60.</p> <code>60</code> <code>prop_trial_sampled</code> <code>float</code> <p>The proportion of trials to sample. Default is 0.5.</p> <code>0.5</code> <code>environments</code> <code>List[str]</code> <p>A list of environments to include as open field. Default includes several environments such as 'box' and 'plus'.</p> <code>['box', 'bigSquare', 'midSquare', 'bigSquarePlus', 'plus']</code> <code>minimum_correlation</code> <code>float</code> <p>The minimum correlation between trials to be considered a trial. Default is 0.6.</p> <code>0.6</code> <code>method</code> <code>str</code> <p>The method to use ('correlation' or 'proportion'). Default is 'correlation'. <code>correlation</code> - use correlation between the trial map and the overall map to determine if it is a trial. <code>proportion</code> - use the proportion of the trial map that is sampled to determine if it is a trial</p> <code>'correlation'</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray</code> <p>The position data for the open field trials.</p> <code>trials</code> <code>EpochArray</code> <p>The epochs of the identified trials.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is not 'correlation' or 'proportion'.</p> Notes <p>This function requires the loading of animal behavior and epoch data from the specified base path.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_openfield_trials(\n    basepath: str,\n    epoch_type: str = \"epochs\",\n    spatial_binsize: int = 3,\n    n_time_bins: int = 1,  # for bin_method = \"fixed\", not used for bin_method = \"dynamic\"\n    bin_method: str = \"dynamic\",\n    trial_time_bin_size: Union[\n        int, float\n    ] = 60,  # in seconds for bin_method = \"dynamic\", not used for bin_method = \"fixed\"\n    prop_trial_sampled: float = 0.5,\n    environments: List[str] = [\n        \"box\",\n        \"bigSquare\",\n        \"midSquare\",\n        \"bigSquarePlus\",\n        \"plus\",\n    ],\n    minimum_correlation: float = 0.6,\n    method: str = \"correlation\",\n) -&gt; Tuple[nel.PositionArray, nel.EpochArray]:\n    \"\"\"\n    Get epochs of openfield trials.\n\n    This function identifies trials in an open field environment that meet\n    specific criteria for spatial sampling to assess spatial stability and\n    population correlations.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    epoch_type : str, optional\n        The type of epoch to use ('trials' or 'epochs'). Default is 'epochs'.\n    spatial_binsize : int, optional\n        The size of spatial bins to use for occupancy. Default is 3.\n    n_time_bins : int, optional\n        The number of time bins to use for occupancy for fixed bin method.\n        Default is 1.\n    bin_method : str, optional\n        The method to use for binning time ('dynamic' or 'fixed').\n        Default is 'dynamic'.\n    trial_time_bin_size : Union[int, float], optional\n        The size of time bins to use for occupancy for dynamic bin method\n        (in seconds). Default is 60.\n    prop_trial_sampled : float, optional\n        The proportion of trials to sample. Default is 0.5.\n    environments : List[str], optional\n        A list of environments to include as open field. Default includes\n        several environments such as 'box' and 'plus'.\n    minimum_correlation : float, optional\n        The minimum correlation between trials to be considered a trial.\n        Default is 0.6.\n    method : str, optional\n        The method to use ('correlation' or 'proportion'). Default is\n        'correlation'. `correlation` - use correlation between the trial map and\n        the overall map to determine if it is a trial. `proportion` - use the\n        proportion of the trial map that is sampled to determine if it is a\n        trial\n\n    Returns\n    -------\n    pos : PositionArray\n        The position data for the open field trials.\n    trials : EpochArray\n        The epochs of the identified trials.\n\n    Raises\n    ------\n    ValueError\n        If the method is not 'correlation' or 'proportion'.\n\n    Notes\n    -----\n    This function requires the loading of animal behavior and epoch data\n    from the specified base path.\n    \"\"\"\n\n    def compute_occupancy_2d(\n        pos_run: object, x_edges: list, y_edges: list\n    ) -&gt; np.ndarray:\n        \"\"\"Compute occupancy of 2D position\n\n        Parameters\n        ----------\n        pos_run : object\n            Position data for the run\n        x_edges : list\n            Bin edges of x position\n        y_edges : list\n            Bin edges of y position\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy map of the position\n        \"\"\"\n        occupancy, _, _ = np.histogram2d(\n            pos_run.data[0, :], pos_run.data[1, :], bins=(x_edges, y_edges)\n        )\n        return occupancy / pos_run.fs\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n    pos = nel.PositionArray(\n        data=position_df_no_nan[[\"x\", \"y\"]].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    if pos.isempty:\n        return pos, nel.EpochArray([], label=\"session_epochs\")\n\n    # load epochs and place in array\n    if epoch_type == \"trials\":\n        epoch_df = loading.load_trials(basepath)\n        openfield_idx = np.arange(\n            0, len(epoch_df)\n        )  # assume trials make up all epochs associated with position\n        trialsID = epoch_df.trialsID.values\n    elif epoch_type == \"epochs\":\n        epoch_df = loading.load_epoch(basepath)\n        # find epochs that are these environments\n        openfield_idx = np.where(np.isin(epoch_df.environment, environments))[0]\n\n    epoch = nel.EpochArray([np.array([epoch_df.startTime, epoch_df.stopTime]).T])\n\n    # find epochs that are these environments\n    trials = []\n    if epoch_type == \"trials\":\n        trial_ID = []\n\n    # loop through epochs\n    for idx in openfield_idx:\n        # get position during epoch\n        current_position = pos[epoch[int(idx)]]\n\n        if current_position.isempty:\n            continue\n\n        # get the edges of the position\n        ext_xmin, ext_xmax = (\n            np.floor(np.nanmin(current_position.data[0, :])),\n            np.ceil(np.nanmax(current_position.data[0, :])),\n        )\n        ext_ymin, ext_ymax = (\n            np.floor(np.nanmin(current_position.data[1, :])),\n            np.ceil(np.nanmax(current_position.data[1, :])),\n        )\n        # create bin edges for occupancy map at spatial_binsize\n        x_edges = np.arange(ext_xmin, ext_xmax + spatial_binsize, spatial_binsize)\n        y_edges = np.arange(ext_ymin, ext_ymax + spatial_binsize, spatial_binsize)\n\n        # compute occupancy map and get proportion of environment sampled\n        occupancy = compute_occupancy_2d(current_position, x_edges, y_edges)\n        overall_prop_sampled = sum(occupancy.flatten() &gt; 0) / (\n            (len(x_edges) - 1) * (len(y_edges) - 1)\n        )\n        # create possible trials based on trial_time_bin_size\n        # these will be iterated over to find trials that are sampled enough\n        duration = epoch_df.iloc[idx].stopTime - epoch_df.iloc[idx].startTime\n\n        if bin_method == \"dynamic\":\n            bins = np.linspace(\n                epoch_df.iloc[idx].startTime,\n                epoch_df.iloc[idx].stopTime,\n                int(np.ceil(duration / (trial_time_bin_size))),\n            )\n        elif bin_method == \"fixed\":\n            bins = np.arange(\n                epoch_df.iloc[idx].startTime,\n                epoch_df.iloc[idx].stopTime,\n                int(np.floor(epoch[int(idx)].duration / n_time_bins)),\n            )\n        trials_temp = nel.EpochArray(np.array([bins[:-1], bins[1:]]).T)\n        if epoch_type == \"trials\":\n            temp_ID = trialsID[idx]\n\n        trial_i = 0\n        # loop through possible trials and find when sampled enough\n        for i_interval in range(trials_temp.n_intervals):\n            # compute occupancy map and get proportion of environment sampled for trial\n            trial_occupancy = compute_occupancy_2d(\n                current_position[trials_temp[trial_i : i_interval + 1]],\n                x_edges,\n                y_edges,\n            )\n\n            if method == \"correlation\":\n                # correlate trial_occupancy with overall occupancy\n                r = np.corrcoef(\n                    occupancy.flatten() &gt; 0,\n                    trial_occupancy.flatten() &gt; 0,\n                )[0, 1]\n\n                # if sampled enough, add to trials\n                if r &gt; minimum_correlation:\n                    trials.append(\n                        [\n                            trials_temp[trial_i : i_interval + 1].start,\n                            trials_temp[trial_i : i_interval + 1].stop,\n                        ]\n                    )\n                    if epoch_type == \"trials\":\n                        trial_ID.append(temp_ID + \"_\" + str(idx))\n                    # update trial_i to next interval to start from\n                    trial_i = i_interval + 1\n\n            elif method == \"proportion\":\n                trial_prop_sampled = sum(trial_occupancy.flatten() &gt; 0) / (\n                    (len(x_edges) - 1) * (len(y_edges) - 1)\n                )\n                if trial_prop_sampled &gt; prop_trial_sampled * overall_prop_sampled:\n                    trials.append(\n                        [\n                            trials_temp[trial_i : i_interval + 1].start,\n                            trials_temp[trial_i : i_interval + 1].stop,\n                        ]\n                    )\n                    if epoch_type == \"trials\":\n                        trial_ID.append(temp_ID + \"_\" + str(idx))\n                    # update trial_i to next interval to start from\n                    trial_i = i_interval + 1\n            else:\n                raise ValueError(\"method must be correlation or proportion\")\n\n    # concatenate trials and place in EpochArray\n    if epoch_type == \"trials\":\n        trials = nel.EpochArray(np.vstack(trials), label=np.vstack(trial_ID))\n    else:\n        trials = nel.EpochArray(np.vstack(trials), label=\"session_epochs\")\n\n    return pos, trials\n</code></pre>"},{"location":"reference/neuro_py/behavior/get_trials/#neuro_py.behavior.get_trials.get_t_maze_trials","title":"<code>get_t_maze_trials(basepath, epoch, bypass_standard_behavior=False)</code>","text":"<p>Get trials for T maze.</p> <p>This function retrieves position data and epochs for right and left trials based on the specified epoch. It checks if the number of outbound laps exceeds the number of inbound laps unless bypassed.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>epoch</code> <code>EpochArray</code> <p>The epoch to get trials for.</p> required <code>bypass_standard_behavior</code> <code>bool</code> <p>If True, allows for more outbound than inbound trials. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the T maze trials.</p> <code>right_epochs</code> <code>EpochArray or None</code> <p>The epochs corresponding to right trials.</p> <code>left_epochs</code> <code>EpochArray or None</code> <p>The epochs corresponding to left trials.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If inbound laps exceed outbound laps and bypass_standard_behavior is False.</p> Notes <p>If there are no valid positions or states in the session data, None is returned for all outputs.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_t_maze_trials(\n    basepath: str, epoch: nel.EpochArray, bypass_standard_behavior: bool = False\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[nel.EpochArray, None],\n    Union[nel.EpochArray, None],\n]:\n    \"\"\"\n    Get trials for T maze.\n\n    This function retrieves position data and epochs for right and left trials\n    based on the specified epoch. It checks if the number of outbound laps exceeds\n    the number of inbound laps unless bypassed.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    epoch : nel.EpochArray\n        The epoch to get trials for.\n    bypass_standard_behavior : bool, optional\n        If True, allows for more outbound than inbound trials. Default is False.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the T maze trials.\n    right_epochs : EpochArray or None\n        The epochs corresponding to right trials.\n    left_epochs : EpochArray or None\n        The epochs corresponding to left trials.\n\n    Raises\n    ------\n    TypeError\n        If inbound laps exceed outbound laps and bypass_standard_behavior is False.\n\n    Notes\n    -----\n    If there are no valid positions or states in the session data, None is returned\n    for all outputs.\n    \"\"\"\n\n    def dissociate_laps_by_states(states, dir_epoch, states_of_interest=[1, 2]):\n        # unique_states = np.unique(states.data[~np.isnan(states.data)])\n        lap_id = []\n        for ep in dir_epoch:\n            state_count = []\n            for us in states_of_interest:\n                state_count.append(np.nansum(states[ep].data == us))\n            lap_id.append(states_of_interest[np.argmax(state_count)])\n        return np.array(lap_id).astype(int)\n\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    if position_df_no_nan.shape[0] == 0:\n        return None, None, None\n\n    if \"linearized\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    if \"states\" not in position_df_no_nan.columns:\n        return None, None, None\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n\n    pos = pos[epoch]\n    if pos.isempty:\n        return None, None, None\n\n    states = nel.AnalogSignalArray(\n        data=position_df_no_nan[\"states\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    states = states[epoch]\n\n    # get outbound and inbound epochs\n    outbound_laps, inbound_laps = linear_positions.get_linear_track_lap_epochs(\n        pos.abscissa_vals, pos.data[0], newLapThreshold=20\n    )\n\n    inbound_laps = linear_positions.find_good_lap_epochs(pos, inbound_laps, min_laps=5)\n    outbound_laps = linear_positions.find_good_lap_epochs(\n        pos, outbound_laps, min_laps=5\n    )\n\n    if outbound_laps.isempty:\n        return None, None, None\n\n    if not inbound_laps.isempty:\n        logging.warning(\"inbound_laps should be empty for tmaze\")\n\n    if (\n        inbound_laps.n_intervals &gt; outbound_laps.n_intervals\n    ) and not bypass_standard_behavior:\n        raise TypeError(\"inbound_laps should be less than outbound_laps for tmaze\")\n\n    # locate laps with the majority in state 1 or 2\n    lap_id = dissociate_laps_by_states(states, outbound_laps, states_of_interest=[1, 2])\n\n    right_epochs = nel.EpochArray(data=outbound_laps.data[lap_id == 1, :])\n    left_epochs = nel.EpochArray(data=outbound_laps.data[lap_id == 2, :])\n\n    position_df_no_nan = position_df_no_nan[\n        position_df_no_nan[\"time\"].between(epoch.start, epoch.stop)\n    ]\n    return pos, right_epochs, left_epochs\n</code></pre>"},{"location":"reference/neuro_py/behavior/get_trials/#neuro_py.behavior.get_trials.get_w_maze_trials","title":"<code>get_w_maze_trials(basepath, max_distance_from_well=20, min_distance_traveled=50)</code>","text":"<p>Get trials for W maze.</p> <p>This function retrieves position data and identifies trials for the W maze based on specified distance criteria.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the session data.</p> required <code>max_distance_from_well</code> <code>int</code> <p>The maximum distance from the well to be considered a trial. Default is 20.</p> <code>20</code> <code>min_distance_traveled</code> <code>int</code> <p>The minimum distance traveled to be considered a trial. Default is 50.</p> <code>50</code> <p>Returns:</p> Name Type Description <code>pos</code> <code>PositionArray or None</code> <p>The position data for the W maze trials.</p> <code>trials</code> <code>ndarray or None</code> <p>The indices of the trials.</p> <code>right_trials</code> <code>ndarray or None</code> <p>The indices of the right trials.</p> <code>left_trials</code> <code>ndarray or None</code> <p>The indices of the left trials.</p> Notes <p>This function requires the following metadata dependencies:</p> <ul> <li><code>animal.behavior.mat</code>: contains center, left, and right x y coordinates.</li> </ul> <p>You can label these with <code>label_key_locations_wmaze.m</code> or manually.</p> Source code in <code>neuro_py/behavior/get_trials.py</code> <pre><code>def get_w_maze_trials(\n    basepath: str, max_distance_from_well: int = 20, min_distance_traveled: int = 50\n) -&gt; Tuple[\n    Union[nel.PositionArray, None],\n    Union[np.ndarray, None],\n    Union[np.ndarray, None],\n    Union[np.ndarray, None],\n]:\n    \"\"\"\n    Get trials for W maze.\n\n    This function retrieves position data and identifies trials for the W maze\n    based on specified distance criteria.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the session data.\n    max_distance_from_well : int, optional\n        The maximum distance from the well to be considered a trial. Default is 20.\n    min_distance_traveled : int, optional\n        The minimum distance traveled to be considered a trial. Default is 50.\n\n    Returns\n    -------\n    pos : PositionArray or None\n        The position data for the W maze trials.\n    trials : ndarray or None\n        The indices of the trials.\n    right_trials : ndarray or None\n        The indices of the right trials.\n    left_trials : ndarray or None\n        The indices of the left trials.\n\n    Notes\n    -----\n    This function requires the following metadata dependencies:\n\n    - `animal.behavior.mat`: contains center, left, and right x y coordinates.\n\n    You can label these with `label_key_locations_wmaze.m` or manually.\n    \"\"\"\n\n    # load position and key location metadata\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # load epochs and place in array\n    epoch_df = loading.load_epoch(basepath)\n\n    # load position and place in array\n    position_df = loading.load_animal_behavior(basepath)\n    position_df_no_nan = position_df.query(\"not x.isnull() &amp; not y.isnull()\")\n\n    pos = nel.PositionArray(\n        data=position_df_no_nan[\"linearized\"].values.T,\n        timestamps=position_df_no_nan.timestamps.values,\n    )\n    wmaze_idx = np.where(epoch_df.environment == \"wmaze\")[0]\n    for idx in wmaze_idx:\n        # get key locations\n        right_x = data[\"behavior\"][\"epochs\"][idx][\"right_x\"]\n        right_y = data[\"behavior\"][\"epochs\"][idx][\"right_y\"]\n\n        center_x = data[\"behavior\"][\"epochs\"][idx][\"center_x\"]\n        center_y = data[\"behavior\"][\"epochs\"][idx][\"center_y\"]\n\n        left_x = data[\"behavior\"][\"epochs\"][idx][\"left_x\"]\n        left_y = data[\"behavior\"][\"epochs\"][idx][\"left_y\"]\n\n        well_locations = np.array(\n            [[center_x, center_y], [left_x, left_y], [right_x, right_y]]\n        )\n\n        current_ts_idx = position_df_no_nan[\"timestamps\"].between(\n            epoch_df.iloc[idx].startTime, epoch_df.iloc[idx].stopTime\n        )\n\n        # temp_df = position_df[~np.isnan(position_df.x)]\n        segments_df, _ = well_traversal_classification.segment_path(\n            position_df_no_nan[\"timestamps\"].values[current_ts_idx],\n            position_df_no_nan[[\"x\", \"y\"]].values[current_ts_idx],\n            well_locations,\n            max_distance_from_well=max_distance_from_well,\n        )\n\n        segments_df = well_traversal_classification.score_inbound_outbound(\n            segments_df, min_distance_traveled=min_distance_traveled\n        )\n        conditions = [\n            \"from_well == 'Center' &amp; to_well == 'Left'\",\n            \"from_well == 'Left' &amp; to_well == 'Center'\",\n            \"from_well == 'Center' &amp; to_well == 'Right'\",\n            \"from_well == 'Right' &amp; to_well == 'Center'\",\n        ]\n        condition_labels = [\n            \"center_left\",\n            \"left_center\",\n            \"center_right\",\n            \"right_center\",\n        ]\n        trajectories = {}\n        for con, con_label in zip(conditions, condition_labels):\n            trajectories[con_label] = nel.EpochArray(\n                np.array(\n                    [segments_df.query(con).start_time, segments_df.query(con).end_time]\n                ).T\n            )\n\n    return pos, trajectories\n</code></pre>"},{"location":"reference/neuro_py/behavior/kinematics/","title":"neuro_py.behavior.kinematics","text":""},{"location":"reference/neuro_py/behavior/kinematics/#neuro_py.behavior.kinematics.get_speed","title":"<code>get_speed(position, time=None)</code>","text":"<p>Computes the speed from position data.</p> <p>Speed is the magnitude of the velocity vector at each time point. If time is not provided, it assumes a constant time step between position samples.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>An array of position data. This can be 1D (for single-dimensional positions) or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).</p> required <code>time</code> <code>Union[ndarray, None]</code> <p>An array of time values corresponding to the position data. If None, the function assumes a constant time step. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of speed values, where each speed is the magnitude of the velocity at the corresponding time point.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n&gt;&gt;&gt; get_speed(position)\narray([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n</code></pre> <pre><code>&gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n&gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n&gt;&gt;&gt; get_speed(position, time)\narray([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n</code></pre> Source code in <code>neuro_py/behavior/kinematics.py</code> <pre><code>def get_speed(position: np.ndarray, time: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n    \"\"\"\n    Computes the speed from position data.\n\n    Speed is the magnitude of the velocity vector at each time point. If time is\n    not provided, it assumes a constant time step between position samples.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        An array of position data. This can be 1D (for single-dimensional positions)\n        or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).\n    time : Union[np.ndarray, None], optional\n        An array of time values corresponding to the position data. If None,\n        the function assumes a constant time step. Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        An array of speed values, where each speed is the magnitude of the velocity\n        at the corresponding time point.\n\n    Examples\n    --------\n    &gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n    &gt;&gt;&gt; get_speed(position)\n    array([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n\n    &gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n    &gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n    &gt;&gt;&gt; get_speed(position, time)\n    array([1.41421356, 2.82842712, 5.65685425, 8.48528137, 9.89949494])\n    \"\"\"\n    velocity = get_velocity(position, time=time)\n    return np.sqrt(np.sum(velocity**2, axis=1))\n</code></pre>"},{"location":"reference/neuro_py/behavior/kinematics/#neuro_py.behavior.kinematics.get_velocity","title":"<code>get_velocity(position, time=None)</code>","text":"<p>Computes the velocity from position data.</p> <p>If time is not provided, it assumes a constant time step between position samples. The velocity is calculated as the gradient of the position with respect to time along the first axis.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>An array of position data. This can be 1D (for single-dimensional positions) or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).</p> required <code>time</code> <code>Union[ndarray, None]</code> <p>An array of time values corresponding to the position data. If None, the function assumes a constant time step. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of velocity values, where each velocity is the rate of change of position with respect to time.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n&gt;&gt;&gt; get_velocity(position)\narray([1., 2., 4., 6., 7.])\n</code></pre> <pre><code>&gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n&gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n&gt;&gt;&gt; get_velocity(position, time)\narray([[1., 1.],\n    [2., 2.],\n    [4., 4.],\n    [6., 6.],\n    [7., 7.]])\n</code></pre> Source code in <code>neuro_py/behavior/kinematics.py</code> <pre><code>def get_velocity(\n    position: np.ndarray, time: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes the velocity from position data.\n\n    If time is not provided, it assumes a constant time step between position\n    samples. The velocity is calculated as the gradient of the position with\n    respect to time along the first axis.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        An array of position data. This can be 1D (for single-dimensional positions)\n        or 2D (for multi-dimensional positions, e.g., x and y coordinates over time).\n    time : Union[np.ndarray, None], optional\n        An array of time values corresponding to the position data. If None,\n        the function assumes a constant time step. Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        An array of velocity values, where each velocity is the rate of change of\n        position with respect to time.\n\n    Examples\n    --------\n    &gt;&gt;&gt; position = np.array([0, 1, 4, 9, 16])\n    &gt;&gt;&gt; get_velocity(position)\n    array([1., 2., 4., 6., 7.])\n\n    &gt;&gt;&gt; position = np.array([[0, 0], [1, 1], [4, 4], [9, 9], [16, 16]])\n    &gt;&gt;&gt; time = np.array([0, 1, 2, 3, 4])\n    &gt;&gt;&gt; get_velocity(position, time)\n    array([[1., 1.],\n        [2., 2.],\n        [4., 4.],\n        [6., 6.],\n        [7., 7.]])\n    \"\"\"\n    if time is None:\n        time = np.arange(position.shape[0])\n    return np.gradient(position, time, axis=0)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linear_positions/","title":"neuro_py.behavior.linear_positions","text":""},{"location":"reference/neuro_py/behavior/linear_positions/#neuro_py.behavior.linear_positions.find_good_lap_epochs","title":"<code>find_good_lap_epochs(pos, dir_epoch, thres=0.5, binsize=6, min_laps=10)</code>","text":"<p>Find good laps in behavior data</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>AnalogSignalArray</code> <p>A nelpy AnalogSignalArray containing the position data with a single dimension.</p> required <code>dir_epoch</code> <code>EpochArray</code> <p>EpochArray defining the laps to analyze for good laps.</p> required <code>thres</code> <code>float</code> <p>Occupancy threshold to determine good laps, by default 0.5.</p> <code>0.5</code> <code>binsize</code> <code>int</code> <p>Size of the bins for calculating occupancy, by default 6.</p> <code>6</code> <code>min_laps</code> <code>int</code> <p>Minimum number of laps required to consider laps as 'good', by default 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>An EpochArray containing the good laps based on the occupancy threshold. Returns an empty EpochArray if no good laps are found or if the number of laps is less than <code>min_laps</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; good_laps = find_good_lap_epochs(pos, dir_epoch)\n</code></pre> Notes <p>The function calculates the percent occupancy over position bins per lap, and identifies laps that meet the occupancy threshold criteria. The laps that meet this condition are returned as an EpochArray.</p> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def find_good_lap_epochs(\n    pos: nel.AnalogSignalArray,\n    dir_epoch: nel.EpochArray,\n    thres: float = 0.5,\n    binsize: int = 6,\n    min_laps: int = 10,\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Find good laps in behavior data\n\n    Parameters\n    ----------\n    pos : nelpy.AnalogSignalArray\n        A nelpy AnalogSignalArray containing the position data with a single dimension.\n    dir_epoch : nelpy.EpochArray\n        EpochArray defining the laps to analyze for good laps.\n    thres : float, optional\n        Occupancy threshold to determine good laps, by default 0.5.\n    binsize : int, optional\n        Size of the bins for calculating occupancy, by default 6.\n    min_laps : int, optional\n        Minimum number of laps required to consider laps as 'good', by default 10.\n\n    Returns\n    -------\n    nelpy.EpochArray\n        An EpochArray containing the good laps based on the occupancy threshold.\n        Returns an empty EpochArray if no good laps are found or if the number\n        of laps is less than `min_laps`.\n\n    Examples\n    -------\n    &gt;&gt;&gt; good_laps = find_good_lap_epochs(pos, dir_epoch)\n\n    Notes\n    -----\n    The function calculates the percent occupancy over position bins per lap,\n    and identifies laps that meet the occupancy threshold criteria. The laps\n    that meet this condition are returned as an EpochArray.\n    \"\"\"\n    # Ensure the input data is valid\n    if pos.isempty or dir_epoch.isempty:\n        return nel.EpochArray()\n\n    # make bin edges to calc occupancy\n    x_edges = np.arange(np.nanmin(pos.data[0]), np.nanmax(pos.data[0]), binsize)\n    # initialize occupancy matrix (position x time)\n    occ = np.zeros([len(x_edges) - 1, dir_epoch.n_intervals])\n\n    # much faster to not use nelpy objects here, so pull out needed data\n    x_coord = pos.data[0]\n    time = pos.abscissa_vals\n    epochs = dir_epoch.data\n\n    # iterate through laps\n    for i, ep in enumerate(epochs):\n        # bin position per lap\n        occ[:, i], _ = np.histogram(\n            x_coord[(time &gt;= ep[0]) &amp; (time &lt;= ep[1])], bins=x_edges\n        )\n\n    # calc percent occupancy over position bins per lap and find good laps\n    good_laps = np.where(~((np.sum(occ == 0, axis=0) / occ.shape[0]) &gt; thres))[0]\n    # if no good laps, return empty epoch\n    if (len(good_laps) == 0) | (len(good_laps) &lt; min_laps):\n        dir_epoch = nel.EpochArray()\n    else:\n        dir_epoch = dir_epoch[good_laps]\n    return dir_epoch\n</code></pre>"},{"location":"reference/neuro_py/behavior/linear_positions/#neuro_py.behavior.linear_positions.get_linear_track_lap_epochs","title":"<code>get_linear_track_lap_epochs(ts, x, newLapThreshold=15, good_laps=False, edgethresh=0.1, completeprop=0.2, posbins=50)</code>","text":"<p>Identifies lap epochs on a linear track and classifies them into outbound and inbound directions.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>ndarray</code> <p>Array of timestamps corresponding to position data.</p> required <code>x</code> <code>ndarray</code> <p>Array of position data along the linear track.</p> required <code>newLapThreshold</code> <code>float</code> <p>Minimum distance between laps to define a new lap, by default 15.</p> <code>15</code> <code>good_laps</code> <code>bool</code> <p>If True, filter out laps that do not meet certain quality criteria, by default False.</p> <code>False</code> <code>edgethresh</code> <code>float</code> <p>Threshold proportion of the track edge to identify potential boundary errors, by default 0.1.</p> <code>0.1</code> <code>completeprop</code> <code>float</code> <p>Minimum proportion of the track that must be traversed for a lap to be considered complete, by default 0.2.</p> <code>0.2</code> <code>posbins</code> <code>int</code> <p>Number of bins to divide the track into for analysis, by default 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>Tuple[EpochArray, EpochArray]</code> <p>A tuple containing two nelpy EpochArray objects: - outbound_epochs: Epochs representing outbound runs (towards the far end of the track). - inbound_epochs: Epochs representing inbound runs (back towards the start).</p> Notes <ul> <li>This function calls <code>find_laps</code> to determine the lap structure, then segregates epochs into outbound and inbound directions.</li> <li>The EpochArray objects represent the start and stop timestamps for each identified lap.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; outbound_epochs, inbound_epochs = get_linear_track_lap_epochs(ts, x)\n</code></pre> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def get_linear_track_lap_epochs(\n    ts: np.ndarray,\n    x: np.ndarray,\n    newLapThreshold: float = 15,\n    good_laps: bool = False,\n    edgethresh: float = 0.1,\n    completeprop: float = 0.2,\n    posbins: int = 50,\n) -&gt; Tuple[nel.EpochArray, nel.EpochArray]:\n    \"\"\"\n    Identifies lap epochs on a linear track and classifies them into outbound and inbound directions.\n\n    Parameters\n    ----------\n    ts : np.ndarray\n        Array of timestamps corresponding to position data.\n    x : np.ndarray\n        Array of position data along the linear track.\n    newLapThreshold : float, optional\n        Minimum distance between laps to define a new lap, by default 15.\n    good_laps : bool, optional\n        If True, filter out laps that do not meet certain quality criteria, by default False.\n    edgethresh : float, optional\n        Threshold proportion of the track edge to identify potential boundary errors, by default 0.1.\n    completeprop : float, optional\n        Minimum proportion of the track that must be traversed for a lap to be considered complete, by default 0.2.\n    posbins : int, optional\n        Number of bins to divide the track into for analysis, by default 50.\n\n    Returns\n    -------\n    Tuple[nel.EpochArray, nel.EpochArray]\n        A tuple containing two nelpy EpochArray objects:\n        - outbound_epochs: Epochs representing outbound runs (towards the far end of the track).\n        - inbound_epochs: Epochs representing inbound runs (back towards the start).\n\n    Notes\n    ------\n    - This function calls `find_laps` to determine the lap structure, then segregates epochs into outbound and inbound directions.\n    - The EpochArray objects represent the start and stop timestamps for each identified lap.\n\n    Examples\n    -------\n    &gt;&gt;&gt; outbound_epochs, inbound_epochs = get_linear_track_lap_epochs(ts, x)\n\n    \"\"\"\n    laps = __find_laps(\n        np.array(ts),\n        np.array(x),\n        newLapThreshold=newLapThreshold,\n        good_laps=good_laps,\n        edgethresh=edgethresh,\n        completeprop=completeprop,\n        posbins=posbins,\n    )\n\n    # Handle no laps\n    if len(laps) == 0:\n        return nel.EpochArray(), nel.EpochArray()\n\n    outbound_start = []\n    outbound_stop = []\n    inbound_start = []\n    inbound_stop = []\n\n    for i in range(len(laps) - 1):\n        if laps.iloc[i].direction == 1:\n            outbound_start.append(laps.iloc[i].start_ts)\n            outbound_stop.append(laps.iloc[i + 1].start_ts)\n\n        if laps.iloc[i].direction == -1:\n            inbound_start.append(laps.iloc[i].start_ts)\n            inbound_stop.append(laps.iloc[i + 1].start_ts)\n\n    outbound_epochs = nel.EpochArray([np.array([outbound_start, outbound_stop]).T])\n    inbound_epochs = nel.EpochArray([np.array([inbound_start, inbound_stop]).T])\n\n    return outbound_epochs, inbound_epochs\n</code></pre>"},{"location":"reference/neuro_py/behavior/linear_positions/#neuro_py.behavior.linear_positions.linearize_position","title":"<code>linearize_position(x, y)</code>","text":"<p>Use PCA (a dimensionality reduction technique) to find the direction of maximal variance in our position data, and use this as the new 1D linear track axis.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>x-coordinates of shape (n, 1)</p> required <code>y</code> <code>ndarray</code> <p>y-coordinates of shape (n, 1)</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>Linearized x and y coordinates, both of shape (n, 1).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; linear_x, linear_y = npy.behavior.linearize_position(x, y)\n&gt;&gt;&gt; linear_x\narray([0.        , 1.41421356, 2.82842712, 4.24264069, 5.65685425])\n&gt;&gt;&gt; linear_y\narray([3.92192151e-16, 0.00000000e+00, 9.80480378e-17, 1.96096076e-16, 2.94144113e-16])\n</code></pre> Source code in <code>neuro_py/behavior/linear_positions.py</code> <pre><code>def linearize_position(x: np.ndarray, y: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Use PCA (a dimensionality reduction technique) to find the direction of maximal variance\n    in our position data, and use this as the new 1D linear track axis.\n\n    Parameters\n    ----------\n    x : numpy.ndarray\n        x-coordinates of shape (n, 1)\n    y : numpy.ndarray\n        y-coordinates of shape (n, 1)\n\n    Returns\n    -------\n    tuple[numpy.ndarray, numpy.ndarray]\n        Linearized x and y coordinates, both of shape (n, 1).\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = np.array([1, 2, 3, 4, 5])\n    &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5])\n    &gt;&gt;&gt; linear_x, linear_y = npy.behavior.linearize_position(x, y)\n    &gt;&gt;&gt; linear_x\n    array([0.        , 1.41421356, 2.82842712, 4.24264069, 5.65685425])\n    &gt;&gt;&gt; linear_y\n    array([3.92192151e-16, 0.00000000e+00, 9.80480378e-17, 1.96096076e-16, 2.94144113e-16])\n    \"\"\"\n    # locate and remove nans (sklearn pca does not like nans)\n    badidx = (np.isnan(x)) | (np.isnan(y))\n    badidx_pos = np.where(badidx)\n    goodidx_pos = np.where(~badidx)\n    n = len(x)\n\n    x = x[~badidx]\n    y = y[~badidx]\n\n    # perform pca and return the first 2 components\n    pca = PCA(n_components=2)\n    # transform our coords\n    linear = pca.fit_transform(np.array([x, y]).T)\n\n    # add back nans\n    x = np.zeros([n])\n    x[badidx_pos] = np.nan\n    x[goodidx_pos] = linear[:, 0]\n\n    y = np.zeros([n])\n    y[badidx_pos] = np.nan\n    y[goodidx_pos] = linear[:, 1]\n\n    # pca will center data at 0,0... adjust for this here\n    x = x + np.abs(np.nanmin(x))\n    y = y + np.abs(np.nanmin(y))\n\n    return x, y\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/","title":"neuro_py.behavior.linearization","text":""},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer","title":"<code>HMMLinearizer</code>","text":"<p>Hidden Markov Model for track linearization.</p> <p>This class implements an HMM that infers the most likely position on a track given noisy 2D position measurements. The hidden states represent positions along track segments, and observations are 2D coordinates.</p> <p>The default parameters are optimized for multi-segment classification: - emission_noise=5.0: Good balance for tracking data - transition_smoothness=0.1: Allows segment transitions while maintaining smoothness - use_sparse_transitions=True: Essential for multi-segment classification - n_bins_per_segment=50: Provides good spatial resolution</p> <p>Parameters:</p> Name Type Description Default <code>track_graph</code> <code>TrackGraph</code> <p>The track graph defining the track structure</p> required <code>n_bins_per_segment</code> <code>int</code> <p>Number of position bins per track segment, by default 50</p> <code>50</code> <code>transition_smoothness</code> <code>float</code> <p>Smoothness parameter for state transitions, by default 0.1</p> <code>1.0</code> <code>emission_noise</code> <code>float</code> <p>Standard deviation of emission noise, by default 5.0</p> <code>8.0</code> <code>max_iterations</code> <code>int</code> <p>Maximum iterations for Viterbi algorithm, by default 1000</p> <code>1000</code> <p>Attributes:</p> Name Type Description <code>track_graph</code> <code>TrackGraph</code> <p>The track graph</p> <code>n_states</code> <code>int</code> <p>Total number of hidden states</p> <code>n_segments</code> <code>int</code> <p>Number of track segments</p> <code>n_bins_per_segment</code> <code>int</code> <p>Number of position bins per segment</p> <code>transition_matrix</code> <code>ndarray</code> <p>State transition probability matrix</p> <code>emission_centers</code> <code>ndarray</code> <p>Center positions for each hidden state</p> <code>emission_covariance</code> <code>ndarray</code> <p>Covariance matrix for emission model</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class HMMLinearizer:\n    \"\"\"\n    Hidden Markov Model for track linearization.\n\n    This class implements an HMM that infers the most likely position on a track\n    given noisy 2D position measurements. The hidden states represent positions\n    along track segments, and observations are 2D coordinates.\n\n    The default parameters are optimized for multi-segment classification:\n    - emission_noise=5.0: Good balance for tracking data\n    - transition_smoothness=0.1: Allows segment transitions while maintaining smoothness\n    - use_sparse_transitions=True: Essential for multi-segment classification\n    - n_bins_per_segment=50: Provides good spatial resolution\n\n    Parameters\n    ----------\n    track_graph : TrackGraph\n        The track graph defining the track structure\n    n_bins_per_segment : int, optional\n        Number of position bins per track segment, by default 50\n    transition_smoothness : float, optional\n        Smoothness parameter for state transitions, by default 0.1\n    emission_noise : float, optional\n        Standard deviation of emission noise, by default 5.0\n    max_iterations : int, optional\n        Maximum iterations for Viterbi algorithm, by default 1000\n\n    Attributes\n    ----------\n    track_graph : TrackGraph\n        The track graph\n    n_states : int\n        Total number of hidden states\n    n_segments : int\n        Number of track segments\n    n_bins_per_segment : int\n        Number of position bins per segment\n    transition_matrix : np.ndarray\n        State transition probability matrix\n    emission_centers : np.ndarray\n        Center positions for each hidden state\n    emission_covariance : np.ndarray\n        Covariance matrix for emission model\n    \"\"\"\n\n    def __init__(\n        self,\n        track_graph: \"TrackGraph\",\n        n_bins_per_segment: int = 50,\n        transition_smoothness: float = 1.0,  # Increased for better segment transitions\n        emission_noise: float = 8.0,  # Increased for better coverage of real tracking data\n        max_iterations: int = 1000,\n        # Optimization parameters\n        use_sparse_transitions: bool = True,\n        subsample_positions: bool = False,\n        subsample_factor: int = 5,\n        # Additional optimization parameters\n        use_adaptive_subsampling: bool = True,\n        # Advanced optimization parameters\n        use_batch_processing: bool = False,\n        batch_size: int = 1000,\n        # Performance optimization parameters\n        adaptive_binning: bool = True,  # Reduce bins for large track graphs\n        max_total_states: int = 500,  # Maximum total states to prevent slowdown\n        early_termination: bool = True,  # Stop Viterbi early if convergence detected\n    ):\n        self.track_graph = track_graph\n        self.n_bins_per_segment = n_bins_per_segment\n        self.transition_smoothness = transition_smoothness\n        self.emission_noise = emission_noise\n        self.max_iterations = max_iterations\n\n        # Optimization parameters\n        self.use_sparse_transitions = use_sparse_transitions\n        self.subsample_positions = subsample_positions\n        self.subsample_factor = subsample_factor\n        self.use_adaptive_subsampling = use_adaptive_subsampling\n        self.use_batch_processing = use_batch_processing\n        self.batch_size = batch_size\n\n        # Performance optimization parameters\n        self.adaptive_binning = adaptive_binning\n        self.max_total_states = max_total_states\n        self.early_termination = early_termination\n\n        # Calculate track segment properties\n        self.n_segments = len(track_graph.edges)\n\n        # Adaptive binning: reduce bins for large track graphs\n        if self.adaptive_binning and self.n_segments &gt; 5:\n            # Reduce bins per segment to keep total states manageable\n            max_bins_per_segment = max(10, self.max_total_states // self.n_segments)\n            self.n_bins_per_segment = min(self.n_bins_per_segment, max_bins_per_segment)\n            print(f\"Adaptive binning: reduced to {self.n_bins_per_segment} bins per segment for {self.n_segments} segments\")\n\n        self.segment_lengths = []\n        self.segment_positions = []\n\n        for edge in track_graph.edges:\n            if len(edge) &gt;= 2:\n                # Calculate segment length\n                segment_length = 0\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = track_graph.node_positions[node1]\n                    p2 = track_graph.node_positions[node2]\n                    segment_length += np.linalg.norm(p2 - p1)\n\n                self.segment_lengths.append(segment_length)\n\n                # Generate position bins along this segment\n                positions = []\n                for i in range(self.n_bins_per_segment):\n                    t = i / (self.n_bins_per_segment - 1)  # Parameter along segment\n                    pos = self._interpolate_along_segment(edge, t)\n                    positions.append(pos)\n\n                self.segment_positions.append(np.array(positions))\n            else:\n                # Empty segment\n                self.segment_lengths.append(0)\n                self.segment_positions.append(np.array([]))\n\n        # Total number of states\n        self.n_states = sum(len(positions) for positions in self.segment_positions)\n\n        # Build state mapping\n        self.state_to_segment = []\n        self.state_to_position = []\n        state_idx = 0\n\n        for seg_idx, positions in enumerate(self.segment_positions):\n            for pos_idx, pos in enumerate(positions):\n                self.state_to_segment.append(seg_idx)\n                self.state_to_position.append(pos)\n            state_idx += len(positions)\n\n        self.state_to_segment = np.array(self.state_to_segment)\n        self.state_to_position = np.array(self.state_to_position)\n\n        # Build transition matrix\n        self._build_transition_matrix()\n\n        # Build emission model\n        self._build_emission_model()\n\n    def _interpolate_along_segment(self, edge: List[int], t: float) -&gt; np.ndarray:\n        \"\"\"Interpolate position along a track segment.\"\"\"\n        if len(edge) &lt; 2:\n            return np.array([0, 0])\n\n        # Find which sub-segment we're in\n        total_length = 0\n        segment_lengths = []\n\n        for i in range(len(edge) - 1):\n            node1, node2 = edge[i], edge[i + 1]\n            p1 = self.track_graph.node_positions[node1]\n            p2 = self.track_graph.node_positions[node2]\n            length = np.linalg.norm(p2 - p1)\n            segment_lengths.append(length)\n            total_length += length\n\n        if total_length == 0:\n            return self.track_graph.node_positions[edge[0]]\n\n        # Find target position along the segment\n        target_distance = t * total_length\n        current_distance = 0\n\n        for i in range(len(edge) - 1):\n            node1, node2 = edge[i], edge[i + 1]\n            p1 = self.track_graph.node_positions[node1]\n            p2 = self.track_graph.node_positions[node2]\n            length = segment_lengths[i]\n\n            if current_distance + length &gt;= target_distance:\n                # Interpolate within this sub-segment\n                local_t = (target_distance - current_distance) / length\n                return p1 + local_t * (p2 - p1)\n\n            current_distance += length\n\n        # If we get here, return the last point\n        return self.track_graph.node_positions[edge[-1]]\n\n    def _build_transition_matrix(self):\n        \"\"\"Build transition matrix between states using log-probabilities for numerical stability.\"\"\"\n        if self.use_sparse_transitions and NUMBA_AVAILABLE:\n            # Use Numba-optimized sparse transition matrix building\n            # Create segments_connected matrix for Numba\n            segments_connected = np.zeros(\n                (self.n_segments, self.n_segments), dtype=bool\n            )\n            for i in range(self.n_segments):\n                for j in range(self.n_segments):\n                    segments_connected[i, j] = self._segments_connected(i, j)\n\n            self.transition_matrix = _build_sparse_transition_matrix_numba(\n                self.state_to_segment,\n                self.state_to_position,\n                self.n_states,\n                self.transition_smoothness,\n                segments_connected,\n            )\n        else:\n            # Fallback to original implementation with log-probabilities\n            self.transition_matrix = np.full(\n                (self.n_states, self.n_states), -np.inf\n            )  # Initialize with log(0) = -inf\n\n            for i in range(self.n_states):\n                seg1 = self.state_to_segment[i]\n                pos1 = self.state_to_position[i]\n\n                # Early termination for sparse transitions\n                if self.use_sparse_transitions:\n                    # Only compute transitions to nearby states\n                    nearby_states = []\n\n                    # Same segment transitions\n                    for j in range(self.n_states):\n                        if self.state_to_segment[j] == seg1:\n                            pos_diff = abs(i - j)\n                            if pos_diff &lt;= 3:  # Allow more transitions within segments\n                                nearby_states.append(j)\n\n                    # Inter-segment transitions - allow transitions to connected segments\n                    for j in range(self.n_states):\n                        seg2 = self.state_to_segment[j]\n                        if seg1 != seg2 and self._segments_connected(seg1, seg2):\n                            # Allow transitions to boundary states of connected segments\n                            # For each segment, allow transitions to first and last few states\n                            states_in_seg2 = np.where(self.state_to_segment == seg2)[0]\n                            if len(states_in_seg2) &gt; 0:\n                                # Allow transitions to first 5 and last 5 states of connected segments\n                                boundary_states = np.concatenate(\n                                    [\n                                        states_in_seg2[:5],  # First 5 states\n                                        states_in_seg2[-5:],  # Last 5 states\n                                    ]\n                                )\n                                if j in boundary_states:\n                                    nearby_states.append(j)\n\n                    # Compute transitions only for nearby states\n                    for j in nearby_states:\n                        seg2 = self.state_to_segment[j]\n                        pos2 = self.state_to_position[j]\n                        self.transition_matrix[i, j] = (\n                            self._calculate_transition_probability(\n                                seg1, pos1, seg2, pos2\n                            )\n                        )\n                else:\n                    # Full transition matrix (slower but more accurate)\n                    for j in range(self.n_states):\n                        seg2 = self.state_to_segment[j]\n                        pos2 = self.state_to_position[j]\n                        self.transition_matrix[i, j] = (\n                            self._calculate_transition_probability(\n                                seg1, pos1, seg2, pos2\n                            )\n                        )\n\n            # Normalize rows in log-space\n            for i in range(self.n_states):\n                # Find max log-probability in row for numerical stability\n                max_log_prob = np.max(self.transition_matrix[i])\n\n                # If all transitions are -inf, set uniform distribution\n                if max_log_prob == -np.inf:\n                    uniform_log_prob = np.log(1.0 / self.n_states)\n                    self.transition_matrix[i, :] = uniform_log_prob\n                else:\n                    # Subtract max and normalize\n                    sum_exp = np.sum(np.exp(self.transition_matrix[i] - max_log_prob))\n                    if sum_exp &gt; 0:\n                        log_sum = np.log(sum_exp)\n                        self.transition_matrix[i, :] = (\n                            self.transition_matrix[i, :] - max_log_prob - log_sum\n                        )\n                    else:\n                        # If sum is zero, set uniform distribution\n                        uniform_log_prob = np.log(1.0 / self.n_states)\n                        self.transition_matrix[i, :] = uniform_log_prob\n\n    def _calculate_transition_probability(\n        self, seg1: int, pos1: np.ndarray, seg2: int, pos2: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate transition log-probability between two states.\"\"\"\n        # Distance-based probability\n        distance = np.linalg.norm(pos2 - pos1)\n\n        # Same segment: high probability for nearby positions\n        if seg1 == seg2:\n            # Gaussian kernel for smooth transitions\n            log_prob = -(distance**2) / (2 * self.transition_smoothness**2)\n        else:\n            # Different segments: allow more transitions for real data\n            # Check if segments are connected\n            if self._segments_connected(seg1, seg2):\n                # Increase probability for connected segments - much higher for real data\n                log_prob = np.log(0.8) - (distance**2) / (\n                    2 * self.transition_smoothness**2\n                )\n            else:\n                # Still allow some transitions to unconnected segments\n                log_prob = np.log(0.1) - (distance**2) / (\n                    2 * self.transition_smoothness**2\n                )\n\n        return log_prob\n\n    def _segments_connected(self, seg1: int, seg2: int) -&gt; bool:\n        \"\"\"Check if two segments are connected in the track graph.\"\"\"\n        if seg1 &gt;= len(self.track_graph.edges) or seg2 &gt;= len(self.track_graph.edges):\n            return False\n\n        edge1 = self.track_graph.edges[seg1]\n        edge2 = self.track_graph.edges[seg2]\n\n        if len(edge1) == 0 or len(edge2) == 0:\n            return False\n\n        # Check if segments share any nodes\n        nodes1 = set(edge1)\n        nodes2 = set(edge2)\n        return len(nodes1.intersection(nodes2)) &gt; 0\n\n    def _auto_tune_parameters(self, positions: np.ndarray) -&gt; dict:\n        \"\"\"\n        Automatically tune HMM parameters based on data characteristics.\n        Optimized for real rat tracking data from DeepLabCut.\n\n        Parameters\n        ----------\n        positions : np.ndarray\n            Position data to analyze\n\n        Returns\n        -------\n        dict\n            Optimized parameters\n        \"\"\"\n        # Analyze data characteristics\n        data_range = np.ptp(positions, axis=0)  # Peak-to-peak range\n        data_std = np.std(positions, axis=0)  # Standard deviation\n\n        # Estimate appropriate emission noise based on data spread\n        # For DeepLabCut data, we need higher emission noise to account for tracking errors\n        avg_std = np.mean(data_std)\n        if avg_std &lt; 1.0:\n            emission_noise = 3.0  # Very precise tracking\n        elif avg_std &lt; 3.0:\n            emission_noise = 5.0  # Good tracking\n        elif avg_std &lt; 8.0:\n            emission_noise = 8.0  # Moderate tracking\n        else:\n            emission_noise = 12.0  # Noisy tracking\n\n        # Estimate transition smoothness based on track complexity\n        track_length = 0\n        for edge in self.track_graph.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = self.track_graph.node_positions[node1]\n                    p2 = self.track_graph.node_positions[node2]\n                    track_length += np.linalg.norm(p2 - p1)\n\n        # More aggressive transition smoothness for better segment transitions\n        if track_length &lt; 10:\n            transition_smoothness = 0.5\n        elif track_length &lt; 30:\n            transition_smoothness = 0.8\n        elif track_length &lt; 80:\n            transition_smoothness = 1.2\n        else:\n            transition_smoothness = 1.5\n\n        # Adjust number of bins based on track complexity and data size\n        n_positions = len(positions)\n        if len(self.track_graph.edges) &lt;= 2:\n            n_bins_per_segment = min(40, max(20, n_positions // 100))\n        elif len(self.track_graph.edges) &lt;= 4:\n            n_bins_per_segment = min(60, max(30, n_positions // 80))\n        else:\n            n_bins_per_segment = min(80, max(40, n_positions // 60))\n\n        return {\n            \"n_bins_per_segment\": n_bins_per_segment,\n            \"emission_noise\": emission_noise,\n            \"transition_smoothness\": transition_smoothness,\n            \"use_sparse_transitions\": True,\n        }\n\n    def _build_emission_model(self):\n        \"\"\"Build the emission probability model.\"\"\"\n        # Use the state positions as emission centers\n        self.emission_centers = self.state_to_position\n\n        # Create covariance matrix for emission noise\n        # Use larger noise for better coverage of real tracking data\n        # This is more similar to the original LorenFrankLab approach\n        self.emission_covariance = np.eye(2) * self.emission_noise**2\n\n        # For real tracking data, we need to ensure positions can be assigned to states\n        # even if they're not exactly on the track due to tracking noise\n\n    def _emission_probability(self, observation: np.ndarray, state: int) -&gt; float:\n        \"\"\"Calculate emission probability P(observation | state).\"\"\"\n        center = self.emission_centers[state]\n\n        # Use multivariate normal distribution\n        rv = multivariate_normal(center, self.emission_covariance)\n        return rv.pdf(observation)\n\n    def _emission_probabilities_vectorized(\n        self, observations: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Calculate emission log-probabilities for all observations and states at once.\n        Much faster than calling _emission_probability repeatedly.\n        Uses Numba JIT compilation if available.\n        Returns log-probabilities for numerical stability.\n        \"\"\"\n        if NUMBA_AVAILABLE:\n            if (\n                self.use_batch_processing and len(observations) &gt; 100\n            ):  # Use batch processing for any significant number of observations\n                return _process_batch_emissions(\n                    observations,\n                    self.emission_centers,\n                    self.emission_covariance,\n                    self.batch_size,\n                )\n            else:\n                return _emission_probabilities_numba(\n                    observations, self.emission_centers, self.emission_covariance\n                )\n        else:\n            # Fallback to original implementation with log-probabilities\n            n_observations = len(observations)\n            log_emission_probs = np.zeros((n_observations, self.n_states))\n\n            # Pre-compute constants for Gaussian calculation\n            det_cov = np.linalg.det(self.emission_covariance)\n            inv_cov = np.linalg.inv(self.emission_covariance)\n            log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det_cov)))\n\n            for t in range(n_observations):\n                obs = observations[t]\n                for i in range(self.n_states):\n                    center = self.emission_centers[i]\n                    diff = obs - center\n                    # Manual Gaussian calculation (faster than multivariate_normal)\n                    exponent = -0.5 * diff.T @ inv_cov @ diff\n                    log_emission_probs[t, i] = log_norm_const + exponent\n\n            return log_emission_probs\n\n    def linearize_with_hmm(\n        self, positions: np.ndarray\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Linearize positions using HMM inference.\n\n        Parameters\n        ----------\n        positions : np.ndarray\n            Array of 2D positions (n_positions, 2)\n\n        Returns\n        -------\n        linear_positions : np.ndarray\n            Linearized positions along the track\n        track_segment_ids : np.ndarray\n            Track segment IDs for each position\n        projected_positions : np.ndarray\n            Projected 2D positions on the track\n        \"\"\"\n        n_positions = len(positions)\n\n        # Initialize arrays\n        linear_positions = np.full(n_positions, np.nan)\n        track_segment_ids = np.full(n_positions, -1, dtype=int)\n        projected_positions = np.full((n_positions, 2), np.nan)\n\n        # Handle NaN positions\n        valid_mask = ~np.isnan(positions).any(axis=1)\n        if not np.any(valid_mask):\n            return linear_positions, track_segment_ids, projected_positions\n\n        valid_positions = positions[valid_mask]\n\n        # Check if we should use fast approximate method for very large track graphs\n        if self.n_states &gt; 1000 and len(valid_positions) &gt; 500:\n            print(f\"Using fast approximate HMM for large track graph ({self.n_states} states, {len(valid_positions)} positions)\")\n            return self._linearize_with_fast_approximate_hmm(positions, valid_mask)\n\n        # Subsample positions if requested for speed\n        if self.subsample_positions and len(valid_positions) &gt; 1000:\n            # Adaptive subsampling: use larger factor for bigger datasets\n            if self.use_adaptive_subsampling:\n                adaptive_factor = max(\n                    self.subsample_factor, len(valid_positions) // 2000\n                )\n            else:\n                adaptive_factor = self.subsample_factor\n            subsample_indices = np.arange(0, len(valid_positions), adaptive_factor)\n            subsampled_positions = valid_positions[subsample_indices]\n            original_indices = np.where(valid_mask)[0][subsample_indices]\n        else:\n            subsampled_positions = valid_positions\n            original_indices = np.where(valid_mask)[0]\n\n        # Run Viterbi algorithm to find most likely state sequence\n        state_sequence = self._viterbi(subsampled_positions)\n\n        # Convert states back to linear positions and segment IDs\n        for i, state in enumerate(state_sequence):\n            global_idx = original_indices[i]\n\n            seg_id = self.state_to_segment[state]\n            projected_pos = self.state_to_position[state]\n\n            # Calculate linear position along the track\n            linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n            linear_positions[global_idx] = linear_pos\n            track_segment_ids[global_idx] = seg_id\n            projected_positions[global_idx] = projected_pos\n\n        # Interpolate missing values if subsampling was used\n        if self.subsample_positions and len(original_indices) &lt; n_positions:\n            linear_positions, track_segment_ids, projected_positions = (\n                self._interpolate_missing_values(\n                    linear_positions,\n                    track_segment_ids,\n                    projected_positions,\n                    original_indices,\n                    valid_mask,\n                )\n            )\n\n        return linear_positions, track_segment_ids, projected_positions\n\n    def _linearize_with_fast_approximate_hmm(\n        self, positions: np.ndarray, valid_mask: np.ndarray\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Fast approximate HMM linearization for very large track graphs.\n        Uses simplified approach: project to nearest state and apply temporal smoothing.\n        \"\"\"\n        n_positions = len(positions)\n        linear_positions = np.full(n_positions, np.nan)\n        track_segment_ids = np.full(n_positions, -1, dtype=int)\n        projected_positions = np.full((n_positions, 2), np.nan)\n\n        valid_positions = positions[valid_mask]\n\n        # Step 1: Find nearest state for each position (much faster than full HMM)\n        nearest_states = np.zeros(len(valid_positions), dtype=int)\n        for i, pos in enumerate(valid_positions):\n            # Find nearest emission center\n            distances = np.linalg.norm(self.emission_centers - pos, axis=1)\n            nearest_states[i] = np.argmin(distances)\n\n        # Step 2: Apply simple temporal smoothing (optional)\n        if len(nearest_states) &gt; 1:\n            smoothed_states = self._apply_temporal_smoothing(nearest_states)\n        else:\n            smoothed_states = nearest_states\n\n        # Step 3: Convert states to positions\n        for i, state in enumerate(smoothed_states):\n            global_idx = np.where(valid_mask)[0][i]\n\n            seg_id = self.state_to_segment[state]\n            projected_pos = self.state_to_position[state]\n            linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n            linear_positions[global_idx] = linear_pos\n            track_segment_ids[global_idx] = seg_id\n            projected_positions[global_idx] = projected_pos\n\n        return linear_positions, track_segment_ids, projected_positions\n\n    def _apply_temporal_smoothing(self, states: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Apply simple temporal smoothing to state sequence.\n        Uses a moving average approach to reduce noise.\n        \"\"\"\n        smoothed = states.copy()\n        window_size = min(5, len(states) // 10)  # Adaptive window size\n\n        if window_size &lt; 2:\n            return smoothed\n\n        # Apply moving average smoothing\n        for i in range(len(states)):\n            start = max(0, i - window_size // 2)\n            end = min(len(states), i + window_size // 2 + 1)\n            window_states = states[start:end]\n\n            # Use mode (most common state) in window\n            unique, counts = np.unique(window_states, return_counts=True)\n            smoothed[i] = unique[np.argmax(counts)]\n\n        return smoothed\n\n    def _viterbi(self, observations: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Run Viterbi algorithm to find most likely state sequence.\n        Uses log-probabilities for numerical stability.\n        Vectorized implementation for better performance.\n        Uses Numba JIT compilation if available.\n\n        Parameters\n        ----------\n        observations : np.ndarray\n            Array of observations (n_observations, 2)\n\n        Returns\n        -------\n        np.ndarray\n            Most likely state sequence\n        \"\"\"\n        n_observations = len(observations)\n\n        # Pre-compute log emission probabilities for all observations and states\n        log_emission_probs = self._emission_probabilities_vectorized(observations)\n\n        if NUMBA_AVAILABLE:\n            return _viterbi_numba(\n                log_emission_probs,\n                self.transition_matrix,\n                n_observations,\n                self.n_states,\n            )\n        else:\n            # Fallback to original implementation with log-probabilities\n            # Initialize\n            log_delta = np.zeros((n_observations, self.n_states))\n            psi = np.zeros((n_observations, self.n_states), dtype=int)\n\n            # Initialize with log-emission probabilities of first observation\n            log_initial_probs = log_emission_probs[0]\n\n            # Forward pass (vectorized)\n            for t in range(n_observations):\n                if t == 0:\n                    # Initial log-probabilities\n                    log_delta[t] = log_initial_probs\n                else:\n                    # Vectorized recursion: compute all state transitions at once\n                    # log_delta[t-1] + log_transition_matrix gives us all possible log-transitions\n                    log_transition_probs = (\n                        log_delta[t - 1].reshape(-1, 1) + self.transition_matrix\n                    )\n\n                    # Find maximum log-probability and corresponding previous state for each current state\n                    max_indices = np.argmax(log_transition_probs, axis=0)\n                    max_log_probs = np.max(log_transition_probs, axis=0)\n\n                    # Update log_delta and psi\n                    log_delta[t] = max_log_probs + log_emission_probs[t]\n                    psi[t] = max_indices\n\n            # Backward pass\n            state_sequence = np.zeros(n_observations, dtype=int)\n            state_sequence[-1] = np.argmax(log_delta[-1])\n\n            for t in range(n_observations - 2, -1, -1):\n                state_sequence[t] = psi[t + 1, state_sequence[t + 1]]\n\n            return state_sequence\n\n    def _calculate_linear_position(\n        self, segment_id: int, position: np.ndarray\n    ) -&gt; float:\n        \"\"\"Calculate linear position along the track for a given segment and position.\"\"\"\n        if segment_id &gt;= len(self.track_graph.edges):\n            return 0.0\n\n        # Calculate cumulative distance to this segment\n        cumulative_distance = 0.0\n\n        for i in range(segment_id):\n            if i &lt; len(self.track_graph.cumulative_distances):\n                # Use the track graph's cumulative distances\n                edge = self.track_graph.edges[i]\n                if len(edge) &gt;= 2:\n                    node1, node2 = edge[0], edge[-1]\n                    cumulative_distance += self.track_graph.edge_distances.get(\n                        (node1, node2), 0\n                    )\n\n        # Add distance within current segment\n        if segment_id &lt; len(self.track_graph.edges):\n            edge = self.track_graph.edges[segment_id]\n            if len(edge) &gt;= 2:\n                # Find closest point on this segment\n                min_distance = np.inf\n                segment_position = 0.0\n\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    p1 = self.track_graph.node_positions[node1]\n                    p2 = self.track_graph.node_positions[node2]\n\n                    # Project position onto this line segment\n                    v = p2 - p1\n                    u = position - p1\n                    t = np.dot(u, v) / np.dot(v, v)\n                    t = np.clip(t, 0, 1)\n\n                    projected = p1 + t * v\n                    distance = np.linalg.norm(position - projected)\n\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        segment_position = t * np.linalg.norm(v)\n\n                cumulative_distance += segment_position\n\n        return cumulative_distance\n\n    def _interpolate_missing_values(\n        self,\n        linear_positions: np.ndarray,\n        track_segment_ids: np.ndarray,\n        projected_positions: np.ndarray,\n        original_indices: np.ndarray,\n        valid_mask: np.ndarray,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Interpolate missing values in subsampled linearization results.\n\n        This method fills in the NaN values between linearized points using\n        linear interpolation. For rat tracking data, this provides smooth\n        trajectories while maintaining the speed benefits of subsampling.\n\n        Parameters\n        ----------\n        linear_positions : np.ndarray\n            Array of linear positions with NaN values for missing points\n        track_segment_ids : np.ndarray\n            Array of track segment IDs with -1 for missing points\n        projected_positions : np.ndarray\n            Array of projected 2D positions with NaN values for missing points\n        original_indices : np.ndarray\n            Indices of the original positions that were linearized\n        valid_mask : np.ndarray\n            Boolean mask indicating which original positions are valid (not NaN)\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            Interpolated linear_positions, track_segment_ids, and projected_positions\n        \"\"\"\n        from scipy.interpolate import interp1d\n\n        # Get the valid linearized indices (where we have actual values)\n        valid_linearized = original_indices[\n            ~np.isnan(linear_positions[original_indices])\n        ]\n\n        if len(valid_linearized) &lt; 2:\n            # Not enough points to interpolate\n            return linear_positions, track_segment_ids, projected_positions\n\n        # Get the corresponding values\n        valid_linear = linear_positions[valid_linearized]\n        valid_segments = track_segment_ids[valid_linearized]\n        valid_projected = projected_positions[valid_linearized]\n\n        # Find all missing indices that need interpolation\n        all_valid_indices = np.where(valid_mask)[0]\n        missing_indices = all_valid_indices[\n            ~np.isin(all_valid_indices, valid_linearized)\n        ]\n\n        if len(missing_indices) == 0:\n            return linear_positions, track_segment_ids, projected_positions\n\n        # Sort by index for proper interpolation\n        sort_idx = np.argsort(valid_linearized)\n        sorted_indices = valid_linearized[sort_idx]\n        sorted_linear = valid_linear[sort_idx]\n        sorted_segments = valid_segments[sort_idx]\n        sorted_projected = valid_projected[sort_idx]\n\n        # Interpolate linear positions\n        try:\n            linear_interp = interp1d(\n                sorted_indices,\n                sorted_linear,\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n            linear_positions[missing_indices] = linear_interp(missing_indices)\n        except Exception:\n            # Fallback to nearest neighbor if interpolation fails\n            for idx in missing_indices:\n                # Find closest valid index\n                closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n                linear_positions[idx] = linear_positions[closest_idx]\n\n        # Interpolate segment IDs (use mode/nearest neighbor for categorical data)\n        for idx in missing_indices:\n            # Find the two closest valid indices\n            distances = np.abs(sorted_indices - idx)\n            closest_indices = sorted_indices[np.argsort(distances)[:2]]\n\n            if len(closest_indices) == 1:\n                track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n            else:\n                # Use the closer one, or the one with higher linear position if tied\n                if (\n                    distances[np.argsort(distances)[0]]\n                    &lt; distances[np.argsort(distances)[1]]\n                ):\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                else:\n                    # If equidistant, use the one with higher linear position\n                    if (\n                        linear_positions[closest_indices[0]]\n                        &gt; linear_positions[closest_indices[1]]\n                    ):\n                        track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                    else:\n                        track_segment_ids[idx] = track_segment_ids[closest_indices[1]]\n\n        # Interpolate projected positions\n        try:\n            # Interpolate x and y coordinates separately\n            x_interp = interp1d(\n                sorted_indices,\n                sorted_projected[:, 0],\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n            y_interp = interp1d(\n                sorted_indices,\n                sorted_projected[:, 1],\n                kind=\"linear\",\n                bounds_error=False,\n                fill_value=\"extrapolate\",\n            )\n\n            projected_positions[missing_indices, 0] = x_interp(missing_indices)\n            projected_positions[missing_indices, 1] = y_interp(missing_indices)\n        except Exception:\n            # Fallback to nearest neighbor if interpolation fails\n            for idx in missing_indices:\n                closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n                projected_positions[idx] = projected_positions[closest_idx]\n\n        return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._apply_temporal_smoothing","title":"<code>_apply_temporal_smoothing(states)</code>","text":"<p>Apply simple temporal smoothing to state sequence. Uses a moving average approach to reduce noise.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _apply_temporal_smoothing(self, states: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply simple temporal smoothing to state sequence.\n    Uses a moving average approach to reduce noise.\n    \"\"\"\n    smoothed = states.copy()\n    window_size = min(5, len(states) // 10)  # Adaptive window size\n\n    if window_size &lt; 2:\n        return smoothed\n\n    # Apply moving average smoothing\n    for i in range(len(states)):\n        start = max(0, i - window_size // 2)\n        end = min(len(states), i + window_size // 2 + 1)\n        window_states = states[start:end]\n\n        # Use mode (most common state) in window\n        unique, counts = np.unique(window_states, return_counts=True)\n        smoothed[i] = unique[np.argmax(counts)]\n\n    return smoothed\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._auto_tune_parameters","title":"<code>_auto_tune_parameters(positions)</code>","text":"<p>Automatically tune HMM parameters based on data characteristics. Optimized for real rat tracking data from DeepLabCut.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>ndarray</code> <p>Position data to analyze</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Optimized parameters</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _auto_tune_parameters(self, positions: np.ndarray) -&gt; dict:\n    \"\"\"\n    Automatically tune HMM parameters based on data characteristics.\n    Optimized for real rat tracking data from DeepLabCut.\n\n    Parameters\n    ----------\n    positions : np.ndarray\n        Position data to analyze\n\n    Returns\n    -------\n    dict\n        Optimized parameters\n    \"\"\"\n    # Analyze data characteristics\n    data_range = np.ptp(positions, axis=0)  # Peak-to-peak range\n    data_std = np.std(positions, axis=0)  # Standard deviation\n\n    # Estimate appropriate emission noise based on data spread\n    # For DeepLabCut data, we need higher emission noise to account for tracking errors\n    avg_std = np.mean(data_std)\n    if avg_std &lt; 1.0:\n        emission_noise = 3.0  # Very precise tracking\n    elif avg_std &lt; 3.0:\n        emission_noise = 5.0  # Good tracking\n    elif avg_std &lt; 8.0:\n        emission_noise = 8.0  # Moderate tracking\n    else:\n        emission_noise = 12.0  # Noisy tracking\n\n    # Estimate transition smoothness based on track complexity\n    track_length = 0\n    for edge in self.track_graph.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                p1 = self.track_graph.node_positions[node1]\n                p2 = self.track_graph.node_positions[node2]\n                track_length += np.linalg.norm(p2 - p1)\n\n    # More aggressive transition smoothness for better segment transitions\n    if track_length &lt; 10:\n        transition_smoothness = 0.5\n    elif track_length &lt; 30:\n        transition_smoothness = 0.8\n    elif track_length &lt; 80:\n        transition_smoothness = 1.2\n    else:\n        transition_smoothness = 1.5\n\n    # Adjust number of bins based on track complexity and data size\n    n_positions = len(positions)\n    if len(self.track_graph.edges) &lt;= 2:\n        n_bins_per_segment = min(40, max(20, n_positions // 100))\n    elif len(self.track_graph.edges) &lt;= 4:\n        n_bins_per_segment = min(60, max(30, n_positions // 80))\n    else:\n        n_bins_per_segment = min(80, max(40, n_positions // 60))\n\n    return {\n        \"n_bins_per_segment\": n_bins_per_segment,\n        \"emission_noise\": emission_noise,\n        \"transition_smoothness\": transition_smoothness,\n        \"use_sparse_transitions\": True,\n    }\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._build_emission_model","title":"<code>_build_emission_model()</code>","text":"<p>Build the emission probability model.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _build_emission_model(self):\n    \"\"\"Build the emission probability model.\"\"\"\n    # Use the state positions as emission centers\n    self.emission_centers = self.state_to_position\n\n    # Create covariance matrix for emission noise\n    # Use larger noise for better coverage of real tracking data\n    # This is more similar to the original LorenFrankLab approach\n    self.emission_covariance = np.eye(2) * self.emission_noise**2\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._build_transition_matrix","title":"<code>_build_transition_matrix()</code>","text":"<p>Build transition matrix between states using log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _build_transition_matrix(self):\n    \"\"\"Build transition matrix between states using log-probabilities for numerical stability.\"\"\"\n    if self.use_sparse_transitions and NUMBA_AVAILABLE:\n        # Use Numba-optimized sparse transition matrix building\n        # Create segments_connected matrix for Numba\n        segments_connected = np.zeros(\n            (self.n_segments, self.n_segments), dtype=bool\n        )\n        for i in range(self.n_segments):\n            for j in range(self.n_segments):\n                segments_connected[i, j] = self._segments_connected(i, j)\n\n        self.transition_matrix = _build_sparse_transition_matrix_numba(\n            self.state_to_segment,\n            self.state_to_position,\n            self.n_states,\n            self.transition_smoothness,\n            segments_connected,\n        )\n    else:\n        # Fallback to original implementation with log-probabilities\n        self.transition_matrix = np.full(\n            (self.n_states, self.n_states), -np.inf\n        )  # Initialize with log(0) = -inf\n\n        for i in range(self.n_states):\n            seg1 = self.state_to_segment[i]\n            pos1 = self.state_to_position[i]\n\n            # Early termination for sparse transitions\n            if self.use_sparse_transitions:\n                # Only compute transitions to nearby states\n                nearby_states = []\n\n                # Same segment transitions\n                for j in range(self.n_states):\n                    if self.state_to_segment[j] == seg1:\n                        pos_diff = abs(i - j)\n                        if pos_diff &lt;= 3:  # Allow more transitions within segments\n                            nearby_states.append(j)\n\n                # Inter-segment transitions - allow transitions to connected segments\n                for j in range(self.n_states):\n                    seg2 = self.state_to_segment[j]\n                    if seg1 != seg2 and self._segments_connected(seg1, seg2):\n                        # Allow transitions to boundary states of connected segments\n                        # For each segment, allow transitions to first and last few states\n                        states_in_seg2 = np.where(self.state_to_segment == seg2)[0]\n                        if len(states_in_seg2) &gt; 0:\n                            # Allow transitions to first 5 and last 5 states of connected segments\n                            boundary_states = np.concatenate(\n                                [\n                                    states_in_seg2[:5],  # First 5 states\n                                    states_in_seg2[-5:],  # Last 5 states\n                                ]\n                            )\n                            if j in boundary_states:\n                                nearby_states.append(j)\n\n                # Compute transitions only for nearby states\n                for j in nearby_states:\n                    seg2 = self.state_to_segment[j]\n                    pos2 = self.state_to_position[j]\n                    self.transition_matrix[i, j] = (\n                        self._calculate_transition_probability(\n                            seg1, pos1, seg2, pos2\n                        )\n                    )\n            else:\n                # Full transition matrix (slower but more accurate)\n                for j in range(self.n_states):\n                    seg2 = self.state_to_segment[j]\n                    pos2 = self.state_to_position[j]\n                    self.transition_matrix[i, j] = (\n                        self._calculate_transition_probability(\n                            seg1, pos1, seg2, pos2\n                        )\n                    )\n\n        # Normalize rows in log-space\n        for i in range(self.n_states):\n            # Find max log-probability in row for numerical stability\n            max_log_prob = np.max(self.transition_matrix[i])\n\n            # If all transitions are -inf, set uniform distribution\n            if max_log_prob == -np.inf:\n                uniform_log_prob = np.log(1.0 / self.n_states)\n                self.transition_matrix[i, :] = uniform_log_prob\n            else:\n                # Subtract max and normalize\n                sum_exp = np.sum(np.exp(self.transition_matrix[i] - max_log_prob))\n                if sum_exp &gt; 0:\n                    log_sum = np.log(sum_exp)\n                    self.transition_matrix[i, :] = (\n                        self.transition_matrix[i, :] - max_log_prob - log_sum\n                    )\n                else:\n                    # If sum is zero, set uniform distribution\n                    uniform_log_prob = np.log(1.0 / self.n_states)\n                    self.transition_matrix[i, :] = uniform_log_prob\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._calculate_linear_position","title":"<code>_calculate_linear_position(segment_id, position)</code>","text":"<p>Calculate linear position along the track for a given segment and position.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_linear_position(\n    self, segment_id: int, position: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate linear position along the track for a given segment and position.\"\"\"\n    if segment_id &gt;= len(self.track_graph.edges):\n        return 0.0\n\n    # Calculate cumulative distance to this segment\n    cumulative_distance = 0.0\n\n    for i in range(segment_id):\n        if i &lt; len(self.track_graph.cumulative_distances):\n            # Use the track graph's cumulative distances\n            edge = self.track_graph.edges[i]\n            if len(edge) &gt;= 2:\n                node1, node2 = edge[0], edge[-1]\n                cumulative_distance += self.track_graph.edge_distances.get(\n                    (node1, node2), 0\n                )\n\n    # Add distance within current segment\n    if segment_id &lt; len(self.track_graph.edges):\n        edge = self.track_graph.edges[segment_id]\n        if len(edge) &gt;= 2:\n            # Find closest point on this segment\n            min_distance = np.inf\n            segment_position = 0.0\n\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                p1 = self.track_graph.node_positions[node1]\n                p2 = self.track_graph.node_positions[node2]\n\n                # Project position onto this line segment\n                v = p2 - p1\n                u = position - p1\n                t = np.dot(u, v) / np.dot(v, v)\n                t = np.clip(t, 0, 1)\n\n                projected = p1 + t * v\n                distance = np.linalg.norm(position - projected)\n\n                if distance &lt; min_distance:\n                    min_distance = distance\n                    segment_position = t * np.linalg.norm(v)\n\n            cumulative_distance += segment_position\n\n    return cumulative_distance\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._calculate_transition_probability","title":"<code>_calculate_transition_probability(seg1, pos1, seg2, pos2)</code>","text":"<p>Calculate transition log-probability between two states.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_transition_probability(\n    self, seg1: int, pos1: np.ndarray, seg2: int, pos2: np.ndarray\n) -&gt; float:\n    \"\"\"Calculate transition log-probability between two states.\"\"\"\n    # Distance-based probability\n    distance = np.linalg.norm(pos2 - pos1)\n\n    # Same segment: high probability for nearby positions\n    if seg1 == seg2:\n        # Gaussian kernel for smooth transitions\n        log_prob = -(distance**2) / (2 * self.transition_smoothness**2)\n    else:\n        # Different segments: allow more transitions for real data\n        # Check if segments are connected\n        if self._segments_connected(seg1, seg2):\n            # Increase probability for connected segments - much higher for real data\n            log_prob = np.log(0.8) - (distance**2) / (\n                2 * self.transition_smoothness**2\n            )\n        else:\n            # Still allow some transitions to unconnected segments\n            log_prob = np.log(0.1) - (distance**2) / (\n                2 * self.transition_smoothness**2\n            )\n\n    return log_prob\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._emission_probabilities_vectorized","title":"<code>_emission_probabilities_vectorized(observations)</code>","text":"<p>Calculate emission log-probabilities for all observations and states at once. Much faster than calling _emission_probability repeatedly. Uses Numba JIT compilation if available. Returns log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _emission_probabilities_vectorized(\n    self, observations: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculate emission log-probabilities for all observations and states at once.\n    Much faster than calling _emission_probability repeatedly.\n    Uses Numba JIT compilation if available.\n    Returns log-probabilities for numerical stability.\n    \"\"\"\n    if NUMBA_AVAILABLE:\n        if (\n            self.use_batch_processing and len(observations) &gt; 100\n        ):  # Use batch processing for any significant number of observations\n            return _process_batch_emissions(\n                observations,\n                self.emission_centers,\n                self.emission_covariance,\n                self.batch_size,\n            )\n        else:\n            return _emission_probabilities_numba(\n                observations, self.emission_centers, self.emission_covariance\n            )\n    else:\n        # Fallback to original implementation with log-probabilities\n        n_observations = len(observations)\n        log_emission_probs = np.zeros((n_observations, self.n_states))\n\n        # Pre-compute constants for Gaussian calculation\n        det_cov = np.linalg.det(self.emission_covariance)\n        inv_cov = np.linalg.inv(self.emission_covariance)\n        log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det_cov)))\n\n        for t in range(n_observations):\n            obs = observations[t]\n            for i in range(self.n_states):\n                center = self.emission_centers[i]\n                diff = obs - center\n                # Manual Gaussian calculation (faster than multivariate_normal)\n                exponent = -0.5 * diff.T @ inv_cov @ diff\n                log_emission_probs[t, i] = log_norm_const + exponent\n\n        return log_emission_probs\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._emission_probability","title":"<code>_emission_probability(observation, state)</code>","text":"<p>Calculate emission probability P(observation | state).</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _emission_probability(self, observation: np.ndarray, state: int) -&gt; float:\n    \"\"\"Calculate emission probability P(observation | state).\"\"\"\n    center = self.emission_centers[state]\n\n    # Use multivariate normal distribution\n    rv = multivariate_normal(center, self.emission_covariance)\n    return rv.pdf(observation)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._interpolate_along_segment","title":"<code>_interpolate_along_segment(edge, t)</code>","text":"<p>Interpolate position along a track segment.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _interpolate_along_segment(self, edge: List[int], t: float) -&gt; np.ndarray:\n    \"\"\"Interpolate position along a track segment.\"\"\"\n    if len(edge) &lt; 2:\n        return np.array([0, 0])\n\n    # Find which sub-segment we're in\n    total_length = 0\n    segment_lengths = []\n\n    for i in range(len(edge) - 1):\n        node1, node2 = edge[i], edge[i + 1]\n        p1 = self.track_graph.node_positions[node1]\n        p2 = self.track_graph.node_positions[node2]\n        length = np.linalg.norm(p2 - p1)\n        segment_lengths.append(length)\n        total_length += length\n\n    if total_length == 0:\n        return self.track_graph.node_positions[edge[0]]\n\n    # Find target position along the segment\n    target_distance = t * total_length\n    current_distance = 0\n\n    for i in range(len(edge) - 1):\n        node1, node2 = edge[i], edge[i + 1]\n        p1 = self.track_graph.node_positions[node1]\n        p2 = self.track_graph.node_positions[node2]\n        length = segment_lengths[i]\n\n        if current_distance + length &gt;= target_distance:\n            # Interpolate within this sub-segment\n            local_t = (target_distance - current_distance) / length\n            return p1 + local_t * (p2 - p1)\n\n        current_distance += length\n\n    # If we get here, return the last point\n    return self.track_graph.node_positions[edge[-1]]\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._interpolate_missing_values","title":"<code>_interpolate_missing_values(linear_positions, track_segment_ids, projected_positions, original_indices, valid_mask)</code>","text":"<p>Interpolate missing values in subsampled linearization results.</p> <p>This method fills in the NaN values between linearized points using linear interpolation. For rat tracking data, this provides smooth trajectories while maintaining the speed benefits of subsampling.</p> <p>Parameters:</p> Name Type Description Default <code>linear_positions</code> <code>ndarray</code> <p>Array of linear positions with NaN values for missing points</p> required <code>track_segment_ids</code> <code>ndarray</code> <p>Array of track segment IDs with -1 for missing points</p> required <code>projected_positions</code> <code>ndarray</code> <p>Array of projected 2D positions with NaN values for missing points</p> required <code>original_indices</code> <code>ndarray</code> <p>Indices of the original positions that were linearized</p> required <code>valid_mask</code> <code>ndarray</code> <p>Boolean mask indicating which original positions are valid (not NaN)</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Interpolated linear_positions, track_segment_ids, and projected_positions</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _interpolate_missing_values(\n    self,\n    linear_positions: np.ndarray,\n    track_segment_ids: np.ndarray,\n    projected_positions: np.ndarray,\n    original_indices: np.ndarray,\n    valid_mask: np.ndarray,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Interpolate missing values in subsampled linearization results.\n\n    This method fills in the NaN values between linearized points using\n    linear interpolation. For rat tracking data, this provides smooth\n    trajectories while maintaining the speed benefits of subsampling.\n\n    Parameters\n    ----------\n    linear_positions : np.ndarray\n        Array of linear positions with NaN values for missing points\n    track_segment_ids : np.ndarray\n        Array of track segment IDs with -1 for missing points\n    projected_positions : np.ndarray\n        Array of projected 2D positions with NaN values for missing points\n    original_indices : np.ndarray\n        Indices of the original positions that were linearized\n    valid_mask : np.ndarray\n        Boolean mask indicating which original positions are valid (not NaN)\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Interpolated linear_positions, track_segment_ids, and projected_positions\n    \"\"\"\n    from scipy.interpolate import interp1d\n\n    # Get the valid linearized indices (where we have actual values)\n    valid_linearized = original_indices[\n        ~np.isnan(linear_positions[original_indices])\n    ]\n\n    if len(valid_linearized) &lt; 2:\n        # Not enough points to interpolate\n        return linear_positions, track_segment_ids, projected_positions\n\n    # Get the corresponding values\n    valid_linear = linear_positions[valid_linearized]\n    valid_segments = track_segment_ids[valid_linearized]\n    valid_projected = projected_positions[valid_linearized]\n\n    # Find all missing indices that need interpolation\n    all_valid_indices = np.where(valid_mask)[0]\n    missing_indices = all_valid_indices[\n        ~np.isin(all_valid_indices, valid_linearized)\n    ]\n\n    if len(missing_indices) == 0:\n        return linear_positions, track_segment_ids, projected_positions\n\n    # Sort by index for proper interpolation\n    sort_idx = np.argsort(valid_linearized)\n    sorted_indices = valid_linearized[sort_idx]\n    sorted_linear = valid_linear[sort_idx]\n    sorted_segments = valid_segments[sort_idx]\n    sorted_projected = valid_projected[sort_idx]\n\n    # Interpolate linear positions\n    try:\n        linear_interp = interp1d(\n            sorted_indices,\n            sorted_linear,\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n        linear_positions[missing_indices] = linear_interp(missing_indices)\n    except Exception:\n        # Fallback to nearest neighbor if interpolation fails\n        for idx in missing_indices:\n            # Find closest valid index\n            closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n            linear_positions[idx] = linear_positions[closest_idx]\n\n    # Interpolate segment IDs (use mode/nearest neighbor for categorical data)\n    for idx in missing_indices:\n        # Find the two closest valid indices\n        distances = np.abs(sorted_indices - idx)\n        closest_indices = sorted_indices[np.argsort(distances)[:2]]\n\n        if len(closest_indices) == 1:\n            track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n        else:\n            # Use the closer one, or the one with higher linear position if tied\n            if (\n                distances[np.argsort(distances)[0]]\n                &lt; distances[np.argsort(distances)[1]]\n            ):\n                track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n            else:\n                # If equidistant, use the one with higher linear position\n                if (\n                    linear_positions[closest_indices[0]]\n                    &gt; linear_positions[closest_indices[1]]\n                ):\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[0]]\n                else:\n                    track_segment_ids[idx] = track_segment_ids[closest_indices[1]]\n\n    # Interpolate projected positions\n    try:\n        # Interpolate x and y coordinates separately\n        x_interp = interp1d(\n            sorted_indices,\n            sorted_projected[:, 0],\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n        y_interp = interp1d(\n            sorted_indices,\n            sorted_projected[:, 1],\n            kind=\"linear\",\n            bounds_error=False,\n            fill_value=\"extrapolate\",\n        )\n\n        projected_positions[missing_indices, 0] = x_interp(missing_indices)\n        projected_positions[missing_indices, 1] = y_interp(missing_indices)\n    except Exception:\n        # Fallback to nearest neighbor if interpolation fails\n        for idx in missing_indices:\n            closest_idx = sorted_indices[np.argmin(np.abs(sorted_indices - idx))]\n            projected_positions[idx] = projected_positions[closest_idx]\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._linearize_with_fast_approximate_hmm","title":"<code>_linearize_with_fast_approximate_hmm(positions, valid_mask)</code>","text":"<p>Fast approximate HMM linearization for very large track graphs. Uses simplified approach: project to nearest state and apply temporal smoothing.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _linearize_with_fast_approximate_hmm(\n    self, positions: np.ndarray, valid_mask: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Fast approximate HMM linearization for very large track graphs.\n    Uses simplified approach: project to nearest state and apply temporal smoothing.\n    \"\"\"\n    n_positions = len(positions)\n    linear_positions = np.full(n_positions, np.nan)\n    track_segment_ids = np.full(n_positions, -1, dtype=int)\n    projected_positions = np.full((n_positions, 2), np.nan)\n\n    valid_positions = positions[valid_mask]\n\n    # Step 1: Find nearest state for each position (much faster than full HMM)\n    nearest_states = np.zeros(len(valid_positions), dtype=int)\n    for i, pos in enumerate(valid_positions):\n        # Find nearest emission center\n        distances = np.linalg.norm(self.emission_centers - pos, axis=1)\n        nearest_states[i] = np.argmin(distances)\n\n    # Step 2: Apply simple temporal smoothing (optional)\n    if len(nearest_states) &gt; 1:\n        smoothed_states = self._apply_temporal_smoothing(nearest_states)\n    else:\n        smoothed_states = nearest_states\n\n    # Step 3: Convert states to positions\n    for i, state in enumerate(smoothed_states):\n        global_idx = np.where(valid_mask)[0][i]\n\n        seg_id = self.state_to_segment[state]\n        projected_pos = self.state_to_position[state]\n        linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n        linear_positions[global_idx] = linear_pos\n        track_segment_ids[global_idx] = seg_id\n        projected_positions[global_idx] = projected_pos\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._segments_connected","title":"<code>_segments_connected(seg1, seg2)</code>","text":"<p>Check if two segments are connected in the track graph.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _segments_connected(self, seg1: int, seg2: int) -&gt; bool:\n    \"\"\"Check if two segments are connected in the track graph.\"\"\"\n    if seg1 &gt;= len(self.track_graph.edges) or seg2 &gt;= len(self.track_graph.edges):\n        return False\n\n    edge1 = self.track_graph.edges[seg1]\n    edge2 = self.track_graph.edges[seg2]\n\n    if len(edge1) == 0 or len(edge2) == 0:\n        return False\n\n    # Check if segments share any nodes\n    nodes1 = set(edge1)\n    nodes2 = set(edge2)\n    return len(nodes1.intersection(nodes2)) &gt; 0\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer._viterbi","title":"<code>_viterbi(observations)</code>","text":"<p>Run Viterbi algorithm to find most likely state sequence. Uses log-probabilities for numerical stability. Vectorized implementation for better performance. Uses Numba JIT compilation if available.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ndarray</code> <p>Array of observations (n_observations, 2)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Most likely state sequence</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _viterbi(self, observations: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Run Viterbi algorithm to find most likely state sequence.\n    Uses log-probabilities for numerical stability.\n    Vectorized implementation for better performance.\n    Uses Numba JIT compilation if available.\n\n    Parameters\n    ----------\n    observations : np.ndarray\n        Array of observations (n_observations, 2)\n\n    Returns\n    -------\n    np.ndarray\n        Most likely state sequence\n    \"\"\"\n    n_observations = len(observations)\n\n    # Pre-compute log emission probabilities for all observations and states\n    log_emission_probs = self._emission_probabilities_vectorized(observations)\n\n    if NUMBA_AVAILABLE:\n        return _viterbi_numba(\n            log_emission_probs,\n            self.transition_matrix,\n            n_observations,\n            self.n_states,\n        )\n    else:\n        # Fallback to original implementation with log-probabilities\n        # Initialize\n        log_delta = np.zeros((n_observations, self.n_states))\n        psi = np.zeros((n_observations, self.n_states), dtype=int)\n\n        # Initialize with log-emission probabilities of first observation\n        log_initial_probs = log_emission_probs[0]\n\n        # Forward pass (vectorized)\n        for t in range(n_observations):\n            if t == 0:\n                # Initial log-probabilities\n                log_delta[t] = log_initial_probs\n            else:\n                # Vectorized recursion: compute all state transitions at once\n                # log_delta[t-1] + log_transition_matrix gives us all possible log-transitions\n                log_transition_probs = (\n                    log_delta[t - 1].reshape(-1, 1) + self.transition_matrix\n                )\n\n                # Find maximum log-probability and corresponding previous state for each current state\n                max_indices = np.argmax(log_transition_probs, axis=0)\n                max_log_probs = np.max(log_transition_probs, axis=0)\n\n                # Update log_delta and psi\n                log_delta[t] = max_log_probs + log_emission_probs[t]\n                psi[t] = max_indices\n\n        # Backward pass\n        state_sequence = np.zeros(n_observations, dtype=int)\n        state_sequence[-1] = np.argmax(log_delta[-1])\n\n        for t in range(n_observations - 2, -1, -1):\n            state_sequence[t] = psi[t + 1, state_sequence[t + 1]]\n\n        return state_sequence\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.HMMLinearizer.linearize_with_hmm","title":"<code>linearize_with_hmm(positions)</code>","text":"<p>Linearize positions using HMM inference.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <p>Returns:</p> Name Type Description <code>linear_positions</code> <code>ndarray</code> <p>Linearized positions along the track</p> <code>track_segment_ids</code> <code>ndarray</code> <p>Track segment IDs for each position</p> <code>projected_positions</code> <code>ndarray</code> <p>Projected 2D positions on the track</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def linearize_with_hmm(\n    self, positions: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Linearize positions using HMM inference.\n\n    Parameters\n    ----------\n    positions : np.ndarray\n        Array of 2D positions (n_positions, 2)\n\n    Returns\n    -------\n    linear_positions : np.ndarray\n        Linearized positions along the track\n    track_segment_ids : np.ndarray\n        Track segment IDs for each position\n    projected_positions : np.ndarray\n        Projected 2D positions on the track\n    \"\"\"\n    n_positions = len(positions)\n\n    # Initialize arrays\n    linear_positions = np.full(n_positions, np.nan)\n    track_segment_ids = np.full(n_positions, -1, dtype=int)\n    projected_positions = np.full((n_positions, 2), np.nan)\n\n    # Handle NaN positions\n    valid_mask = ~np.isnan(positions).any(axis=1)\n    if not np.any(valid_mask):\n        return linear_positions, track_segment_ids, projected_positions\n\n    valid_positions = positions[valid_mask]\n\n    # Check if we should use fast approximate method for very large track graphs\n    if self.n_states &gt; 1000 and len(valid_positions) &gt; 500:\n        print(f\"Using fast approximate HMM for large track graph ({self.n_states} states, {len(valid_positions)} positions)\")\n        return self._linearize_with_fast_approximate_hmm(positions, valid_mask)\n\n    # Subsample positions if requested for speed\n    if self.subsample_positions and len(valid_positions) &gt; 1000:\n        # Adaptive subsampling: use larger factor for bigger datasets\n        if self.use_adaptive_subsampling:\n            adaptive_factor = max(\n                self.subsample_factor, len(valid_positions) // 2000\n            )\n        else:\n            adaptive_factor = self.subsample_factor\n        subsample_indices = np.arange(0, len(valid_positions), adaptive_factor)\n        subsampled_positions = valid_positions[subsample_indices]\n        original_indices = np.where(valid_mask)[0][subsample_indices]\n    else:\n        subsampled_positions = valid_positions\n        original_indices = np.where(valid_mask)[0]\n\n    # Run Viterbi algorithm to find most likely state sequence\n    state_sequence = self._viterbi(subsampled_positions)\n\n    # Convert states back to linear positions and segment IDs\n    for i, state in enumerate(state_sequence):\n        global_idx = original_indices[i]\n\n        seg_id = self.state_to_segment[state]\n        projected_pos = self.state_to_position[state]\n\n        # Calculate linear position along the track\n        linear_pos = self._calculate_linear_position(seg_id, projected_pos)\n\n        linear_positions[global_idx] = linear_pos\n        track_segment_ids[global_idx] = seg_id\n        projected_positions[global_idx] = projected_pos\n\n    # Interpolate missing values if subsampling was used\n    if self.subsample_positions and len(original_indices) &lt; n_positions:\n        linear_positions, track_segment_ids, projected_positions = (\n            self._interpolate_missing_values(\n                linear_positions,\n                track_segment_ids,\n                projected_positions,\n                original_indices,\n                valid_mask,\n            )\n        )\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker","title":"<code>NodePicker</code>","text":"<p>Interactive creation of track graph by looking at video frames.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on, by default None.</p> <code>None</code> <code>basepath</code> <code>str</code> <p>The base path for saving data, by default None.</p> <code>None</code> <code>node_color</code> <code>str</code> <p>The color of the nodes, by default \"#177ee6\".</p> <code>'#177ee6'</code> <code>node_size</code> <code>int</code> <p>The size of the nodes, by default 100.</p> <code>100</code> <code>epoch</code> <code>int</code> <p>The epoch number, by default None.</p> <code>None</code> <code>interval</code> <code>Tuple[float, float]</code> <p>Time interval to process, by default None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on.</p> <code>canvas</code> <code>FigureCanvas</code> <p>The matplotlib figure canvas.</p> <code>cid</code> <code>int</code> <p>The connection id for the event handler.</p> <code>_nodes</code> <code>list</code> <p>The list of node positions.</p> <code>node_color</code> <code>str</code> <p>The color of the nodes.</p> <code>_nodes_plot</code> <code>scatter</code> <p>The scatter plot of the nodes.</p> <code>edges</code> <code>list</code> <p>The list of edges.</p> <code>basepath</code> <code>str</code> <p>The base path for saving data.</p> <code>epoch</code> <code>int</code> <p>The epoch number.</p> <code>use_HMM</code> <code>bool</code> <p>Whether to use the hidden markov model.</p> <p>Methods:</p> Name Description <code>node_positions</code> <p>Get the positions of the nodes.</p> <code>connect</code> <p>Connect the event handlers.</p> <code>disconnect</code> <p>Disconnect the event handlers.</p> <code>process_key</code> <p>Process key press events.</p> <code>click_event</code> <p>Process mouse click events.</p> <code>redraw</code> <p>Redraw the nodes and edges.</p> <code>remove_point</code> <p>Remove a point from the nodes.</p> <code>clear</code> <p>Clear all nodes and edges.</p> <code>format_and_save</code> <p>Format the data and save it to disk.</p> <code>save_nodes_edges</code> <p>Save the nodes and edges to a pickle file.</p> <code>save_nodes_edges_to_behavior</code> <p>Store nodes and edges into behavior file.</p> <p>Examples:</p>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker--in-command-line","title":"in command line","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker--for-a-specific-epoch","title":"for a specific epoch","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session 1\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker--for-a-specific-interval","title":"for a specific interval","text":"<pre><code>&gt;&gt;&gt; python linearization.py path/to/session 0 100\n</code></pre> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class NodePicker:\n    \"\"\"\n    Interactive creation of track graph by looking at video frames.\n\n    Parameters\n    ----------\n    ax : plt.Axes, optional\n        The matplotlib axes to draw on, by default None.\n    basepath : str, optional\n        The base path for saving data, by default None.\n    node_color : str, optional\n        The color of the nodes, by default \"#177ee6\".\n    node_size : int, optional\n        The size of the nodes, by default 100.\n    epoch : int, optional\n        The epoch number, by default None.\n    interval : Tuple[float, float], optional\n        Time interval to process, by default None.\n\n    Attributes\n    ----------\n    ax : plt.Axes\n        The matplotlib axes to draw on.\n    canvas : plt.FigureCanvas\n        The matplotlib figure canvas.\n    cid : int\n        The connection id for the event handler.\n    _nodes : list\n        The list of node positions.\n    node_color : str\n        The color of the nodes.\n    _nodes_plot : plt.scatter\n        The scatter plot of the nodes.\n    edges : list\n        The list of edges.\n    basepath : str\n        The base path for saving data.\n    epoch : int\n        The epoch number.\n    use_HMM : bool\n        Whether to use the hidden markov model.\n\n    Methods\n    -------\n    node_positions\n        Get the positions of the nodes.\n    connect\n        Connect the event handlers.\n    disconnect\n        Disconnect the event handlers.\n    process_key\n        Process key press events.\n    click_event\n        Process mouse click events.\n    redraw\n        Redraw the nodes and edges.\n    remove_point\n        Remove a point from the nodes.\n    clear\n        Clear all nodes and edges.\n    format_and_save\n        Format the data and save it to disk.\n    save_nodes_edges\n        Save the nodes and edges to a pickle file.\n    save_nodes_edges_to_behavior\n        Store nodes and edges into behavior file.\n\n    Examples\n    --------\n    # in command line\n    &gt;&gt;&gt; python linearization.py path/to/session\n\n    # for a specific epoch\n    &gt;&gt;&gt; python linearization.py path/to/session 1\n\n    # for a specific interval\n    &gt;&gt;&gt; python linearization.py path/to/session 0 100\n    \"\"\"\n\n    def __init__(\n        self,\n        ax: Optional[plt.Axes] = None,\n        basepath: Optional[str] = None,\n        node_color: str = \"#177ee6\",\n        node_size: int = 100,\n        epoch: Optional[int] = None,\n        interval: Optional[Tuple[float, float]] = None,\n    ):\n        \"\"\"\n        Initialize the NodePicker.\n\n        Parameters\n        ----------\n        ax : plt.Axes, optional\n            The matplotlib axes to draw on, by default None.\n        basepath : str, optional\n            The base path for saving data, by default None.\n        node_color : str, optional\n            The color of the nodes, by default \"#177ee6\".\n        node_size : int, optional\n            The size of the nodes, by default 100.\n        epoch : int, optional\n            The epoch number, by default None.\n        interval : Tuple[float, float], optional\n            Time interval to process, by default None.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n        self.ax = ax\n        self.canvas = ax.get_figure().canvas\n        self.cid = None\n        self._nodes = []\n        self.node_color = node_color\n        self._nodes_plot = ax.scatter([], [], zorder=5, s=node_size, color=node_color)\n        self.edges = [[]]\n        self.basepath = basepath\n        self.epoch = epoch\n        self.interval = interval\n        self.use_HMM = True\n\n        if self.epoch is not None:\n            self.epoch = int(self.epoch)\n\n        ax.set_title(\n            \"Left click to place node.\\nRight click to remove node.\"\n            \"\\nShift+Left click to clear nodes.\\nCntrl+Left click two nodes to place an edge\"\n            \"\\nEnter to save and exit.\",\n            fontsize=8,\n        )\n\n        self.canvas.draw()\n        self.connect()\n\n    @property\n    def node_positions(self) -&gt; np.ndarray:\n        \"\"\"\n        Get the positions of the nodes.\n\n        Returns\n        -------\n        np.ndarray\n            An array of node positions.\n        \"\"\"\n        return np.asarray(self._nodes)\n\n    def connect(self) -&gt; None:\n        \"\"\"Connect the event handlers.\"\"\"\n        print(\"Connecting to events\")\n        if self.cid is None:\n            self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n            self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n            print(\"Mouse click event connected!\")\n\n    def disconnect(self) -&gt; None:\n        \"\"\"Disconnect the event handlers.\"\"\"\n        if self.cid is not None:\n            self.canvas.mpl_disconnect(self.cid)\n            self.cid = None\n\n    def process_key(self, event: Any) -&gt; None:\n        \"\"\"\n        Process key press events.\n\n        Parameters\n        ----------\n        event : Any\n            The key press event.\n        \"\"\"\n        if event.key == \"enter\":\n            self.format_and_save()\n\n    def click_event(self, event: Any) -&gt; None:\n        \"\"\"\n        Process mouse click events.\n\n        Parameters\n        ----------\n        event : Any\n            The mouse click event.\n        \"\"\"\n        print(\n            f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n        )\n        if not event.inaxes:\n            return\n\n        if event.key is None:  # Regular mouse clicks\n            if event.button == 1:  # Left click\n                self._nodes.append((event.xdata, event.ydata))\n            elif event.button == 3:  # Right click\n                self.remove_point((event.xdata, event.ydata))\n\n        elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n            self.clear()\n\n        elif (\n            event.key == \"control\" and event.button == 1\n        ):  # Ctrl + Left click (Edge creation)\n            if len(self._nodes) == 0:\n                return\n            point = (event.xdata, event.ydata)\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            if len(self.edges[-1]) &lt; 2:\n                self.edges[-1].append(closest_node_ind)\n            else:\n                self.edges.append([closest_node_ind])\n\n        elif event.key == \"enter\":  # Pressing Enter\n            self.format_and_save()\n\n        self.redraw()\n\n    def redraw(self) -&gt; None:\n        \"\"\"Redraw the nodes and edges.\"\"\"\n        # Draw Node Circles\n        if len(self.node_positions) &gt; 0:\n            self._nodes_plot.set_offsets(self.node_positions)\n        else:\n            self._nodes_plot.set_offsets([])\n\n        # Draw Node Numbers\n        for ind, (x, y) in enumerate(self.node_positions):\n            self.ax.text(\n                x,\n                y,\n                ind,\n                zorder=6,\n                fontsize=10,\n                horizontalalignment=\"center\",\n                verticalalignment=\"center\",\n                clip_on=True,\n                bbox=None,\n                transform=self.ax.transData,\n            )\n        # Draw Edges\n        for edge in self.edges:\n            if len(edge) &gt; 1:\n                x1, y1 = self.node_positions[edge[0]]\n                x2, y2 = self.node_positions[edge[1]]\n                self.ax.plot(\n                    [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n                )\n        self.canvas.draw()\n\n    def remove_point(self, point: Tuple[float, float]) -&gt; None:\n        \"\"\"\n        Remove a point from the nodes.\n\n        Parameters\n        ----------\n        point : Tuple[float, float]\n            The point to remove.\n        \"\"\"\n        if len(self._nodes) &gt; 0:\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            self._nodes.pop(closest_node_ind)\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear all nodes and edges.\"\"\"\n        self._nodes = []\n        self.edges = [[]]\n        self.redraw()\n\n    def format_and_save(self) -&gt; None:\n        \"\"\"Format the data and save it to disk.\"\"\"\n        behave_df = load_animal_behavior(self.basepath)\n\n        if self.epoch is not None:\n            epochs = load_epoch(self.basepath)\n\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n                &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n            )\n        elif self.interval is not None:\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= self.interval[0])\n                &amp; (behave_df.time &lt;= self.interval[1])\n            )\n        else:\n            cur_epoch = ~np.isnan(behave_df.x)\n\n        print(\"running linearization...\")\n        track_graph = make_track_graph(self.node_positions, self.edges)\n\n        position = np.vstack(\n            [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n        ).T\n\n        position_df = get_linearized_position(\n            position=position,\n            track_graph=track_graph,\n            edge_order=self.edges,\n            use_HMM=self.use_HMM,\n            show_confirmation_plot=True,\n            # HMM optimization parameters - Updated defaults based on diagnostic results\n            n_bins_per_segment=50,  # Increased from 30 for better accuracy\n            use_sparse_transitions=True,  # Essential for multi-segment classification\n            subsample_positions=False,  # Keep False for accuracy\n            subsample_factor=5,\n            use_adaptive_subsampling=True,\n            # Advanced optimization parameters\n            use_batch_processing=False,\n            batch_size=1000,\n        )\n\n        print(\"saving to disk...\")\n        behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n        behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n        behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n            position_df.projected_x_position.values\n        )\n        behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n            position_df.projected_y_position.values\n        )\n\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n        )\n\n        data = loadmat(filename, simplify_cells=True)\n\n        data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n        data[\"behavior\"][\"states\"] = behave_df.states.values\n        data[\"behavior\"][\"position\"][\"projected_x\"] = (\n            behave_df.projected_x_position.values\n        )\n        data[\"behavior\"][\"position\"][\"projected_y\"] = (\n            behave_df.projected_y_position.values\n        )\n\n        # store nodes and edges within behavior file\n        data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n        savemat(filename, data, long_field_names=True)\n\n        self.save_nodes_edges()\n        self.disconnect()\n\n    def save_nodes_edges(self) -&gt; None:\n        \"\"\"Save the nodes and edges to a pickle file.\"\"\"\n        results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n        save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n        with open(save_file, \"wb\") as f:\n            pickle.dump(results, f)\n\n    def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n        \"\"\"\n        Store nodes and edges into behavior file.\n        Searches to find epochs with valid linearized coords.\n        Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n        Parameters\n        ----------\n        data : dict\n            The behavior data dictionary.\n        behave_df : pd.DataFrame\n            The DataFrame containing behavior data.\n\n        Returns\n        -------\n        dict\n            The updated behavior data dictionary.\n        \"\"\"\n        if self.epoch is None and self.interval is None:\n            # load epochs\n            epochs = load_epoch(self.basepath)\n            # iter over each epoch\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # locate index for given epoch\n                idx = behave_df.time.between(ep.startTime, ep.stopTime)\n                # if linearized is not all nan, add nodes and edges\n                if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                    behave_df[idx].shape[0] != 0\n                ):\n                    # adding nodes and edges\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        elif self.interval is not None:\n            # if interval was used, add nodes and edges just the epochs within that interval\n            epochs = load_epoch(self.basepath)\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # amount of overlap between interval and epoch\n                start_overlap = max(self.interval[0], ep.startTime)\n                end_overlap = min(self.interval[1], ep.stopTime)\n                overlap = max(0, end_overlap - start_overlap)\n\n                # if overlap is greater than 1 second, add nodes and edges\n                if overlap &gt; 1:\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        else:\n            # if epoch was used, add nodes and edges just that that epoch\n            data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n                self.node_positions\n            )\n            data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n        return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.node_positions","title":"<code>node_positions</code>  <code>property</code>","text":"<p>Get the positions of the nodes.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of node positions.</p>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.clear","title":"<code>clear()</code>","text":"<p>Clear all nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clear all nodes and edges.\"\"\"\n    self._nodes = []\n    self.edges = [[]]\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.click_event","title":"<code>click_event(event)</code>","text":"<p>Process mouse click events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The mouse click event.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def click_event(self, event: Any) -&gt; None:\n    \"\"\"\n    Process mouse click events.\n\n    Parameters\n    ----------\n    event : Any\n        The mouse click event.\n    \"\"\"\n    print(\n        f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n    )\n    if not event.inaxes:\n        return\n\n    if event.key is None:  # Regular mouse clicks\n        if event.button == 1:  # Left click\n            self._nodes.append((event.xdata, event.ydata))\n        elif event.button == 3:  # Right click\n            self.remove_point((event.xdata, event.ydata))\n\n    elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n        self.clear()\n\n    elif (\n        event.key == \"control\" and event.button == 1\n    ):  # Ctrl + Left click (Edge creation)\n        if len(self._nodes) == 0:\n            return\n        point = (event.xdata, event.ydata)\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        if len(self.edges[-1]) &lt; 2:\n            self.edges[-1].append(closest_node_ind)\n        else:\n            self.edges.append([closest_node_ind])\n\n    elif event.key == \"enter\":  # Pressing Enter\n        self.format_and_save()\n\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.connect","title":"<code>connect()</code>","text":"<p>Connect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def connect(self) -&gt; None:\n    \"\"\"Connect the event handlers.\"\"\"\n    print(\"Connecting to events\")\n    if self.cid is None:\n        self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n        self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n        print(\"Mouse click event connected!\")\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.disconnect","title":"<code>disconnect()</code>","text":"<p>Disconnect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def disconnect(self) -&gt; None:\n    \"\"\"Disconnect the event handlers.\"\"\"\n    if self.cid is not None:\n        self.canvas.mpl_disconnect(self.cid)\n        self.cid = None\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.format_and_save","title":"<code>format_and_save()</code>","text":"<p>Format the data and save it to disk.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def format_and_save(self) -&gt; None:\n    \"\"\"Format the data and save it to disk.\"\"\"\n    behave_df = load_animal_behavior(self.basepath)\n\n    if self.epoch is not None:\n        epochs = load_epoch(self.basepath)\n\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n            &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n        )\n    elif self.interval is not None:\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= self.interval[0])\n            &amp; (behave_df.time &lt;= self.interval[1])\n        )\n    else:\n        cur_epoch = ~np.isnan(behave_df.x)\n\n    print(\"running linearization...\")\n    track_graph = make_track_graph(self.node_positions, self.edges)\n\n    position = np.vstack(\n        [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n    ).T\n\n    position_df = get_linearized_position(\n        position=position,\n        track_graph=track_graph,\n        edge_order=self.edges,\n        use_HMM=self.use_HMM,\n        show_confirmation_plot=True,\n        # HMM optimization parameters - Updated defaults based on diagnostic results\n        n_bins_per_segment=50,  # Increased from 30 for better accuracy\n        use_sparse_transitions=True,  # Essential for multi-segment classification\n        subsample_positions=False,  # Keep False for accuracy\n        subsample_factor=5,\n        use_adaptive_subsampling=True,\n        # Advanced optimization parameters\n        use_batch_processing=False,\n        batch_size=1000,\n    )\n\n    print(\"saving to disk...\")\n    behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n    behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n    behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n        position_df.projected_x_position.values\n    )\n    behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n        position_df.projected_y_position.values\n    )\n\n    filename = os.path.join(\n        self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n    )\n\n    data = loadmat(filename, simplify_cells=True)\n\n    data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n    data[\"behavior\"][\"states\"] = behave_df.states.values\n    data[\"behavior\"][\"position\"][\"projected_x\"] = (\n        behave_df.projected_x_position.values\n    )\n    data[\"behavior\"][\"position\"][\"projected_y\"] = (\n        behave_df.projected_y_position.values\n    )\n\n    # store nodes and edges within behavior file\n    data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n    savemat(filename, data, long_field_names=True)\n\n    self.save_nodes_edges()\n    self.disconnect()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.process_key","title":"<code>process_key(event)</code>","text":"<p>Process key press events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The key press event.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def process_key(self, event: Any) -&gt; None:\n    \"\"\"\n    Process key press events.\n\n    Parameters\n    ----------\n    event : Any\n        The key press event.\n    \"\"\"\n    if event.key == \"enter\":\n        self.format_and_save()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.redraw","title":"<code>redraw()</code>","text":"<p>Redraw the nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def redraw(self) -&gt; None:\n    \"\"\"Redraw the nodes and edges.\"\"\"\n    # Draw Node Circles\n    if len(self.node_positions) &gt; 0:\n        self._nodes_plot.set_offsets(self.node_positions)\n    else:\n        self._nodes_plot.set_offsets([])\n\n    # Draw Node Numbers\n    for ind, (x, y) in enumerate(self.node_positions):\n        self.ax.text(\n            x,\n            y,\n            ind,\n            zorder=6,\n            fontsize=10,\n            horizontalalignment=\"center\",\n            verticalalignment=\"center\",\n            clip_on=True,\n            bbox=None,\n            transform=self.ax.transData,\n        )\n    # Draw Edges\n    for edge in self.edges:\n        if len(edge) &gt; 1:\n            x1, y1 = self.node_positions[edge[0]]\n            x2, y2 = self.node_positions[edge[1]]\n            self.ax.plot(\n                [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n            )\n    self.canvas.draw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.remove_point","title":"<code>remove_point(point)</code>","text":"<p>Remove a point from the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Tuple[float, float]</code> <p>The point to remove.</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def remove_point(self, point: Tuple[float, float]) -&gt; None:\n    \"\"\"\n    Remove a point from the nodes.\n\n    Parameters\n    ----------\n    point : Tuple[float, float]\n        The point to remove.\n    \"\"\"\n    if len(self._nodes) &gt; 0:\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        self._nodes.pop(closest_node_ind)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.save_nodes_edges","title":"<code>save_nodes_edges()</code>","text":"<p>Save the nodes and edges to a pickle file.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def save_nodes_edges(self) -&gt; None:\n    \"\"\"Save the nodes and edges to a pickle file.\"\"\"\n    results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n    save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n    with open(save_file, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.NodePicker.save_nodes_edges_to_behavior","title":"<code>save_nodes_edges_to_behavior(data, behave_df)</code>","text":"<p>Store nodes and edges into behavior file. Searches to find epochs with valid linearized coords. Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>The behavior data dictionary.</p> required <code>behave_df</code> <code>DataFrame</code> <p>The DataFrame containing behavior data.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The updated behavior data dictionary.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n    \"\"\"\n    Store nodes and edges into behavior file.\n    Searches to find epochs with valid linearized coords.\n    Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n    Parameters\n    ----------\n    data : dict\n        The behavior data dictionary.\n    behave_df : pd.DataFrame\n        The DataFrame containing behavior data.\n\n    Returns\n    -------\n    dict\n        The updated behavior data dictionary.\n    \"\"\"\n    if self.epoch is None and self.interval is None:\n        # load epochs\n        epochs = load_epoch(self.basepath)\n        # iter over each epoch\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # locate index for given epoch\n            idx = behave_df.time.between(ep.startTime, ep.stopTime)\n            # if linearized is not all nan, add nodes and edges\n            if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                behave_df[idx].shape[0] != 0\n            ):\n                # adding nodes and edges\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    elif self.interval is not None:\n        # if interval was used, add nodes and edges just the epochs within that interval\n        epochs = load_epoch(self.basepath)\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # amount of overlap between interval and epoch\n            start_overlap = max(self.interval[0], ep.startTime)\n            end_overlap = min(self.interval[1], ep.stopTime)\n            overlap = max(0, end_overlap - start_overlap)\n\n            # if overlap is greater than 1 second, add nodes and edges\n            if overlap &gt; 1:\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    else:\n        # if epoch was used, add nodes and edges just that that epoch\n        data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n            self.node_positions\n        )\n        data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n    return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.TrackGraph","title":"<code>TrackGraph</code>","text":"<p>A simple track graph implementation for linearization.</p> <p>Parameters:</p> Name Type Description Default <code>node_positions</code> <code>ndarray</code> <p>Array of node positions (n_nodes, 2)</p> required <code>edges</code> <code>list</code> <p>List of edge connections between nodes</p> required Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>class TrackGraph:\n    \"\"\"\n    A simple track graph implementation for linearization.\n\n    Parameters\n    ----------\n    node_positions : np.ndarray\n        Array of node positions (n_nodes, 2)\n    edges : list\n        List of edge connections between nodes\n    \"\"\"\n\n    def __init__(self, node_positions: np.ndarray, edges: List[List[int]]):\n        self.node_positions = np.asarray(node_positions)\n        self.edges = edges\n        self.n_nodes = len(node_positions)\n\n        # Create adjacency matrix\n        self.adjacency_matrix = self._create_adjacency_matrix()\n\n        # Calculate distances between connected nodes\n        self.edge_distances = self._calculate_edge_distances()\n\n        # Calculate cumulative distances for linearization\n        self.cumulative_distances = self._calculate_cumulative_distances()\n\n    def _create_adjacency_matrix(self) -&gt; csr_matrix:\n        \"\"\"Create sparse adjacency matrix from edges.\"\"\"\n        row_indices = []\n        col_indices = []\n\n        for edge in self.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    row_indices.extend([edge[i], edge[i + 1]])\n                    col_indices.extend([edge[i + 1], edge[i]])\n\n        data = np.ones(len(row_indices))\n        return csr_matrix(\n            (data, (row_indices, col_indices)), shape=(self.n_nodes, self.n_nodes)\n        )\n\n    def _calculate_edge_distances(self) -&gt; dict:\n        \"\"\"Calculate distances between connected nodes.\"\"\"\n        distances = {}\n        for edge in self.edges:\n            if len(edge) &gt;= 2:\n                for i in range(len(edge) - 1):\n                    node1, node2 = edge[i], edge[i + 1]\n                    dist = np.linalg.norm(\n                        self.node_positions[node1] - self.node_positions[node2]\n                    )\n                    distances[(node1, node2)] = dist\n                    distances[(node2, node1)] = dist\n        return distances\n\n    def _calculate_cumulative_distances(self) -&gt; np.ndarray:\n        \"\"\"Calculate cumulative distances along the track.\"\"\"\n        # Find the main path through the track\n        # For simplicity, we'll use the first edge as the starting point\n        if not self.edges or len(self.edges[0]) &lt; 2:\n            return np.zeros(self.n_nodes)\n\n        cumulative = np.zeros(self.n_nodes)\n        visited = set()\n\n        # Start from the first edge\n        current_edge = self.edges[0]\n        if len(current_edge) &gt;= 2:\n            for i in range(len(current_edge) - 1):\n                node1, node2 = current_edge[i], current_edge[i + 1]\n                if node1 not in visited:\n                    visited.add(node1)\n                if node2 not in visited:\n                    visited.add(node2)\n                    cumulative[node2] = cumulative[node1] + self.edge_distances.get(\n                        (node1, node2), 0\n                    )\n\n        return cumulative\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.TrackGraph._calculate_cumulative_distances","title":"<code>_calculate_cumulative_distances()</code>","text":"<p>Calculate cumulative distances along the track.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_cumulative_distances(self) -&gt; np.ndarray:\n    \"\"\"Calculate cumulative distances along the track.\"\"\"\n    # Find the main path through the track\n    # For simplicity, we'll use the first edge as the starting point\n    if not self.edges or len(self.edges[0]) &lt; 2:\n        return np.zeros(self.n_nodes)\n\n    cumulative = np.zeros(self.n_nodes)\n    visited = set()\n\n    # Start from the first edge\n    current_edge = self.edges[0]\n    if len(current_edge) &gt;= 2:\n        for i in range(len(current_edge) - 1):\n            node1, node2 = current_edge[i], current_edge[i + 1]\n            if node1 not in visited:\n                visited.add(node1)\n            if node2 not in visited:\n                visited.add(node2)\n                cumulative[node2] = cumulative[node1] + self.edge_distances.get(\n                    (node1, node2), 0\n                )\n\n    return cumulative\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.TrackGraph._calculate_edge_distances","title":"<code>_calculate_edge_distances()</code>","text":"<p>Calculate distances between connected nodes.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _calculate_edge_distances(self) -&gt; dict:\n    \"\"\"Calculate distances between connected nodes.\"\"\"\n    distances = {}\n    for edge in self.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                node1, node2 = edge[i], edge[i + 1]\n                dist = np.linalg.norm(\n                    self.node_positions[node1] - self.node_positions[node2]\n                )\n                distances[(node1, node2)] = dist\n                distances[(node2, node1)] = dist\n    return distances\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.TrackGraph._create_adjacency_matrix","title":"<code>_create_adjacency_matrix()</code>","text":"<p>Create sparse adjacency matrix from edges.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def _create_adjacency_matrix(self) -&gt; csr_matrix:\n    \"\"\"Create sparse adjacency matrix from edges.\"\"\"\n    row_indices = []\n    col_indices = []\n\n    for edge in self.edges:\n        if len(edge) &gt;= 2:\n            for i in range(len(edge) - 1):\n                row_indices.extend([edge[i], edge[i + 1]])\n                col_indices.extend([edge[i + 1], edge[i]])\n\n    data = np.ones(len(row_indices))\n    return csr_matrix(\n        (data, (row_indices, col_indices)), shape=(self.n_nodes, self.n_nodes)\n    )\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization._build_sparse_transition_matrix_numba","title":"<code>_build_sparse_transition_matrix_numba(state_to_segment, state_to_position, n_states, transition_smoothness, segments_connected)</code>","text":"<p>Numba-optimized sparse transition matrix building. Returns log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>@njit(parallel=True)\ndef _build_sparse_transition_matrix_numba(\n    state_to_segment,\n    state_to_position,\n    n_states,\n    transition_smoothness,\n    segments_connected,\n):\n    \"\"\"\n    Numba-optimized sparse transition matrix building.\n    Returns log-probabilities for numerical stability.\n    \"\"\"\n    log_transition_matrix = np.full(\n        (n_states, n_states), -np.inf\n    )  # Initialize with log(0) = -inf\n\n    for i in prange(n_states):\n        seg1 = state_to_segment[i]\n        pos1 = state_to_position[i]\n\n        # Compute transitions for all states (Numba doesn't handle dynamic lists well)\n        for j in range(n_states):\n            seg2 = state_to_segment[j]\n            pos2 = state_to_position[j]\n\n            # Check if this is a valid transition for sparse mode\n            valid_transition = False\n\n            # Same segment transitions (nearby positions only)\n            if seg1 == seg2:\n                pos_diff = abs(i - j)\n                if pos_diff &lt;= 3:  # Allow more transitions within segments\n                    valid_transition = True\n\n            # Inter-segment transitions - allow transitions to connected segments\n            elif segments_connected[seg1, seg2]:\n                # Allow transitions to boundary states of connected segments\n                # For each segment, allow transitions to first and last few states\n                # Count states in seg2 to find boundary states\n                seg2_start = 0\n                seg2_end = 0\n                for k in range(n_states):\n                    if state_to_segment[k] == seg2:\n                        if seg2_start == 0:\n                            seg2_start = k\n                        seg2_end = k\n\n                # Allow transitions to first 5 and last 5 states of connected segments\n                if (j &gt;= seg2_start and j &lt; seg2_start + 5) or (\n                    j &lt;= seg2_end and j &gt; seg2_end - 5\n                ):\n                    valid_transition = True\n\n            if valid_transition:\n                # Calculate transition log-probability\n                if seg1 == seg2:\n                    # Within same segment\n                    dx = pos1[0] - pos2[0]\n                    dy = pos1[1] - pos2[1]\n                    distance = (dx * dx + dy * dy) ** 0.5\n                    log_prob = -(distance**2) / (2 * transition_smoothness**2)\n                else:\n                    # Between segments - increase probability for better transitions\n                    dx = pos1[0] - pos2[0]\n                    dy = pos1[1] - pos2[1]\n                    distance = (dx * dx + dy * dy) ** 0.5\n                    log_prob = np.log(0.5) - (distance**2) / (\n                        2 * transition_smoothness**2\n                    )\n\n                log_transition_matrix[i, j] = log_prob\n\n    # Normalize rows in log-space\n    for i in range(n_states):\n        # Find max log-probability in row for numerical stability\n        max_log_prob = -np.inf\n        for j in range(n_states):\n            if log_transition_matrix[i, j] &gt; max_log_prob:\n                max_log_prob = log_transition_matrix[i, j]\n\n        # If all transitions are -inf, set uniform distribution\n        if max_log_prob == -np.inf:\n            uniform_log_prob = np.log(1.0 / n_states)\n            for j in range(n_states):\n                log_transition_matrix[i, j] = uniform_log_prob\n        else:\n            # Subtract max and normalize\n            sum_exp = 0.0\n            for j in range(n_states):\n                if log_transition_matrix[i, j] &gt; -np.inf:\n                    sum_exp += np.exp(log_transition_matrix[i, j] - max_log_prob)\n\n            if sum_exp &gt; 0:\n                log_sum = np.log(sum_exp)\n                for j in range(n_states):\n                    if log_transition_matrix[i, j] &gt; -np.inf:\n                        log_transition_matrix[i, j] = (\n                            log_transition_matrix[i, j] - max_log_prob - log_sum\n                        )\n                    else:\n                        log_transition_matrix[i, j] = -np.inf\n\n    return log_transition_matrix\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization._emission_probabilities_numba","title":"<code>_emission_probabilities_numba(observations, emission_centers, emission_covariance)</code>","text":"<p>Numba-optimized emission probability calculation. Returns log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>@njit(parallel=True, fastmath=True)\ndef _emission_probabilities_numba(observations, emission_centers, emission_covariance):\n    \"\"\"\n    Numba-optimized emission probability calculation.\n    Returns log-probabilities for numerical stability.\n    \"\"\"\n    n_observations = len(observations)\n    n_states = len(emission_centers)\n    log_emission_probs = np.zeros((n_observations, n_states))\n\n    # Pre-compute covariance matrix components for 2D case\n    # For 2x2 covariance matrix: [[a, b], [b, c]]\n    a = emission_covariance[0, 0]\n    b = emission_covariance[0, 1]\n    c = emission_covariance[1, 1]\n\n    # Determinant: det = a*c - b*b\n    det = a * c - b * b\n\n    # Inverse matrix: [[c, -b], [-b, a]] / det\n    inv_a = c / det\n    inv_b = -b / det\n    inv_c = a / det\n\n    # Log normalization constant\n    log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det)))\n\n    for t in prange(n_observations):\n        obs = observations[t]\n        for i in range(n_states):\n            center = emission_centers[i]\n            dx = obs[0] - center[0]\n            dy = obs[1] - center[1]\n\n            # Full Gaussian calculation: diff.T @ inv_cov @ diff\n            # For 2D: [dx, dy] @ [[inv_a, inv_b], [inv_b, inv_c]] @ [dx, dy]\n            # = dx*(inv_a*dx + inv_b*dy) + dy*(inv_b*dx + inv_c*dy)\n            # = dx*inv_a*dx + dx*inv_b*dy + dy*inv_b*dx + dy*inv_c*dy\n            # = inv_a*dx*dx + 2*inv_b*dx*dy + inv_c*dy*dy\n            exponent = -0.5 * (inv_a * dx * dx + 2 * inv_b * dx * dy + inv_c * dy * dy)\n            log_emission_probs[t, i] = log_norm_const + exponent\n\n    return log_emission_probs\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization._process_batch_emissions","title":"<code>_process_batch_emissions(observations_batch, emission_centers, emission_covariance, batch_size)</code>","text":"<p>Process emission log-probabilities in batches to reduce memory usage. Returns log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>@njit(fastmath=True)\ndef _process_batch_emissions(\n    observations_batch, emission_centers, emission_covariance, batch_size\n):\n    \"\"\"\n    Process emission log-probabilities in batches to reduce memory usage.\n    Returns log-probabilities for numerical stability.\n    \"\"\"\n    n_observations = len(observations_batch)\n    n_states = len(emission_centers)\n    log_emission_probs = np.zeros((n_observations, n_states))\n\n    # Pre-compute covariance matrix components for 2D case\n    # For 2x2 covariance matrix: [[a, b], [b, c]]\n    a = emission_covariance[0, 0]\n    b = emission_covariance[0, 1]\n    c = emission_covariance[1, 1]\n\n    # Determinant: det = a*c - b*b\n    det = a * c - b * b\n\n    # Inverse matrix: [[c, -b], [-b, a]] / det\n    inv_a = c / det\n    inv_b = -b / det\n    inv_c = a / det\n\n    # Log normalization constant\n    log_norm_const = np.log(1.0 / (2 * np.pi * np.sqrt(det)))\n\n    # Process in batches\n    for batch_start in range(0, n_observations, batch_size):\n        batch_end = min(batch_start + batch_size, n_observations)\n\n        for t in range(batch_start, batch_end):\n            obs = observations_batch[t]\n            for i in range(n_states):\n                center = emission_centers[i]\n                dx = obs[0] - center[0]\n                dy = obs[1] - center[1]\n\n                # Full Gaussian calculation: diff.T @ inv_cov @ diff\n                # For 2D: [dx, dy] @ [[inv_a, inv_b], [inv_b, inv_c]] @ [dx, dy]\n                # = inv_a*dx*dx + 2*inv_b*dx*dy + inv_c*dy*dy\n                exponent = -0.5 * (\n                    inv_a * dx * dx + 2 * inv_b * dx * dy + inv_c * dy * dy\n                )\n                log_emission_probs[t, i] = log_norm_const + exponent\n\n    return log_emission_probs\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization._project_positions_parallel","title":"<code>_project_positions_parallel(positions, node_positions, edges, n_positions)</code>","text":"<p>Numba-optimized parallel position projection onto track.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>@njit(parallel=True, fastmath=True)\ndef _project_positions_parallel(positions, node_positions, edges, n_positions):\n    \"\"\"\n    Numba-optimized parallel position projection onto track.\n    \"\"\"\n    linear_positions = np.full(n_positions, np.nan)\n    track_segment_ids = np.full(n_positions, -1, dtype=np.int32)\n    projected_positions = np.full((n_positions, 2), np.nan)\n\n    for i in prange(n_positions):\n        pos = positions[i]\n\n        # Find closest edge\n        min_distance = np.inf\n        best_segment = -1\n        best_projection = np.array([np.nan, np.nan])\n\n        for edge_idx, edge in enumerate(edges):\n            if len(edge) &gt;= 2:\n                for j in range(len(edge) - 1):\n                    node1, node2 = edge[j], edge[j + 1]\n                    p1 = node_positions[node1]\n                    p2 = node_positions[node2]\n\n                    # Project position onto this line segment\n                    v = p2 - p1\n                    u = pos - p1\n                    t = np.dot(u, v) / np.dot(v, v)\n                    t = np.clip(t, 0, 1)\n\n                    projected = p1 + t * v\n                    distance = np.linalg.norm(pos - projected)\n\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        best_segment = edge_idx\n                        best_projection = projected\n\n        if best_segment &gt;= 0:\n            track_segment_ids[i] = best_segment\n            projected_positions[i] = best_projection\n            # Calculate linear position (simplified)\n            linear_positions[i] = (\n                best_segment + best_projection[0] / 100.0\n            )  # Rough approximation\n\n    return linear_positions, track_segment_ids, projected_positions\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization._viterbi_numba","title":"<code>_viterbi_numba(log_emission_probs, log_transition_matrix, n_observations, n_states)</code>","text":"<p>Numba-optimized Viterbi algorithm using log-probabilities for numerical stability.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>@njit(fastmath=True)\ndef _viterbi_numba(log_emission_probs, log_transition_matrix, n_observations, n_states):\n    \"\"\"\n    Numba-optimized Viterbi algorithm using log-probabilities for numerical stability.\n    \"\"\"\n    # Initialize log-probabilities\n    log_delta = np.zeros((n_observations, n_states))\n    psi = np.zeros((n_observations, n_states), dtype=np.int32)\n\n    # Initialize with log-emission probabilities of first observation\n    # Add small constant to avoid log(0)\n    log_initial_probs = np.zeros(n_states)\n    for i in range(n_states):\n        log_initial_probs[i] = log_emission_probs[0, i]\n\n    # Forward pass\n    for t in range(n_observations):\n        if t == 0:\n            log_delta[t] = log_initial_probs\n        else:\n            # Manual max operations for Numba compatibility\n            max_log_probs = np.zeros(n_states)\n            max_indices = np.zeros(n_states, dtype=np.int32)\n\n            for j in range(n_states):\n                max_val = -np.inf\n                max_idx = 0\n\n                for i in range(n_states):\n                    # Add log-probabilities instead of multiplying\n                    val = log_delta[t - 1, i] + log_transition_matrix[i, j]\n                    if val &gt; max_val:\n                        max_val = val\n                        max_idx = i\n\n                max_log_probs[j] = max_val\n                max_indices[j] = max_idx\n\n            # Add emission log-probabilities\n            log_delta[t] = max_log_probs + log_emission_probs[t]\n            psi[t] = max_indices\n\n    # Backward pass\n    state_sequence = np.zeros(n_observations, dtype=np.int32)\n\n    # Find the state with maximum log-probability at the last time step\n    max_val = -np.inf\n    max_idx = 0\n    for i in range(n_states):\n        if log_delta[-1, i] &gt; max_val:\n            max_val = log_delta[-1, i]\n            max_idx = i\n    state_sequence[-1] = max_idx\n\n    for t in range(n_observations - 2, -1, -1):\n        state_sequence[t] = psi[t + 1, state_sequence[t + 1]]\n\n    return state_sequence\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.get_linearized_position","title":"<code>get_linearized_position(position, track_graph, edge_order=None, use_HMM=False, show_confirmation_plot=True, n_bins_per_segment=50, use_sparse_transitions=True, subsample_positions=False, subsample_factor=5, use_adaptive_subsampling=True, use_batch_processing=False, batch_size=1000, auto_tune=True)</code>","text":"<p>Get linearized position along a track.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object</p> required <code>edge_order</code> <code>List[List[int]]</code> <p>Order of edges to traverse, by default None</p> <code>None</code> <code>use_HMM</code> <code>bool</code> <p>Whether to use HMM-based linearization, by default False</p> <code>False</code> <code>show_confirmation_plot</code> <code>bool</code> <p>Whether to show confirmation plot, by default True</p> <code>True</code> <code>n_bins_per_segment</code> <code>int</code> <p>Number of bins per segment for HMM, by default 50</p> <code>50</code> <code>use_sparse_transitions</code> <code>bool</code> <p>Whether to use sparse transitions for HMM, by default True</p> <code>True</code> <code>subsample_positions</code> <code>bool</code> <p>Whether to subsample positions for speed, by default False</p> <code>False</code> <code>subsample_factor</code> <code>int</code> <p>Subsampling factor, by default 5</p> <code>5</code> <code>use_adaptive_subsampling</code> <code>bool</code> <p>Whether to use adaptive subsampling, by default True</p> <code>True</code> <code>use_batch_processing</code> <code>bool</code> <p>Whether to use batch processing, by default False</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Batch size for processing, by default 1000</p> <code>1000</code> <code>auto_tune</code> <code>bool</code> <p>Whether to auto-tune parameters, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with linearization results</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def get_linearized_position(\n    position: np.ndarray,\n    track_graph: TrackGraph,\n    edge_order: Optional[List[List[int]]] = None,\n    use_HMM: bool = False,\n    show_confirmation_plot: bool = True,\n    # HMM optimization parameters - Updated defaults for real data\n    n_bins_per_segment: int = 50,  # Good balance of accuracy and speed\n    use_sparse_transitions: bool = True,  # Essential for multi-segment classification\n    subsample_positions: bool = False,  # Keep False for accuracy\n    subsample_factor: int = 5,\n    use_adaptive_subsampling: bool = True,\n    # Advanced optimization parameters\n    use_batch_processing: bool = False,\n    batch_size: int = 1000,\n    # Auto-tuning parameter\n    auto_tune: bool = True,  # Automatically tune parameters based on data for better results\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Get linearized position along a track.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        Array of 2D positions (n_positions, 2)\n    track_graph : TrackGraph\n        Track graph object\n    edge_order : List[List[int]], optional\n        Order of edges to traverse, by default None\n    use_HMM : bool, optional\n        Whether to use HMM-based linearization, by default False\n    show_confirmation_plot : bool, optional\n        Whether to show confirmation plot, by default True\n    n_bins_per_segment : int, optional\n        Number of bins per segment for HMM, by default 50\n    use_sparse_transitions : bool, optional\n        Whether to use sparse transitions for HMM, by default True\n    subsample_positions : bool, optional\n        Whether to subsample positions for speed, by default False\n    subsample_factor : int, optional\n        Subsampling factor, by default 5\n    use_adaptive_subsampling : bool, optional\n        Whether to use adaptive subsampling, by default True\n    use_batch_processing : bool, optional\n        Whether to use batch processing, by default False\n    batch_size : int, optional\n        Batch size for processing, by default 1000\n    auto_tune : bool, optional\n        Whether to auto-tune parameters, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with linearization results\n    \"\"\"\n    # Auto-adjust parameters for large track graphs\n    n_segments = len(track_graph.edges)\n    if n_segments &gt; 10:\n        # For large track graphs, use more aggressive optimization\n        if n_bins_per_segment &gt; 30:\n            n_bins_per_segment = 30\n            print(f\"Reduced bins per segment to {n_bins_per_segment} for large track graph ({n_segments} segments)\")\n\n        # Enable subsampling for very large datasets\n        if len(position) &gt; 1000 and not subsample_positions:\n            subsample_positions = True\n            subsample_factor = max(3, len(position) // 2000)\n            print(f\"Enabled subsampling with factor {subsample_factor} for large dataset ({len(position)} positions)\")\n\n        # Enable batch processing for large track graphs\n        if not use_batch_processing:\n            use_batch_processing = True\n            print(\"Enabled batch processing for large track graph\")\n\n    if use_HMM:\n        # Use HMM-based linearization\n        hmm_linearizer = HMMLinearizer(\n            track_graph,\n            n_bins_per_segment=n_bins_per_segment,\n            use_sparse_transitions=use_sparse_transitions,\n            subsample_positions=subsample_positions,\n            subsample_factor=subsample_factor,\n            use_adaptive_subsampling=use_adaptive_subsampling,\n            use_batch_processing=use_batch_processing,\n            batch_size=batch_size,\n            adaptive_binning=True,  # Enable adaptive binning for large track graphs\n            max_total_states=500,   # Limit total states for performance\n        )\n\n        # Auto-tune parameters if requested\n        if auto_tune:\n            tuned_params = hmm_linearizer._auto_tune_parameters(position)\n            print(f\"Auto-tuned HMM parameters: {tuned_params}\")\n            # Apply tuned parameters\n            hmm_linearizer.emission_noise = tuned_params.get(\"emission_noise\", hmm_linearizer.emission_noise)\n            hmm_linearizer.transition_smoothness = tuned_params.get(\"transition_smoothness\", hmm_linearizer.transition_smoothness)\n\n        # Perform HMM linearization\n        linear_positions, track_segment_ids, projected_positions = hmm_linearizer.linearize_with_hmm(position)\n\n        # Create DataFrame\n        result_df = pd.DataFrame({\n            \"linear_position\": linear_positions,\n            \"track_segment_id\": track_segment_ids,\n            \"projected_x_position\": projected_positions[:, 0],\n            \"projected_y_position\": projected_positions[:, 1],\n        })\n\n        # Show confirmation plot if requested\n        if show_confirmation_plot:\n            plot_linearization_confirmation(\n                position, result_df, track_graph, title=\"Linearization Confirmation (HMM)\"\n            )\n\n        return result_df\n    else:\n        # Use standard linearization\n        linear_positions, track_segment_ids, projected_positions = project_position_to_track(position, track_graph)\n\n        # Create DataFrame\n        result_df = pd.DataFrame({\n            \"linear_position\": linear_positions,\n            \"track_segment_id\": track_segment_ids,\n            \"projected_x_position\": projected_positions[:, 0],\n            \"projected_y_position\": projected_positions[:, 1],\n        })\n\n        # Show confirmation plot if requested\n        if show_confirmation_plot:\n            plot_linearization_confirmation(\n                position, result_df, track_graph, title=\"Linearization Confirmation (Standard)\"\n            )\n\n        return result_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.load_animal_behavior","title":"<code>load_animal_behavior(basepath)</code>","text":"<p>Load animal behavior data from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the .mat file is located.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the animal behavior data.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def load_animal_behavior(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load animal behavior data from a .mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the .mat file is located.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the animal behavior data.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = loadmat(filename, simplify_cells=True)\n    df = pd.DataFrame()\n    df[\"time\"] = data[\"behavior\"][\"timestamps\"]\n    try:\n        df[\"states\"] = data[\"behavior\"][\"states\"]\n    except Exception:\n        pass\n    for key in data[\"behavior\"][\"position\"].keys():\n        try:\n            df[key] = data[\"behavior\"][\"position\"][key]\n        except Exception:\n            pass\n    return df\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.load_epoch","title":"<code>load_epoch(basepath)</code>","text":"<p>Load epoch info from cell explorer basename.session and store in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the .session.mat file is located.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the epoch information.</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def load_epoch(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load epoch info from cell explorer basename.session and store in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the .session.mat file is located.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the epoch information.\n    \"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n    data = loadmat(filename, simplify_cells=True)\n    try:\n        return pd.DataFrame(data[\"session\"][\"epochs\"])\n    except Exception:\n        return pd.DataFrame([data[\"session\"][\"epochs\"]])\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.make_track_graph","title":"<code>make_track_graph(node_positions, edges)</code>","text":"<p>Create a track graph from node positions and edges.</p> <p>Parameters:</p> Name Type Description Default <code>node_positions</code> <code>ndarray</code> <p>Array of node positions (n_nodes, 2)</p> required <code>edges</code> <code>list</code> <p>List of edge connections between nodes</p> required <p>Returns:</p> Type Description <code>TrackGraph</code> <p>Track graph object</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def make_track_graph(node_positions: np.ndarray, edges: List[List[int]]) -&gt; TrackGraph:\n    \"\"\"\n    Create a track graph from node positions and edges.\n\n    Parameters\n    ----------\n    node_positions : np.ndarray\n        Array of node positions (n_nodes, 2)\n    edges : list\n        List of edge connections between nodes\n\n    Returns\n    -------\n    TrackGraph\n        Track graph object\n    \"\"\"\n    return TrackGraph(node_positions, edges)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.plot_linearization_confirmation","title":"<code>plot_linearization_confirmation(original_positions, linearized_df, track_graph, title='Linearization Confirmation', show_plot=True)</code>","text":"<p>Create a confirmation plot showing the linearization results.</p> <p>Parameters:</p> Name Type Description Default <code>original_positions</code> <code>ndarray</code> <p>Original 2D positions (n_positions, 2)</p> required <code>linearized_df</code> <code>DataFrame</code> <p>DataFrame with linearization results from get_linearized_position</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object used for linearization</p> required <code>title</code> <code>str</code> <p>Title for the plot, by default \"Linearization Confirmation\"</p> <code>'Linearization Confirmation'</code> <code>show_plot</code> <code>bool</code> <p>Whether to display the plot, by default True</p> <code>True</code> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def plot_linearization_confirmation(\n    original_positions: np.ndarray,\n    linearized_df: pd.DataFrame,\n    track_graph: TrackGraph,\n    title: str = \"Linearization Confirmation\",\n    show_plot: bool = True,\n) -&gt; None:\n    \"\"\"\n    Create a confirmation plot showing the linearization results.\n\n    Parameters\n    ----------\n    original_positions : np.ndarray\n        Original 2D positions (n_positions, 2)\n    linearized_df : pd.DataFrame\n        DataFrame with linearization results from get_linearized_position\n    track_graph : TrackGraph\n        Track graph object used for linearization\n    title : str, optional\n        Title for the plot, by default \"Linearization Confirmation\"\n    show_plot : bool, optional\n        Whether to display the plot, by default True\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n    fig.suptitle(title, fontsize=16)\n\n    # Create color map for segments\n    unique_segments = sorted(linearized_df[\"track_segment_id\"].unique())\n    if len(unique_segments) &gt; 0:\n        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_segments)))\n        segment_colors = dict(zip(unique_segments, colors))\n    else:\n        segment_colors = {}\n\n    # Plot 1: Original 2D positions with track graph (color coded by segment)\n    ax1 = axes[0, 0]\n\n    # Color code original positions by their corresponding segment\n    if len(segment_colors) &gt; 0:\n        # Get segment IDs for original positions (assuming they correspond to linearized_df order)\n        segment_ids = linearized_df[\"track_segment_id\"].values\n        valid_mask = segment_ids &gt;= 0  # Only plot valid segments\n\n        if np.any(valid_mask):\n            valid_positions = original_positions[valid_mask]\n            valid_segments = segment_ids[valid_mask]\n            colors_for_positions = [\n                segment_colors.get(seg, \"gray\") for seg in valid_segments\n            ]\n\n            ax1.scatter(\n                valid_positions[:, 0],\n                valid_positions[:, 1],\n                c=colors_for_positions,\n                s=1,\n                alpha=0.6,\n            )\n        else:\n            ax1.scatter(\n                original_positions[:, 0],\n                original_positions[:, 1],\n                color=\"lightblue\", \n                s=1,\n                alpha=0.6,\n            )\n    else:\n        ax1.scatter(\n            original_positions[:, 0],\n            original_positions[:, 1],\n            color=\"lightblue\", \n            s=1,\n            alpha=0.6,\n        )\n\n    # Plot track graph nodes and edges with color coding\n    node_positions = track_graph.node_positions\n    ax1.scatter(\n        node_positions[:, 0], node_positions[:, 1], color=\"red\", s=50, zorder=5\n    ) \n\n    # Draw edges with color coding\n    for i, edge in enumerate(track_graph.edges):\n        start_pos = node_positions[edge[0]]\n        end_pos = node_positions[edge[1]]\n        edge_color = segment_colors.get(i, \"black\")\n        ax1.plot(\n            [start_pos[0], end_pos[0]],\n            [start_pos[1], end_pos[1]],\n            color=edge_color,\n            linewidth=3,\n            alpha=0.8,\n        )\n\n    ax1.set_xlabel(\"X Position (cm)\")\n    ax1.set_ylabel(\"Y Position (cm)\")\n    ax1.set_title(\"Original 2D Positions with Track Graph (Color Coded by Segment)\")\n    ax1.grid(True, alpha=0.3)\n    ax1.axis(\"equal\")\n\n    # Plot 2: Projected positions on track (color coded by segment)\n    ax2 = axes[0, 1]\n\n    # Color code projected positions by segment\n    if len(segment_colors) &gt; 0:\n        valid_mask = linearized_df[\"track_segment_id\"] &gt;= 0\n        if np.any(valid_mask):\n            valid_proj_x = linearized_df.loc[valid_mask, \"projected_x_position\"]\n            valid_proj_y = linearized_df.loc[valid_mask, \"projected_y_position\"]\n            valid_segments = linearized_df.loc[valid_mask, \"track_segment_id\"]\n            colors_for_proj = [\n                segment_colors.get(seg, \"gray\") for seg in valid_segments\n            ]\n\n            ax2.scatter(valid_proj_x, valid_proj_y, c=colors_for_proj, s=1, alpha=0.6)\n        else:\n            ax2.scatter(\n                linearized_df[\"projected_x_position\"],\n                linearized_df[\"projected_y_position\"],\n                color=\"green\", \n                s=1,\n                alpha=0.6,\n            )\n    else:\n        ax2.scatter(\n            linearized_df[\"projected_x_position\"],\n            linearized_df[\"projected_y_position\"],\n            color=\"green\", \n            s=1,\n            alpha=0.6,\n        )\n\n    # Plot track graph nodes and edges with color coding\n    ax2.scatter(\n        node_positions[:, 0], node_positions[:, 1], color=\"red\", s=50, zorder=5\n    ) \n\n    # Draw edges with color coding\n    for i, edge in enumerate(track_graph.edges):\n        start_pos = node_positions[edge[0]]\n        end_pos = node_positions[edge[1]]\n        edge_color = segment_colors.get(i, \"black\")\n        ax2.plot(\n            [start_pos[0], end_pos[0]],\n            [start_pos[1], end_pos[1]],\n            color=edge_color,\n            linewidth=3,\n            alpha=0.8,\n        )\n\n    ax2.set_xlabel(\"X Position (cm)\")\n    ax2.set_ylabel(\"Y Position (cm)\")\n    ax2.set_title(\"Projected Positions on Track (Color Coded by Segment)\")\n    ax2.grid(True, alpha=0.3)\n    ax2.axis(\"equal\")\n\n    # Plot 3: Linear position over time (color coded by segment)\n    ax3 = axes[1, 0]\n    time_points = np.arange(len(linearized_df))\n\n    if len(segment_colors) &gt; 0:\n        # Plot each segment separately with different colors using scatter\n        for segment_id in unique_segments:\n            if segment_id &gt;= 0:  # Only plot valid segments\n                segment_mask = linearized_df[\"track_segment_id\"] == segment_id\n                if np.any(segment_mask):\n                    segment_times = time_points[segment_mask]\n                    segment_positions = linearized_df.loc[\n                        segment_mask, \"linear_position\"\n                    ]\n                    # Use the color directly from the colormap, not as a list\n                    segment_color = segment_colors[segment_id]\n                    ax3.scatter(\n                        segment_times,\n                        segment_positions,\n                        color=segment_color, \n                        s=1,\n                        alpha=0.7,\n                    )\n    else:\n        ax3.scatter(\n            time_points,\n            linearized_df[\"linear_position\"],\n            color=\"blue\", \n            s=1,\n            alpha=0.7,\n        )\n\n    ax3.set_xlabel(\"Time Point\")\n    ax3.set_ylabel(\"Linear Position (cm)\")\n    ax3.set_title(\"Linear Position Over Time (Color Coded by Segment)\")\n    ax3.grid(True, alpha=0.3)\n\n    # Plot 4: Track segment distribution (color coded)\n    ax4 = axes[1, 1]\n    segment_counts = linearized_df[\"track_segment_id\"].value_counts().sort_index()\n\n    if len(segment_colors) &gt; 0:\n        # Color code the bars by segment\n        bar_colors = [segment_colors.get(seg, \"gray\") for seg in segment_counts.index]\n        ax4.bar(\n            segment_counts.index, segment_counts.values, alpha=0.7, color=bar_colors\n        )\n    else:\n        ax4.bar(segment_counts.index, segment_counts.values, alpha=0.7, color=\"orange\")\n\n    ax4.set_xlabel(\"Track Segment ID\")\n    ax4.set_ylabel(\"Number of Positions\")\n    ax4.set_title(\"Distribution Across Track Segments (Color Coded)\")\n    ax4.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n\n    if show_plot:\n        plt.show(block=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.project_position_to_track","title":"<code>project_position_to_track(position, track_graph)</code>","text":"<p>Project 2D positions onto the track graph.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ndarray</code> <p>Array of 2D positions (n_positions, 2)</p> required <code>track_graph</code> <code>TrackGraph</code> <p>Track graph object</p> required <p>Returns:</p> Name Type Description <code>linear_position</code> <code>ndarray</code> <p>Linearized positions along the track</p> <code>track_segment_id</code> <code>ndarray</code> <p>Track segment IDs for each position</p> <code>projected_position</code> <code>ndarray</code> <p>Projected 2D positions on the track</p> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def project_position_to_track(\n    position: np.ndarray, track_graph: TrackGraph\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Project 2D positions onto the track graph.\n\n    Parameters\n    ----------\n    position : np.ndarray\n        Array of 2D positions (n_positions, 2)\n    track_graph : TrackGraph\n        Track graph object\n\n    Returns\n    -------\n    linear_position : np.ndarray\n        Linearized positions along the track\n    track_segment_id : np.ndarray\n        Track segment IDs for each position\n    projected_position : np.ndarray\n        Projected 2D positions on the track\n    \"\"\"\n    n_positions = position.shape[0]\n    linear_position = np.full(n_positions, np.nan)\n    track_segment_id = np.full(n_positions, -1, dtype=int)\n    projected_position = np.full((n_positions, 2), np.nan)\n\n    for i, pos in enumerate(position):\n        # Find closest node\n        distances_to_nodes = np.linalg.norm(track_graph.node_positions - pos, axis=1)\n        closest_node = np.argmin(distances_to_nodes)\n\n        # Find closest edge\n        min_distance = np.inf\n        best_segment = -1\n        best_projection = None\n\n        for edge_idx, edge in enumerate(track_graph.edges):\n            if len(edge) &gt;= 2:\n                for j in range(len(edge) - 1):\n                    node1, node2 = edge[j], edge[j + 1]\n                    p1 = track_graph.node_positions[node1]\n                    p2 = track_graph.node_positions[node2]\n\n                    # Project point onto line segment\n                    v = p2 - p1\n                    u = pos - p1\n                    t = np.dot(u, v) / np.dot(v, v)\n                    t = np.clip(t, 0, 1)\n\n                    projection = p1 + t * v\n                    distance = np.linalg.norm(pos - projection)\n\n                    if distance &lt; min_distance:\n                        min_distance = distance\n                        best_segment = edge_idx\n                        best_projection = projection\n\n        if best_segment &gt;= 0 and best_projection is not None:\n            # Calculate linear position\n            edge = track_graph.edges[best_segment]\n            for j in range(len(edge) - 1):\n                node1, node2 = edge[j], edge[j + 1]\n                p1 = track_graph.node_positions[node1]\n                p2 = track_graph.node_positions[node2]\n\n                # Check if projection is on this segment\n                v = p2 - p1\n                u = best_projection - p1\n                t = np.dot(u, v) / np.dot(v, v)\n\n                if 0 &lt;= t &lt;= 1:\n                    # Linear position is cumulative distance to node1 + distance along segment\n                    linear_position[i] = track_graph.cumulative_distances[\n                        node1\n                    ] + t * np.linalg.norm(v)\n                    track_segment_id[i] = best_segment\n                    projected_position[i] = best_projection\n                    break\n\n    return linear_position, track_segment_id, projected_position\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization/#neuro_py.behavior.linearization.run","title":"<code>run(basepath, epoch=None, interval=None)</code>","text":"<p>Run the linearization pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the data files are located.</p> required <code>epoch</code> <code>int</code> <p>The epoch number to process, by default None.</p> <code>None</code> <code>interval</code> <code>Tuple[float, float]</code> <p>Time interval to process, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/behavior/linearization.py</code> <pre><code>def run(\n    basepath: str,\n    epoch: Optional[int] = None,\n    interval: Optional[Tuple[float, float]] = None,\n) -&gt; None:\n    \"\"\"\n    Run the linearization pipeline.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the data files are located.\n    epoch : int, optional\n        The epoch number to process, by default None.\n    interval : Tuple[float, float], optional\n        Time interval to process, by default None.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    plt.close(\"all\")\n    print(\"here is the file,\", basepath)\n\n    with plt.style.context(\"dark_background\"):\n        plt.ioff()\n\n        _, ax = plt.subplots(figsize=(5, 5))\n\n        behave_df = load_animal_behavior(basepath)\n\n        if epoch is not None:\n            epochs = load_epoch(basepath)\n\n            behave_df = behave_df[\n                behave_df[\"time\"].between(\n                    epochs.iloc[epoch].startTime, epochs.iloc[epoch].stopTime\n                )\n            ]\n        elif interval is not None:\n            behave_df = behave_df[behave_df[\"time\"].between(interval[0], interval[1])]\n\n        ax.scatter(behave_df.x, behave_df.y, color=\"white\", s=0.5, alpha=0.5)\n        ax.axis(\"equal\")\n        ax.set_axisbelow(True)\n        ax.yaxis.grid(color=\"gray\", linestyle=\"dashed\")\n        ax.xaxis.grid(color=\"gray\", linestyle=\"dashed\")\n        ax.set_ylabel(\"y (cm)\")\n        ax.set_xlabel(\"x (cm)\")\n\n        picker = NodePicker(ax=ax, basepath=basepath, epoch=epoch, interval=interval)\n        picker.connect()  # Ensure connection\n\n        plt.show(block=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/","title":"neuro_py.behavior.linearization_pipeline","text":""},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker","title":"<code>NodePicker</code>","text":"<p>Interactive creation of track graph by looking at video frames.</p> <p>.. deprecated:: 1.0     This class is deprecated. Use the new implementation in     :mod:<code>neuro_py.behavior.linearization</code> instead, which provides     improved functionality including HMM-based linearization.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on, by default None.</p> <code>None</code> <code>basepath</code> <code>str</code> <p>The base path for saving data, by default None.</p> <code>None</code> <code>node_color</code> <code>str</code> <p>The color of the nodes, by default \"#177ee6\".</p> <code>'#177ee6'</code> <code>node_size</code> <code>int</code> <p>The size of the nodes, by default 100.</p> <code>100</code> <code>epoch</code> <code>int</code> <p>The epoch number, by default None.</p> <code>None</code> <code>interval</code> <code>Tuple[float, float]</code> <code>None</code> <p>Attributes:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The matplotlib axes to draw on.</p> <code>canvas</code> <code>FigureCanvas</code> <p>The matplotlib figure canvas.</p> <code>cid</code> <code>int</code> <p>The connection id for the event handler.</p> <code>_nodes</code> <code>list</code> <p>The list of node positions.</p> <code>node_color</code> <code>str</code> <p>The color of the nodes.</p> <code>_nodes_plot</code> <code>scatter</code> <p>The scatter plot of the nodes.</p> <code>edges</code> <code>list</code> <p>The list of edges.</p> <code>basepath</code> <code>str</code> <p>The base path for saving data.</p> <code>epoch</code> <code>int</code> <p>The epoch number.</p> <code>use_HMM</code> <code>bool</code> <p>Whether to use the hidden markov model.</p> <p>Methods:</p> Name Description <code>node_positions</code> <p>Get the positions of the nodes.</p> <code>connect</code> <p>Connect the event handlers.</p> <code>disconnect</code> <p>Disconnect the event handlers.</p> <code>process_key</code> <p>Process key press events.</p> <code>click_event</code> <p>Process mouse click events.</p> <code>redraw</code> <p>Redraw the nodes and edges.</p> <code>remove_point</code> <p>Remove a point from the nodes.</p> <code>clear</code> <p>Clear all nodes and edges.</p> <code>format_and_save</code> <p>Format the data and save it to disk.</p> <code>save_nodes_edges</code> <p>Save the nodes and edges to a pickle file.</p> <code>save_nodes_edges_to_behavior</code> <p>Store nodes and edges into behavior file.</p> <p>Examples:</p>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker--in-command-line","title":"in command line","text":"<pre><code>&gt;&gt;&gt; python linearization_pipeline.py path/to/session\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker--for-a-specific-epoch","title":"for a specific epoch","text":"<pre><code>&gt;&gt;&gt; python linearization_pipeline.py path/to/session 1\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker--for-a-specific-interval","title":"for a specific interval","text":"<pre><code>&gt;&gt;&gt; python linearization_pipeline.py path/to/session 0 100\n</code></pre> References <p>https://github.com/LorenFrankLab/track_linearization</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>class NodePicker:\n    \"\"\"\n    Interactive creation of track graph by looking at video frames.\n\n    .. deprecated:: 1.0\n        This class is deprecated. Use the new implementation in\n        :mod:`neuro_py.behavior.linearization` instead, which provides\n        improved functionality including HMM-based linearization.\n\n    Parameters\n    ----------\n    ax : plt.Axes, optional\n        The matplotlib axes to draw on, by default None.\n    basepath : str, optional\n        The base path for saving data, by default None.\n    node_color : str, optional\n        The color of the nodes, by default \"#177ee6\".\n    node_size : int, optional\n        The size of the nodes, by default 100.\n    epoch : int, optional\n        The epoch number, by default None.\n    interval : Tuple[float, float], optional\n\n    Attributes\n    ----------\n    ax : plt.Axes\n        The matplotlib axes to draw on.\n    canvas : plt.FigureCanvas\n        The matplotlib figure canvas.\n    cid : int\n        The connection id for the event handler.\n    _nodes : list\n        The list of node positions.\n    node_color : str\n        The color of the nodes.\n    _nodes_plot : plt.scatter\n        The scatter plot of the nodes.\n    edges : list\n        The list of edges.\n    basepath : str\n        The base path for saving data.\n    epoch : int\n        The epoch number.\n    use_HMM : bool\n        Whether to use the hidden markov model.\n\n    Methods\n    -------\n    node_positions\n        Get the positions of the nodes.\n    connect\n        Connect the event handlers.\n    disconnect\n        Disconnect the event handlers.\n    process_key\n        Process key press events.\n    click_event\n        Process mouse click events.\n    redraw\n        Redraw the nodes and edges.\n    remove_point\n        Remove a point from the nodes.\n    clear\n        Clear all nodes and edges.\n    format_and_save\n        Format the data and save it to disk.\n    save_nodes_edges\n        Save the nodes and edges to a pickle file.\n    save_nodes_edges_to_behavior\n        Store nodes and edges into behavior file.\n\n    Examples\n    --------\n    # in command line\n    &gt;&gt;&gt; python linearization_pipeline.py path/to/session\n\n    # for a specific epoch\n    &gt;&gt;&gt; python linearization_pipeline.py path/to/session 1\n\n    # for a specific interval\n    &gt;&gt;&gt; python linearization_pipeline.py path/to/session 0 100\n\n    References\n    ----------\n    https://github.com/LorenFrankLab/track_linearization\n\n    \"\"\"\n\n    def __init__(\n        self,\n        ax: Optional[plt.Axes] = None,\n        basepath: Optional[str] = None,\n        node_color: str = \"#177ee6\",\n        node_size: int = 100,\n        epoch: Optional[int] = None,\n        interval: Optional[Tuple[float, float]] = None,\n    ):\n        \"\"\"\n        Initialize the NodePicker.\n\n        Parameters\n        ----------\n        ax : plt.Axes, optional\n            The matplotlib axes to draw on, by default None.\n        basepath : str, optional\n            The base path for saving data, by default None.\n        node_color : str, optional\n            The color of the nodes, by default \"#177ee6\".\n        node_size : int, optional\n            The size of the nodes, by default 100.\n        epoch : int, optional\n            The epoch number, by default None.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n        self.ax = ax\n        self.canvas = ax.get_figure().canvas\n        self.cid = None\n        self._nodes = []\n        self.node_color = node_color\n        self._nodes_plot = ax.scatter([], [], zorder=5, s=node_size, color=node_color)\n        self.edges = [[]]\n        self.basepath = basepath\n        self.epoch = epoch\n        self.interval = interval\n        self.use_HMM = False\n\n        if self.epoch is not None:\n            self.epoch = int(self.epoch)\n\n        ax.set_title(\n            \"Left click to place node.\\nRight click to remove node.\"\n            \"\\nShift+Left click to clear nodes.\\nCntrl+Left click two nodes to place an edge\"\n            \"\\nEnter to save and exit.\",\n            fontsize=8,\n        )\n\n        self.canvas.draw()\n\n        self.connect()\n\n    @property\n    def node_positions(self) -&gt; np.ndarray:\n        \"\"\"\n        Get the positions of the nodes.\n\n        Returns\n        -------\n        np.ndarray\n            An array of node positions.\n        \"\"\"\n        return np.asarray(self._nodes)\n\n    def connect(self) -&gt; None:\n        \"\"\"\n        Connect the event handlers.\n        \"\"\"\n        print(\"Connecting to events\")\n        if self.cid is None:\n            self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n            self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n            print(\"Mouse click event connected!\")  # Debugging\n\n    def disconnect(self) -&gt; None:\n        \"\"\"\n        Disconnect the event handlers.\n        \"\"\"\n        if self.cid is not None:\n            self.canvas.mpl_disconnect(self.cid)\n            self.cid = None\n\n    def process_key(self, event: Any) -&gt; None:\n        \"\"\"\n        Process key press events.\n\n        Parameters\n        ----------\n        event : Any\n            The key press event.\n        \"\"\"\n        if event.key == \"enter\":\n            self.format_and_save()\n\n    def click_event(self, event: Any) -&gt; None:\n        \"\"\"\n        Process mouse click events.\n\n        Parameters\n        ----------\n        event : Any\n            The mouse click event.\n        \"\"\"\n\n        print(\n            f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n        )  # Debugging\n        if not event.inaxes:\n            return\n\n        if event.key is None:  # Regular mouse clicks\n            if event.button == 1:  # Left click\n                self._nodes.append((event.xdata, event.ydata))\n            elif event.button == 3:  # Right click\n                self.remove_point((event.xdata, event.ydata))\n\n        elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n            self.clear()\n\n        elif (\n            event.key == \"control\" and event.button == 1\n        ):  # Ctrl + Left click (Edge creation)\n            if len(self._nodes) == 0:\n                return\n            point = (event.xdata, event.ydata)\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            if len(self.edges[-1]) &lt; 2:\n                self.edges[-1].append(closest_node_ind)\n            else:\n                self.edges.append([closest_node_ind])\n\n        elif event.key == \"enter\":  # Pressing Enter\n            self.format_and_save()\n\n        self.redraw()\n\n    def redraw(self) -&gt; None:\n        \"\"\"\n        Redraw the nodes and edges.\n        \"\"\"\n        # Draw Node Circles\n        if len(self.node_positions) &gt; 0:\n            self._nodes_plot.set_offsets(self.node_positions)\n        else:\n            self._nodes_plot.set_offsets([])\n\n        # Draw Node Numbers\n        for ind, (x, y) in enumerate(self.node_positions):\n            self.ax.text(\n                x,\n                y,\n                ind,\n                zorder=6,\n                fontsize=10,\n                horizontalalignment=\"center\",\n                verticalalignment=\"center\",\n                clip_on=True,\n                bbox=None,\n                transform=self.ax.transData,\n            )\n        # Draw Edges\n        for edge in self.edges:\n            if len(edge) &gt; 1:\n                x1, y1 = self.node_positions[edge[0]]\n                x2, y2 = self.node_positions[edge[1]]\n                self.ax.plot(\n                    [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n                )\n        self.canvas.draw()\n\n    def remove_point(self, point: Tuple[float, float]) -&gt; None:\n        \"\"\"\n        Remove a point from the nodes.\n\n        Parameters\n        ----------\n        point : Tuple[float, float]\n            The point to remove.\n        \"\"\"\n        if len(self._nodes) &gt; 0:\n            distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n            closest_node_ind = np.argmin(distance_to_nodes)\n            self._nodes.pop(closest_node_ind)\n\n    def clear(self) -&gt; None:\n        \"\"\"\n        Clear all nodes and edges.\n        \"\"\"\n        self._nodes = []\n        self.edges = [[]]\n        self.redraw()\n\n    def format_and_save(self) -&gt; None:\n        \"\"\"\n        Format the data and save it to disk.\n        \"\"\"\n        behave_df = load_animal_behavior(self.basepath)\n\n        if self.epoch is not None:\n            epochs = load_epoch(self.basepath)\n\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n                &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n            )\n        elif self.interval is not None:\n            cur_epoch = (\n                ~np.isnan(behave_df.x)\n                &amp; (behave_df.time &gt;= self.interval[0])\n                &amp; (behave_df.time &lt;= self.interval[1])\n            )\n        else:\n            cur_epoch = ~np.isnan(behave_df.x)\n\n        print(\"running hmm...\")\n        track_graph = make_track_graph(self.node_positions, self.edges)\n\n        position = np.vstack(\n            [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n        ).T\n\n        position_df = get_linearized_position(\n            position=position,\n            track_graph=track_graph,\n            edge_order=self.edges,\n            use_HMM=self.use_HMM,\n        )\n\n        print(\"saving to disk...\")\n        behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n        behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n        behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n            position_df.projected_x_position.values\n        )\n        behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n            position_df.projected_y_position.values\n        )\n\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n        )\n\n        data = loadmat(filename, simplify_cells=True)\n\n        data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n        data[\"behavior\"][\"states\"] = behave_df.states.values\n        data[\"behavior\"][\"position\"][\"projected_x\"] = (\n            behave_df.projected_x_position.values\n        )\n        data[\"behavior\"][\"position\"][\"projected_y\"] = (\n            behave_df.projected_y_position.values\n        )\n\n        # store nodes and edges within behavior file\n        data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n        savemat(filename, data, long_field_names=True)\n\n        self.save_nodes_edges()\n        self.disconnect()\n        plt.close()\n\n    def save_nodes_edges(self) -&gt; None:\n        \"\"\"\n        Save the nodes and edges to a pickle file.\n        \"\"\"\n        results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n        save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n        with open(save_file, \"wb\") as f:\n            pickle.dump(results, f)\n\n    def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n        \"\"\"\n        Store nodes and edges into behavior file.\n        Searches to find epochs with valid linearized coords.\n        Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n        Parameters\n        ----------\n        data : dict\n            The behavior data dictionary.\n        behave_df : pd.DataFrame\n            The DataFrame containing behavior data.\n\n        Returns\n        -------\n        dict\n            The updated behavior data dictionary.\n        \"\"\"\n        if self.epoch is None and self.interval is None:\n            # load epochs\n            epochs = load_epoch(self.basepath)\n            # iter over each epoch\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # locate index for given epoch\n                idx = behave_df.time.between(ep.startTime, ep.stopTime)\n                # if linearized is not all nan, add nodes and edges\n                if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                    behave_df[idx].shape[0] != 0\n                ):\n                    # adding nodes and edges\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        elif self.interval is not None:\n            # if interval was used, add nodes and edges just the epochs within that interval\n            epochs = load_epoch(self.basepath)\n            for epoch_i, ep in enumerate(epochs.itertuples()):\n                # amount of overlap between interval and epoch\n                start_overlap = max(self.interval[0], ep.startTime)\n                end_overlap = min(self.interval[1], ep.stopTime)\n                overlap = max(0, end_overlap - start_overlap)\n\n                # if overlap is greater than 1 second, add nodes and edges\n                if overlap &gt; 1:\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                        self.node_positions\n                    )\n                    data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n        else:\n            # if epoch was used, add nodes and edges just that that epoch\n            data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n                self.node_positions\n            )\n            data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n        return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.node_positions","title":"<code>node_positions</code>  <code>property</code>","text":"<p>Get the positions of the nodes.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of node positions.</p>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.clear","title":"<code>clear()</code>","text":"<p>Clear all nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clear all nodes and edges.\n    \"\"\"\n    self._nodes = []\n    self.edges = [[]]\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.click_event","title":"<code>click_event(event)</code>","text":"<p>Process mouse click events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The mouse click event.</p> required Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def click_event(self, event: Any) -&gt; None:\n    \"\"\"\n    Process mouse click events.\n\n    Parameters\n    ----------\n    event : Any\n        The mouse click event.\n    \"\"\"\n\n    print(\n        f\"Mouse clicked at: {event.xdata}, {event.ydata}, button: {event.button}, key: {event.key}\"\n    )  # Debugging\n    if not event.inaxes:\n        return\n\n    if event.key is None:  # Regular mouse clicks\n        if event.button == 1:  # Left click\n            self._nodes.append((event.xdata, event.ydata))\n        elif event.button == 3:  # Right click\n            self.remove_point((event.xdata, event.ydata))\n\n    elif event.key == \"shift\" and event.button == 1:  # Shift + Left click\n        self.clear()\n\n    elif (\n        event.key == \"control\" and event.button == 1\n    ):  # Ctrl + Left click (Edge creation)\n        if len(self._nodes) == 0:\n            return\n        point = (event.xdata, event.ydata)\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        if len(self.edges[-1]) &lt; 2:\n            self.edges[-1].append(closest_node_ind)\n        else:\n            self.edges.append([closest_node_ind])\n\n    elif event.key == \"enter\":  # Pressing Enter\n        self.format_and_save()\n\n    self.redraw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.connect","title":"<code>connect()</code>","text":"<p>Connect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def connect(self) -&gt; None:\n    \"\"\"\n    Connect the event handlers.\n    \"\"\"\n    print(\"Connecting to events\")\n    if self.cid is None:\n        self.cid = self.canvas.mpl_connect(\"button_press_event\", self.click_event)\n        self.canvas.mpl_connect(\"key_press_event\", self.process_key)\n        print(\"Mouse click event connected!\")  # Debugging\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.disconnect","title":"<code>disconnect()</code>","text":"<p>Disconnect the event handlers.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def disconnect(self) -&gt; None:\n    \"\"\"\n    Disconnect the event handlers.\n    \"\"\"\n    if self.cid is not None:\n        self.canvas.mpl_disconnect(self.cid)\n        self.cid = None\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.format_and_save","title":"<code>format_and_save()</code>","text":"<p>Format the data and save it to disk.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def format_and_save(self) -&gt; None:\n    \"\"\"\n    Format the data and save it to disk.\n    \"\"\"\n    behave_df = load_animal_behavior(self.basepath)\n\n    if self.epoch is not None:\n        epochs = load_epoch(self.basepath)\n\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= epochs.iloc[self.epoch].startTime)\n            &amp; (behave_df.time &lt;= epochs.iloc[self.epoch].stopTime)\n        )\n    elif self.interval is not None:\n        cur_epoch = (\n            ~np.isnan(behave_df.x)\n            &amp; (behave_df.time &gt;= self.interval[0])\n            &amp; (behave_df.time &lt;= self.interval[1])\n        )\n    else:\n        cur_epoch = ~np.isnan(behave_df.x)\n\n    print(\"running hmm...\")\n    track_graph = make_track_graph(self.node_positions, self.edges)\n\n    position = np.vstack(\n        [behave_df[cur_epoch].x.values, behave_df[cur_epoch].y.values]\n    ).T\n\n    position_df = get_linearized_position(\n        position=position,\n        track_graph=track_graph,\n        edge_order=self.edges,\n        use_HMM=self.use_HMM,\n    )\n\n    print(\"saving to disk...\")\n    behave_df.loc[cur_epoch, \"linearized\"] = position_df.linear_position.values\n    behave_df.loc[cur_epoch, \"states\"] = position_df.track_segment_id.values\n    behave_df.loc[cur_epoch, \"projected_x_position\"] = (\n        position_df.projected_x_position.values\n    )\n    behave_df.loc[cur_epoch, \"projected_y_position\"] = (\n        position_df.projected_y_position.values\n    )\n\n    filename = os.path.join(\n        self.basepath, os.path.basename(self.basepath) + \".animal.behavior.mat\"\n    )\n\n    data = loadmat(filename, simplify_cells=True)\n\n    data[\"behavior\"][\"position\"][\"linearized\"] = behave_df.linearized.values\n    data[\"behavior\"][\"states\"] = behave_df.states.values\n    data[\"behavior\"][\"position\"][\"projected_x\"] = (\n        behave_df.projected_x_position.values\n    )\n    data[\"behavior\"][\"position\"][\"projected_y\"] = (\n        behave_df.projected_y_position.values\n    )\n\n    # store nodes and edges within behavior file\n    data = self.save_nodes_edges_to_behavior(data, behave_df)\n\n    savemat(filename, data, long_field_names=True)\n\n    self.save_nodes_edges()\n    self.disconnect()\n    plt.close()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.process_key","title":"<code>process_key(event)</code>","text":"<p>Process key press events.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>The key press event.</p> required Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def process_key(self, event: Any) -&gt; None:\n    \"\"\"\n    Process key press events.\n\n    Parameters\n    ----------\n    event : Any\n        The key press event.\n    \"\"\"\n    if event.key == \"enter\":\n        self.format_and_save()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.redraw","title":"<code>redraw()</code>","text":"<p>Redraw the nodes and edges.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def redraw(self) -&gt; None:\n    \"\"\"\n    Redraw the nodes and edges.\n    \"\"\"\n    # Draw Node Circles\n    if len(self.node_positions) &gt; 0:\n        self._nodes_plot.set_offsets(self.node_positions)\n    else:\n        self._nodes_plot.set_offsets([])\n\n    # Draw Node Numbers\n    for ind, (x, y) in enumerate(self.node_positions):\n        self.ax.text(\n            x,\n            y,\n            ind,\n            zorder=6,\n            fontsize=10,\n            horizontalalignment=\"center\",\n            verticalalignment=\"center\",\n            clip_on=True,\n            bbox=None,\n            transform=self.ax.transData,\n        )\n    # Draw Edges\n    for edge in self.edges:\n        if len(edge) &gt; 1:\n            x1, y1 = self.node_positions[edge[0]]\n            x2, y2 = self.node_positions[edge[1]]\n            self.ax.plot(\n                [x1, x2], [y1, y2], color=\"#1f8e4f\", linewidth=3, zorder=1000\n            )\n    self.canvas.draw()\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.remove_point","title":"<code>remove_point(point)</code>","text":"<p>Remove a point from the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>Tuple[float, float]</code> <p>The point to remove.</p> required Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def remove_point(self, point: Tuple[float, float]) -&gt; None:\n    \"\"\"\n    Remove a point from the nodes.\n\n    Parameters\n    ----------\n    point : Tuple[float, float]\n        The point to remove.\n    \"\"\"\n    if len(self._nodes) &gt; 0:\n        distance_to_nodes = np.linalg.norm(self.node_positions - point, axis=1)\n        closest_node_ind = np.argmin(distance_to_nodes)\n        self._nodes.pop(closest_node_ind)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.save_nodes_edges","title":"<code>save_nodes_edges()</code>","text":"<p>Save the nodes and edges to a pickle file.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def save_nodes_edges(self) -&gt; None:\n    \"\"\"\n    Save the nodes and edges to a pickle file.\n    \"\"\"\n    results = {\"node_positions\": self.node_positions, \"edges\": self.edges}\n    save_file = os.path.join(self.basepath, \"linearization_nodes_edges.pkl\")\n    with open(save_file, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.NodePicker.save_nodes_edges_to_behavior","title":"<code>save_nodes_edges_to_behavior(data, behave_df)</code>","text":"<p>Store nodes and edges into behavior file. Searches to find epochs with valid linearized coords. Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>The behavior data dictionary.</p> required <code>behave_df</code> <code>DataFrame</code> <p>The DataFrame containing behavior data.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The updated behavior data dictionary.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def save_nodes_edges_to_behavior(self, data: dict, behave_df: pd.DataFrame) -&gt; dict:\n    \"\"\"\n    Store nodes and edges into behavior file.\n    Searches to find epochs with valid linearized coords.\n    Nodes and edges are stored within behavior.epochs{n}.{node_positions and edges}\n\n    Parameters\n    ----------\n    data : dict\n        The behavior data dictionary.\n    behave_df : pd.DataFrame\n        The DataFrame containing behavior data.\n\n    Returns\n    -------\n    dict\n        The updated behavior data dictionary.\n    \"\"\"\n    if self.epoch is None and self.interval is None:\n        # load epochs\n        epochs = load_epoch(self.basepath)\n        # iter over each epoch\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # locate index for given epoch\n            idx = behave_df.time.between(ep.startTime, ep.stopTime)\n            # if linearized is not all nan, add nodes and edges\n            if not all(np.isnan(behave_df[idx].linearized)) &amp; (\n                behave_df[idx].shape[0] != 0\n            ):\n                # adding nodes and edges\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    elif self.interval is not None:\n        # if interval was used, add nodes and edges just the epochs within that interval\n        epochs = load_epoch(self.basepath)\n        for epoch_i, ep in enumerate(epochs.itertuples()):\n            # amount of overlap between interval and epoch\n            start_overlap = max(self.interval[0], ep.startTime)\n            end_overlap = min(self.interval[1], ep.stopTime)\n            overlap = max(0, end_overlap - start_overlap)\n\n            # if overlap is greater than 1 second, add nodes and edges\n            if overlap &gt; 1:\n                data[\"behavior\"][\"epochs\"][epoch_i][\"node_positions\"] = (\n                    self.node_positions\n                )\n                data[\"behavior\"][\"epochs\"][epoch_i][\"edges\"] = self.edges\n    else:\n        # if epoch was used, add nodes and edges just that that epoch\n        data[\"behavior\"][\"epochs\"][self.epoch][\"node_positions\"] = (\n            self.node_positions\n        )\n        data[\"behavior\"][\"epochs\"][self.epoch][\"edges\"] = self.edges\n\n    return data\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.load_animal_behavior","title":"<code>load_animal_behavior(basepath)</code>","text":"<p>Load animal behavior data from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the .mat file is located.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the animal behavior data.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def load_animal_behavior(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load animal behavior data from a .mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the .mat file is located.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the animal behavior data.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n    data = loadmat(filename, simplify_cells=True)\n    df = pd.DataFrame()\n    df[\"time\"] = data[\"behavior\"][\"timestamps\"]\n    try:\n        df[\"states\"] = data[\"behavior\"][\"states\"]\n    except Exception:\n        pass\n    for key in data[\"behavior\"][\"position\"].keys():\n        try:\n            df[key] = data[\"behavior\"][\"position\"][key]\n        except Exception:\n            pass\n    return df\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.load_epoch","title":"<code>load_epoch(basepath)</code>","text":"<p>Load epoch info from cell explorer basename.session and store in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the .session.mat file is located.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the epoch information.</p> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def load_epoch(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load epoch info from cell explorer basename.session and store in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the .session.mat file is located.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the epoch information.\n    \"\"\"\n\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n    data = loadmat(filename, simplify_cells=True)\n    try:\n        return pd.DataFrame(data[\"session\"][\"epochs\"])\n    except Exception:\n        return pd.DataFrame([data[\"session\"][\"epochs\"]])\n</code></pre>"},{"location":"reference/neuro_py/behavior/linearization_pipeline/#neuro_py.behavior.linearization_pipeline.run","title":"<code>run(basepath, epoch=None, interval=None)</code>","text":"<p>Run the linearization pipeline.</p> <p>.. deprecated:: 1.0     This function is deprecated. Use the new implementation in     :mod:<code>neuro_py.behavior.linearization</code> instead, which provides     improved functionality including HMM-based linearization.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path where the data files are located.</p> required <code>epoch</code> <code>int</code> <p>The epoch number to process, by default None.</p> <code>None</code> <code>interval</code> <code>Tuple[float, float]</code> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/behavior/linearization_pipeline.py</code> <pre><code>def run(\n    basepath: str,\n    epoch: Optional[int] = None,\n    interval: Optional[Tuple[float, float]] = None,\n) -&gt; None:\n    \"\"\"\n    Run the linearization pipeline.\n\n    .. deprecated:: 1.0\n        This function is deprecated. Use the new implementation in\n        :mod:`neuro_py.behavior.linearization` instead, which provides\n        improved functionality including HMM-based linearization.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path where the data files are located.\n    epoch : int, optional\n        The epoch number to process, by default None.\n    interval : Tuple[float, float], optional\n\n    Returns\n    -------\n    None\n    \"\"\"\n    plt.close(\"all\")\n    print(\"here is the file,\", basepath)\n\n    with plt.style.context(\"dark_background\"):\n        plt.ioff()\n\n        _, ax = plt.subplots(figsize=(5, 5))\n\n        behave_df = load_animal_behavior(basepath)\n\n        if epoch is not None:\n            epochs = load_epoch(basepath)\n\n            behave_df = behave_df[\n                behave_df[\"time\"].between(\n                    epochs.iloc[epoch].startTime, epochs.iloc[epoch].stopTime\n                )\n            ]\n        elif interval is not None:\n            behave_df = behave_df[behave_df[\"time\"].between(interval[0], interval[1])]\n\n        ax.scatter(behave_df.x, behave_df.y, color=\"white\", s=0.5, alpha=0.5)\n        ax.axis(\"equal\")\n        ax.set_axisbelow(True)\n        ax.yaxis.grid(color=\"gray\", linestyle=\"dashed\")\n        ax.xaxis.grid(color=\"gray\", linestyle=\"dashed\")\n        ax.set_ylabel(\"y (cm)\")\n        ax.set_xlabel(\"x (cm)\")\n\n        picker = NodePicker(ax=ax, basepath=basepath, epoch=epoch, interval=interval)\n        picker.connect()  # Ensure connection\n\n        plt.show(block=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/preprocessing/","title":"neuro_py.behavior.preprocessing","text":""},{"location":"reference/neuro_py/behavior/preprocessing/#neuro_py.behavior.preprocessing.filter_tracker_jumps","title":"<code>filter_tracker_jumps(beh_df, max_speed=100)</code>","text":"<p>Filter out tracker jumps (to NaN) in the behavior data.</p> <p>Parameters:</p> Name Type Description Default <code>beh_df</code> <code>DataFrame</code> <p>Behavior data with columns x, y, and timestamps.</p> required <code>max_speed</code> <code>Union[int, float]</code> <p>Maximum allowed speed in cm per second.</p> <code>100</code> <p>Returns:</p> Type Description <code>DataFrame</code> Notes <p>Will force dtypes of x and y to float64</p> Source code in <code>neuro_py/behavior/preprocessing.py</code> <pre><code>def filter_tracker_jumps(\n    beh_df: pd.DataFrame, max_speed: Union[int, float] = 100\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Filter out tracker jumps (to NaN) in the behavior data.\n\n    Parameters\n    ----------\n    beh_df : pd.DataFrame\n        Behavior data with columns x, y, and timestamps.\n    max_speed : Union[int,float], optional\n        Maximum allowed speed in cm per second.\n\n    Returns\n    -------\n    pd.DataFrame\n\n    Notes\n    -----\n    Will force dtypes of x and y to float64\n    \"\"\"\n\n    # Calculate the Euclidean distance between consecutive points\n    beh_df[\"dx\"] = beh_df[\"x\"].diff()\n    beh_df[\"dy\"] = beh_df[\"y\"].diff()\n    beh_df[\"distance\"] = np.sqrt(beh_df[\"dx\"] ** 2 + beh_df[\"dy\"] ** 2)\n\n    # Calculate the time difference between consecutive timestamps\n    beh_df[\"dt\"] = beh_df[\"timestamps\"].diff()\n\n    # Calculate the speed between consecutive points (distance / time)\n    beh_df[\"speed\"] = beh_df[\"distance\"] / beh_df[\"dt\"]\n\n    # Identify the start of each jump\n    # A jump starts when the speed exceeds the threshold, and the previous speed did not\n    jump_starts = (beh_df[\"speed\"] &gt; max_speed) &amp; (\n        beh_df[\"speed\"].shift(1) &lt;= max_speed\n    )\n\n    # Mark x and y as NaN only for the first frame of each jump\n    beh_df.loc[jump_starts, [\"x\", \"y\"]] = np.nan\n\n    beh_df = beh_df.drop(columns=[\"dx\", \"dy\", \"distance\", \"dt\", \"speed\"])\n\n    return beh_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/preprocessing/#neuro_py.behavior.preprocessing.filter_tracker_jumps_in_file","title":"<code>filter_tracker_jumps_in_file(basepath, epoch_number=None, epoch_interval=None)</code>","text":"<p>Filter out tracker jumps in the behavior data (to NaN) and save the filtered data back to the file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Basepath to the behavior file.</p> required <code>epoch_number</code> <code>int</code> <p>Epoch number to filter the behavior data to.</p> <code>None</code> <code>epoch_interval</code> <code>tuple</code> <p>Epoch interval to filter the behavior data to.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = \"path/to/behavior/file\"\n&gt;&gt;&gt; filter_tracker_jumps_in_file(basepath, epoch_number=1)\n</code></pre> Source code in <code>neuro_py/behavior/preprocessing.py</code> <pre><code>def filter_tracker_jumps_in_file(\n    basepath: str, epoch_number=None, epoch_interval=None\n) -&gt; None:\n    \"\"\"\n    Filter out tracker jumps in the behavior data (to NaN) and save the filtered data back to the file.\n\n    Parameters\n    ----------\n    basepath : str\n        Basepath to the behavior file.\n    epoch_number : int, optional\n        Epoch number to filter the behavior data to.\n    epoch_interval : tuple, optional\n        Epoch interval to filter the behavior data to.\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; basepath = \"path/to/behavior/file\"\n    &gt;&gt;&gt; filter_tracker_jumps_in_file(basepath, epoch_number=1)\n    \"\"\"\n\n    # Load the behavior data\n    file = os.path.join(basepath, os.path.basename(basepath) + \".animal.behavior.mat\")\n\n    behavior = loadmat(file, simplify_cells=True)\n\n    # Filter the behavior data to remove tracker jumps\n    if epoch_number is not None:\n        epoch_df = npy.io.load_epoch(basepath)\n        idx = (\n            behavior[\"behavior\"][\"timestamps\"] &gt; epoch_df.loc[epoch_number].startTime\n        ) &amp; (behavior[\"behavior\"][\"timestamps\"] &lt; epoch_df.loc[epoch_number].stopTime)\n    elif epoch_interval is not None:\n        idx = (behavior[\"behavior\"][\"timestamps\"] &gt; epoch_interval[0]) &amp; (\n            behavior[\"behavior\"][\"timestamps\"] &lt; epoch_interval[1]\n        )\n    else:\n        # bool length of the same length as the number of timestamps\n        idx = np.ones(len(behavior[\"behavior\"][\"timestamps\"]), dtype=bool)\n\n    # Filter the behavior data and add to dataframe\n    x = behavior[\"behavior\"][\"position\"][\"x\"][idx]\n    y = behavior[\"behavior\"][\"position\"][\"y\"][idx]\n    ts = behavior[\"behavior\"][\"timestamps\"][idx]\n    beh_df = pd.DataFrame({\"x\": x, \"y\": y, \"timestamps\": ts})\n\n    # Filter out tracker jumps\n    beh_df = filter_tracker_jumps(beh_df)\n\n    # Save the filtered behavior data back to the file\n    behavior[\"behavior\"][\"position\"][\"x\"][idx] = beh_df.x.values\n    behavior[\"behavior\"][\"position\"][\"y\"][idx] = beh_df.y.values\n\n    savemat(file, behavior, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/","title":"neuro_py.behavior.well_traversal_classification","text":""},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.enter_exit_target","title":"<code>enter_exit_target(position, target, max_distance=1.0)</code>","text":"<p>Marks when a position has reached a target (\"enter\") and when it has left a target (\"exit\").</p> <p>The position is considered to have reached a target when it is less than the <code>max_distance</code> from the target.</p> <p>Enter and exit times are marked as follows:  1: entered the target radius  0: neither -1: exited the target radius</p> <p>Works for 1D position and 2D position.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <code>target</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (1, n_space).</p> required <code>max_distance</code> <code>float</code> <p>How close the position is to the target to be considered at the target, by default 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of two arrays: - The first array contains the enter/exit times. - The second array contains the times when the position is at the target.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def enter_exit_target(\n    position: Union[np.ndarray, list],\n    target: Union[np.ndarray, list],\n    max_distance: float = 1.0,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Marks when a position has reached a target (\"enter\") and when it has left a target (\"exit\").\n\n    The position is considered to have reached a target when it is less than\n    the `max_distance` from the target.\n\n    Enter and exit times are marked as follows:\n     1: entered the target radius\n     0: neither\n    -1: exited the target radius\n\n    Works for 1D position and 2D position.\n\n    Parameters\n    ----------\n    position : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n    target : Union[np.ndarray, list]\n        Array or list of shape (1, n_space).\n    max_distance : float, optional\n        How close the position is to the target to be considered at the target, by default 1.0.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple of two arrays:\n        - The first array contains the enter/exit times.\n        - The second array contains the times when the position is at the target.\n    \"\"\"\n    distance_from_target = paired_distances(position, target)\n    at_target = distance_from_target &lt; max_distance\n    enter_exit = np.r_[0, np.diff(at_target.astype(float))]\n    return enter_exit, at_target\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.enter_exit_target_dio","title":"<code>enter_exit_target_dio(dio_indicator)</code>","text":"<p>Marks when a digital input/output (DIO) indicator has entered or exited a target state.</p> <p>Parameters:</p> Name Type Description Default <code>dio_indicator</code> <code>ndarray</code> <p>Array of DIO indicator values.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing: - enter_exit: np.ndarray     Array indicating enter (1) and exit (-1) events. - at_target: np.ndarray     Array indicating whether the target is active (1) or not (0).</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def enter_exit_target_dio(dio_indicator: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Marks when a digital input/output (DIO) indicator has entered or exited a target state.\n\n    Parameters\n    ----------\n    dio_indicator : np.ndarray\n        Array of DIO indicator values.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing:\n        - enter_exit: np.ndarray\n            Array indicating enter (1) and exit (-1) events.\n        - at_target: np.ndarray\n            Array indicating whether the target is active (1) or not (0).\n    \"\"\"\n    at_target = (dio_indicator &gt; 0).astype(np.float16)\n    enter_exit = np.r_[0, np.diff(at_target)]\n    return enter_exit, at_target\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.find_last_non_center_well","title":"<code>find_last_non_center_well(segments_df, segment_ind)</code>","text":"<p>Find the last non-center well before the given segment index.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>DataFrame containing segment information.</p> required <code>segment_ind</code> <code>int</code> <p>The segment index to search up to.</p> required <p>Returns:</p> Type Description <code>Union[str, int]</code> <p>The last non-center well before the given segment index. If no non-center wells are found, returns an empty string.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def find_last_non_center_well(\n    segments_df: pd.DataFrame, segment_ind: int\n) -&gt; Union[str, int]:\n    \"\"\"\n    Find the last non-center well before the given segment index.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        DataFrame containing segment information.\n    segment_ind : int\n        The segment index to search up to.\n\n    Returns\n    -------\n    Union[str, int]\n        The last non-center well before the given segment index. If no non-center wells are found,\n        returns an empty string.\n    \"\"\"\n    last_wells = segments_df.iloc[:segment_ind].to_well\n    try:\n        return last_wells[last_wells != \"Center\"].iloc[-1]\n    except IndexError:\n        # There are no non-center wells. Just return current well.\n        return \"\"\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.get_correct_inbound_outbound","title":"<code>get_correct_inbound_outbound(segments_df)</code>","text":"<p>Determine the task type (inbound or outbound), correctness, and turn direction for each segment.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>DataFrame containing segment information.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Updated DataFrame with additional columns for task type, correctness, and turn direction.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def get_correct_inbound_outbound(segments_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Determine the task type (inbound or outbound), correctness, and turn direction for each segment.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        DataFrame containing segment information.\n\n    Returns\n    -------\n    pd.DataFrame\n        Updated DataFrame with additional columns for task type, correctness, and turn direction.\n    \"\"\"\n    n_segments = segments_df.shape[0]\n    task = np.empty((n_segments,), dtype=object)\n    turn = np.empty((n_segments,), dtype=object)\n    is_correct = np.zeros((n_segments,), dtype=bool)\n\n    for segment_ind in np.arange(n_segments):\n        cur_segment = segments_df.iloc[segment_ind]\n        if cur_segment.from_well == \"Center\":\n            task[segment_ind] = \"Outbound\"\n            last_non_center_well = find_last_non_center_well(segments_df, segment_ind)\n            is_correct[segment_ind] = (cur_segment.to_well != last_non_center_well) &amp; (\n                cur_segment.to_well != \"Center\"\n            )\n            if (last_non_center_well != \"\") | ~is_correct[segment_ind]:\n                turn[segment_ind] = last_non_center_well\n            else:\n                is_left_turn = (\n                    (cur_segment.from_well == \"Left\")\n                    &amp; (cur_segment.to_well == \"Center\")\n                ) | (\n                    (cur_segment.from_well == \"Center\")\n                    &amp; (cur_segment.to_well == \"Right\")\n                )\n\n                turn[segment_ind] = \"Left\" if is_left_turn else \"Right\"\n        else:\n            task[segment_ind] = \"Inbound\"\n            is_correct[segment_ind] = segments_df.iloc[segment_ind].to_well == \"Center\"\n            turn[segment_ind] = cur_segment.from_well\n\n    segments_df[\"task\"] = task\n    segments_df[\"is_correct\"] = is_correct\n    segments_df[\"turn\"] = turn\n\n    return segments_df\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.paired_distances","title":"<code>paired_distances(x, y)</code>","text":"<p>Euclidean distance between x and y at each time point.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <code>y</code> <code>Union[ndarray, list]</code> <p>Array or list of shape (n_time, n_space).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of shape (n_time,) containing the distances.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def paired_distances(\n    x: Union[np.ndarray, list], y: Union[np.ndarray, list]\n) -&gt; np.ndarray:\n    \"\"\"\n    Euclidean distance between x and y at each time point.\n\n    Parameters\n    ----------\n    x : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n    y : Union[np.ndarray, list]\n        Array or list of shape (n_time, n_space).\n\n    Returns\n    -------\n    np.ndarray\n        Array of shape (n_time,) containing the distances.\n    \"\"\"\n    x, y = np.array(x), np.array(y)\n    x = np.atleast_2d(x).T if x.ndim &lt; 2 else x\n    y = np.atleast_2d(y).T if y.ndim &lt; 2 else y\n    return np.linalg.norm(x - y, axis=1)\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.score_inbound_outbound","title":"<code>score_inbound_outbound(segments_df, min_distance_traveled=50, well_names={1: 'Center', 2: 'Left', 3: 'Right'})</code>","text":"<p>In the alternating arm task, determines whether the trial should be inbound (running to the center arm) or outbound (running to the opposite outer arm as before) and if the trial was performed correctly.</p> <p>Parameters:</p> Name Type Description Default <code>segments_df</code> <code>DataFrame</code> <p>Output of <code>segment_path</code> function.</p> required <code>min_distance_traveled</code> <code>float</code> <p>Minimum path length (in cm) while outside of the well radius for a segment to be considered as a trial, by default 50.</p> <code>50</code> <code>well_names</code> <code>Dict[int, str]</code> <p>Dictionary mapping well indices to well names, by default {1: \"Center\", 2: \"Left\", 3: \"Right\"}.</p> <code>{1: 'Center', 2: 'Left', 3: 'Right'}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Same as the input dataframe but with the wells labeled (left, right, center) and columns for <code>task</code> (inbound/outbound) and <code>is_correct</code> (True/False).</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def score_inbound_outbound(\n    segments_df: pd.DataFrame,\n    min_distance_traveled: float = 50,\n    well_names: Dict[int, str] = {1: \"Center\", 2: \"Left\", 3: \"Right\"},\n) -&gt; pd.DataFrame:\n    \"\"\"\n    In the alternating arm task, determines whether the trial should be\n    inbound (running to the center arm) or outbound (running to the opposite\n    outer arm as before) and if the trial was performed correctly.\n\n    Parameters\n    ----------\n    segments_df : pd.DataFrame\n        Output of `segment_path` function.\n    min_distance_traveled : float, optional\n        Minimum path length (in cm) while outside of the well radius for\n        a segment to be considered as a trial, by default 50.\n    well_names : Dict[int, str], optional\n        Dictionary mapping well indices to well names, by default {1: \"Center\", 2: \"Left\", 3: \"Right\"}.\n\n    Returns\n    -------\n    pd.DataFrame\n        Same as the input dataframe but with the wells labeled\n        (left, right, center) and columns for `task` (inbound/outbound) and\n        `is_correct` (True/False).\n    \"\"\"\n    segments_df = (\n        segments_df.copy()\n        .loc[segments_df.distance_traveled &gt; min_distance_traveled]\n        .dropna()\n    )\n    segments_df = segments_df.assign(\n        to_well=lambda df: df.to_well.map(well_names),\n        from_well=lambda df: df.from_well.map(well_names),\n    )\n    return get_correct_inbound_outbound(segments_df)\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.segment_path","title":"<code>segment_path(time, position, well_locations, max_distance_from_well=10)</code>","text":"<p>Label traversals between each well location.</p> <p>Parameters:</p> Name Type Description Default <code>time</code> <code>(ndarray, shape(n_time))</code> <p>Array of time points.</p> required <code>position</code> <code>(ndarray, shape(n_time, n_space))</code> <p>Array of positions at each time point.</p> required <code>well_locations</code> <code>(ndarray, shape(n_wells, n_space))</code> <p>Array of well locations.</p> required <code>max_distance_from_well</code> <code>float</code> <p>The animal is considered at a well location if its position is closer than this value, by default 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <ul> <li>segments_df: DataFrame of shape (n_segments, 6) containing segment information.</li> <li>labeled_segments: DataFrame of shape (n_time,) containing labeled segments.</li> </ul> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def segment_path(\n    time: np.ndarray,\n    position: np.ndarray,\n    well_locations: np.ndarray,\n    max_distance_from_well: float = 10,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Label traversals between each well location.\n\n    Parameters\n    ----------\n    time : np.ndarray, shape (n_time,)\n        Array of time points.\n    position : np.ndarray, shape (n_time, n_space)\n        Array of positions at each time point.\n    well_locations : np.ndarray, shape (n_wells, n_space)\n        Array of well locations.\n    max_distance_from_well : float, optional\n        The animal is considered at a well location if its position is closer\n        than this value, by default 10.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        - segments_df: DataFrame of shape (n_segments, 6) containing segment information.\n        - labeled_segments: DataFrame of shape (n_time,) containing labeled segments.\n    \"\"\"\n\n    well_enter_exit, at_target = np.stack(\n        [\n            enter_exit_target(position, np.atleast_2d(well), max_distance_from_well)\n            for well in well_locations\n        ],\n        axis=1,\n    )\n    n_wells = len(well_locations)\n    well_labels = np.arange(n_wells) + 1\n    well_enter_exit = np.sum(well_enter_exit.T * well_labels, axis=1)\n    shifted_well_enter_exit = shift_well_enters(well_enter_exit)\n    is_segment = ~(np.sum(at_target, axis=0) &gt; 0)\n    labeled_segments, n_segment_labels = label(is_segment)\n    segment_labels = np.arange(n_segment_labels) + 1\n\n    start_time, end_time, duration = [], [], []\n    distance_traveled, from_well, to_well = [], [], []\n\n    for segment_label in segment_labels:\n        is_seg = np.isin(labeled_segments, segment_label)\n        segment_time = time[is_seg]\n        start_time.append(segment_time.min())\n        end_time.append(segment_time.max())\n        duration.append(segment_time.max() - segment_time.min())\n        try:\n            start, _, end = np.unique(shifted_well_enter_exit[is_seg])\n        except ValueError:\n            start, end = np.nan, np.nan\n\n        from_well.append(np.abs(start))\n        to_well.append(np.abs(end))\n        p = position[is_seg]\n        distance_traveled.append(np.sum(paired_distances(p[1:], p[:-1])))\n\n    data = [\n        (\"start_time\", start_time),\n        (\"end_time\", end_time),\n        (\"duration\", duration),\n        (\"from_well\", from_well),\n        (\"to_well\", to_well),\n        (\"distance_traveled\", distance_traveled),\n    ]\n    index = pd.Index(segment_labels, name=\"segment\")\n    return (\n        pd.DataFrame.from_dict(dict(data)).set_index(index),\n        pd.DataFrame(dict(labeled_segments=labeled_segments), index=time),\n    )\n</code></pre>"},{"location":"reference/neuro_py/behavior/well_traversal_classification/#neuro_py.behavior.well_traversal_classification.shift_well_enters","title":"<code>shift_well_enters(enter_exit)</code>","text":"<p>Shifts the enter times back one time point.</p> <p>Parameters:</p> Name Type Description Default <code>enter_exit</code> <code>ndarray</code> <p>Array indicating enter (positive values) and exit (negative values) events.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with enter times shifted back by one time point.</p> Source code in <code>neuro_py/behavior/well_traversal_classification.py</code> <pre><code>def shift_well_enters(enter_exit: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Shifts the enter times back one time point.\n\n    Parameters\n    ----------\n    enter_exit : np.ndarray\n        Array indicating enter (positive values) and exit (negative values) events.\n\n    Returns\n    -------\n    np.ndarray\n        Array with enter times shifted back by one time point.\n    \"\"\"\n    shifted_enter_exit = enter_exit.copy()\n    old_ind = np.where(enter_exit &gt; 0)[0]  # positive entries are well-entries\n    new_ind = old_ind - 1\n    shifted_enter_exit[new_ind] = enter_exit[old_ind]\n    shifted_enter_exit[old_ind] = 0\n    return shifted_enter_exit\n</code></pre>"},{"location":"reference/neuro_py/detectors/","title":"neuro_py.detectors","text":""},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS","title":"<code>DetectDS</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for detecting dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the data</p> required <code>hilus_ch</code> <code>int</code> <p>Channel number of the hilus signal (0 indexing)</p> required <code>mol_ch</code> <code>int</code> <p>Channel number of the mol signal (0 indexing)</p> required <code>noise_ch</code> <code>int</code> <p>Channel number of the noise signal or signal far from dentate (0 indexing)</p> <code>None</code> <code>lowcut</code> <code>float</code> <p>Low cut frequency for the signal filter</p> <code>10</code> <code>highcut</code> <code>float</code> <p>High cut frequency for the signal filter</p> <code>250</code> <code>filter_signal_bool</code> <code>bool</code> <p>If True, the signal will be filtered</p> <code>True</code> <code>primary_threshold</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes (difference method only)</p> <code>5</code> <code>secondary_threshold</code> <code>float</code> <p>Secondary threshold for detecting the dentate spikes (difference method only)</p> required <code>primary_thres_mol</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes in the mol signal</p> <code>2</code> <code>primary_thres_hilus</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes in the hilus signal</p> <code>5</code> <code>min_duration</code> <code>float</code> <p>Minimum duration of the dentate spikes</p> <code>0.005</code> <code>max_duration</code> <code>float</code> <p>Maximum duration of the dentate spikes</p> <code>0.05</code> <code>filter_order</code> <code>int</code> <p>Order of the filter</p> <code>4</code> <code>filter_rs</code> <code>int</code> <p>Resonance frequency of the filter</p> <code>20</code> <code>method</code> <code>str</code> <p>Method for detecting the dentate spikes. \"difference\" for detecting the dentate spikes by difference between the hilus and mol signal \"seperately\" for detecting the dentate spikes by the hilus and mol signal separately</p> <code>'seperately'</code> <code>clean_lfp</code> <code>bool</code> <p>If True, the LFP signal will be cleaned</p> <code>False</code> <code>emg_threshold</code> <code>float</code> <p>Threshold for the EMG signal to remove dentate spikes</p> <code>0.9</code> <p>Attributes:</p> Name Type Description <code>lfp</code> <code>AnalogSignalArray</code> <p>LFP signal</p> <code>filtered_lfp</code> <code>AnalogSignalArray</code> <p>Filtered LFP signal</p> <code>mol_hilus_diff</code> <code>AnalogSignalArray</code> <p>Difference between the hilus and mol signal</p> <code>ds_epoch</code> <code>EpochArray</code> <p>EpochArray with the dentate spikes</p> <code>peak_val</code> <code>ndarray</code> <p>Peak value of the dentate spikes</p> <p>Methods:</p> Name Description <code>load_lfp</code> <p>Load the LFP signal</p> <code>filter_signal</code> <p>Filter the LFP signal</p> <code>get_filtered_lfp</code> <p>Get the filtered LFP signal</p> <code>get_lfp_diff</code> <p>Get the difference between the hilus and mol signal</p> <code>detect_ds_difference</code> <p>Detect the dentate spikes by difference between the hilus and mol signal</p> <code>detect_ds_seperately</code> <p>Detect the dentate spikes by the hilus and mol signal separately</p> <code>save_ds_epoch</code> <p>Save the dentate spikes as an EpochArray</p> <p>Examples:</p> <p>In IDE or python console</p> <pre><code>&gt;&gt;&gt; from ds_swr.detection.detect_dentate_spike import DetectDS\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; channel_tags = loading.load_channel_tags(basepath)\n&gt;&gt;&gt; dds = DetectDS(\n    basepath,\n    channel_tags[\"hilus\"][\"channels\"] - 1,\n    channel_tags[\"mol\"][\"channels\"] - 1\n)\n&gt;&gt;&gt; dds.detect_ds()\n&gt;&gt;&gt; dds.save_ds_epoch()\n&gt;&gt;&gt; dds\n&lt;DetectDS at 0x17fe787c640: dentate spikes 5,769&gt; of length 1:11:257 minutes\n</code></pre> <p>In command line</p> <pre><code>&gt;&gt;&gt; python detect_dentate_spike.py Z:\\Data\\Can\\OML22\\day20\n</code></pre> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>class DetectDS(object):\n    \"\"\"\n    Class for detecting dentate spikes\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the data\n    hilus_ch : int\n        Channel number of the hilus signal (0 indexing)\n    mol_ch : int\n        Channel number of the mol signal (0 indexing)\n    noise_ch : int, optional\n        Channel number of the noise signal or signal far from dentate (0 indexing)\n    lowcut : float, optional\n        Low cut frequency for the signal filter\n    highcut : float, optional\n        High cut frequency for the signal filter\n    filter_signal_bool : bool, optional\n        If True, the signal will be filtered\n    primary_threshold : float, optional\n        Primary threshold for detecting the dentate spikes (difference method only)\n    secondary_threshold : float, optional\n        Secondary threshold for detecting the dentate spikes (difference method only)\n    primary_thres_mol : float, optional\n        Primary threshold for detecting the dentate spikes in the mol signal\n    primary_thres_hilus : float, optional\n        Primary threshold for detecting the dentate spikes in the hilus signal\n    min_duration : float, optional\n        Minimum duration of the dentate spikes\n    max_duration : float, optional\n        Maximum duration of the dentate spikes\n    filter_order : int, optional\n        Order of the filter\n    filter_rs : int, optional\n        Resonance frequency of the filter\n    method : str, optional\n        Method for detecting the dentate spikes.\n        \"difference\" for detecting the dentate spikes by difference between the hilus and mol signal\n        \"seperately\" for detecting the dentate spikes by the hilus and mol signal separately\n    clean_lfp : bool, optional\n        If True, the LFP signal will be cleaned\n    emg_threshold : float, optional\n        Threshold for the EMG signal to remove dentate spikes\n\n\n    Attributes\n    ----------\n    lfp : nelpy.AnalogSignalArray\n        LFP signal\n    filtered_lfp : nelpy.AnalogSignalArray\n        Filtered LFP signal\n    mol_hilus_diff : nelpy.AnalogSignalArray\n        Difference between the hilus and mol signal\n    ds_epoch : nelpy.EpochArray\n        EpochArray with the dentate spikes\n    peak_val : np.ndarray\n        Peak value of the dentate spikes\n\n\n    Methods\n    -------\n    load_lfp()\n        Load the LFP signal\n    filter_signal()\n        Filter the LFP signal\n    get_filtered_lfp()\n        Get the filtered LFP signal\n    get_lfp_diff()\n        Get the difference between the hilus and mol signal\n    detect_ds_difference()\n        Detect the dentate spikes by difference between the hilus and mol signal\n    detect_ds_seperately()\n        Detect the dentate spikes by the hilus and mol signal separately\n    save_ds_epoch()\n        Save the dentate spikes as an EpochArray\n\n    Examples\n    --------\n    In IDE or python console\n\n    &gt;&gt;&gt; from ds_swr.detection.detect_dentate_spike import DetectDS\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; channel_tags = loading.load_channel_tags(basepath)\n    &gt;&gt;&gt; dds = DetectDS(\n        basepath,\n        channel_tags[\"hilus\"][\"channels\"] - 1,\n        channel_tags[\"mol\"][\"channels\"] - 1\n    )\n    &gt;&gt;&gt; dds.detect_ds()\n    &gt;&gt;&gt; dds.save_ds_epoch()\n    &gt;&gt;&gt; dds\n    &lt;DetectDS at 0x17fe787c640: dentate spikes 5,769&gt; of length 1:11:257 minutes\n\n\n    In command line\n\n    &gt;&gt;&gt; python detect_dentate_spike.py Z:\\Data\\Can\\OML22\\day20\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: str,\n        hilus_ch: int,\n        mol_ch: int,\n        noise_ch: Union[int, None] = None,\n        lowcut: int = 10,\n        highcut: int = 250,\n        filter_signal_bool: bool = True,\n        primary_threshold: Union[int, float] = 5,\n        primary_thres_mol: Union[int, float] = 2,\n        primary_thres_hilus: Union[int, float] = 5,\n        min_duration: float = 0.005,\n        max_duration: float = 0.05,\n        filter_order: int = 4,\n        filter_rs: int = 20,\n        method: str = \"seperately\",\n        clean_lfp: bool = False,\n        emg_threshold: float = 0.9,\n    ) -&gt; None:\n        # adding all the parameters to the class\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n        # setting the type name\n        self.type_name = self.__class__.__name__\n        self.get_xml_data()\n\n    def get_xml_data(self):\n        \"\"\"\n        Load the XML file to get the number of channels, sampling frequency and shank to channel mapping\n        \"\"\"\n        nChannels, fs, fs_dat, shank_to_channel = loading.loadXML(self.basepath)\n        self.nChannels = nChannels\n        self.fs = fs\n        self.fs_dat = fs_dat\n        self.shank_to_channel = shank_to_channel\n\n    def load_lfp(self):\n        \"\"\"\n        Load the LFP signal\n        \"\"\"\n\n        lfp, timestep = loading.loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            frequency=self.fs,\n            ext=\"lfp\",\n        )\n\n        if self.noise_ch is None:\n            channels = [self.hilus_ch, self.mol_ch]\n        else:\n            channels = [self.hilus_ch, self.mol_ch, self.noise_ch]\n\n        self.lfp = nel.AnalogSignalArray(\n            data=lfp[:, channels].T,\n            timestamps=timestep,\n            fs=self.fs,\n            support=nel.EpochArray(np.array([min(timestep), max(timestep)])),\n        )\n        if self.clean_lfp:\n            self.lfp._data = np.array(\n                [\n                    clean_lfp(self.lfp.signals[0]),\n                    clean_lfp(self.lfp.signals[1]),\n                ]\n            )\n\n    def filter_signal(self):\n        \"\"\"\n        Filter the LFP signal\n\n        Returns\n        -------\n        np.ndarray\n            Filtered LFP signal\n        \"\"\"\n        if not hasattr(self, \"lfp\"):\n            self.load_lfp()\n\n        b, a = cheby2(\n            self.filter_order,\n            self.filter_rs,\n            [self.lowcut, self.highcut],\n            fs=self.fs,\n            btype=\"bandpass\",\n        )\n        return filtfilt(b, a, self.lfp.data)\n\n    def get_filtered_lfp(self):\n        if not hasattr(self, \"lfp\"):\n            self.load_lfp()\n\n        self.filtered_lfp = deepcopy(self.lfp)\n        self.filtered_lfp._data = self.filter_signal()\n\n    def get_lfp_diff(self):\n        if self.filter_signal_bool:\n            y = self.filter_signal()\n        else:\n            if not hasattr(self, \"lfp\"):\n                self.load_lfp()\n            y = self.lfp.data\n\n        self.mol_hilus_diff = nel.AnalogSignalArray(\n            data=y[0, :] - y[1, :],\n            timestamps=self.lfp.abscissa_vals,\n            fs=self.fs,\n            support=nel.EpochArray(\n                np.array([min(self.lfp.abscissa_vals), max(self.lfp.abscissa_vals)])\n            ),\n        )\n\n    def detect_ds_difference(self):\n        if not hasattr(self, \"mol_hilus_diff\"):\n            self.get_lfp_diff()\n\n        PrimaryThreshold = (\n            self.mol_hilus_diff.mean()\n            + self.primary_threshold * self.mol_hilus_diff.std()\n        )\n        SecondaryThreshold = (\n            self.mol_hilus_diff.mean()\n            + self.secondary_threshold * self.mol_hilus_diff.std()\n        )\n        bounds, self.peak_val, _ = nel.utils.get_events_boundaries(\n            x=self.mol_hilus_diff.data,\n            PrimaryThreshold=PrimaryThreshold,\n            SecondaryThreshold=SecondaryThreshold,\n            minThresholdLength=0,\n            minLength=self.min_duration,\n            maxLength=self.max_duration,\n            ds=1 / self.mol_hilus_diff.fs,\n        )\n        # convert bounds to time in seconds\n        timebounds = self.mol_hilus_diff.time[bounds]\n        # add 1/fs to stops for open interval\n        timebounds[:, 1] += 1 / self.mol_hilus_diff.fs\n        # create EpochArray with bounds\n        self.ds_epoch = nel.EpochArray(timebounds)\n\n        # remove ds in high emg\n        _, high_emg_epoch, _ = loading.load_emg(self.basepath, self.emg_threshold)\n        if not high_emg_epoch.isempty:\n            idx = find_intersecting_intervals(self.ds_epoch, high_emg_epoch)\n            self.ds_epoch._data = self.ds_epoch.data[~idx]\n            self.peak_val = self.peak_val[~idx]\n\n    def detect_ds_seperately(self):\n        if not hasattr(self, \"filtered_lfp\"):\n            self.get_filtered_lfp()\n\n        # min and max time width of ds (converted to samples for find_peaks)\n        time_widths = [\n            int(self.min_duration * self.filtered_lfp.fs),\n            int(self.max_duration * self.filtered_lfp.fs),\n        ]\n\n        # detect ds in hilus\n        PrimaryThreshold = (\n            self.filtered_lfp.data[0, :].mean()\n            + self.primary_thres_hilus * self.filtered_lfp.data[0, :].std()\n        )\n\n        peaks, properties = find_peaks(\n            self.filtered_lfp.data[0, :],\n            height=PrimaryThreshold,\n            width=time_widths,\n        )\n        self.peaks = peaks / self.filtered_lfp.fs\n        self.peak_val = properties[\"peak_heights\"]\n\n        # create EpochArray with bounds\n        hilus_epoch = nel.EpochArray(\n            np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n            / self.filtered_lfp.fs\n        )\n\n        # detect ds in mol\n        PrimaryThreshold = (\n            self.filtered_lfp.data[1, :].mean()\n            + self.primary_thres_mol * self.filtered_lfp.data[1, :].std()\n        )\n\n        peaks, properties = find_peaks(\n            -self.filtered_lfp.data[1, :],\n            height=PrimaryThreshold,\n            width=time_widths,\n        )\n        mol_epoch_peak = peaks / self.filtered_lfp.fs\n        # create EpochArray with bounds\n        mol_epoch = nel.EpochArray(\n            np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n            / self.filtered_lfp.fs\n        )\n\n        # detect ds in noise channel\n        if self.noise_ch is not None:\n            PrimaryThreshold = (\n                self.filtered_lfp.data[2, :].mean()\n                + self.primary_thres_hilus * self.filtered_lfp.data[2, :].std()\n            )\n\n            peaks, properties = find_peaks(\n                self.filtered_lfp.data[2, :],\n                height=PrimaryThreshold,\n                width=time_widths,\n            )\n\n            # create EpochArray with bounds\n            noise_epoch = nel.EpochArray(\n                np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n                / self.filtered_lfp.fs\n            )\n\n        # remove hilus spikes that are not overlapping with mol spikes\n        # first, find mol peaks that are within hilus epoch\n        idx = in_intervals(mol_epoch_peak, hilus_epoch.data)\n        mol_epoch._data = mol_epoch.data[idx]\n\n        overlap = find_intersecting_intervals(\n            hilus_epoch, mol_epoch, return_indices=True\n        )\n        self.ds_epoch = nel.EpochArray(hilus_epoch.data[overlap])\n        self.peak_val = self.peak_val[overlap]\n        self.peaks = self.peaks[overlap]\n\n        # remove dentate spikes that are overlapping with noise spikes\n        if self.noise_ch is not None:\n            overlap = find_intersecting_intervals(\n                self.ds_epoch, noise_epoch, return_indices=True\n            )\n            self.ds_epoch = nel.EpochArray(self.ds_epoch.data[~overlap])\n            self.peak_val = self.peak_val[~overlap]\n            self.peaks = self.peaks[~overlap]\n\n        # remove ds in high emg\n        _, high_emg_epoch, _ = loading.load_emg(self.basepath, self.emg_threshold)\n        if not high_emg_epoch.isempty:\n            idx = find_intersecting_intervals(self.ds_epoch, high_emg_epoch)\n            self.ds_epoch._data = self.ds_epoch.data[~idx]\n            self.peak_val = self.peak_val[~idx]\n            self.peaks = self.peaks[~idx]\n\n    def detect_ds(self):\n        \"\"\"\n        Detect the dentate spikes based on the method provided\n        \"\"\"\n        if self.method == \"difference\":\n            # deprecated\n            raise NotImplementedError\n            # self.detect_ds_difference()\n        elif self.method == \"seperately\":\n            self.detect_ds_seperately()\n        else:\n            raise ValueError(f\"Method {self.method} not recognized\")\n\n    def save_ds_epoch(self):\n        \"\"\"\n        Save the dentate spikes as a cellexplorer mat file\n        \"\"\"\n\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".DS2.events.mat\"\n        )\n        data = {}\n        data[\"DS2\"] = {}\n        data[\"DS2\"][\"detectorinfo\"] = {}\n        data[\"DS2\"][\"timestamps\"] = self.ds_epoch.data\n        data[\"DS2\"][\"peaks\"] = self.peaks\n        data[\"DS2\"][\"amplitudes\"] = self.peak_val.T\n        data[\"DS2\"][\"amplitudeUnits\"] = \"mV\"\n        data[\"DS2\"][\"eventID\"] = []\n        data[\"DS2\"][\"eventIDlabels\"] = []\n        data[\"DS2\"][\"eventIDbinary\"] = []\n        data[\"DS2\"][\"duration\"] = self.ds_epoch.durations.T\n        data[\"DS2\"][\"center\"] = np.median(self.ds_epoch.data, axis=1).T\n        data[\"DS2\"][\"detectorinfo\"][\"detectorname\"] = \"DetectDS\"\n        data[\"DS2\"][\"detectorinfo\"][\"detectionparms\"] = []\n        data[\"DS2\"][\"detectorinfo\"][\"detectionintervals\"] = []\n        data[\"DS2\"][\"detectorinfo\"][\"ml_channel\"] = self.mol_ch\n        data[\"DS2\"][\"detectorinfo\"][\"h_channel\"] = self.hilus_ch\n        if self.noise_ch is not None:\n            data[\"DS2\"][\"detectorinfo\"][\"noise_channel\"] = self.noise_ch\n\n        savemat(filename, data, long_field_names=True)\n\n    def get_average_trace(self, shank=None, window=[-0.15, 0.15]):\n        \"\"\"\n        Get the average LFP trace around the dentate spikes\n\n        Parameters\n        ----------\n        shank : int, optional\n            Shank number of the hilus signal\n        window : list, optional\n            Window around the dentate spikes\n\n        Returns\n        -------\n        np.ndarray\n            Average LFP trace around the dentate spikes\n        np.ndarray\n            Time lags around the dentate spikes\n        \"\"\"\n\n        lfp, _ = loading.loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            frequency=self.fs,\n            ext=\"lfp\",\n        )\n\n        if shank is None:\n            hilus_shank = [\n                k for k, v in self.shank_to_channel.items() if self.hilus_ch in v\n            ][0]\n\n        ds_average, time_lags = event_triggered_average_fast(\n            signal=lfp[:, self.shank_to_channel[hilus_shank]].T,\n            events=self.ds_epoch.starts,\n            sampling_rate=self.fs,\n            window=window,\n            return_average=True,\n        )\n        return ds_average, time_lags\n\n    def plot(self, ax=None, window=[-0.15, 0.15], channel_offset=9e4):\n        \"\"\"\n        Plot the average LFP trace around the dentate spikes\n\n        Parameters\n        ----------\n        ax : matplotlib.axes._subplots.AxesSubplot, optional\n            Axis to plot the average LFP trace\n        window : list, optional\n            Window around the dentate spikes\n        channel_offset : float, optional\n            Offset between the channels\n\n        Returns\n        -------\n        matplotlib.axes._subplots.AxesSubplot\n            Axis with the average LFP trace\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n\n        ds_average, time_lags = self.get_average_trace(window=window)\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(5, 10))\n\n        ax.plot(\n            time_lags,\n            ds_average.T - np.linspace(0, channel_offset, ds_average.shape[0]),\n            alpha=0.75,\n        )\n        return ax\n\n    def _detach(self):\n        \"\"\"Detach the data from the object to allow for pickling\"\"\"\n        self.filtered_lfp = None\n        self.lfp = None\n        self.mol_hilus_diff = None\n\n    def save(self, filename: str):\n        \"\"\"\n        Save the DetectDS object as a pickle file\n\n        Parameters\n        ----------\n        filename : str\n            Path to the file where the DetectDS object will be saved\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        self._detach()\n        with open(filename, \"wb\") as f:\n            pickle.dump(self, f)\n\n    @classmethod\n    def load(cls, filename: str):\n        \"\"\"\n        Load a DetectDS object from a pickle file\n\n        Parameters\n        ----------\n        filename : str\n            Path to the file where the DetectDS object is saved\n\n        Returns\n        -------\n        DetectDS\n            The loaded DetectDS object\n\n        \"\"\"\n        with open(filename, \"rb\") as f:\n            return pickle.load(f)\n\n    def __repr__(self) -&gt; str:\n        address_str = \" at \" + str(hex(id(self)))\n\n        if not hasattr(self, \"ds_epoch\"):\n            return \"&lt;%s%s&gt;\" % (self.type_name, address_str)\n\n        if self.ds_epoch.isempty:\n            return \"&lt;%s%s: empty&gt;\" % self.type_name\n\n        dentate_spikes = f\"dentate spikes {self.ds_epoch.n_intervals}\"\n        dstr = f\"of length {self.ds_epoch.length}\"\n\n        return \"&lt;%s%s: %s&gt; %s\" % (self.type_name, address_str, dentate_spikes, dstr)\n\n    def __str__(self) -&gt; str:\n        return self.__repr__()\n\n    def __len__(self) -&gt; int:\n        if not hasattr(self, \"ds_epoch\"):\n            return 0\n        return self.ds_epoch.n_intervals\n\n    def __getitem__(self, key):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return self.ds_epoch[key]\n\n    def __iter__(self):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return iter(self.ds_epoch)\n\n    def __contains__(self, item):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return item in self.ds_epoch\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS._detach","title":"<code>_detach()</code>","text":"<p>Detach the data from the object to allow for pickling</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def _detach(self):\n    \"\"\"Detach the data from the object to allow for pickling\"\"\"\n    self.filtered_lfp = None\n    self.lfp = None\n    self.mol_hilus_diff = None\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.detect_ds","title":"<code>detect_ds()</code>","text":"<p>Detect the dentate spikes based on the method provided</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def detect_ds(self):\n    \"\"\"\n    Detect the dentate spikes based on the method provided\n    \"\"\"\n    if self.method == \"difference\":\n        # deprecated\n        raise NotImplementedError\n        # self.detect_ds_difference()\n    elif self.method == \"seperately\":\n        self.detect_ds_seperately()\n    else:\n        raise ValueError(f\"Method {self.method} not recognized\")\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.filter_signal","title":"<code>filter_signal()</code>","text":"<p>Filter the LFP signal</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered LFP signal</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def filter_signal(self):\n    \"\"\"\n    Filter the LFP signal\n\n    Returns\n    -------\n    np.ndarray\n        Filtered LFP signal\n    \"\"\"\n    if not hasattr(self, \"lfp\"):\n        self.load_lfp()\n\n    b, a = cheby2(\n        self.filter_order,\n        self.filter_rs,\n        [self.lowcut, self.highcut],\n        fs=self.fs,\n        btype=\"bandpass\",\n    )\n    return filtfilt(b, a, self.lfp.data)\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.get_average_trace","title":"<code>get_average_trace(shank=None, window=[-0.15, 0.15])</code>","text":"<p>Get the average LFP trace around the dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>shank</code> <code>int</code> <p>Shank number of the hilus signal</p> <code>None</code> <code>window</code> <code>list</code> <p>Window around the dentate spikes</p> <code>[-0.15, 0.15]</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Average LFP trace around the dentate spikes</p> <code>ndarray</code> <p>Time lags around the dentate spikes</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def get_average_trace(self, shank=None, window=[-0.15, 0.15]):\n    \"\"\"\n    Get the average LFP trace around the dentate spikes\n\n    Parameters\n    ----------\n    shank : int, optional\n        Shank number of the hilus signal\n    window : list, optional\n        Window around the dentate spikes\n\n    Returns\n    -------\n    np.ndarray\n        Average LFP trace around the dentate spikes\n    np.ndarray\n        Time lags around the dentate spikes\n    \"\"\"\n\n    lfp, _ = loading.loadLFP(\n        self.basepath,\n        n_channels=self.nChannels,\n        frequency=self.fs,\n        ext=\"lfp\",\n    )\n\n    if shank is None:\n        hilus_shank = [\n            k for k, v in self.shank_to_channel.items() if self.hilus_ch in v\n        ][0]\n\n    ds_average, time_lags = event_triggered_average_fast(\n        signal=lfp[:, self.shank_to_channel[hilus_shank]].T,\n        events=self.ds_epoch.starts,\n        sampling_rate=self.fs,\n        window=window,\n        return_average=True,\n    )\n    return ds_average, time_lags\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.get_xml_data","title":"<code>get_xml_data()</code>","text":"<p>Load the XML file to get the number of channels, sampling frequency and shank to channel mapping</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def get_xml_data(self):\n    \"\"\"\n    Load the XML file to get the number of channels, sampling frequency and shank to channel mapping\n    \"\"\"\n    nChannels, fs, fs_dat, shank_to_channel = loading.loadXML(self.basepath)\n    self.nChannels = nChannels\n    self.fs = fs\n    self.fs_dat = fs_dat\n    self.shank_to_channel = shank_to_channel\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.load","title":"<code>load(filename)</code>  <code>classmethod</code>","text":"<p>Load a DetectDS object from a pickle file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the file where the DetectDS object is saved</p> required <p>Returns:</p> Type Description <code>DetectDS</code> <p>The loaded DetectDS object</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>@classmethod\ndef load(cls, filename: str):\n    \"\"\"\n    Load a DetectDS object from a pickle file\n\n    Parameters\n    ----------\n    filename : str\n        Path to the file where the DetectDS object is saved\n\n    Returns\n    -------\n    DetectDS\n        The loaded DetectDS object\n\n    \"\"\"\n    with open(filename, \"rb\") as f:\n        return pickle.load(f)\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.load_lfp","title":"<code>load_lfp()</code>","text":"<p>Load the LFP signal</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def load_lfp(self):\n    \"\"\"\n    Load the LFP signal\n    \"\"\"\n\n    lfp, timestep = loading.loadLFP(\n        self.basepath,\n        n_channels=self.nChannels,\n        frequency=self.fs,\n        ext=\"lfp\",\n    )\n\n    if self.noise_ch is None:\n        channels = [self.hilus_ch, self.mol_ch]\n    else:\n        channels = [self.hilus_ch, self.mol_ch, self.noise_ch]\n\n    self.lfp = nel.AnalogSignalArray(\n        data=lfp[:, channels].T,\n        timestamps=timestep,\n        fs=self.fs,\n        support=nel.EpochArray(np.array([min(timestep), max(timestep)])),\n    )\n    if self.clean_lfp:\n        self.lfp._data = np.array(\n            [\n                clean_lfp(self.lfp.signals[0]),\n                clean_lfp(self.lfp.signals[1]),\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.plot","title":"<code>plot(ax=None, window=[-0.15, 0.15], channel_offset=90000.0)</code>","text":"<p>Plot the average LFP trace around the dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>AxesSubplot</code> <p>Axis to plot the average LFP trace</p> <code>None</code> <code>window</code> <code>list</code> <p>Window around the dentate spikes</p> <code>[-0.15, 0.15]</code> <code>channel_offset</code> <code>float</code> <p>Offset between the channels</p> <code>90000.0</code> <p>Returns:</p> Type Description <code>AxesSubplot</code> <p>Axis with the average LFP trace</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def plot(self, ax=None, window=[-0.15, 0.15], channel_offset=9e4):\n    \"\"\"\n    Plot the average LFP trace around the dentate spikes\n\n    Parameters\n    ----------\n    ax : matplotlib.axes._subplots.AxesSubplot, optional\n        Axis to plot the average LFP trace\n    window : list, optional\n        Window around the dentate spikes\n    channel_offset : float, optional\n        Offset between the channels\n\n    Returns\n    -------\n    matplotlib.axes._subplots.AxesSubplot\n        Axis with the average LFP trace\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n\n    ds_average, time_lags = self.get_average_trace(window=window)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(5, 10))\n\n    ax.plot(\n        time_lags,\n        ds_average.T - np.linspace(0, channel_offset, ds_average.shape[0]),\n        alpha=0.75,\n    )\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.save","title":"<code>save(filename)</code>","text":"<p>Save the DetectDS object as a pickle file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the file where the DetectDS object will be saved</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def save(self, filename: str):\n    \"\"\"\n    Save the DetectDS object as a pickle file\n\n    Parameters\n    ----------\n    filename : str\n        Path to the file where the DetectDS object will be saved\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    self._detach()\n    with open(filename, \"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.DetectDS.save_ds_epoch","title":"<code>save_ds_epoch()</code>","text":"<p>Save the dentate spikes as a cellexplorer mat file</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def save_ds_epoch(self):\n    \"\"\"\n    Save the dentate spikes as a cellexplorer mat file\n    \"\"\"\n\n    filename = os.path.join(\n        self.basepath, os.path.basename(self.basepath) + \".DS2.events.mat\"\n    )\n    data = {}\n    data[\"DS2\"] = {}\n    data[\"DS2\"][\"detectorinfo\"] = {}\n    data[\"DS2\"][\"timestamps\"] = self.ds_epoch.data\n    data[\"DS2\"][\"peaks\"] = self.peaks\n    data[\"DS2\"][\"amplitudes\"] = self.peak_val.T\n    data[\"DS2\"][\"amplitudeUnits\"] = \"mV\"\n    data[\"DS2\"][\"eventID\"] = []\n    data[\"DS2\"][\"eventIDlabels\"] = []\n    data[\"DS2\"][\"eventIDbinary\"] = []\n    data[\"DS2\"][\"duration\"] = self.ds_epoch.durations.T\n    data[\"DS2\"][\"center\"] = np.median(self.ds_epoch.data, axis=1).T\n    data[\"DS2\"][\"detectorinfo\"][\"detectorname\"] = \"DetectDS\"\n    data[\"DS2\"][\"detectorinfo\"][\"detectionparms\"] = []\n    data[\"DS2\"][\"detectorinfo\"][\"detectionintervals\"] = []\n    data[\"DS2\"][\"detectorinfo\"][\"ml_channel\"] = self.mol_ch\n    data[\"DS2\"][\"detectorinfo\"][\"h_channel\"] = self.hilus_ch\n    if self.noise_ch is not None:\n        data[\"DS2\"][\"detectorinfo\"][\"noise_channel\"] = self.noise_ch\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.bimodal_thresh","title":"<code>bimodal_thresh(bimodal_data, max_thresh=np.inf, schmidt=False, max_hist_bins=25, start_bins=10, set_thresh=None, nboot=100, force_bimodal=False)</code>","text":"<p>BimodalThresh: Find threshold between bimodal data modes (e.g., UP vs DOWN states) and return crossing times (UP/DOWN onset/offset times).</p> <p>Parameters:</p> Name Type Description Default <code>bimodal_data</code> <code>array - like</code> <p>Vector of bimodal data</p> required <code>max_thresh</code> <code>float</code> <p>Maximum threshold value (default: inf)</p> <code>inf</code> <code>schmidt</code> <code>bool</code> <p>Use Schmidt trigger with halfway points between trough and peaks (default: False)</p> <code>False</code> <code>max_hist_bins</code> <code>int</code> <p>Maximum number of histogram bins to try before giving up (default: 25)</p> <code>25</code> <code>start_bins</code> <code>int</code> <p>Minimum number of histogram bins for initial histogram (default: 10)</p> <code>10</code> <code>set_thresh</code> <code>float</code> <p>Manually set your own threshold (default: None)</p> <code>None</code> <code>nboot</code> <code>int</code> <p>Number of bootstrap iterations for dip test (default: 100)</p> <code>100</code> <code>force_bimodal</code> <code>bool</code> <p>If True, skip bimodality test and proceed with threshold detection (default: False)</p> <code>False</code> <p>Returns:</p> Name Type Description <code>thresh</code> <code>float</code> <p>Threshold value between modes</p> <code>cross</code> <code>dict</code> <p>Dictionary with keys: - 'upints': array of UP state intervals [onsets, offsets] - 'downints': array of DOWN state intervals [onsets, offsets]</p> <code>bihist</code> <code>dict</code> <p>Dictionary with keys: - 'bins': bin centers - 'hist': counts</p> <code>diptest_result</code> <code>dict</code> <p>Dictionary with keys: - 'dip': Hartigan's dip test statistic - 'p': p-value for bimodal distribution</p> Example <p>data = np.concatenate([np.random.normal(0, 1, 1000), ...                        np.random.normal(5, 1, 1000)]) thresh, cross, bihist, diptest_result = bimodal_thresh(data)</p> Notes <p>Python translation of BimodalThresh.m from MehrotraLevenstein_2023</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def bimodal_thresh(\n    bimodal_data,\n    max_thresh=np.inf,\n    schmidt=False,\n    max_hist_bins=25,\n    start_bins=10,\n    set_thresh=None,\n    nboot=100,\n    force_bimodal=False,\n):\n    \"\"\"\n    BimodalThresh: Find threshold between bimodal data modes (e.g., UP vs DOWN states)\n    and return crossing times (UP/DOWN onset/offset times).\n\n    Parameters\n    ----------\n    bimodal_data : array-like\n        Vector of bimodal data\n    max_thresh : float, optional\n        Maximum threshold value (default: inf)\n    schmidt : bool, optional\n        Use Schmidt trigger with halfway points between trough and peaks (default: False)\n    max_hist_bins : int, optional\n        Maximum number of histogram bins to try before giving up (default: 25)\n    start_bins : int, optional\n        Minimum number of histogram bins for initial histogram (default: 10)\n    set_thresh : float, optional\n        Manually set your own threshold (default: None)\n    nboot : int, optional\n        Number of bootstrap iterations for dip test (default: 100)\n    force_bimodal : bool, optional\n        If True, skip bimodality test and proceed with threshold detection (default: False)\n\n    Returns\n    -------\n    thresh : float\n        Threshold value between modes\n    cross : dict\n        Dictionary with keys:\n        - 'upints': array of UP state intervals [onsets, offsets]\n        - 'downints': array of DOWN state intervals [onsets, offsets]\n    bihist : dict\n        Dictionary with keys:\n        - 'bins': bin centers\n        - 'hist': counts\n    diptest_result : dict\n        Dictionary with keys:\n        - 'dip': Hartigan's dip test statistic\n        - 'p': p-value for bimodal distribution\n\n    Example\n    -------\n    &gt;&gt;&gt; data = np.concatenate([np.random.normal(0, 1, 1000),\n    ...                        np.random.normal(5, 1, 1000)])\n    &gt;&gt;&gt; thresh, cross, bihist, diptest_result = bimodal_thresh(data)\n\n    Notes\n    -----\n    Python translation of BimodalThresh.m from MehrotraLevenstein_2023\n\n    \"\"\"\n\n    # Initialize\n    bimodal_data = np.array(bimodal_data).flatten()\n    bimodal_data = bimodal_data[~np.isnan(bimodal_data)]\n\n    # Run Hartigan's dip test for bimodality\n    dip_stat, p_value = hartigan_diptest(bimodal_data, n_boot=nboot)\n    diptest_result = {\"dip\": dip_stat, \"p\": p_value}\n\n    # If not bimodal, return empty (unless forced)\n    if p_value &gt; 0.05 and not force_bimodal:\n        cross = {\"upints\": np.array([]), \"downints\": np.array([])}\n        hist_counts, bin_edges = np.histogram(bimodal_data, bins=start_bins)\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n        bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n        return np.nan, cross, bihist, diptest_result\n\n    # Remove data over max threshold\n    bimodal_data = bimodal_data[bimodal_data &lt; max_thresh]\n\n    # Find histogram with exactly 2 peaks\n    num_peaks = 1\n    num_bins = start_bins\n\n    while num_peaks != 2:\n        hist_counts, bin_edges = np.histogram(bimodal_data, bins=num_bins)\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n\n        # Find peaks (add zeros at edges for edge detection)\n        padded_hist = np.concatenate([[0], hist_counts, [0]])\n        peaks, _ = find_peaks(padded_hist, distance=1)\n        peaks = np.sort(peaks) - 1  # Adjust for padding\n\n        # Keep only top 2 peaks\n        if len(peaks) &gt; 2:\n            peak_heights = hist_counts[peaks]\n            top_2_idx = np.argsort(peak_heights)[-2:]\n            peaks = np.sort(peaks[top_2_idx])\n\n        num_peaks = len(peaks)\n        num_bins += 1\n\n        if num_bins &gt;= max_hist_bins and set_thresh is None:\n            print(\"Unable to find trough\")\n            cross = {\"upints\": np.array([]), \"downints\": np.array([])}\n            bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n            return np.nan, cross, bihist, diptest_result\n\n    bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n\n    # Find trough between peaks\n    between_peaks = bin_centers[peaks[0] : peaks[1] + 1]\n    between_hist = hist_counts[peaks[0] : peaks[1] + 1]\n\n    # Find minimum (trough)\n    trough_idx = np.argmin(between_hist)\n\n    if set_thresh is not None:\n        thresh = set_thresh\n    else:\n        thresh = between_peaks[trough_idx]\n\n    # Schmidt trigger: use halfway points between trough and peaks\n    if schmidt:\n        thresh_up = thresh + 0.5 * (between_peaks[-1] - thresh)\n        thresh_down = thresh + 0.5 * (between_peaks[0] - thresh)\n\n        over_up = bimodal_data &gt; thresh_up\n        over_down = bimodal_data &gt; thresh_down\n\n        cross_up = np.where(np.diff(over_up.astype(int)) == 1)[0]\n        cross_down = np.where(np.diff(over_down.astype(int)) == -1)[0]\n\n        # Check for empty crossings before vstack\n        if len(cross_up) == 0 or len(cross_down) == 0:\n            cross = {\n                \"upints\": np.array([]).reshape(0, 2),\n                \"downints\": np.array([]).reshape(0, 2),\n            }\n            return thresh, cross, bihist, diptest_result\n\n        # Delete incomplete (repeat) crossings\n        all_crossings = np.vstack(\n            [\n                np.column_stack([cross_up, np.ones(len(cross_up))]),\n                np.column_stack([cross_down, np.zeros(len(cross_down))]),\n            ]\n        )\n\n        sort_order = np.argsort(all_crossings[:, 0])\n        all_crossings = all_crossings[sort_order]\n\n        up_down_switch = np.diff(all_crossings[:, 1])\n        same_state = np.where(up_down_switch == 0)[0] + 1\n        all_crossings = np.delete(all_crossings, same_state, axis=0)\n\n        cross_up = all_crossings[all_crossings[:, 1] == 1, 0].astype(int)\n        cross_down = all_crossings[all_crossings[:, 1] == 0, 0].astype(int)\n    else:\n        over_ind = bimodal_data &gt; thresh\n        cross_up = np.where(np.diff(over_ind.astype(int)) == 1)[0]\n        cross_down = np.where(np.diff(over_ind.astype(int)) == -1)[0]\n\n    # If only one crossing, return empty\n    if len(cross_up) == 0 or len(cross_down) == 0:\n        cross = {\n            \"upints\": np.array([]).reshape(0, 2),\n            \"downints\": np.array([]).reshape(0, 2),\n        }\n        return thresh, cross, bihist, diptest_result\n\n    # Create interval arrays\n    up_for_up = cross_up.copy()\n    up_for_down = cross_up.copy()\n    down_for_up = cross_down.copy()\n    down_for_down = cross_down.copy()\n\n    # Adjust for proper pairing\n    if cross_up[0] &lt; cross_down[0]:\n        up_for_down = up_for_down[1:]\n    if cross_down[-1] &gt; cross_up[-1]:\n        down_for_down = down_for_down[:-1]\n    if cross_down[0] &lt; cross_up[0]:\n        down_for_up = down_for_up[1:]\n    if cross_up[-1] &gt; cross_down[-1]:\n        up_for_up = up_for_up[:-1]\n\n    # Ensure equal length for pairing\n    min_len_up = min(len(up_for_up), len(down_for_up))\n    min_len_down = min(len(down_for_down), len(up_for_down))\n\n    # Check if pairing resulted in any valid intervals\n    if min_len_up == 0 or min_len_down == 0:\n        cross = {\n            \"upints\": np.array([]).reshape(0, 2),\n            \"downints\": np.array([]).reshape(0, 2),\n        }\n        return thresh, cross, bihist, diptest_result\n\n    upints = np.column_stack([up_for_up[:min_len_up], down_for_up[:min_len_up]])\n    downints = np.column_stack(\n        [down_for_down[:min_len_down], up_for_down[:min_len_down]]\n    )\n\n    cross = {\"upints\": upints, \"downints\": downints}\n\n    return thresh, cross, bihist, diptest_result\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.detect_up_down_states","title":"<code>detect_up_down_states(basepath=None, st=None, nrem_epochs=None, region='ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX', min_dur=0.03, max_dur=0.5, percentile=20, bin_size=0.01, smooth_sigma=0.02, min_cells=10, save_mat=True, epoch_by_epoch=False, beh_epochs=None, show_figure=False, overwrite=False)</code>","text":"<p>Detect UP and DOWN states in neural data.</p> <p>UP and DOWN states are identified by computing the total firing rate of all simultaneously recorded neurons in bins of 10 ms, smoothed with a Gaussian kernel of 20 ms s.d. Epochs with a firing rate below the specified percentile threshold are considered DOWN states, while the intervals between DOWN states are classified as UP states. Epochs shorter than <code>min_dur</code> or longer than <code>max_dur</code> are discarded.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Base directory path where event files and neural data are stored.</p> <code>None</code> <code>st</code> <code>Optional[SpikeTrain]</code> <p>Spike train data. If None, spike data will be loaded based on specified regions.</p> <code>None</code> <code>nrem_epochs</code> <code>Optional[EpochArray]</code> <p>NREM epochs. If None, epochs will be loaded from the basepath.</p> <code>None</code> <code>region</code> <code>str</code> <p>Brain regions for loading spikes. The first region is prioritized.</p> <code>\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC\"</code> <code>min_dur</code> <code>float</code> <p>Minimum duration for DOWN states, in seconds.</p> <code>0.03</code> <code>max_dur</code> <code>float</code> <p>Maximum duration for DOWN states, in seconds.</p> <code>0.5</code> <code>percentile</code> <code>float</code> <p>Percentile threshold for determining DOWN states based on firing rate.</p> <code>20</code> <code>bin_size</code> <code>float</code> <p>Bin size for computing firing rates, in seconds.</p> <code>0.01</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian kernel smoothing, in seconds.</p> <code>0.02</code> <code>min_cells</code> <code>int</code> <p>Minimum number of neurons required for analysis.</p> <code>10</code> <code>save_mat</code> <code>bool</code> <p>Whether to save the detected UP and DOWN states to .mat files.</p> <code>True</code> <code>epoch_by_epoch</code> <code>bool</code> <p>Whether to perform detection epoch by epoch. If True, detection will be performed separately for each sleep epoch.</p> <code>False</code> <code>beh_epochs</code> <code>Optional[EpochArray]</code> <p>Optional behavioral epochs to use for epoch-by-epoch detection. If None, sleep epochs will be loaded and used.</p> <code>None</code> <code>show_figure</code> <code>bool</code> <p>Whether to display a figure showing firing rates during detected UP and DOWN states.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing .mat files when saving detected states.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[Optional[EpochArray], Optional[EpochArray]]</code> <p>A tuple containing the detected DOWN state epochs and UP state epochs. Returns (None, None) if no suitable states are found or insufficient data is available.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; down_state, up_state = detect_up_down_states(basepath=\"/path/to/data\", show_figure=True)\n</code></pre> <p>From command line: $ python up_down_state.py /path/to/data</p> Notes <p>Detection method based on https://doi.org/10.1038/s41467-020-15842-4</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def detect_up_down_states(\n    basepath: Optional[str] = None,\n    st: Optional[nel.SpikeTrainArray] = None,\n    nrem_epochs: Optional[nel.EpochArray] = None,\n    region: str = \"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\",\n    min_dur: float = 0.03,\n    max_dur: float = 0.5,\n    percentile: float = 20,\n    bin_size: float = 0.01,\n    smooth_sigma: float = 0.02,\n    min_cells: int = 10,\n    save_mat: bool = True,\n    epoch_by_epoch: bool = False,\n    beh_epochs: Optional[nel.EpochArray] = None,\n    show_figure: bool = False,\n    overwrite: bool = False,\n) -&gt; Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]:\n    \"\"\"\n    Detect UP and DOWN states in neural data.\n\n    UP and DOWN states are identified by computing the total firing rate of all\n    simultaneously recorded neurons in bins of 10 ms, smoothed with a Gaussian kernel\n    of 20 ms s.d. Epochs with a firing rate below the specified percentile threshold\n    are considered DOWN states, while the intervals between DOWN states are classified\n    as UP states. Epochs shorter than `min_dur` or longer than `max_dur` are discarded.\n\n    Parameters\n    ----------\n    basepath : str\n        Base directory path where event files and neural data are stored.\n    st : Optional[nel.SpikeTrain], default=None\n        Spike train data. If None, spike data will be loaded based on specified regions.\n    nrem_epochs : Optional[nel.EpochArray], default=None\n        NREM epochs. If None, epochs will be loaded from the basepath.\n    region : str, default=\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC\"\n        Brain regions for loading spikes. The first region is prioritized.\n    min_dur : float, default=0.03\n        Minimum duration for DOWN states, in seconds.\n    max_dur : float, default=0.5\n        Maximum duration for DOWN states, in seconds.\n    percentile : float, default=20\n        Percentile threshold for determining DOWN states based on firing rate.\n    bin_size : float, default=0.01\n        Bin size for computing firing rates, in seconds.\n    smooth_sigma : float, default=0.02\n        Standard deviation for Gaussian kernel smoothing, in seconds.\n    min_cells : int, default=10\n        Minimum number of neurons required for analysis.\n    save_mat : bool, default=True\n        Whether to save the detected UP and DOWN states to .mat files.\n    epoch_by_epoch : bool, default=False\n        Whether to perform detection epoch by epoch. If True, detection will be performed separately for each sleep epoch.\n    beh_epochs : Optional[nel.EpochArray], default=None\n        Optional behavioral epochs to use for epoch-by-epoch detection. If None, sleep epochs will be loaded and used.\n    show_figure : bool, default=False\n        Whether to display a figure showing firing rates during detected UP and DOWN states.\n    overwrite : bool, default=False\n        Whether to overwrite existing .mat files when saving detected states.\n\n    Returns\n    -------\n    Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]\n        A tuple containing the detected DOWN state epochs and UP state epochs.\n        Returns (None, None) if no suitable states are found or insufficient data is available.\n\n    Examples\n    --------\n    &gt;&gt;&gt; down_state, up_state = detect_up_down_states(basepath=\"/path/to/data\", show_figure=True)\n\n    From command line:\n    $ python up_down_state.py /path/to/data\n\n    Notes\n    -----\n    Detection method based on https://doi.org/10.1038/s41467-020-15842-4\n    \"\"\"\n\n    def _detect_states(bst_segment: nel.AnalogSignalArray, domain: nel.EpochArray):\n        \"\"\"Detect down/up states within a given domain using shared logic.\"\"\"\n\n        down_state_epochs = bst_segment.bin_centers[\n            find_interval(\n                bst_segment.data.flatten()\n                &lt; np.percentile(bst_segment.data.T, percentile)\n            )\n        ]\n        if down_state_epochs.shape[0] == 0:\n            return None, None\n\n        durations = down_state_epochs[:, 1] - down_state_epochs[:, 0]\n        down_state_epochs = down_state_epochs[durations &gt; bin_size]\n\n        down_state_epochs = (\n            nel.EpochArray(data=down_state_epochs).merge(gap=bin_size * 2).data\n        )\n        durations = down_state_epochs[:, 1] - down_state_epochs[:, 0]\n        down_state_epochs = down_state_epochs[\n            ~((durations &lt; min_dur) | (durations &gt; max_dur)), :\n        ]\n        if down_state_epochs.shape[0] == 0:\n            return None, None\n\n        down_state_epochs = nel.EpochArray(data=down_state_epochs, domain=domain)\n\n        up_state_epochs = ~down_state_epochs\n        up_state_epochs = up_state_epochs.data\n        # make sure up states are longer than bin size\n        durations = up_state_epochs[:, 1] - up_state_epochs[:, 0]\n        up_state_epochs = up_state_epochs[durations &gt; bin_size]\n        # merge nearby up states that are closer than 2*bin_size\n        up_state_epochs = nel.EpochArray(data=up_state_epochs, domain=domain).merge(\n            gap=bin_size * 2\n        )\n\n        return down_state_epochs, up_state_epochs\n\n    # check for existence of event files\n    if save_mat and not overwrite:\n        filename_downstate = os.path.join(\n            basepath, os.path.basename(basepath) + \".\" + \"down_state\" + \".events.mat\"\n        )\n        filename_upstate = os.path.join(\n            basepath, os.path.basename(basepath) + \".\" + \"up_state\" + \".events.mat\"\n        )\n        if os.path.exists(filename_downstate) &amp; os.path.exists(filename_upstate):\n            down_state = loading.load_events(basepath=basepath, epoch_name=\"down_state\")\n            up_state = loading.load_events(basepath=basepath, epoch_name=\"up_state\")\n            return down_state, up_state\n\n    # load brain states\n    if nrem_epochs is None:\n        state_dict = loading.load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"])\n\n    if nrem_epochs.isempty:\n        print(f\"No NREM epochs found for {basepath}\")\n        return None, None\n\n    # load spikes\n    if st is None:\n        st, _ = loading.load_spikes(basepath, brainRegion=region)\n\n    # check if there are enough cells\n    if st is None or st.isempty or st.data.shape[0] &lt; min_cells:\n        print(f\"No spikes found for {basepath} {region}\")\n        return None, None\n\n    # flatten spikes\n    st = st[nrem_epochs].flatten()\n\n    # bin and smooth\n    bst = st.bin(ds=bin_size).smooth(sigma=smooth_sigma)\n\n    if epoch_by_epoch:\n        if beh_epochs is None:\n            epoch_df = npy.io.load_epoch(basepath)\n            epoch_df = npy.session.compress_repeated_epochs(epoch_df)\n            epoch_df = epoch_df.query(\"environment == 'sleep'\")\n            beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n        down_state_epochs = []\n        up_state_epochs = []\n        for ep in beh_epochs:\n            domain = nrem_epochs &amp; ep\n            if domain.isempty:\n                continue\n\n            down_state_epochs_, up_state_epochs_ = _detect_states(bst[domain], domain)\n            if down_state_epochs_ is None or up_state_epochs_ is None:\n                continue\n\n            down_state_epochs.append(down_state_epochs_.data)\n            up_state_epochs.append(up_state_epochs_.data)\n\n        if len(down_state_epochs) == 0 or len(up_state_epochs) == 0:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n        down_state_epochs = nel.EpochArray(\n            data=np.concatenate(down_state_epochs), domain=nrem_epochs\n        )\n        up_state_epochs = nel.EpochArray(\n            data=np.concatenate(up_state_epochs), domain=nrem_epochs\n        )\n    else:\n        down_state_epochs, up_state_epochs = _detect_states(bst, nrem_epochs)\n        if down_state_epochs is None or up_state_epochs is None:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n    # save to cell explorer mat file\n    if save_mat:\n        epoch_to_mat(down_state_epochs, basepath, \"down_state\", \"detect_up_down_states\")\n        epoch_to_mat(up_state_epochs, basepath, \"up_state\", \"detect_up_down_states\")\n\n    # optional figure to show firing rate during up and down states\n    if show_figure:\n        from matplotlib import pyplot as plt\n\n        plt.figure()\n        ax = plt.gca()\n        psth = npy.process.compute_psth(st.data, down_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Down states\"]\n        psth.plot(ax=ax)\n\n        psth = npy.process.compute_psth(st.data, up_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Up states\"]\n\n        psth.plot(ax=ax)\n        ax.legend(loc=\"upper right\", frameon=False)\n        ax.axvline(0, color=\"k\", linestyle=\"--\")\n\n        ax.set_xlabel(\"Time from state transition (s)\")\n        ax.set_ylabel(\"Firing rate (Hz)\")\n\n    return down_state_epochs, up_state_epochs\n</code></pre>"},{"location":"reference/neuro_py/detectors/#neuro_py.detectors.detect_up_down_states_bimodal_thresh","title":"<code>detect_up_down_states_bimodal_thresh(basepath=None, st=None, nrem_epochs=None, region='ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX', bin_size=0.01, smooth_sigma=0.02, min_cells=10, save_mat=True, epoch_by_epoch=False, beh_epochs=None, show_figure=False, overwrite=False, schmidt=False, nboot=100, force_bimodal=False)</code>","text":"<p>Detect UP and DOWN states using bimodal_thresh on firing rate distribution.</p> <p>Uses the same data loading and epoch-by-epoch logic as <code>detect_up_down_states</code>, but applies Hartigan's dip test and bimodal threshold detection instead of a fixed percentile. This is useful when UP/DOWN states form a clear bimodal distribution in the firing rate histogram.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Base directory path where event files and neural data are stored.</p> <code>None</code> <code>st</code> <code>Optional[SpikeTrainArray]</code> <p>Spike train data. If None, spike data will be loaded based on specified regions.</p> <code>None</code> <code>nrem_epochs</code> <code>Optional[EpochArray]</code> <p>NREM epochs. If None, epochs will be loaded from the basepath.</p> <code>None</code> <code>region</code> <code>str</code> <p>Brain regions for loading spikes. The first region is prioritized.</p> <code>\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\"</code> <code>bin_size</code> <code>float</code> <p>Bin size for computing firing rates, in seconds.</p> <code>0.01</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian kernel smoothing, in seconds.</p> <code>0.02</code> <code>min_cells</code> <code>int</code> <p>Minimum number of neurons required for analysis.</p> <code>10</code> <code>save_mat</code> <code>bool</code> <p>Whether to save the detected UP and DOWN states to .mat files.</p> <code>True</code> <code>epoch_by_epoch</code> <code>bool</code> <p>Whether to perform detection epoch by epoch.</p> <code>False</code> <code>beh_epochs</code> <code>Optional[EpochArray]</code> <p>Optional behavioral epochs to use for epoch-by-epoch detection.</p> <code>None</code> <code>show_figure</code> <code>bool</code> <p>Whether to display a figure showing firing rates during detected UP and DOWN states.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing .mat files when saving detected states.</p> <code>False</code> <code>schmidt</code> <code>bool</code> <p>Use Schmidt trigger (hysteresis) for state transitions in bimodal_thresh.</p> <code>False</code> <code>nboot</code> <code>int</code> <p>Number of bootstrap iterations for Hartigan's dip test. Reduce further (e.g., 50) for very long recordings to improve performance.</p> <code>100</code> <code>force_bimodal</code> <code>bool</code> <p>If True, skip the bimodality test and force threshold detection even if the distribution appears unimodal. Use with caution.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[Optional[EpochArray], Optional[EpochArray]]</code> <p>A tuple containing the detected DOWN state epochs and UP state epochs. Returns (None, None) if no suitable states are found or insufficient data is available.</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def detect_up_down_states_bimodal_thresh(\n    basepath: Optional[str] = None,\n    st: Optional[nel.SpikeTrainArray] = None,\n    nrem_epochs: Optional[nel.EpochArray] = None,\n    region: str = \"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\",\n    bin_size: float = 0.01,\n    smooth_sigma: float = 0.02,\n    min_cells: int = 10,\n    save_mat: bool = True,\n    epoch_by_epoch: bool = False,\n    beh_epochs: Optional[nel.EpochArray] = None,\n    show_figure: bool = False,\n    overwrite: bool = False,\n    schmidt: bool = False,\n    nboot: int = 100,\n    force_bimodal: bool = False,\n) -&gt; Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]:\n    \"\"\"\n    Detect UP and DOWN states using bimodal_thresh on firing rate distribution.\n\n    Uses the same data loading and epoch-by-epoch logic as `detect_up_down_states`,\n    but applies Hartigan's dip test and bimodal threshold detection instead of a\n    fixed percentile. This is useful when UP/DOWN states form a clear bimodal\n    distribution in the firing rate histogram.\n\n    Parameters\n    ----------\n    basepath : str\n        Base directory path where event files and neural data are stored.\n    st : Optional[nel.SpikeTrainArray], default=None\n        Spike train data. If None, spike data will be loaded based on specified regions.\n    nrem_epochs : Optional[nel.EpochArray], default=None\n        NREM epochs. If None, epochs will be loaded from the basepath.\n    region : str, default=\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\"\n        Brain regions for loading spikes. The first region is prioritized.\n    bin_size : float, default=0.01\n        Bin size for computing firing rates, in seconds.\n    smooth_sigma : float, default=0.02\n        Standard deviation for Gaussian kernel smoothing, in seconds.\n    min_cells : int, default=10\n        Minimum number of neurons required for analysis.\n    save_mat : bool, default=True\n        Whether to save the detected UP and DOWN states to .mat files.\n    epoch_by_epoch : bool, default=False\n        Whether to perform detection epoch by epoch.\n    beh_epochs : Optional[nel.EpochArray], default=None\n        Optional behavioral epochs to use for epoch-by-epoch detection.\n    show_figure : bool, default=False\n        Whether to display a figure showing firing rates during detected UP and DOWN states.\n    overwrite : bool, default=False\n        Whether to overwrite existing .mat files when saving detected states.\n    schmidt : bool, default=False\n        Use Schmidt trigger (hysteresis) for state transitions in bimodal_thresh.\n    nboot : int, default=100\n        Number of bootstrap iterations for Hartigan's dip test. Reduce further (e.g., 50)\n        for very long recordings to improve performance.\n    force_bimodal : bool, default=False\n        If True, skip the bimodality test and force threshold detection even if\n        the distribution appears unimodal. Use with caution.\n\n    Returns\n    -------\n    Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]\n        A tuple containing the detected DOWN state epochs and UP state epochs.\n        Returns (None, None) if no suitable states are found or insufficient data is available.\n    \"\"\"\n\n    # check for existence of event files\n    if save_mat and not overwrite:\n        filename_downstate = os.path.join(\n            basepath,\n            os.path.basename(basepath) + \".\" + \"down_state\" + \".events.mat\",\n        )\n        filename_upstate = os.path.join(\n            basepath,\n            os.path.basename(basepath) + \".\" + \"up_state\" + \".events.mat\",\n        )\n        if os.path.exists(filename_downstate) &amp; os.path.exists(filename_upstate):\n            down_state = loading.load_events(basepath=basepath, epoch_name=\"down_state\")\n            up_state = loading.load_events(basepath=basepath, epoch_name=\"up_state\")\n            return down_state, up_state\n\n    # load brain states\n    if nrem_epochs is None:\n        state_dict = loading.load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"])\n\n    if nrem_epochs.isempty:\n        print(f\"No NREM epochs found for {basepath}\")\n        return None, None\n\n    # load spikes\n    if st is None:\n        st, _ = loading.load_spikes(basepath, brainRegion=region)\n\n    # check if there are enough cells\n    if st is None or st.isempty or st.data.shape[0] &lt; min_cells:\n        print(f\"No spikes found for {basepath} {region}\")\n        return None, None\n\n    # flatten spikes\n    st = st[nrem_epochs].flatten()\n\n    # bin and smooth\n    bst = st.bin(ds=bin_size).smooth(sigma=smooth_sigma)\n\n    def _detect_states_bimodal(\n        bst_segment: nel.AnalogSignalArray, domain: nel.EpochArray\n    ):\n        \"\"\"Detect down/up states using bimodal_thresh within a given domain.\"\"\"\n\n        # Get firing rate time series\n        firing_rates = bst_segment.data.flatten()\n        if firing_rates.size == 0:\n            return None, None\n\n        # Apply bimodal_thresh to the firing rates\n        thresh, cross, bihist, diptest_result = bimodal_thresh(\n            firing_rates, schmidt=schmidt, nboot=nboot, force_bimodal=force_bimodal\n        )\n\n        # If not bimodal or no threshold found\n        if np.isnan(thresh):\n            return None, None\n\n        # Get bin centers (times)\n        bin_centers = bst_segment.bin_centers\n\n        # Extract downints and upints from cross\n        downints = cross[\"downints\"]  # indices into firing_rates array [n_intervals, 2]\n        upints = cross[\"upints\"]\n\n        # Convert indices to time intervals using bin_centers\n        if downints.size == 0:\n            return None, None\n\n        # Clip indices to valid range to prevent out-of-bounds access\n        n_bins = len(bin_centers)\n        downints_clipped = np.clip(downints.astype(int), 0, n_bins - 1)\n        upints_clipped = (\n            np.clip(upints.astype(int), 0, n_bins - 1)\n            if upints.size &gt; 0\n            else np.array([], dtype=int).reshape(0, 2)\n        )\n\n        # Convert index intervals to time intervals\n        # downints has shape [n, 2] where each row is [start_idx, end_idx]\n        down_state_times = np.column_stack(\n            [\n                bin_centers[downints_clipped[:, 0]],\n                bin_centers[downints_clipped[:, 1]],\n            ]\n        )\n        down_state_epochs = nel.EpochArray(data=down_state_times, domain=domain)\n\n        if upints.size == 0:\n            # Generate up states as complement\n            up_state_epochs = ~down_state_epochs\n        else:\n            up_state_times = np.column_stack(\n                [\n                    bin_centers[upints_clipped[:, 0]],\n                    bin_centers[upints_clipped[:, 1]],\n                ]\n            )\n            up_state_epochs = nel.EpochArray(data=up_state_times, domain=domain)\n\n        return down_state_epochs, up_state_epochs\n\n    if epoch_by_epoch:\n        if beh_epochs is None:\n            epoch_df = npy.io.load_epoch(basepath)\n            epoch_df = npy.session.compress_repeated_epochs(epoch_df)\n            epoch_df = epoch_df.query(\"environment == 'sleep'\")\n            beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n        down_state_epochs = []\n        up_state_epochs = []\n        for ep in beh_epochs:\n            domain = nrem_epochs &amp; ep\n            if domain.isempty:\n                continue\n\n            down_state_epochs_, up_state_epochs_ = _detect_states_bimodal(\n                bst[domain], domain\n            )\n            if down_state_epochs_ is None or up_state_epochs_ is None:\n                continue\n\n            down_state_epochs.append(down_state_epochs_.data)\n            up_state_epochs.append(up_state_epochs_.data)\n\n        if len(down_state_epochs) == 0 or len(up_state_epochs) == 0:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n        down_state_epochs = nel.EpochArray(\n            data=np.concatenate(down_state_epochs), domain=nrem_epochs\n        )\n        up_state_epochs = nel.EpochArray(\n            data=np.concatenate(up_state_epochs), domain=nrem_epochs\n        )\n    else:\n        down_state_epochs, up_state_epochs = _detect_states_bimodal(\n            bst[nrem_epochs], nrem_epochs\n        )\n        if down_state_epochs is None or up_state_epochs is None:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n    # save to cell explorer mat file\n    if save_mat:\n        epoch_to_mat(\n            down_state_epochs,\n            basepath,\n            \"down_state\",\n            \"detect_up_down_states_bimodal_thresh\",\n        )\n        epoch_to_mat(\n            up_state_epochs,\n            basepath,\n            \"up_state\",\n            \"detect_up_down_states_bimodal_thresh\",\n        )\n\n    # optional figure to show firing rate during up and down states\n    if show_figure:\n        from matplotlib import pyplot as plt\n\n        plt.figure()\n        ax = plt.gca()\n        psth = npy.process.compute_psth(st.data, down_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Down states\"]\n        psth.plot(ax=ax)\n\n        psth = npy.process.compute_psth(st.data, up_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Up states\"]\n\n        psth.plot(ax=ax)\n        ax.legend(loc=\"upper right\", frameon=False)\n        ax.axvline(0, color=\"k\", linestyle=\"--\")\n\n        ax.set_xlabel(\"Time from state transition (s)\")\n        ax.set_ylabel(\"Firing rate (Hz)\")\n\n    return down_state_epochs, up_state_epochs\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/","title":"neuro_py.detectors.dentate_spike","text":""},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS","title":"<code>DetectDS</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for detecting dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the data</p> required <code>hilus_ch</code> <code>int</code> <p>Channel number of the hilus signal (0 indexing)</p> required <code>mol_ch</code> <code>int</code> <p>Channel number of the mol signal (0 indexing)</p> required <code>noise_ch</code> <code>int</code> <p>Channel number of the noise signal or signal far from dentate (0 indexing)</p> <code>None</code> <code>lowcut</code> <code>float</code> <p>Low cut frequency for the signal filter</p> <code>10</code> <code>highcut</code> <code>float</code> <p>High cut frequency for the signal filter</p> <code>250</code> <code>filter_signal_bool</code> <code>bool</code> <p>If True, the signal will be filtered</p> <code>True</code> <code>primary_threshold</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes (difference method only)</p> <code>5</code> <code>secondary_threshold</code> <code>float</code> <p>Secondary threshold for detecting the dentate spikes (difference method only)</p> required <code>primary_thres_mol</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes in the mol signal</p> <code>2</code> <code>primary_thres_hilus</code> <code>float</code> <p>Primary threshold for detecting the dentate spikes in the hilus signal</p> <code>5</code> <code>min_duration</code> <code>float</code> <p>Minimum duration of the dentate spikes</p> <code>0.005</code> <code>max_duration</code> <code>float</code> <p>Maximum duration of the dentate spikes</p> <code>0.05</code> <code>filter_order</code> <code>int</code> <p>Order of the filter</p> <code>4</code> <code>filter_rs</code> <code>int</code> <p>Resonance frequency of the filter</p> <code>20</code> <code>method</code> <code>str</code> <p>Method for detecting the dentate spikes. \"difference\" for detecting the dentate spikes by difference between the hilus and mol signal \"seperately\" for detecting the dentate spikes by the hilus and mol signal separately</p> <code>'seperately'</code> <code>clean_lfp</code> <code>bool</code> <p>If True, the LFP signal will be cleaned</p> <code>False</code> <code>emg_threshold</code> <code>float</code> <p>Threshold for the EMG signal to remove dentate spikes</p> <code>0.9</code> <p>Attributes:</p> Name Type Description <code>lfp</code> <code>AnalogSignalArray</code> <p>LFP signal</p> <code>filtered_lfp</code> <code>AnalogSignalArray</code> <p>Filtered LFP signal</p> <code>mol_hilus_diff</code> <code>AnalogSignalArray</code> <p>Difference between the hilus and mol signal</p> <code>ds_epoch</code> <code>EpochArray</code> <p>EpochArray with the dentate spikes</p> <code>peak_val</code> <code>ndarray</code> <p>Peak value of the dentate spikes</p> <p>Methods:</p> Name Description <code>load_lfp</code> <p>Load the LFP signal</p> <code>filter_signal</code> <p>Filter the LFP signal</p> <code>get_filtered_lfp</code> <p>Get the filtered LFP signal</p> <code>get_lfp_diff</code> <p>Get the difference between the hilus and mol signal</p> <code>detect_ds_difference</code> <p>Detect the dentate spikes by difference between the hilus and mol signal</p> <code>detect_ds_seperately</code> <p>Detect the dentate spikes by the hilus and mol signal separately</p> <code>save_ds_epoch</code> <p>Save the dentate spikes as an EpochArray</p> <p>Examples:</p> <p>In IDE or python console</p> <pre><code>&gt;&gt;&gt; from ds_swr.detection.detect_dentate_spike import DetectDS\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; channel_tags = loading.load_channel_tags(basepath)\n&gt;&gt;&gt; dds = DetectDS(\n    basepath,\n    channel_tags[\"hilus\"][\"channels\"] - 1,\n    channel_tags[\"mol\"][\"channels\"] - 1\n)\n&gt;&gt;&gt; dds.detect_ds()\n&gt;&gt;&gt; dds.save_ds_epoch()\n&gt;&gt;&gt; dds\n&lt;DetectDS at 0x17fe787c640: dentate spikes 5,769&gt; of length 1:11:257 minutes\n</code></pre> <p>In command line</p> <pre><code>&gt;&gt;&gt; python detect_dentate_spike.py Z:\\Data\\Can\\OML22\\day20\n</code></pre> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>class DetectDS(object):\n    \"\"\"\n    Class for detecting dentate spikes\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the data\n    hilus_ch : int\n        Channel number of the hilus signal (0 indexing)\n    mol_ch : int\n        Channel number of the mol signal (0 indexing)\n    noise_ch : int, optional\n        Channel number of the noise signal or signal far from dentate (0 indexing)\n    lowcut : float, optional\n        Low cut frequency for the signal filter\n    highcut : float, optional\n        High cut frequency for the signal filter\n    filter_signal_bool : bool, optional\n        If True, the signal will be filtered\n    primary_threshold : float, optional\n        Primary threshold for detecting the dentate spikes (difference method only)\n    secondary_threshold : float, optional\n        Secondary threshold for detecting the dentate spikes (difference method only)\n    primary_thres_mol : float, optional\n        Primary threshold for detecting the dentate spikes in the mol signal\n    primary_thres_hilus : float, optional\n        Primary threshold for detecting the dentate spikes in the hilus signal\n    min_duration : float, optional\n        Minimum duration of the dentate spikes\n    max_duration : float, optional\n        Maximum duration of the dentate spikes\n    filter_order : int, optional\n        Order of the filter\n    filter_rs : int, optional\n        Resonance frequency of the filter\n    method : str, optional\n        Method for detecting the dentate spikes.\n        \"difference\" for detecting the dentate spikes by difference between the hilus and mol signal\n        \"seperately\" for detecting the dentate spikes by the hilus and mol signal separately\n    clean_lfp : bool, optional\n        If True, the LFP signal will be cleaned\n    emg_threshold : float, optional\n        Threshold for the EMG signal to remove dentate spikes\n\n\n    Attributes\n    ----------\n    lfp : nelpy.AnalogSignalArray\n        LFP signal\n    filtered_lfp : nelpy.AnalogSignalArray\n        Filtered LFP signal\n    mol_hilus_diff : nelpy.AnalogSignalArray\n        Difference between the hilus and mol signal\n    ds_epoch : nelpy.EpochArray\n        EpochArray with the dentate spikes\n    peak_val : np.ndarray\n        Peak value of the dentate spikes\n\n\n    Methods\n    -------\n    load_lfp()\n        Load the LFP signal\n    filter_signal()\n        Filter the LFP signal\n    get_filtered_lfp()\n        Get the filtered LFP signal\n    get_lfp_diff()\n        Get the difference between the hilus and mol signal\n    detect_ds_difference()\n        Detect the dentate spikes by difference between the hilus and mol signal\n    detect_ds_seperately()\n        Detect the dentate spikes by the hilus and mol signal separately\n    save_ds_epoch()\n        Save the dentate spikes as an EpochArray\n\n    Examples\n    --------\n    In IDE or python console\n\n    &gt;&gt;&gt; from ds_swr.detection.detect_dentate_spike import DetectDS\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; channel_tags = loading.load_channel_tags(basepath)\n    &gt;&gt;&gt; dds = DetectDS(\n        basepath,\n        channel_tags[\"hilus\"][\"channels\"] - 1,\n        channel_tags[\"mol\"][\"channels\"] - 1\n    )\n    &gt;&gt;&gt; dds.detect_ds()\n    &gt;&gt;&gt; dds.save_ds_epoch()\n    &gt;&gt;&gt; dds\n    &lt;DetectDS at 0x17fe787c640: dentate spikes 5,769&gt; of length 1:11:257 minutes\n\n\n    In command line\n\n    &gt;&gt;&gt; python detect_dentate_spike.py Z:\\Data\\Can\\OML22\\day20\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: str,\n        hilus_ch: int,\n        mol_ch: int,\n        noise_ch: Union[int, None] = None,\n        lowcut: int = 10,\n        highcut: int = 250,\n        filter_signal_bool: bool = True,\n        primary_threshold: Union[int, float] = 5,\n        primary_thres_mol: Union[int, float] = 2,\n        primary_thres_hilus: Union[int, float] = 5,\n        min_duration: float = 0.005,\n        max_duration: float = 0.05,\n        filter_order: int = 4,\n        filter_rs: int = 20,\n        method: str = \"seperately\",\n        clean_lfp: bool = False,\n        emg_threshold: float = 0.9,\n    ) -&gt; None:\n        # adding all the parameters to the class\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n        # setting the type name\n        self.type_name = self.__class__.__name__\n        self.get_xml_data()\n\n    def get_xml_data(self):\n        \"\"\"\n        Load the XML file to get the number of channels, sampling frequency and shank to channel mapping\n        \"\"\"\n        nChannels, fs, fs_dat, shank_to_channel = loading.loadXML(self.basepath)\n        self.nChannels = nChannels\n        self.fs = fs\n        self.fs_dat = fs_dat\n        self.shank_to_channel = shank_to_channel\n\n    def load_lfp(self):\n        \"\"\"\n        Load the LFP signal\n        \"\"\"\n\n        lfp, timestep = loading.loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            frequency=self.fs,\n            ext=\"lfp\",\n        )\n\n        if self.noise_ch is None:\n            channels = [self.hilus_ch, self.mol_ch]\n        else:\n            channels = [self.hilus_ch, self.mol_ch, self.noise_ch]\n\n        self.lfp = nel.AnalogSignalArray(\n            data=lfp[:, channels].T,\n            timestamps=timestep,\n            fs=self.fs,\n            support=nel.EpochArray(np.array([min(timestep), max(timestep)])),\n        )\n        if self.clean_lfp:\n            self.lfp._data = np.array(\n                [\n                    clean_lfp(self.lfp.signals[0]),\n                    clean_lfp(self.lfp.signals[1]),\n                ]\n            )\n\n    def filter_signal(self):\n        \"\"\"\n        Filter the LFP signal\n\n        Returns\n        -------\n        np.ndarray\n            Filtered LFP signal\n        \"\"\"\n        if not hasattr(self, \"lfp\"):\n            self.load_lfp()\n\n        b, a = cheby2(\n            self.filter_order,\n            self.filter_rs,\n            [self.lowcut, self.highcut],\n            fs=self.fs,\n            btype=\"bandpass\",\n        )\n        return filtfilt(b, a, self.lfp.data)\n\n    def get_filtered_lfp(self):\n        if not hasattr(self, \"lfp\"):\n            self.load_lfp()\n\n        self.filtered_lfp = deepcopy(self.lfp)\n        self.filtered_lfp._data = self.filter_signal()\n\n    def get_lfp_diff(self):\n        if self.filter_signal_bool:\n            y = self.filter_signal()\n        else:\n            if not hasattr(self, \"lfp\"):\n                self.load_lfp()\n            y = self.lfp.data\n\n        self.mol_hilus_diff = nel.AnalogSignalArray(\n            data=y[0, :] - y[1, :],\n            timestamps=self.lfp.abscissa_vals,\n            fs=self.fs,\n            support=nel.EpochArray(\n                np.array([min(self.lfp.abscissa_vals), max(self.lfp.abscissa_vals)])\n            ),\n        )\n\n    def detect_ds_difference(self):\n        if not hasattr(self, \"mol_hilus_diff\"):\n            self.get_lfp_diff()\n\n        PrimaryThreshold = (\n            self.mol_hilus_diff.mean()\n            + self.primary_threshold * self.mol_hilus_diff.std()\n        )\n        SecondaryThreshold = (\n            self.mol_hilus_diff.mean()\n            + self.secondary_threshold * self.mol_hilus_diff.std()\n        )\n        bounds, self.peak_val, _ = nel.utils.get_events_boundaries(\n            x=self.mol_hilus_diff.data,\n            PrimaryThreshold=PrimaryThreshold,\n            SecondaryThreshold=SecondaryThreshold,\n            minThresholdLength=0,\n            minLength=self.min_duration,\n            maxLength=self.max_duration,\n            ds=1 / self.mol_hilus_diff.fs,\n        )\n        # convert bounds to time in seconds\n        timebounds = self.mol_hilus_diff.time[bounds]\n        # add 1/fs to stops for open interval\n        timebounds[:, 1] += 1 / self.mol_hilus_diff.fs\n        # create EpochArray with bounds\n        self.ds_epoch = nel.EpochArray(timebounds)\n\n        # remove ds in high emg\n        _, high_emg_epoch, _ = loading.load_emg(self.basepath, self.emg_threshold)\n        if not high_emg_epoch.isempty:\n            idx = find_intersecting_intervals(self.ds_epoch, high_emg_epoch)\n            self.ds_epoch._data = self.ds_epoch.data[~idx]\n            self.peak_val = self.peak_val[~idx]\n\n    def detect_ds_seperately(self):\n        if not hasattr(self, \"filtered_lfp\"):\n            self.get_filtered_lfp()\n\n        # min and max time width of ds (converted to samples for find_peaks)\n        time_widths = [\n            int(self.min_duration * self.filtered_lfp.fs),\n            int(self.max_duration * self.filtered_lfp.fs),\n        ]\n\n        # detect ds in hilus\n        PrimaryThreshold = (\n            self.filtered_lfp.data[0, :].mean()\n            + self.primary_thres_hilus * self.filtered_lfp.data[0, :].std()\n        )\n\n        peaks, properties = find_peaks(\n            self.filtered_lfp.data[0, :],\n            height=PrimaryThreshold,\n            width=time_widths,\n        )\n        self.peaks = peaks / self.filtered_lfp.fs\n        self.peak_val = properties[\"peak_heights\"]\n\n        # create EpochArray with bounds\n        hilus_epoch = nel.EpochArray(\n            np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n            / self.filtered_lfp.fs\n        )\n\n        # detect ds in mol\n        PrimaryThreshold = (\n            self.filtered_lfp.data[1, :].mean()\n            + self.primary_thres_mol * self.filtered_lfp.data[1, :].std()\n        )\n\n        peaks, properties = find_peaks(\n            -self.filtered_lfp.data[1, :],\n            height=PrimaryThreshold,\n            width=time_widths,\n        )\n        mol_epoch_peak = peaks / self.filtered_lfp.fs\n        # create EpochArray with bounds\n        mol_epoch = nel.EpochArray(\n            np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n            / self.filtered_lfp.fs\n        )\n\n        # detect ds in noise channel\n        if self.noise_ch is not None:\n            PrimaryThreshold = (\n                self.filtered_lfp.data[2, :].mean()\n                + self.primary_thres_hilus * self.filtered_lfp.data[2, :].std()\n            )\n\n            peaks, properties = find_peaks(\n                self.filtered_lfp.data[2, :],\n                height=PrimaryThreshold,\n                width=time_widths,\n            )\n\n            # create EpochArray with bounds\n            noise_epoch = nel.EpochArray(\n                np.array([properties[\"left_ips\"], properties[\"right_ips\"]]).T\n                / self.filtered_lfp.fs\n            )\n\n        # remove hilus spikes that are not overlapping with mol spikes\n        # first, find mol peaks that are within hilus epoch\n        idx = in_intervals(mol_epoch_peak, hilus_epoch.data)\n        mol_epoch._data = mol_epoch.data[idx]\n\n        overlap = find_intersecting_intervals(\n            hilus_epoch, mol_epoch, return_indices=True\n        )\n        self.ds_epoch = nel.EpochArray(hilus_epoch.data[overlap])\n        self.peak_val = self.peak_val[overlap]\n        self.peaks = self.peaks[overlap]\n\n        # remove dentate spikes that are overlapping with noise spikes\n        if self.noise_ch is not None:\n            overlap = find_intersecting_intervals(\n                self.ds_epoch, noise_epoch, return_indices=True\n            )\n            self.ds_epoch = nel.EpochArray(self.ds_epoch.data[~overlap])\n            self.peak_val = self.peak_val[~overlap]\n            self.peaks = self.peaks[~overlap]\n\n        # remove ds in high emg\n        _, high_emg_epoch, _ = loading.load_emg(self.basepath, self.emg_threshold)\n        if not high_emg_epoch.isempty:\n            idx = find_intersecting_intervals(self.ds_epoch, high_emg_epoch)\n            self.ds_epoch._data = self.ds_epoch.data[~idx]\n            self.peak_val = self.peak_val[~idx]\n            self.peaks = self.peaks[~idx]\n\n    def detect_ds(self):\n        \"\"\"\n        Detect the dentate spikes based on the method provided\n        \"\"\"\n        if self.method == \"difference\":\n            # deprecated\n            raise NotImplementedError\n            # self.detect_ds_difference()\n        elif self.method == \"seperately\":\n            self.detect_ds_seperately()\n        else:\n            raise ValueError(f\"Method {self.method} not recognized\")\n\n    def save_ds_epoch(self):\n        \"\"\"\n        Save the dentate spikes as a cellexplorer mat file\n        \"\"\"\n\n        filename = os.path.join(\n            self.basepath, os.path.basename(self.basepath) + \".DS2.events.mat\"\n        )\n        data = {}\n        data[\"DS2\"] = {}\n        data[\"DS2\"][\"detectorinfo\"] = {}\n        data[\"DS2\"][\"timestamps\"] = self.ds_epoch.data\n        data[\"DS2\"][\"peaks\"] = self.peaks\n        data[\"DS2\"][\"amplitudes\"] = self.peak_val.T\n        data[\"DS2\"][\"amplitudeUnits\"] = \"mV\"\n        data[\"DS2\"][\"eventID\"] = []\n        data[\"DS2\"][\"eventIDlabels\"] = []\n        data[\"DS2\"][\"eventIDbinary\"] = []\n        data[\"DS2\"][\"duration\"] = self.ds_epoch.durations.T\n        data[\"DS2\"][\"center\"] = np.median(self.ds_epoch.data, axis=1).T\n        data[\"DS2\"][\"detectorinfo\"][\"detectorname\"] = \"DetectDS\"\n        data[\"DS2\"][\"detectorinfo\"][\"detectionparms\"] = []\n        data[\"DS2\"][\"detectorinfo\"][\"detectionintervals\"] = []\n        data[\"DS2\"][\"detectorinfo\"][\"ml_channel\"] = self.mol_ch\n        data[\"DS2\"][\"detectorinfo\"][\"h_channel\"] = self.hilus_ch\n        if self.noise_ch is not None:\n            data[\"DS2\"][\"detectorinfo\"][\"noise_channel\"] = self.noise_ch\n\n        savemat(filename, data, long_field_names=True)\n\n    def get_average_trace(self, shank=None, window=[-0.15, 0.15]):\n        \"\"\"\n        Get the average LFP trace around the dentate spikes\n\n        Parameters\n        ----------\n        shank : int, optional\n            Shank number of the hilus signal\n        window : list, optional\n            Window around the dentate spikes\n\n        Returns\n        -------\n        np.ndarray\n            Average LFP trace around the dentate spikes\n        np.ndarray\n            Time lags around the dentate spikes\n        \"\"\"\n\n        lfp, _ = loading.loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            frequency=self.fs,\n            ext=\"lfp\",\n        )\n\n        if shank is None:\n            hilus_shank = [\n                k for k, v in self.shank_to_channel.items() if self.hilus_ch in v\n            ][0]\n\n        ds_average, time_lags = event_triggered_average_fast(\n            signal=lfp[:, self.shank_to_channel[hilus_shank]].T,\n            events=self.ds_epoch.starts,\n            sampling_rate=self.fs,\n            window=window,\n            return_average=True,\n        )\n        return ds_average, time_lags\n\n    def plot(self, ax=None, window=[-0.15, 0.15], channel_offset=9e4):\n        \"\"\"\n        Plot the average LFP trace around the dentate spikes\n\n        Parameters\n        ----------\n        ax : matplotlib.axes._subplots.AxesSubplot, optional\n            Axis to plot the average LFP trace\n        window : list, optional\n            Window around the dentate spikes\n        channel_offset : float, optional\n            Offset between the channels\n\n        Returns\n        -------\n        matplotlib.axes._subplots.AxesSubplot\n            Axis with the average LFP trace\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n\n        ds_average, time_lags = self.get_average_trace(window=window)\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(5, 10))\n\n        ax.plot(\n            time_lags,\n            ds_average.T - np.linspace(0, channel_offset, ds_average.shape[0]),\n            alpha=0.75,\n        )\n        return ax\n\n    def _detach(self):\n        \"\"\"Detach the data from the object to allow for pickling\"\"\"\n        self.filtered_lfp = None\n        self.lfp = None\n        self.mol_hilus_diff = None\n\n    def save(self, filename: str):\n        \"\"\"\n        Save the DetectDS object as a pickle file\n\n        Parameters\n        ----------\n        filename : str\n            Path to the file where the DetectDS object will be saved\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        self._detach()\n        with open(filename, \"wb\") as f:\n            pickle.dump(self, f)\n\n    @classmethod\n    def load(cls, filename: str):\n        \"\"\"\n        Load a DetectDS object from a pickle file\n\n        Parameters\n        ----------\n        filename : str\n            Path to the file where the DetectDS object is saved\n\n        Returns\n        -------\n        DetectDS\n            The loaded DetectDS object\n\n        \"\"\"\n        with open(filename, \"rb\") as f:\n            return pickle.load(f)\n\n    def __repr__(self) -&gt; str:\n        address_str = \" at \" + str(hex(id(self)))\n\n        if not hasattr(self, \"ds_epoch\"):\n            return \"&lt;%s%s&gt;\" % (self.type_name, address_str)\n\n        if self.ds_epoch.isempty:\n            return \"&lt;%s%s: empty&gt;\" % self.type_name\n\n        dentate_spikes = f\"dentate spikes {self.ds_epoch.n_intervals}\"\n        dstr = f\"of length {self.ds_epoch.length}\"\n\n        return \"&lt;%s%s: %s&gt; %s\" % (self.type_name, address_str, dentate_spikes, dstr)\n\n    def __str__(self) -&gt; str:\n        return self.__repr__()\n\n    def __len__(self) -&gt; int:\n        if not hasattr(self, \"ds_epoch\"):\n            return 0\n        return self.ds_epoch.n_intervals\n\n    def __getitem__(self, key):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return self.ds_epoch[key]\n\n    def __iter__(self):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return iter(self.ds_epoch)\n\n    def __contains__(self, item):\n        if not hasattr(self, \"ds_epoch\"):\n            raise IndexError(\"No dentate spikes detected yet\")\n        return item in self.ds_epoch\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS._detach","title":"<code>_detach()</code>","text":"<p>Detach the data from the object to allow for pickling</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def _detach(self):\n    \"\"\"Detach the data from the object to allow for pickling\"\"\"\n    self.filtered_lfp = None\n    self.lfp = None\n    self.mol_hilus_diff = None\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.detect_ds","title":"<code>detect_ds()</code>","text":"<p>Detect the dentate spikes based on the method provided</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def detect_ds(self):\n    \"\"\"\n    Detect the dentate spikes based on the method provided\n    \"\"\"\n    if self.method == \"difference\":\n        # deprecated\n        raise NotImplementedError\n        # self.detect_ds_difference()\n    elif self.method == \"seperately\":\n        self.detect_ds_seperately()\n    else:\n        raise ValueError(f\"Method {self.method} not recognized\")\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.filter_signal","title":"<code>filter_signal()</code>","text":"<p>Filter the LFP signal</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered LFP signal</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def filter_signal(self):\n    \"\"\"\n    Filter the LFP signal\n\n    Returns\n    -------\n    np.ndarray\n        Filtered LFP signal\n    \"\"\"\n    if not hasattr(self, \"lfp\"):\n        self.load_lfp()\n\n    b, a = cheby2(\n        self.filter_order,\n        self.filter_rs,\n        [self.lowcut, self.highcut],\n        fs=self.fs,\n        btype=\"bandpass\",\n    )\n    return filtfilt(b, a, self.lfp.data)\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.get_average_trace","title":"<code>get_average_trace(shank=None, window=[-0.15, 0.15])</code>","text":"<p>Get the average LFP trace around the dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>shank</code> <code>int</code> <p>Shank number of the hilus signal</p> <code>None</code> <code>window</code> <code>list</code> <p>Window around the dentate spikes</p> <code>[-0.15, 0.15]</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Average LFP trace around the dentate spikes</p> <code>ndarray</code> <p>Time lags around the dentate spikes</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def get_average_trace(self, shank=None, window=[-0.15, 0.15]):\n    \"\"\"\n    Get the average LFP trace around the dentate spikes\n\n    Parameters\n    ----------\n    shank : int, optional\n        Shank number of the hilus signal\n    window : list, optional\n        Window around the dentate spikes\n\n    Returns\n    -------\n    np.ndarray\n        Average LFP trace around the dentate spikes\n    np.ndarray\n        Time lags around the dentate spikes\n    \"\"\"\n\n    lfp, _ = loading.loadLFP(\n        self.basepath,\n        n_channels=self.nChannels,\n        frequency=self.fs,\n        ext=\"lfp\",\n    )\n\n    if shank is None:\n        hilus_shank = [\n            k for k, v in self.shank_to_channel.items() if self.hilus_ch in v\n        ][0]\n\n    ds_average, time_lags = event_triggered_average_fast(\n        signal=lfp[:, self.shank_to_channel[hilus_shank]].T,\n        events=self.ds_epoch.starts,\n        sampling_rate=self.fs,\n        window=window,\n        return_average=True,\n    )\n    return ds_average, time_lags\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.get_xml_data","title":"<code>get_xml_data()</code>","text":"<p>Load the XML file to get the number of channels, sampling frequency and shank to channel mapping</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def get_xml_data(self):\n    \"\"\"\n    Load the XML file to get the number of channels, sampling frequency and shank to channel mapping\n    \"\"\"\n    nChannels, fs, fs_dat, shank_to_channel = loading.loadXML(self.basepath)\n    self.nChannels = nChannels\n    self.fs = fs\n    self.fs_dat = fs_dat\n    self.shank_to_channel = shank_to_channel\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.load","title":"<code>load(filename)</code>  <code>classmethod</code>","text":"<p>Load a DetectDS object from a pickle file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the file where the DetectDS object is saved</p> required <p>Returns:</p> Type Description <code>DetectDS</code> <p>The loaded DetectDS object</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>@classmethod\ndef load(cls, filename: str):\n    \"\"\"\n    Load a DetectDS object from a pickle file\n\n    Parameters\n    ----------\n    filename : str\n        Path to the file where the DetectDS object is saved\n\n    Returns\n    -------\n    DetectDS\n        The loaded DetectDS object\n\n    \"\"\"\n    with open(filename, \"rb\") as f:\n        return pickle.load(f)\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.load_lfp","title":"<code>load_lfp()</code>","text":"<p>Load the LFP signal</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def load_lfp(self):\n    \"\"\"\n    Load the LFP signal\n    \"\"\"\n\n    lfp, timestep = loading.loadLFP(\n        self.basepath,\n        n_channels=self.nChannels,\n        frequency=self.fs,\n        ext=\"lfp\",\n    )\n\n    if self.noise_ch is None:\n        channels = [self.hilus_ch, self.mol_ch]\n    else:\n        channels = [self.hilus_ch, self.mol_ch, self.noise_ch]\n\n    self.lfp = nel.AnalogSignalArray(\n        data=lfp[:, channels].T,\n        timestamps=timestep,\n        fs=self.fs,\n        support=nel.EpochArray(np.array([min(timestep), max(timestep)])),\n    )\n    if self.clean_lfp:\n        self.lfp._data = np.array(\n            [\n                clean_lfp(self.lfp.signals[0]),\n                clean_lfp(self.lfp.signals[1]),\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.plot","title":"<code>plot(ax=None, window=[-0.15, 0.15], channel_offset=90000.0)</code>","text":"<p>Plot the average LFP trace around the dentate spikes</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>AxesSubplot</code> <p>Axis to plot the average LFP trace</p> <code>None</code> <code>window</code> <code>list</code> <p>Window around the dentate spikes</p> <code>[-0.15, 0.15]</code> <code>channel_offset</code> <code>float</code> <p>Offset between the channels</p> <code>90000.0</code> <p>Returns:</p> Type Description <code>AxesSubplot</code> <p>Axis with the average LFP trace</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def plot(self, ax=None, window=[-0.15, 0.15], channel_offset=9e4):\n    \"\"\"\n    Plot the average LFP trace around the dentate spikes\n\n    Parameters\n    ----------\n    ax : matplotlib.axes._subplots.AxesSubplot, optional\n        Axis to plot the average LFP trace\n    window : list, optional\n        Window around the dentate spikes\n    channel_offset : float, optional\n        Offset between the channels\n\n    Returns\n    -------\n    matplotlib.axes._subplots.AxesSubplot\n        Axis with the average LFP trace\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n\n    ds_average, time_lags = self.get_average_trace(window=window)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(5, 10))\n\n    ax.plot(\n        time_lags,\n        ds_average.T - np.linspace(0, channel_offset, ds_average.shape[0]),\n        alpha=0.75,\n    )\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.save","title":"<code>save(filename)</code>","text":"<p>Save the DetectDS object as a pickle file</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the file where the DetectDS object will be saved</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def save(self, filename: str):\n    \"\"\"\n    Save the DetectDS object as a pickle file\n\n    Parameters\n    ----------\n    filename : str\n        Path to the file where the DetectDS object will be saved\n\n    Returns\n    -------\n    None\n\n    \"\"\"\n    self._detach()\n    with open(filename, \"wb\") as f:\n        pickle.dump(self, f)\n</code></pre>"},{"location":"reference/neuro_py/detectors/dentate_spike/#neuro_py.detectors.dentate_spike.DetectDS.save_ds_epoch","title":"<code>save_ds_epoch()</code>","text":"<p>Save the dentate spikes as a cellexplorer mat file</p> Source code in <code>neuro_py/detectors/dentate_spike.py</code> <pre><code>def save_ds_epoch(self):\n    \"\"\"\n    Save the dentate spikes as a cellexplorer mat file\n    \"\"\"\n\n    filename = os.path.join(\n        self.basepath, os.path.basename(self.basepath) + \".DS2.events.mat\"\n    )\n    data = {}\n    data[\"DS2\"] = {}\n    data[\"DS2\"][\"detectorinfo\"] = {}\n    data[\"DS2\"][\"timestamps\"] = self.ds_epoch.data\n    data[\"DS2\"][\"peaks\"] = self.peaks\n    data[\"DS2\"][\"amplitudes\"] = self.peak_val.T\n    data[\"DS2\"][\"amplitudeUnits\"] = \"mV\"\n    data[\"DS2\"][\"eventID\"] = []\n    data[\"DS2\"][\"eventIDlabels\"] = []\n    data[\"DS2\"][\"eventIDbinary\"] = []\n    data[\"DS2\"][\"duration\"] = self.ds_epoch.durations.T\n    data[\"DS2\"][\"center\"] = np.median(self.ds_epoch.data, axis=1).T\n    data[\"DS2\"][\"detectorinfo\"][\"detectorname\"] = \"DetectDS\"\n    data[\"DS2\"][\"detectorinfo\"][\"detectionparms\"] = []\n    data[\"DS2\"][\"detectorinfo\"][\"detectionintervals\"] = []\n    data[\"DS2\"][\"detectorinfo\"][\"ml_channel\"] = self.mol_ch\n    data[\"DS2\"][\"detectorinfo\"][\"h_channel\"] = self.hilus_ch\n    if self.noise_ch is not None:\n        data[\"DS2\"][\"detectorinfo\"][\"noise_channel\"] = self.noise_ch\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/detectors/up_down_state/","title":"neuro_py.detectors.up_down_state","text":""},{"location":"reference/neuro_py/detectors/up_down_state/#neuro_py.detectors.up_down_state.bimodal_thresh","title":"<code>bimodal_thresh(bimodal_data, max_thresh=np.inf, schmidt=False, max_hist_bins=25, start_bins=10, set_thresh=None, nboot=100, force_bimodal=False)</code>","text":"<p>BimodalThresh: Find threshold between bimodal data modes (e.g., UP vs DOWN states) and return crossing times (UP/DOWN onset/offset times).</p> <p>Parameters:</p> Name Type Description Default <code>bimodal_data</code> <code>array - like</code> <p>Vector of bimodal data</p> required <code>max_thresh</code> <code>float</code> <p>Maximum threshold value (default: inf)</p> <code>inf</code> <code>schmidt</code> <code>bool</code> <p>Use Schmidt trigger with halfway points between trough and peaks (default: False)</p> <code>False</code> <code>max_hist_bins</code> <code>int</code> <p>Maximum number of histogram bins to try before giving up (default: 25)</p> <code>25</code> <code>start_bins</code> <code>int</code> <p>Minimum number of histogram bins for initial histogram (default: 10)</p> <code>10</code> <code>set_thresh</code> <code>float</code> <p>Manually set your own threshold (default: None)</p> <code>None</code> <code>nboot</code> <code>int</code> <p>Number of bootstrap iterations for dip test (default: 100)</p> <code>100</code> <code>force_bimodal</code> <code>bool</code> <p>If True, skip bimodality test and proceed with threshold detection (default: False)</p> <code>False</code> <p>Returns:</p> Name Type Description <code>thresh</code> <code>float</code> <p>Threshold value between modes</p> <code>cross</code> <code>dict</code> <p>Dictionary with keys: - 'upints': array of UP state intervals [onsets, offsets] - 'downints': array of DOWN state intervals [onsets, offsets]</p> <code>bihist</code> <code>dict</code> <p>Dictionary with keys: - 'bins': bin centers - 'hist': counts</p> <code>diptest_result</code> <code>dict</code> <p>Dictionary with keys: - 'dip': Hartigan's dip test statistic - 'p': p-value for bimodal distribution</p> Example <p>data = np.concatenate([np.random.normal(0, 1, 1000), ...                        np.random.normal(5, 1, 1000)]) thresh, cross, bihist, diptest_result = bimodal_thresh(data)</p> Notes <p>Python translation of BimodalThresh.m from MehrotraLevenstein_2023</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def bimodal_thresh(\n    bimodal_data,\n    max_thresh=np.inf,\n    schmidt=False,\n    max_hist_bins=25,\n    start_bins=10,\n    set_thresh=None,\n    nboot=100,\n    force_bimodal=False,\n):\n    \"\"\"\n    BimodalThresh: Find threshold between bimodal data modes (e.g., UP vs DOWN states)\n    and return crossing times (UP/DOWN onset/offset times).\n\n    Parameters\n    ----------\n    bimodal_data : array-like\n        Vector of bimodal data\n    max_thresh : float, optional\n        Maximum threshold value (default: inf)\n    schmidt : bool, optional\n        Use Schmidt trigger with halfway points between trough and peaks (default: False)\n    max_hist_bins : int, optional\n        Maximum number of histogram bins to try before giving up (default: 25)\n    start_bins : int, optional\n        Minimum number of histogram bins for initial histogram (default: 10)\n    set_thresh : float, optional\n        Manually set your own threshold (default: None)\n    nboot : int, optional\n        Number of bootstrap iterations for dip test (default: 100)\n    force_bimodal : bool, optional\n        If True, skip bimodality test and proceed with threshold detection (default: False)\n\n    Returns\n    -------\n    thresh : float\n        Threshold value between modes\n    cross : dict\n        Dictionary with keys:\n        - 'upints': array of UP state intervals [onsets, offsets]\n        - 'downints': array of DOWN state intervals [onsets, offsets]\n    bihist : dict\n        Dictionary with keys:\n        - 'bins': bin centers\n        - 'hist': counts\n    diptest_result : dict\n        Dictionary with keys:\n        - 'dip': Hartigan's dip test statistic\n        - 'p': p-value for bimodal distribution\n\n    Example\n    -------\n    &gt;&gt;&gt; data = np.concatenate([np.random.normal(0, 1, 1000),\n    ...                        np.random.normal(5, 1, 1000)])\n    &gt;&gt;&gt; thresh, cross, bihist, diptest_result = bimodal_thresh(data)\n\n    Notes\n    -----\n    Python translation of BimodalThresh.m from MehrotraLevenstein_2023\n\n    \"\"\"\n\n    # Initialize\n    bimodal_data = np.array(bimodal_data).flatten()\n    bimodal_data = bimodal_data[~np.isnan(bimodal_data)]\n\n    # Run Hartigan's dip test for bimodality\n    dip_stat, p_value = hartigan_diptest(bimodal_data, n_boot=nboot)\n    diptest_result = {\"dip\": dip_stat, \"p\": p_value}\n\n    # If not bimodal, return empty (unless forced)\n    if p_value &gt; 0.05 and not force_bimodal:\n        cross = {\"upints\": np.array([]), \"downints\": np.array([])}\n        hist_counts, bin_edges = np.histogram(bimodal_data, bins=start_bins)\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n        bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n        return np.nan, cross, bihist, diptest_result\n\n    # Remove data over max threshold\n    bimodal_data = bimodal_data[bimodal_data &lt; max_thresh]\n\n    # Find histogram with exactly 2 peaks\n    num_peaks = 1\n    num_bins = start_bins\n\n    while num_peaks != 2:\n        hist_counts, bin_edges = np.histogram(bimodal_data, bins=num_bins)\n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n\n        # Find peaks (add zeros at edges for edge detection)\n        padded_hist = np.concatenate([[0], hist_counts, [0]])\n        peaks, _ = find_peaks(padded_hist, distance=1)\n        peaks = np.sort(peaks) - 1  # Adjust for padding\n\n        # Keep only top 2 peaks\n        if len(peaks) &gt; 2:\n            peak_heights = hist_counts[peaks]\n            top_2_idx = np.argsort(peak_heights)[-2:]\n            peaks = np.sort(peaks[top_2_idx])\n\n        num_peaks = len(peaks)\n        num_bins += 1\n\n        if num_bins &gt;= max_hist_bins and set_thresh is None:\n            print(\"Unable to find trough\")\n            cross = {\"upints\": np.array([]), \"downints\": np.array([])}\n            bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n            return np.nan, cross, bihist, diptest_result\n\n    bihist = {\"hist\": hist_counts, \"bins\": bin_centers}\n\n    # Find trough between peaks\n    between_peaks = bin_centers[peaks[0] : peaks[1] + 1]\n    between_hist = hist_counts[peaks[0] : peaks[1] + 1]\n\n    # Find minimum (trough)\n    trough_idx = np.argmin(between_hist)\n\n    if set_thresh is not None:\n        thresh = set_thresh\n    else:\n        thresh = between_peaks[trough_idx]\n\n    # Schmidt trigger: use halfway points between trough and peaks\n    if schmidt:\n        thresh_up = thresh + 0.5 * (between_peaks[-1] - thresh)\n        thresh_down = thresh + 0.5 * (between_peaks[0] - thresh)\n\n        over_up = bimodal_data &gt; thresh_up\n        over_down = bimodal_data &gt; thresh_down\n\n        cross_up = np.where(np.diff(over_up.astype(int)) == 1)[0]\n        cross_down = np.where(np.diff(over_down.astype(int)) == -1)[0]\n\n        # Check for empty crossings before vstack\n        if len(cross_up) == 0 or len(cross_down) == 0:\n            cross = {\n                \"upints\": np.array([]).reshape(0, 2),\n                \"downints\": np.array([]).reshape(0, 2),\n            }\n            return thresh, cross, bihist, diptest_result\n\n        # Delete incomplete (repeat) crossings\n        all_crossings = np.vstack(\n            [\n                np.column_stack([cross_up, np.ones(len(cross_up))]),\n                np.column_stack([cross_down, np.zeros(len(cross_down))]),\n            ]\n        )\n\n        sort_order = np.argsort(all_crossings[:, 0])\n        all_crossings = all_crossings[sort_order]\n\n        up_down_switch = np.diff(all_crossings[:, 1])\n        same_state = np.where(up_down_switch == 0)[0] + 1\n        all_crossings = np.delete(all_crossings, same_state, axis=0)\n\n        cross_up = all_crossings[all_crossings[:, 1] == 1, 0].astype(int)\n        cross_down = all_crossings[all_crossings[:, 1] == 0, 0].astype(int)\n    else:\n        over_ind = bimodal_data &gt; thresh\n        cross_up = np.where(np.diff(over_ind.astype(int)) == 1)[0]\n        cross_down = np.where(np.diff(over_ind.astype(int)) == -1)[0]\n\n    # If only one crossing, return empty\n    if len(cross_up) == 0 or len(cross_down) == 0:\n        cross = {\n            \"upints\": np.array([]).reshape(0, 2),\n            \"downints\": np.array([]).reshape(0, 2),\n        }\n        return thresh, cross, bihist, diptest_result\n\n    # Create interval arrays\n    up_for_up = cross_up.copy()\n    up_for_down = cross_up.copy()\n    down_for_up = cross_down.copy()\n    down_for_down = cross_down.copy()\n\n    # Adjust for proper pairing\n    if cross_up[0] &lt; cross_down[0]:\n        up_for_down = up_for_down[1:]\n    if cross_down[-1] &gt; cross_up[-1]:\n        down_for_down = down_for_down[:-1]\n    if cross_down[0] &lt; cross_up[0]:\n        down_for_up = down_for_up[1:]\n    if cross_up[-1] &gt; cross_down[-1]:\n        up_for_up = up_for_up[:-1]\n\n    # Ensure equal length for pairing\n    min_len_up = min(len(up_for_up), len(down_for_up))\n    min_len_down = min(len(down_for_down), len(up_for_down))\n\n    # Check if pairing resulted in any valid intervals\n    if min_len_up == 0 or min_len_down == 0:\n        cross = {\n            \"upints\": np.array([]).reshape(0, 2),\n            \"downints\": np.array([]).reshape(0, 2),\n        }\n        return thresh, cross, bihist, diptest_result\n\n    upints = np.column_stack([up_for_up[:min_len_up], down_for_up[:min_len_up]])\n    downints = np.column_stack(\n        [down_for_down[:min_len_down], up_for_down[:min_len_down]]\n    )\n\n    cross = {\"upints\": upints, \"downints\": downints}\n\n    return thresh, cross, bihist, diptest_result\n</code></pre>"},{"location":"reference/neuro_py/detectors/up_down_state/#neuro_py.detectors.up_down_state.detect_up_down_states","title":"<code>detect_up_down_states(basepath=None, st=None, nrem_epochs=None, region='ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX', min_dur=0.03, max_dur=0.5, percentile=20, bin_size=0.01, smooth_sigma=0.02, min_cells=10, save_mat=True, epoch_by_epoch=False, beh_epochs=None, show_figure=False, overwrite=False)</code>","text":"<p>Detect UP and DOWN states in neural data.</p> <p>UP and DOWN states are identified by computing the total firing rate of all simultaneously recorded neurons in bins of 10 ms, smoothed with a Gaussian kernel of 20 ms s.d. Epochs with a firing rate below the specified percentile threshold are considered DOWN states, while the intervals between DOWN states are classified as UP states. Epochs shorter than <code>min_dur</code> or longer than <code>max_dur</code> are discarded.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Base directory path where event files and neural data are stored.</p> <code>None</code> <code>st</code> <code>Optional[SpikeTrain]</code> <p>Spike train data. If None, spike data will be loaded based on specified regions.</p> <code>None</code> <code>nrem_epochs</code> <code>Optional[EpochArray]</code> <p>NREM epochs. If None, epochs will be loaded from the basepath.</p> <code>None</code> <code>region</code> <code>str</code> <p>Brain regions for loading spikes. The first region is prioritized.</p> <code>\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC\"</code> <code>min_dur</code> <code>float</code> <p>Minimum duration for DOWN states, in seconds.</p> <code>0.03</code> <code>max_dur</code> <code>float</code> <p>Maximum duration for DOWN states, in seconds.</p> <code>0.5</code> <code>percentile</code> <code>float</code> <p>Percentile threshold for determining DOWN states based on firing rate.</p> <code>20</code> <code>bin_size</code> <code>float</code> <p>Bin size for computing firing rates, in seconds.</p> <code>0.01</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian kernel smoothing, in seconds.</p> <code>0.02</code> <code>min_cells</code> <code>int</code> <p>Minimum number of neurons required for analysis.</p> <code>10</code> <code>save_mat</code> <code>bool</code> <p>Whether to save the detected UP and DOWN states to .mat files.</p> <code>True</code> <code>epoch_by_epoch</code> <code>bool</code> <p>Whether to perform detection epoch by epoch. If True, detection will be performed separately for each sleep epoch.</p> <code>False</code> <code>beh_epochs</code> <code>Optional[EpochArray]</code> <p>Optional behavioral epochs to use for epoch-by-epoch detection. If None, sleep epochs will be loaded and used.</p> <code>None</code> <code>show_figure</code> <code>bool</code> <p>Whether to display a figure showing firing rates during detected UP and DOWN states.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing .mat files when saving detected states.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[Optional[EpochArray], Optional[EpochArray]]</code> <p>A tuple containing the detected DOWN state epochs and UP state epochs. Returns (None, None) if no suitable states are found or insufficient data is available.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; down_state, up_state = detect_up_down_states(basepath=\"/path/to/data\", show_figure=True)\n</code></pre> <p>From command line: $ python up_down_state.py /path/to/data</p> Notes <p>Detection method based on https://doi.org/10.1038/s41467-020-15842-4</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def detect_up_down_states(\n    basepath: Optional[str] = None,\n    st: Optional[nel.SpikeTrainArray] = None,\n    nrem_epochs: Optional[nel.EpochArray] = None,\n    region: str = \"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\",\n    min_dur: float = 0.03,\n    max_dur: float = 0.5,\n    percentile: float = 20,\n    bin_size: float = 0.01,\n    smooth_sigma: float = 0.02,\n    min_cells: int = 10,\n    save_mat: bool = True,\n    epoch_by_epoch: bool = False,\n    beh_epochs: Optional[nel.EpochArray] = None,\n    show_figure: bool = False,\n    overwrite: bool = False,\n) -&gt; Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]:\n    \"\"\"\n    Detect UP and DOWN states in neural data.\n\n    UP and DOWN states are identified by computing the total firing rate of all\n    simultaneously recorded neurons in bins of 10 ms, smoothed with a Gaussian kernel\n    of 20 ms s.d. Epochs with a firing rate below the specified percentile threshold\n    are considered DOWN states, while the intervals between DOWN states are classified\n    as UP states. Epochs shorter than `min_dur` or longer than `max_dur` are discarded.\n\n    Parameters\n    ----------\n    basepath : str\n        Base directory path where event files and neural data are stored.\n    st : Optional[nel.SpikeTrain], default=None\n        Spike train data. If None, spike data will be loaded based on specified regions.\n    nrem_epochs : Optional[nel.EpochArray], default=None\n        NREM epochs. If None, epochs will be loaded from the basepath.\n    region : str, default=\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC\"\n        Brain regions for loading spikes. The first region is prioritized.\n    min_dur : float, default=0.03\n        Minimum duration for DOWN states, in seconds.\n    max_dur : float, default=0.5\n        Maximum duration for DOWN states, in seconds.\n    percentile : float, default=20\n        Percentile threshold for determining DOWN states based on firing rate.\n    bin_size : float, default=0.01\n        Bin size for computing firing rates, in seconds.\n    smooth_sigma : float, default=0.02\n        Standard deviation for Gaussian kernel smoothing, in seconds.\n    min_cells : int, default=10\n        Minimum number of neurons required for analysis.\n    save_mat : bool, default=True\n        Whether to save the detected UP and DOWN states to .mat files.\n    epoch_by_epoch : bool, default=False\n        Whether to perform detection epoch by epoch. If True, detection will be performed separately for each sleep epoch.\n    beh_epochs : Optional[nel.EpochArray], default=None\n        Optional behavioral epochs to use for epoch-by-epoch detection. If None, sleep epochs will be loaded and used.\n    show_figure : bool, default=False\n        Whether to display a figure showing firing rates during detected UP and DOWN states.\n    overwrite : bool, default=False\n        Whether to overwrite existing .mat files when saving detected states.\n\n    Returns\n    -------\n    Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]\n        A tuple containing the detected DOWN state epochs and UP state epochs.\n        Returns (None, None) if no suitable states are found or insufficient data is available.\n\n    Examples\n    --------\n    &gt;&gt;&gt; down_state, up_state = detect_up_down_states(basepath=\"/path/to/data\", show_figure=True)\n\n    From command line:\n    $ python up_down_state.py /path/to/data\n\n    Notes\n    -----\n    Detection method based on https://doi.org/10.1038/s41467-020-15842-4\n    \"\"\"\n\n    def _detect_states(bst_segment: nel.AnalogSignalArray, domain: nel.EpochArray):\n        \"\"\"Detect down/up states within a given domain using shared logic.\"\"\"\n\n        down_state_epochs = bst_segment.bin_centers[\n            find_interval(\n                bst_segment.data.flatten()\n                &lt; np.percentile(bst_segment.data.T, percentile)\n            )\n        ]\n        if down_state_epochs.shape[0] == 0:\n            return None, None\n\n        durations = down_state_epochs[:, 1] - down_state_epochs[:, 0]\n        down_state_epochs = down_state_epochs[durations &gt; bin_size]\n\n        down_state_epochs = (\n            nel.EpochArray(data=down_state_epochs).merge(gap=bin_size * 2).data\n        )\n        durations = down_state_epochs[:, 1] - down_state_epochs[:, 0]\n        down_state_epochs = down_state_epochs[\n            ~((durations &lt; min_dur) | (durations &gt; max_dur)), :\n        ]\n        if down_state_epochs.shape[0] == 0:\n            return None, None\n\n        down_state_epochs = nel.EpochArray(data=down_state_epochs, domain=domain)\n\n        up_state_epochs = ~down_state_epochs\n        up_state_epochs = up_state_epochs.data\n        # make sure up states are longer than bin size\n        durations = up_state_epochs[:, 1] - up_state_epochs[:, 0]\n        up_state_epochs = up_state_epochs[durations &gt; bin_size]\n        # merge nearby up states that are closer than 2*bin_size\n        up_state_epochs = nel.EpochArray(data=up_state_epochs, domain=domain).merge(\n            gap=bin_size * 2\n        )\n\n        return down_state_epochs, up_state_epochs\n\n    # check for existence of event files\n    if save_mat and not overwrite:\n        filename_downstate = os.path.join(\n            basepath, os.path.basename(basepath) + \".\" + \"down_state\" + \".events.mat\"\n        )\n        filename_upstate = os.path.join(\n            basepath, os.path.basename(basepath) + \".\" + \"up_state\" + \".events.mat\"\n        )\n        if os.path.exists(filename_downstate) &amp; os.path.exists(filename_upstate):\n            down_state = loading.load_events(basepath=basepath, epoch_name=\"down_state\")\n            up_state = loading.load_events(basepath=basepath, epoch_name=\"up_state\")\n            return down_state, up_state\n\n    # load brain states\n    if nrem_epochs is None:\n        state_dict = loading.load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"])\n\n    if nrem_epochs.isempty:\n        print(f\"No NREM epochs found for {basepath}\")\n        return None, None\n\n    # load spikes\n    if st is None:\n        st, _ = loading.load_spikes(basepath, brainRegion=region)\n\n    # check if there are enough cells\n    if st is None or st.isempty or st.data.shape[0] &lt; min_cells:\n        print(f\"No spikes found for {basepath} {region}\")\n        return None, None\n\n    # flatten spikes\n    st = st[nrem_epochs].flatten()\n\n    # bin and smooth\n    bst = st.bin(ds=bin_size).smooth(sigma=smooth_sigma)\n\n    if epoch_by_epoch:\n        if beh_epochs is None:\n            epoch_df = npy.io.load_epoch(basepath)\n            epoch_df = npy.session.compress_repeated_epochs(epoch_df)\n            epoch_df = epoch_df.query(\"environment == 'sleep'\")\n            beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n        down_state_epochs = []\n        up_state_epochs = []\n        for ep in beh_epochs:\n            domain = nrem_epochs &amp; ep\n            if domain.isempty:\n                continue\n\n            down_state_epochs_, up_state_epochs_ = _detect_states(bst[domain], domain)\n            if down_state_epochs_ is None or up_state_epochs_ is None:\n                continue\n\n            down_state_epochs.append(down_state_epochs_.data)\n            up_state_epochs.append(up_state_epochs_.data)\n\n        if len(down_state_epochs) == 0 or len(up_state_epochs) == 0:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n        down_state_epochs = nel.EpochArray(\n            data=np.concatenate(down_state_epochs), domain=nrem_epochs\n        )\n        up_state_epochs = nel.EpochArray(\n            data=np.concatenate(up_state_epochs), domain=nrem_epochs\n        )\n    else:\n        down_state_epochs, up_state_epochs = _detect_states(bst, nrem_epochs)\n        if down_state_epochs is None or up_state_epochs is None:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n    # save to cell explorer mat file\n    if save_mat:\n        epoch_to_mat(down_state_epochs, basepath, \"down_state\", \"detect_up_down_states\")\n        epoch_to_mat(up_state_epochs, basepath, \"up_state\", \"detect_up_down_states\")\n\n    # optional figure to show firing rate during up and down states\n    if show_figure:\n        from matplotlib import pyplot as plt\n\n        plt.figure()\n        ax = plt.gca()\n        psth = npy.process.compute_psth(st.data, down_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Down states\"]\n        psth.plot(ax=ax)\n\n        psth = npy.process.compute_psth(st.data, up_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Up states\"]\n\n        psth.plot(ax=ax)\n        ax.legend(loc=\"upper right\", frameon=False)\n        ax.axvline(0, color=\"k\", linestyle=\"--\")\n\n        ax.set_xlabel(\"Time from state transition (s)\")\n        ax.set_ylabel(\"Firing rate (Hz)\")\n\n    return down_state_epochs, up_state_epochs\n</code></pre>"},{"location":"reference/neuro_py/detectors/up_down_state/#neuro_py.detectors.up_down_state.detect_up_down_states_bimodal_thresh","title":"<code>detect_up_down_states_bimodal_thresh(basepath=None, st=None, nrem_epochs=None, region='ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX', bin_size=0.01, smooth_sigma=0.02, min_cells=10, save_mat=True, epoch_by_epoch=False, beh_epochs=None, show_figure=False, overwrite=False, schmidt=False, nboot=100, force_bimodal=False)</code>","text":"<p>Detect UP and DOWN states using bimodal_thresh on firing rate distribution.</p> <p>Uses the same data loading and epoch-by-epoch logic as <code>detect_up_down_states</code>, but applies Hartigan's dip test and bimodal threshold detection instead of a fixed percentile. This is useful when UP/DOWN states form a clear bimodal distribution in the firing rate histogram.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Base directory path where event files and neural data are stored.</p> <code>None</code> <code>st</code> <code>Optional[SpikeTrainArray]</code> <p>Spike train data. If None, spike data will be loaded based on specified regions.</p> <code>None</code> <code>nrem_epochs</code> <code>Optional[EpochArray]</code> <p>NREM epochs. If None, epochs will be loaded from the basepath.</p> <code>None</code> <code>region</code> <code>str</code> <p>Brain regions for loading spikes. The first region is prioritized.</p> <code>\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\"</code> <code>bin_size</code> <code>float</code> <p>Bin size for computing firing rates, in seconds.</p> <code>0.01</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian kernel smoothing, in seconds.</p> <code>0.02</code> <code>min_cells</code> <code>int</code> <p>Minimum number of neurons required for analysis.</p> <code>10</code> <code>save_mat</code> <code>bool</code> <p>Whether to save the detected UP and DOWN states to .mat files.</p> <code>True</code> <code>epoch_by_epoch</code> <code>bool</code> <p>Whether to perform detection epoch by epoch.</p> <code>False</code> <code>beh_epochs</code> <code>Optional[EpochArray]</code> <p>Optional behavioral epochs to use for epoch-by-epoch detection.</p> <code>None</code> <code>show_figure</code> <code>bool</code> <p>Whether to display a figure showing firing rates during detected UP and DOWN states.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing .mat files when saving detected states.</p> <code>False</code> <code>schmidt</code> <code>bool</code> <p>Use Schmidt trigger (hysteresis) for state transitions in bimodal_thresh.</p> <code>False</code> <code>nboot</code> <code>int</code> <p>Number of bootstrap iterations for Hartigan's dip test. Reduce further (e.g., 50) for very long recordings to improve performance.</p> <code>100</code> <code>force_bimodal</code> <code>bool</code> <p>If True, skip the bimodality test and force threshold detection even if the distribution appears unimodal. Use with caution.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[Optional[EpochArray], Optional[EpochArray]]</code> <p>A tuple containing the detected DOWN state epochs and UP state epochs. Returns (None, None) if no suitable states are found or insufficient data is available.</p> Source code in <code>neuro_py/detectors/up_down_state.py</code> <pre><code>def detect_up_down_states_bimodal_thresh(\n    basepath: Optional[str] = None,\n    st: Optional[nel.SpikeTrainArray] = None,\n    nrem_epochs: Optional[nel.EpochArray] = None,\n    region: str = \"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\",\n    bin_size: float = 0.01,\n    smooth_sigma: float = 0.02,\n    min_cells: int = 10,\n    save_mat: bool = True,\n    epoch_by_epoch: bool = False,\n    beh_epochs: Optional[nel.EpochArray] = None,\n    show_figure: bool = False,\n    overwrite: bool = False,\n    schmidt: bool = False,\n    nboot: int = 100,\n    force_bimodal: bool = False,\n) -&gt; Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]:\n    \"\"\"\n    Detect UP and DOWN states using bimodal_thresh on firing rate distribution.\n\n    Uses the same data loading and epoch-by-epoch logic as `detect_up_down_states`,\n    but applies Hartigan's dip test and bimodal threshold detection instead of a\n    fixed percentile. This is useful when UP/DOWN states form a clear bimodal\n    distribution in the firing rate histogram.\n\n    Parameters\n    ----------\n    basepath : str\n        Base directory path where event files and neural data are stored.\n    st : Optional[nel.SpikeTrainArray], default=None\n        Spike train data. If None, spike data will be loaded based on specified regions.\n    nrem_epochs : Optional[nel.EpochArray], default=None\n        NREM epochs. If None, epochs will be loaded from the basepath.\n    region : str, default=\"ILA|PFC|PL|EC1|EC2|EC3|EC4|EC5|MEC|CTX\"\n        Brain regions for loading spikes. The first region is prioritized.\n    bin_size : float, default=0.01\n        Bin size for computing firing rates, in seconds.\n    smooth_sigma : float, default=0.02\n        Standard deviation for Gaussian kernel smoothing, in seconds.\n    min_cells : int, default=10\n        Minimum number of neurons required for analysis.\n    save_mat : bool, default=True\n        Whether to save the detected UP and DOWN states to .mat files.\n    epoch_by_epoch : bool, default=False\n        Whether to perform detection epoch by epoch.\n    beh_epochs : Optional[nel.EpochArray], default=None\n        Optional behavioral epochs to use for epoch-by-epoch detection.\n    show_figure : bool, default=False\n        Whether to display a figure showing firing rates during detected UP and DOWN states.\n    overwrite : bool, default=False\n        Whether to overwrite existing .mat files when saving detected states.\n    schmidt : bool, default=False\n        Use Schmidt trigger (hysteresis) for state transitions in bimodal_thresh.\n    nboot : int, default=100\n        Number of bootstrap iterations for Hartigan's dip test. Reduce further (e.g., 50)\n        for very long recordings to improve performance.\n    force_bimodal : bool, default=False\n        If True, skip the bimodality test and force threshold detection even if\n        the distribution appears unimodal. Use with caution.\n\n    Returns\n    -------\n    Tuple[Optional[nel.EpochArray], Optional[nel.EpochArray]]\n        A tuple containing the detected DOWN state epochs and UP state epochs.\n        Returns (None, None) if no suitable states are found or insufficient data is available.\n    \"\"\"\n\n    # check for existence of event files\n    if save_mat and not overwrite:\n        filename_downstate = os.path.join(\n            basepath,\n            os.path.basename(basepath) + \".\" + \"down_state\" + \".events.mat\",\n        )\n        filename_upstate = os.path.join(\n            basepath,\n            os.path.basename(basepath) + \".\" + \"up_state\" + \".events.mat\",\n        )\n        if os.path.exists(filename_downstate) &amp; os.path.exists(filename_upstate):\n            down_state = loading.load_events(basepath=basepath, epoch_name=\"down_state\")\n            up_state = loading.load_events(basepath=basepath, epoch_name=\"up_state\")\n            return down_state, up_state\n\n    # load brain states\n    if nrem_epochs is None:\n        state_dict = loading.load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"])\n\n    if nrem_epochs.isempty:\n        print(f\"No NREM epochs found for {basepath}\")\n        return None, None\n\n    # load spikes\n    if st is None:\n        st, _ = loading.load_spikes(basepath, brainRegion=region)\n\n    # check if there are enough cells\n    if st is None or st.isempty or st.data.shape[0] &lt; min_cells:\n        print(f\"No spikes found for {basepath} {region}\")\n        return None, None\n\n    # flatten spikes\n    st = st[nrem_epochs].flatten()\n\n    # bin and smooth\n    bst = st.bin(ds=bin_size).smooth(sigma=smooth_sigma)\n\n    def _detect_states_bimodal(\n        bst_segment: nel.AnalogSignalArray, domain: nel.EpochArray\n    ):\n        \"\"\"Detect down/up states using bimodal_thresh within a given domain.\"\"\"\n\n        # Get firing rate time series\n        firing_rates = bst_segment.data.flatten()\n        if firing_rates.size == 0:\n            return None, None\n\n        # Apply bimodal_thresh to the firing rates\n        thresh, cross, bihist, diptest_result = bimodal_thresh(\n            firing_rates, schmidt=schmidt, nboot=nboot, force_bimodal=force_bimodal\n        )\n\n        # If not bimodal or no threshold found\n        if np.isnan(thresh):\n            return None, None\n\n        # Get bin centers (times)\n        bin_centers = bst_segment.bin_centers\n\n        # Extract downints and upints from cross\n        downints = cross[\"downints\"]  # indices into firing_rates array [n_intervals, 2]\n        upints = cross[\"upints\"]\n\n        # Convert indices to time intervals using bin_centers\n        if downints.size == 0:\n            return None, None\n\n        # Clip indices to valid range to prevent out-of-bounds access\n        n_bins = len(bin_centers)\n        downints_clipped = np.clip(downints.astype(int), 0, n_bins - 1)\n        upints_clipped = (\n            np.clip(upints.astype(int), 0, n_bins - 1)\n            if upints.size &gt; 0\n            else np.array([], dtype=int).reshape(0, 2)\n        )\n\n        # Convert index intervals to time intervals\n        # downints has shape [n, 2] where each row is [start_idx, end_idx]\n        down_state_times = np.column_stack(\n            [\n                bin_centers[downints_clipped[:, 0]],\n                bin_centers[downints_clipped[:, 1]],\n            ]\n        )\n        down_state_epochs = nel.EpochArray(data=down_state_times, domain=domain)\n\n        if upints.size == 0:\n            # Generate up states as complement\n            up_state_epochs = ~down_state_epochs\n        else:\n            up_state_times = np.column_stack(\n                [\n                    bin_centers[upints_clipped[:, 0]],\n                    bin_centers[upints_clipped[:, 1]],\n                ]\n            )\n            up_state_epochs = nel.EpochArray(data=up_state_times, domain=domain)\n\n        return down_state_epochs, up_state_epochs\n\n    if epoch_by_epoch:\n        if beh_epochs is None:\n            epoch_df = npy.io.load_epoch(basepath)\n            epoch_df = npy.session.compress_repeated_epochs(epoch_df)\n            epoch_df = epoch_df.query(\"environment == 'sleep'\")\n            beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n        down_state_epochs = []\n        up_state_epochs = []\n        for ep in beh_epochs:\n            domain = nrem_epochs &amp; ep\n            if domain.isempty:\n                continue\n\n            down_state_epochs_, up_state_epochs_ = _detect_states_bimodal(\n                bst[domain], domain\n            )\n            if down_state_epochs_ is None or up_state_epochs_ is None:\n                continue\n\n            down_state_epochs.append(down_state_epochs_.data)\n            up_state_epochs.append(up_state_epochs_.data)\n\n        if len(down_state_epochs) == 0 or len(up_state_epochs) == 0:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n        down_state_epochs = nel.EpochArray(\n            data=np.concatenate(down_state_epochs), domain=nrem_epochs\n        )\n        up_state_epochs = nel.EpochArray(\n            data=np.concatenate(up_state_epochs), domain=nrem_epochs\n        )\n    else:\n        down_state_epochs, up_state_epochs = _detect_states_bimodal(\n            bst[nrem_epochs], nrem_epochs\n        )\n        if down_state_epochs is None or up_state_epochs is None:\n            print(f\"No down states found for {basepath}\")\n            return None, None\n\n    # save to cell explorer mat file\n    if save_mat:\n        epoch_to_mat(\n            down_state_epochs,\n            basepath,\n            \"down_state\",\n            \"detect_up_down_states_bimodal_thresh\",\n        )\n        epoch_to_mat(\n            up_state_epochs,\n            basepath,\n            \"up_state\",\n            \"detect_up_down_states_bimodal_thresh\",\n        )\n\n    # optional figure to show firing rate during up and down states\n    if show_figure:\n        from matplotlib import pyplot as plt\n\n        plt.figure()\n        ax = plt.gca()\n        psth = npy.process.compute_psth(st.data, down_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Down states\"]\n        psth.plot(ax=ax)\n\n        psth = npy.process.compute_psth(st.data, up_state_epochs.starts, n_bins=500)\n        psth.columns = [\"Up states\"]\n\n        psth.plot(ax=ax)\n        ax.legend(loc=\"upper right\", frameon=False)\n        ax.axvline(0, color=\"k\", linestyle=\"--\")\n\n        ax.set_xlabel(\"Time from state transition (s)\")\n        ax.set_ylabel(\"Firing rate (Hz)\")\n\n    return down_state_epochs, up_state_epochs\n</code></pre>"},{"location":"reference/neuro_py/ensemble/","title":"neuro_py.ensemble","text":""},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact","title":"<code>AssemblyReact</code>","text":"<p>Class for running assembly reactivation analysis</p> <p>Core assembly methods come from assembly.py by V\u00edtor Lopes dos Santos     https://doi.org/10.1016/j.jneumeth.2013.04.010</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder</p> <code>None</code> <code>brainRegion</code> <code>str</code> <p>Brain region to restrict to. Can be multi ex. \"CA1|CA2\"</p> <code>'CA1'</code> <code>putativeCellType</code> <code>str</code> <p>Cell type to restrict to</p> <code>'Pyramidal Cell'</code> <code>weight_dt</code> <code>float</code> <p>Time resolution of the weight matrix</p> <code>0.025</code> <code>z_mat_dt</code> <code>float</code> <p>Time resolution of the z matrix</p> <code>0.002</code> <code>method</code> <code>str</code> <p>Defines how to extract assembly patterns (ica,pca).</p> <code>'ica'</code> <code>nullhyp</code> <code>str</code> <p>Defines how to generate statistical threshold for assembly detection (bin,circ,mp).</p> <code>'mp'</code> <code>nshu</code> <code>int</code> <p>Number of shuffles for bin and circ null hypothesis.</p> <code>1000</code> <code>percentile</code> <code>int</code> <p>Percentile for mp null hypothesis.</p> <code>99</code> <code>tracywidom</code> <code>bool</code> <p>If true, uses Tracy-Widom distribution for mp null hypothesis.</p> <code>False</code> <code>cross_structural</code> <code>ndarray</code> <p>A categorical vector indicating group membership for each neuron. If provided, the function will strictly detect cross-structural assemblies (correlations within the same group will be ignored). Should have the same length as the number of neurons in the spike train.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>st</code> <code>SpikeTrainArray</code> <p>Spike train</p> <code>cell_metrics</code> <code>DataFrame</code> <p>Cell metrics</p> <code>ripples</code> <code>EpochArray</code> <p>Ripples</p> <code>patterns</code> <code>ndarray</code> <p>Assembly patterns</p> <code>assembly_act</code> <code>AnalogSignalArray</code> <p>Assembly activity</p> <p>Methods:</p> Name Description <code>load_data</code> <p>Load data (st, ripples, epochs)</p> <code>restrict_to_epoch</code> <p>Restrict to a specific epoch</p> <code>get_z_mat</code> <p>Get z matrix</p> <code>get_weights</code> <p>Get assembly weights</p> <code>get_assembly_act</code> <p>Get assembly activity</p> <code>n_assemblies</code> <p>Number of detected assemblies</p> <code>isempty</code> <p>Check if empty</p> <code>copy</code> <p>Returns copy of class</p> <code>plot</code> <p>Stem plot of assembly weights</p> <code>find_members</code> <p>Find members of an assembly</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # create the object assembly_react\n&gt;&gt;&gt; assembly_react = assembly_reactivation.AssemblyReact(\n...    basepath=basepath,\n...    )\n</code></pre> <pre><code>&gt;&gt;&gt; # load need data (spikes, ripples, epochs)\n&gt;&gt;&gt; assembly_react.load_data()\n</code></pre> <pre><code>&gt;&gt;&gt; # detect assemblies\n&gt;&gt;&gt; assembly_react.get_weights()\n</code></pre> <pre><code>&gt;&gt;&gt; # visually inspect weights for each assembly\n&gt;&gt;&gt; assembly_react.plot()\n</code></pre> <pre><code>&gt;&gt;&gt; # compute time resolved signal for each assembly\n&gt;&gt;&gt; assembly_act = assembly_react.get_assembly_act()\n</code></pre> <pre><code>&gt;&gt;&gt; # locate members of assemblies\n&gt;&gt;&gt; assembly_members = assembly_react.find_members()\n</code></pre> <pre><code>&gt;&gt;&gt; # Example: Cross-structural assemblies between CA1 and CA3\n&gt;&gt;&gt; # Assuming you have neurons from both regions\n&gt;&gt;&gt; cross_groups = np.array(['CA1'] * 50 + ['CA3'] * 30)  # 50 CA1, 30 CA3 neurons\n&gt;&gt;&gt; assembly_react_cross = assembly_reactivation.AssemblyReact(\n...    basepath=basepath,\n...    cross_structural=cross_groups\n...    )\n&gt;&gt;&gt; assembly_react_cross.load_data()\n&gt;&gt;&gt; assembly_react_cross.get_weights()  # Will only detect cross-regional assemblies\n</code></pre> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>class AssemblyReact:\n    \"\"\"\n    Class for running assembly reactivation analysis\n\n    Core assembly methods come from assembly.py by V\u00edtor Lopes dos Santos\n        https://doi.org/10.1016/j.jneumeth.2013.04.010\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder\n    brainRegion : str\n        Brain region to restrict to. Can be multi ex. \"CA1|CA2\"\n    putativeCellType : str\n        Cell type to restrict to\n    weight_dt : float\n        Time resolution of the weight matrix\n    z_mat_dt : float\n        Time resolution of the z matrix\n    method : str\n        Defines how to extract assembly patterns (ica,pca).\n    nullhyp : str\n        Defines how to generate statistical threshold for assembly detection (bin,circ,mp).\n    nshu : int\n        Number of shuffles for bin and circ null hypothesis.\n    percentile : int\n        Percentile for mp null hypothesis.\n    tracywidom : bool\n        If true, uses Tracy-Widom distribution for mp null hypothesis.\n    cross_structural : np.ndarray, optional\n        A categorical vector indicating group membership for each neuron.\n        If provided, the function will strictly detect cross-structural assemblies\n        (correlations within the same group will be ignored). Should have the same\n        length as the number of neurons in the spike train.\n\n    Attributes\n    ----------\n    st : nelpy.SpikeTrainArray\n        Spike train\n    cell_metrics : pd.DataFrame\n        Cell metrics\n    ripples : nelpy.EpochArray\n        Ripples\n    patterns : np.ndarray\n        Assembly patterns\n    assembly_act : nelpy.AnalogSignalArray\n        Assembly activity\n\n    Methods\n    -------\n    load_data()\n        Load data (st, ripples, epochs)\n    restrict_to_epoch(epoch)\n        Restrict to a specific epoch\n    get_z_mat(st)\n        Get z matrix\n    get_weights(epoch=None)\n        Get assembly weights\n    get_assembly_act(epoch=None)\n        Get assembly activity\n    n_assemblies()\n        Number of detected assemblies\n    isempty()\n        Check if empty\n    copy()\n        Returns copy of class\n    plot()\n        Stem plot of assembly weights\n    find_members()\n        Find members of an assembly\n\n\n    Examples\n    --------\n    &gt;&gt;&gt; # create the object assembly_react\n    &gt;&gt;&gt; assembly_react = assembly_reactivation.AssemblyReact(\n    ...    basepath=basepath,\n    ...    )\n\n    &gt;&gt;&gt; # load need data (spikes, ripples, epochs)\n    &gt;&gt;&gt; assembly_react.load_data()\n\n    &gt;&gt;&gt; # detect assemblies\n    &gt;&gt;&gt; assembly_react.get_weights()\n\n    &gt;&gt;&gt; # visually inspect weights for each assembly\n    &gt;&gt;&gt; assembly_react.plot()\n\n    &gt;&gt;&gt; # compute time resolved signal for each assembly\n    &gt;&gt;&gt; assembly_act = assembly_react.get_assembly_act()\n\n    &gt;&gt;&gt; # locate members of assemblies\n    &gt;&gt;&gt; assembly_members = assembly_react.find_members()\n\n    &gt;&gt;&gt; # Example: Cross-structural assemblies between CA1 and CA3\n    &gt;&gt;&gt; # Assuming you have neurons from both regions\n    &gt;&gt;&gt; cross_groups = np.array(['CA1'] * 50 + ['CA3'] * 30)  # 50 CA1, 30 CA3 neurons\n    &gt;&gt;&gt; assembly_react_cross = assembly_reactivation.AssemblyReact(\n    ...    basepath=basepath,\n    ...    cross_structural=cross_groups\n    ...    )\n    &gt;&gt;&gt; assembly_react_cross.load_data()\n    &gt;&gt;&gt; assembly_react_cross.get_weights()  # Will only detect cross-regional assemblies\n\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: Union[str, None] = None,\n        brainRegion: str = \"CA1\",\n        putativeCellType: str = \"Pyramidal Cell\",\n        weight_dt: float = 0.025,\n        z_mat_dt: float = 0.002,\n        method: str = \"ica\",\n        nullhyp: str = \"mp\",\n        nshu: int = 1000,\n        percentile: int = 99,\n        tracywidom: bool = False,\n        whiten: str = \"unit-variance\",\n        cross_structural: Optional[np.ndarray] = None,\n    ):\n        self.basepath = basepath\n        self.brainRegion = brainRegion\n        self.putativeCellType = putativeCellType\n        self.weight_dt = weight_dt\n        self.z_mat_dt = z_mat_dt\n        self.method = method\n        self.nullhyp = nullhyp\n        self.nshu = nshu\n        self.percentile = percentile\n        self.tracywidom = tracywidom\n        self.whiten = whiten\n        self.cross_structural = cross_structural\n        self.type_name = self.__class__.__name__\n\n    def add_st(self, st: nel.SpikeTrainArray) -&gt; None:\n        self.st = st\n\n    def add_ripples(self, ripples: nel.EpochArray) -&gt; None:\n        self.ripples = ripples\n\n    def add_epoch_df(self, epoch_df: pd.DataFrame) -&gt; None:\n        self.epoch_df = epoch_df\n\n    def load_spikes(self) -&gt; None:\n        \"\"\"\n        loads spikes from the session folder\n        \"\"\"\n        self.st, self.cell_metrics = loading.load_spikes(\n            self.basepath,\n            brainRegion=self.brainRegion,\n            putativeCellType=self.putativeCellType,\n            support=self.time_support,\n        )\n\n    def load_ripples(self) -&gt; None:\n        \"\"\"\n        loads ripples from the session folder\n        \"\"\"\n        ripples = loading.load_ripples_events(self.basepath)\n        self.ripples = nel.EpochArray(\n            [np.array([ripples.start, ripples.stop]).T], domain=self.time_support\n        )\n\n    def load_epoch(self) -&gt; None:\n        \"\"\"\n        loads epochs from the session folder\n        \"\"\"\n        epoch_df = loading.load_epoch(self.basepath)\n        epoch_df = compress_repeated_epochs(epoch_df)\n        self.time_support = nel.EpochArray(\n            [epoch_df.iloc[0].startTime, epoch_df.iloc[-1].stopTime]\n        )\n        self.epochs = nel.EpochArray(\n            [np.array([epoch_df.startTime, epoch_df.stopTime]).T],\n            domain=self.time_support,\n        )\n        self.epoch_df = epoch_df\n\n    def load_data(self) -&gt; None:\n        \"\"\"\n        loads data (spikes,ripples,epochs) from the session folder\n        \"\"\"\n        self.load_epoch()\n        self.load_spikes()\n        self.load_ripples()\n\n    def restrict_epochs_to_pre_task_post(self) -&gt; None:\n        \"\"\"\n        Restricts the epochs to the specified epochs\n        \"\"\"\n        # fetch data\n        epoch_df = loading.load_epoch(self.basepath)\n        # compress back to back sleep epochs (an issue further up the pipeline)\n        epoch_df = compress_repeated_epochs(epoch_df)\n        # restrict to pre task post epochs\n        idx = find_pre_task_post(epoch_df.environment)\n        self.epoch_df = epoch_df[idx[0]]\n        # convert to epoch array and add to object\n        self.epochs = nel.EpochArray(\n            [np.array([self.epoch_df.startTime, self.epoch_df.stopTime]).T],\n            label=\"session_epochs\",\n            domain=self.time_support,\n        )\n\n    def restrict_to_epoch(self, epoch) -&gt; None:\n        \"\"\"\n        Restricts the spike data to a specific epoch.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray\n            The epoch to restrict to.\n        \"\"\"\n        self.st_resticted = self.st[epoch]\n\n    def get_z_mat(self, st: nel.SpikeTrainArray) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get z matrix.\n\n        Parameters\n        ----------\n        st : nel.SpikeTrainArray\n            Spike train array.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray]\n            Z-scored binned spike train and bin centers.\n        \"\"\"\n        # binning the spike train\n        z_t = st.bin(ds=self.z_mat_dt)\n        # gaussian kernel to match the bin-size used to identify the assembly patterns\n        sigma = self.weight_dt / np.sqrt(int(1000 * self.weight_dt / 2))\n        z_t.smooth(sigma=sigma, inplace=True)\n        # zscore the z matrix\n        z_scored_bst = stats.zscore(z_t.data, axis=1)\n        # make sure there are no nans, important as strengths will all be nan otherwise\n        z_scored_bst[np.isnan(z_scored_bst).any(axis=1)] = 0\n\n        return z_scored_bst, z_t.bin_centers\n\n    def get_weights(self, epoch: Optional[nel.EpochArray] = None) -&gt; None:\n        \"\"\"\n        Gets the assembly weights.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray, optional\n            The epoch to restrict to, by default None.\n        \"\"\"\n\n        # check if st has any neurons\n        if self.st.isempty:\n            self.patterns = None\n            return\n\n        if epoch is not None:\n            bst = self.st[epoch].bin(ds=self.weight_dt).data\n        else:\n            bst = self.st.bin(ds=self.weight_dt).data\n\n        if (bst == 0).all():\n            self.patterns = None\n            return\n        else:\n            patterns, _, _ = assembly.runPatterns(\n                bst,\n                method=self.method,\n                nullhyp=self.nullhyp,\n                nshu=self.nshu,\n                percentile=self.percentile,\n                tracywidom=self.tracywidom,\n                whiten=self.whiten,\n                cross_structural=self.cross_structural,\n            )\n\n            if patterns is None:\n                self.patterns = None\n                return\n\n            # flip patterns to have positive max\n            self.patterns = np.array(\n                [\n                    (\n                        patterns[i, :]\n                        if patterns[i, np.argmax(np.abs(patterns[i, :]))] &gt; 0\n                        else -patterns[i, :]\n                    )\n                    for i in range(patterns.shape[0])\n                ]\n            )\n\n    def get_assembly_act(\n        self, epoch: Optional[nel.EpochArray] = None\n    ) -&gt; nel.AnalogSignalArray:\n        \"\"\"\n        Get assembly activity.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray, optional\n            The epoch to restrict to, by default None.\n\n        Returns\n        -------\n        nel.AnalogSignalArray\n            Assembly activity.\n        \"\"\"\n        # check for num of assemblies first\n        if self.n_assemblies() == 0:\n            return nel.AnalogSignalArray(empty=True)\n\n        if epoch is not None:\n            zactmat, ts = self.get_z_mat(self.st[epoch])\n        else:\n            zactmat, ts = self.get_z_mat(self.st)\n\n        assembly_act = nel.AnalogSignalArray(\n            data=assembly.computeAssemblyActivity(self.patterns, zactmat),\n            timestamps=ts,\n            fs=1 / self.z_mat_dt,\n        )\n        return assembly_act\n\n    def plot(\n        self,\n        plot_members: bool = True,\n        central_line_color: str = \"grey\",\n        marker_color: str = \"k\",\n        member_color: Union[str, list] = \"#6768ab\",\n        line_width: float = 1.25,\n        markersize: float = 4,\n        x_padding: float = 0.2,\n        figsize: Union[tuple, None] = None,\n    ) -&gt; Union[Tuple[plt.Figure, np.ndarray], str, None]:\n        \"\"\"\n        Plots basic stem plot to display assembly weights.\n\n        Parameters\n        ----------\n        plot_members : bool, optional\n            Whether to plot assembly members, by default True.\n        central_line_color : str, optional\n            Color of the central line, by default \"grey\".\n        marker_color : str, optional\n            Color of the markers, by default \"k\".\n        member_color : Union[str, List[str]], optional\n            Color of the members, by default \"#6768ab\".\n        line_width : float, optional\n            Width of the lines, by default 1.25.\n        markersize : float, optional\n            Size of the markers, by default 4.\n        x_padding : float, optional\n            Padding on the x-axis, by default 0.2.\n        figsize : Optional[Tuple[float, float]], optional\n            Size of the figure, by default None.\n\n        Returns\n        -------\n        Union[Tuple[plt.Figure, np.ndarray], str, None]\n            The figure and axes if successful, otherwise a message or None.\n        \"\"\"\n        if not hasattr(self, \"patterns\"):\n            return \"run get_weights first\"\n        else:\n            if self.patterns is None:\n                return None, None\n            if plot_members:\n                self.find_members()\n            if figsize is None:\n                figsize = (self.n_assemblies() + 1, np.round(self.n_assemblies() / 2))\n            # set up figure with size relative to assembly matrix\n            fig, axes = plt.subplots(\n                1,\n                self.n_assemblies(),\n                figsize=figsize,\n                sharey=True,\n                sharex=True,\n            )\n            # iter over each assembly and plot the weight per cell\n            for i in range(self.n_assemblies()):\n                markerline, stemlines, baseline = axes[i].stem(\n                    self.patterns[i, :], orientation=\"horizontal\"\n                )\n                markerline._color = marker_color\n                baseline._color = central_line_color\n                baseline.zorder = -1000\n                plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                plt.setp(stemlines, linewidth=line_width)\n                plt.setp(markerline, markersize=markersize)\n\n                if plot_members:\n                    current_pattern = self.patterns[i, :].copy()\n                    current_pattern[~self.assembly_members[i, :]] = np.nan\n                    markerline, stemlines, baseline = axes[i].stem(\n                        current_pattern, orientation=\"horizontal\"\n                    )\n                    if isinstance(\n                        member_color, sns.palettes._ColorPalette\n                    ) or isinstance(member_color, list):\n                        markerline._color = member_color[i]\n                    else:\n                        markerline._color = member_color\n                    baseline._color = \"#00000000\"\n                    baseline.zorder = -1000\n                    plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                    plt.setp(stemlines, linewidth=line_width)\n                    plt.setp(markerline, markersize=markersize)\n\n                axes[i].spines[\"top\"].set_visible(False)\n                axes[i].spines[\"right\"].set_visible(False)\n\n            # give room for marker\n            axes[0].set_xlim(\n                -self.patterns.max() - x_padding, self.patterns.max() + x_padding\n            )\n\n            axes[0].set_ylabel(\"Neurons #\")\n            axes[0].set_xlabel(\"Weights (a.u.)\")\n\n            return fig, axes\n\n    def n_assemblies(self) -&gt; int:\n        \"\"\"\n        Get the number of detected assemblies.\n\n        Returns\n        -------\n        int\n            Number of detected assemblies.\n        \"\"\"\n        if hasattr(self, \"patterns\"):\n            if self.patterns is None:\n                return 0\n            return self.patterns.shape[0]\n\n    @property\n    def isempty(self) -&gt; bool:\n        \"\"\"\n        Check if the object is empty.\n\n        Returns\n        -------\n        bool\n            True if empty, False otherwise.\n        \"\"\"\n        if hasattr(self, \"st\"):\n            return False\n        elif not hasattr(self, \"st\"):\n            return True\n\n    def copy(self) -&gt; \"AssemblyReact\":\n        \"\"\"\n        Returns a copy of the current class.\n\n        Returns\n        -------\n        AssemblyReact\n            A copy of the current class.\n        \"\"\"\n        newcopy = copy.deepcopy(self)\n        return newcopy\n\n    def __repr__(self) -&gt; str:\n        if self.isempty:\n            return f\"&lt;{self.type_name}: empty&gt;\"\n\n        # if st data as been loaded and patterns have been computed\n        if hasattr(self, \"patterns\"):\n            n_units = f\"{self.st.n_active} units\"\n            n_patterns = f\"{self.n_assemblies()} assemblies\"\n            dstr = f\"of length {self.st.support.length}\"\n            return \"&lt;%s: %s, %s&gt; %s\" % (self.type_name, n_units, n_patterns, dstr)\n\n        # if st data as been loaded\n        if hasattr(self, \"st\"):\n            n_units = f\"{self.st.n_active} units\"\n            dstr = f\"of length {self.st.support.length}\"\n            return \"&lt;%s: %s&gt; %s\" % (self.type_name, n_units, dstr)\n\n    def find_members(self) -&gt; np.ndarray:\n        \"\"\"\n        Finds significant assembly patterns and significant assembly members.\n\n        Returns\n        -------\n        np.ndarray\n            A ndarray of booleans indicating whether each unit is a significant member of an assembly.\n\n        Notes\n        -----\n        also, sets self.assembly_members and self.valid_assembly\n\n        self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)\n        \"\"\"\n\n        def Otsu(vector: np.ndarray) -&gt; Tuple[np.ndarray, float, float]:\n            \"\"\"\n            The Otsu method for splitting data into two groups.\n\n            Parameters\n            ----------\n            vector : np.ndarray\n                Arbitrary vector.\n\n            Returns\n            -------\n            Tuple[np.ndarray, float, float]\n                Group, threshold used for classification, and effectiveness metric.\n            \"\"\"\n            sorted = np.sort(vector)\n            n = len(vector)\n            intraClassVariance = [np.nan] * n\n            for i in np.arange(n):\n                p = (i + 1) / n\n                p0 = 1 - p\n                if i + 1 == n:\n                    intraClassVariance[i] = np.nan\n                else:\n                    intraClassVariance[i] = p * np.var(sorted[0 : i + 1]) + p0 * np.var(\n                        sorted[i + 1 :]\n                    )\n\n            minIntraVariance = np.nanmin(intraClassVariance)\n            idx = np.nanargmin(intraClassVariance)\n            threshold = sorted[idx]\n            group = vector &gt; threshold\n\n            em = 1 - (minIntraVariance / np.var(vector))\n\n            return group, threshold, em\n\n        is_member = []\n        keep_assembly = []\n        for pat in self.patterns:\n            isMember, _, _ = Otsu(np.abs(pat))\n            is_member.append(isMember)\n\n            if np.any(pat[isMember] &lt; 0) &amp; np.any(pat[isMember] &gt; 0):\n                keep_assembly.append(False)\n            elif sum(isMember) == 0:\n                keep_assembly.append(False)\n            else:\n                keep_assembly.append(True)\n\n        self.assembly_members = np.array(is_member)\n        self.valid_assembly = np.array(keep_assembly)\n\n        return self.assembly_members\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.isempty","title":"<code>isempty</code>  <code>property</code>","text":"<p>Check if the object is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if empty, False otherwise.</p>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.copy","title":"<code>copy()</code>","text":"<p>Returns a copy of the current class.</p> <p>Returns:</p> Type Description <code>AssemblyReact</code> <p>A copy of the current class.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def copy(self) -&gt; \"AssemblyReact\":\n    \"\"\"\n    Returns a copy of the current class.\n\n    Returns\n    -------\n    AssemblyReact\n        A copy of the current class.\n    \"\"\"\n    newcopy = copy.deepcopy(self)\n    return newcopy\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.find_members","title":"<code>find_members()</code>","text":"<p>Finds significant assembly patterns and significant assembly members.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A ndarray of booleans indicating whether each unit is a significant member of an assembly.</p> Notes <p>also, sets self.assembly_members and self.valid_assembly</p> <p>self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def find_members(self) -&gt; np.ndarray:\n    \"\"\"\n    Finds significant assembly patterns and significant assembly members.\n\n    Returns\n    -------\n    np.ndarray\n        A ndarray of booleans indicating whether each unit is a significant member of an assembly.\n\n    Notes\n    -----\n    also, sets self.assembly_members and self.valid_assembly\n\n    self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)\n    \"\"\"\n\n    def Otsu(vector: np.ndarray) -&gt; Tuple[np.ndarray, float, float]:\n        \"\"\"\n        The Otsu method for splitting data into two groups.\n\n        Parameters\n        ----------\n        vector : np.ndarray\n            Arbitrary vector.\n\n        Returns\n        -------\n        Tuple[np.ndarray, float, float]\n            Group, threshold used for classification, and effectiveness metric.\n        \"\"\"\n        sorted = np.sort(vector)\n        n = len(vector)\n        intraClassVariance = [np.nan] * n\n        for i in np.arange(n):\n            p = (i + 1) / n\n            p0 = 1 - p\n            if i + 1 == n:\n                intraClassVariance[i] = np.nan\n            else:\n                intraClassVariance[i] = p * np.var(sorted[0 : i + 1]) + p0 * np.var(\n                    sorted[i + 1 :]\n                )\n\n        minIntraVariance = np.nanmin(intraClassVariance)\n        idx = np.nanargmin(intraClassVariance)\n        threshold = sorted[idx]\n        group = vector &gt; threshold\n\n        em = 1 - (minIntraVariance / np.var(vector))\n\n        return group, threshold, em\n\n    is_member = []\n    keep_assembly = []\n    for pat in self.patterns:\n        isMember, _, _ = Otsu(np.abs(pat))\n        is_member.append(isMember)\n\n        if np.any(pat[isMember] &lt; 0) &amp; np.any(pat[isMember] &gt; 0):\n            keep_assembly.append(False)\n        elif sum(isMember) == 0:\n            keep_assembly.append(False)\n        else:\n            keep_assembly.append(True)\n\n    self.assembly_members = np.array(is_member)\n    self.valid_assembly = np.array(keep_assembly)\n\n    return self.assembly_members\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.get_assembly_act","title":"<code>get_assembly_act(epoch=None)</code>","text":"<p>Get assembly activity.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>AnalogSignalArray</code> <p>Assembly activity.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_assembly_act(\n    self, epoch: Optional[nel.EpochArray] = None\n) -&gt; nel.AnalogSignalArray:\n    \"\"\"\n    Get assembly activity.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray, optional\n        The epoch to restrict to, by default None.\n\n    Returns\n    -------\n    nel.AnalogSignalArray\n        Assembly activity.\n    \"\"\"\n    # check for num of assemblies first\n    if self.n_assemblies() == 0:\n        return nel.AnalogSignalArray(empty=True)\n\n    if epoch is not None:\n        zactmat, ts = self.get_z_mat(self.st[epoch])\n    else:\n        zactmat, ts = self.get_z_mat(self.st)\n\n    assembly_act = nel.AnalogSignalArray(\n        data=assembly.computeAssemblyActivity(self.patterns, zactmat),\n        timestamps=ts,\n        fs=1 / self.z_mat_dt,\n    )\n    return assembly_act\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.get_weights","title":"<code>get_weights(epoch=None)</code>","text":"<p>Gets the assembly weights.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to, by default None.</p> <code>None</code> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_weights(self, epoch: Optional[nel.EpochArray] = None) -&gt; None:\n    \"\"\"\n    Gets the assembly weights.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray, optional\n        The epoch to restrict to, by default None.\n    \"\"\"\n\n    # check if st has any neurons\n    if self.st.isempty:\n        self.patterns = None\n        return\n\n    if epoch is not None:\n        bst = self.st[epoch].bin(ds=self.weight_dt).data\n    else:\n        bst = self.st.bin(ds=self.weight_dt).data\n\n    if (bst == 0).all():\n        self.patterns = None\n        return\n    else:\n        patterns, _, _ = assembly.runPatterns(\n            bst,\n            method=self.method,\n            nullhyp=self.nullhyp,\n            nshu=self.nshu,\n            percentile=self.percentile,\n            tracywidom=self.tracywidom,\n            whiten=self.whiten,\n            cross_structural=self.cross_structural,\n        )\n\n        if patterns is None:\n            self.patterns = None\n            return\n\n        # flip patterns to have positive max\n        self.patterns = np.array(\n            [\n                (\n                    patterns[i, :]\n                    if patterns[i, np.argmax(np.abs(patterns[i, :]))] &gt; 0\n                    else -patterns[i, :]\n                )\n                for i in range(patterns.shape[0])\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.get_z_mat","title":"<code>get_z_mat(st)</code>","text":"<p>Get z matrix.</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>Spike train array.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Z-scored binned spike train and bin centers.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_z_mat(self, st: nel.SpikeTrainArray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get z matrix.\n\n    Parameters\n    ----------\n    st : nel.SpikeTrainArray\n        Spike train array.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Z-scored binned spike train and bin centers.\n    \"\"\"\n    # binning the spike train\n    z_t = st.bin(ds=self.z_mat_dt)\n    # gaussian kernel to match the bin-size used to identify the assembly patterns\n    sigma = self.weight_dt / np.sqrt(int(1000 * self.weight_dt / 2))\n    z_t.smooth(sigma=sigma, inplace=True)\n    # zscore the z matrix\n    z_scored_bst = stats.zscore(z_t.data, axis=1)\n    # make sure there are no nans, important as strengths will all be nan otherwise\n    z_scored_bst[np.isnan(z_scored_bst).any(axis=1)] = 0\n\n    return z_scored_bst, z_t.bin_centers\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.load_data","title":"<code>load_data()</code>","text":"<p>loads data (spikes,ripples,epochs) from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_data(self) -&gt; None:\n    \"\"\"\n    loads data (spikes,ripples,epochs) from the session folder\n    \"\"\"\n    self.load_epoch()\n    self.load_spikes()\n    self.load_ripples()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.load_epoch","title":"<code>load_epoch()</code>","text":"<p>loads epochs from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_epoch(self) -&gt; None:\n    \"\"\"\n    loads epochs from the session folder\n    \"\"\"\n    epoch_df = loading.load_epoch(self.basepath)\n    epoch_df = compress_repeated_epochs(epoch_df)\n    self.time_support = nel.EpochArray(\n        [epoch_df.iloc[0].startTime, epoch_df.iloc[-1].stopTime]\n    )\n    self.epochs = nel.EpochArray(\n        [np.array([epoch_df.startTime, epoch_df.stopTime]).T],\n        domain=self.time_support,\n    )\n    self.epoch_df = epoch_df\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.load_ripples","title":"<code>load_ripples()</code>","text":"<p>loads ripples from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_ripples(self) -&gt; None:\n    \"\"\"\n    loads ripples from the session folder\n    \"\"\"\n    ripples = loading.load_ripples_events(self.basepath)\n    self.ripples = nel.EpochArray(\n        [np.array([ripples.start, ripples.stop]).T], domain=self.time_support\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.load_spikes","title":"<code>load_spikes()</code>","text":"<p>loads spikes from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_spikes(self) -&gt; None:\n    \"\"\"\n    loads spikes from the session folder\n    \"\"\"\n    self.st, self.cell_metrics = loading.load_spikes(\n        self.basepath,\n        brainRegion=self.brainRegion,\n        putativeCellType=self.putativeCellType,\n        support=self.time_support,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.n_assemblies","title":"<code>n_assemblies()</code>","text":"<p>Get the number of detected assemblies.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of detected assemblies.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def n_assemblies(self) -&gt; int:\n    \"\"\"\n    Get the number of detected assemblies.\n\n    Returns\n    -------\n    int\n        Number of detected assemblies.\n    \"\"\"\n    if hasattr(self, \"patterns\"):\n        if self.patterns is None:\n            return 0\n        return self.patterns.shape[0]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.plot","title":"<code>plot(plot_members=True, central_line_color='grey', marker_color='k', member_color='#6768ab', line_width=1.25, markersize=4, x_padding=0.2, figsize=None)</code>","text":"<p>Plots basic stem plot to display assembly weights.</p> <p>Parameters:</p> Name Type Description Default <code>plot_members</code> <code>bool</code> <p>Whether to plot assembly members, by default True.</p> <code>True</code> <code>central_line_color</code> <code>str</code> <p>Color of the central line, by default \"grey\".</p> <code>'grey'</code> <code>marker_color</code> <code>str</code> <p>Color of the markers, by default \"k\".</p> <code>'k'</code> <code>member_color</code> <code>Union[str, List[str]]</code> <p>Color of the members, by default \"#6768ab\".</p> <code>'#6768ab'</code> <code>line_width</code> <code>float</code> <p>Width of the lines, by default 1.25.</p> <code>1.25</code> <code>markersize</code> <code>float</code> <p>Size of the markers, by default 4.</p> <code>4</code> <code>x_padding</code> <code>float</code> <p>Padding on the x-axis, by default 0.2.</p> <code>0.2</code> <code>figsize</code> <code>Optional[Tuple[float, float]]</code> <p>Size of the figure, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Tuple[Figure, ndarray], str, None]</code> <p>The figure and axes if successful, otherwise a message or None.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def plot(\n    self,\n    plot_members: bool = True,\n    central_line_color: str = \"grey\",\n    marker_color: str = \"k\",\n    member_color: Union[str, list] = \"#6768ab\",\n    line_width: float = 1.25,\n    markersize: float = 4,\n    x_padding: float = 0.2,\n    figsize: Union[tuple, None] = None,\n) -&gt; Union[Tuple[plt.Figure, np.ndarray], str, None]:\n    \"\"\"\n    Plots basic stem plot to display assembly weights.\n\n    Parameters\n    ----------\n    plot_members : bool, optional\n        Whether to plot assembly members, by default True.\n    central_line_color : str, optional\n        Color of the central line, by default \"grey\".\n    marker_color : str, optional\n        Color of the markers, by default \"k\".\n    member_color : Union[str, List[str]], optional\n        Color of the members, by default \"#6768ab\".\n    line_width : float, optional\n        Width of the lines, by default 1.25.\n    markersize : float, optional\n        Size of the markers, by default 4.\n    x_padding : float, optional\n        Padding on the x-axis, by default 0.2.\n    figsize : Optional[Tuple[float, float]], optional\n        Size of the figure, by default None.\n\n    Returns\n    -------\n    Union[Tuple[plt.Figure, np.ndarray], str, None]\n        The figure and axes if successful, otherwise a message or None.\n    \"\"\"\n    if not hasattr(self, \"patterns\"):\n        return \"run get_weights first\"\n    else:\n        if self.patterns is None:\n            return None, None\n        if plot_members:\n            self.find_members()\n        if figsize is None:\n            figsize = (self.n_assemblies() + 1, np.round(self.n_assemblies() / 2))\n        # set up figure with size relative to assembly matrix\n        fig, axes = plt.subplots(\n            1,\n            self.n_assemblies(),\n            figsize=figsize,\n            sharey=True,\n            sharex=True,\n        )\n        # iter over each assembly and plot the weight per cell\n        for i in range(self.n_assemblies()):\n            markerline, stemlines, baseline = axes[i].stem(\n                self.patterns[i, :], orientation=\"horizontal\"\n            )\n            markerline._color = marker_color\n            baseline._color = central_line_color\n            baseline.zorder = -1000\n            plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n            plt.setp(stemlines, linewidth=line_width)\n            plt.setp(markerline, markersize=markersize)\n\n            if plot_members:\n                current_pattern = self.patterns[i, :].copy()\n                current_pattern[~self.assembly_members[i, :]] = np.nan\n                markerline, stemlines, baseline = axes[i].stem(\n                    current_pattern, orientation=\"horizontal\"\n                )\n                if isinstance(\n                    member_color, sns.palettes._ColorPalette\n                ) or isinstance(member_color, list):\n                    markerline._color = member_color[i]\n                else:\n                    markerline._color = member_color\n                baseline._color = \"#00000000\"\n                baseline.zorder = -1000\n                plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                plt.setp(stemlines, linewidth=line_width)\n                plt.setp(markerline, markersize=markersize)\n\n            axes[i].spines[\"top\"].set_visible(False)\n            axes[i].spines[\"right\"].set_visible(False)\n\n        # give room for marker\n        axes[0].set_xlim(\n            -self.patterns.max() - x_padding, self.patterns.max() + x_padding\n        )\n\n        axes[0].set_ylabel(\"Neurons #\")\n        axes[0].set_xlabel(\"Weights (a.u.)\")\n\n        return fig, axes\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.restrict_epochs_to_pre_task_post","title":"<code>restrict_epochs_to_pre_task_post()</code>","text":"<p>Restricts the epochs to the specified epochs</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def restrict_epochs_to_pre_task_post(self) -&gt; None:\n    \"\"\"\n    Restricts the epochs to the specified epochs\n    \"\"\"\n    # fetch data\n    epoch_df = loading.load_epoch(self.basepath)\n    # compress back to back sleep epochs (an issue further up the pipeline)\n    epoch_df = compress_repeated_epochs(epoch_df)\n    # restrict to pre task post epochs\n    idx = find_pre_task_post(epoch_df.environment)\n    self.epoch_df = epoch_df[idx[0]]\n    # convert to epoch array and add to object\n    self.epochs = nel.EpochArray(\n        [np.array([self.epoch_df.startTime, self.epoch_df.stopTime]).T],\n        label=\"session_epochs\",\n        domain=self.time_support,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.AssemblyReact.restrict_to_epoch","title":"<code>restrict_to_epoch(epoch)</code>","text":"<p>Restricts the spike data to a specific epoch.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to.</p> required Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def restrict_to_epoch(self, epoch) -&gt; None:\n    \"\"\"\n    Restricts the spike data to a specific epoch.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The epoch to restrict to.\n    \"\"\"\n    self.st_resticted = self.st[epoch]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance","title":"<code>ExplainedVariance</code>","text":"<p>               Bases: <code>object</code></p> <p>Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.</p> References <p>1) Kudrimoti, H. S., Barnes, C. A., &amp; McNaughton, B. L. (1999).     Reactivation of Hippocampal Cell Assemblies: Effects of Behavioral State, Experience, and EEG Dynamics.     Journal of Neuroscience, 19(10), 4090-4101. https://doi.org/10/4090 2) Tatsuno, M., Lipa, P., &amp; McNaughton, B. L. (2006).     Methodological Considerations on the Use of Template Matching to Study Long-Lasting Memory Trace Replay.     Journal of Neuroscience, 26(42), 10727-10742. https://doi.org/10.1523/JNEUROSCI.3317-06.2006</p> <p>Adapted from https://github.com/diba-lab/NeuroPy/blob/main/neuropy/analyses/reactivation.py</p> <p>Attributes:</p> Name Type Description <code>st</code> <code>SpikeTrainArray</code> <p>obj that holds spiketrains</p> <code>template</code> <code>EpochArray</code> <p>time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)</p> <code>matching</code> <code>EpochArray</code> <p>time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)</p> <code>control</code> <code>EpochArray</code> <p>time in seconds, control for pairwise correlations within this period (pre-task period)</p> <code>bin_size</code> <code>float</code> <p>in seconds, binning size for spike counts</p> <code>window</code> <code>int</code> <p>window over which pairwise correlations will be calculated in matching and control time periods,     if window is None entire time period is considered, in seconds</p> <code>slideby</code> <code>int</code> <p>slide window by this much, in seconds</p> <code>matching_windows</code> <code>array</code> <p>windows for matching period</p> <code>control_windows</code> <code>array</code> <p>windows for control period</p> <code>template_corr</code> <code>array</code> <p>pairwise correlations for template period</p> <code>matching_paircorr</code> <code>array</code> <p>pairwise correlations for matching period</p> <code>control_paircorr</code> <code>array</code> <p>pairwise correlations for control period</p> <code>ev</code> <code>array</code> <p>explained variance for each time point</p> <code>rev</code> <code>array</code> <p>reverse explained variance for each time point</p> <code>ev_std</code> <code>array</code> <p>explained variance standard deviation for each time point</p> <code>rev_std</code> <code>array</code> <p>reverse explained variance standard deviation for each time point</p> <code>partial_corr</code> <code>array</code> <p>partial correlations for each time point</p> <code>rev_partial_corr</code> <code>array</code> <p>reverse partial correlations for each time point</p> <code>n_pairs</code> <code>int</code> <p>number of pairs</p> <code>matching_time</code> <code>array</code> <p>time points for matching period</p> <code>control_time</code> <code>array</code> <p>time points for control period</p> <code>ev_signal</code> <code>AnalogSignalArray</code> <p>explained variance signal</p> <code>rev_signal</code> <code>AnalogSignalArray</code> <p>reverse explained variance signal</p> <code>plot</code> <code>function</code> <p>plot explained variance</p> <code>pvalue</code> <code>function</code> <p>calculate p-value for explained variance by shuffling the template correlations</p> <p>Examples:</p>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance--load-data","title":"Load data","text":"<pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\HMC\\HMC1\\day8\"\n&gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"CA1\",putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance--most-simple-case-returns-single-explained-variance-value","title":"Most simple case, returns single explained variance value","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=beh_epochs[2],\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=None,\n&gt;&gt;&gt;    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance--get-time-resolved-explained-variance-across-entire-session-in-200sec-bins","title":"Get time resolved explained variance across entire session in 200sec bins","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=200\n&gt;&gt;&gt;    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance--get-time-resolved-explained-variance-across-entire-session-in-200sec-bins-sliding-by-100sec","title":"Get time resolved explained variance across entire session in 200sec bins sliding by 100sec","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=200,\n&gt;&gt;&gt;        slideby=100\n&gt;&gt;&gt;    )\n</code></pre> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>class ExplainedVariance(object):\n    \"\"\"Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.\n\n    References\n    -------\n    1) Kudrimoti, H. S., Barnes, C. A., &amp; McNaughton, B. L. (1999).\n        Reactivation of Hippocampal Cell Assemblies: Effects of Behavioral State, Experience, and EEG Dynamics.\n        Journal of Neuroscience, 19(10), 4090-4101. https://doi.org/10/4090\n    2) Tatsuno, M., Lipa, P., &amp; McNaughton, B. L. (2006).\n        Methodological Considerations on the Use of Template Matching to Study Long-Lasting Memory Trace Replay.\n        Journal of Neuroscience, 26(42), 10727-10742. https://doi.org/10.1523/JNEUROSCI.3317-06.2006\n\n    Adapted from https://github.com/diba-lab/NeuroPy/blob/main/neuropy/analyses/reactivation.py\n\n    Attributes\n    ----------\n    st : SpikeTrainArray\n        obj that holds spiketrains\n    template : EpochArray\n        time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)\n    matching : EpochArray\n        time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)\n    control : EpochArray\n        time in seconds, control for pairwise correlations within this period (pre-task period)\n    bin_size : float\n        in seconds, binning size for spike counts\n    window : int\n        window over which pairwise correlations will be calculated in matching and control time periods,\n            if window is None entire time period is considered, in seconds\n    slideby : int\n        slide window by this much, in seconds\n    matching_windows : array\n        windows for matching period\n    control_windows : array\n        windows for control period\n    template_corr : array\n        pairwise correlations for template period\n    matching_paircorr : array\n        pairwise correlations for matching period\n    control_paircorr : array\n        pairwise correlations for control period\n    ev : array\n        explained variance for each time point\n    rev : array\n        reverse explained variance for each time point\n    ev_std : array\n        explained variance standard deviation for each time point\n    rev_std : array\n        reverse explained variance standard deviation for each time point\n    partial_corr : array\n        partial correlations for each time point\n    rev_partial_corr : array\n        reverse partial correlations for each time point\n    n_pairs : int\n        number of pairs\n    matching_time : array\n        time points for matching period\n    control_time : array\n        time points for control period\n    ev_signal : AnalogSignalArray\n        explained variance signal\n    rev_signal : AnalogSignalArray\n        reverse explained variance signal\n    plot : function\n        plot explained variance\n    pvalue : function\n        calculate p-value for explained variance by shuffling the template correlations\n\n    Examples\n    --------\n    # Load data\n    &gt;&gt;&gt; basepath = r\"U:\\data\\HMC\\HMC1\\day8\"\n    &gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"CA1\",putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n\n    # Most simple case, returns single explained variance value\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=beh_epochs[2],\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=None,\n    &gt;&gt;&gt;    )\n\n    # Get time resolved explained variance across entire session in 200sec bins\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=200\n    &gt;&gt;&gt;    )\n\n    # Get time resolved explained variance across entire session in 200sec bins sliding by 100sec\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=200,\n    &gt;&gt;&gt;        slideby=100\n    &gt;&gt;&gt;    )\n    \"\"\"\n\n    def __init__(\n        self,\n        st: SpikeTrainArray,\n        template: EpochArray,\n        matching: EpochArray,\n        control: EpochArray,\n        bin_size: float = 0.2,\n        window: int = 900,\n        slideby: int = None,\n    ):\n        \"\"\"Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.\n\n        Parameters\n        ----------\n        st : SpikeTrainArray\n            obj that holds spiketrains\n        template : EpochArray\n            time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)\n        matching : EpochArray\n            time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)\n        control : EpochArray\n            time in seconds, control for pairwise correlations within this period (pre-task period)\n        bin_size : float, optional\n            in seconds, binning size for spike counts, by default 0.2\n        window : int, optional\n            window over which pairwise correlations will be calculated in matching and control time periods,\n                if window is None entire time period is considered, in seconds, by default 900\n        slideby : int, optional\n            slide window by this much, in seconds, by default None\n        \"\"\"\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n\n        self.__validate_input()\n        self.__calculate()\n\n    def __validate_input(self):\n        \"\"\"Validate input parameters.\"\"\"\n        assert isinstance(self.st, SpikeTrainArray)\n        assert isinstance(self.template, EpochArray)\n        assert isinstance(self.matching, EpochArray)\n        assert isinstance(self.control, EpochArray)\n        assert isinstance(self.bin_size, (float, int))\n        assert isinstance(self.window, (int, type(None)))\n        assert isinstance(self.slideby, (int, type(None)))\n\n    def __calculate(self):\n        \"\"\"processing steps for explained variance calculation.\"\"\"\n        control_window_size, matching_window_size, slideby = self.__get_window_sizes()\n\n        self.matching_windows = self.__get_windows_array(\n            self.matching, matching_window_size, slideby\n        )\n        self.control_windows = self.__get_windows_array(\n            self.control, control_window_size, slideby\n        )\n        self.__validate_window_sizes(control_window_size, matching_window_size)\n        self.template_corr = self.__get_template_corr()\n        self.__calculate_pairwise_correlations()\n        self.__calculate_partial_correlations()\n\n    def __get_window_sizes(self):\n        \"\"\"Get window sizes for control and matching periods.\"\"\"\n        if self.window is None:\n            control_window_size = np.array(self.control.duration).astype(int)\n            matching_window_size = np.array(self.matching.duration).astype(int)\n            slideby = None\n        elif self.slideby is None:\n            control_window_size = self.window\n            matching_window_size = self.window\n            slideby = None\n        else:\n            control_window_size = self.window\n            matching_window_size = self.window\n            slideby = self.slideby\n        return control_window_size, matching_window_size, slideby\n\n    def __get_windows_array(self, epoch_array, window_size, slideby):\n        \"\"\"Get windows array for control and matching periods.\"\"\"\n        if slideby is not None:\n            array = np.arange(epoch_array.start, epoch_array.stop)\n            windows = np.lib.stride_tricks.sliding_window_view(array, window_size)\n            windows = windows[::slideby, [0, -1]]\n        elif np.array(epoch_array.duration) == window_size:\n            windows = np.array([[epoch_array.start, epoch_array.stop]])\n        else:\n            array = np.arange(epoch_array.start, epoch_array.stop, window_size)\n            windows = np.array([array[:-1], array[1:]]).T\n        return windows\n\n    def __validate_window_sizes(self, control_window_size, matching_window_size):\n        \"\"\"Validate window sizes.\"\"\"\n        assert (\n            control_window_size &lt;= self.control.duration\n        ), \"window is bigger than control\"\n        assert (\n            matching_window_size &lt;= self.matching.duration\n        ), \"window is bigger than matching\"\n\n    def __get_template_corr(self):\n        \"\"\"Get pairwise correlations for template period.\"\"\"\n        self.bst = self.st.bin(ds=self.bin_size)\n        return self.__get_pairwise_corr(self.bst[self.template].data)\n\n    def __calculate_pairwise_correlations(self):\n        \"\"\"Calculate pairwise correlations for matching and control periods.\"\"\"\n        self.matching_paircorr = self.__time_resolved_correlation(self.matching_windows)\n        self.control_paircorr = self.__time_resolved_correlation(self.control_windows)\n\n    @staticmethod\n    def __get_pairwise_corr(bst_data):\n        \"\"\"Calculate pairwise correlations.\"\"\"\n        corr = np.corrcoef(bst_data)\n        return corr[np.tril_indices(corr.shape[0], k=-1)]\n\n    def __time_resolved_correlation(self, windows):\n        \"\"\"Calculate pairwise correlations for given windows.\"\"\"\n        paircorr = []\n        bst_data = self.bst.data\n        bin_centers = self.bst.bin_centers\n\n        for w in windows:\n            start, stop = w\n            idx = (bin_centers &gt; start) &amp; (bin_centers &lt; stop)\n            corr = np.corrcoef(bst_data[:, idx])\n            paircorr.append(corr[np.tril_indices(corr.shape[0], k=-1)])\n\n        return np.array(paircorr)\n\n    def __calculate_partial_correlations(self):\n        \"\"\"Calculate partial correlations.\"\"\"\n        partial_corr, rev_partial_corr = self.__calculate_partial_correlations_(\n            self.matching_paircorr, self.control_paircorr, self.template_corr\n        )\n        self.__calculate_statistics(partial_corr, rev_partial_corr)\n\n    @staticmethod\n    @jit(nopython=True)\n    def __calculate_partial_correlations_(\n        matching_paircorr, control_paircorr, template_corr\n    ):\n        \"\"\"Calculate partial correlations.\"\"\"\n\n        def __explained_variance(x, y, covar):\n            \"\"\"Calculate explained variance and reverse explained variance.\"\"\"\n\n            # Calculate covariance matrix\n            n = len(covar)\n            valid = np.zeros(n, dtype=np.bool_)\n            for i in range(n):\n                valid[i] = not (np.isnan(covar[i]) or np.isnan(x[i]) or np.isnan(y[i]))\n            mat = np.empty((3, len(x)))\n            mat[0] = covar\n            mat[1] = x\n            mat[2] = y\n            cov = np.corrcoef(mat[:, valid])\n\n            # Calculate explained variance\n            EV = (cov[1, 2] - cov[0, 1] * cov[0, 2]) / (\n                np.sqrt((1 - cov[0, 1] ** 2) * (1 - cov[0, 2] ** 2)) + 1e-10\n            )\n\n            # Calculate reverse explained variance\n            rEV = (cov[0, 1] - cov[1, 2] * cov[0, 2]) / (\n                np.sqrt((1 - cov[1, 2] ** 2) * (1 - cov[0, 2] ** 2)) + 1e-10\n            )\n\n            return EV, rEV\n\n        n_matching = len(matching_paircorr)\n        n_control = len(control_paircorr)\n        partial_corr = np.zeros((n_control, n_matching))\n        rev_partial_corr = np.zeros((n_control, n_matching))\n\n        for m_i, m_pairs in enumerate(matching_paircorr):\n            for c_i, c_pairs in enumerate(control_paircorr):\n                partial_corr[c_i, m_i], rev_partial_corr[c_i, m_i] = (\n                    __explained_variance(template_corr, m_pairs, c_pairs)\n                )\n        return partial_corr, rev_partial_corr\n\n    def __calculate_statistics(self, partial_corr, rev_partial_corr):\n        \"\"\"Calculate explained variance statistics.\"\"\"\n        self.ev = np.nanmean(partial_corr**2, axis=0)\n        self.rev = np.nanmean(rev_partial_corr**2, axis=0)\n        self.ev_std = np.nanstd(partial_corr**2, axis=0)\n        self.rev_std = np.nanstd(rev_partial_corr**2, axis=0)\n        self.partial_corr = partial_corr**2\n        self.rev_partial_corr = rev_partial_corr**2\n        self.n_pairs = len(self.template_corr)\n        self.matching_time = np.mean(self.matching_windows, axis=1)\n        self.control_time = np.mean(self.control_windows, axis=1)\n\n    @property\n    def ev_signal(self):\n        \"\"\"Return explained variance signal.\"\"\"\n        return AnalogSignalArray(\n            data=self.ev,\n            timestamps=self.matching_time,\n            fs=1 / np.diff(self.matching_time)[0],\n            support=EpochArray(data=[self.matching.start, self.matching.stop]),\n        )\n\n    @property\n    def rev_signal(self):\n        \"\"\"Return reverse explained variance signal.\"\"\"\n        return AnalogSignalArray(\n            data=self.rev,\n            timestamps=self.matching_time,\n            fs=1 / np.diff(self.matching_time)[0],\n            support=EpochArray(data=[self.matching.start, self.matching.stop]),\n        )\n\n    def pvalue(self, n_shuffles=1000):\n        \"\"\"\n        Calculate p-value for explained variance by shuffling the template correlations.\n        \"\"\"\n        from copy import deepcopy\n\n        def shuffle_template(self):\n            template_corr = deepcopy(self.template_corr)\n            np.random.shuffle(template_corr)\n\n            partial_corr, _ = self.__calculate_partial_correlations_(\n                self.matching_paircorr, self.control_paircorr, template_corr\n            )\n            ev = np.nanmean(partial_corr**2, axis=0)\n            return ev.flatten()\n\n        if len(self.ev) &gt; 1:\n            print(\"Multiple time points, p-values are not supported\")\n            return\n\n        ev_shuffle = [shuffle_template(self) for _ in range(n_shuffles)]\n\n        ev_shuffle = np.array(ev_shuffle)\n\n        n = len(ev_shuffle)\n        r = np.sum(ev_shuffle &gt; self.ev)\n        pvalues = (r + 1) / (n + 1)\n        return pvalues\n\n    def plot(self):\n        \"\"\"Plot explained variance.\"\"\"\n        if self.matching_time.size == 1:\n            print(\"Only single time point, cannot plot\")\n            return\n        import matplotlib.pyplot as plt\n\n        fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n        ax.plot(self.matching_time, self.ev, label=\"EV\")\n        ax.fill_between(\n            self.matching_time,\n            self.ev - self.ev_std,\n            self.ev + self.ev_std,\n            alpha=0.5,\n        )\n        ax.plot(self.matching_time, self.rev, label=\"rEV\", color=\"grey\")\n        ax.fill_between(\n            self.matching_time,\n            self.rev - self.rev_std,\n            self.rev + self.rev_std,\n            alpha=0.5,\n            color=\"grey\",\n        )\n        # check if matching time overlaps with control time and plot control time\n        if np.any(\n            (self.control_time &gt;= self.matching_time[0])\n            &amp; (self.control_time &lt;= self.matching_time[-1])\n        ):\n            ax.axvspan(\n                self.control.start,\n                self.control.stop,\n                color=\"green\",\n                alpha=0.3,\n                label=\"Control\",\n                zorder=-10,\n            )\n        # check if matching time overlaps with template time and plot template time\n        if np.any(\n            (self.template.start &gt;= self.matching_time[0])\n            &amp; (self.template.stop &lt;= self.matching_time[-1])\n        ):\n            ax.axvspan(\n                self.template.start,\n                self.template.stop,\n                color=\"purple\",\n                alpha=0.4,\n                label=\"Template\",\n                zorder=-10,\n            )\n        # remove axis spines\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"top\"].set_visible(False)\n\n        ax.legend(frameon=False)\n        ax.set_xlabel(\"Time (s)\")\n        ax.set_ylabel(\"Explained Variance\")\n        ax.set_title(\"Explained Variance\")\n        plt.show()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance.ev_signal","title":"<code>ev_signal</code>  <code>property</code>","text":"<p>Return explained variance signal.</p>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance.rev_signal","title":"<code>rev_signal</code>  <code>property</code>","text":"<p>Return reverse explained variance signal.</p>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance.plot","title":"<code>plot()</code>","text":"<p>Plot explained variance.</p> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>def plot(self):\n    \"\"\"Plot explained variance.\"\"\"\n    if self.matching_time.size == 1:\n        print(\"Only single time point, cannot plot\")\n        return\n    import matplotlib.pyplot as plt\n\n    fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n    ax.plot(self.matching_time, self.ev, label=\"EV\")\n    ax.fill_between(\n        self.matching_time,\n        self.ev - self.ev_std,\n        self.ev + self.ev_std,\n        alpha=0.5,\n    )\n    ax.plot(self.matching_time, self.rev, label=\"rEV\", color=\"grey\")\n    ax.fill_between(\n        self.matching_time,\n        self.rev - self.rev_std,\n        self.rev + self.rev_std,\n        alpha=0.5,\n        color=\"grey\",\n    )\n    # check if matching time overlaps with control time and plot control time\n    if np.any(\n        (self.control_time &gt;= self.matching_time[0])\n        &amp; (self.control_time &lt;= self.matching_time[-1])\n    ):\n        ax.axvspan(\n            self.control.start,\n            self.control.stop,\n            color=\"green\",\n            alpha=0.3,\n            label=\"Control\",\n            zorder=-10,\n        )\n    # check if matching time overlaps with template time and plot template time\n    if np.any(\n        (self.template.start &gt;= self.matching_time[0])\n        &amp; (self.template.stop &lt;= self.matching_time[-1])\n    ):\n        ax.axvspan(\n            self.template.start,\n            self.template.stop,\n            color=\"purple\",\n            alpha=0.4,\n            label=\"Template\",\n            zorder=-10,\n        )\n    # remove axis spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n\n    ax.legend(frameon=False)\n    ax.set_xlabel(\"Time (s)\")\n    ax.set_ylabel(\"Explained Variance\")\n    ax.set_title(\"Explained Variance\")\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.ExplainedVariance.pvalue","title":"<code>pvalue(n_shuffles=1000)</code>","text":"<p>Calculate p-value for explained variance by shuffling the template correlations.</p> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>def pvalue(self, n_shuffles=1000):\n    \"\"\"\n    Calculate p-value for explained variance by shuffling the template correlations.\n    \"\"\"\n    from copy import deepcopy\n\n    def shuffle_template(self):\n        template_corr = deepcopy(self.template_corr)\n        np.random.shuffle(template_corr)\n\n        partial_corr, _ = self.__calculate_partial_correlations_(\n            self.matching_paircorr, self.control_paircorr, template_corr\n        )\n        ev = np.nanmean(partial_corr**2, axis=0)\n        return ev.flatten()\n\n    if len(self.ev) &gt; 1:\n        print(\"Multiple time points, p-values are not supported\")\n        return\n\n    ev_shuffle = [shuffle_template(self) for _ in range(n_shuffles)]\n\n    ev_shuffle = np.array(ev_shuffle)\n\n    n = len(ev_shuffle)\n    r = np.sum(ev_shuffle &gt; self.ev)\n    pvalues = (r + 1) / (n + 1)\n    return pvalues\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias","title":"<code>PairwiseBias</code>","text":"<p>               Bases: <code>object</code></p> <p>Pairwise bias analysis for comparing task and post-task spike sequences.</p> <p>Parameters:</p> Name Type Description Default <code>num_shuffles</code> <code>int</code> <p>Number of shuffles to perform for significance testing. Default is 300.</p> <code>300</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to run for computing correlations. Default is 10.</p> <code>10</code> <p>Attributes:</p> Name Type Description <code>total_neurons</code> <code>int, or None</code> <p>Total number of neurons in the dataset.</p> <code>task_skew_bias</code> <code>np.ndarray, or None</code> <p>Normalized skew-bias matrix for the task data.</p> <code>observed_correlation_</code> <code>np.ndarray, or None</code> <p>Observed cosine similarity between task and post-task bias matrices.</p> <code>shuffled_correlations_</code> <code>np.ndarray, or None</code> <p>Shuffled cosine similarities for significance testing.</p> <code>z_score_</code> <code>np.ndarray, or None</code> <p>Z-score of the observed correlation compared to the shuffled distribution.</p> <code>p_value_</code> <code>np.ndarray, or None</code> <p>p-value for significance test.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model using the task spike data.</p> <code>transform</code> <p>Transform the post-task data to compute z-scores and p-values.</p> <code>fit_transform</code> <p>Fit the model with task data and transform the post-task data.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>class PairwiseBias(object):\n    \"\"\"\n    Pairwise bias analysis for comparing task and post-task spike sequences.\n\n    Parameters\n    ----------\n    num_shuffles : int, optional\n        Number of shuffles to perform for significance testing. Default is 300.\n    n_jobs : int, optional\n        Number of parallel jobs to run for computing correlations. Default is 10.\n\n    Attributes\n    ----------\n    total_neurons : int, or None\n        Total number of neurons in the dataset.\n    task_skew_bias : np.ndarray, or None\n        Normalized skew-bias matrix for the task data.\n    observed_correlation_ : np.ndarray, or None\n        Observed cosine similarity between task and post-task bias matrices.\n    shuffled_correlations_ : np.ndarray, or None\n        Shuffled cosine similarities for significance testing.\n    z_score_ : np.ndarray, or None\n        Z-score of the observed correlation compared to the shuffled distribution.\n    p_value_ : np.ndarray, or None\n        p-value for significance test.\n\n    Methods\n    -------\n    fit(task_spikes: Union[List[float], np.ndarray], task_neurons: Union[List[int], np.ndarray]) -&gt; 'PairwiseBias'\n        Fit the model using the task spike data.\n    transform(post_spikes: Union[List[float], np.ndarray], post_neurons: Union[List[int], np.ndarray], post_intervals: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Transform the post-task data to compute z-scores and p-values.\n    fit_transform(task_spikes: Union[List[float], np.ndarray], task_neurons: Union[List[int], np.ndarray], post_spikes: Union[List[float], np.ndarray], post_neurons: Union[List[int], np.ndarray], post_intervals: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Fit the model with task data and transform the post-task data.\n    \"\"\"\n\n    def __init__(\n        self, num_shuffles: int = 300, n_jobs: int = 10, fillneutral: float = np.nan\n    ):\n        self.num_shuffles = num_shuffles\n        self.n_jobs = n_jobs\n        self.fillneutral = fillneutral\n        self.total_neurons = None\n        self.task_skew_bias = None\n        self.observed_correlation_ = None\n        self.shuffled_correlations_ = None\n        self.z_score_ = None\n        self.p_value_ = None\n\n    @staticmethod\n    def bias_matrix(\n        spike_times: np.ndarray,\n        neuron_ids: np.ndarray,\n        total_neurons: int,\n        fillneutral: float = np.nan,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.\n\n        Parameters\n        ----------\n        spike_times : np.ndarray\n            Spike times for the sequence.\n        neuron_ids : np.ndarray\n            Neuron identifiers corresponding to spike_times.\n        total_neurons : int\n            Total number of neurons being considered.\n        fillneutral : float, optional\n            Value to fill the diagonal of the bias matrix and other empty\n            combinations, by default np.nan.\n\n        Returns\n        -------\n        np.ndarray\n            A matrix of size (total_neurons, total_neurons) representing the bias.\n        \"\"\"\n        return skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral)\n\n    @staticmethod\n    def cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n        \"\"\"\n        Computes the cosine similarity between two flattened bias matrices.\n\n        Parameters\n        ----------\n        matrix1 : np.ndarray\n            A normalized bias matrix.\n        matrix2 : np.ndarray\n            Another normalized bias matrix.\n\n        Returns\n        -------\n        float\n            The cosine similarity between the two matrices.\n        \"\"\"\n        return cosine_similarity_matrices(matrix1, matrix2)\n\n    def observed_and_shuffled_correlation(\n        self,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        task_skew_bias: np.ndarray,\n        post_intervals: np.ndarray,\n        interval_i: int,\n    ) -&gt; Tuple[float, List[float]]:\n        \"\"\"\n        Compute observed and shuffled correlation for a given post-task interval.\n\n        Parameters\n        ----------\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        task_normalized : np.ndarray\n            Normalized task bias matrix.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs.\n        interval_i : int\n            Index of the current post-task interval.\n\n        Returns\n        -------\n        Tuple[float, List[float]]\n            The observed correlation and a list of shuffled correlations.\n        \"\"\"\n        post_neurons = np.asarray(post_neurons, dtype=int)\n\n        start, end = post_intervals[interval_i]\n        start_idx = np.searchsorted(post_spikes, start, side=\"left\")\n        end_idx = np.searchsorted(post_spikes, end, side=\"right\")\n\n        filtered_spikes = post_spikes[start_idx:end_idx]\n        filtered_neurons = post_neurons[start_idx:end_idx]\n\n        post_skew_bias = self.bias_matrix(\n            filtered_spikes,\n            filtered_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n\n        observed_correlation = self.cosine_similarity_matrices(\n            task_skew_bias, post_skew_bias\n        )\n\n        shuffled_correlation = []\n        for _ in range(self.num_shuffles):\n            shuffled_neurons = np.random.permutation(filtered_neurons)\n            shuffled_skew_bias = self.bias_matrix(\n                filtered_spikes,\n                shuffled_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            shuffled_correlation.append(\n                self.cosine_similarity_matrices(task_skew_bias, shuffled_skew_bias)\n            )\n\n        return observed_correlation, shuffled_correlation\n\n    def fit(\n        self,\n        task_spikes: np.ndarray,\n        task_neurons: np.ndarray,\n        task_intervals: np.ndarray = None,\n    ) -&gt; \"PairwiseBias\":\n        \"\"\"\n        Fit the model using the task spike data.\n\n        Parameters\n        ----------\n        task_spikes : np.ndarray\n            Spike times during the task.\n        task_neurons : np.ndarray\n            Neuron identifiers for task spikes.\n        task_intervals : np.ndarray, optional\n            Intervals for task epochs, by default None. If None, the entire task\n            data is used. Otherwise, the average bias matrix is computed across\n            all task intervals. Shape: (n_intervals, 2).\n\n        Returns\n        -------\n        PairwiseBias\n            Returns the instance itself.\n        \"\"\"\n        # Convert task_neurons to numpy array of integers\n        task_neurons = np.asarray(task_neurons, dtype=int)\n\n        # Calculate the total number of neurons based on unique entries in task_neurons\n        self.total_neurons = len(np.unique(task_neurons))\n\n        if task_intervals is None:\n            # Compute bias matrix for task data and normalize\n            task_skew_bias = self.bias_matrix(\n                task_spikes,\n                task_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            self.task_skew_bias = task_skew_bias\n        else:\n            # Compute bias matrices for each task interval\n            task_skew_biases = []\n\n            for interval in task_intervals:\n                # find the indices of spikes within the interval\n                start_idx = np.searchsorted(task_spikes, interval[0], side=\"left\")\n                end_idx = np.searchsorted(task_spikes, interval[1], side=\"right\")\n\n                # Extract spikes and neurons within the interval\n                interval_spikes = task_spikes[start_idx:end_idx]\n                interval_neurons = task_neurons[start_idx:end_idx]\n\n                # Compute the bias matrix for the interval\n                interval_skew_bias = self.bias_matrix(\n                    interval_spikes,\n                    interval_neurons,\n                    self.total_neurons,\n                    fillneutral=self.fillneutral,\n                )\n                task_skew_biases.append(interval_skew_bias)\n\n            # Average the normalized bias matrices\n            # I expect to see RuntimeWarnings in this block\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                self.task_skew_bias = np.nanmean(task_skew_biases, axis=0)\n        return self\n\n    def transform(\n        self,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        post_intervals: np.ndarray,\n        allow_reverse_replay: bool = False,\n        parallel: bool = True,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Transform the post-task data to compute z-scores and p-values.\n\n        Parameters\n        ----------\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs. Shape: (n_intervals, 2).\n        allow_reverse_replay : bool, optional\n            Whether to allow reverse sequences, by default False.\n        parallel : bool, optional\n            Whether to run in parallel, by default True.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            z_score: The z-score of the observed correlation compared to the shuffled distribution.\n            p_value: p-value for significance test.\n            observed_correlation_: The observed correlation for each interval.\n        \"\"\"\n        # Check if the number of jobs is less than the number of intervals\n        if post_intervals.shape[0] &lt; self.n_jobs:\n            self.n_jobs = post_intervals.shape[0]\n\n        if parallel:\n            observed_correlation, shuffled_correlations = zip(\n                *Parallel(n_jobs=self.n_jobs)(\n                    delayed(self.observed_and_shuffled_correlation)(\n                        post_spikes,\n                        post_neurons,\n                        self.task_skew_bias,\n                        post_intervals,\n                        interval_i,\n                    )\n                    for interval_i in range(post_intervals.shape[0])\n                )\n            )\n        else:  # Run in serial for debugging\n            observed_correlation, shuffled_correlations = zip(\n                *[\n                    self.observed_and_shuffled_correlation(\n                        post_spikes,\n                        post_neurons,\n                        self.task_skew_bias,\n                        post_intervals,\n                        interval_i,\n                    )\n                    for interval_i in range(post_intervals.shape[0])\n                ]\n            )\n\n        self.observed_correlation_ = np.array(\n            observed_correlation\n        )  # Shape: (n_intervals,)\n        self.shuffled_correlations_ = np.array(\n            shuffled_correlations\n        )  # Shape: (n_intervals, n_shuffles)\n\n        shuffled_mean = np.mean(self.shuffled_correlations_, axis=1)\n        shuffled_std = np.std(self.shuffled_correlations_, axis=1)\n        self.z_score_ = (self.observed_correlation_ - shuffled_mean) / shuffled_std\n\n        observed_correlation = self.observed_correlation_\n        shuffled_correlations = self.shuffled_correlations_\n        if allow_reverse_replay:\n            observed_correlation = np.abs(observed_correlation)\n            shuffled_correlations = np.abs(shuffled_correlations)\n\n        self.p_value_ = (\n            np.sum(\n                shuffled_correlations.T &gt; observed_correlation,\n                axis=0,\n            )\n            + 1\n        ) / (self.num_shuffles + 1)\n\n        return self.z_score_, self.p_value_, self.observed_correlation_\n\n    def fit_transform(\n        self,\n        task_spikes: np.ndarray,\n        task_neurons: np.ndarray,\n        task_intervals: np.ndarray,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        post_intervals: np.ndarray,\n        allow_reverse_replay: bool = False,\n        parallel: bool = True,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Fit the model with task data and transform the post-task data.\n\n        Parameters\n        ----------\n        task_spikes : np.ndarray\n            Spike times during the task.\n        task_neurons : np.ndarray\n            Neuron identifiers for task spikes.\n        task_intervals : np.ndarray\n            Intervals for task epochs. Shape: (n_intervals, 2).\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs. Shape: (n_intervals, 2).\n        allow_reverse_replay : bool, optional\n            Whether to allow reverse sequences, by default False.\n        parallel : bool, optional\n            Whether to run in parallel, by default True.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            z_score: The z-score of the observed correlation compared to the shuffled distribution.\n            p_value: p-value for significance test.\n            observed_correlation_: The observed correlation for each interval.\n        \"\"\"\n        self.fit(task_spikes, task_neurons, task_intervals)\n        return self.transform(\n            post_spikes, post_neurons, post_intervals, allow_reverse_replay, parallel\n        )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.bias_matrix","title":"<code>bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral=np.nan)</code>  <code>staticmethod</code>","text":"<p>Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.</p> <p>Parameters:</p> Name Type Description Default <code>spike_times</code> <code>ndarray</code> <p>Spike times for the sequence.</p> required <code>neuron_ids</code> <code>ndarray</code> <p>Neuron identifiers corresponding to spike_times.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered.</p> required <code>fillneutral</code> <code>float</code> <p>Value to fill the diagonal of the bias matrix and other empty combinations, by default np.nan.</p> <code>nan</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size (total_neurons, total_neurons) representing the bias.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>@staticmethod\ndef bias_matrix(\n    spike_times: np.ndarray,\n    neuron_ids: np.ndarray,\n    total_neurons: int,\n    fillneutral: float = np.nan,\n) -&gt; np.ndarray:\n    \"\"\"\n    Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.\n\n    Parameters\n    ----------\n    spike_times : np.ndarray\n        Spike times for the sequence.\n    neuron_ids : np.ndarray\n        Neuron identifiers corresponding to spike_times.\n    total_neurons : int\n        Total number of neurons being considered.\n    fillneutral : float, optional\n        Value to fill the diagonal of the bias matrix and other empty\n        combinations, by default np.nan.\n\n    Returns\n    -------\n    np.ndarray\n        A matrix of size (total_neurons, total_neurons) representing the bias.\n    \"\"\"\n    return skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.cosine_similarity_matrices","title":"<code>cosine_similarity_matrices(matrix1, matrix2)</code>  <code>staticmethod</code>","text":"<p>Computes the cosine similarity between two flattened bias matrices.</p> <p>Parameters:</p> Name Type Description Default <code>matrix1</code> <code>ndarray</code> <p>A normalized bias matrix.</p> required <code>matrix2</code> <code>ndarray</code> <p>Another normalized bias matrix.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The cosine similarity between the two matrices.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>@staticmethod\ndef cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the cosine similarity between two flattened bias matrices.\n\n    Parameters\n    ----------\n    matrix1 : np.ndarray\n        A normalized bias matrix.\n    matrix2 : np.ndarray\n        Another normalized bias matrix.\n\n    Returns\n    -------\n    float\n        The cosine similarity between the two matrices.\n    \"\"\"\n    return cosine_similarity_matrices(matrix1, matrix2)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.fit","title":"<code>fit(task_spikes, task_neurons, task_intervals=None)</code>","text":"<p>Fit the model using the task spike data.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike times during the task.</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers for task spikes.</p> required <code>task_intervals</code> <code>ndarray</code> <p>Intervals for task epochs, by default None. If None, the entire task data is used. Otherwise, the average bias matrix is computed across all task intervals. Shape: (n_intervals, 2).</p> <code>None</code> <p>Returns:</p> Type Description <code>PairwiseBias</code> <p>Returns the instance itself.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def fit(\n    self,\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    task_intervals: np.ndarray = None,\n) -&gt; \"PairwiseBias\":\n    \"\"\"\n    Fit the model using the task spike data.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike times during the task.\n    task_neurons : np.ndarray\n        Neuron identifiers for task spikes.\n    task_intervals : np.ndarray, optional\n        Intervals for task epochs, by default None. If None, the entire task\n        data is used. Otherwise, the average bias matrix is computed across\n        all task intervals. Shape: (n_intervals, 2).\n\n    Returns\n    -------\n    PairwiseBias\n        Returns the instance itself.\n    \"\"\"\n    # Convert task_neurons to numpy array of integers\n    task_neurons = np.asarray(task_neurons, dtype=int)\n\n    # Calculate the total number of neurons based on unique entries in task_neurons\n    self.total_neurons = len(np.unique(task_neurons))\n\n    if task_intervals is None:\n        # Compute bias matrix for task data and normalize\n        task_skew_bias = self.bias_matrix(\n            task_spikes,\n            task_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n        self.task_skew_bias = task_skew_bias\n    else:\n        # Compute bias matrices for each task interval\n        task_skew_biases = []\n\n        for interval in task_intervals:\n            # find the indices of spikes within the interval\n            start_idx = np.searchsorted(task_spikes, interval[0], side=\"left\")\n            end_idx = np.searchsorted(task_spikes, interval[1], side=\"right\")\n\n            # Extract spikes and neurons within the interval\n            interval_spikes = task_spikes[start_idx:end_idx]\n            interval_neurons = task_neurons[start_idx:end_idx]\n\n            # Compute the bias matrix for the interval\n            interval_skew_bias = self.bias_matrix(\n                interval_spikes,\n                interval_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            task_skew_biases.append(interval_skew_bias)\n\n        # Average the normalized bias matrices\n        # I expect to see RuntimeWarnings in this block\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            self.task_skew_bias = np.nanmean(task_skew_biases, axis=0)\n    return self\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.fit_transform","title":"<code>fit_transform(task_spikes, task_neurons, task_intervals, post_spikes, post_neurons, post_intervals, allow_reverse_replay=False, parallel=True)</code>","text":"<p>Fit the model with task data and transform the post-task data.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike times during the task.</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers for task spikes.</p> required <code>task_intervals</code> <code>ndarray</code> <p>Intervals for task epochs. Shape: (n_intervals, 2).</p> required <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs. Shape: (n_intervals, 2).</p> required <code>allow_reverse_replay</code> <code>bool</code> <p>Whether to allow reverse sequences, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>z_score: The z-score of the observed correlation compared to the shuffled distribution. p_value: p-value for significance test. observed_correlation_: The observed correlation for each interval.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def fit_transform(\n    self,\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    task_intervals: np.ndarray,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    post_intervals: np.ndarray,\n    allow_reverse_replay: bool = False,\n    parallel: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Fit the model with task data and transform the post-task data.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike times during the task.\n    task_neurons : np.ndarray\n        Neuron identifiers for task spikes.\n    task_intervals : np.ndarray\n        Intervals for task epochs. Shape: (n_intervals, 2).\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs. Shape: (n_intervals, 2).\n    allow_reverse_replay : bool, optional\n        Whether to allow reverse sequences, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        z_score: The z-score of the observed correlation compared to the shuffled distribution.\n        p_value: p-value for significance test.\n        observed_correlation_: The observed correlation for each interval.\n    \"\"\"\n    self.fit(task_spikes, task_neurons, task_intervals)\n    return self.transform(\n        post_spikes, post_neurons, post_intervals, allow_reverse_replay, parallel\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.observed_and_shuffled_correlation","title":"<code>observed_and_shuffled_correlation(post_spikes, post_neurons, task_skew_bias, post_intervals, interval_i)</code>","text":"<p>Compute observed and shuffled correlation for a given post-task interval.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>task_normalized</code> <code>ndarray</code> <p>Normalized task bias matrix.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs.</p> required <code>interval_i</code> <code>int</code> <p>Index of the current post-task interval.</p> required <p>Returns:</p> Type Description <code>Tuple[float, List[float]]</code> <p>The observed correlation and a list of shuffled correlations.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def observed_and_shuffled_correlation(\n    self,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    task_skew_bias: np.ndarray,\n    post_intervals: np.ndarray,\n    interval_i: int,\n) -&gt; Tuple[float, List[float]]:\n    \"\"\"\n    Compute observed and shuffled correlation for a given post-task interval.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    task_normalized : np.ndarray\n        Normalized task bias matrix.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs.\n    interval_i : int\n        Index of the current post-task interval.\n\n    Returns\n    -------\n    Tuple[float, List[float]]\n        The observed correlation and a list of shuffled correlations.\n    \"\"\"\n    post_neurons = np.asarray(post_neurons, dtype=int)\n\n    start, end = post_intervals[interval_i]\n    start_idx = np.searchsorted(post_spikes, start, side=\"left\")\n    end_idx = np.searchsorted(post_spikes, end, side=\"right\")\n\n    filtered_spikes = post_spikes[start_idx:end_idx]\n    filtered_neurons = post_neurons[start_idx:end_idx]\n\n    post_skew_bias = self.bias_matrix(\n        filtered_spikes,\n        filtered_neurons,\n        self.total_neurons,\n        fillneutral=self.fillneutral,\n    )\n\n    observed_correlation = self.cosine_similarity_matrices(\n        task_skew_bias, post_skew_bias\n    )\n\n    shuffled_correlation = []\n    for _ in range(self.num_shuffles):\n        shuffled_neurons = np.random.permutation(filtered_neurons)\n        shuffled_skew_bias = self.bias_matrix(\n            filtered_spikes,\n            shuffled_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n        shuffled_correlation.append(\n            self.cosine_similarity_matrices(task_skew_bias, shuffled_skew_bias)\n        )\n\n    return observed_correlation, shuffled_correlation\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.PairwiseBias.transform","title":"<code>transform(post_spikes, post_neurons, post_intervals, allow_reverse_replay=False, parallel=True)</code>","text":"<p>Transform the post-task data to compute z-scores and p-values.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs. Shape: (n_intervals, 2).</p> required <code>allow_reverse_replay</code> <code>bool</code> <p>Whether to allow reverse sequences, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>z_score: The z-score of the observed correlation compared to the shuffled distribution. p_value: p-value for significance test. observed_correlation_: The observed correlation for each interval.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def transform(\n    self,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    post_intervals: np.ndarray,\n    allow_reverse_replay: bool = False,\n    parallel: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Transform the post-task data to compute z-scores and p-values.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs. Shape: (n_intervals, 2).\n    allow_reverse_replay : bool, optional\n        Whether to allow reverse sequences, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        z_score: The z-score of the observed correlation compared to the shuffled distribution.\n        p_value: p-value for significance test.\n        observed_correlation_: The observed correlation for each interval.\n    \"\"\"\n    # Check if the number of jobs is less than the number of intervals\n    if post_intervals.shape[0] &lt; self.n_jobs:\n        self.n_jobs = post_intervals.shape[0]\n\n    if parallel:\n        observed_correlation, shuffled_correlations = zip(\n            *Parallel(n_jobs=self.n_jobs)(\n                delayed(self.observed_and_shuffled_correlation)(\n                    post_spikes,\n                    post_neurons,\n                    self.task_skew_bias,\n                    post_intervals,\n                    interval_i,\n                )\n                for interval_i in range(post_intervals.shape[0])\n            )\n        )\n    else:  # Run in serial for debugging\n        observed_correlation, shuffled_correlations = zip(\n            *[\n                self.observed_and_shuffled_correlation(\n                    post_spikes,\n                    post_neurons,\n                    self.task_skew_bias,\n                    post_intervals,\n                    interval_i,\n                )\n                for interval_i in range(post_intervals.shape[0])\n            ]\n        )\n\n    self.observed_correlation_ = np.array(\n        observed_correlation\n    )  # Shape: (n_intervals,)\n    self.shuffled_correlations_ = np.array(\n        shuffled_correlations\n    )  # Shape: (n_intervals, n_shuffles)\n\n    shuffled_mean = np.mean(self.shuffled_correlations_, axis=1)\n    shuffled_std = np.std(self.shuffled_correlations_, axis=1)\n    self.z_score_ = (self.observed_correlation_ - shuffled_mean) / shuffled_std\n\n    observed_correlation = self.observed_correlation_\n    shuffled_correlations = self.shuffled_correlations_\n    if allow_reverse_replay:\n        observed_correlation = np.abs(observed_correlation)\n        shuffled_correlations = np.abs(shuffled_correlations)\n\n    self.p_value_ = (\n        np.sum(\n            shuffled_correlations.T &gt; observed_correlation,\n            axis=0,\n        )\n        + 1\n    ) / (self.num_shuffles + 1)\n\n    return self.z_score_, self.p_value_, self.observed_correlation_\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.WeightedCorr","title":"<code>WeightedCorr(weights, x=None, y=None)</code>","text":"<p>Calculate the weighted correlation between the X and Y dimensions of the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A matrix of weights.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>X-values for each column and row, by default None.</p> <code>None</code> <code>y</code> <code>Optional[ndarray]</code> <p>Y-values for each column and row, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The weighted correlation coefficient.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def WeightedCorr(\n    weights: np.ndarray, x: Optional[np.ndarray] = None, y: Optional[np.ndarray] = None\n) -&gt; float:\n    \"\"\"\n    Calculate the weighted correlation between the X and Y dimensions of the matrix.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A matrix of weights.\n    x : Optional[np.ndarray], optional\n        X-values for each column and row, by default None.\n    y : Optional[np.ndarray], optional\n        Y-values for each column and row, by default None.\n\n    Returns\n    -------\n    float\n        The weighted correlation coefficient.\n    \"\"\"\n    weights[np.isnan(weights)] = 0.0\n\n    if x is not None and x.size &gt; 0:\n        if np.ndim(x) == 1:\n            x = np.tile(x, (weights.shape[0], 1))\n    else:\n        x, _ = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n\n    if y is not None and y.size &gt; 0:\n        if np.ndim(y) == 1:\n            y = np.tile(y, (weights.shape[0], 1))\n    else:\n        _, y = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n\n    x = x.flatten()\n    y = y.flatten()\n    w = weights.flatten()\n\n    mX = np.nansum(w * x) / np.nansum(w)\n    mY = np.nansum(w * y) / np.nansum(w)\n\n    covXY = np.nansum(w * (x - mX) * (y - mY)) / np.nansum(w)\n    covXX = np.nansum(w * (x - mX) ** 2) / np.nansum(w)\n    covYY = np.nansum(w * (y - mY) ** 2) / np.nansum(w)\n\n    c = covXY / np.sqrt(covXX * covYY)\n\n    return c\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.WeightedCorrCirc","title":"<code>WeightedCorrCirc(weights, x=None, alpha=None)</code>","text":"<p>Compute the correlation between x and y dimensions of a matrix with angular (circular) values.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A 2D numpy array of weights.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>A 2D numpy array of x-values, by default None.</p> <code>None</code> <code>alpha</code> <code>Optional[ndarray]</code> <p>A 2D numpy array of angular (circular) y-values, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The correlation between x and y dimensions.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def WeightedCorrCirc(\n    weights: np.ndarray,\n    x: Optional[np.ndarray] = None,\n    alpha: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"\n    Compute the correlation between x and y dimensions of a matrix with angular (circular) values.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A 2D numpy array of weights.\n    x : Optional[np.ndarray], optional\n        A 2D numpy array of x-values, by default None.\n    alpha : Optional[np.ndarray], optional\n        A 2D numpy array of angular (circular) y-values, by default None.\n\n    Returns\n    -------\n    float\n        The correlation between x and y dimensions.\n    \"\"\"\n    weights[np.isnan(weights)] = 0.0\n\n    if x is not None and x.size &gt; 0:\n        if np.ndim(x) == 1:\n            x = np.tile(x, (weights.shape[0], 1))\n    else:\n        x, _ = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n    if alpha is None:\n        alpha = np.tile(\n            np.linspace(0, 2 * np.pi, weights.shape[0], endpoint=False),\n            (weights.shape[1], 1),\n        ).T\n\n    rxs = WeightedCorr(weights, x, np.sin(alpha))\n    rxc = WeightedCorr(weights, x, np.cos(alpha))\n    rcs = WeightedCorr(weights, np.sin(alpha), np.cos(alpha))\n\n    # Compute angular-linear correlation\n    rho = np.sqrt((rxc**2 + rxs**2 - 2 * rxc * rxs * rcs) / (1 - rcs**2))\n    return rho\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.binshuffling","title":"<code>binshuffling(zactmat, significance)</code>","text":"<p>Perform bin shuffling to generate statistical threshold.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def binshuffling(zactmat: np.ndarray, significance: object) -&gt; float:\n    \"\"\"\n    Perform bin shuffling to generate statistical threshold.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    np.random.seed()\n\n    lambdamax_ = np.zeros(significance.nshu)\n    for shui in range(significance.nshu):\n        zactmat_ = np.copy(zactmat)\n        for neuroni, activity in enumerate(zactmat_):\n            randomorder = np.argsort(np.random.rand(significance.nbins))\n            zactmat_[neuroni, :] = activity[randomorder]\n        lambdamax_[shui] = getlambdacontrol(zactmat_)\n\n    lambdaMax = np.percentile(lambdamax_, significance.percentile)\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.bottom_up_replay_detection","title":"<code>bottom_up_replay_detection(posterior, time_centers, bin_centers, speed_times, speed_values, window_dt=None, speed_thresh=5.0, spread_thresh=10.0, com_jump_thresh=20.0, merge_spatial_gap=20.0, merge_time_gap=0.05, min_duration=0.1, dispersion_thresh=12.0, method='com')</code>","text":"<p>Bottom-up replay detector following Widloski &amp; Foster (2022) \"Replay detection and analysis\".</p> <p>Parameters:</p> Name Type Description Default <code>posterior</code> <code>ndarray</code> <p>Shape (n_time, n_space_bins) posterior probability for each time window.</p> required <code>time_centers</code> <code>ndarray</code> <p>Center time of each posterior time bin (length n_time) in seconds.</p> required <code>bin_centers</code> <code>ndarray</code> <p>Spatial bin centers (length n_space_bins) in same units as thresholds (cm).</p> required <code>speed_times</code> <code>ndarray</code> <p>Time stamps and speed values (cm/s) for the animal; used to interpolate speed at time_centers.</p> required <code>speed_values</code> <code>ndarray</code> <p>Time stamps and speed values (cm/s) for the animal; used to interpolate speed at time_centers.</p> required <code>window_dt</code> <code>Optional[float]</code> <p>Duration of each posterior time bin. If None, computed from time_centers diff.</p> <code>None</code> <code>speed_thresh</code> <code>float</code> <p>Speed threshold for filtering candidate replays (cm/s).</p> <code>5.0</code> <code>spread_thresh</code> <code>float</code> <p>Spread threshold for filtering candidate replays (cm).</p> <code>10.0</code> <code>com_jump_thresh</code> <code>float</code> <p>Center-of-mass jump threshold for filtering candidate replays (cm).</p> <code>20.0</code> <code>merge_spatial_gap</code> <code>float</code> <p>Spatial gap threshold for merging candidate replays (cm).</p> <code>20.0</code> <code>merge_time_gap</code> <code>float</code> <p>Temporal gap threshold for merging candidate replays (s).</p> <code>0.05</code> <code>min_duration</code> <code>float</code> <p>Minimum duration for keeping candidate replays (s).</p> <code>0.1</code> <code>dispersion_thresh</code> <code>float</code> <p>Dispersion threshold (mean absolute deviation of COM across sequence) for labeling replays (cm).</p> <code>12.0</code> <p>Returns:</p> Name Type Description <code>replays</code> <code>ndarray</code> <p>Array of replay events that passed dispersion threshold; shape (k,2) start/end times.</p> <code>meta</code> <code>dict</code> <p>Metadata dict with keys:  - 'candidates': candidate subsequences before dispersion filter; list of dicts with keys:     - 'start_time': start time of each candidate     - 'end_time': end time of each candidate     - 'start_idx': start index of each candidate     - 'end_idx': end index of each candidate     - 'duration': duration of each candidate (s)     - 'D2': dispersion (RMS radial deviation) per candidate (cm)     - 'com_trace': NaN-removed sequence of center-of-mass positions used for metrics     - 'path_length': path length (sum of consecutive COM step distances) across valid bins (cm)     - 'maxJump_NaN': maximum consecutive-step jump computed on the raw COM slice (may be NaN)     - 'maxJump_NaNremoved': maximum consecutive-step jump computed on the NaN-removed COM trace (cm)     - 'maxJump_NaNremoved_time': maximum temporal gap between valid (NaN-removed) samples (s)     - 'posteriorSpreadMax': maximum per-bin posterior spread across the candidate (cm)     - 'posteriorSpreadMean': mean per-bin posterior spread across the candidate (cm)  - 'com': center-of-mass per kept bin (array of shape (n_time, ) or (n_time,2))  - 'spread': posterior spread per kept bin (array of length n_time)  - 'mask': boolean mask of kept bins (array of length n_time)</p> Notes <p>This implementation assumes 1D and 2D spatial decoding.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def bottom_up_replay_detection(\n    posterior: np.ndarray,\n    time_centers: np.ndarray,\n    bin_centers: np.ndarray,\n    speed_times: np.ndarray,\n    speed_values: np.ndarray,\n    window_dt: Optional[float] = None,\n    speed_thresh: float = 5.0,\n    spread_thresh: float = 10.0,\n    com_jump_thresh: float = 20.0,\n    merge_spatial_gap: float = 20.0,\n    merge_time_gap: float = 0.05,\n    min_duration: float = 0.1,\n    dispersion_thresh: float = 12.0,\n    method: str = \"com\",\n) -&gt; Tuple[np.ndarray, dict]:\n    \"\"\"\n    Bottom-up replay detector following Widloski &amp; Foster (2022) \"Replay detection and analysis\".\n\n    Parameters\n    ----------\n    posterior : np.ndarray\n        Shape (n_time, n_space_bins) posterior probability for each time window.\n    time_centers : np.ndarray\n        Center time of each posterior time bin (length n_time) in seconds.\n    bin_centers : np.ndarray\n        Spatial bin centers (length n_space_bins) in same units as thresholds (cm).\n    speed_times, speed_values : np.ndarray\n        Time stamps and speed values (cm/s) for the animal; used to interpolate\n        speed at time_centers.\n    window_dt : Optional[float]\n        Duration of each posterior time bin. If None, computed from time_centers diff.\n    speed_thresh : float\n        Speed threshold for filtering candidate replays (cm/s).\n    spread_thresh : float\n        Spread threshold for filtering candidate replays (cm).\n    com_jump_thresh : float\n        Center-of-mass jump threshold for filtering candidate replays (cm).\n    merge_spatial_gap : float\n        Spatial gap threshold for merging candidate replays (cm).\n    merge_time_gap : float\n        Temporal gap threshold for merging candidate replays (s).\n    min_duration : float\n        Minimum duration for keeping candidate replays (s).\n    dispersion_thresh : float\n        Dispersion threshold (mean absolute deviation of COM across sequence) for labeling replays (cm).\n\n    Returns\n    -------\n    replays : np.ndarray\n        Array of replay events that passed dispersion threshold; shape (k,2) start/end times.\n    meta : dict\n        Metadata dict with keys:\n         - 'candidates': candidate subsequences before dispersion filter; list of dicts with keys:\n            - 'start_time': start time of each candidate\n            - 'end_time': end time of each candidate\n            - 'start_idx': start index of each candidate\n            - 'end_idx': end index of each candidate\n            - 'duration': duration of each candidate (s)\n            - 'D2': dispersion (RMS radial deviation) per candidate (cm)\n            - 'com_trace': NaN-removed sequence of center-of-mass positions used for metrics\n            - 'path_length': path length (sum of consecutive COM step distances) across valid bins (cm)\n            - 'maxJump_NaN': maximum consecutive-step jump computed on the raw COM slice (may be NaN)\n            - 'maxJump_NaNremoved': maximum consecutive-step jump computed on the NaN-removed COM trace (cm)\n            - 'maxJump_NaNremoved_time': maximum temporal gap between valid (NaN-removed) samples (s)\n            - 'posteriorSpreadMax': maximum per-bin posterior spread across the candidate (cm)\n            - 'posteriorSpreadMean': mean per-bin posterior spread across the candidate (cm)\n         - 'com': center-of-mass per kept bin (array of shape (n_time, ) or (n_time,2))\n         - 'spread': posterior spread per kept bin (array of length n_time)\n         - 'mask': boolean mask of kept bins (array of length n_time)\n\n    Notes\n    -----\n    This implementation assumes 1D and 2D spatial decoding.\n    \"\"\"\n    posterior = np.asarray(posterior)\n    time_centers = np.asarray(time_centers)\n\n    # Support posteriors where time is the last axis (space..., time)\n    # Move time axis to front so internal code works with shape (n_time, ...)\n    if posterior.ndim &gt;= 2 and posterior.shape[0] != time_centers.shape[0]:\n        if posterior.shape[-1] == time_centers.shape[0]:\n            posterior = np.moveaxis(posterior, -1, 0)\n        else:\n            raise ValueError(\"posterior time dimension does not match time_centers\")\n    # bin_centers may be a 1D array for 1D posteriors or a tuple (y_centers, x_centers)\n    # for 2D posteriors. Don't force-cast a tuple into an ndarray.\n    if posterior.ndim == 3:\n        if not (isinstance(bin_centers, (tuple, list)) and len(bin_centers) == 2):\n            raise ValueError(\n                \"For 2D posterior, bin_centers must be (y_centers, x_centers)\"\n            )\n        y_centers, x_centers = bin_centers\n    else:\n        bin_centers = np.asarray(bin_centers)\n\n    if posterior.shape[0] != time_centers.shape[0]:\n        raise ValueError(\n            \"posterior and time_centers must have matching first dimension\"\n        )\n\n    n_time = posterior.shape[0]\n\n    # bin duration\n    if window_dt is None:\n        if n_time &gt; 1:\n            window_dt = np.median(np.diff(time_centers))\n        else:\n            window_dt = 0.0\n\n    # compute COMs and spread; support 1D and 2D posteriors\n    if posterior.ndim == 2:\n        # 1D posterior: shape (n_time, n_space)\n        com = position_estimator(posterior, bin_centers, method=method)\n\n        # compute posterior spread (weighted std)\n        spread = np.full(n_time, np.nan)\n        for ti in range(n_time):\n            P = posterior[ti]\n            s = np.sum(P)\n            if s &gt; 0:\n                Pn = P / s\n                mu = np.sum(bin_centers * Pn)\n                spread[ti] = np.sqrt(np.sum(((bin_centers - mu) ** 2) * Pn))\n\n        # compute COM jump sizes (between consecutive bins)\n        com_jump = np.full(n_time, np.nan)\n        com_diff = np.abs(np.diff(com, prepend=np.nan))\n        com_jump[1:] = com_diff[1:]\n\n    elif posterior.ndim == 3:\n        # 2D posterior: shape (n_time, ny, nx)\n        y_centers, x_centers = bin_centers\n        xx, yy = np.meshgrid(x_centers, y_centers, indexing=\"xy\")\n\n        com = np.full((n_time, 2), np.nan)\n        spread = np.full(n_time, np.nan)\n        for ti in range(n_time):\n            P = posterior[ti]\n            s = np.sum(P)\n            if s &gt; 0:\n                Pn = P / s\n                mu_x = np.sum(xx * Pn)\n                mu_y = np.sum(yy * Pn)\n                com[ti, 0] = mu_x\n                com[ti, 1] = mu_y\n                # RMS distance from mean\n                spread[ti] = np.sqrt(np.sum(((xx - mu_x) ** 2 + (yy - mu_y) ** 2) * Pn))\n\n        # compute COM jump sizes (Euclidean distance between consecutive COMs)\n        com_jump = np.full(n_time, np.nan)\n        for ti in range(1, n_time):\n            if not np.any(np.isnan(com[ti - 1])) and not np.any(np.isnan(com[ti])):\n                com_jump[ti] = np.linalg.norm(com[ti] - com[ti - 1])\n    else:\n        raise ValueError(\"posterior must be 2D (time,x) or 3D (time,y,x)\")\n\n    # interpolate speed at time_centers\n    speed = np.interp(time_centers, speed_times, speed_values)\n\n    # treat NaN COM-jumps (e.g. first bin) as failing the com_jump criterion\n    # to avoid letting NaNs silently pass (np.nan_to_num -&gt; 0). Set NaNs to +inf\n    # so they are excluded when compared to com_jump_thresh.\n    com_jump = np.array(com_jump, copy=True)\n    com_jump[np.isnan(com_jump)] = np.inf\n\n    # mask time bins that satisfy all three criteria\n    mask = (\n        (speed &lt; speed_thresh) &amp; (spread &lt; spread_thresh) &amp; (com_jump &lt; com_jump_thresh)\n    )\n\n    # find contiguous subsequences of True in mask\n    subseqs = []\n    if np.any(mask):\n        edges = np.diff(mask.astype(int))\n        starts = np.where(edges == 1)[0] + 1\n        ends = np.where(edges == -1)[0] + 1\n        if mask[0]:\n            starts = np.concatenate(([0], starts))\n        if mask[-1]:\n            ends = np.concatenate((ends, [n_time]))\n\n        for s, e in zip(starts, ends):\n            subseqs.append(\n                {\n                    \"start_idx\": s,\n                    \"end_idx\": e,\n                    \"start_time\": time_centers[s],\n                    \"end_time\": time_centers[e - 1],\n                }\n            )\n\n    # merge neighboring subsequences based on spatial and temporal gaps\n    merged = []\n    for seq in subseqs:\n        if not merged:\n            merged.append(seq)\n            continue\n        prev = merged[-1]\n        temporal_gap = seq[\"start_time\"] - prev[\"end_time\"]\n        # compute spatial gap differently for 1D vs 2D COM\n        if posterior.ndim == 2:\n            spatial_gap = np.abs(com[seq[\"start_idx\"]] - com[prev[\"end_idx\"] - 1])\n        else:\n            # com entries are 2D vectors (mu_x, mu_y)\n            a = com[seq[\"start_idx\"]]\n            b = com[prev[\"end_idx\"] - 1]\n            if np.any(np.isnan(a)) or np.any(np.isnan(b)):\n                spatial_gap = np.inf\n            else:\n                spatial_gap = float(np.linalg.norm(a - b))\n\n        if temporal_gap &lt;= merge_time_gap and spatial_gap &lt;= merge_spatial_gap:\n            # merge\n            prev[\"end_idx\"] = seq[\"end_idx\"]\n            prev[\"end_time\"] = seq[\"end_time\"]\n        else:\n            merged.append(seq)\n\n    # candidate sequences: duration &gt; min_duration\n    candidates = []\n    for seq in merged:\n        duration = (\n            seq[\"end_time\"] - seq[\"start_time\"] + (window_dt if window_dt &gt; 0 else 0.0)\n        )\n        if duration &gt;= min_duration:\n            # record COM trace for sequence and compute metrics on NaN-removed trace\n            idxs = np.arange(seq[\"start_idx\"], seq[\"end_idx\"])\n            com_trace = com[idxs]\n\n            # remove NaN entries (bins with no posterior mass)\n            if posterior.ndim == 2:\n                # 1D case: com_trace is 1D array\n                valid_mask = ~np.isnan(com_trace)\n                com_trace_valid = com_trace[valid_mask]\n            else:\n                # 2D case: com_trace is (n_bins, 2)\n                valid_mask = ~np.isnan(com_trace).any(axis=1)\n                com_trace_valid = com_trace[valid_mask]\n\n            # dispersion D2 = RMS radial deviation from centroid (match MATLAB)\n            if com_trace_valid.size == 0:\n                D2 = np.nan\n                centroid = np.nan\n            else:\n                if posterior.ndim == 2:\n                    centroid = np.nanmean(com_trace_valid)\n                    D2 = np.sqrt(np.nanmean((com_trace_valid - centroid) ** 2))\n                else:\n                    centroid = np.nanmean(com_trace_valid, axis=0)\n                    diffs = np.linalg.norm(com_trace_valid - centroid, axis=1)\n                    D2 = np.sqrt(np.nanmean(diffs**2))\n\n            # compute path length (sum of Euclidean distances between consecutive valid COM points)\n            if com_trace_valid.size == 0:\n                path_length = 0.0\n            else:\n                if com_trace_valid.ndim == 1:\n                    steps = np.abs(np.diff(com_trace_valid))\n                else:\n                    steps = np.linalg.norm(np.diff(com_trace_valid, axis=0), axis=1)\n                path_length = float(np.nansum(steps))\n\n            # compute maxJump on raw (may contain NaNs) and on NaN-removed trace\n            # For raw trace: compute diffs and allow NaNs to propagate (max may be NaN)\n            try:\n                if com_trace.size == 0:\n                    maxJump_NaN = np.nan\n                else:\n                    if com_trace.ndim == 1:\n                        raw_steps = np.abs(np.diff(com_trace))\n                    else:\n                        raw_steps = np.linalg.norm(np.diff(com_trace, axis=0), axis=1)\n                    maxJump_NaN = (\n                        float(np.nanmax(raw_steps)) if raw_steps.size &gt; 0 else np.nan\n                    )\n            except Exception:\n                maxJump_NaN = np.nan\n\n            # For NaN-removed trace\n            if com_trace_valid.size == 0:\n                maxJump_NaNremoved = np.nan\n                maxJump_NaNremoved_time = np.nan\n            else:\n                if com_trace_valid.ndim == 1:\n                    valid_steps = np.abs(np.diff(com_trace_valid))\n                else:\n                    valid_steps = np.linalg.norm(\n                        np.diff(com_trace_valid, axis=0), axis=1\n                    )\n                maxJump_NaNremoved = (\n                    float(np.nanmax(valid_steps)) if valid_steps.size &gt; 0 else np.nan\n                )\n\n                # compute times of valid samples to get max time gap\n                times_seq = time_centers[idxs]\n                times_valid = times_seq[valid_mask]\n                if times_valid.size &gt; 1:\n                    maxJump_NaNremoved_time = float(np.max(np.diff(times_valid)))\n                else:\n                    maxJump_NaNremoved_time = np.nan\n\n            # posteriorSpreadMax and posteriorSpreadMean for the sequence (NaN-removed)\n            seq_spreads = spread[idxs]\n            seq_spreads_valid = seq_spreads[~np.isnan(seq_spreads)]\n            if seq_spreads_valid.size &gt; 0:\n                posteriorSpreadMax = float(np.max(seq_spreads_valid))\n                posteriorSpreadMean = float(np.mean(seq_spreads_valid))\n            else:\n                posteriorSpreadMax = np.nan\n                posteriorSpreadMean = np.nan\n\n            candidates.append(\n                {\n                    \"start_time\": seq[\"start_time\"],\n                    \"end_time\": seq[\"end_time\"],\n                    \"start_idx\": seq[\"start_idx\"],\n                    \"end_idx\": seq[\"end_idx\"],\n                    \"duration\": duration,\n                    \"D2\": D2,\n                    \"com_trace\": com_trace_valid,\n                    \"path_length\": path_length,\n                    \"maxJump_NaN\": maxJump_NaN,\n                    \"maxJump_NaNremoved\": maxJump_NaNremoved,\n                    \"maxJump_NaNremoved_time\": maxJump_NaNremoved_time,\n                    \"posteriorSpreadMax\": posteriorSpreadMax,\n                    \"posteriorSpreadMean\": posteriorSpreadMean,\n                }\n            )\n\n    # select replays by dispersion threshold\n    replays = []\n    for c in candidates:\n        if c[\"D2\"] &gt; dispersion_thresh:\n            replays.append([c[\"start_time\"], c[\"end_time\"]])\n\n    replays = np.array(replays)\n\n    meta = {\n        \"candidates\": candidates,\n        \"com\": com,\n        \"spread\": spread,\n        \"mask\": mask,\n        \"window_dt\": window_dt,\n    }\n\n    return replays, meta\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.circshuffling","title":"<code>circshuffling(zactmat, significance)</code>","text":"<p>Perform circular shuffling to generate statistical threshold.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def circshuffling(zactmat: np.ndarray, significance: object) -&gt; float:\n    \"\"\"\n    Perform circular shuffling to generate statistical threshold.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    np.random.seed()\n\n    lambdamax_ = np.zeros(significance.nshu)\n    for shui in range(significance.nshu):\n        zactmat_ = np.copy(zactmat)\n        for neuroni, activity in enumerate(zactmat_):\n            cut = int(np.random.randint(significance.nbins * 2))\n            zactmat_[neuroni, :] = np.roll(activity, cut)\n        lambdamax_[shui] = getlambdacontrol(zactmat_)\n\n    lambdaMax = np.percentile(lambdamax_, significance.percentile)\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.computeAssemblyActivity","title":"<code>computeAssemblyActivity(patterns, zactmat, zerodiag=True)</code>","text":"<p>Compute assembly activity.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>ndarray</code> <p>Co-activation patterns (assemblies, neurons).</p> required <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix (neurons, time bins).</p> required <code>zerodiag</code> <code>bool</code> <p>If True, diagonal of projection matrix is set to zero, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Assembly activity matrix (assemblies, time bins).</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def computeAssemblyActivity(\n    patterns: np.ndarray,\n    zactmat: np.ndarray,\n    zerodiag: bool = True,\n) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Compute assembly activity.\n\n    Parameters\n    ----------\n    patterns : np.ndarray\n        Co-activation patterns (assemblies, neurons).\n    zactmat : np.ndarray\n        Z-scored activity matrix (neurons, time bins).\n    zerodiag : bool, optional\n        If True, diagonal of projection matrix is set to zero, by default True.\n\n    Returns\n    -------\n    Optional[np.ndarray]\n        Assembly activity matrix (assemblies, time bins).\n    \"\"\"\n    # check if patterns is empty (no assembly detected) and return None if so\n    if len(patterns) == 0:\n        return None\n\n    # number of assemblies and time bins\n    nassemblies = len(patterns)\n    nbins = np.size(zactmat, 1)\n\n    # transpose for later matrix multiplication\n    zactmat = zactmat.T\n\n    # preallocate assembly activity matrix (nassemblies, nbins)\n    assemblyAct = np.zeros((nassemblies, nbins))\n\n    # loop over assemblies\n    for assemblyi, pattern in enumerate(patterns):\n        # compute projection matrix (neurons, neurons)\n        projMat = np.outer(pattern, pattern)\n\n        # set the diagonal to zero to not count coactivation of i and j when i=j\n        if zerodiag:\n            np.fill_diagonal(projMat, 0)\n\n        # project assembly pattern onto z-scored activity matrix\n        assemblyAct[assemblyi, :] = np.nansum(zactmat @ projMat * zactmat, axis=1)\n\n    return assemblyAct\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.cosine_similarity","title":"<code>cosine_similarity(pv1, pv2)</code>","text":"<p>Cosine similarity between temporal difference vectors of two firing rate vector trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>pv1</code> <code>ndarray</code> <p>Temporal difference of firing rate vector trajectory in one context. Shape: (num_bins, num_neurons)</p> required <code>pv2</code> <code>ndarray</code> <p>Temporal difference of firing rate vector trajectory in another context. Shape: (num_bins, num_neurons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cosine similarity between the two contexts.</p> References <p>.. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A., Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J., Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional specialization manifests in the reliability of neural population codes. bioRxiv : the preprint server for biology, 2024.01.25.576941. https://doi.org/10.1101/2024.01.25.576941</p> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def cosine_similarity(pv1: np.ndarray, pv2: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Cosine similarity between temporal difference vectors of two firing rate\n    vector trajectories.\n\n    Parameters\n    ----------\n    pv1 : numpy.ndarray\n        Temporal difference of firing rate vector trajectory in one context.\n        Shape: (num_bins, num_neurons)\n\n    pv2 : numpy.ndarray\n        Temporal difference of firing rate vector trajectory in another context.\n        Shape: (num_bins, num_neurons)\n\n    Returns\n    -------\n    numpy.ndarray\n        Cosine similarity between the two contexts.\n\n    References\n    ----------\n    .. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,\n    Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,\n    Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional\n    specialization manifests in the reliability of neural population codes.\n    bioRxiv : the preprint server for biology, 2024.01.25.576941.\n    https://doi.org/10.1101/2024.01.25.576941\n    \"\"\"\n    cosine_mat = sklearn.metrics.pairwise.cosine_similarity(pv1, pv2)\n    cosine_sim = np.diag(cosine_mat)\n\n    return cosine_sim\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.cosine_similarity_matrices","title":"<code>cosine_similarity_matrices(matrix1, matrix2)</code>","text":"<p>Compute the cosine similarity between two flattened matrices</p> <p>Parameters:</p> Name Type Description Default <code>matrix1</code> <code>ndarray</code> <p>A normalized bias matrix</p> required <code>matrix2</code> <code>ndarray</code> <p>Another normalized bias matrix</p> required <p>Returns:</p> Type Description <code>float</code> <p>The cosine similarity between the two matrices.</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n    \"\"\"\n    Compute the cosine similarity between two flattened matrices\n\n    Parameters\n    ----------\n    matrix1 : numpy.ndarray\n        A normalized bias matrix\n    matrix2 : numpy.ndarray\n        Another normalized bias matrix\n\n    Returns\n    -------\n    float\n        The cosine similarity between the two matrices.\n    \"\"\"\n    # Flatten matrices\n    x = matrix1.flatten().reshape(1, -1)\n    y = matrix2.flatten().reshape(1, -1)\n\n    if np.all(np.isnan(x)) or np.all(np.isnan(y)):\n        return np.nan\n\n    # handle nan values\n    x = np.nan_to_num(x)\n    y = np.nan_to_num(y)\n\n    cossim = sklearn.metrics.pairwise.cosine_similarity(x, y)\n\n    # Compute cosine similarity\n    return cossim.item()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.extractPatterns","title":"<code>extractPatterns(actmat, significance, method, whiten='unit-variance', cross_structural=None)</code>","text":"<p>Extract co-activation patterns (assemblies).</p> <p>Parameters:</p> Name Type Description Default <code>actmat</code> <code>ndarray</code> <p>Activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <code>method</code> <code>str</code> <p>Method to extract assembly patterns (ica, pca).</p> required <code>whiten</code> <code>str</code> <p>Whitening method, by default \"unit-variance\".</p> <code>'unit-variance'</code> <code>cross_structural</code> <code>Optional[ndarray]</code> <p>Categorical vector indicating group membership for each neuron. If provided and method is 'ica', will run ICA on data with modified cross-structural correlation structure, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Co-activation patterns (assemblies).</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def extractPatterns(\n    actmat: np.ndarray,\n    significance: object,\n    method: str,\n    whiten: str = \"unit-variance\",\n    cross_structural: Optional[np.ndarray] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Extract co-activation patterns (assemblies).\n\n    Parameters\n    ----------\n    actmat : np.ndarray\n        Activity matrix.\n    significance : object\n        Object containing significance parameters.\n    method : str\n        Method to extract assembly patterns (ica, pca).\n    whiten : str, optional\n        Whitening method, by default \"unit-variance\".\n    cross_structural : Optional[np.ndarray], optional\n        Categorical vector indicating group membership for each neuron.\n        If provided and method is 'ica', will run ICA on data with modified\n        cross-structural correlation structure, by default None.\n\n    Returns\n    -------\n    np.ndarray\n        Co-activation patterns (assemblies).\n    \"\"\"\n    nassemblies = significance.nassemblies\n\n    if method == \"pca\":\n        idxs = np.argsort(-significance.explained_variance_)[0:nassemblies]\n        patterns = significance.components_[idxs, :]\n    elif method == \"ica\":\n        if cross_structural is not None:\n            # For cross-structural ICA, modify the input data to reflect the cross-structural correlation structure\n            correlations = _compute_cross_structural_correlation(\n                actmat, cross_structural\n            )\n\n            # Eigenvalue decomposition to get the cross-structural subspace\n            eigenvalues, eigenvectors = np.linalg.eigh(correlations)\n            idx = np.argsort(eigenvalues)[::-1]\n            eigenvalues = eigenvalues[idx]\n            eigenvectors = eigenvectors[:, idx]\n\n            # Use the top nassemblies components (already determined)\n            eigenvectors_sig = eigenvectors[:, :nassemblies]\n            eigenvalues_sig = eigenvalues[:nassemblies]\n\n            # Project the data onto the cross-structural subspace\n            projected_data = (\n                eigenvectors_sig * np.sqrt(np.maximum(eigenvalues_sig, 0))\n            ).T @ actmat\n\n            # Run ICA on the projected data\n            ica = FastICA(n_components=nassemblies, random_state=0, whiten=whiten)\n            ica.fit(projected_data.T)\n            # Transform ICA components back to original space\n            patterns = (\n                ica.components_\n                @ (eigenvectors_sig * np.sqrt(np.maximum(eigenvalues_sig, 0))).T\n            )\n        else:\n            # Standard ICA\n            ica = FastICA(n_components=nassemblies, random_state=0, whiten=whiten)\n            ica.fit(actmat.T)\n            patterns = ica.components_\n    else:\n        raise ValueError(\n            \"assembly extraction method \" + str(method) + \" not understood\"\n        )\n\n    if patterns is not np.nan:\n        patterns = patterns.reshape(nassemblies, -1)\n\n        # sets norm of assembly vectors to 1\n        norms = np.linalg.norm(patterns, axis=1)\n        patterns /= np.tile(norms, [np.size(patterns, 1), 1]).T\n\n    return patterns\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.getlambdacontrol","title":"<code>getlambdacontrol(zactmat_)</code>","text":"<p>Get the maximum eigenvalue from PCA.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat_</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Maximum eigenvalue.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def getlambdacontrol(zactmat_: np.ndarray) -&gt; float:\n    \"\"\"\n    Get the maximum eigenvalue from PCA.\n\n    Parameters\n    ----------\n    zactmat_ : np.ndarray\n        Z-scored activity matrix.\n\n    Returns\n    -------\n    float\n        Maximum eigenvalue.\n    \"\"\"\n    significance_ = PCA()\n    significance_.fit(zactmat_.T)\n    lambdamax_ = np.max(significance_.explained_variance_)\n\n    return lambdamax_\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.marcenkopastur","title":"<code>marcenkopastur(significance)</code>","text":"<p>Calculate statistical threshold from Marcenko-Pastur distribution.</p> <p>Parameters:</p> Name Type Description Default <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def marcenkopastur(significance: object) -&gt; float:\n    \"\"\"\n    Calculate statistical threshold from Marcenko-Pastur distribution.\n\n    Parameters\n    ----------\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    nbins = significance.nbins\n    nneurons = significance.nneurons\n    tracywidom = significance.tracywidom\n\n    # calculates statistical threshold from Marcenko-Pastur distribution\n    q = float(nbins) / float(nneurons)  # note that silent neurons are counted too\n    lambdaMax = pow((1 + np.sqrt(1 / q)), 2)\n    lambdaMax += tracywidom * pow(nneurons, -2.0 / 3)  # Tracy-Widom correction\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.observed_and_shuffled_correlation","title":"<code>observed_and_shuffled_correlation(post_spikes, post_neurons, total_neurons, task_normalized, post_intervals, interval_i, num_shuffles=100)</code>","text":"<p>Calculate observed and shuffled correlations between task and post-task neural activity.</p> <p>This function computes the correlation between normalized task bias matrix and post-task bias matrix, as well as correlations with shuffled post-task data.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Array of post-task spike times.</p> required <code>post_neurons</code> <code>ndarray</code> <p>Array of neuron IDs corresponding to post_spikes.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons in the dataset.</p> required <code>task_normalized</code> <code>ndarray</code> <p>Normalized bias matrix from task period.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Array of post-task intervals, shape (n_intervals, 2).</p> required <code>interval_i</code> <code>int</code> <p>Index of the current interval to analyze.</p> required <code>num_shuffles</code> <code>int</code> <p>Number of times to shuffle post-task data for null distribution, by default 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>Tuple[float, List[float]]</code> <p>A tuple containing: - observed_correlation: float     Cosine similarity between task and post-task bias matrices. - shuffled_correlation: List[float]     List of cosine similarities between task and shuffled post-task bias matrices.</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def observed_and_shuffled_correlation(\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    total_neurons: int,\n    task_normalized: np.ndarray,\n    post_intervals: np.ndarray,\n    interval_i: int,\n    num_shuffles: int = 100,\n) -&gt; Tuple[float, List[float]]:\n    \"\"\"\n    Calculate observed and shuffled correlations between task and post-task neural activity.\n\n    This function computes the correlation between normalized task bias matrix and\n    post-task bias matrix, as well as correlations with shuffled post-task data.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Array of post-task spike times.\n    post_neurons : np.ndarray\n        Array of neuron IDs corresponding to post_spikes.\n    total_neurons : int\n        Total number of neurons in the dataset.\n    task_normalized : np.ndarray\n        Normalized bias matrix from task period.\n    post_intervals : np.ndarray\n        Array of post-task intervals, shape (n_intervals, 2).\n    interval_i : int\n        Index of the current interval to analyze.\n    num_shuffles : int, optional\n        Number of times to shuffle post-task data for null distribution, by default 100.\n\n    Returns\n    -------\n    Tuple[float, List[float]]\n        A tuple containing:\n        - observed_correlation: float\n            Cosine similarity between task and post-task bias matrices.\n        - shuffled_correlation: List[float]\n            List of cosine similarities between task and shuffled post-task bias matrices.\n    \"\"\"\n    # for i_interval in range(post_intervals.shape[0]):\n    idx = (post_spikes &gt; post_intervals[interval_i][0]) &amp; (\n        post_spikes &lt; post_intervals[interval_i][1]\n    )\n\n    post_bias_matrix = skew_bias_matrix(\n        post_spikes[idx], post_neurons[idx], total_neurons\n    )\n\n    # Compute cosine similarity between task and post-task bias matrices\n    observed_correlation = cosine_similarity_matrices(task_normalized, post_bias_matrix)\n\n    # Shuffle post-task spikes and compute bias matrix\n    shuffled_correlation = [\n        cosine_similarity_matrices(\n            task_normalized,\n            skew_bias_matrix(\n                post_spikes[idx],\n                np.random.permutation(post_neurons[idx]),\n                total_neurons,\n            ),\n        )\n        for _ in range(num_shuffles)\n    ]\n\n    return observed_correlation, shuffled_correlation\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.position_estimator","title":"<code>position_estimator(posterior_prob, *bin_centers, method='com')</code>","text":"<p>Decode 1D or 2D position from posterior probability distributions.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_prob</code> <code>ndarray</code> <p>Posterior probability distributions over spatial bins for each time bin. For 1D: shape (n_time_bins, n_bins) For 2D: shape (n_time_bins, n_y_bins, n_x_bins) Each time slice should contain non-negative values.</p> required <code>*bin_centers</code> <code>ndarray</code> <p>Coordinate values for the center of each spatial bin. For 1D: single array of shape (n_bins,) For 2D: two arrays - y_bin_centers of shape (n_y_bins,) and         x_bin_centers of shape (n_x_bins,)</p> <code>()</code> <code>method</code> <code>str</code> <p>Decoding method to use. Options are: - \"com\" : Center of mass (weighted average) (default) - \"max\" : Maximum a posteriori (position of maximum probability)</p> <code>'com'</code> <p>Returns:</p> Name Type Description <code>position</code> <code>ndarray</code> <p>Decoded positions for each time bin. For 1D: shape (n_time_bins,) containing position coordinates For 2D: shape (n_time_bins, 2) where position[:, 0] contains         x-coordinates and position[:, 1] contains y-coordinates Time bins with zero probability sum are filled with NaN.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If method is not \"com\" or \"max\", or if dimensions don't match expectations.</p> Notes <p>For the center of mass method, probabilities are normalized before computing the weighted average. For time bins where all probabilities are zero, the decoded position is set to NaN.</p> <p>The function automatically detects whether to perform 1D or 2D decoding based on the shape of the posterior_prob array and number of bin_centers provided.</p> <p>Examples:</p> <p>1D example:</p> <pre><code>&gt;&gt;&gt; posterior_1d = np.random.rand(10, 20)  # 10 time bins, 20 spatial bins\n&gt;&gt;&gt; bin_centers = np.linspace(0, 19, 20)\n&gt;&gt;&gt; positions = decode_position(posterior_1d, bin_centers)\n&gt;&gt;&gt; positions.shape\n(10,)\n</code></pre> <p>2D example:</p> <pre><code>&gt;&gt;&gt; posterior_2d = np.random.rand(10, 5, 4)  # 10 time bins, 5x4 spatial grid\n&gt;&gt;&gt; y_centers = np.linspace(0, 4, 5)\n&gt;&gt;&gt; x_centers = np.linspace(0, 3, 4)\n&gt;&gt;&gt; positions = decode_position(posterior_2d, y_centers, x_centers)\n&gt;&gt;&gt; positions.shape\n(10, 2)\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def position_estimator(\n    posterior_prob: np.ndarray, *bin_centers: np.ndarray, method: str = \"com\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode 1D or 2D position from posterior probability distributions.\n\n    Parameters\n    ----------\n    posterior_prob : np.ndarray\n        Posterior probability distributions over spatial bins for each time bin.\n        For 1D: shape (n_time_bins, n_bins)\n        For 2D: shape (n_time_bins, n_y_bins, n_x_bins)\n        Each time slice should contain non-negative values.\n    *bin_centers : np.ndarray\n        Coordinate values for the center of each spatial bin.\n        For 1D: single array of shape (n_bins,)\n        For 2D: two arrays - y_bin_centers of shape (n_y_bins,) and\n                x_bin_centers of shape (n_x_bins,)\n    method : str, optional\n        Decoding method to use. Options are:\n        - \"com\" : Center of mass (weighted average) (default)\n        - \"max\" : Maximum a posteriori (position of maximum probability)\n\n    Returns\n    -------\n    position : np.ndarray\n        Decoded positions for each time bin.\n        For 1D: shape (n_time_bins,) containing position coordinates\n        For 2D: shape (n_time_bins, 2) where position[:, 0] contains\n                x-coordinates and position[:, 1] contains y-coordinates\n        Time bins with zero probability sum are filled with NaN.\n\n    Raises\n    ------\n    ValueError\n        If method is not \"com\" or \"max\", or if dimensions don't match expectations.\n\n    Notes\n    -----\n    For the center of mass method, probabilities are normalized before computing\n    the weighted average. For time bins where all probabilities are zero,\n    the decoded position is set to NaN.\n\n    The function automatically detects whether to perform 1D or 2D decoding\n    based on the shape of the posterior_prob array and number of bin_centers provided.\n\n    Examples\n    --------\n    1D example:\n    &gt;&gt;&gt; posterior_1d = np.random.rand(10, 20)  # 10 time bins, 20 spatial bins\n    &gt;&gt;&gt; bin_centers = np.linspace(0, 19, 20)\n    &gt;&gt;&gt; positions = decode_position(posterior_1d, bin_centers)\n    &gt;&gt;&gt; positions.shape\n    (10,)\n\n    2D example:\n    &gt;&gt;&gt; posterior_2d = np.random.rand(10, 5, 4)  # 10 time bins, 5x4 spatial grid\n    &gt;&gt;&gt; y_centers = np.linspace(0, 4, 5)\n    &gt;&gt;&gt; x_centers = np.linspace(0, 3, 4)\n    &gt;&gt;&gt; positions = decode_position(posterior_2d, y_centers, x_centers)\n    &gt;&gt;&gt; positions.shape\n    (10, 2)\n    \"\"\"\n    if method not in [\"com\", \"max\"]:\n        raise ValueError(f\"Method '{method}' not recognized. Use 'com' or 'max'.\")\n\n    n_dims = len(posterior_prob.shape) - 1  # Subtract time dimension\n    n_time_bins = posterior_prob.shape[0]\n\n    if n_dims == 1:\n        return _position_estimator_1d(\n            posterior_prob, bin_centers[0], method, n_time_bins\n        )\n    elif n_dims == 2:\n        if len(bin_centers) != 2:\n            raise ValueError(\n                \"For 2D decoding, provide exactly 2 bin_centers arrays (y_centers, x_centers)\"\n            )\n        return _position_estimator_2d(\n            posterior_prob, bin_centers[0], bin_centers[1], method, n_time_bins\n        )\n    else:\n        raise ValueError(f\"Only 1D and 2D decoding supported, got {n_dims}D\")\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.potential_landscape","title":"<code>potential_landscape(X_dyn, projbins, domainbins=None)</code>","text":"<p>Compute numerical approximation of potential energy landscape across 1D state and domain (e.g. time, position, etc.).</p> <p>Potential landscape is defined as the integral of the flow vectors.</p> <p>Parameters:</p> Name Type Description Default <code>X_dyn</code> <code>ndarray</code> <p>State vectors of shape (trials, bins).</p> required <code>projbins</code> <code>int or array - like</code> <p>Number of bins for projection axis or bin edges</p> required <code>domainbins</code> <code>int or array - like</code> <p>Number of bins for domain axis or bin edges, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Potential energy landscape across state and domain</p> <code>ndarray</code> <p>Temporal gradient of potential energy landscape across state and domain</p> <code>ndarray</code> <p>Histogram of state vectors across state and domain</p> <code>ndarray</code> <p>Bin edges of state vectors</p> <code>ndarray</code> <p>Bin edges of domain</p> References <p>.. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect        decision confidence in macaque prefrontal cortex. Nat Neurosci 26,        1970\u20131980 (2023).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X_dyn = np.array([[0.1, 0.2, 0.4], [0.0, 0.3, 0.6]])\n&gt;&gt;&gt; projbins = 3\n&gt;&gt;&gt; domainbins = 3\n&gt;&gt;&gt; potential_landscape(X_dyn, projbins, domainbins)\n(array([[ 0.  ,  0.  ,   nan],\n        [-0.1 ,  0.  ,   nan],\n        [  nan,  0.  , -0.25]]),\narray([[0.3 ,  nan,  nan],\n       [0.1 ,  nan,  nan],\n       [ nan,  nan, 0.25]]),\narray([[1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 2.]]),\narray([0. , 0.1, 0.2, 0.3]),\narray([0.        , 0.33333333, 0.66666667, 1.        ]))\n</code></pre> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def potential_landscape(\n    X_dyn: np.ndarray,\n    projbins: Union[int, np.ndarray],\n    domainbins: Union[int, np.ndarray, None] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute numerical approximation of potential energy landscape across\n    1D state and domain (e.g. time, position, etc.).\n\n    Potential landscape is defined as the integral of the flow vectors.\n\n    Parameters\n    ----------\n    X_dyn : np.ndarray\n        State vectors of shape (trials, bins).\n    projbins : int or array-like\n        Number of bins for projection axis or bin edges\n    domainbins : int or array-like, optional\n        Number of bins for domain axis or bin edges, by default None\n\n    Returns\n    -------\n    np.ndarray\n        Potential energy landscape across state and domain\n    np.ndarray\n        Temporal gradient of potential energy landscape across state and domain\n    np.ndarray\n        Histogram of state vectors across state and domain\n    np.ndarray\n        Bin edges of state vectors\n    np.ndarray\n        Bin edges of domain\n\n    References\n    ----------\n    .. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect\n           decision confidence in macaque prefrontal cortex. Nat Neurosci 26,\n           1970\u20131980 (2023).\n\n    Examples\n    --------\n    &gt;&gt;&gt; X_dyn = np.array([[0.1, 0.2, 0.4], [0.0, 0.3, 0.6]])\n    &gt;&gt;&gt; projbins = 3\n    &gt;&gt;&gt; domainbins = 3\n    &gt;&gt;&gt; potential_landscape(X_dyn, projbins, domainbins)\n    (array([[ 0.  ,  0.  ,   nan],\n            [-0.1 ,  0.  ,   nan],\n            [  nan,  0.  , -0.25]]),\n    array([[0.3 ,  nan,  nan],\n           [0.1 ,  nan,  nan],\n           [ nan,  nan, 0.25]]),\n    array([[1., 0., 0.],\n           [1., 0., 0.],\n           [0., 0., 2.]]),\n    array([0. , 0.1, 0.2, 0.3]),\n    array([0.        , 0.33333333, 0.66666667, 1.        ]))\n    \"\"\"\n    # _t suffix is following notation of paper but applicable across any domain\n    nnrns = 1\n    ntrials, nbins = X_dyn.shape\n    delta_t = np.diff(X_dyn, axis=1)  # time derivatives: ntrials x nbins-1 x nnrns\n\n    X_t_flat = np.reshape(\n        X_dyn[:, :-1], (-1, nnrns), order=\"F\"\n    ).ravel()  # skip last bin as no displacement exists for last time point\n    delta_t_flat = np.reshape(\n        delta_t, (-1, nnrns), order=\"F\"\n    ).ravel()  # column-major order\n    norm_tpts = np.repeat(np.arange(nbins - 1), ntrials)\n\n    nbins_domain = (\n        nbins - 1 if domainbins is None else domainbins\n    )  # downsample domain bins\n\n    # 1D state space binning of time derivatives across domain\n    # assumes landscape may morph across domain\n    H, bin_edges, _ = binned_statistic_dd(  # posbins x time\n        np.asarray((X_t_flat, norm_tpts)).T,\n        delta_t_flat,\n        statistic=\"count\",\n        bins=(projbins, nbins_domain),\n    )\n    latentedges, domainedges = bin_edges\n\n    grad_pos_t_svm = binned_statistic_dd(\n        np.asarray((X_t_flat, norm_tpts)).T,\n        delta_t_flat,\n        statistic=\"sum\",\n        bins=(projbins, nbins_domain),\n    ).statistic\n    # average derivative, a.k.a. flow/vector field for dynamics underlying\n    # population activity\n    grad_pos_t_svm = np.divide(grad_pos_t_svm, H, where=H != 0)\n    grad_pos_t_svm[H == 0] = np.nan  # crucial to handle division by zero\n    # spatial integration via nnancumsum treats nan as zero for cumulative sum\n    potential_pos_t = -np.nancumsum(grad_pos_t_svm, axis=0)  # projbins x domainbins\n\n    idx_zero_X_t = np.searchsorted(latentedges, 0)\n    offset = potential_pos_t[idx_zero_X_t, :]  # use potential at X_t = 0 as reference\n    potential_pos_t = potential_pos_t - offset  # potential difference\n\n    nonzero_mask = H != 0\n    idx_first_nonzero, idx_last_nonzero = find_terminal_masked_indices(\n        nonzero_mask, axis=0\n    )  # each have shape: time\n    # along axis 0 set all values from start to idx_first_nonzero to nan\n    for t in range(H.shape[1]):\n        potential_pos_t[: idx_first_nonzero[t], t] = np.nan\n        potential_pos_t[idx_last_nonzero[t] + 1 :, t] = np.nan\n\n    return potential_pos_t, grad_pos_t_svm, H, latentedges, domainedges\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.potential_landscape_nd","title":"<code>potential_landscape_nd(X_dyn, projbins, domainbins=None, nanborderempty=True)</code>","text":"<p>Compute numerical approximation of potential energy landscape across n-dimensional state and domain (e.g. time, position, etc.).</p> <p>Potential landscape is defined as the integral of the flow vectors.</p> <p>Parameters:</p> Name Type Description Default <code>X_dyn</code> <code>ndarray</code> <p>State vectors of shape (trials, bins, neurons)</p> required <code>projbins</code> <code>int or array - like</code> <p>Number of bins for projection axis or bin edges for each neuron</p> required <code>domainbins</code> <code>int or array - like</code> <p>Number of bins for domain axis or bin edges, by default None</p> <code>None</code> <code>nanborderempty</code> <code>bool</code> <p>Whether to set border values to nan if they are empty, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Potential energy landscape across state averaged across domain for each neuron. Shape: nnrns x projbins times nnrns</p> <code>ndarray</code> <p>Potential energy landscape across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Temporal gradient of potential energy landscape across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Histogram of state vectors across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Bin edges of state vectors for each neuron</p> <code>ndarray</code> <p>Bin edges of domain for each neuron</p> References <p>.. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect        decision confidence in macaque prefrontal cortex. Nat Neurosci 26,        1970\u20131980 (2023).</p> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def potential_landscape_nd(\n    X_dyn: np.ndarray,\n    projbins: Union[int, np.ndarray],\n    domainbins: Union[int, np.ndarray, None] = None,\n    nanborderempty: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute numerical approximation of potential energy landscape across\n    n-dimensional state and domain (e.g. time, position, etc.).\n\n    Potential landscape is defined as the integral of the flow vectors.\n\n    Parameters\n    ----------\n    X_dyn : np.ndarray\n        State vectors of shape (trials, bins, neurons)\n    projbins : int or array-like\n        Number of bins for projection axis or bin edges for each neuron\n    domainbins : int or array-like, optional\n        Number of bins for domain axis or bin edges, by default None\n    nanborderempty : bool, optional\n        Whether to set border values to nan if they are empty, by default True\n\n    Returns\n    -------\n    np.ndarray\n        Potential energy landscape across state averaged across domain for each\n        neuron. Shape: nnrns x projbins times nnrns\n    np.ndarray\n        Potential energy landscape across state and domain for each neuron.\n        Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Temporal gradient of potential energy landscape across state and domain\n        for each neuron. Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Histogram of state vectors across state and domain for each neuron.\n        Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Bin edges of state vectors for each neuron\n    np.ndarray\n        Bin edges of domain for each neuron\n\n    References\n    ----------\n    .. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect\n           decision confidence in macaque prefrontal cortex. Nat Neurosci 26,\n           1970\u20131980 (2023).\n    \"\"\"\n    # _t suffix is following notation of paper but applicable across any domain\n    ntrials, nbins, nnrns = X_dyn.shape\n    delta_t = np.diff(\n        X_dyn, axis=1\n    )  # time derivatives: ntrials x ndomainbins-1 x nnrns\n\n    X_t_flat = np.reshape(\n        X_dyn[:, :-1], (-1, nnrns), order=\"F\"\n    )  # skip last bin as no displacement exists for last time point\n    delta_t_flat = np.reshape(delta_t, (-1, nnrns), order=\"F\")  # column-major order\n    norm_tpts = np.repeat(np.arange(nbins - 1), ntrials)\n\n    nbins_domain = (\n        nbins - 1 if domainbins is None else domainbins\n    )  # downsample domain bins\n\n    potential_pos_t_nrns = []\n    grad_pos_t_svm_nrns = []\n    hist_nrns = []\n    latentedges_nrns = []\n    domainedges_nrns = []\n    for nnrn in range(nnrns):\n        # 1D state space binning of time derivatives across domain\n        # assumes landscape may morph across domain\n        H, bin_edges, _ = binned_statistic_dd(  # (nnrns times projbins) x time\n            np.asarray((*X_t_flat.T, norm_tpts)).T,\n            delta_t_flat[:, nnrn],\n            statistic=\"count\",\n            bins=(\n                *[\n                    projbins if isinstance(projbins, int) else projbins[idx]\n                    for idx in range(nnrns)\n                ],\n                nbins_domain,\n            ),\n        )\n        latentedges = bin_edges[nnrn]\n        domainedges = bin_edges[-1]\n\n        grad_pos_t_svm = binned_statistic_dd(\n            np.asarray((*X_t_flat.T, norm_tpts)).T,\n            delta_t_flat[:, nnrn],\n            statistic=\"sum\",\n            bins=(\n                *[\n                    projbins if isinstance(projbins, int) else projbins[idx]\n                    for idx in range(nnrns)\n                ],\n                nbins_domain,\n            ),\n        ).statistic\n        # average derivative, a.k.a. flow/vector field for dynamics underlying\n        # population activity\n        grad_pos_t_svm = np.divide(grad_pos_t_svm, H, where=H != 0)\n        grad_pos_t_svm[H == 0] = np.nan  # crucial to handle division by zero\n        # spatial integration via nnancumsum treats nan as zero for cumulative sum\n        potential_pos_t = -np.nancumsum(\n            grad_pos_t_svm, axis=nnrn\n        )  # (nnrns times projbins) x domainbins\n\n        if nanborderempty:\n            nonzero_mask = H != 0\n\n            for t in range(nbins_domain):\n                nrndimslices = [slice(None)] * nnrns\n                nrndimslices.append(t)\n                peripheral_zeros_nanmask = ~np.isnan(\n                    replace_border_zeros_with_nan(nonzero_mask[tuple(nrndimslices)])\n                )\n                peripheral_zeros_nanmask = np.where(\n                    peripheral_zeros_nanmask, peripheral_zeros_nanmask, np.nan\n                )\n                potential_pos_t[tuple(nrndimslices)] *= peripheral_zeros_nanmask\n\n        potential_pos_t_nrns.append(potential_pos_t)\n        grad_pos_t_svm_nrns.append(grad_pos_t_svm)\n        hist_nrns.append(H)\n        latentedges_nrns.append(latentedges)\n        domainedges_nrns.append(domainedges)\n\n    potential_pos_t_nrns = np.stack(\n        potential_pos_t_nrns, axis=-1\n    )  # projbins x domainbins x nnrns\n    grad_pos_t_svm_nrns = np.stack(\n        grad_pos_t_svm_nrns, axis=-1\n    )  # projbins x domainbins x nnrns\n    hist = np.stack(hist_nrns, axis=-1)  # projbins x domainbins x nnrns\n    latentedges_nrns = np.stack(latentedges_nrns, axis=-1)  # projbins x nnrns\n    domainedges_nrns = np.stack(domainedges_nrns, axis=-1)  # domainbins x nnrns\n    nrndimslices = [slice(None)] * (nnrns + 1)\n    nrndimslices.append(0)\n    potential_nrns_pos = []\n    for nrn in range(nnrns):\n        nrndimslices[-1] = nrn\n        potential_nrns_pos.append(\n            np.nanmean(\n                potential_pos_t_nrns[tuple(nrndimslices)], axis=-1\n            )  # average across domainbins\n        )\n    potential_nrns_pos = np.asarray(potential_nrns_pos)  # nnrns x nnrns times projbins\n\n    return (\n        potential_nrns_pos,\n        potential_pos_t_nrns,\n        grad_pos_t_svm_nrns,\n        hist,\n        latentedges_nrns,\n        domainedges_nrns,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.proximity","title":"<code>proximity(pv1, pv2)</code>","text":"<p>Proximity between two firing rate vector trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>pv1</code> <code>ndarray</code> <p>Firing rate vector trajectory in one context. Shape: (num_bins, num_neurons)</p> required <code>pv2</code> <code>ndarray</code> <p>Firing rate vector trajectory in another context. Shape: (num_bins, num_neurons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Proximity between the two contexts.</p> References <p>.. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,     Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,     Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional     specialization manifests in the reliability of neural population codes.     bioRxiv : the preprint server for biology, 2024.01.25.576941.     https://doi.org/10.1101/2024.01.25.576941</p> Source code in <code>neuro_py/ensemble/geometry.py</code> <pre><code>def proximity(pv1: np.ndarray, pv2: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Proximity between two firing rate vector trajectories.\n\n    Parameters\n    ----------\n    pv1 : numpy.ndarray\n        Firing rate vector trajectory in one context.\n        Shape: (num_bins, num_neurons)\n\n    pv2 : numpy.ndarray\n        Firing rate vector trajectory in another context.\n        Shape: (num_bins, num_neurons)\n\n    Returns\n    -------\n    numpy.ndarray\n        Proximity between the two contexts.\n\n    References\n    ----------\n    .. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,\n        Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,\n        Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional\n        specialization manifests in the reliability of neural population codes.\n        bioRxiv : the preprint server for biology, 2024.01.25.576941.\n        https://doi.org/10.1101/2024.01.25.576941\n    \"\"\"\n    # Calculate the norms\n    norm_diff = np.linalg.norm(pv1 - pv2, axis=1)\n\n    norm_diff_mean = np.apply_along_axis(\n        lambda e: np.mean(np.linalg.norm(e - pv2, axis=1)), arr=pv1, axis=1\n    )\n\n    # Calculate proximity\n    prox = 1 - (norm_diff / norm_diff_mean)\n\n    return prox\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.runPatterns","title":"<code>runPatterns(actmat, method='ica', nullhyp='mp', nshu=1000, percentile=99, tracywidom=False, whiten='unit-variance', nassemblies=None, cross_structural=None)</code>","text":"<p>Run pattern detection to identify cell assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>actmat</code> <code>ndarray</code> <p>Activity matrix (neurons, time bins).</p> required <code>method</code> <code>str</code> <p>Method to extract assembly patterns (ica, pca), by default \"ica\".</p> <code>'ica'</code> <code>nullhyp</code> <code>str</code> <p>Null hypothesis method (bin, circ, mp), by default \"mp\".</p> <code>'mp'</code> <code>nshu</code> <code>int</code> <p>Number of shuffling controls, by default 1000.</p> <code>1000</code> <code>percentile</code> <code>int</code> <p>Percentile for shuffling methods, by default 99.</p> <code>99</code> <code>tracywidom</code> <code>bool</code> <p>Use Tracy-Widom correction, by default False.</p> <code>False</code> <code>whiten</code> <code>str</code> <p>Whitening method, by default \"unit-variance\".</p> <code>'unit-variance'</code> <code>nassemblies</code> <code>Optional[int]</code> <p>Number of assemblies, by default None.</p> <code>None</code> <code>cross_structural</code> <code>Optional[ndarray]</code> <p>A categorical vector indicating group membership for each neuron. If provided, the function will strictly detect cross-structural assemblies (correlations within the same group will be ignored), by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Tuple[Union[ndarray, None], object, Union[ndarray, None]], None]</code> <p>Patterns, significance object, and z-scored activity matrix.</p> Notes <p>nullhyp     'bin' - bin shuffling, will shuffle time bins of each neuron independently     'circ' - circular shuffling, will shift time bins of each neuron independently     'mp' - Marcenko-Pastur distribution - analytical threshold</p> <p>cross_structural     When provided, this vector should have the same length as the number of neurons     in actmat. Each element indicates the group membership (e.g., brain region,     cell type) for the corresponding neuron. The algorithm will then only detect     assemblies that span across different groups by setting within-group     correlations to zero.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def runPatterns(\n    actmat: np.ndarray,\n    method: str = \"ica\",\n    nullhyp: str = \"mp\",\n    nshu: int = 1000,\n    percentile: int = 99,\n    tracywidom: bool = False,\n    whiten: str = \"unit-variance\",\n    nassemblies: int = None,\n    cross_structural: Optional[np.ndarray] = None,\n) -&gt; Union[Tuple[Union[np.ndarray, None], object, Union[np.ndarray, None]], None]:\n    \"\"\"\n    Run pattern detection to identify cell assemblies.\n\n    Parameters\n    ----------\n    actmat : np.ndarray\n        Activity matrix (neurons, time bins).\n    method : str, optional\n        Method to extract assembly patterns (ica, pca), by default \"ica\".\n    nullhyp : str, optional\n        Null hypothesis method (bin, circ, mp), by default \"mp\".\n    nshu : int, optional\n        Number of shuffling controls, by default 1000.\n    percentile : int, optional\n        Percentile for shuffling methods, by default 99.\n    tracywidom : bool, optional\n        Use Tracy-Widom correction, by default False.\n    whiten : str, optional\n        Whitening method, by default \"unit-variance\".\n    nassemblies : Optional[int], optional\n        Number of assemblies, by default None.\n    cross_structural : Optional[np.ndarray], optional\n        A categorical vector indicating group membership for each neuron.\n        If provided, the function will strictly detect cross-structural assemblies\n        (correlations within the same group will be ignored), by default None.\n\n    Returns\n    -------\n    Union[Tuple[Union[np.ndarray, None], object, Union[np.ndarray, None]], None]\n        Patterns, significance object, and z-scored activity matrix.\n\n    Notes\n    -----\n    nullhyp\n        'bin' - bin shuffling, will shuffle time bins of each neuron independently\n        'circ' - circular shuffling, will shift time bins of each neuron independently\n        'mp' - Marcenko-Pastur distribution - analytical threshold\n\n    cross_structural\n        When provided, this vector should have the same length as the number of neurons\n        in actmat. Each element indicates the group membership (e.g., brain region,\n        cell type) for the corresponding neuron. The algorithm will then only detect\n        assemblies that span across different groups by setting within-group\n        correlations to zero.\n    \"\"\"\n\n    nneurons = np.size(actmat, 0)\n    nbins = np.size(actmat, 1)\n\n    # Validate cross_structural parameter if provided\n    if cross_structural is not None:\n        if len(cross_structural) != nneurons:\n            raise ValueError(\n                f\"cross_structural length ({len(cross_structural)}) must match \"\n                f\"number of neurons ({nneurons})\"\n            )\n\n    silentneurons = np.var(actmat, axis=1) == 0\n    actmat_ = actmat[~silentneurons, :]\n    if actmat_.shape[0] == 0:\n        warnings.warn(\"no active neurons\")\n        return None, None, None\n\n    # Update cross_structural to match active neurons only\n    cross_structural_ = None\n    if cross_structural is not None:\n        cross_structural_ = cross_structural[~silentneurons]\n\n    # z-scoring activity matrix\n    zactmat_ = stats.zscore(actmat_, axis=1)\n\n    # running significance (estimating number of assemblies)\n    significance = PCA()\n\n    if cross_structural_ is not None:\n        # Compute custom correlation matrix for cross-structural assemblies\n        correlations = _compute_cross_structural_correlation(\n            zactmat_, cross_structural_\n        )\n        # Perform eigenvalue decomposition on the custom correlation matrix\n        eigenvalues, eigenvectors = np.linalg.eigh(correlations)\n        # Sort in descending order\n        idx = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        # Store results in significance object to mimic PCA interface\n        significance.explained_variance_ = eigenvalues\n        significance.components_ = eigenvectors.T\n    else:\n        # Use standard PCA\n        significance.fit(zactmat_.T)\n\n    significance.nneurons = nneurons\n    significance.nbins = nbins\n    significance.nshu = nshu\n    significance.percentile = percentile\n    significance.tracywidom = tracywidom\n    significance.nullhyp = nullhyp\n    significance = runSignificance(zactmat_, significance)\n\n    if nassemblies is not None:\n        significance.nassemblies = nassemblies\n\n    if np.isnan(significance.nassemblies):\n        return None, significance, None\n\n    if significance.nassemblies &lt; 1:\n        warnings.warn(\"no assembly detected\")\n\n        patterns = None\n        zactmat = None\n    else:\n        # extracting co-activation patterns\n        patterns_ = extractPatterns(\n            zactmat_,\n            significance,\n            method,\n            whiten=whiten,\n            cross_structural=cross_structural_,\n        )\n        if patterns_ is np.nan:\n            return None\n\n        # putting eventual silent neurons back (their assembly weights are defined as zero)\n        patterns = np.zeros((np.size(patterns_, 0), nneurons))\n        patterns[:, ~silentneurons] = patterns_\n        zactmat = np.copy(actmat)\n        zactmat[~silentneurons, :] = zactmat_\n\n    return patterns, significance, zactmat\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.runSignificance","title":"<code>runSignificance(zactmat, significance)</code>","text":"<p>Run significance tests to estimate the number of assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Updated significance object with the number of assemblies.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def runSignificance(zactmat: np.ndarray, significance: object) -&gt; object:\n    \"\"\"\n    Run significance tests to estimate the number of assemblies.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    object\n        Updated significance object with the number of assemblies.\n    \"\"\"\n    if significance.nullhyp == \"mp\":\n        lambdaMax = marcenkopastur(significance)\n    elif significance.nullhyp == \"bin\":\n        lambdaMax = binshuffling(zactmat, significance)\n    elif significance.nullhyp == \"circ\":\n        lambdaMax = circshuffling(zactmat, significance)\n    else:\n        raise ValueError(\n            \"nyll hypothesis method \" + str(significance.nullhyp) + \" not understood\"\n        )\n\n    nassemblies = np.sum(significance.explained_variance_ &gt; lambdaMax)\n    significance.nassemblies = nassemblies\n\n    return significance\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.shuffle_and_score","title":"<code>shuffle_and_score(posterior_array, w, normalize, tc, ds, dp)</code>","text":"<p>Shuffle the posterior array and compute scores and weighted correlations.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_array</code> <code>ndarray</code> <p>The posterior probability array.</p> required <code>w</code> <code>ndarray</code> <p>Weights array.</p> required <code>normalize</code> <code>bool</code> <p>Whether to normalize the scores.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, float, float]</code> <p>Scores and weighted correlations for time-swapped and column-cycled arrays.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def shuffle_and_score(\n    posterior_array: np.ndarray,\n    w: np.ndarray,\n    normalize: bool,\n    tc: float,\n    ds: float,\n    dp: float,\n) -&gt; Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Shuffle the posterior array and compute scores and weighted correlations.\n\n    Parameters\n    ----------\n    posterior_array : np.ndarray\n        The posterior probability array.\n    w : np.ndarray\n        Weights array.\n    normalize : bool\n        Whether to normalize the scores.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, float, float]\n        Scores and weighted correlations for time-swapped and column-cycled arrays.\n    \"\"\"\n\n    posterior_ts = replay.time_swap_array(posterior_array)\n    posterior_cs = replay.column_cycle_array(posterior_array)\n\n    scores_time_swap = replay.trajectory_score_array(\n        posterior=posterior_ts, w=w, normalize=normalize\n    )\n    scores_col_cycle = replay.trajectory_score_array(\n        posterior=posterior_cs, w=w, normalize=normalize\n    )\n\n    weighted_corr_time_swap = weighted_correlation(posterior_ts)\n    weighted_corr_col_cycle = weighted_correlation(posterior_cs)\n\n    return (\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.shuffled_significance","title":"<code>shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals=np.array([[-np.inf, np.inf]]), num_shuffles=100, n_jobs=-1)</code>","text":"<p>Computes the significance of the task-post correlation by comparing against shuffled distributions.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike timestamps during the task. Shape is (n_spikes_task,)</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers corresponding to each of <code>task_spikes</code>. Shape is (n_spikes_task,)</p> required <code>post_spikes</code> <code>ndarray</code> <p>Spike timestamps during post-task (e.g., sleep). Shape is (n_spikes_post,)</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers corresponding to <code>post_spikes</code>. Shape is (n_spikes_post,)</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs, with shape (n_intervals, 2). Each row defines the start and end of an interval. May correspond to specific sleep states. Default is <code>np.array([[-np.inf, np.inf]])</code>, representing the entire range of post-task epochs</p> <code>array([[-inf, inf]])</code> <code>num_shuffles</code> <code>int</code> <p>Number of shuffles to compute the significance. Default is 100</p> <code>100</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to use for shuffling. Default is -1 (use all available cores).</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>z_score</code> <code>ndarray</code> <p>Z-scores of the observed correlations compared to the shuffled distributions. Shape is (n_intervals,).</p> <code>p_value</code> <code>ndarray</code> <p>P-values indicating the significance of the observed correlation. Shape is (n_intervals,).</p> Notes <p>The function uses parallel processing to compute observed and shuffled correlations for each post-task interval. The z-score is calculated as:</p> <pre><code>z_score = (observed_correlation - mean(shuffled_correlations)) / std(shuffled_correlations)\n</code></pre> <p>The p-value is computed as the proportion of shuffled correlations greater than the observed correlation, with a small constant added for numerical stability.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; task_spikes = np.array([1.2, 3.4, 5.6])\n&gt;&gt;&gt; task_neurons = np.array([0, 1, 0])\n&gt;&gt;&gt; post_spikes = np.array([2.3, 4.5, 6.7])\n&gt;&gt;&gt; post_neurons = np.array([1, 0, 1])\n&gt;&gt;&gt; total_neurons = 2\n&gt;&gt;&gt; post_intervals = np.array([[0, 10]])\n&gt;&gt;&gt; z_score, p_value = shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals)\n&gt;&gt;&gt; z_score\narray([1.23])\n&gt;&gt;&gt; p_value\narray([0.04])\n</code></pre> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def shuffled_significance(\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    total_neurons: int,\n    post_intervals: np.ndarray = np.array([[-np.inf, np.inf]]),\n    num_shuffles: int = 100,\n    n_jobs: int = -1,\n):\n    \"\"\"\n    Computes the significance of the task-post correlation by comparing against shuffled distributions.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike timestamps during the task. Shape is (n_spikes_task,)\n    task_neurons : np.ndarray\n        Neuron identifiers corresponding to each of `task_spikes`. Shape is\n        (n_spikes_task,)\n    post_spikes : np.ndarray\n        Spike timestamps during post-task (e.g., sleep). Shape is\n        (n_spikes_post,)\n    post_neurons : np.ndarray\n        Neuron identifiers corresponding to `post_spikes`. Shape is\n        (n_spikes_post,)\n    total_neurons : int\n        Total number of neurons being considered\n    post_intervals : np.ndarray, optional\n        Intervals for post-task epochs, with shape (n_intervals, 2).\n        Each row defines the start and end of an interval. May correspond to\n        specific sleep states. Default is `np.array([[-np.inf, np.inf]])`,\n        representing the entire range of post-task epochs\n    num_shuffles : int, optional\n        Number of shuffles to compute the significance. Default is 100\n    n_jobs : int, optional\n        Number of parallel jobs to use for shuffling. Default is -1 (use all\n        available cores).\n\n    Returns\n    -------\n    z_score : np.ndarray\n        Z-scores of the observed correlations compared to the shuffled distributions.\n        Shape is (n_intervals,).\n    p_value : np.ndarray\n        P-values indicating the significance of the observed correlation.\n        Shape is (n_intervals,).\n\n    Notes\n    -----\n    The function uses parallel processing to compute observed and shuffled\n    correlations for each post-task interval. The z-score is calculated as:\n\n        z_score = (observed_correlation - mean(shuffled_correlations)) / std(shuffled_correlations)\n\n    The p-value is computed as the proportion of shuffled correlations greater than\n    the observed correlation, with a small constant added for numerical stability.\n\n    Examples\n    --------\n    &gt;&gt;&gt; task_spikes = np.array([1.2, 3.4, 5.6])\n    &gt;&gt;&gt; task_neurons = np.array([0, 1, 0])\n    &gt;&gt;&gt; post_spikes = np.array([2.3, 4.5, 6.7])\n    &gt;&gt;&gt; post_neurons = np.array([1, 0, 1])\n    &gt;&gt;&gt; total_neurons = 2\n    &gt;&gt;&gt; post_intervals = np.array([[0, 10]])\n    &gt;&gt;&gt; z_score, p_value = shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals)\n    &gt;&gt;&gt; z_score\n    array([1.23])\n    &gt;&gt;&gt; p_value\n    array([0.04])\n    \"\"\"\n    # set random seed for reproducibility\n    np.random.seed(0)\n\n    # Compute bias matrices for task epochs\n    task_bias_matrix = skew_bias_matrix(task_spikes, task_neurons, total_neurons)\n\n    # Get shuffled and observed correlations using parallel processing\n    observed_correlation, shuffled_correlations = zip(\n        *Parallel(n_jobs=n_jobs)(\n            delayed(observed_and_shuffled_correlation)(\n                post_spikes,\n                post_neurons,\n                total_neurons,\n                task_bias_matrix,\n                post_intervals,\n                interval_i,\n                num_shuffles,\n            )\n            for interval_i in range(post_intervals.shape[0])\n        )\n    )\n    observed_correlation, shuffled_correlations = (\n        np.array(observed_correlation),\n        np.array(shuffled_correlations),\n    )\n    # Compute z-score\n    shuffled_mean = np.mean(shuffled_correlations, axis=1)\n    shuffled_std = np.std(shuffled_correlations, axis=1)\n    z_score = (observed_correlation - shuffled_mean) / shuffled_std\n\n    # significance test between the observed correlation and the shuffled distribution\n    p_value = (np.sum(shuffled_correlations.T &gt; observed_correlation, axis=0) + 1) / (\n        num_shuffles + 1\n    )\n\n    return z_score, p_value\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.skew_bias_matrix","title":"<code>skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral=0)</code>","text":"<p>Compute the pairwise skew-bias matrix for a given sequence of spikes.</p> <p>Parameters:</p> Name Type Description Default <code>spike_times</code> <code>ndarray</code> <p>Spike times for the sequence, assumed to be sorted.</p> required <code>neuron_ids</code> <code>ndarray</code> <p>Neuron identifiers corresponding to <code>spike_times</code>. Values should be integers between 0 and <code>total_neurons - 1</code>.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered.</p> required <code>fillneutral</code> <code>float</code> <p>Value to fill for neutral bias, by default 0</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Skew-bias matrix of size <code>(total_neurons, total_neurons)</code> where each entry represents the normalized bias between neuron pairs.</p> Notes <p>The probability-bias ( B_{ij} ) for neurons ( i ) and ( j ) is computed as: [ B_{ij} = \\frac{nspikes_{ij}}{nspikes_i \\cdot nspikes_j} ] where ( nspikes_{ij} ) is the count of spikes from neuron ( i ) occurring before spikes from neuron ( j ). If there are no spikes for either neuron, the bias is set to 0.5 (neutral bias).</p> <p>The skew-bias matrix is computed as: [ S_{ij} = 2 \\cdot B_{ij} - 1 ] where ( B_{ij} ) is the probability-bias matrix.</p> <p>The skew-bias matrix is a skew-symmetric matrix as ( S_{ij} = -S_{ji} ). The values are normalized between -1 and 1. A value of 1 indicates that neuron ( i ) spikes before neuron ( j ) in all cases, while -1 indicates the opposite. A value of 0 indicates that the order of spikes is random.</p> References <p>.. [1] Roth, Z. (2016). Analysis of neuronal sequences using pairwise     biases. arXiv, 11-16. https://arxiv.org/abs/1603.02916</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>@njit\ndef skew_bias_matrix(\n    spike_times: np.ndarray,\n    neuron_ids: np.ndarray,\n    total_neurons: int,\n    fillneutral: float = 0,\n) -&gt; np.ndarray:\n    r\"\"\"\n    Compute the pairwise skew-bias matrix for a given sequence of spikes.\n\n    Parameters\n    ----------\n    spike_times : numpy.ndarray\n        Spike times for the sequence, assumed to be sorted.\n    neuron_ids : numpy.ndarray\n        Neuron identifiers corresponding to `spike_times`.\n        Values should be integers between 0 and `total_neurons - 1`.\n    total_neurons : int\n        Total number of neurons being considered.\n    fillneutral : float, optional\n        Value to fill for neutral bias, by default 0\n\n    Returns\n    -------\n    numpy.ndarray\n        Skew-bias matrix of size `(total_neurons, total_neurons)` where\n        each entry represents the normalized bias between neuron pairs.\n\n    Notes\n    -----\n    The probability-bias \\( B_{ij} \\) for neurons \\( i \\) and \\( j \\) is\n    computed as:\n    \\[\n    B_{ij} = \\frac{nspikes_{ij}}{nspikes_i \\cdot nspikes_j}\n    \\]\n    where \\( nspikes_{ij} \\) is the count of spikes from neuron \\( i \\)\n    occurring before spikes from neuron \\( j \\). If there are no spikes for\n    either neuron, the bias is set to 0.5 (neutral bias).\n\n    The skew-bias matrix is computed as:\n    \\[\n    S_{ij} = 2 \\cdot B_{ij} - 1\n    \\]\n    where \\( B_{ij} \\) is the probability-bias matrix.\n\n    The skew-bias matrix is a skew-symmetric matrix as \\( S_{ij} = -S_{ji} \\).\n    The values are normalized between -1 and 1. A value of 1 indicates that\n    neuron \\( i \\) spikes before neuron \\( j \\) in all cases, while -1 indicates\n    the opposite. A value of 0 indicates that the order of spikes is random.\n\n    References\n    ----------\n    .. [1] Roth, Z. (2016). Analysis of neuronal sequences using pairwise\n        biases. arXiv, 11-16. https://arxiv.org/abs/1603.02916\n    \"\"\"\n    bias = np.empty((total_neurons, total_neurons))\n    nrn_spk_rindices = np.empty(total_neurons + 1, dtype=np.int64)\n    nrn_spk_rindices[0] = 0\n\n    nrns_st = numba.typed.List()\n    for _ in range(total_neurons):\n        nrns_st.append(numba.typed.List.empty_list(np.float64))\n    for i, nrn_id in enumerate(neuron_ids):\n        nrns_st[nrn_id].append(spike_times[i])\n    for nnrn in range(total_neurons):\n        nrn_spk_rindices[nnrn + 1] = nrn_spk_rindices[nnrn] + len(nrns_st[nnrn])\n\n    nrns_st_all = np.empty(nrn_spk_rindices[-1], dtype=np.float64)\n    for nnrn in range(total_neurons):\n        nrns_st_all[nrn_spk_rindices[nnrn] : nrn_spk_rindices[nnrn + 1]] = np.asarray(\n            nrns_st[nnrn]\n        )\n\n    # Build bias matrix\n    for i in range(total_neurons):\n        spikes_i = nrns_st_all[nrn_spk_rindices[i] : nrn_spk_rindices[i + 1]]\n        nspikes_i = len(spikes_i)\n\n        for j in range(i + 1, total_neurons):\n            nspikes_j = len(nrns_st[j])\n            if (nspikes_i == 0) or (nspikes_j == 0):\n                bias[i, j] = bias[j, i] = fillneutral\n            else:\n                spikes_j = nrns_st_all[nrn_spk_rindices[j] : nrn_spk_rindices[j + 1]]\n\n                nspikes_ij = np.searchsorted(spikes_i, spikes_j, side=\"right\").sum()\n                bias[i, j] = 2 * (nspikes_ij / (nspikes_i * nspikes_j)) - 1\n                bias[j, i] = -bias[i, j]\n\n    # set diagonal to fillneutral\n    for i in range(total_neurons):\n        bias[i, i] = fillneutral\n\n    return bias\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.toyExample","title":"<code>toyExample(assemblies, nneurons=10, nbins=1000, rate=1.0)</code>","text":"<p>Generate a toy example activity matrix with assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>assemblies</code> <code>ToyAssemblies</code> <p>The toy assemblies.</p> required <code>nneurons</code> <code>int</code> <p>Number of neurons, by default 10.</p> <code>10</code> <code>nbins</code> <code>int</code> <p>Number of time bins, by default 1000.</p> <code>1000</code> <code>rate</code> <code>float</code> <p>Poisson rate, by default 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Activity matrix.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def toyExample(\n    assemblies: \"ToyAssemblies\",\n    nneurons: int = 10,\n    nbins: int = 1000,\n    rate: float = 1.0,\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate a toy example activity matrix with assemblies.\n\n    Parameters\n    ----------\n    assemblies : ToyAssemblies\n        The toy assemblies.\n    nneurons : int, optional\n        Number of neurons, by default 10.\n    nbins : int, optional\n        Number of time bins, by default 1000.\n    rate : float, optional\n        Poisson rate, by default 1.0.\n\n    Returns\n    -------\n    np.ndarray\n        Activity matrix.\n    \"\"\"\n    np.random.seed(42)\n\n    actmat = np.random.poisson(rate, nneurons * nbins).reshape(nneurons, nbins)\n    assemblies.actbins = [None] * len(assemblies.membership)\n    for ai, members in enumerate(assemblies.membership):\n        members = np.array(members)\n        nact = int(nbins * assemblies.actrate[ai])\n        actstrength_ = rate * assemblies.actstrength[ai]\n\n        actbins = np.argsort(np.random.rand(nbins))[0:nact]\n\n        actmat[members.reshape(-1, 1), actbins] = (\n            np.ones((len(members), nact)) + actstrength_\n        )\n\n        assemblies.actbins[ai] = np.sort(actbins)\n\n    return actmat\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.trajectory_score_bst","title":"<code>trajectory_score_bst(bst, tuningcurve, w=None, n_shuffles=1000, weights=None, normalize=False, parallel=True)</code>","text":"<p>Calculate trajectory scores and weighted correlations for Bayesian spike train decoding.</p> <p>Parameters:</p> Name Type Description Default <code>bst</code> <code>BinnedSpikeTrainArray</code> <p>Binned spike train object.</p> required <code>tuningcurve</code> <code>TuningCurve1D</code> <p>Tuning curve object.</p> required <code>w</code> <code>Optional[int]</code> <p>Window size, by default None.</p> <code>None</code> <code>n_shuffles</code> <code>int</code> <p>Number of shuffles, by default 1000.</p> <code>1000</code> <code>weights</code> <code>Optional[ndarray]</code> <p>Weights array, by default None.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to normalize the scores, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[</code> <p>Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray],</p> <code>]</code> <p>Scores and weighted correlations for original, time-swapped, and column-cycled arrays.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def trajectory_score_bst(\n    bst: BinnedSpikeTrainArray,\n    tuningcurve: TuningCurve1D,\n    w: Optional[int] = None,\n    n_shuffles: int = 1000,\n    weights: Optional[np.ndarray] = None,\n    normalize: bool = False,\n    parallel: bool = True,\n) -&gt; Union[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    Tuple[np.ndarray, np.ndarray],\n]:\n    \"\"\"\n    Calculate trajectory scores and weighted correlations for Bayesian spike train decoding.\n\n    Parameters\n    ----------\n    bst : BinnedSpikeTrainArray\n        Binned spike train object.\n    tuningcurve : TuningCurve1D\n        Tuning curve object.\n    w : Optional[int], optional\n        Window size, by default None.\n    n_shuffles : int, optional\n        Number of shuffles, by default 1000.\n    weights : Optional[np.ndarray], optional\n        Weights array, by default None.\n    normalize : bool, optional\n        Whether to normalize the scores, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Union[\n        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n        Tuple[np.ndarray, np.ndarray],\n    ]\n        Scores and weighted correlations for original, time-swapped, and column-cycled arrays.\n    \"\"\"\n\n    if w is None:\n        w = 0\n    if not float(w).is_integer:\n        raise ValueError(\"w has to be an integer!\")\n\n    if float(n_shuffles).is_integer:\n        n_shuffles = int(n_shuffles)\n    else:\n        raise ValueError(\"n_shuffles must be an integer!\")\n\n    posterior, bdries, _, _ = decode(bst=bst, ratemap=tuningcurve)\n\n    num_cores = 1\n\n    if parallel:\n        # all but one core\n        num_cores = multiprocessing.cpu_count() - 1\n\n    ds, dp = bst.ds, np.diff(tuningcurve.bins)[0]\n\n    (\n        scores,\n        weighted_corr,\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    ) = zip(\n        *Parallel(n_jobs=num_cores)(\n            delayed(_shuffle_and_score)(\n                posterior[:, bdries[idx] : bdries[idx + 1]],\n                tuningcurve,\n                w,\n                normalize,\n                ds,\n                dp,\n                n_shuffles,\n            )\n            for idx in range(bst.n_epochs)\n        )\n    )\n\n    if n_shuffles &gt; 0:\n        return (\n            np.array(scores),\n            np.array(weighted_corr),\n            np.array(scores_time_swap).T,\n            np.array(scores_col_cycle).T,\n            np.array(weighted_corr_time_swap).T,\n            np.array(weighted_corr_col_cycle).T,\n        )\n    return scores, weighted_corr\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.weighted_corr_2d","title":"<code>weighted_corr_2d(weights, x_coords=None, y_coords=None, time_coords=None)</code>","text":"<p>Calculate the weighted correlation between the X and Y dimensions of the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A matrix of weights.</p> required <code>x_coords</code> <code>Optional[ndarray]</code> <p>X-values for each column and row, by default None.</p> <code>None</code> <code>y_coords</code> <code>Optional[ndarray]</code> <p>Y-values for each column and row, by default None.</p> <code>None</code> <code>time_coords</code> <code>Optional[ndarray]</code> <p>Time-values for each column and row, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, ndarray, ndarray, float, float, float, float]</code> <p>The weighted correlation coefficient, x trajectory, y trajectory, slope_x, slope_y, mean_x, mean_y.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; weights = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n&gt;&gt;&gt; x_coords = np.array([0, 1])\n&gt;&gt;&gt; y_coords = np.array([0, 1])\n&gt;&gt;&gt; time_coords = np.array([0, 1, 2])\n&gt;&gt;&gt; weighted_corr_2d(weights, x_coords, y_coords, time_coords)\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def weighted_corr_2d(\n    weights: np.ndarray,\n    x_coords: Optional[np.ndarray] = None,\n    y_coords: Optional[np.ndarray] = None,\n    time_coords: Optional[np.ndarray] = None,\n) -&gt; Tuple[float, np.ndarray, np.ndarray, float, float, float, float]:\n    \"\"\"\n    Calculate the weighted correlation between the X and Y dimensions of the matrix.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A matrix of weights.\n    x_coords : Optional[np.ndarray], optional\n        X-values for each column and row, by default None.\n    y_coords : Optional[np.ndarray], optional\n        Y-values for each column and row, by default None.\n    time_coords : Optional[np.ndarray], optional\n        Time-values for each column and row, by default None.\n\n    Returns\n    -------\n    Tuple[float, np.ndarray, np.ndarray, float, float, float, float]\n        The weighted correlation coefficient, x trajectory, y trajectory,\n        slope_x, slope_y, mean_x, mean_y.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; weights = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n    &gt;&gt;&gt; x_coords = np.array([0, 1])\n    &gt;&gt;&gt; y_coords = np.array([0, 1])\n    &gt;&gt;&gt; time_coords = np.array([0, 1, 2])\n    &gt;&gt;&gt; weighted_corr_2d(weights, x_coords, y_coords, time_coords)\n\n    \"\"\"\n    x_dim, y_dim, t_dim = weights.shape\n    dtype = weights.dtype\n\n    x_coords = (\n        np.arange(x_dim, dtype=dtype)\n        if x_coords is None\n        else np.asarray(x_coords, dtype=dtype)\n    )\n    y_coords = (\n        np.arange(y_dim, dtype=dtype)\n        if y_coords is None\n        else np.asarray(y_coords, dtype=dtype)\n    )\n    time_coords = (\n        np.arange(t_dim, dtype=dtype)\n        if time_coords is None\n        else np.asarray(time_coords, dtype=dtype)\n    )\n\n    return __weighted_corr_2d_jit(weights, x_coords, y_coords, time_coords)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/#neuro_py.ensemble.weighted_correlation","title":"<code>weighted_correlation(posterior, time=None, place_bin_centers=None, return_full_output=False)</code>","text":"<p>Calculate the weighted correlation between time and place bin centers using a posterior probability matrix.</p> <p>Parameters:</p> Name Type Description Default <code>posterior</code> <code>ndarray</code> <p>A 2D numpy array representing the posterior probability matrix.</p> required <code>time</code> <code>Optional[ndarray]</code> <p>A 1D numpy array representing the time bins, by default None.</p> <code>None</code> <code>place_bin_centers</code> <code>Optional[ndarray]</code> <p>A 1D numpy array representing the place bin centers, by default None.</p> <code>None</code> <code>return_full_output</code> <code>bool</code> <p>If True, return trajectory, slopes, means, and intercept in addition to correlation, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[float, Tuple[float, ndarray, float, float, float, float]]</code> <p>If return_full_output is False:     The weighted correlation coefficient (float). If return_full_output is True:     Tuple of (correlation, place_trajectory, slope_place, mean_time, mean_place, intercept_place)     where:     - correlation: weighted correlation coefficient     - place_trajectory: place position at each time bin     - slope_place: slope of place vs time     - mean_time: weighted mean of time     - mean_place: weighted mean of place     - intercept_place: intercept of linear relationship (place = intercept + slope_place * time)</p> <p>Examples:</p> <p>Basic usage with just a posterior matrix:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; # Create a synthetic posterior with forward replay pattern\n&gt;&gt;&gt; n_place_bins, n_time_bins = 20, 10\n&gt;&gt;&gt; posterior = np.zeros((n_place_bins, n_time_bins))\n&gt;&gt;&gt; for t in range(n_time_bins):\n...     posterior[2*t:2*t+3, t] = 1.0  # diagonal pattern\n&gt;&gt;&gt; correlation = weighted_correlation(posterior)\n&gt;&gt;&gt; print(f\"Correlation: {correlation:.3f}\")\n</code></pre> <p>With custom time and place bin centers:</p> <pre><code>&gt;&gt;&gt; time = np.linspace(0, 1, n_time_bins)  # 1 second duration\n&gt;&gt;&gt; place_bin_centers = np.linspace(0, 100, n_place_bins)  # 100 cm track\n&gt;&gt;&gt; correlation = weighted_correlation(posterior, time, place_bin_centers)\n</code></pre> <p>Getting full output including trajectory and slope:</p> <pre><code>&gt;&gt;&gt; corr, traj, slope, mean_t, mean_p, intercept = weighted_correlation(\n...     posterior, time, place_bin_centers, return_full_output=True\n... )\n&gt;&gt;&gt; print(f\"Replay speed: {slope:.1f} cm/s\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.imshow(\n...    posterior,\n...    aspect=\"auto\",\n...    origin=\"lower\",\n...    extent=[time[0], time[-1], place_bin_centers[0], place_bin_centers[-1]],\n...   cmap=\"bone_r\"\n... )\n&gt;&gt;&gt; plt.colorbar(label=\"Posterior Probability Density\")\n&gt;&gt;&gt; plt.plot(time, slope * time + intercept, color=\"red\", linewidth=2, label=\"fit line\")\n&gt;&gt;&gt; plt.legend()\n&gt;&gt;&gt; plt.xlabel(\"Time (s)\")\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def weighted_correlation(\n    posterior: np.ndarray,\n    time: Optional[np.ndarray] = None,\n    place_bin_centers: Optional[np.ndarray] = None,\n    return_full_output: bool = False,\n) -&gt; Union[float, Tuple[float, np.ndarray, float, float, float, float]]:\n    \"\"\"\n    Calculate the weighted correlation between time and place bin centers using a posterior probability matrix.\n\n    Parameters\n    ----------\n    posterior : np.ndarray\n        A 2D numpy array representing the posterior probability matrix.\n    time : Optional[np.ndarray], optional\n        A 1D numpy array representing the time bins, by default None.\n    place_bin_centers : Optional[np.ndarray], optional\n        A 1D numpy array representing the place bin centers, by default None.\n    return_full_output : bool, optional\n        If True, return trajectory, slopes, means, and intercept in addition to correlation, by default False.\n    Returns\n    -------\n    Union[float, Tuple[float, np.ndarray, float, float, float, float]]\n        If return_full_output is False:\n            The weighted correlation coefficient (float).\n        If return_full_output is True:\n            Tuple of (correlation, place_trajectory, slope_place, mean_time, mean_place, intercept_place)\n            where:\n            - correlation: weighted correlation coefficient\n            - place_trajectory: place position at each time bin\n            - slope_place: slope of place vs time\n            - mean_time: weighted mean of time\n            - mean_place: weighted mean of place\n            - intercept_place: intercept of linear relationship (place = intercept + slope_place * time)\n\n    Examples\n    --------\n    Basic usage with just a posterior matrix:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; # Create a synthetic posterior with forward replay pattern\n    &gt;&gt;&gt; n_place_bins, n_time_bins = 20, 10\n    &gt;&gt;&gt; posterior = np.zeros((n_place_bins, n_time_bins))\n    &gt;&gt;&gt; for t in range(n_time_bins):\n    ...     posterior[2*t:2*t+3, t] = 1.0  # diagonal pattern\n    &gt;&gt;&gt; correlation = weighted_correlation(posterior)\n    &gt;&gt;&gt; print(f\"Correlation: {correlation:.3f}\")\n\n    With custom time and place bin centers:\n\n    &gt;&gt;&gt; time = np.linspace(0, 1, n_time_bins)  # 1 second duration\n    &gt;&gt;&gt; place_bin_centers = np.linspace(0, 100, n_place_bins)  # 100 cm track\n    &gt;&gt;&gt; correlation = weighted_correlation(posterior, time, place_bin_centers)\n\n    Getting full output including trajectory and slope:\n\n    &gt;&gt;&gt; corr, traj, slope, mean_t, mean_p, intercept = weighted_correlation(\n    ...     posterior, time, place_bin_centers, return_full_output=True\n    ... )\n    &gt;&gt;&gt; print(f\"Replay speed: {slope:.1f} cm/s\")\n\n    &gt;&gt;&gt; plt.imshow(\n    ...    posterior,\n    ...    aspect=\"auto\",\n    ...    origin=\"lower\",\n    ...    extent=[time[0], time[-1], place_bin_centers[0], place_bin_centers[-1]],\n    ...   cmap=\"bone_r\"\n    ... )\n    &gt;&gt;&gt; plt.colorbar(label=\"Posterior Probability Density\")\n    &gt;&gt;&gt; plt.plot(time, slope * time + intercept, color=\"red\", linewidth=2, label=\"fit line\")\n    &gt;&gt;&gt; plt.legend()\n    &gt;&gt;&gt; plt.xlabel(\"Time (s)\")\n    \"\"\"\n\n    def _m(x, w) -&gt; float:\n        \"\"\"Weighted Mean\"\"\"\n        return np.sum(x * w) / np.sum(w)\n\n    def _cov(x, y, w) -&gt; float:\n        \"\"\"Weighted Covariance\"\"\"\n        return np.sum(w * (x - _m(x, w)) * (y - _m(y, w))) / np.sum(w)\n\n    def _corr(x, y, w) -&gt; float:\n        \"\"\"Weighted Correlation\"\"\"\n        return _cov(x, y, w) / np.sqrt(_cov(x, x, w) * _cov(y, y, w))\n\n    if time is None:\n        time = np.arange(posterior.shape[1])\n    if place_bin_centers is None:\n        place_bin_centers = np.arange(posterior.shape[0])\n\n    time = np.asarray(time)\n    place_bin_centers = place_bin_centers.squeeze()\n    posterior = np.array(posterior, copy=True)\n    posterior[np.isnan(posterior)] = 0.0\n\n    correlation = _corr(\n        time[:, np.newaxis], place_bin_centers[np.newaxis, :], posterior.T\n    )\n\n    if not return_full_output:\n        return correlation\n\n    # Compute full output (trajectory, slopes, means)\n    weights = posterior.T.flatten()\n    time_2d, place_2d = np.meshgrid(time, place_bin_centers, indexing=\"ij\")\n    time_flat = time_2d.flatten()\n    place_flat = place_2d.flatten()\n\n    # Compute weighted means\n    total_weight = np.sum(weights)\n\n    # Handle degenerate case: no weights\n    if total_weight == 0.0:\n        return (\n            np.nan,\n            np.full_like(time, np.nan),\n            np.nan,\n            np.nan,\n            np.nan,\n            np.nan,\n        )\n\n    mean_time = np.sum(weights * time_flat) / total_weight\n    mean_place = np.sum(weights * place_flat) / total_weight\n\n    # Compute covariances\n    cov_time_place = (\n        np.sum(weights * (time_flat - mean_time) * (place_flat - mean_place))\n        / total_weight\n    )\n    cov_time_time = np.sum(weights * (time_flat - mean_time) ** 2) / total_weight\n\n    # Handle degenerate case: no temporal variance\n    if cov_time_time == 0.0:\n        return (\n            np.nan,\n            np.full_like(time, np.nan),\n            np.nan,\n            mean_time,\n            mean_place,\n            np.nan,\n        )\n\n    # Compute slope and trajectory\n    slope_place = cov_time_place / cov_time_time\n    place_trajectory = mean_place + slope_place * (time - mean_time)\n    intercept_place = mean_place - slope_place * mean_time\n\n    return (\n        correlation,\n        place_trajectory,\n        slope_place,\n        mean_time,\n        mean_place,\n        intercept_place,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/","title":"neuro_py.ensemble.assembly","text":"<p>Codes for PCA/ICA methods described in Detecting cell assemblies in large neuronal populations, Lopes-dos-Santos et al (2013). https://doi.org/10.1016/j.jneumeth.2013.04.010 This implementation was written in Feb 2019. Please e-mail me if you have comments, doubts, bug reports or criticism (V\u00edtor, vtlsantos@gmail.com /  vitor.lopesdossantos@pharm.ox.ac.uk).</p>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.ToyAssemblies","title":"<code>ToyAssemblies</code>","text":"Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>class ToyAssemblies:\n    def __init__(\n        self,\n        membership: List[List[int]],\n        actrate: List[float],\n        actstrength: List[float],\n    ):\n        \"\"\"\n        Initialize ToyAssemblies.\n\n        Parameters\n        ----------\n        membership : List[List[int]]\n            List of lists containing neuron memberships for each assembly.\n        actrate : List[float]\n            List of activation rates for each assembly.\n        actstrength : List[float]\n            List of activation strengths for each assembly.\n        \"\"\"\n        self.membership = membership\n        self.actrate = actrate\n        self.actstrength = actstrength\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly._compute_cross_structural_correlation","title":"<code>_compute_cross_structural_correlation(zactmat, cross_structural)</code>","text":"<p>Compute correlation matrix with within-group correlations set to zero.</p> <p>This implements the cross-structural assembly detection approach where correlations within the same group are ignored to force detection of assemblies that span across different groups.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix (neurons, time bins).</p> required <code>cross_structural</code> <code>ndarray</code> <p>Categorical vector indicating group membership for each neuron.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Modified correlation matrix with within-group correlations set to zero.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def _compute_cross_structural_correlation(\n    zactmat: np.ndarray, cross_structural: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute correlation matrix with within-group correlations set to zero.\n\n    This implements the cross-structural assembly detection approach where\n    correlations within the same group are ignored to force detection of\n    assemblies that span across different groups.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix (neurons, time bins).\n    cross_structural : np.ndarray\n        Categorical vector indicating group membership for each neuron.\n\n    Returns\n    -------\n    np.ndarray\n        Modified correlation matrix with within-group correlations set to zero.\n    \"\"\"\n    # Compute standard correlation matrix\n    correlations = np.corrcoef(zactmat)\n\n    # Create mask for same-group pairs\n    groups = np.array(cross_structural)\n    same_group_mask = groups[:, np.newaxis] == groups[np.newaxis, :]\n\n    # Set within-group correlations to zero, but keep diagonal as 1\n    correlations[same_group_mask] = 0\n    np.fill_diagonal(correlations, 1)\n\n    return correlations\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.binshuffling","title":"<code>binshuffling(zactmat, significance)</code>","text":"<p>Perform bin shuffling to generate statistical threshold.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def binshuffling(zactmat: np.ndarray, significance: object) -&gt; float:\n    \"\"\"\n    Perform bin shuffling to generate statistical threshold.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    np.random.seed()\n\n    lambdamax_ = np.zeros(significance.nshu)\n    for shui in range(significance.nshu):\n        zactmat_ = np.copy(zactmat)\n        for neuroni, activity in enumerate(zactmat_):\n            randomorder = np.argsort(np.random.rand(significance.nbins))\n            zactmat_[neuroni, :] = activity[randomorder]\n        lambdamax_[shui] = getlambdacontrol(zactmat_)\n\n    lambdaMax = np.percentile(lambdamax_, significance.percentile)\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.circshuffling","title":"<code>circshuffling(zactmat, significance)</code>","text":"<p>Perform circular shuffling to generate statistical threshold.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def circshuffling(zactmat: np.ndarray, significance: object) -&gt; float:\n    \"\"\"\n    Perform circular shuffling to generate statistical threshold.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    np.random.seed()\n\n    lambdamax_ = np.zeros(significance.nshu)\n    for shui in range(significance.nshu):\n        zactmat_ = np.copy(zactmat)\n        for neuroni, activity in enumerate(zactmat_):\n            cut = int(np.random.randint(significance.nbins * 2))\n            zactmat_[neuroni, :] = np.roll(activity, cut)\n        lambdamax_[shui] = getlambdacontrol(zactmat_)\n\n    lambdaMax = np.percentile(lambdamax_, significance.percentile)\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.computeAssemblyActivity","title":"<code>computeAssemblyActivity(patterns, zactmat, zerodiag=True)</code>","text":"<p>Compute assembly activity.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>ndarray</code> <p>Co-activation patterns (assemblies, neurons).</p> required <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix (neurons, time bins).</p> required <code>zerodiag</code> <code>bool</code> <p>If True, diagonal of projection matrix is set to zero, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Assembly activity matrix (assemblies, time bins).</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def computeAssemblyActivity(\n    patterns: np.ndarray,\n    zactmat: np.ndarray,\n    zerodiag: bool = True,\n) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Compute assembly activity.\n\n    Parameters\n    ----------\n    patterns : np.ndarray\n        Co-activation patterns (assemblies, neurons).\n    zactmat : np.ndarray\n        Z-scored activity matrix (neurons, time bins).\n    zerodiag : bool, optional\n        If True, diagonal of projection matrix is set to zero, by default True.\n\n    Returns\n    -------\n    Optional[np.ndarray]\n        Assembly activity matrix (assemblies, time bins).\n    \"\"\"\n    # check if patterns is empty (no assembly detected) and return None if so\n    if len(patterns) == 0:\n        return None\n\n    # number of assemblies and time bins\n    nassemblies = len(patterns)\n    nbins = np.size(zactmat, 1)\n\n    # transpose for later matrix multiplication\n    zactmat = zactmat.T\n\n    # preallocate assembly activity matrix (nassemblies, nbins)\n    assemblyAct = np.zeros((nassemblies, nbins))\n\n    # loop over assemblies\n    for assemblyi, pattern in enumerate(patterns):\n        # compute projection matrix (neurons, neurons)\n        projMat = np.outer(pattern, pattern)\n\n        # set the diagonal to zero to not count coactivation of i and j when i=j\n        if zerodiag:\n            np.fill_diagonal(projMat, 0)\n\n        # project assembly pattern onto z-scored activity matrix\n        assemblyAct[assemblyi, :] = np.nansum(zactmat @ projMat * zactmat, axis=1)\n\n    return assemblyAct\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.extractPatterns","title":"<code>extractPatterns(actmat, significance, method, whiten='unit-variance', cross_structural=None)</code>","text":"<p>Extract co-activation patterns (assemblies).</p> <p>Parameters:</p> Name Type Description Default <code>actmat</code> <code>ndarray</code> <p>Activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <code>method</code> <code>str</code> <p>Method to extract assembly patterns (ica, pca).</p> required <code>whiten</code> <code>str</code> <p>Whitening method, by default \"unit-variance\".</p> <code>'unit-variance'</code> <code>cross_structural</code> <code>Optional[ndarray]</code> <p>Categorical vector indicating group membership for each neuron. If provided and method is 'ica', will run ICA on data with modified cross-structural correlation structure, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Co-activation patterns (assemblies).</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def extractPatterns(\n    actmat: np.ndarray,\n    significance: object,\n    method: str,\n    whiten: str = \"unit-variance\",\n    cross_structural: Optional[np.ndarray] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Extract co-activation patterns (assemblies).\n\n    Parameters\n    ----------\n    actmat : np.ndarray\n        Activity matrix.\n    significance : object\n        Object containing significance parameters.\n    method : str\n        Method to extract assembly patterns (ica, pca).\n    whiten : str, optional\n        Whitening method, by default \"unit-variance\".\n    cross_structural : Optional[np.ndarray], optional\n        Categorical vector indicating group membership for each neuron.\n        If provided and method is 'ica', will run ICA on data with modified\n        cross-structural correlation structure, by default None.\n\n    Returns\n    -------\n    np.ndarray\n        Co-activation patterns (assemblies).\n    \"\"\"\n    nassemblies = significance.nassemblies\n\n    if method == \"pca\":\n        idxs = np.argsort(-significance.explained_variance_)[0:nassemblies]\n        patterns = significance.components_[idxs, :]\n    elif method == \"ica\":\n        if cross_structural is not None:\n            # For cross-structural ICA, modify the input data to reflect the cross-structural correlation structure\n            correlations = _compute_cross_structural_correlation(\n                actmat, cross_structural\n            )\n\n            # Eigenvalue decomposition to get the cross-structural subspace\n            eigenvalues, eigenvectors = np.linalg.eigh(correlations)\n            idx = np.argsort(eigenvalues)[::-1]\n            eigenvalues = eigenvalues[idx]\n            eigenvectors = eigenvectors[:, idx]\n\n            # Use the top nassemblies components (already determined)\n            eigenvectors_sig = eigenvectors[:, :nassemblies]\n            eigenvalues_sig = eigenvalues[:nassemblies]\n\n            # Project the data onto the cross-structural subspace\n            projected_data = (\n                eigenvectors_sig * np.sqrt(np.maximum(eigenvalues_sig, 0))\n            ).T @ actmat\n\n            # Run ICA on the projected data\n            ica = FastICA(n_components=nassemblies, random_state=0, whiten=whiten)\n            ica.fit(projected_data.T)\n            # Transform ICA components back to original space\n            patterns = (\n                ica.components_\n                @ (eigenvectors_sig * np.sqrt(np.maximum(eigenvalues_sig, 0))).T\n            )\n        else:\n            # Standard ICA\n            ica = FastICA(n_components=nassemblies, random_state=0, whiten=whiten)\n            ica.fit(actmat.T)\n            patterns = ica.components_\n    else:\n        raise ValueError(\n            \"assembly extraction method \" + str(method) + \" not understood\"\n        )\n\n    if patterns is not np.nan:\n        patterns = patterns.reshape(nassemblies, -1)\n\n        # sets norm of assembly vectors to 1\n        norms = np.linalg.norm(patterns, axis=1)\n        patterns /= np.tile(norms, [np.size(patterns, 1), 1]).T\n\n    return patterns\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.getlambdacontrol","title":"<code>getlambdacontrol(zactmat_)</code>","text":"<p>Get the maximum eigenvalue from PCA.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat_</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Maximum eigenvalue.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def getlambdacontrol(zactmat_: np.ndarray) -&gt; float:\n    \"\"\"\n    Get the maximum eigenvalue from PCA.\n\n    Parameters\n    ----------\n    zactmat_ : np.ndarray\n        Z-scored activity matrix.\n\n    Returns\n    -------\n    float\n        Maximum eigenvalue.\n    \"\"\"\n    significance_ = PCA()\n    significance_.fit(zactmat_.T)\n    lambdamax_ = np.max(significance_.explained_variance_)\n\n    return lambdamax_\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.marcenkopastur","title":"<code>marcenkopastur(significance)</code>","text":"<p>Calculate statistical threshold from Marcenko-Pastur distribution.</p> <p>Parameters:</p> Name Type Description Default <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Statistical threshold.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def marcenkopastur(significance: object) -&gt; float:\n    \"\"\"\n    Calculate statistical threshold from Marcenko-Pastur distribution.\n\n    Parameters\n    ----------\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    float\n        Statistical threshold.\n    \"\"\"\n    nbins = significance.nbins\n    nneurons = significance.nneurons\n    tracywidom = significance.tracywidom\n\n    # calculates statistical threshold from Marcenko-Pastur distribution\n    q = float(nbins) / float(nneurons)  # note that silent neurons are counted too\n    lambdaMax = pow((1 + np.sqrt(1 / q)), 2)\n    lambdaMax += tracywidom * pow(nneurons, -2.0 / 3)  # Tracy-Widom correction\n\n    return lambdaMax\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.runPatterns","title":"<code>runPatterns(actmat, method='ica', nullhyp='mp', nshu=1000, percentile=99, tracywidom=False, whiten='unit-variance', nassemblies=None, cross_structural=None)</code>","text":"<p>Run pattern detection to identify cell assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>actmat</code> <code>ndarray</code> <p>Activity matrix (neurons, time bins).</p> required <code>method</code> <code>str</code> <p>Method to extract assembly patterns (ica, pca), by default \"ica\".</p> <code>'ica'</code> <code>nullhyp</code> <code>str</code> <p>Null hypothesis method (bin, circ, mp), by default \"mp\".</p> <code>'mp'</code> <code>nshu</code> <code>int</code> <p>Number of shuffling controls, by default 1000.</p> <code>1000</code> <code>percentile</code> <code>int</code> <p>Percentile for shuffling methods, by default 99.</p> <code>99</code> <code>tracywidom</code> <code>bool</code> <p>Use Tracy-Widom correction, by default False.</p> <code>False</code> <code>whiten</code> <code>str</code> <p>Whitening method, by default \"unit-variance\".</p> <code>'unit-variance'</code> <code>nassemblies</code> <code>Optional[int]</code> <p>Number of assemblies, by default None.</p> <code>None</code> <code>cross_structural</code> <code>Optional[ndarray]</code> <p>A categorical vector indicating group membership for each neuron. If provided, the function will strictly detect cross-structural assemblies (correlations within the same group will be ignored), by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Tuple[Union[ndarray, None], object, Union[ndarray, None]], None]</code> <p>Patterns, significance object, and z-scored activity matrix.</p> Notes <p>nullhyp     'bin' - bin shuffling, will shuffle time bins of each neuron independently     'circ' - circular shuffling, will shift time bins of each neuron independently     'mp' - Marcenko-Pastur distribution - analytical threshold</p> <p>cross_structural     When provided, this vector should have the same length as the number of neurons     in actmat. Each element indicates the group membership (e.g., brain region,     cell type) for the corresponding neuron. The algorithm will then only detect     assemblies that span across different groups by setting within-group     correlations to zero.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def runPatterns(\n    actmat: np.ndarray,\n    method: str = \"ica\",\n    nullhyp: str = \"mp\",\n    nshu: int = 1000,\n    percentile: int = 99,\n    tracywidom: bool = False,\n    whiten: str = \"unit-variance\",\n    nassemblies: int = None,\n    cross_structural: Optional[np.ndarray] = None,\n) -&gt; Union[Tuple[Union[np.ndarray, None], object, Union[np.ndarray, None]], None]:\n    \"\"\"\n    Run pattern detection to identify cell assemblies.\n\n    Parameters\n    ----------\n    actmat : np.ndarray\n        Activity matrix (neurons, time bins).\n    method : str, optional\n        Method to extract assembly patterns (ica, pca), by default \"ica\".\n    nullhyp : str, optional\n        Null hypothesis method (bin, circ, mp), by default \"mp\".\n    nshu : int, optional\n        Number of shuffling controls, by default 1000.\n    percentile : int, optional\n        Percentile for shuffling methods, by default 99.\n    tracywidom : bool, optional\n        Use Tracy-Widom correction, by default False.\n    whiten : str, optional\n        Whitening method, by default \"unit-variance\".\n    nassemblies : Optional[int], optional\n        Number of assemblies, by default None.\n    cross_structural : Optional[np.ndarray], optional\n        A categorical vector indicating group membership for each neuron.\n        If provided, the function will strictly detect cross-structural assemblies\n        (correlations within the same group will be ignored), by default None.\n\n    Returns\n    -------\n    Union[Tuple[Union[np.ndarray, None], object, Union[np.ndarray, None]], None]\n        Patterns, significance object, and z-scored activity matrix.\n\n    Notes\n    -----\n    nullhyp\n        'bin' - bin shuffling, will shuffle time bins of each neuron independently\n        'circ' - circular shuffling, will shift time bins of each neuron independently\n        'mp' - Marcenko-Pastur distribution - analytical threshold\n\n    cross_structural\n        When provided, this vector should have the same length as the number of neurons\n        in actmat. Each element indicates the group membership (e.g., brain region,\n        cell type) for the corresponding neuron. The algorithm will then only detect\n        assemblies that span across different groups by setting within-group\n        correlations to zero.\n    \"\"\"\n\n    nneurons = np.size(actmat, 0)\n    nbins = np.size(actmat, 1)\n\n    # Validate cross_structural parameter if provided\n    if cross_structural is not None:\n        if len(cross_structural) != nneurons:\n            raise ValueError(\n                f\"cross_structural length ({len(cross_structural)}) must match \"\n                f\"number of neurons ({nneurons})\"\n            )\n\n    silentneurons = np.var(actmat, axis=1) == 0\n    actmat_ = actmat[~silentneurons, :]\n    if actmat_.shape[0] == 0:\n        warnings.warn(\"no active neurons\")\n        return None, None, None\n\n    # Update cross_structural to match active neurons only\n    cross_structural_ = None\n    if cross_structural is not None:\n        cross_structural_ = cross_structural[~silentneurons]\n\n    # z-scoring activity matrix\n    zactmat_ = stats.zscore(actmat_, axis=1)\n\n    # running significance (estimating number of assemblies)\n    significance = PCA()\n\n    if cross_structural_ is not None:\n        # Compute custom correlation matrix for cross-structural assemblies\n        correlations = _compute_cross_structural_correlation(\n            zactmat_, cross_structural_\n        )\n        # Perform eigenvalue decomposition on the custom correlation matrix\n        eigenvalues, eigenvectors = np.linalg.eigh(correlations)\n        # Sort in descending order\n        idx = np.argsort(eigenvalues)[::-1]\n        eigenvalues = eigenvalues[idx]\n        eigenvectors = eigenvectors[:, idx]\n        # Store results in significance object to mimic PCA interface\n        significance.explained_variance_ = eigenvalues\n        significance.components_ = eigenvectors.T\n    else:\n        # Use standard PCA\n        significance.fit(zactmat_.T)\n\n    significance.nneurons = nneurons\n    significance.nbins = nbins\n    significance.nshu = nshu\n    significance.percentile = percentile\n    significance.tracywidom = tracywidom\n    significance.nullhyp = nullhyp\n    significance = runSignificance(zactmat_, significance)\n\n    if nassemblies is not None:\n        significance.nassemblies = nassemblies\n\n    if np.isnan(significance.nassemblies):\n        return None, significance, None\n\n    if significance.nassemblies &lt; 1:\n        warnings.warn(\"no assembly detected\")\n\n        patterns = None\n        zactmat = None\n    else:\n        # extracting co-activation patterns\n        patterns_ = extractPatterns(\n            zactmat_,\n            significance,\n            method,\n            whiten=whiten,\n            cross_structural=cross_structural_,\n        )\n        if patterns_ is np.nan:\n            return None\n\n        # putting eventual silent neurons back (their assembly weights are defined as zero)\n        patterns = np.zeros((np.size(patterns_, 0), nneurons))\n        patterns[:, ~silentneurons] = patterns_\n        zactmat = np.copy(actmat)\n        zactmat[~silentneurons, :] = zactmat_\n\n    return patterns, significance, zactmat\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.runSignificance","title":"<code>runSignificance(zactmat, significance)</code>","text":"<p>Run significance tests to estimate the number of assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>zactmat</code> <code>ndarray</code> <p>Z-scored activity matrix.</p> required <code>significance</code> <code>object</code> <p>Object containing significance parameters.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Updated significance object with the number of assemblies.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def runSignificance(zactmat: np.ndarray, significance: object) -&gt; object:\n    \"\"\"\n    Run significance tests to estimate the number of assemblies.\n\n    Parameters\n    ----------\n    zactmat : np.ndarray\n        Z-scored activity matrix.\n    significance : object\n        Object containing significance parameters.\n\n    Returns\n    -------\n    object\n        Updated significance object with the number of assemblies.\n    \"\"\"\n    if significance.nullhyp == \"mp\":\n        lambdaMax = marcenkopastur(significance)\n    elif significance.nullhyp == \"bin\":\n        lambdaMax = binshuffling(zactmat, significance)\n    elif significance.nullhyp == \"circ\":\n        lambdaMax = circshuffling(zactmat, significance)\n    else:\n        raise ValueError(\n            \"nyll hypothesis method \" + str(significance.nullhyp) + \" not understood\"\n        )\n\n    nassemblies = np.sum(significance.explained_variance_ &gt; lambdaMax)\n    significance.nassemblies = nassemblies\n\n    return significance\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly/#neuro_py.ensemble.assembly.toyExample","title":"<code>toyExample(assemblies, nneurons=10, nbins=1000, rate=1.0)</code>","text":"<p>Generate a toy example activity matrix with assemblies.</p> <p>Parameters:</p> Name Type Description Default <code>assemblies</code> <code>ToyAssemblies</code> <p>The toy assemblies.</p> required <code>nneurons</code> <code>int</code> <p>Number of neurons, by default 10.</p> <code>10</code> <code>nbins</code> <code>int</code> <p>Number of time bins, by default 1000.</p> <code>1000</code> <code>rate</code> <code>float</code> <p>Poisson rate, by default 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Activity matrix.</p> Source code in <code>neuro_py/ensemble/assembly.py</code> <pre><code>def toyExample(\n    assemblies: \"ToyAssemblies\",\n    nneurons: int = 10,\n    nbins: int = 1000,\n    rate: float = 1.0,\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate a toy example activity matrix with assemblies.\n\n    Parameters\n    ----------\n    assemblies : ToyAssemblies\n        The toy assemblies.\n    nneurons : int, optional\n        Number of neurons, by default 10.\n    nbins : int, optional\n        Number of time bins, by default 1000.\n    rate : float, optional\n        Poisson rate, by default 1.0.\n\n    Returns\n    -------\n    np.ndarray\n        Activity matrix.\n    \"\"\"\n    np.random.seed(42)\n\n    actmat = np.random.poisson(rate, nneurons * nbins).reshape(nneurons, nbins)\n    assemblies.actbins = [None] * len(assemblies.membership)\n    for ai, members in enumerate(assemblies.membership):\n        members = np.array(members)\n        nact = int(nbins * assemblies.actrate[ai])\n        actstrength_ = rate * assemblies.actstrength[ai]\n\n        actbins = np.argsort(np.random.rand(nbins))[0:nact]\n\n        actmat[members.reshape(-1, 1), actbins] = (\n            np.ones((len(members), nact)) + actstrength_\n        )\n\n        assemblies.actbins[ai] = np.sort(actbins)\n\n    return actmat\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/","title":"neuro_py.ensemble.assembly_reactivation","text":""},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact","title":"<code>AssemblyReact</code>","text":"<p>Class for running assembly reactivation analysis</p> <p>Core assembly methods come from assembly.py by V\u00edtor Lopes dos Santos     https://doi.org/10.1016/j.jneumeth.2013.04.010</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder</p> <code>None</code> <code>brainRegion</code> <code>str</code> <p>Brain region to restrict to. Can be multi ex. \"CA1|CA2\"</p> <code>'CA1'</code> <code>putativeCellType</code> <code>str</code> <p>Cell type to restrict to</p> <code>'Pyramidal Cell'</code> <code>weight_dt</code> <code>float</code> <p>Time resolution of the weight matrix</p> <code>0.025</code> <code>z_mat_dt</code> <code>float</code> <p>Time resolution of the z matrix</p> <code>0.002</code> <code>method</code> <code>str</code> <p>Defines how to extract assembly patterns (ica,pca).</p> <code>'ica'</code> <code>nullhyp</code> <code>str</code> <p>Defines how to generate statistical threshold for assembly detection (bin,circ,mp).</p> <code>'mp'</code> <code>nshu</code> <code>int</code> <p>Number of shuffles for bin and circ null hypothesis.</p> <code>1000</code> <code>percentile</code> <code>int</code> <p>Percentile for mp null hypothesis.</p> <code>99</code> <code>tracywidom</code> <code>bool</code> <p>If true, uses Tracy-Widom distribution for mp null hypothesis.</p> <code>False</code> <code>cross_structural</code> <code>ndarray</code> <p>A categorical vector indicating group membership for each neuron. If provided, the function will strictly detect cross-structural assemblies (correlations within the same group will be ignored). Should have the same length as the number of neurons in the spike train.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>st</code> <code>SpikeTrainArray</code> <p>Spike train</p> <code>cell_metrics</code> <code>DataFrame</code> <p>Cell metrics</p> <code>ripples</code> <code>EpochArray</code> <p>Ripples</p> <code>patterns</code> <code>ndarray</code> <p>Assembly patterns</p> <code>assembly_act</code> <code>AnalogSignalArray</code> <p>Assembly activity</p> <p>Methods:</p> Name Description <code>load_data</code> <p>Load data (st, ripples, epochs)</p> <code>restrict_to_epoch</code> <p>Restrict to a specific epoch</p> <code>get_z_mat</code> <p>Get z matrix</p> <code>get_weights</code> <p>Get assembly weights</p> <code>get_assembly_act</code> <p>Get assembly activity</p> <code>n_assemblies</code> <p>Number of detected assemblies</p> <code>isempty</code> <p>Check if empty</p> <code>copy</code> <p>Returns copy of class</p> <code>plot</code> <p>Stem plot of assembly weights</p> <code>find_members</code> <p>Find members of an assembly</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # create the object assembly_react\n&gt;&gt;&gt; assembly_react = assembly_reactivation.AssemblyReact(\n...    basepath=basepath,\n...    )\n</code></pre> <pre><code>&gt;&gt;&gt; # load need data (spikes, ripples, epochs)\n&gt;&gt;&gt; assembly_react.load_data()\n</code></pre> <pre><code>&gt;&gt;&gt; # detect assemblies\n&gt;&gt;&gt; assembly_react.get_weights()\n</code></pre> <pre><code>&gt;&gt;&gt; # visually inspect weights for each assembly\n&gt;&gt;&gt; assembly_react.plot()\n</code></pre> <pre><code>&gt;&gt;&gt; # compute time resolved signal for each assembly\n&gt;&gt;&gt; assembly_act = assembly_react.get_assembly_act()\n</code></pre> <pre><code>&gt;&gt;&gt; # locate members of assemblies\n&gt;&gt;&gt; assembly_members = assembly_react.find_members()\n</code></pre> <pre><code>&gt;&gt;&gt; # Example: Cross-structural assemblies between CA1 and CA3\n&gt;&gt;&gt; # Assuming you have neurons from both regions\n&gt;&gt;&gt; cross_groups = np.array(['CA1'] * 50 + ['CA3'] * 30)  # 50 CA1, 30 CA3 neurons\n&gt;&gt;&gt; assembly_react_cross = assembly_reactivation.AssemblyReact(\n...    basepath=basepath,\n...    cross_structural=cross_groups\n...    )\n&gt;&gt;&gt; assembly_react_cross.load_data()\n&gt;&gt;&gt; assembly_react_cross.get_weights()  # Will only detect cross-regional assemblies\n</code></pre> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>class AssemblyReact:\n    \"\"\"\n    Class for running assembly reactivation analysis\n\n    Core assembly methods come from assembly.py by V\u00edtor Lopes dos Santos\n        https://doi.org/10.1016/j.jneumeth.2013.04.010\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder\n    brainRegion : str\n        Brain region to restrict to. Can be multi ex. \"CA1|CA2\"\n    putativeCellType : str\n        Cell type to restrict to\n    weight_dt : float\n        Time resolution of the weight matrix\n    z_mat_dt : float\n        Time resolution of the z matrix\n    method : str\n        Defines how to extract assembly patterns (ica,pca).\n    nullhyp : str\n        Defines how to generate statistical threshold for assembly detection (bin,circ,mp).\n    nshu : int\n        Number of shuffles for bin and circ null hypothesis.\n    percentile : int\n        Percentile for mp null hypothesis.\n    tracywidom : bool\n        If true, uses Tracy-Widom distribution for mp null hypothesis.\n    cross_structural : np.ndarray, optional\n        A categorical vector indicating group membership for each neuron.\n        If provided, the function will strictly detect cross-structural assemblies\n        (correlations within the same group will be ignored). Should have the same\n        length as the number of neurons in the spike train.\n\n    Attributes\n    ----------\n    st : nelpy.SpikeTrainArray\n        Spike train\n    cell_metrics : pd.DataFrame\n        Cell metrics\n    ripples : nelpy.EpochArray\n        Ripples\n    patterns : np.ndarray\n        Assembly patterns\n    assembly_act : nelpy.AnalogSignalArray\n        Assembly activity\n\n    Methods\n    -------\n    load_data()\n        Load data (st, ripples, epochs)\n    restrict_to_epoch(epoch)\n        Restrict to a specific epoch\n    get_z_mat(st)\n        Get z matrix\n    get_weights(epoch=None)\n        Get assembly weights\n    get_assembly_act(epoch=None)\n        Get assembly activity\n    n_assemblies()\n        Number of detected assemblies\n    isempty()\n        Check if empty\n    copy()\n        Returns copy of class\n    plot()\n        Stem plot of assembly weights\n    find_members()\n        Find members of an assembly\n\n\n    Examples\n    --------\n    &gt;&gt;&gt; # create the object assembly_react\n    &gt;&gt;&gt; assembly_react = assembly_reactivation.AssemblyReact(\n    ...    basepath=basepath,\n    ...    )\n\n    &gt;&gt;&gt; # load need data (spikes, ripples, epochs)\n    &gt;&gt;&gt; assembly_react.load_data()\n\n    &gt;&gt;&gt; # detect assemblies\n    &gt;&gt;&gt; assembly_react.get_weights()\n\n    &gt;&gt;&gt; # visually inspect weights for each assembly\n    &gt;&gt;&gt; assembly_react.plot()\n\n    &gt;&gt;&gt; # compute time resolved signal for each assembly\n    &gt;&gt;&gt; assembly_act = assembly_react.get_assembly_act()\n\n    &gt;&gt;&gt; # locate members of assemblies\n    &gt;&gt;&gt; assembly_members = assembly_react.find_members()\n\n    &gt;&gt;&gt; # Example: Cross-structural assemblies between CA1 and CA3\n    &gt;&gt;&gt; # Assuming you have neurons from both regions\n    &gt;&gt;&gt; cross_groups = np.array(['CA1'] * 50 + ['CA3'] * 30)  # 50 CA1, 30 CA3 neurons\n    &gt;&gt;&gt; assembly_react_cross = assembly_reactivation.AssemblyReact(\n    ...    basepath=basepath,\n    ...    cross_structural=cross_groups\n    ...    )\n    &gt;&gt;&gt; assembly_react_cross.load_data()\n    &gt;&gt;&gt; assembly_react_cross.get_weights()  # Will only detect cross-regional assemblies\n\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: Union[str, None] = None,\n        brainRegion: str = \"CA1\",\n        putativeCellType: str = \"Pyramidal Cell\",\n        weight_dt: float = 0.025,\n        z_mat_dt: float = 0.002,\n        method: str = \"ica\",\n        nullhyp: str = \"mp\",\n        nshu: int = 1000,\n        percentile: int = 99,\n        tracywidom: bool = False,\n        whiten: str = \"unit-variance\",\n        cross_structural: Optional[np.ndarray] = None,\n    ):\n        self.basepath = basepath\n        self.brainRegion = brainRegion\n        self.putativeCellType = putativeCellType\n        self.weight_dt = weight_dt\n        self.z_mat_dt = z_mat_dt\n        self.method = method\n        self.nullhyp = nullhyp\n        self.nshu = nshu\n        self.percentile = percentile\n        self.tracywidom = tracywidom\n        self.whiten = whiten\n        self.cross_structural = cross_structural\n        self.type_name = self.__class__.__name__\n\n    def add_st(self, st: nel.SpikeTrainArray) -&gt; None:\n        self.st = st\n\n    def add_ripples(self, ripples: nel.EpochArray) -&gt; None:\n        self.ripples = ripples\n\n    def add_epoch_df(self, epoch_df: pd.DataFrame) -&gt; None:\n        self.epoch_df = epoch_df\n\n    def load_spikes(self) -&gt; None:\n        \"\"\"\n        loads spikes from the session folder\n        \"\"\"\n        self.st, self.cell_metrics = loading.load_spikes(\n            self.basepath,\n            brainRegion=self.brainRegion,\n            putativeCellType=self.putativeCellType,\n            support=self.time_support,\n        )\n\n    def load_ripples(self) -&gt; None:\n        \"\"\"\n        loads ripples from the session folder\n        \"\"\"\n        ripples = loading.load_ripples_events(self.basepath)\n        self.ripples = nel.EpochArray(\n            [np.array([ripples.start, ripples.stop]).T], domain=self.time_support\n        )\n\n    def load_epoch(self) -&gt; None:\n        \"\"\"\n        loads epochs from the session folder\n        \"\"\"\n        epoch_df = loading.load_epoch(self.basepath)\n        epoch_df = compress_repeated_epochs(epoch_df)\n        self.time_support = nel.EpochArray(\n            [epoch_df.iloc[0].startTime, epoch_df.iloc[-1].stopTime]\n        )\n        self.epochs = nel.EpochArray(\n            [np.array([epoch_df.startTime, epoch_df.stopTime]).T],\n            domain=self.time_support,\n        )\n        self.epoch_df = epoch_df\n\n    def load_data(self) -&gt; None:\n        \"\"\"\n        loads data (spikes,ripples,epochs) from the session folder\n        \"\"\"\n        self.load_epoch()\n        self.load_spikes()\n        self.load_ripples()\n\n    def restrict_epochs_to_pre_task_post(self) -&gt; None:\n        \"\"\"\n        Restricts the epochs to the specified epochs\n        \"\"\"\n        # fetch data\n        epoch_df = loading.load_epoch(self.basepath)\n        # compress back to back sleep epochs (an issue further up the pipeline)\n        epoch_df = compress_repeated_epochs(epoch_df)\n        # restrict to pre task post epochs\n        idx = find_pre_task_post(epoch_df.environment)\n        self.epoch_df = epoch_df[idx[0]]\n        # convert to epoch array and add to object\n        self.epochs = nel.EpochArray(\n            [np.array([self.epoch_df.startTime, self.epoch_df.stopTime]).T],\n            label=\"session_epochs\",\n            domain=self.time_support,\n        )\n\n    def restrict_to_epoch(self, epoch) -&gt; None:\n        \"\"\"\n        Restricts the spike data to a specific epoch.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray\n            The epoch to restrict to.\n        \"\"\"\n        self.st_resticted = self.st[epoch]\n\n    def get_z_mat(self, st: nel.SpikeTrainArray) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get z matrix.\n\n        Parameters\n        ----------\n        st : nel.SpikeTrainArray\n            Spike train array.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray]\n            Z-scored binned spike train and bin centers.\n        \"\"\"\n        # binning the spike train\n        z_t = st.bin(ds=self.z_mat_dt)\n        # gaussian kernel to match the bin-size used to identify the assembly patterns\n        sigma = self.weight_dt / np.sqrt(int(1000 * self.weight_dt / 2))\n        z_t.smooth(sigma=sigma, inplace=True)\n        # zscore the z matrix\n        z_scored_bst = stats.zscore(z_t.data, axis=1)\n        # make sure there are no nans, important as strengths will all be nan otherwise\n        z_scored_bst[np.isnan(z_scored_bst).any(axis=1)] = 0\n\n        return z_scored_bst, z_t.bin_centers\n\n    def get_weights(self, epoch: Optional[nel.EpochArray] = None) -&gt; None:\n        \"\"\"\n        Gets the assembly weights.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray, optional\n            The epoch to restrict to, by default None.\n        \"\"\"\n\n        # check if st has any neurons\n        if self.st.isempty:\n            self.patterns = None\n            return\n\n        if epoch is not None:\n            bst = self.st[epoch].bin(ds=self.weight_dt).data\n        else:\n            bst = self.st.bin(ds=self.weight_dt).data\n\n        if (bst == 0).all():\n            self.patterns = None\n            return\n        else:\n            patterns, _, _ = assembly.runPatterns(\n                bst,\n                method=self.method,\n                nullhyp=self.nullhyp,\n                nshu=self.nshu,\n                percentile=self.percentile,\n                tracywidom=self.tracywidom,\n                whiten=self.whiten,\n                cross_structural=self.cross_structural,\n            )\n\n            if patterns is None:\n                self.patterns = None\n                return\n\n            # flip patterns to have positive max\n            self.patterns = np.array(\n                [\n                    (\n                        patterns[i, :]\n                        if patterns[i, np.argmax(np.abs(patterns[i, :]))] &gt; 0\n                        else -patterns[i, :]\n                    )\n                    for i in range(patterns.shape[0])\n                ]\n            )\n\n    def get_assembly_act(\n        self, epoch: Optional[nel.EpochArray] = None\n    ) -&gt; nel.AnalogSignalArray:\n        \"\"\"\n        Get assembly activity.\n\n        Parameters\n        ----------\n        epoch : nel.EpochArray, optional\n            The epoch to restrict to, by default None.\n\n        Returns\n        -------\n        nel.AnalogSignalArray\n            Assembly activity.\n        \"\"\"\n        # check for num of assemblies first\n        if self.n_assemblies() == 0:\n            return nel.AnalogSignalArray(empty=True)\n\n        if epoch is not None:\n            zactmat, ts = self.get_z_mat(self.st[epoch])\n        else:\n            zactmat, ts = self.get_z_mat(self.st)\n\n        assembly_act = nel.AnalogSignalArray(\n            data=assembly.computeAssemblyActivity(self.patterns, zactmat),\n            timestamps=ts,\n            fs=1 / self.z_mat_dt,\n        )\n        return assembly_act\n\n    def plot(\n        self,\n        plot_members: bool = True,\n        central_line_color: str = \"grey\",\n        marker_color: str = \"k\",\n        member_color: Union[str, list] = \"#6768ab\",\n        line_width: float = 1.25,\n        markersize: float = 4,\n        x_padding: float = 0.2,\n        figsize: Union[tuple, None] = None,\n    ) -&gt; Union[Tuple[plt.Figure, np.ndarray], str, None]:\n        \"\"\"\n        Plots basic stem plot to display assembly weights.\n\n        Parameters\n        ----------\n        plot_members : bool, optional\n            Whether to plot assembly members, by default True.\n        central_line_color : str, optional\n            Color of the central line, by default \"grey\".\n        marker_color : str, optional\n            Color of the markers, by default \"k\".\n        member_color : Union[str, List[str]], optional\n            Color of the members, by default \"#6768ab\".\n        line_width : float, optional\n            Width of the lines, by default 1.25.\n        markersize : float, optional\n            Size of the markers, by default 4.\n        x_padding : float, optional\n            Padding on the x-axis, by default 0.2.\n        figsize : Optional[Tuple[float, float]], optional\n            Size of the figure, by default None.\n\n        Returns\n        -------\n        Union[Tuple[plt.Figure, np.ndarray], str, None]\n            The figure and axes if successful, otherwise a message or None.\n        \"\"\"\n        if not hasattr(self, \"patterns\"):\n            return \"run get_weights first\"\n        else:\n            if self.patterns is None:\n                return None, None\n            if plot_members:\n                self.find_members()\n            if figsize is None:\n                figsize = (self.n_assemblies() + 1, np.round(self.n_assemblies() / 2))\n            # set up figure with size relative to assembly matrix\n            fig, axes = plt.subplots(\n                1,\n                self.n_assemblies(),\n                figsize=figsize,\n                sharey=True,\n                sharex=True,\n            )\n            # iter over each assembly and plot the weight per cell\n            for i in range(self.n_assemblies()):\n                markerline, stemlines, baseline = axes[i].stem(\n                    self.patterns[i, :], orientation=\"horizontal\"\n                )\n                markerline._color = marker_color\n                baseline._color = central_line_color\n                baseline.zorder = -1000\n                plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                plt.setp(stemlines, linewidth=line_width)\n                plt.setp(markerline, markersize=markersize)\n\n                if plot_members:\n                    current_pattern = self.patterns[i, :].copy()\n                    current_pattern[~self.assembly_members[i, :]] = np.nan\n                    markerline, stemlines, baseline = axes[i].stem(\n                        current_pattern, orientation=\"horizontal\"\n                    )\n                    if isinstance(\n                        member_color, sns.palettes._ColorPalette\n                    ) or isinstance(member_color, list):\n                        markerline._color = member_color[i]\n                    else:\n                        markerline._color = member_color\n                    baseline._color = \"#00000000\"\n                    baseline.zorder = -1000\n                    plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                    plt.setp(stemlines, linewidth=line_width)\n                    plt.setp(markerline, markersize=markersize)\n\n                axes[i].spines[\"top\"].set_visible(False)\n                axes[i].spines[\"right\"].set_visible(False)\n\n            # give room for marker\n            axes[0].set_xlim(\n                -self.patterns.max() - x_padding, self.patterns.max() + x_padding\n            )\n\n            axes[0].set_ylabel(\"Neurons #\")\n            axes[0].set_xlabel(\"Weights (a.u.)\")\n\n            return fig, axes\n\n    def n_assemblies(self) -&gt; int:\n        \"\"\"\n        Get the number of detected assemblies.\n\n        Returns\n        -------\n        int\n            Number of detected assemblies.\n        \"\"\"\n        if hasattr(self, \"patterns\"):\n            if self.patterns is None:\n                return 0\n            return self.patterns.shape[0]\n\n    @property\n    def isempty(self) -&gt; bool:\n        \"\"\"\n        Check if the object is empty.\n\n        Returns\n        -------\n        bool\n            True if empty, False otherwise.\n        \"\"\"\n        if hasattr(self, \"st\"):\n            return False\n        elif not hasattr(self, \"st\"):\n            return True\n\n    def copy(self) -&gt; \"AssemblyReact\":\n        \"\"\"\n        Returns a copy of the current class.\n\n        Returns\n        -------\n        AssemblyReact\n            A copy of the current class.\n        \"\"\"\n        newcopy = copy.deepcopy(self)\n        return newcopy\n\n    def __repr__(self) -&gt; str:\n        if self.isempty:\n            return f\"&lt;{self.type_name}: empty&gt;\"\n\n        # if st data as been loaded and patterns have been computed\n        if hasattr(self, \"patterns\"):\n            n_units = f\"{self.st.n_active} units\"\n            n_patterns = f\"{self.n_assemblies()} assemblies\"\n            dstr = f\"of length {self.st.support.length}\"\n            return \"&lt;%s: %s, %s&gt; %s\" % (self.type_name, n_units, n_patterns, dstr)\n\n        # if st data as been loaded\n        if hasattr(self, \"st\"):\n            n_units = f\"{self.st.n_active} units\"\n            dstr = f\"of length {self.st.support.length}\"\n            return \"&lt;%s: %s&gt; %s\" % (self.type_name, n_units, dstr)\n\n    def find_members(self) -&gt; np.ndarray:\n        \"\"\"\n        Finds significant assembly patterns and significant assembly members.\n\n        Returns\n        -------\n        np.ndarray\n            A ndarray of booleans indicating whether each unit is a significant member of an assembly.\n\n        Notes\n        -----\n        also, sets self.assembly_members and self.valid_assembly\n\n        self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)\n        \"\"\"\n\n        def Otsu(vector: np.ndarray) -&gt; Tuple[np.ndarray, float, float]:\n            \"\"\"\n            The Otsu method for splitting data into two groups.\n\n            Parameters\n            ----------\n            vector : np.ndarray\n                Arbitrary vector.\n\n            Returns\n            -------\n            Tuple[np.ndarray, float, float]\n                Group, threshold used for classification, and effectiveness metric.\n            \"\"\"\n            sorted = np.sort(vector)\n            n = len(vector)\n            intraClassVariance = [np.nan] * n\n            for i in np.arange(n):\n                p = (i + 1) / n\n                p0 = 1 - p\n                if i + 1 == n:\n                    intraClassVariance[i] = np.nan\n                else:\n                    intraClassVariance[i] = p * np.var(sorted[0 : i + 1]) + p0 * np.var(\n                        sorted[i + 1 :]\n                    )\n\n            minIntraVariance = np.nanmin(intraClassVariance)\n            idx = np.nanargmin(intraClassVariance)\n            threshold = sorted[idx]\n            group = vector &gt; threshold\n\n            em = 1 - (minIntraVariance / np.var(vector))\n\n            return group, threshold, em\n\n        is_member = []\n        keep_assembly = []\n        for pat in self.patterns:\n            isMember, _, _ = Otsu(np.abs(pat))\n            is_member.append(isMember)\n\n            if np.any(pat[isMember] &lt; 0) &amp; np.any(pat[isMember] &gt; 0):\n                keep_assembly.append(False)\n            elif sum(isMember) == 0:\n                keep_assembly.append(False)\n            else:\n                keep_assembly.append(True)\n\n        self.assembly_members = np.array(is_member)\n        self.valid_assembly = np.array(keep_assembly)\n\n        return self.assembly_members\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.isempty","title":"<code>isempty</code>  <code>property</code>","text":"<p>Check if the object is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if empty, False otherwise.</p>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.copy","title":"<code>copy()</code>","text":"<p>Returns a copy of the current class.</p> <p>Returns:</p> Type Description <code>AssemblyReact</code> <p>A copy of the current class.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def copy(self) -&gt; \"AssemblyReact\":\n    \"\"\"\n    Returns a copy of the current class.\n\n    Returns\n    -------\n    AssemblyReact\n        A copy of the current class.\n    \"\"\"\n    newcopy = copy.deepcopy(self)\n    return newcopy\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.find_members","title":"<code>find_members()</code>","text":"<p>Finds significant assembly patterns and significant assembly members.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A ndarray of booleans indicating whether each unit is a significant member of an assembly.</p> Notes <p>also, sets self.assembly_members and self.valid_assembly</p> <p>self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def find_members(self) -&gt; np.ndarray:\n    \"\"\"\n    Finds significant assembly patterns and significant assembly members.\n\n    Returns\n    -------\n    np.ndarray\n        A ndarray of booleans indicating whether each unit is a significant member of an assembly.\n\n    Notes\n    -----\n    also, sets self.assembly_members and self.valid_assembly\n\n    self.valid_assembly: a ndarray of booleans indicating an assembly has members with the same sign (Boucly et al. 2022)\n    \"\"\"\n\n    def Otsu(vector: np.ndarray) -&gt; Tuple[np.ndarray, float, float]:\n        \"\"\"\n        The Otsu method for splitting data into two groups.\n\n        Parameters\n        ----------\n        vector : np.ndarray\n            Arbitrary vector.\n\n        Returns\n        -------\n        Tuple[np.ndarray, float, float]\n            Group, threshold used for classification, and effectiveness metric.\n        \"\"\"\n        sorted = np.sort(vector)\n        n = len(vector)\n        intraClassVariance = [np.nan] * n\n        for i in np.arange(n):\n            p = (i + 1) / n\n            p0 = 1 - p\n            if i + 1 == n:\n                intraClassVariance[i] = np.nan\n            else:\n                intraClassVariance[i] = p * np.var(sorted[0 : i + 1]) + p0 * np.var(\n                    sorted[i + 1 :]\n                )\n\n        minIntraVariance = np.nanmin(intraClassVariance)\n        idx = np.nanargmin(intraClassVariance)\n        threshold = sorted[idx]\n        group = vector &gt; threshold\n\n        em = 1 - (minIntraVariance / np.var(vector))\n\n        return group, threshold, em\n\n    is_member = []\n    keep_assembly = []\n    for pat in self.patterns:\n        isMember, _, _ = Otsu(np.abs(pat))\n        is_member.append(isMember)\n\n        if np.any(pat[isMember] &lt; 0) &amp; np.any(pat[isMember] &gt; 0):\n            keep_assembly.append(False)\n        elif sum(isMember) == 0:\n            keep_assembly.append(False)\n        else:\n            keep_assembly.append(True)\n\n    self.assembly_members = np.array(is_member)\n    self.valid_assembly = np.array(keep_assembly)\n\n    return self.assembly_members\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.get_assembly_act","title":"<code>get_assembly_act(epoch=None)</code>","text":"<p>Get assembly activity.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>AnalogSignalArray</code> <p>Assembly activity.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_assembly_act(\n    self, epoch: Optional[nel.EpochArray] = None\n) -&gt; nel.AnalogSignalArray:\n    \"\"\"\n    Get assembly activity.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray, optional\n        The epoch to restrict to, by default None.\n\n    Returns\n    -------\n    nel.AnalogSignalArray\n        Assembly activity.\n    \"\"\"\n    # check for num of assemblies first\n    if self.n_assemblies() == 0:\n        return nel.AnalogSignalArray(empty=True)\n\n    if epoch is not None:\n        zactmat, ts = self.get_z_mat(self.st[epoch])\n    else:\n        zactmat, ts = self.get_z_mat(self.st)\n\n    assembly_act = nel.AnalogSignalArray(\n        data=assembly.computeAssemblyActivity(self.patterns, zactmat),\n        timestamps=ts,\n        fs=1 / self.z_mat_dt,\n    )\n    return assembly_act\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.get_weights","title":"<code>get_weights(epoch=None)</code>","text":"<p>Gets the assembly weights.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to, by default None.</p> <code>None</code> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_weights(self, epoch: Optional[nel.EpochArray] = None) -&gt; None:\n    \"\"\"\n    Gets the assembly weights.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray, optional\n        The epoch to restrict to, by default None.\n    \"\"\"\n\n    # check if st has any neurons\n    if self.st.isempty:\n        self.patterns = None\n        return\n\n    if epoch is not None:\n        bst = self.st[epoch].bin(ds=self.weight_dt).data\n    else:\n        bst = self.st.bin(ds=self.weight_dt).data\n\n    if (bst == 0).all():\n        self.patterns = None\n        return\n    else:\n        patterns, _, _ = assembly.runPatterns(\n            bst,\n            method=self.method,\n            nullhyp=self.nullhyp,\n            nshu=self.nshu,\n            percentile=self.percentile,\n            tracywidom=self.tracywidom,\n            whiten=self.whiten,\n            cross_structural=self.cross_structural,\n        )\n\n        if patterns is None:\n            self.patterns = None\n            return\n\n        # flip patterns to have positive max\n        self.patterns = np.array(\n            [\n                (\n                    patterns[i, :]\n                    if patterns[i, np.argmax(np.abs(patterns[i, :]))] &gt; 0\n                    else -patterns[i, :]\n                )\n                for i in range(patterns.shape[0])\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.get_z_mat","title":"<code>get_z_mat(st)</code>","text":"<p>Get z matrix.</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>Spike train array.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Z-scored binned spike train and bin centers.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def get_z_mat(self, st: nel.SpikeTrainArray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get z matrix.\n\n    Parameters\n    ----------\n    st : nel.SpikeTrainArray\n        Spike train array.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Z-scored binned spike train and bin centers.\n    \"\"\"\n    # binning the spike train\n    z_t = st.bin(ds=self.z_mat_dt)\n    # gaussian kernel to match the bin-size used to identify the assembly patterns\n    sigma = self.weight_dt / np.sqrt(int(1000 * self.weight_dt / 2))\n    z_t.smooth(sigma=sigma, inplace=True)\n    # zscore the z matrix\n    z_scored_bst = stats.zscore(z_t.data, axis=1)\n    # make sure there are no nans, important as strengths will all be nan otherwise\n    z_scored_bst[np.isnan(z_scored_bst).any(axis=1)] = 0\n\n    return z_scored_bst, z_t.bin_centers\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.load_data","title":"<code>load_data()</code>","text":"<p>loads data (spikes,ripples,epochs) from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_data(self) -&gt; None:\n    \"\"\"\n    loads data (spikes,ripples,epochs) from the session folder\n    \"\"\"\n    self.load_epoch()\n    self.load_spikes()\n    self.load_ripples()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.load_epoch","title":"<code>load_epoch()</code>","text":"<p>loads epochs from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_epoch(self) -&gt; None:\n    \"\"\"\n    loads epochs from the session folder\n    \"\"\"\n    epoch_df = loading.load_epoch(self.basepath)\n    epoch_df = compress_repeated_epochs(epoch_df)\n    self.time_support = nel.EpochArray(\n        [epoch_df.iloc[0].startTime, epoch_df.iloc[-1].stopTime]\n    )\n    self.epochs = nel.EpochArray(\n        [np.array([epoch_df.startTime, epoch_df.stopTime]).T],\n        domain=self.time_support,\n    )\n    self.epoch_df = epoch_df\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.load_ripples","title":"<code>load_ripples()</code>","text":"<p>loads ripples from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_ripples(self) -&gt; None:\n    \"\"\"\n    loads ripples from the session folder\n    \"\"\"\n    ripples = loading.load_ripples_events(self.basepath)\n    self.ripples = nel.EpochArray(\n        [np.array([ripples.start, ripples.stop]).T], domain=self.time_support\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.load_spikes","title":"<code>load_spikes()</code>","text":"<p>loads spikes from the session folder</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def load_spikes(self) -&gt; None:\n    \"\"\"\n    loads spikes from the session folder\n    \"\"\"\n    self.st, self.cell_metrics = loading.load_spikes(\n        self.basepath,\n        brainRegion=self.brainRegion,\n        putativeCellType=self.putativeCellType,\n        support=self.time_support,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.n_assemblies","title":"<code>n_assemblies()</code>","text":"<p>Get the number of detected assemblies.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of detected assemblies.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def n_assemblies(self) -&gt; int:\n    \"\"\"\n    Get the number of detected assemblies.\n\n    Returns\n    -------\n    int\n        Number of detected assemblies.\n    \"\"\"\n    if hasattr(self, \"patterns\"):\n        if self.patterns is None:\n            return 0\n        return self.patterns.shape[0]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.plot","title":"<code>plot(plot_members=True, central_line_color='grey', marker_color='k', member_color='#6768ab', line_width=1.25, markersize=4, x_padding=0.2, figsize=None)</code>","text":"<p>Plots basic stem plot to display assembly weights.</p> <p>Parameters:</p> Name Type Description Default <code>plot_members</code> <code>bool</code> <p>Whether to plot assembly members, by default True.</p> <code>True</code> <code>central_line_color</code> <code>str</code> <p>Color of the central line, by default \"grey\".</p> <code>'grey'</code> <code>marker_color</code> <code>str</code> <p>Color of the markers, by default \"k\".</p> <code>'k'</code> <code>member_color</code> <code>Union[str, List[str]]</code> <p>Color of the members, by default \"#6768ab\".</p> <code>'#6768ab'</code> <code>line_width</code> <code>float</code> <p>Width of the lines, by default 1.25.</p> <code>1.25</code> <code>markersize</code> <code>float</code> <p>Size of the markers, by default 4.</p> <code>4</code> <code>x_padding</code> <code>float</code> <p>Padding on the x-axis, by default 0.2.</p> <code>0.2</code> <code>figsize</code> <code>Optional[Tuple[float, float]]</code> <p>Size of the figure, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Tuple[Figure, ndarray], str, None]</code> <p>The figure and axes if successful, otherwise a message or None.</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def plot(\n    self,\n    plot_members: bool = True,\n    central_line_color: str = \"grey\",\n    marker_color: str = \"k\",\n    member_color: Union[str, list] = \"#6768ab\",\n    line_width: float = 1.25,\n    markersize: float = 4,\n    x_padding: float = 0.2,\n    figsize: Union[tuple, None] = None,\n) -&gt; Union[Tuple[plt.Figure, np.ndarray], str, None]:\n    \"\"\"\n    Plots basic stem plot to display assembly weights.\n\n    Parameters\n    ----------\n    plot_members : bool, optional\n        Whether to plot assembly members, by default True.\n    central_line_color : str, optional\n        Color of the central line, by default \"grey\".\n    marker_color : str, optional\n        Color of the markers, by default \"k\".\n    member_color : Union[str, List[str]], optional\n        Color of the members, by default \"#6768ab\".\n    line_width : float, optional\n        Width of the lines, by default 1.25.\n    markersize : float, optional\n        Size of the markers, by default 4.\n    x_padding : float, optional\n        Padding on the x-axis, by default 0.2.\n    figsize : Optional[Tuple[float, float]], optional\n        Size of the figure, by default None.\n\n    Returns\n    -------\n    Union[Tuple[plt.Figure, np.ndarray], str, None]\n        The figure and axes if successful, otherwise a message or None.\n    \"\"\"\n    if not hasattr(self, \"patterns\"):\n        return \"run get_weights first\"\n    else:\n        if self.patterns is None:\n            return None, None\n        if plot_members:\n            self.find_members()\n        if figsize is None:\n            figsize = (self.n_assemblies() + 1, np.round(self.n_assemblies() / 2))\n        # set up figure with size relative to assembly matrix\n        fig, axes = plt.subplots(\n            1,\n            self.n_assemblies(),\n            figsize=figsize,\n            sharey=True,\n            sharex=True,\n        )\n        # iter over each assembly and plot the weight per cell\n        for i in range(self.n_assemblies()):\n            markerline, stemlines, baseline = axes[i].stem(\n                self.patterns[i, :], orientation=\"horizontal\"\n            )\n            markerline._color = marker_color\n            baseline._color = central_line_color\n            baseline.zorder = -1000\n            plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n            plt.setp(stemlines, linewidth=line_width)\n            plt.setp(markerline, markersize=markersize)\n\n            if plot_members:\n                current_pattern = self.patterns[i, :].copy()\n                current_pattern[~self.assembly_members[i, :]] = np.nan\n                markerline, stemlines, baseline = axes[i].stem(\n                    current_pattern, orientation=\"horizontal\"\n                )\n                if isinstance(\n                    member_color, sns.palettes._ColorPalette\n                ) or isinstance(member_color, list):\n                    markerline._color = member_color[i]\n                else:\n                    markerline._color = member_color\n                baseline._color = \"#00000000\"\n                baseline.zorder = -1000\n                plt.setp(stemlines, \"color\", plt.getp(markerline, \"color\"))\n                plt.setp(stemlines, linewidth=line_width)\n                plt.setp(markerline, markersize=markersize)\n\n            axes[i].spines[\"top\"].set_visible(False)\n            axes[i].spines[\"right\"].set_visible(False)\n\n        # give room for marker\n        axes[0].set_xlim(\n            -self.patterns.max() - x_padding, self.patterns.max() + x_padding\n        )\n\n        axes[0].set_ylabel(\"Neurons #\")\n        axes[0].set_xlabel(\"Weights (a.u.)\")\n\n        return fig, axes\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.restrict_epochs_to_pre_task_post","title":"<code>restrict_epochs_to_pre_task_post()</code>","text":"<p>Restricts the epochs to the specified epochs</p> Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def restrict_epochs_to_pre_task_post(self) -&gt; None:\n    \"\"\"\n    Restricts the epochs to the specified epochs\n    \"\"\"\n    # fetch data\n    epoch_df = loading.load_epoch(self.basepath)\n    # compress back to back sleep epochs (an issue further up the pipeline)\n    epoch_df = compress_repeated_epochs(epoch_df)\n    # restrict to pre task post epochs\n    idx = find_pre_task_post(epoch_df.environment)\n    self.epoch_df = epoch_df[idx[0]]\n    # convert to epoch array and add to object\n    self.epochs = nel.EpochArray(\n        [np.array([self.epoch_df.startTime, self.epoch_df.stopTime]).T],\n        label=\"session_epochs\",\n        domain=self.time_support,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/assembly_reactivation/#neuro_py.ensemble.assembly_reactivation.AssemblyReact.restrict_to_epoch","title":"<code>restrict_to_epoch(epoch)</code>","text":"<p>Restricts the spike data to a specific epoch.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epoch to restrict to.</p> required Source code in <code>neuro_py/ensemble/assembly_reactivation.py</code> <pre><code>def restrict_to_epoch(self, epoch) -&gt; None:\n    \"\"\"\n    Restricts the spike data to a specific epoch.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The epoch to restrict to.\n    \"\"\"\n    self.st_resticted = self.st[epoch]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/dynamics/","title":"neuro_py.ensemble.dynamics","text":""},{"location":"reference/neuro_py/ensemble/dynamics/#neuro_py.ensemble.dynamics.cosine_similarity","title":"<code>cosine_similarity(pv1, pv2)</code>","text":"<p>Cosine similarity between temporal difference vectors of two firing rate vector trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>pv1</code> <code>ndarray</code> <p>Temporal difference of firing rate vector trajectory in one context. Shape: (num_bins, num_neurons)</p> required <code>pv2</code> <code>ndarray</code> <p>Temporal difference of firing rate vector trajectory in another context. Shape: (num_bins, num_neurons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cosine similarity between the two contexts.</p> References <p>.. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A., Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J., Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional specialization manifests in the reliability of neural population codes. bioRxiv : the preprint server for biology, 2024.01.25.576941. https://doi.org/10.1101/2024.01.25.576941</p> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def cosine_similarity(pv1: np.ndarray, pv2: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Cosine similarity between temporal difference vectors of two firing rate\n    vector trajectories.\n\n    Parameters\n    ----------\n    pv1 : numpy.ndarray\n        Temporal difference of firing rate vector trajectory in one context.\n        Shape: (num_bins, num_neurons)\n\n    pv2 : numpy.ndarray\n        Temporal difference of firing rate vector trajectory in another context.\n        Shape: (num_bins, num_neurons)\n\n    Returns\n    -------\n    numpy.ndarray\n        Cosine similarity between the two contexts.\n\n    References\n    ----------\n    .. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,\n    Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,\n    Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional\n    specialization manifests in the reliability of neural population codes.\n    bioRxiv : the preprint server for biology, 2024.01.25.576941.\n    https://doi.org/10.1101/2024.01.25.576941\n    \"\"\"\n    cosine_mat = sklearn.metrics.pairwise.cosine_similarity(pv1, pv2)\n    cosine_sim = np.diag(cosine_mat)\n\n    return cosine_sim\n</code></pre>"},{"location":"reference/neuro_py/ensemble/dynamics/#neuro_py.ensemble.dynamics.potential_landscape","title":"<code>potential_landscape(X_dyn, projbins, domainbins=None)</code>","text":"<p>Compute numerical approximation of potential energy landscape across 1D state and domain (e.g. time, position, etc.).</p> <p>Potential landscape is defined as the integral of the flow vectors.</p> <p>Parameters:</p> Name Type Description Default <code>X_dyn</code> <code>ndarray</code> <p>State vectors of shape (trials, bins).</p> required <code>projbins</code> <code>int or array - like</code> <p>Number of bins for projection axis or bin edges</p> required <code>domainbins</code> <code>int or array - like</code> <p>Number of bins for domain axis or bin edges, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Potential energy landscape across state and domain</p> <code>ndarray</code> <p>Temporal gradient of potential energy landscape across state and domain</p> <code>ndarray</code> <p>Histogram of state vectors across state and domain</p> <code>ndarray</code> <p>Bin edges of state vectors</p> <code>ndarray</code> <p>Bin edges of domain</p> References <p>.. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect        decision confidence in macaque prefrontal cortex. Nat Neurosci 26,        1970\u20131980 (2023).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X_dyn = np.array([[0.1, 0.2, 0.4], [0.0, 0.3, 0.6]])\n&gt;&gt;&gt; projbins = 3\n&gt;&gt;&gt; domainbins = 3\n&gt;&gt;&gt; potential_landscape(X_dyn, projbins, domainbins)\n(array([[ 0.  ,  0.  ,   nan],\n        [-0.1 ,  0.  ,   nan],\n        [  nan,  0.  , -0.25]]),\narray([[0.3 ,  nan,  nan],\n       [0.1 ,  nan,  nan],\n       [ nan,  nan, 0.25]]),\narray([[1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 2.]]),\narray([0. , 0.1, 0.2, 0.3]),\narray([0.        , 0.33333333, 0.66666667, 1.        ]))\n</code></pre> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def potential_landscape(\n    X_dyn: np.ndarray,\n    projbins: Union[int, np.ndarray],\n    domainbins: Union[int, np.ndarray, None] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute numerical approximation of potential energy landscape across\n    1D state and domain (e.g. time, position, etc.).\n\n    Potential landscape is defined as the integral of the flow vectors.\n\n    Parameters\n    ----------\n    X_dyn : np.ndarray\n        State vectors of shape (trials, bins).\n    projbins : int or array-like\n        Number of bins for projection axis or bin edges\n    domainbins : int or array-like, optional\n        Number of bins for domain axis or bin edges, by default None\n\n    Returns\n    -------\n    np.ndarray\n        Potential energy landscape across state and domain\n    np.ndarray\n        Temporal gradient of potential energy landscape across state and domain\n    np.ndarray\n        Histogram of state vectors across state and domain\n    np.ndarray\n        Bin edges of state vectors\n    np.ndarray\n        Bin edges of domain\n\n    References\n    ----------\n    .. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect\n           decision confidence in macaque prefrontal cortex. Nat Neurosci 26,\n           1970\u20131980 (2023).\n\n    Examples\n    --------\n    &gt;&gt;&gt; X_dyn = np.array([[0.1, 0.2, 0.4], [0.0, 0.3, 0.6]])\n    &gt;&gt;&gt; projbins = 3\n    &gt;&gt;&gt; domainbins = 3\n    &gt;&gt;&gt; potential_landscape(X_dyn, projbins, domainbins)\n    (array([[ 0.  ,  0.  ,   nan],\n            [-0.1 ,  0.  ,   nan],\n            [  nan,  0.  , -0.25]]),\n    array([[0.3 ,  nan,  nan],\n           [0.1 ,  nan,  nan],\n           [ nan,  nan, 0.25]]),\n    array([[1., 0., 0.],\n           [1., 0., 0.],\n           [0., 0., 2.]]),\n    array([0. , 0.1, 0.2, 0.3]),\n    array([0.        , 0.33333333, 0.66666667, 1.        ]))\n    \"\"\"\n    # _t suffix is following notation of paper but applicable across any domain\n    nnrns = 1\n    ntrials, nbins = X_dyn.shape\n    delta_t = np.diff(X_dyn, axis=1)  # time derivatives: ntrials x nbins-1 x nnrns\n\n    X_t_flat = np.reshape(\n        X_dyn[:, :-1], (-1, nnrns), order=\"F\"\n    ).ravel()  # skip last bin as no displacement exists for last time point\n    delta_t_flat = np.reshape(\n        delta_t, (-1, nnrns), order=\"F\"\n    ).ravel()  # column-major order\n    norm_tpts = np.repeat(np.arange(nbins - 1), ntrials)\n\n    nbins_domain = (\n        nbins - 1 if domainbins is None else domainbins\n    )  # downsample domain bins\n\n    # 1D state space binning of time derivatives across domain\n    # assumes landscape may morph across domain\n    H, bin_edges, _ = binned_statistic_dd(  # posbins x time\n        np.asarray((X_t_flat, norm_tpts)).T,\n        delta_t_flat,\n        statistic=\"count\",\n        bins=(projbins, nbins_domain),\n    )\n    latentedges, domainedges = bin_edges\n\n    grad_pos_t_svm = binned_statistic_dd(\n        np.asarray((X_t_flat, norm_tpts)).T,\n        delta_t_flat,\n        statistic=\"sum\",\n        bins=(projbins, nbins_domain),\n    ).statistic\n    # average derivative, a.k.a. flow/vector field for dynamics underlying\n    # population activity\n    grad_pos_t_svm = np.divide(grad_pos_t_svm, H, where=H != 0)\n    grad_pos_t_svm[H == 0] = np.nan  # crucial to handle division by zero\n    # spatial integration via nnancumsum treats nan as zero for cumulative sum\n    potential_pos_t = -np.nancumsum(grad_pos_t_svm, axis=0)  # projbins x domainbins\n\n    idx_zero_X_t = np.searchsorted(latentedges, 0)\n    offset = potential_pos_t[idx_zero_X_t, :]  # use potential at X_t = 0 as reference\n    potential_pos_t = potential_pos_t - offset  # potential difference\n\n    nonzero_mask = H != 0\n    idx_first_nonzero, idx_last_nonzero = find_terminal_masked_indices(\n        nonzero_mask, axis=0\n    )  # each have shape: time\n    # along axis 0 set all values from start to idx_first_nonzero to nan\n    for t in range(H.shape[1]):\n        potential_pos_t[: idx_first_nonzero[t], t] = np.nan\n        potential_pos_t[idx_last_nonzero[t] + 1 :, t] = np.nan\n\n    return potential_pos_t, grad_pos_t_svm, H, latentedges, domainedges\n</code></pre>"},{"location":"reference/neuro_py/ensemble/dynamics/#neuro_py.ensemble.dynamics.potential_landscape_nd","title":"<code>potential_landscape_nd(X_dyn, projbins, domainbins=None, nanborderempty=True)</code>","text":"<p>Compute numerical approximation of potential energy landscape across n-dimensional state and domain (e.g. time, position, etc.).</p> <p>Potential landscape is defined as the integral of the flow vectors.</p> <p>Parameters:</p> Name Type Description Default <code>X_dyn</code> <code>ndarray</code> <p>State vectors of shape (trials, bins, neurons)</p> required <code>projbins</code> <code>int or array - like</code> <p>Number of bins for projection axis or bin edges for each neuron</p> required <code>domainbins</code> <code>int or array - like</code> <p>Number of bins for domain axis or bin edges, by default None</p> <code>None</code> <code>nanborderempty</code> <code>bool</code> <p>Whether to set border values to nan if they are empty, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Potential energy landscape across state averaged across domain for each neuron. Shape: nnrns x projbins times nnrns</p> <code>ndarray</code> <p>Potential energy landscape across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Temporal gradient of potential energy landscape across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Histogram of state vectors across state and domain for each neuron. Shape: projbins times nnrns x domainbins x nnrns</p> <code>ndarray</code> <p>Bin edges of state vectors for each neuron</p> <code>ndarray</code> <p>Bin edges of domain for each neuron</p> References <p>.. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect        decision confidence in macaque prefrontal cortex. Nat Neurosci 26,        1970\u20131980 (2023).</p> Source code in <code>neuro_py/ensemble/dynamics.py</code> <pre><code>def potential_landscape_nd(\n    X_dyn: np.ndarray,\n    projbins: Union[int, np.ndarray],\n    domainbins: Union[int, np.ndarray, None] = None,\n    nanborderempty: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute numerical approximation of potential energy landscape across\n    n-dimensional state and domain (e.g. time, position, etc.).\n\n    Potential landscape is defined as the integral of the flow vectors.\n\n    Parameters\n    ----------\n    X_dyn : np.ndarray\n        State vectors of shape (trials, bins, neurons)\n    projbins : int or array-like\n        Number of bins for projection axis or bin edges for each neuron\n    domainbins : int or array-like, optional\n        Number of bins for domain axis or bin edges, by default None\n    nanborderempty : bool, optional\n        Whether to set border values to nan if they are empty, by default True\n\n    Returns\n    -------\n    np.ndarray\n        Potential energy landscape across state averaged across domain for each\n        neuron. Shape: nnrns x projbins times nnrns\n    np.ndarray\n        Potential energy landscape across state and domain for each neuron.\n        Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Temporal gradient of potential energy landscape across state and domain\n        for each neuron. Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Histogram of state vectors across state and domain for each neuron.\n        Shape: projbins times nnrns x domainbins x nnrns\n    np.ndarray\n        Bin edges of state vectors for each neuron\n    np.ndarray\n        Bin edges of domain for each neuron\n\n    References\n    ----------\n    .. [1] Wang, S., Falcone, R., Richmond, B. et al. Attractor dynamics reflect\n           decision confidence in macaque prefrontal cortex. Nat Neurosci 26,\n           1970\u20131980 (2023).\n    \"\"\"\n    # _t suffix is following notation of paper but applicable across any domain\n    ntrials, nbins, nnrns = X_dyn.shape\n    delta_t = np.diff(\n        X_dyn, axis=1\n    )  # time derivatives: ntrials x ndomainbins-1 x nnrns\n\n    X_t_flat = np.reshape(\n        X_dyn[:, :-1], (-1, nnrns), order=\"F\"\n    )  # skip last bin as no displacement exists for last time point\n    delta_t_flat = np.reshape(delta_t, (-1, nnrns), order=\"F\")  # column-major order\n    norm_tpts = np.repeat(np.arange(nbins - 1), ntrials)\n\n    nbins_domain = (\n        nbins - 1 if domainbins is None else domainbins\n    )  # downsample domain bins\n\n    potential_pos_t_nrns = []\n    grad_pos_t_svm_nrns = []\n    hist_nrns = []\n    latentedges_nrns = []\n    domainedges_nrns = []\n    for nnrn in range(nnrns):\n        # 1D state space binning of time derivatives across domain\n        # assumes landscape may morph across domain\n        H, bin_edges, _ = binned_statistic_dd(  # (nnrns times projbins) x time\n            np.asarray((*X_t_flat.T, norm_tpts)).T,\n            delta_t_flat[:, nnrn],\n            statistic=\"count\",\n            bins=(\n                *[\n                    projbins if isinstance(projbins, int) else projbins[idx]\n                    for idx in range(nnrns)\n                ],\n                nbins_domain,\n            ),\n        )\n        latentedges = bin_edges[nnrn]\n        domainedges = bin_edges[-1]\n\n        grad_pos_t_svm = binned_statistic_dd(\n            np.asarray((*X_t_flat.T, norm_tpts)).T,\n            delta_t_flat[:, nnrn],\n            statistic=\"sum\",\n            bins=(\n                *[\n                    projbins if isinstance(projbins, int) else projbins[idx]\n                    for idx in range(nnrns)\n                ],\n                nbins_domain,\n            ),\n        ).statistic\n        # average derivative, a.k.a. flow/vector field for dynamics underlying\n        # population activity\n        grad_pos_t_svm = np.divide(grad_pos_t_svm, H, where=H != 0)\n        grad_pos_t_svm[H == 0] = np.nan  # crucial to handle division by zero\n        # spatial integration via nnancumsum treats nan as zero for cumulative sum\n        potential_pos_t = -np.nancumsum(\n            grad_pos_t_svm, axis=nnrn\n        )  # (nnrns times projbins) x domainbins\n\n        if nanborderempty:\n            nonzero_mask = H != 0\n\n            for t in range(nbins_domain):\n                nrndimslices = [slice(None)] * nnrns\n                nrndimslices.append(t)\n                peripheral_zeros_nanmask = ~np.isnan(\n                    replace_border_zeros_with_nan(nonzero_mask[tuple(nrndimslices)])\n                )\n                peripheral_zeros_nanmask = np.where(\n                    peripheral_zeros_nanmask, peripheral_zeros_nanmask, np.nan\n                )\n                potential_pos_t[tuple(nrndimslices)] *= peripheral_zeros_nanmask\n\n        potential_pos_t_nrns.append(potential_pos_t)\n        grad_pos_t_svm_nrns.append(grad_pos_t_svm)\n        hist_nrns.append(H)\n        latentedges_nrns.append(latentedges)\n        domainedges_nrns.append(domainedges)\n\n    potential_pos_t_nrns = np.stack(\n        potential_pos_t_nrns, axis=-1\n    )  # projbins x domainbins x nnrns\n    grad_pos_t_svm_nrns = np.stack(\n        grad_pos_t_svm_nrns, axis=-1\n    )  # projbins x domainbins x nnrns\n    hist = np.stack(hist_nrns, axis=-1)  # projbins x domainbins x nnrns\n    latentedges_nrns = np.stack(latentedges_nrns, axis=-1)  # projbins x nnrns\n    domainedges_nrns = np.stack(domainedges_nrns, axis=-1)  # domainbins x nnrns\n    nrndimslices = [slice(None)] * (nnrns + 1)\n    nrndimslices.append(0)\n    potential_nrns_pos = []\n    for nrn in range(nnrns):\n        nrndimslices[-1] = nrn\n        potential_nrns_pos.append(\n            np.nanmean(\n                potential_pos_t_nrns[tuple(nrndimslices)], axis=-1\n            )  # average across domainbins\n        )\n    potential_nrns_pos = np.asarray(potential_nrns_pos)  # nnrns x nnrns times projbins\n\n    return (\n        potential_nrns_pos,\n        potential_pos_t_nrns,\n        grad_pos_t_svm_nrns,\n        hist,\n        latentedges_nrns,\n        domainedges_nrns,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/","title":"neuro_py.ensemble.explained_variance","text":""},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance","title":"<code>ExplainedVariance</code>","text":"<p>               Bases: <code>object</code></p> <p>Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.</p> References <p>1) Kudrimoti, H. S., Barnes, C. A., &amp; McNaughton, B. L. (1999).     Reactivation of Hippocampal Cell Assemblies: Effects of Behavioral State, Experience, and EEG Dynamics.     Journal of Neuroscience, 19(10), 4090-4101. https://doi.org/10/4090 2) Tatsuno, M., Lipa, P., &amp; McNaughton, B. L. (2006).     Methodological Considerations on the Use of Template Matching to Study Long-Lasting Memory Trace Replay.     Journal of Neuroscience, 26(42), 10727-10742. https://doi.org/10.1523/JNEUROSCI.3317-06.2006</p> <p>Adapted from https://github.com/diba-lab/NeuroPy/blob/main/neuropy/analyses/reactivation.py</p> <p>Attributes:</p> Name Type Description <code>st</code> <code>SpikeTrainArray</code> <p>obj that holds spiketrains</p> <code>template</code> <code>EpochArray</code> <p>time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)</p> <code>matching</code> <code>EpochArray</code> <p>time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)</p> <code>control</code> <code>EpochArray</code> <p>time in seconds, control for pairwise correlations within this period (pre-task period)</p> <code>bin_size</code> <code>float</code> <p>in seconds, binning size for spike counts</p> <code>window</code> <code>int</code> <p>window over which pairwise correlations will be calculated in matching and control time periods,     if window is None entire time period is considered, in seconds</p> <code>slideby</code> <code>int</code> <p>slide window by this much, in seconds</p> <code>matching_windows</code> <code>array</code> <p>windows for matching period</p> <code>control_windows</code> <code>array</code> <p>windows for control period</p> <code>template_corr</code> <code>array</code> <p>pairwise correlations for template period</p> <code>matching_paircorr</code> <code>array</code> <p>pairwise correlations for matching period</p> <code>control_paircorr</code> <code>array</code> <p>pairwise correlations for control period</p> <code>ev</code> <code>array</code> <p>explained variance for each time point</p> <code>rev</code> <code>array</code> <p>reverse explained variance for each time point</p> <code>ev_std</code> <code>array</code> <p>explained variance standard deviation for each time point</p> <code>rev_std</code> <code>array</code> <p>reverse explained variance standard deviation for each time point</p> <code>partial_corr</code> <code>array</code> <p>partial correlations for each time point</p> <code>rev_partial_corr</code> <code>array</code> <p>reverse partial correlations for each time point</p> <code>n_pairs</code> <code>int</code> <p>number of pairs</p> <code>matching_time</code> <code>array</code> <p>time points for matching period</p> <code>control_time</code> <code>array</code> <p>time points for control period</p> <code>ev_signal</code> <code>AnalogSignalArray</code> <p>explained variance signal</p> <code>rev_signal</code> <code>AnalogSignalArray</code> <p>reverse explained variance signal</p> <code>plot</code> <code>function</code> <p>plot explained variance</p> <code>pvalue</code> <code>function</code> <p>calculate p-value for explained variance by shuffling the template correlations</p> <p>Examples:</p>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance--load-data","title":"Load data","text":"<pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\HMC\\HMC1\\day8\"\n&gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"CA1\",putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance--most-simple-case-returns-single-explained-variance-value","title":"Most simple case, returns single explained variance value","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=beh_epochs[2],\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=None,\n&gt;&gt;&gt;    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance--get-time-resolved-explained-variance-across-entire-session-in-200sec-bins","title":"Get time resolved explained variance across entire session in 200sec bins","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=200\n&gt;&gt;&gt;    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance--get-time-resolved-explained-variance-across-entire-session-in-200sec-bins-sliding-by-100sec","title":"Get time resolved explained variance across entire session in 200sec bins sliding by 100sec","text":"<pre><code>&gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n&gt;&gt;&gt;        st=st,\n&gt;&gt;&gt;        template=beh_epochs[1],\n&gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n&gt;&gt;&gt;        control=beh_epochs[0],\n&gt;&gt;&gt;        window=200,\n&gt;&gt;&gt;        slideby=100\n&gt;&gt;&gt;    )\n</code></pre> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>class ExplainedVariance(object):\n    \"\"\"Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.\n\n    References\n    -------\n    1) Kudrimoti, H. S., Barnes, C. A., &amp; McNaughton, B. L. (1999).\n        Reactivation of Hippocampal Cell Assemblies: Effects of Behavioral State, Experience, and EEG Dynamics.\n        Journal of Neuroscience, 19(10), 4090-4101. https://doi.org/10/4090\n    2) Tatsuno, M., Lipa, P., &amp; McNaughton, B. L. (2006).\n        Methodological Considerations on the Use of Template Matching to Study Long-Lasting Memory Trace Replay.\n        Journal of Neuroscience, 26(42), 10727-10742. https://doi.org/10.1523/JNEUROSCI.3317-06.2006\n\n    Adapted from https://github.com/diba-lab/NeuroPy/blob/main/neuropy/analyses/reactivation.py\n\n    Attributes\n    ----------\n    st : SpikeTrainArray\n        obj that holds spiketrains\n    template : EpochArray\n        time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)\n    matching : EpochArray\n        time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)\n    control : EpochArray\n        time in seconds, control for pairwise correlations within this period (pre-task period)\n    bin_size : float\n        in seconds, binning size for spike counts\n    window : int\n        window over which pairwise correlations will be calculated in matching and control time periods,\n            if window is None entire time period is considered, in seconds\n    slideby : int\n        slide window by this much, in seconds\n    matching_windows : array\n        windows for matching period\n    control_windows : array\n        windows for control period\n    template_corr : array\n        pairwise correlations for template period\n    matching_paircorr : array\n        pairwise correlations for matching period\n    control_paircorr : array\n        pairwise correlations for control period\n    ev : array\n        explained variance for each time point\n    rev : array\n        reverse explained variance for each time point\n    ev_std : array\n        explained variance standard deviation for each time point\n    rev_std : array\n        reverse explained variance standard deviation for each time point\n    partial_corr : array\n        partial correlations for each time point\n    rev_partial_corr : array\n        reverse partial correlations for each time point\n    n_pairs : int\n        number of pairs\n    matching_time : array\n        time points for matching period\n    control_time : array\n        time points for control period\n    ev_signal : AnalogSignalArray\n        explained variance signal\n    rev_signal : AnalogSignalArray\n        reverse explained variance signal\n    plot : function\n        plot explained variance\n    pvalue : function\n        calculate p-value for explained variance by shuffling the template correlations\n\n    Examples\n    --------\n    # Load data\n    &gt;&gt;&gt; basepath = r\"U:\\data\\HMC\\HMC1\\day8\"\n    &gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"CA1\",putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\n\n    # Most simple case, returns single explained variance value\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=beh_epochs[2],\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=None,\n    &gt;&gt;&gt;    )\n\n    # Get time resolved explained variance across entire session in 200sec bins\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=200\n    &gt;&gt;&gt;    )\n\n    # Get time resolved explained variance across entire session in 200sec bins sliding by 100sec\n    &gt;&gt;&gt; expvar = explained_variance.ExplainedVariance(\n    &gt;&gt;&gt;        st=st,\n    &gt;&gt;&gt;        template=beh_epochs[1],\n    &gt;&gt;&gt;        matching=nel.EpochArray([beh_epochs.start, beh_epochs.stop]),\n    &gt;&gt;&gt;        control=beh_epochs[0],\n    &gt;&gt;&gt;        window=200,\n    &gt;&gt;&gt;        slideby=100\n    &gt;&gt;&gt;    )\n    \"\"\"\n\n    def __init__(\n        self,\n        st: SpikeTrainArray,\n        template: EpochArray,\n        matching: EpochArray,\n        control: EpochArray,\n        bin_size: float = 0.2,\n        window: int = 900,\n        slideby: int = None,\n    ):\n        \"\"\"Explained variance measure for assessing reactivation of neuronal activity using pairwise correlations.\n\n        Parameters\n        ----------\n        st : SpikeTrainArray\n            obj that holds spiketrains\n        template : EpochArray\n            time in seconds, pairwise correlation calculated from this period will be compared to matching period (task-period)\n        matching : EpochArray\n            time in seconds, template-correlations will be correlated with pariwise correlations of this period (post-task period)\n        control : EpochArray\n            time in seconds, control for pairwise correlations within this period (pre-task period)\n        bin_size : float, optional\n            in seconds, binning size for spike counts, by default 0.2\n        window : int, optional\n            window over which pairwise correlations will be calculated in matching and control time periods,\n                if window is None entire time period is considered, in seconds, by default 900\n        slideby : int, optional\n            slide window by this much, in seconds, by default None\n        \"\"\"\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n\n        self.__validate_input()\n        self.__calculate()\n\n    def __validate_input(self):\n        \"\"\"Validate input parameters.\"\"\"\n        assert isinstance(self.st, SpikeTrainArray)\n        assert isinstance(self.template, EpochArray)\n        assert isinstance(self.matching, EpochArray)\n        assert isinstance(self.control, EpochArray)\n        assert isinstance(self.bin_size, (float, int))\n        assert isinstance(self.window, (int, type(None)))\n        assert isinstance(self.slideby, (int, type(None)))\n\n    def __calculate(self):\n        \"\"\"processing steps for explained variance calculation.\"\"\"\n        control_window_size, matching_window_size, slideby = self.__get_window_sizes()\n\n        self.matching_windows = self.__get_windows_array(\n            self.matching, matching_window_size, slideby\n        )\n        self.control_windows = self.__get_windows_array(\n            self.control, control_window_size, slideby\n        )\n        self.__validate_window_sizes(control_window_size, matching_window_size)\n        self.template_corr = self.__get_template_corr()\n        self.__calculate_pairwise_correlations()\n        self.__calculate_partial_correlations()\n\n    def __get_window_sizes(self):\n        \"\"\"Get window sizes for control and matching periods.\"\"\"\n        if self.window is None:\n            control_window_size = np.array(self.control.duration).astype(int)\n            matching_window_size = np.array(self.matching.duration).astype(int)\n            slideby = None\n        elif self.slideby is None:\n            control_window_size = self.window\n            matching_window_size = self.window\n            slideby = None\n        else:\n            control_window_size = self.window\n            matching_window_size = self.window\n            slideby = self.slideby\n        return control_window_size, matching_window_size, slideby\n\n    def __get_windows_array(self, epoch_array, window_size, slideby):\n        \"\"\"Get windows array for control and matching periods.\"\"\"\n        if slideby is not None:\n            array = np.arange(epoch_array.start, epoch_array.stop)\n            windows = np.lib.stride_tricks.sliding_window_view(array, window_size)\n            windows = windows[::slideby, [0, -1]]\n        elif np.array(epoch_array.duration) == window_size:\n            windows = np.array([[epoch_array.start, epoch_array.stop]])\n        else:\n            array = np.arange(epoch_array.start, epoch_array.stop, window_size)\n            windows = np.array([array[:-1], array[1:]]).T\n        return windows\n\n    def __validate_window_sizes(self, control_window_size, matching_window_size):\n        \"\"\"Validate window sizes.\"\"\"\n        assert (\n            control_window_size &lt;= self.control.duration\n        ), \"window is bigger than control\"\n        assert (\n            matching_window_size &lt;= self.matching.duration\n        ), \"window is bigger than matching\"\n\n    def __get_template_corr(self):\n        \"\"\"Get pairwise correlations for template period.\"\"\"\n        self.bst = self.st.bin(ds=self.bin_size)\n        return self.__get_pairwise_corr(self.bst[self.template].data)\n\n    def __calculate_pairwise_correlations(self):\n        \"\"\"Calculate pairwise correlations for matching and control periods.\"\"\"\n        self.matching_paircorr = self.__time_resolved_correlation(self.matching_windows)\n        self.control_paircorr = self.__time_resolved_correlation(self.control_windows)\n\n    @staticmethod\n    def __get_pairwise_corr(bst_data):\n        \"\"\"Calculate pairwise correlations.\"\"\"\n        corr = np.corrcoef(bst_data)\n        return corr[np.tril_indices(corr.shape[0], k=-1)]\n\n    def __time_resolved_correlation(self, windows):\n        \"\"\"Calculate pairwise correlations for given windows.\"\"\"\n        paircorr = []\n        bst_data = self.bst.data\n        bin_centers = self.bst.bin_centers\n\n        for w in windows:\n            start, stop = w\n            idx = (bin_centers &gt; start) &amp; (bin_centers &lt; stop)\n            corr = np.corrcoef(bst_data[:, idx])\n            paircorr.append(corr[np.tril_indices(corr.shape[0], k=-1)])\n\n        return np.array(paircorr)\n\n    def __calculate_partial_correlations(self):\n        \"\"\"Calculate partial correlations.\"\"\"\n        partial_corr, rev_partial_corr = self.__calculate_partial_correlations_(\n            self.matching_paircorr, self.control_paircorr, self.template_corr\n        )\n        self.__calculate_statistics(partial_corr, rev_partial_corr)\n\n    @staticmethod\n    @jit(nopython=True)\n    def __calculate_partial_correlations_(\n        matching_paircorr, control_paircorr, template_corr\n    ):\n        \"\"\"Calculate partial correlations.\"\"\"\n\n        def __explained_variance(x, y, covar):\n            \"\"\"Calculate explained variance and reverse explained variance.\"\"\"\n\n            # Calculate covariance matrix\n            n = len(covar)\n            valid = np.zeros(n, dtype=np.bool_)\n            for i in range(n):\n                valid[i] = not (np.isnan(covar[i]) or np.isnan(x[i]) or np.isnan(y[i]))\n            mat = np.empty((3, len(x)))\n            mat[0] = covar\n            mat[1] = x\n            mat[2] = y\n            cov = np.corrcoef(mat[:, valid])\n\n            # Calculate explained variance\n            EV = (cov[1, 2] - cov[0, 1] * cov[0, 2]) / (\n                np.sqrt((1 - cov[0, 1] ** 2) * (1 - cov[0, 2] ** 2)) + 1e-10\n            )\n\n            # Calculate reverse explained variance\n            rEV = (cov[0, 1] - cov[1, 2] * cov[0, 2]) / (\n                np.sqrt((1 - cov[1, 2] ** 2) * (1 - cov[0, 2] ** 2)) + 1e-10\n            )\n\n            return EV, rEV\n\n        n_matching = len(matching_paircorr)\n        n_control = len(control_paircorr)\n        partial_corr = np.zeros((n_control, n_matching))\n        rev_partial_corr = np.zeros((n_control, n_matching))\n\n        for m_i, m_pairs in enumerate(matching_paircorr):\n            for c_i, c_pairs in enumerate(control_paircorr):\n                partial_corr[c_i, m_i], rev_partial_corr[c_i, m_i] = (\n                    __explained_variance(template_corr, m_pairs, c_pairs)\n                )\n        return partial_corr, rev_partial_corr\n\n    def __calculate_statistics(self, partial_corr, rev_partial_corr):\n        \"\"\"Calculate explained variance statistics.\"\"\"\n        self.ev = np.nanmean(partial_corr**2, axis=0)\n        self.rev = np.nanmean(rev_partial_corr**2, axis=0)\n        self.ev_std = np.nanstd(partial_corr**2, axis=0)\n        self.rev_std = np.nanstd(rev_partial_corr**2, axis=0)\n        self.partial_corr = partial_corr**2\n        self.rev_partial_corr = rev_partial_corr**2\n        self.n_pairs = len(self.template_corr)\n        self.matching_time = np.mean(self.matching_windows, axis=1)\n        self.control_time = np.mean(self.control_windows, axis=1)\n\n    @property\n    def ev_signal(self):\n        \"\"\"Return explained variance signal.\"\"\"\n        return AnalogSignalArray(\n            data=self.ev,\n            timestamps=self.matching_time,\n            fs=1 / np.diff(self.matching_time)[0],\n            support=EpochArray(data=[self.matching.start, self.matching.stop]),\n        )\n\n    @property\n    def rev_signal(self):\n        \"\"\"Return reverse explained variance signal.\"\"\"\n        return AnalogSignalArray(\n            data=self.rev,\n            timestamps=self.matching_time,\n            fs=1 / np.diff(self.matching_time)[0],\n            support=EpochArray(data=[self.matching.start, self.matching.stop]),\n        )\n\n    def pvalue(self, n_shuffles=1000):\n        \"\"\"\n        Calculate p-value for explained variance by shuffling the template correlations.\n        \"\"\"\n        from copy import deepcopy\n\n        def shuffle_template(self):\n            template_corr = deepcopy(self.template_corr)\n            np.random.shuffle(template_corr)\n\n            partial_corr, _ = self.__calculate_partial_correlations_(\n                self.matching_paircorr, self.control_paircorr, template_corr\n            )\n            ev = np.nanmean(partial_corr**2, axis=0)\n            return ev.flatten()\n\n        if len(self.ev) &gt; 1:\n            print(\"Multiple time points, p-values are not supported\")\n            return\n\n        ev_shuffle = [shuffle_template(self) for _ in range(n_shuffles)]\n\n        ev_shuffle = np.array(ev_shuffle)\n\n        n = len(ev_shuffle)\n        r = np.sum(ev_shuffle &gt; self.ev)\n        pvalues = (r + 1) / (n + 1)\n        return pvalues\n\n    def plot(self):\n        \"\"\"Plot explained variance.\"\"\"\n        if self.matching_time.size == 1:\n            print(\"Only single time point, cannot plot\")\n            return\n        import matplotlib.pyplot as plt\n\n        fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n        ax.plot(self.matching_time, self.ev, label=\"EV\")\n        ax.fill_between(\n            self.matching_time,\n            self.ev - self.ev_std,\n            self.ev + self.ev_std,\n            alpha=0.5,\n        )\n        ax.plot(self.matching_time, self.rev, label=\"rEV\", color=\"grey\")\n        ax.fill_between(\n            self.matching_time,\n            self.rev - self.rev_std,\n            self.rev + self.rev_std,\n            alpha=0.5,\n            color=\"grey\",\n        )\n        # check if matching time overlaps with control time and plot control time\n        if np.any(\n            (self.control_time &gt;= self.matching_time[0])\n            &amp; (self.control_time &lt;= self.matching_time[-1])\n        ):\n            ax.axvspan(\n                self.control.start,\n                self.control.stop,\n                color=\"green\",\n                alpha=0.3,\n                label=\"Control\",\n                zorder=-10,\n            )\n        # check if matching time overlaps with template time and plot template time\n        if np.any(\n            (self.template.start &gt;= self.matching_time[0])\n            &amp; (self.template.stop &lt;= self.matching_time[-1])\n        ):\n            ax.axvspan(\n                self.template.start,\n                self.template.stop,\n                color=\"purple\",\n                alpha=0.4,\n                label=\"Template\",\n                zorder=-10,\n            )\n        # remove axis spines\n        ax.spines[\"right\"].set_visible(False)\n        ax.spines[\"top\"].set_visible(False)\n\n        ax.legend(frameon=False)\n        ax.set_xlabel(\"Time (s)\")\n        ax.set_ylabel(\"Explained Variance\")\n        ax.set_title(\"Explained Variance\")\n        plt.show()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance.ev_signal","title":"<code>ev_signal</code>  <code>property</code>","text":"<p>Return explained variance signal.</p>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance.rev_signal","title":"<code>rev_signal</code>  <code>property</code>","text":"<p>Return reverse explained variance signal.</p>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance.plot","title":"<code>plot()</code>","text":"<p>Plot explained variance.</p> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>def plot(self):\n    \"\"\"Plot explained variance.\"\"\"\n    if self.matching_time.size == 1:\n        print(\"Only single time point, cannot plot\")\n        return\n    import matplotlib.pyplot as plt\n\n    fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n    ax.plot(self.matching_time, self.ev, label=\"EV\")\n    ax.fill_between(\n        self.matching_time,\n        self.ev - self.ev_std,\n        self.ev + self.ev_std,\n        alpha=0.5,\n    )\n    ax.plot(self.matching_time, self.rev, label=\"rEV\", color=\"grey\")\n    ax.fill_between(\n        self.matching_time,\n        self.rev - self.rev_std,\n        self.rev + self.rev_std,\n        alpha=0.5,\n        color=\"grey\",\n    )\n    # check if matching time overlaps with control time and plot control time\n    if np.any(\n        (self.control_time &gt;= self.matching_time[0])\n        &amp; (self.control_time &lt;= self.matching_time[-1])\n    ):\n        ax.axvspan(\n            self.control.start,\n            self.control.stop,\n            color=\"green\",\n            alpha=0.3,\n            label=\"Control\",\n            zorder=-10,\n        )\n    # check if matching time overlaps with template time and plot template time\n    if np.any(\n        (self.template.start &gt;= self.matching_time[0])\n        &amp; (self.template.stop &lt;= self.matching_time[-1])\n    ):\n        ax.axvspan(\n            self.template.start,\n            self.template.stop,\n            color=\"purple\",\n            alpha=0.4,\n            label=\"Template\",\n            zorder=-10,\n        )\n    # remove axis spines\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"top\"].set_visible(False)\n\n    ax.legend(frameon=False)\n    ax.set_xlabel(\"Time (s)\")\n    ax.set_ylabel(\"Explained Variance\")\n    ax.set_title(\"Explained Variance\")\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.ExplainedVariance.pvalue","title":"<code>pvalue(n_shuffles=1000)</code>","text":"<p>Calculate p-value for explained variance by shuffling the template correlations.</p> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>def pvalue(self, n_shuffles=1000):\n    \"\"\"\n    Calculate p-value for explained variance by shuffling the template correlations.\n    \"\"\"\n    from copy import deepcopy\n\n    def shuffle_template(self):\n        template_corr = deepcopy(self.template_corr)\n        np.random.shuffle(template_corr)\n\n        partial_corr, _ = self.__calculate_partial_correlations_(\n            self.matching_paircorr, self.control_paircorr, template_corr\n        )\n        ev = np.nanmean(partial_corr**2, axis=0)\n        return ev.flatten()\n\n    if len(self.ev) &gt; 1:\n        print(\"Multiple time points, p-values are not supported\")\n        return\n\n    ev_shuffle = [shuffle_template(self) for _ in range(n_shuffles)]\n\n    ev_shuffle = np.array(ev_shuffle)\n\n    n = len(ev_shuffle)\n    r = np.sum(ev_shuffle &gt; self.ev)\n    pvalues = (r + 1) / (n + 1)\n    return pvalues\n</code></pre>"},{"location":"reference/neuro_py/ensemble/explained_variance/#neuro_py.ensemble.explained_variance.explained_variance","title":"<code>explained_variance(task, post_task, pre_task)</code>","text":"<p>Simplified version of explained variance and reverse explained variance</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape(n_features, n_timepoints)</p> required <code>post_task</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape(n_features, n_timepoints)</p> required <code>pre_task</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape(n_features, n_timepoints)</p> required <p>Returns:</p> Name Type Description <code>EV</code> <code>float</code> <p>explained variance</p> <code>rEV</code> <code>float</code> <p>reverse explained variance</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from neuro_py.ensemble import explained_variance\n&gt;&gt;&gt; # build correlated task/post epochs and a weaker pre epoch\n&gt;&gt;&gt; rng = np.random.default_rng(0)\n&gt;&gt;&gt; n_features, n_time = 10, 300\n&gt;&gt;&gt; rho_task, rho_pre = 0.5, 0.1\n&gt;&gt;&gt; cov_task = np.full((n_features, n_features), rho_task); np.fill_diagonal(cov_task, 1.0)\n&gt;&gt;&gt; cov_pre = np.full((n_features, n_features), rho_pre); np.fill_diagonal(cov_pre, 1.0)\n&gt;&gt;&gt; task = rng.multivariate_normal(np.zeros(n_features), cov_task, size=n_time).T\n&gt;&gt;&gt; post = rng.multivariate_normal(np.zeros(n_features), cov_task, size=n_time).T\n&gt;&gt;&gt; pre = rng.multivariate_normal(np.zeros(n_features), cov_pre, size=n_time).T\n&gt;&gt;&gt; EV, rEV = explained_variance.explained_variance(task, post, pre)\n&gt;&gt;&gt; EV &gt; rEV\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; import neuro_py as npy\n&gt;&gt;&gt; import nelpy as nel\n&gt;&gt;&gt; from neuro_py.ensemble import explained_variance\n&gt;&gt;&gt; basepath = r\"S:\\data\\HMC\\HMC1\\day8\"\n&gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n&gt;&gt;&gt; epoch_df = npy.io.load_epoch(basepath)\n&gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n&gt;&gt;&gt; state_dict = npy.io.load_SleepState_states(basepath)\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n...    state_dict[\"NREMstate\"],\n... )\n&gt;&gt;&gt; theta_cycles = npy.io.load_theta_cycles(basepath, return_epoch_array=True)\n&gt;&gt;&gt; theta_cycles = theta_cycles[beh_epochs[1]]  # only during behavior\n&gt;&gt;&gt; # bin spike trains into each theta cycle\n&gt;&gt;&gt; bst_task = npy.process.count_in_interval(\n...     st.data, theta_cycles.starts, theta_cycles.stops\n... )\n&gt;&gt;&gt; # bin spike trains into 50ms bins during pre sleep\n&gt;&gt;&gt; bst_pre = st[beh_epochs[0] &amp; nrem_epochs].bin(ds=0.05).data\n&gt;&gt;&gt; # bin spike trains into 50ms bins during post sleep\n&gt;&gt;&gt; bst_post = st[beh_epochs[2] &amp; nrem_epochs].bin(ds=0.05).data\n</code></pre> <pre><code>&gt;&gt;&gt; ev, rev = explained_variance.explained_variance(bst_task, bst_post, bst_pre)\n&gt;&gt;&gt; print(f\"Explained Variance: {ev}, Reverse Explained Variance: {rev}\")\nExplained Variance: 0.21654828336188703, Reverse Explained Variance: 0.00413191971965775\n</code></pre> Notes <p>n_timepoints can differ between task, post_task, pre_task</p> Source code in <code>neuro_py/ensemble/explained_variance.py</code> <pre><code>def explained_variance(\n    task: np.ndarray, post_task: np.ndarray, pre_task: np.ndarray\n) -&gt; tuple:\n    \"\"\"\n    Simplified version of explained variance and reverse explained variance\n\n    Parameters\n    ----------\n    task : np.ndarray\n        2D array, spike counts matrix with shape(n_features, n_timepoints)\n    post_task : np.ndarray\n        2D array, spike counts matrix with shape(n_features, n_timepoints)\n    pre_task : np.ndarray\n        2D array, spike counts matrix with shape(n_features, n_timepoints)\n\n    Returns\n    -------\n    EV : float\n        explained variance\n    rEV : float\n        reverse explained variance\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from neuro_py.ensemble import explained_variance\n    &gt;&gt;&gt; # build correlated task/post epochs and a weaker pre epoch\n    &gt;&gt;&gt; rng = np.random.default_rng(0)\n    &gt;&gt;&gt; n_features, n_time = 10, 300\n    &gt;&gt;&gt; rho_task, rho_pre = 0.5, 0.1\n    &gt;&gt;&gt; cov_task = np.full((n_features, n_features), rho_task); np.fill_diagonal(cov_task, 1.0)\n    &gt;&gt;&gt; cov_pre = np.full((n_features, n_features), rho_pre); np.fill_diagonal(cov_pre, 1.0)\n    &gt;&gt;&gt; task = rng.multivariate_normal(np.zeros(n_features), cov_task, size=n_time).T\n    &gt;&gt;&gt; post = rng.multivariate_normal(np.zeros(n_features), cov_task, size=n_time).T\n    &gt;&gt;&gt; pre = rng.multivariate_normal(np.zeros(n_features), cov_pre, size=n_time).T\n    &gt;&gt;&gt; EV, rEV = explained_variance.explained_variance(task, post, pre)\n    &gt;&gt;&gt; EV &gt; rEV\n    True\n\n\n    &gt;&gt;&gt; import neuro_py as npy\n    &gt;&gt;&gt; import nelpy as nel\n    &gt;&gt;&gt; from neuro_py.ensemble import explained_variance\n    &gt;&gt;&gt; basepath = r\"S:\\data\\HMC\\HMC1\\day8\"\n    &gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n    &gt;&gt;&gt; epoch_df = npy.io.load_epoch(basepath)\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n    &gt;&gt;&gt; state_dict = npy.io.load_SleepState_states(basepath)\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n    ...    state_dict[\"NREMstate\"],\n    ... )\n    &gt;&gt;&gt; theta_cycles = npy.io.load_theta_cycles(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; theta_cycles = theta_cycles[beh_epochs[1]]  # only during behavior\n    &gt;&gt;&gt; # bin spike trains into each theta cycle\n    &gt;&gt;&gt; bst_task = npy.process.count_in_interval(\n    ...     st.data, theta_cycles.starts, theta_cycles.stops\n    ... )\n    &gt;&gt;&gt; # bin spike trains into 50ms bins during pre sleep\n    &gt;&gt;&gt; bst_pre = st[beh_epochs[0] &amp; nrem_epochs].bin(ds=0.05).data\n    &gt;&gt;&gt; # bin spike trains into 50ms bins during post sleep\n    &gt;&gt;&gt; bst_post = st[beh_epochs[2] &amp; nrem_epochs].bin(ds=0.05).data\n\n    &gt;&gt;&gt; ev, rev = explained_variance.explained_variance(bst_task, bst_post, bst_pre)\n    &gt;&gt;&gt; print(f\"Explained Variance: {ev}, Reverse Explained Variance: {rev}\")\n    Explained Variance: 0.21654828336188703, Reverse Explained Variance: 0.00413191971965775\n\n    Notes\n    -----\n    n_timepoints can differ between task, post_task, pre_task\n    \"\"\"\n\n    # Coerce inputs to NumPy arrays and validate dimensionality\n    task = np.asarray(task)\n    pre_task = np.asarray(pre_task)\n    post_task = np.asarray(post_task)\n\n    for name, arr in ((\"task\", task), (\"post_task\", post_task), (\"pre_task\", pre_task)):\n        if arr.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2D array of shape (n_units, n_bins); \"\n                f\"got array with shape {arr.shape} and ndim={arr.ndim}\"\n            )\n\n    # Validate feature dimensions match\n    if task.shape[0] != post_task.shape[0] or task.shape[0] != pre_task.shape[0]:\n        raise ValueError(\"All inputs must have the same number of features (rows)\")\n\n    # Pairwise correlation matrices for each epoch\n    corr_beh = np.corrcoef(task)\n    corr_pre = np.corrcoef(pre_task)\n    corr_post = np.corrcoef(post_task)\n\n    # Use strictly lower triangle (no diagonal) to form pair vectors\n    n = corr_beh.shape[0]\n    li = np.tril_indices(n, k=-1)\n    r_beh = corr_beh[li]\n    r_pre = corr_pre[li]\n    r_post = corr_post[li]\n\n    # Helper: correlation between 1D vectors (guard against degenerate variance and NaNs)\n    def _corr(a, b):\n        # Remove entries where either vector has NaN\n        mask = ~np.isnan(a) &amp; ~np.isnan(b)\n        a_clean = a[mask]\n        b_clean = b[mask]\n        if a_clean.size == 0 or b_clean.size == 0:\n            return np.nan\n        if np.nanstd(a_clean) == 0 or np.nanstd(b_clean) == 0:\n            return 0.0\n        return float(np.corrcoef(a_clean, b_clean)[0, 1])\n\n    # Between-epoch correlations of pairwise templates\n    beh_pos = _corr(r_beh, r_post)\n    beh_pre = _corr(r_beh, r_pre)\n    pre_pos = _corr(r_pre, r_post)\n\n    # Explained variance and reverse explained variance (squared partial correlations)\n    eps = 1e-10\n    denom_ev = np.sqrt((1 - beh_pre**2) * (1 - pre_pos**2)) + eps\n    denom_rev = np.sqrt((1 - beh_pos**2) * (1 - pre_pos**2)) + eps\n    EV = ((beh_pos - beh_pre * pre_pos) / denom_ev) ** 2\n    rEV = ((beh_pre - beh_pos * pre_pos) / denom_rev) ** 2\n\n    return EV, rEV\n</code></pre>"},{"location":"reference/neuro_py/ensemble/geometry/","title":"neuro_py.ensemble.geometry","text":""},{"location":"reference/neuro_py/ensemble/geometry/#neuro_py.ensemble.geometry.proximity","title":"<code>proximity(pv1, pv2)</code>","text":"<p>Proximity between two firing rate vector trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>pv1</code> <code>ndarray</code> <p>Firing rate vector trajectory in one context. Shape: (num_bins, num_neurons)</p> required <code>pv2</code> <code>ndarray</code> <p>Firing rate vector trajectory in another context. Shape: (num_bins, num_neurons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Proximity between the two contexts.</p> References <p>.. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,     Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,     Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional     specialization manifests in the reliability of neural population codes.     bioRxiv : the preprint server for biology, 2024.01.25.576941.     https://doi.org/10.1101/2024.01.25.576941</p> Source code in <code>neuro_py/ensemble/geometry.py</code> <pre><code>def proximity(pv1: np.ndarray, pv2: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Proximity between two firing rate vector trajectories.\n\n    Parameters\n    ----------\n    pv1 : numpy.ndarray\n        Firing rate vector trajectory in one context.\n        Shape: (num_bins, num_neurons)\n\n    pv2 : numpy.ndarray\n        Firing rate vector trajectory in another context.\n        Shape: (num_bins, num_neurons)\n\n    Returns\n    -------\n    numpy.ndarray\n        Proximity between the two contexts.\n\n    References\n    ----------\n    .. [1] Guidera, J. A., Gramling, D. P., Comrie, A. E., Joshi, A.,\n        Denovellis, E. L., Lee, K. H., Zhou, J., Thompson, P., Hernandez, J.,\n        Yorita, A., Haque, R., Kirst, C., &amp; Frank, L. M. (2024). Regional\n        specialization manifests in the reliability of neural population codes.\n        bioRxiv : the preprint server for biology, 2024.01.25.576941.\n        https://doi.org/10.1101/2024.01.25.576941\n    \"\"\"\n    # Calculate the norms\n    norm_diff = np.linalg.norm(pv1 - pv2, axis=1)\n\n    norm_diff_mean = np.apply_along_axis(\n        lambda e: np.mean(np.linalg.norm(e - pv2, axis=1)), arr=pv1, axis=1\n    )\n\n    # Calculate proximity\n    prox = 1 - (norm_diff / norm_diff_mean)\n\n    return prox\n</code></pre>"},{"location":"reference/neuro_py/ensemble/pairwise_bias_correlation/","title":"neuro_py.ensemble.pairwise_bias_correlation","text":""},{"location":"reference/neuro_py/ensemble/pairwise_bias_correlation/#neuro_py.ensemble.pairwise_bias_correlation.cosine_similarity_matrices","title":"<code>cosine_similarity_matrices(matrix1, matrix2)</code>","text":"<p>Compute the cosine similarity between two flattened matrices</p> <p>Parameters:</p> Name Type Description Default <code>matrix1</code> <code>ndarray</code> <p>A normalized bias matrix</p> required <code>matrix2</code> <code>ndarray</code> <p>Another normalized bias matrix</p> required <p>Returns:</p> Type Description <code>float</code> <p>The cosine similarity between the two matrices.</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n    \"\"\"\n    Compute the cosine similarity between two flattened matrices\n\n    Parameters\n    ----------\n    matrix1 : numpy.ndarray\n        A normalized bias matrix\n    matrix2 : numpy.ndarray\n        Another normalized bias matrix\n\n    Returns\n    -------\n    float\n        The cosine similarity between the two matrices.\n    \"\"\"\n    # Flatten matrices\n    x = matrix1.flatten().reshape(1, -1)\n    y = matrix2.flatten().reshape(1, -1)\n\n    if np.all(np.isnan(x)) or np.all(np.isnan(y)):\n        return np.nan\n\n    # handle nan values\n    x = np.nan_to_num(x)\n    y = np.nan_to_num(y)\n\n    cossim = sklearn.metrics.pairwise.cosine_similarity(x, y)\n\n    # Compute cosine similarity\n    return cossim.item()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/pairwise_bias_correlation/#neuro_py.ensemble.pairwise_bias_correlation.observed_and_shuffled_correlation","title":"<code>observed_and_shuffled_correlation(post_spikes, post_neurons, total_neurons, task_normalized, post_intervals, interval_i, num_shuffles=100)</code>","text":"<p>Calculate observed and shuffled correlations between task and post-task neural activity.</p> <p>This function computes the correlation between normalized task bias matrix and post-task bias matrix, as well as correlations with shuffled post-task data.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Array of post-task spike times.</p> required <code>post_neurons</code> <code>ndarray</code> <p>Array of neuron IDs corresponding to post_spikes.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons in the dataset.</p> required <code>task_normalized</code> <code>ndarray</code> <p>Normalized bias matrix from task period.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Array of post-task intervals, shape (n_intervals, 2).</p> required <code>interval_i</code> <code>int</code> <p>Index of the current interval to analyze.</p> required <code>num_shuffles</code> <code>int</code> <p>Number of times to shuffle post-task data for null distribution, by default 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>Tuple[float, List[float]]</code> <p>A tuple containing: - observed_correlation: float     Cosine similarity between task and post-task bias matrices. - shuffled_correlation: List[float]     List of cosine similarities between task and shuffled post-task bias matrices.</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def observed_and_shuffled_correlation(\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    total_neurons: int,\n    task_normalized: np.ndarray,\n    post_intervals: np.ndarray,\n    interval_i: int,\n    num_shuffles: int = 100,\n) -&gt; Tuple[float, List[float]]:\n    \"\"\"\n    Calculate observed and shuffled correlations between task and post-task neural activity.\n\n    This function computes the correlation between normalized task bias matrix and\n    post-task bias matrix, as well as correlations with shuffled post-task data.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Array of post-task spike times.\n    post_neurons : np.ndarray\n        Array of neuron IDs corresponding to post_spikes.\n    total_neurons : int\n        Total number of neurons in the dataset.\n    task_normalized : np.ndarray\n        Normalized bias matrix from task period.\n    post_intervals : np.ndarray\n        Array of post-task intervals, shape (n_intervals, 2).\n    interval_i : int\n        Index of the current interval to analyze.\n    num_shuffles : int, optional\n        Number of times to shuffle post-task data for null distribution, by default 100.\n\n    Returns\n    -------\n    Tuple[float, List[float]]\n        A tuple containing:\n        - observed_correlation: float\n            Cosine similarity between task and post-task bias matrices.\n        - shuffled_correlation: List[float]\n            List of cosine similarities between task and shuffled post-task bias matrices.\n    \"\"\"\n    # for i_interval in range(post_intervals.shape[0]):\n    idx = (post_spikes &gt; post_intervals[interval_i][0]) &amp; (\n        post_spikes &lt; post_intervals[interval_i][1]\n    )\n\n    post_bias_matrix = skew_bias_matrix(\n        post_spikes[idx], post_neurons[idx], total_neurons\n    )\n\n    # Compute cosine similarity between task and post-task bias matrices\n    observed_correlation = cosine_similarity_matrices(task_normalized, post_bias_matrix)\n\n    # Shuffle post-task spikes and compute bias matrix\n    shuffled_correlation = [\n        cosine_similarity_matrices(\n            task_normalized,\n            skew_bias_matrix(\n                post_spikes[idx],\n                np.random.permutation(post_neurons[idx]),\n                total_neurons,\n            ),\n        )\n        for _ in range(num_shuffles)\n    ]\n\n    return observed_correlation, shuffled_correlation\n</code></pre>"},{"location":"reference/neuro_py/ensemble/pairwise_bias_correlation/#neuro_py.ensemble.pairwise_bias_correlation.shuffled_significance","title":"<code>shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals=np.array([[-np.inf, np.inf]]), num_shuffles=100, n_jobs=-1)</code>","text":"<p>Computes the significance of the task-post correlation by comparing against shuffled distributions.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike timestamps during the task. Shape is (n_spikes_task,)</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers corresponding to each of <code>task_spikes</code>. Shape is (n_spikes_task,)</p> required <code>post_spikes</code> <code>ndarray</code> <p>Spike timestamps during post-task (e.g., sleep). Shape is (n_spikes_post,)</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers corresponding to <code>post_spikes</code>. Shape is (n_spikes_post,)</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs, with shape (n_intervals, 2). Each row defines the start and end of an interval. May correspond to specific sleep states. Default is <code>np.array([[-np.inf, np.inf]])</code>, representing the entire range of post-task epochs</p> <code>array([[-inf, inf]])</code> <code>num_shuffles</code> <code>int</code> <p>Number of shuffles to compute the significance. Default is 100</p> <code>100</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to use for shuffling. Default is -1 (use all available cores).</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>z_score</code> <code>ndarray</code> <p>Z-scores of the observed correlations compared to the shuffled distributions. Shape is (n_intervals,).</p> <code>p_value</code> <code>ndarray</code> <p>P-values indicating the significance of the observed correlation. Shape is (n_intervals,).</p> Notes <p>The function uses parallel processing to compute observed and shuffled correlations for each post-task interval. The z-score is calculated as:</p> <pre><code>z_score = (observed_correlation - mean(shuffled_correlations)) / std(shuffled_correlations)\n</code></pre> <p>The p-value is computed as the proportion of shuffled correlations greater than the observed correlation, with a small constant added for numerical stability.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; task_spikes = np.array([1.2, 3.4, 5.6])\n&gt;&gt;&gt; task_neurons = np.array([0, 1, 0])\n&gt;&gt;&gt; post_spikes = np.array([2.3, 4.5, 6.7])\n&gt;&gt;&gt; post_neurons = np.array([1, 0, 1])\n&gt;&gt;&gt; total_neurons = 2\n&gt;&gt;&gt; post_intervals = np.array([[0, 10]])\n&gt;&gt;&gt; z_score, p_value = shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals)\n&gt;&gt;&gt; z_score\narray([1.23])\n&gt;&gt;&gt; p_value\narray([0.04])\n</code></pre> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>def shuffled_significance(\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    total_neurons: int,\n    post_intervals: np.ndarray = np.array([[-np.inf, np.inf]]),\n    num_shuffles: int = 100,\n    n_jobs: int = -1,\n):\n    \"\"\"\n    Computes the significance of the task-post correlation by comparing against shuffled distributions.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike timestamps during the task. Shape is (n_spikes_task,)\n    task_neurons : np.ndarray\n        Neuron identifiers corresponding to each of `task_spikes`. Shape is\n        (n_spikes_task,)\n    post_spikes : np.ndarray\n        Spike timestamps during post-task (e.g., sleep). Shape is\n        (n_spikes_post,)\n    post_neurons : np.ndarray\n        Neuron identifiers corresponding to `post_spikes`. Shape is\n        (n_spikes_post,)\n    total_neurons : int\n        Total number of neurons being considered\n    post_intervals : np.ndarray, optional\n        Intervals for post-task epochs, with shape (n_intervals, 2).\n        Each row defines the start and end of an interval. May correspond to\n        specific sleep states. Default is `np.array([[-np.inf, np.inf]])`,\n        representing the entire range of post-task epochs\n    num_shuffles : int, optional\n        Number of shuffles to compute the significance. Default is 100\n    n_jobs : int, optional\n        Number of parallel jobs to use for shuffling. Default is -1 (use all\n        available cores).\n\n    Returns\n    -------\n    z_score : np.ndarray\n        Z-scores of the observed correlations compared to the shuffled distributions.\n        Shape is (n_intervals,).\n    p_value : np.ndarray\n        P-values indicating the significance of the observed correlation.\n        Shape is (n_intervals,).\n\n    Notes\n    -----\n    The function uses parallel processing to compute observed and shuffled\n    correlations for each post-task interval. The z-score is calculated as:\n\n        z_score = (observed_correlation - mean(shuffled_correlations)) / std(shuffled_correlations)\n\n    The p-value is computed as the proportion of shuffled correlations greater than\n    the observed correlation, with a small constant added for numerical stability.\n\n    Examples\n    --------\n    &gt;&gt;&gt; task_spikes = np.array([1.2, 3.4, 5.6])\n    &gt;&gt;&gt; task_neurons = np.array([0, 1, 0])\n    &gt;&gt;&gt; post_spikes = np.array([2.3, 4.5, 6.7])\n    &gt;&gt;&gt; post_neurons = np.array([1, 0, 1])\n    &gt;&gt;&gt; total_neurons = 2\n    &gt;&gt;&gt; post_intervals = np.array([[0, 10]])\n    &gt;&gt;&gt; z_score, p_value = shuffled_significance(task_spikes, task_neurons, post_spikes, post_neurons, total_neurons, post_intervals)\n    &gt;&gt;&gt; z_score\n    array([1.23])\n    &gt;&gt;&gt; p_value\n    array([0.04])\n    \"\"\"\n    # set random seed for reproducibility\n    np.random.seed(0)\n\n    # Compute bias matrices for task epochs\n    task_bias_matrix = skew_bias_matrix(task_spikes, task_neurons, total_neurons)\n\n    # Get shuffled and observed correlations using parallel processing\n    observed_correlation, shuffled_correlations = zip(\n        *Parallel(n_jobs=n_jobs)(\n            delayed(observed_and_shuffled_correlation)(\n                post_spikes,\n                post_neurons,\n                total_neurons,\n                task_bias_matrix,\n                post_intervals,\n                interval_i,\n                num_shuffles,\n            )\n            for interval_i in range(post_intervals.shape[0])\n        )\n    )\n    observed_correlation, shuffled_correlations = (\n        np.array(observed_correlation),\n        np.array(shuffled_correlations),\n    )\n    # Compute z-score\n    shuffled_mean = np.mean(shuffled_correlations, axis=1)\n    shuffled_std = np.std(shuffled_correlations, axis=1)\n    z_score = (observed_correlation - shuffled_mean) / shuffled_std\n\n    # significance test between the observed correlation and the shuffled distribution\n    p_value = (np.sum(shuffled_correlations.T &gt; observed_correlation, axis=0) + 1) / (\n        num_shuffles + 1\n    )\n\n    return z_score, p_value\n</code></pre>"},{"location":"reference/neuro_py/ensemble/pairwise_bias_correlation/#neuro_py.ensemble.pairwise_bias_correlation.skew_bias_matrix","title":"<code>skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral=0)</code>","text":"<p>Compute the pairwise skew-bias matrix for a given sequence of spikes.</p> <p>Parameters:</p> Name Type Description Default <code>spike_times</code> <code>ndarray</code> <p>Spike times for the sequence, assumed to be sorted.</p> required <code>neuron_ids</code> <code>ndarray</code> <p>Neuron identifiers corresponding to <code>spike_times</code>. Values should be integers between 0 and <code>total_neurons - 1</code>.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered.</p> required <code>fillneutral</code> <code>float</code> <p>Value to fill for neutral bias, by default 0</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Skew-bias matrix of size <code>(total_neurons, total_neurons)</code> where each entry represents the normalized bias between neuron pairs.</p> Notes <p>The probability-bias ( B_{ij} ) for neurons ( i ) and ( j ) is computed as: [ B_{ij} = \\frac{nspikes_{ij}}{nspikes_i \\cdot nspikes_j} ] where ( nspikes_{ij} ) is the count of spikes from neuron ( i ) occurring before spikes from neuron ( j ). If there are no spikes for either neuron, the bias is set to 0.5 (neutral bias).</p> <p>The skew-bias matrix is computed as: [ S_{ij} = 2 \\cdot B_{ij} - 1 ] where ( B_{ij} ) is the probability-bias matrix.</p> <p>The skew-bias matrix is a skew-symmetric matrix as ( S_{ij} = -S_{ji} ). The values are normalized between -1 and 1. A value of 1 indicates that neuron ( i ) spikes before neuron ( j ) in all cases, while -1 indicates the opposite. A value of 0 indicates that the order of spikes is random.</p> References <p>.. [1] Roth, Z. (2016). Analysis of neuronal sequences using pairwise     biases. arXiv, 11-16. https://arxiv.org/abs/1603.02916</p> Source code in <code>neuro_py/ensemble/pairwise_bias_correlation.py</code> <pre><code>@njit\ndef skew_bias_matrix(\n    spike_times: np.ndarray,\n    neuron_ids: np.ndarray,\n    total_neurons: int,\n    fillneutral: float = 0,\n) -&gt; np.ndarray:\n    r\"\"\"\n    Compute the pairwise skew-bias matrix for a given sequence of spikes.\n\n    Parameters\n    ----------\n    spike_times : numpy.ndarray\n        Spike times for the sequence, assumed to be sorted.\n    neuron_ids : numpy.ndarray\n        Neuron identifiers corresponding to `spike_times`.\n        Values should be integers between 0 and `total_neurons - 1`.\n    total_neurons : int\n        Total number of neurons being considered.\n    fillneutral : float, optional\n        Value to fill for neutral bias, by default 0\n\n    Returns\n    -------\n    numpy.ndarray\n        Skew-bias matrix of size `(total_neurons, total_neurons)` where\n        each entry represents the normalized bias between neuron pairs.\n\n    Notes\n    -----\n    The probability-bias \\( B_{ij} \\) for neurons \\( i \\) and \\( j \\) is\n    computed as:\n    \\[\n    B_{ij} = \\frac{nspikes_{ij}}{nspikes_i \\cdot nspikes_j}\n    \\]\n    where \\( nspikes_{ij} \\) is the count of spikes from neuron \\( i \\)\n    occurring before spikes from neuron \\( j \\). If there are no spikes for\n    either neuron, the bias is set to 0.5 (neutral bias).\n\n    The skew-bias matrix is computed as:\n    \\[\n    S_{ij} = 2 \\cdot B_{ij} - 1\n    \\]\n    where \\( B_{ij} \\) is the probability-bias matrix.\n\n    The skew-bias matrix is a skew-symmetric matrix as \\( S_{ij} = -S_{ji} \\).\n    The values are normalized between -1 and 1. A value of 1 indicates that\n    neuron \\( i \\) spikes before neuron \\( j \\) in all cases, while -1 indicates\n    the opposite. A value of 0 indicates that the order of spikes is random.\n\n    References\n    ----------\n    .. [1] Roth, Z. (2016). Analysis of neuronal sequences using pairwise\n        biases. arXiv, 11-16. https://arxiv.org/abs/1603.02916\n    \"\"\"\n    bias = np.empty((total_neurons, total_neurons))\n    nrn_spk_rindices = np.empty(total_neurons + 1, dtype=np.int64)\n    nrn_spk_rindices[0] = 0\n\n    nrns_st = numba.typed.List()\n    for _ in range(total_neurons):\n        nrns_st.append(numba.typed.List.empty_list(np.float64))\n    for i, nrn_id in enumerate(neuron_ids):\n        nrns_st[nrn_id].append(spike_times[i])\n    for nnrn in range(total_neurons):\n        nrn_spk_rindices[nnrn + 1] = nrn_spk_rindices[nnrn] + len(nrns_st[nnrn])\n\n    nrns_st_all = np.empty(nrn_spk_rindices[-1], dtype=np.float64)\n    for nnrn in range(total_neurons):\n        nrns_st_all[nrn_spk_rindices[nnrn] : nrn_spk_rindices[nnrn + 1]] = np.asarray(\n            nrns_st[nnrn]\n        )\n\n    # Build bias matrix\n    for i in range(total_neurons):\n        spikes_i = nrns_st_all[nrn_spk_rindices[i] : nrn_spk_rindices[i + 1]]\n        nspikes_i = len(spikes_i)\n\n        for j in range(i + 1, total_neurons):\n            nspikes_j = len(nrns_st[j])\n            if (nspikes_i == 0) or (nspikes_j == 0):\n                bias[i, j] = bias[j, i] = fillneutral\n            else:\n                spikes_j = nrns_st_all[nrn_spk_rindices[j] : nrn_spk_rindices[j + 1]]\n\n                nspikes_ij = np.searchsorted(spikes_i, spikes_j, side=\"right\").sum()\n                bias[i, j] = 2 * (nspikes_ij / (nspikes_i * nspikes_j)) - 1\n                bias[j, i] = -bias[i, j]\n\n    # set diagonal to fillneutral\n    for i in range(total_neurons):\n        bias[i, i] = fillneutral\n\n    return bias\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/","title":"neuro_py.ensemble.replay","text":""},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias","title":"<code>PairwiseBias</code>","text":"<p>               Bases: <code>object</code></p> <p>Pairwise bias analysis for comparing task and post-task spike sequences.</p> <p>Parameters:</p> Name Type Description Default <code>num_shuffles</code> <code>int</code> <p>Number of shuffles to perform for significance testing. Default is 300.</p> <code>300</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to run for computing correlations. Default is 10.</p> <code>10</code> <p>Attributes:</p> Name Type Description <code>total_neurons</code> <code>int, or None</code> <p>Total number of neurons in the dataset.</p> <code>task_skew_bias</code> <code>np.ndarray, or None</code> <p>Normalized skew-bias matrix for the task data.</p> <code>observed_correlation_</code> <code>np.ndarray, or None</code> <p>Observed cosine similarity between task and post-task bias matrices.</p> <code>shuffled_correlations_</code> <code>np.ndarray, or None</code> <p>Shuffled cosine similarities for significance testing.</p> <code>z_score_</code> <code>np.ndarray, or None</code> <p>Z-score of the observed correlation compared to the shuffled distribution.</p> <code>p_value_</code> <code>np.ndarray, or None</code> <p>p-value for significance test.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model using the task spike data.</p> <code>transform</code> <p>Transform the post-task data to compute z-scores and p-values.</p> <code>fit_transform</code> <p>Fit the model with task data and transform the post-task data.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>class PairwiseBias(object):\n    \"\"\"\n    Pairwise bias analysis for comparing task and post-task spike sequences.\n\n    Parameters\n    ----------\n    num_shuffles : int, optional\n        Number of shuffles to perform for significance testing. Default is 300.\n    n_jobs : int, optional\n        Number of parallel jobs to run for computing correlations. Default is 10.\n\n    Attributes\n    ----------\n    total_neurons : int, or None\n        Total number of neurons in the dataset.\n    task_skew_bias : np.ndarray, or None\n        Normalized skew-bias matrix for the task data.\n    observed_correlation_ : np.ndarray, or None\n        Observed cosine similarity between task and post-task bias matrices.\n    shuffled_correlations_ : np.ndarray, or None\n        Shuffled cosine similarities for significance testing.\n    z_score_ : np.ndarray, or None\n        Z-score of the observed correlation compared to the shuffled distribution.\n    p_value_ : np.ndarray, or None\n        p-value for significance test.\n\n    Methods\n    -------\n    fit(task_spikes: Union[List[float], np.ndarray], task_neurons: Union[List[int], np.ndarray]) -&gt; 'PairwiseBias'\n        Fit the model using the task spike data.\n    transform(post_spikes: Union[List[float], np.ndarray], post_neurons: Union[List[int], np.ndarray], post_intervals: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Transform the post-task data to compute z-scores and p-values.\n    fit_transform(task_spikes: Union[List[float], np.ndarray], task_neurons: Union[List[int], np.ndarray], post_spikes: Union[List[float], np.ndarray], post_neurons: Union[List[int], np.ndarray], post_intervals: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Fit the model with task data and transform the post-task data.\n    \"\"\"\n\n    def __init__(\n        self, num_shuffles: int = 300, n_jobs: int = 10, fillneutral: float = np.nan\n    ):\n        self.num_shuffles = num_shuffles\n        self.n_jobs = n_jobs\n        self.fillneutral = fillneutral\n        self.total_neurons = None\n        self.task_skew_bias = None\n        self.observed_correlation_ = None\n        self.shuffled_correlations_ = None\n        self.z_score_ = None\n        self.p_value_ = None\n\n    @staticmethod\n    def bias_matrix(\n        spike_times: np.ndarray,\n        neuron_ids: np.ndarray,\n        total_neurons: int,\n        fillneutral: float = np.nan,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.\n\n        Parameters\n        ----------\n        spike_times : np.ndarray\n            Spike times for the sequence.\n        neuron_ids : np.ndarray\n            Neuron identifiers corresponding to spike_times.\n        total_neurons : int\n            Total number of neurons being considered.\n        fillneutral : float, optional\n            Value to fill the diagonal of the bias matrix and other empty\n            combinations, by default np.nan.\n\n        Returns\n        -------\n        np.ndarray\n            A matrix of size (total_neurons, total_neurons) representing the bias.\n        \"\"\"\n        return skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral)\n\n    @staticmethod\n    def cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n        \"\"\"\n        Computes the cosine similarity between two flattened bias matrices.\n\n        Parameters\n        ----------\n        matrix1 : np.ndarray\n            A normalized bias matrix.\n        matrix2 : np.ndarray\n            Another normalized bias matrix.\n\n        Returns\n        -------\n        float\n            The cosine similarity between the two matrices.\n        \"\"\"\n        return cosine_similarity_matrices(matrix1, matrix2)\n\n    def observed_and_shuffled_correlation(\n        self,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        task_skew_bias: np.ndarray,\n        post_intervals: np.ndarray,\n        interval_i: int,\n    ) -&gt; Tuple[float, List[float]]:\n        \"\"\"\n        Compute observed and shuffled correlation for a given post-task interval.\n\n        Parameters\n        ----------\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        task_normalized : np.ndarray\n            Normalized task bias matrix.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs.\n        interval_i : int\n            Index of the current post-task interval.\n\n        Returns\n        -------\n        Tuple[float, List[float]]\n            The observed correlation and a list of shuffled correlations.\n        \"\"\"\n        post_neurons = np.asarray(post_neurons, dtype=int)\n\n        start, end = post_intervals[interval_i]\n        start_idx = np.searchsorted(post_spikes, start, side=\"left\")\n        end_idx = np.searchsorted(post_spikes, end, side=\"right\")\n\n        filtered_spikes = post_spikes[start_idx:end_idx]\n        filtered_neurons = post_neurons[start_idx:end_idx]\n\n        post_skew_bias = self.bias_matrix(\n            filtered_spikes,\n            filtered_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n\n        observed_correlation = self.cosine_similarity_matrices(\n            task_skew_bias, post_skew_bias\n        )\n\n        shuffled_correlation = []\n        for _ in range(self.num_shuffles):\n            shuffled_neurons = np.random.permutation(filtered_neurons)\n            shuffled_skew_bias = self.bias_matrix(\n                filtered_spikes,\n                shuffled_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            shuffled_correlation.append(\n                self.cosine_similarity_matrices(task_skew_bias, shuffled_skew_bias)\n            )\n\n        return observed_correlation, shuffled_correlation\n\n    def fit(\n        self,\n        task_spikes: np.ndarray,\n        task_neurons: np.ndarray,\n        task_intervals: np.ndarray = None,\n    ) -&gt; \"PairwiseBias\":\n        \"\"\"\n        Fit the model using the task spike data.\n\n        Parameters\n        ----------\n        task_spikes : np.ndarray\n            Spike times during the task.\n        task_neurons : np.ndarray\n            Neuron identifiers for task spikes.\n        task_intervals : np.ndarray, optional\n            Intervals for task epochs, by default None. If None, the entire task\n            data is used. Otherwise, the average bias matrix is computed across\n            all task intervals. Shape: (n_intervals, 2).\n\n        Returns\n        -------\n        PairwiseBias\n            Returns the instance itself.\n        \"\"\"\n        # Convert task_neurons to numpy array of integers\n        task_neurons = np.asarray(task_neurons, dtype=int)\n\n        # Calculate the total number of neurons based on unique entries in task_neurons\n        self.total_neurons = len(np.unique(task_neurons))\n\n        if task_intervals is None:\n            # Compute bias matrix for task data and normalize\n            task_skew_bias = self.bias_matrix(\n                task_spikes,\n                task_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            self.task_skew_bias = task_skew_bias\n        else:\n            # Compute bias matrices for each task interval\n            task_skew_biases = []\n\n            for interval in task_intervals:\n                # find the indices of spikes within the interval\n                start_idx = np.searchsorted(task_spikes, interval[0], side=\"left\")\n                end_idx = np.searchsorted(task_spikes, interval[1], side=\"right\")\n\n                # Extract spikes and neurons within the interval\n                interval_spikes = task_spikes[start_idx:end_idx]\n                interval_neurons = task_neurons[start_idx:end_idx]\n\n                # Compute the bias matrix for the interval\n                interval_skew_bias = self.bias_matrix(\n                    interval_spikes,\n                    interval_neurons,\n                    self.total_neurons,\n                    fillneutral=self.fillneutral,\n                )\n                task_skew_biases.append(interval_skew_bias)\n\n            # Average the normalized bias matrices\n            # I expect to see RuntimeWarnings in this block\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                self.task_skew_bias = np.nanmean(task_skew_biases, axis=0)\n        return self\n\n    def transform(\n        self,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        post_intervals: np.ndarray,\n        allow_reverse_replay: bool = False,\n        parallel: bool = True,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Transform the post-task data to compute z-scores and p-values.\n\n        Parameters\n        ----------\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs. Shape: (n_intervals, 2).\n        allow_reverse_replay : bool, optional\n            Whether to allow reverse sequences, by default False.\n        parallel : bool, optional\n            Whether to run in parallel, by default True.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            z_score: The z-score of the observed correlation compared to the shuffled distribution.\n            p_value: p-value for significance test.\n            observed_correlation_: The observed correlation for each interval.\n        \"\"\"\n        # Check if the number of jobs is less than the number of intervals\n        if post_intervals.shape[0] &lt; self.n_jobs:\n            self.n_jobs = post_intervals.shape[0]\n\n        if parallel:\n            observed_correlation, shuffled_correlations = zip(\n                *Parallel(n_jobs=self.n_jobs)(\n                    delayed(self.observed_and_shuffled_correlation)(\n                        post_spikes,\n                        post_neurons,\n                        self.task_skew_bias,\n                        post_intervals,\n                        interval_i,\n                    )\n                    for interval_i in range(post_intervals.shape[0])\n                )\n            )\n        else:  # Run in serial for debugging\n            observed_correlation, shuffled_correlations = zip(\n                *[\n                    self.observed_and_shuffled_correlation(\n                        post_spikes,\n                        post_neurons,\n                        self.task_skew_bias,\n                        post_intervals,\n                        interval_i,\n                    )\n                    for interval_i in range(post_intervals.shape[0])\n                ]\n            )\n\n        self.observed_correlation_ = np.array(\n            observed_correlation\n        )  # Shape: (n_intervals,)\n        self.shuffled_correlations_ = np.array(\n            shuffled_correlations\n        )  # Shape: (n_intervals, n_shuffles)\n\n        shuffled_mean = np.mean(self.shuffled_correlations_, axis=1)\n        shuffled_std = np.std(self.shuffled_correlations_, axis=1)\n        self.z_score_ = (self.observed_correlation_ - shuffled_mean) / shuffled_std\n\n        observed_correlation = self.observed_correlation_\n        shuffled_correlations = self.shuffled_correlations_\n        if allow_reverse_replay:\n            observed_correlation = np.abs(observed_correlation)\n            shuffled_correlations = np.abs(shuffled_correlations)\n\n        self.p_value_ = (\n            np.sum(\n                shuffled_correlations.T &gt; observed_correlation,\n                axis=0,\n            )\n            + 1\n        ) / (self.num_shuffles + 1)\n\n        return self.z_score_, self.p_value_, self.observed_correlation_\n\n    def fit_transform(\n        self,\n        task_spikes: np.ndarray,\n        task_neurons: np.ndarray,\n        task_intervals: np.ndarray,\n        post_spikes: np.ndarray,\n        post_neurons: np.ndarray,\n        post_intervals: np.ndarray,\n        allow_reverse_replay: bool = False,\n        parallel: bool = True,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Fit the model with task data and transform the post-task data.\n\n        Parameters\n        ----------\n        task_spikes : np.ndarray\n            Spike times during the task.\n        task_neurons : np.ndarray\n            Neuron identifiers for task spikes.\n        task_intervals : np.ndarray\n            Intervals for task epochs. Shape: (n_intervals, 2).\n        post_spikes : np.ndarray\n            Spike times during post-task (e.g., sleep).\n        post_neurons : np.ndarray\n            Neuron identifiers for post-task spikes.\n        post_intervals : np.ndarray\n            Intervals for post-task epochs. Shape: (n_intervals, 2).\n        allow_reverse_replay : bool, optional\n            Whether to allow reverse sequences, by default False.\n        parallel : bool, optional\n            Whether to run in parallel, by default True.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            z_score: The z-score of the observed correlation compared to the shuffled distribution.\n            p_value: p-value for significance test.\n            observed_correlation_: The observed correlation for each interval.\n        \"\"\"\n        self.fit(task_spikes, task_neurons, task_intervals)\n        return self.transform(\n            post_spikes, post_neurons, post_intervals, allow_reverse_replay, parallel\n        )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.bias_matrix","title":"<code>bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral=np.nan)</code>  <code>staticmethod</code>","text":"<p>Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.</p> <p>Parameters:</p> Name Type Description Default <code>spike_times</code> <code>ndarray</code> <p>Spike times for the sequence.</p> required <code>neuron_ids</code> <code>ndarray</code> <p>Neuron identifiers corresponding to spike_times.</p> required <code>total_neurons</code> <code>int</code> <p>Total number of neurons being considered.</p> required <code>fillneutral</code> <code>float</code> <p>Value to fill the diagonal of the bias matrix and other empty combinations, by default np.nan.</p> <code>nan</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size (total_neurons, total_neurons) representing the bias.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>@staticmethod\ndef bias_matrix(\n    spike_times: np.ndarray,\n    neuron_ids: np.ndarray,\n    total_neurons: int,\n    fillneutral: float = np.nan,\n) -&gt; np.ndarray:\n    \"\"\"\n    Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.\n\n    Parameters\n    ----------\n    spike_times : np.ndarray\n        Spike times for the sequence.\n    neuron_ids : np.ndarray\n        Neuron identifiers corresponding to spike_times.\n    total_neurons : int\n        Total number of neurons being considered.\n    fillneutral : float, optional\n        Value to fill the diagonal of the bias matrix and other empty\n        combinations, by default np.nan.\n\n    Returns\n    -------\n    np.ndarray\n        A matrix of size (total_neurons, total_neurons) representing the bias.\n    \"\"\"\n    return skew_bias_matrix(spike_times, neuron_ids, total_neurons, fillneutral)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.cosine_similarity_matrices","title":"<code>cosine_similarity_matrices(matrix1, matrix2)</code>  <code>staticmethod</code>","text":"<p>Computes the cosine similarity between two flattened bias matrices.</p> <p>Parameters:</p> Name Type Description Default <code>matrix1</code> <code>ndarray</code> <p>A normalized bias matrix.</p> required <code>matrix2</code> <code>ndarray</code> <p>Another normalized bias matrix.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The cosine similarity between the two matrices.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>@staticmethod\ndef cosine_similarity_matrices(matrix1: np.ndarray, matrix2: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the cosine similarity between two flattened bias matrices.\n\n    Parameters\n    ----------\n    matrix1 : np.ndarray\n        A normalized bias matrix.\n    matrix2 : np.ndarray\n        Another normalized bias matrix.\n\n    Returns\n    -------\n    float\n        The cosine similarity between the two matrices.\n    \"\"\"\n    return cosine_similarity_matrices(matrix1, matrix2)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.fit","title":"<code>fit(task_spikes, task_neurons, task_intervals=None)</code>","text":"<p>Fit the model using the task spike data.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike times during the task.</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers for task spikes.</p> required <code>task_intervals</code> <code>ndarray</code> <p>Intervals for task epochs, by default None. If None, the entire task data is used. Otherwise, the average bias matrix is computed across all task intervals. Shape: (n_intervals, 2).</p> <code>None</code> <p>Returns:</p> Type Description <code>PairwiseBias</code> <p>Returns the instance itself.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def fit(\n    self,\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    task_intervals: np.ndarray = None,\n) -&gt; \"PairwiseBias\":\n    \"\"\"\n    Fit the model using the task spike data.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike times during the task.\n    task_neurons : np.ndarray\n        Neuron identifiers for task spikes.\n    task_intervals : np.ndarray, optional\n        Intervals for task epochs, by default None. If None, the entire task\n        data is used. Otherwise, the average bias matrix is computed across\n        all task intervals. Shape: (n_intervals, 2).\n\n    Returns\n    -------\n    PairwiseBias\n        Returns the instance itself.\n    \"\"\"\n    # Convert task_neurons to numpy array of integers\n    task_neurons = np.asarray(task_neurons, dtype=int)\n\n    # Calculate the total number of neurons based on unique entries in task_neurons\n    self.total_neurons = len(np.unique(task_neurons))\n\n    if task_intervals is None:\n        # Compute bias matrix for task data and normalize\n        task_skew_bias = self.bias_matrix(\n            task_spikes,\n            task_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n        self.task_skew_bias = task_skew_bias\n    else:\n        # Compute bias matrices for each task interval\n        task_skew_biases = []\n\n        for interval in task_intervals:\n            # find the indices of spikes within the interval\n            start_idx = np.searchsorted(task_spikes, interval[0], side=\"left\")\n            end_idx = np.searchsorted(task_spikes, interval[1], side=\"right\")\n\n            # Extract spikes and neurons within the interval\n            interval_spikes = task_spikes[start_idx:end_idx]\n            interval_neurons = task_neurons[start_idx:end_idx]\n\n            # Compute the bias matrix for the interval\n            interval_skew_bias = self.bias_matrix(\n                interval_spikes,\n                interval_neurons,\n                self.total_neurons,\n                fillneutral=self.fillneutral,\n            )\n            task_skew_biases.append(interval_skew_bias)\n\n        # Average the normalized bias matrices\n        # I expect to see RuntimeWarnings in this block\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            self.task_skew_bias = np.nanmean(task_skew_biases, axis=0)\n    return self\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.fit_transform","title":"<code>fit_transform(task_spikes, task_neurons, task_intervals, post_spikes, post_neurons, post_intervals, allow_reverse_replay=False, parallel=True)</code>","text":"<p>Fit the model with task data and transform the post-task data.</p> <p>Parameters:</p> Name Type Description Default <code>task_spikes</code> <code>ndarray</code> <p>Spike times during the task.</p> required <code>task_neurons</code> <code>ndarray</code> <p>Neuron identifiers for task spikes.</p> required <code>task_intervals</code> <code>ndarray</code> <p>Intervals for task epochs. Shape: (n_intervals, 2).</p> required <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs. Shape: (n_intervals, 2).</p> required <code>allow_reverse_replay</code> <code>bool</code> <p>Whether to allow reverse sequences, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>z_score: The z-score of the observed correlation compared to the shuffled distribution. p_value: p-value for significance test. observed_correlation_: The observed correlation for each interval.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def fit_transform(\n    self,\n    task_spikes: np.ndarray,\n    task_neurons: np.ndarray,\n    task_intervals: np.ndarray,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    post_intervals: np.ndarray,\n    allow_reverse_replay: bool = False,\n    parallel: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Fit the model with task data and transform the post-task data.\n\n    Parameters\n    ----------\n    task_spikes : np.ndarray\n        Spike times during the task.\n    task_neurons : np.ndarray\n        Neuron identifiers for task spikes.\n    task_intervals : np.ndarray\n        Intervals for task epochs. Shape: (n_intervals, 2).\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs. Shape: (n_intervals, 2).\n    allow_reverse_replay : bool, optional\n        Whether to allow reverse sequences, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        z_score: The z-score of the observed correlation compared to the shuffled distribution.\n        p_value: p-value for significance test.\n        observed_correlation_: The observed correlation for each interval.\n    \"\"\"\n    self.fit(task_spikes, task_neurons, task_intervals)\n    return self.transform(\n        post_spikes, post_neurons, post_intervals, allow_reverse_replay, parallel\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.observed_and_shuffled_correlation","title":"<code>observed_and_shuffled_correlation(post_spikes, post_neurons, task_skew_bias, post_intervals, interval_i)</code>","text":"<p>Compute observed and shuffled correlation for a given post-task interval.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>task_normalized</code> <code>ndarray</code> <p>Normalized task bias matrix.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs.</p> required <code>interval_i</code> <code>int</code> <p>Index of the current post-task interval.</p> required <p>Returns:</p> Type Description <code>Tuple[float, List[float]]</code> <p>The observed correlation and a list of shuffled correlations.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def observed_and_shuffled_correlation(\n    self,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    task_skew_bias: np.ndarray,\n    post_intervals: np.ndarray,\n    interval_i: int,\n) -&gt; Tuple[float, List[float]]:\n    \"\"\"\n    Compute observed and shuffled correlation for a given post-task interval.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    task_normalized : np.ndarray\n        Normalized task bias matrix.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs.\n    interval_i : int\n        Index of the current post-task interval.\n\n    Returns\n    -------\n    Tuple[float, List[float]]\n        The observed correlation and a list of shuffled correlations.\n    \"\"\"\n    post_neurons = np.asarray(post_neurons, dtype=int)\n\n    start, end = post_intervals[interval_i]\n    start_idx = np.searchsorted(post_spikes, start, side=\"left\")\n    end_idx = np.searchsorted(post_spikes, end, side=\"right\")\n\n    filtered_spikes = post_spikes[start_idx:end_idx]\n    filtered_neurons = post_neurons[start_idx:end_idx]\n\n    post_skew_bias = self.bias_matrix(\n        filtered_spikes,\n        filtered_neurons,\n        self.total_neurons,\n        fillneutral=self.fillneutral,\n    )\n\n    observed_correlation = self.cosine_similarity_matrices(\n        task_skew_bias, post_skew_bias\n    )\n\n    shuffled_correlation = []\n    for _ in range(self.num_shuffles):\n        shuffled_neurons = np.random.permutation(filtered_neurons)\n        shuffled_skew_bias = self.bias_matrix(\n            filtered_spikes,\n            shuffled_neurons,\n            self.total_neurons,\n            fillneutral=self.fillneutral,\n        )\n        shuffled_correlation.append(\n            self.cosine_similarity_matrices(task_skew_bias, shuffled_skew_bias)\n        )\n\n    return observed_correlation, shuffled_correlation\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.PairwiseBias.transform","title":"<code>transform(post_spikes, post_neurons, post_intervals, allow_reverse_replay=False, parallel=True)</code>","text":"<p>Transform the post-task data to compute z-scores and p-values.</p> <p>Parameters:</p> Name Type Description Default <code>post_spikes</code> <code>ndarray</code> <p>Spike times during post-task (e.g., sleep).</p> required <code>post_neurons</code> <code>ndarray</code> <p>Neuron identifiers for post-task spikes.</p> required <code>post_intervals</code> <code>ndarray</code> <p>Intervals for post-task epochs. Shape: (n_intervals, 2).</p> required <code>allow_reverse_replay</code> <code>bool</code> <p>Whether to allow reverse sequences, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>z_score: The z-score of the observed correlation compared to the shuffled distribution. p_value: p-value for significance test. observed_correlation_: The observed correlation for each interval.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def transform(\n    self,\n    post_spikes: np.ndarray,\n    post_neurons: np.ndarray,\n    post_intervals: np.ndarray,\n    allow_reverse_replay: bool = False,\n    parallel: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Transform the post-task data to compute z-scores and p-values.\n\n    Parameters\n    ----------\n    post_spikes : np.ndarray\n        Spike times during post-task (e.g., sleep).\n    post_neurons : np.ndarray\n        Neuron identifiers for post-task spikes.\n    post_intervals : np.ndarray\n        Intervals for post-task epochs. Shape: (n_intervals, 2).\n    allow_reverse_replay : bool, optional\n        Whether to allow reverse sequences, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        z_score: The z-score of the observed correlation compared to the shuffled distribution.\n        p_value: p-value for significance test.\n        observed_correlation_: The observed correlation for each interval.\n    \"\"\"\n    # Check if the number of jobs is less than the number of intervals\n    if post_intervals.shape[0] &lt; self.n_jobs:\n        self.n_jobs = post_intervals.shape[0]\n\n    if parallel:\n        observed_correlation, shuffled_correlations = zip(\n            *Parallel(n_jobs=self.n_jobs)(\n                delayed(self.observed_and_shuffled_correlation)(\n                    post_spikes,\n                    post_neurons,\n                    self.task_skew_bias,\n                    post_intervals,\n                    interval_i,\n                )\n                for interval_i in range(post_intervals.shape[0])\n            )\n        )\n    else:  # Run in serial for debugging\n        observed_correlation, shuffled_correlations = zip(\n            *[\n                self.observed_and_shuffled_correlation(\n                    post_spikes,\n                    post_neurons,\n                    self.task_skew_bias,\n                    post_intervals,\n                    interval_i,\n                )\n                for interval_i in range(post_intervals.shape[0])\n            ]\n        )\n\n    self.observed_correlation_ = np.array(\n        observed_correlation\n    )  # Shape: (n_intervals,)\n    self.shuffled_correlations_ = np.array(\n        shuffled_correlations\n    )  # Shape: (n_intervals, n_shuffles)\n\n    shuffled_mean = np.mean(self.shuffled_correlations_, axis=1)\n    shuffled_std = np.std(self.shuffled_correlations_, axis=1)\n    self.z_score_ = (self.observed_correlation_ - shuffled_mean) / shuffled_std\n\n    observed_correlation = self.observed_correlation_\n    shuffled_correlations = self.shuffled_correlations_\n    if allow_reverse_replay:\n        observed_correlation = np.abs(observed_correlation)\n        shuffled_correlations = np.abs(shuffled_correlations)\n\n    self.p_value_ = (\n        np.sum(\n            shuffled_correlations.T &gt; observed_correlation,\n            axis=0,\n        )\n        + 1\n    ) / (self.num_shuffles + 1)\n\n    return self.z_score_, self.p_value_, self.observed_correlation_\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.WeightedCorr","title":"<code>WeightedCorr(weights, x=None, y=None)</code>","text":"<p>Calculate the weighted correlation between the X and Y dimensions of the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A matrix of weights.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>X-values for each column and row, by default None.</p> <code>None</code> <code>y</code> <code>Optional[ndarray]</code> <p>Y-values for each column and row, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The weighted correlation coefficient.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def WeightedCorr(\n    weights: np.ndarray, x: Optional[np.ndarray] = None, y: Optional[np.ndarray] = None\n) -&gt; float:\n    \"\"\"\n    Calculate the weighted correlation between the X and Y dimensions of the matrix.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A matrix of weights.\n    x : Optional[np.ndarray], optional\n        X-values for each column and row, by default None.\n    y : Optional[np.ndarray], optional\n        Y-values for each column and row, by default None.\n\n    Returns\n    -------\n    float\n        The weighted correlation coefficient.\n    \"\"\"\n    weights[np.isnan(weights)] = 0.0\n\n    if x is not None and x.size &gt; 0:\n        if np.ndim(x) == 1:\n            x = np.tile(x, (weights.shape[0], 1))\n    else:\n        x, _ = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n\n    if y is not None and y.size &gt; 0:\n        if np.ndim(y) == 1:\n            y = np.tile(y, (weights.shape[0], 1))\n    else:\n        _, y = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n\n    x = x.flatten()\n    y = y.flatten()\n    w = weights.flatten()\n\n    mX = np.nansum(w * x) / np.nansum(w)\n    mY = np.nansum(w * y) / np.nansum(w)\n\n    covXY = np.nansum(w * (x - mX) * (y - mY)) / np.nansum(w)\n    covXX = np.nansum(w * (x - mX) ** 2) / np.nansum(w)\n    covYY = np.nansum(w * (y - mY) ** 2) / np.nansum(w)\n\n    c = covXY / np.sqrt(covXX * covYY)\n\n    return c\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.WeightedCorrCirc","title":"<code>WeightedCorrCirc(weights, x=None, alpha=None)</code>","text":"<p>Compute the correlation between x and y dimensions of a matrix with angular (circular) values.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A 2D numpy array of weights.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>A 2D numpy array of x-values, by default None.</p> <code>None</code> <code>alpha</code> <code>Optional[ndarray]</code> <p>A 2D numpy array of angular (circular) y-values, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The correlation between x and y dimensions.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def WeightedCorrCirc(\n    weights: np.ndarray,\n    x: Optional[np.ndarray] = None,\n    alpha: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"\n    Compute the correlation between x and y dimensions of a matrix with angular (circular) values.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A 2D numpy array of weights.\n    x : Optional[np.ndarray], optional\n        A 2D numpy array of x-values, by default None.\n    alpha : Optional[np.ndarray], optional\n        A 2D numpy array of angular (circular) y-values, by default None.\n\n    Returns\n    -------\n    float\n        The correlation between x and y dimensions.\n    \"\"\"\n    weights[np.isnan(weights)] = 0.0\n\n    if x is not None and x.size &gt; 0:\n        if np.ndim(x) == 1:\n            x = np.tile(x, (weights.shape[0], 1))\n    else:\n        x, _ = np.meshgrid(\n            np.arange(1, weights.shape[1] + 1), np.arange(1, weights.shape[0] + 1)\n        )\n    if alpha is None:\n        alpha = np.tile(\n            np.linspace(0, 2 * np.pi, weights.shape[0], endpoint=False),\n            (weights.shape[1], 1),\n        ).T\n\n    rxs = WeightedCorr(weights, x, np.sin(alpha))\n    rxc = WeightedCorr(weights, x, np.cos(alpha))\n    rcs = WeightedCorr(weights, np.sin(alpha), np.cos(alpha))\n\n    # Compute angular-linear correlation\n    rho = np.sqrt((rxc**2 + rxs**2 - 2 * rxc * rxs * rcs) / (1 - rcs**2))\n    return rho\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay._position_estimator_1d","title":"<code>_position_estimator_1d(posterior_prob, bin_centers, method, n_time_bins)</code>","text":"<p>Helper function for 1D position decoding.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def _position_estimator_1d(\n    posterior_prob: np.ndarray, bin_centers: np.ndarray, method: str, n_time_bins: int\n):\n    \"\"\"Helper function for 1D position decoding.\"\"\"\n    if posterior_prob.shape[1] != len(bin_centers):\n        raise ValueError(\n            f\"Posterior shape {posterior_prob.shape[1]} doesn't match \"\n            f\"bin_centers length {len(bin_centers)}\"\n        )\n\n    position = np.full(n_time_bins, np.nan)\n\n    for t in range(n_time_bins):\n        P = posterior_prob[t]\n        if np.sum(P) &gt; 0:\n            if method == \"com\":\n                # Normalize probabilities\n                P_norm = P / np.sum(P)\n                # Calculate center of mass\n                position[t] = np.sum(bin_centers * P_norm)\n            elif method == \"max\":\n                # Find the index of the maximum probability\n                max_idx = np.argmax(P)\n                position[t] = bin_centers[max_idx]\n\n    return position\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay._position_estimator_2d","title":"<code>_position_estimator_2d(posterior_prob, ybin_centers, xbin_centers, method, n_time_bins)</code>","text":"<p>Helper function for 2D position decoding.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def _position_estimator_2d(\n    posterior_prob: np.ndarray,\n    ybin_centers: np.ndarray,\n    xbin_centers: np.ndarray,\n    method: str,\n    n_time_bins: int,\n):\n    \"\"\"Helper function for 2D position decoding.\"\"\"\n    if posterior_prob.shape[1] != len(ybin_centers) or posterior_prob.shape[2] != len(\n        xbin_centers\n    ):\n        raise ValueError(\n            f\"Posterior shape {posterior_prob.shape[1:]} doesn't match \"\n            f\"bin_centers shapes ({len(ybin_centers)}, {len(xbin_centers)})\"\n        )\n\n    # Create coordinate meshgrids\n    # Using xy indexing so xx contains x-coords and yy contains y-coords\n    xx, yy = np.meshgrid(xbin_centers, ybin_centers, indexing=\"xy\")\n\n    position = np.full((n_time_bins, 2), np.nan)  # [x, y] coordinates\n\n    for t in range(n_time_bins):\n        P = posterior_prob[t]\n        if np.sum(P) &gt; 0:\n            if method == \"com\":\n                # Normalize probabilities\n                P_norm = P / np.sum(P)\n\n                # Calculate center of mass\n                position[t, 0] = np.sum(xx * P_norm)  # x-coordinate\n                position[t, 1] = np.sum(yy * P_norm)  # y-coordinate\n\n            elif method == \"max\":\n                # Find the index of the maximum probability\n                max_idx = np.unravel_index(np.argmax(P), P.shape)\n                position[t, 0] = xx[max_idx]  # x-coordinate\n                position[t, 1] = yy[max_idx]  # y-coordinate\n\n    return position\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay._shuffle_and_score","title":"<code>_shuffle_and_score(posterior_array, tuningcurve, w, normalize, ds, dp, n_shuffles)</code>","text":"<p>Shuffle the posterior array and compute scores and weighted correlations.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_array</code> <code>ndarray</code> <p>The posterior probability array.</p> required <code>tuningcurve</code> <code>ndarray</code> <p>The tuning curve array.</p> required <code>w</code> <code>ndarray</code> <p>Weights array.</p> required <code>normalize</code> <code>bool</code> <p>Whether to normalize the scores.</p> required <code>ds</code> <code>float</code> <p>Delta space.</p> required <code>dp</code> <code>float</code> <p>Delta probability.</p> required <code>n_shuffles</code> <code>int</code> <p>Number of shuffles.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, float, List[ndarray], List[ndarray], List[float], List[float]]</code> <p>Scores and weighted correlations for original, time-swapped, and column-cycled arrays.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def _shuffle_and_score(\n    posterior_array: np.ndarray,\n    tuningcurve: np.ndarray,\n    w: np.ndarray,\n    normalize: bool,\n    ds: float,\n    dp: float,\n    n_shuffles: int,\n) -&gt; Tuple[\n    np.ndarray, float, List[np.ndarray], List[np.ndarray], List[float], List[float]\n]:\n    \"\"\"\n    Shuffle the posterior array and compute scores and weighted correlations.\n\n    Parameters\n    ----------\n    posterior_array : np.ndarray\n        The posterior probability array.\n    tuningcurve : np.ndarray\n        The tuning curve array.\n    w : np.ndarray\n        Weights array.\n    normalize : bool\n        Whether to normalize the scores.\n    ds : float\n        Delta space.\n    dp : float\n        Delta probability.\n    n_shuffles : int\n        Number of shuffles.\n\n    Returns\n    -------\n    Tuple[np.ndarray, float, List[np.ndarray], List[np.ndarray], List[float], List[float]]\n        Scores and weighted correlations for original, time-swapped, and column-cycled arrays.\n    \"\"\"\n    weighted_corr = weighted_correlation(posterior_array)\n    scores = replay.trajectory_score_array(\n        posterior=posterior_array, w=w, normalize=normalize\n    )\n\n    (\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    ) = zip(\n        *[\n            shuffle_and_score(posterior_array, w, normalize, tuningcurve, ds, dp)\n            for _ in range(n_shuffles)\n        ]\n    )\n    return (\n        scores,\n        weighted_corr,\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.bottom_up_replay_detection","title":"<code>bottom_up_replay_detection(posterior, time_centers, bin_centers, speed_times, speed_values, window_dt=None, speed_thresh=5.0, spread_thresh=10.0, com_jump_thresh=20.0, merge_spatial_gap=20.0, merge_time_gap=0.05, min_duration=0.1, dispersion_thresh=12.0, method='com')</code>","text":"<p>Bottom-up replay detector following Widloski &amp; Foster (2022) \"Replay detection and analysis\".</p> <p>Parameters:</p> Name Type Description Default <code>posterior</code> <code>ndarray</code> <p>Shape (n_time, n_space_bins) posterior probability for each time window.</p> required <code>time_centers</code> <code>ndarray</code> <p>Center time of each posterior time bin (length n_time) in seconds.</p> required <code>bin_centers</code> <code>ndarray</code> <p>Spatial bin centers (length n_space_bins) in same units as thresholds (cm).</p> required <code>speed_times</code> <code>ndarray</code> <p>Time stamps and speed values (cm/s) for the animal; used to interpolate speed at time_centers.</p> required <code>speed_values</code> <code>ndarray</code> <p>Time stamps and speed values (cm/s) for the animal; used to interpolate speed at time_centers.</p> required <code>window_dt</code> <code>Optional[float]</code> <p>Duration of each posterior time bin. If None, computed from time_centers diff.</p> <code>None</code> <code>speed_thresh</code> <code>float</code> <p>Speed threshold for filtering candidate replays (cm/s).</p> <code>5.0</code> <code>spread_thresh</code> <code>float</code> <p>Spread threshold for filtering candidate replays (cm).</p> <code>10.0</code> <code>com_jump_thresh</code> <code>float</code> <p>Center-of-mass jump threshold for filtering candidate replays (cm).</p> <code>20.0</code> <code>merge_spatial_gap</code> <code>float</code> <p>Spatial gap threshold for merging candidate replays (cm).</p> <code>20.0</code> <code>merge_time_gap</code> <code>float</code> <p>Temporal gap threshold for merging candidate replays (s).</p> <code>0.05</code> <code>min_duration</code> <code>float</code> <p>Minimum duration for keeping candidate replays (s).</p> <code>0.1</code> <code>dispersion_thresh</code> <code>float</code> <p>Dispersion threshold (mean absolute deviation of COM across sequence) for labeling replays (cm).</p> <code>12.0</code> <p>Returns:</p> Name Type Description <code>replays</code> <code>ndarray</code> <p>Array of replay events that passed dispersion threshold; shape (k,2) start/end times.</p> <code>meta</code> <code>dict</code> <p>Metadata dict with keys:  - 'candidates': candidate subsequences before dispersion filter; list of dicts with keys:     - 'start_time': start time of each candidate     - 'end_time': end time of each candidate     - 'start_idx': start index of each candidate     - 'end_idx': end index of each candidate     - 'duration': duration of each candidate (s)     - 'D2': dispersion (RMS radial deviation) per candidate (cm)     - 'com_trace': NaN-removed sequence of center-of-mass positions used for metrics     - 'path_length': path length (sum of consecutive COM step distances) across valid bins (cm)     - 'maxJump_NaN': maximum consecutive-step jump computed on the raw COM slice (may be NaN)     - 'maxJump_NaNremoved': maximum consecutive-step jump computed on the NaN-removed COM trace (cm)     - 'maxJump_NaNremoved_time': maximum temporal gap between valid (NaN-removed) samples (s)     - 'posteriorSpreadMax': maximum per-bin posterior spread across the candidate (cm)     - 'posteriorSpreadMean': mean per-bin posterior spread across the candidate (cm)  - 'com': center-of-mass per kept bin (array of shape (n_time, ) or (n_time,2))  - 'spread': posterior spread per kept bin (array of length n_time)  - 'mask': boolean mask of kept bins (array of length n_time)</p> Notes <p>This implementation assumes 1D and 2D spatial decoding.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def bottom_up_replay_detection(\n    posterior: np.ndarray,\n    time_centers: np.ndarray,\n    bin_centers: np.ndarray,\n    speed_times: np.ndarray,\n    speed_values: np.ndarray,\n    window_dt: Optional[float] = None,\n    speed_thresh: float = 5.0,\n    spread_thresh: float = 10.0,\n    com_jump_thresh: float = 20.0,\n    merge_spatial_gap: float = 20.0,\n    merge_time_gap: float = 0.05,\n    min_duration: float = 0.1,\n    dispersion_thresh: float = 12.0,\n    method: str = \"com\",\n) -&gt; Tuple[np.ndarray, dict]:\n    \"\"\"\n    Bottom-up replay detector following Widloski &amp; Foster (2022) \"Replay detection and analysis\".\n\n    Parameters\n    ----------\n    posterior : np.ndarray\n        Shape (n_time, n_space_bins) posterior probability for each time window.\n    time_centers : np.ndarray\n        Center time of each posterior time bin (length n_time) in seconds.\n    bin_centers : np.ndarray\n        Spatial bin centers (length n_space_bins) in same units as thresholds (cm).\n    speed_times, speed_values : np.ndarray\n        Time stamps and speed values (cm/s) for the animal; used to interpolate\n        speed at time_centers.\n    window_dt : Optional[float]\n        Duration of each posterior time bin. If None, computed from time_centers diff.\n    speed_thresh : float\n        Speed threshold for filtering candidate replays (cm/s).\n    spread_thresh : float\n        Spread threshold for filtering candidate replays (cm).\n    com_jump_thresh : float\n        Center-of-mass jump threshold for filtering candidate replays (cm).\n    merge_spatial_gap : float\n        Spatial gap threshold for merging candidate replays (cm).\n    merge_time_gap : float\n        Temporal gap threshold for merging candidate replays (s).\n    min_duration : float\n        Minimum duration for keeping candidate replays (s).\n    dispersion_thresh : float\n        Dispersion threshold (mean absolute deviation of COM across sequence) for labeling replays (cm).\n\n    Returns\n    -------\n    replays : np.ndarray\n        Array of replay events that passed dispersion threshold; shape (k,2) start/end times.\n    meta : dict\n        Metadata dict with keys:\n         - 'candidates': candidate subsequences before dispersion filter; list of dicts with keys:\n            - 'start_time': start time of each candidate\n            - 'end_time': end time of each candidate\n            - 'start_idx': start index of each candidate\n            - 'end_idx': end index of each candidate\n            - 'duration': duration of each candidate (s)\n            - 'D2': dispersion (RMS radial deviation) per candidate (cm)\n            - 'com_trace': NaN-removed sequence of center-of-mass positions used for metrics\n            - 'path_length': path length (sum of consecutive COM step distances) across valid bins (cm)\n            - 'maxJump_NaN': maximum consecutive-step jump computed on the raw COM slice (may be NaN)\n            - 'maxJump_NaNremoved': maximum consecutive-step jump computed on the NaN-removed COM trace (cm)\n            - 'maxJump_NaNremoved_time': maximum temporal gap between valid (NaN-removed) samples (s)\n            - 'posteriorSpreadMax': maximum per-bin posterior spread across the candidate (cm)\n            - 'posteriorSpreadMean': mean per-bin posterior spread across the candidate (cm)\n         - 'com': center-of-mass per kept bin (array of shape (n_time, ) or (n_time,2))\n         - 'spread': posterior spread per kept bin (array of length n_time)\n         - 'mask': boolean mask of kept bins (array of length n_time)\n\n    Notes\n    -----\n    This implementation assumes 1D and 2D spatial decoding.\n    \"\"\"\n    posterior = np.asarray(posterior)\n    time_centers = np.asarray(time_centers)\n\n    # Support posteriors where time is the last axis (space..., time)\n    # Move time axis to front so internal code works with shape (n_time, ...)\n    if posterior.ndim &gt;= 2 and posterior.shape[0] != time_centers.shape[0]:\n        if posterior.shape[-1] == time_centers.shape[0]:\n            posterior = np.moveaxis(posterior, -1, 0)\n        else:\n            raise ValueError(\"posterior time dimension does not match time_centers\")\n    # bin_centers may be a 1D array for 1D posteriors or a tuple (y_centers, x_centers)\n    # for 2D posteriors. Don't force-cast a tuple into an ndarray.\n    if posterior.ndim == 3:\n        if not (isinstance(bin_centers, (tuple, list)) and len(bin_centers) == 2):\n            raise ValueError(\n                \"For 2D posterior, bin_centers must be (y_centers, x_centers)\"\n            )\n        y_centers, x_centers = bin_centers\n    else:\n        bin_centers = np.asarray(bin_centers)\n\n    if posterior.shape[0] != time_centers.shape[0]:\n        raise ValueError(\n            \"posterior and time_centers must have matching first dimension\"\n        )\n\n    n_time = posterior.shape[0]\n\n    # bin duration\n    if window_dt is None:\n        if n_time &gt; 1:\n            window_dt = np.median(np.diff(time_centers))\n        else:\n            window_dt = 0.0\n\n    # compute COMs and spread; support 1D and 2D posteriors\n    if posterior.ndim == 2:\n        # 1D posterior: shape (n_time, n_space)\n        com = position_estimator(posterior, bin_centers, method=method)\n\n        # compute posterior spread (weighted std)\n        spread = np.full(n_time, np.nan)\n        for ti in range(n_time):\n            P = posterior[ti]\n            s = np.sum(P)\n            if s &gt; 0:\n                Pn = P / s\n                mu = np.sum(bin_centers * Pn)\n                spread[ti] = np.sqrt(np.sum(((bin_centers - mu) ** 2) * Pn))\n\n        # compute COM jump sizes (between consecutive bins)\n        com_jump = np.full(n_time, np.nan)\n        com_diff = np.abs(np.diff(com, prepend=np.nan))\n        com_jump[1:] = com_diff[1:]\n\n    elif posterior.ndim == 3:\n        # 2D posterior: shape (n_time, ny, nx)\n        y_centers, x_centers = bin_centers\n        xx, yy = np.meshgrid(x_centers, y_centers, indexing=\"xy\")\n\n        com = np.full((n_time, 2), np.nan)\n        spread = np.full(n_time, np.nan)\n        for ti in range(n_time):\n            P = posterior[ti]\n            s = np.sum(P)\n            if s &gt; 0:\n                Pn = P / s\n                mu_x = np.sum(xx * Pn)\n                mu_y = np.sum(yy * Pn)\n                com[ti, 0] = mu_x\n                com[ti, 1] = mu_y\n                # RMS distance from mean\n                spread[ti] = np.sqrt(np.sum(((xx - mu_x) ** 2 + (yy - mu_y) ** 2) * Pn))\n\n        # compute COM jump sizes (Euclidean distance between consecutive COMs)\n        com_jump = np.full(n_time, np.nan)\n        for ti in range(1, n_time):\n            if not np.any(np.isnan(com[ti - 1])) and not np.any(np.isnan(com[ti])):\n                com_jump[ti] = np.linalg.norm(com[ti] - com[ti - 1])\n    else:\n        raise ValueError(\"posterior must be 2D (time,x) or 3D (time,y,x)\")\n\n    # interpolate speed at time_centers\n    speed = np.interp(time_centers, speed_times, speed_values)\n\n    # treat NaN COM-jumps (e.g. first bin) as failing the com_jump criterion\n    # to avoid letting NaNs silently pass (np.nan_to_num -&gt; 0). Set NaNs to +inf\n    # so they are excluded when compared to com_jump_thresh.\n    com_jump = np.array(com_jump, copy=True)\n    com_jump[np.isnan(com_jump)] = np.inf\n\n    # mask time bins that satisfy all three criteria\n    mask = (\n        (speed &lt; speed_thresh) &amp; (spread &lt; spread_thresh) &amp; (com_jump &lt; com_jump_thresh)\n    )\n\n    # find contiguous subsequences of True in mask\n    subseqs = []\n    if np.any(mask):\n        edges = np.diff(mask.astype(int))\n        starts = np.where(edges == 1)[0] + 1\n        ends = np.where(edges == -1)[0] + 1\n        if mask[0]:\n            starts = np.concatenate(([0], starts))\n        if mask[-1]:\n            ends = np.concatenate((ends, [n_time]))\n\n        for s, e in zip(starts, ends):\n            subseqs.append(\n                {\n                    \"start_idx\": s,\n                    \"end_idx\": e,\n                    \"start_time\": time_centers[s],\n                    \"end_time\": time_centers[e - 1],\n                }\n            )\n\n    # merge neighboring subsequences based on spatial and temporal gaps\n    merged = []\n    for seq in subseqs:\n        if not merged:\n            merged.append(seq)\n            continue\n        prev = merged[-1]\n        temporal_gap = seq[\"start_time\"] - prev[\"end_time\"]\n        # compute spatial gap differently for 1D vs 2D COM\n        if posterior.ndim == 2:\n            spatial_gap = np.abs(com[seq[\"start_idx\"]] - com[prev[\"end_idx\"] - 1])\n        else:\n            # com entries are 2D vectors (mu_x, mu_y)\n            a = com[seq[\"start_idx\"]]\n            b = com[prev[\"end_idx\"] - 1]\n            if np.any(np.isnan(a)) or np.any(np.isnan(b)):\n                spatial_gap = np.inf\n            else:\n                spatial_gap = float(np.linalg.norm(a - b))\n\n        if temporal_gap &lt;= merge_time_gap and spatial_gap &lt;= merge_spatial_gap:\n            # merge\n            prev[\"end_idx\"] = seq[\"end_idx\"]\n            prev[\"end_time\"] = seq[\"end_time\"]\n        else:\n            merged.append(seq)\n\n    # candidate sequences: duration &gt; min_duration\n    candidates = []\n    for seq in merged:\n        duration = (\n            seq[\"end_time\"] - seq[\"start_time\"] + (window_dt if window_dt &gt; 0 else 0.0)\n        )\n        if duration &gt;= min_duration:\n            # record COM trace for sequence and compute metrics on NaN-removed trace\n            idxs = np.arange(seq[\"start_idx\"], seq[\"end_idx\"])\n            com_trace = com[idxs]\n\n            # remove NaN entries (bins with no posterior mass)\n            if posterior.ndim == 2:\n                # 1D case: com_trace is 1D array\n                valid_mask = ~np.isnan(com_trace)\n                com_trace_valid = com_trace[valid_mask]\n            else:\n                # 2D case: com_trace is (n_bins, 2)\n                valid_mask = ~np.isnan(com_trace).any(axis=1)\n                com_trace_valid = com_trace[valid_mask]\n\n            # dispersion D2 = RMS radial deviation from centroid (match MATLAB)\n            if com_trace_valid.size == 0:\n                D2 = np.nan\n                centroid = np.nan\n            else:\n                if posterior.ndim == 2:\n                    centroid = np.nanmean(com_trace_valid)\n                    D2 = np.sqrt(np.nanmean((com_trace_valid - centroid) ** 2))\n                else:\n                    centroid = np.nanmean(com_trace_valid, axis=0)\n                    diffs = np.linalg.norm(com_trace_valid - centroid, axis=1)\n                    D2 = np.sqrt(np.nanmean(diffs**2))\n\n            # compute path length (sum of Euclidean distances between consecutive valid COM points)\n            if com_trace_valid.size == 0:\n                path_length = 0.0\n            else:\n                if com_trace_valid.ndim == 1:\n                    steps = np.abs(np.diff(com_trace_valid))\n                else:\n                    steps = np.linalg.norm(np.diff(com_trace_valid, axis=0), axis=1)\n                path_length = float(np.nansum(steps))\n\n            # compute maxJump on raw (may contain NaNs) and on NaN-removed trace\n            # For raw trace: compute diffs and allow NaNs to propagate (max may be NaN)\n            try:\n                if com_trace.size == 0:\n                    maxJump_NaN = np.nan\n                else:\n                    if com_trace.ndim == 1:\n                        raw_steps = np.abs(np.diff(com_trace))\n                    else:\n                        raw_steps = np.linalg.norm(np.diff(com_trace, axis=0), axis=1)\n                    maxJump_NaN = (\n                        float(np.nanmax(raw_steps)) if raw_steps.size &gt; 0 else np.nan\n                    )\n            except Exception:\n                maxJump_NaN = np.nan\n\n            # For NaN-removed trace\n            if com_trace_valid.size == 0:\n                maxJump_NaNremoved = np.nan\n                maxJump_NaNremoved_time = np.nan\n            else:\n                if com_trace_valid.ndim == 1:\n                    valid_steps = np.abs(np.diff(com_trace_valid))\n                else:\n                    valid_steps = np.linalg.norm(\n                        np.diff(com_trace_valid, axis=0), axis=1\n                    )\n                maxJump_NaNremoved = (\n                    float(np.nanmax(valid_steps)) if valid_steps.size &gt; 0 else np.nan\n                )\n\n                # compute times of valid samples to get max time gap\n                times_seq = time_centers[idxs]\n                times_valid = times_seq[valid_mask]\n                if times_valid.size &gt; 1:\n                    maxJump_NaNremoved_time = float(np.max(np.diff(times_valid)))\n                else:\n                    maxJump_NaNremoved_time = np.nan\n\n            # posteriorSpreadMax and posteriorSpreadMean for the sequence (NaN-removed)\n            seq_spreads = spread[idxs]\n            seq_spreads_valid = seq_spreads[~np.isnan(seq_spreads)]\n            if seq_spreads_valid.size &gt; 0:\n                posteriorSpreadMax = float(np.max(seq_spreads_valid))\n                posteriorSpreadMean = float(np.mean(seq_spreads_valid))\n            else:\n                posteriorSpreadMax = np.nan\n                posteriorSpreadMean = np.nan\n\n            candidates.append(\n                {\n                    \"start_time\": seq[\"start_time\"],\n                    \"end_time\": seq[\"end_time\"],\n                    \"start_idx\": seq[\"start_idx\"],\n                    \"end_idx\": seq[\"end_idx\"],\n                    \"duration\": duration,\n                    \"D2\": D2,\n                    \"com_trace\": com_trace_valid,\n                    \"path_length\": path_length,\n                    \"maxJump_NaN\": maxJump_NaN,\n                    \"maxJump_NaNremoved\": maxJump_NaNremoved,\n                    \"maxJump_NaNremoved_time\": maxJump_NaNremoved_time,\n                    \"posteriorSpreadMax\": posteriorSpreadMax,\n                    \"posteriorSpreadMean\": posteriorSpreadMean,\n                }\n            )\n\n    # select replays by dispersion threshold\n    replays = []\n    for c in candidates:\n        if c[\"D2\"] &gt; dispersion_thresh:\n            replays.append([c[\"start_time\"], c[\"end_time\"]])\n\n    replays = np.array(replays)\n\n    meta = {\n        \"candidates\": candidates,\n        \"com\": com,\n        \"spread\": spread,\n        \"mask\": mask,\n        \"window_dt\": window_dt,\n    }\n\n    return replays, meta\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.compute_bias_matrix_optimized_","title":"<code>compute_bias_matrix_optimized_(spike_times, neuron_ids, total_neurons)</code>","text":"<p>Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.</p> <p>Parameters: - spike_times: list or array of spike times for the sequence. - neuron_ids: list or array of neuron identifiers corresponding to spike_times. - total_neurons: total number of neurons being considered.</p> <p>Returns: - bias_matrix: A matrix of size (total_neurons, total_neurons) representing the bias.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>@jit(nopython=True)\ndef compute_bias_matrix_optimized_(spike_times, neuron_ids, total_neurons):\n    \"\"\"\n    Optimized computation of the bias matrix B_k for a given sequence of spikes using vectorized operations.\n\n    Parameters:\n    - spike_times: list or array of spike times for the sequence.\n    - neuron_ids: list or array of neuron identifiers corresponding to spike_times.\n    - total_neurons: total number of neurons being considered.\n\n    Returns:\n    - bias_matrix: A matrix of size (total_neurons, total_neurons) representing the bias.\n    \"\"\"\n\n    # Create an empty bias matrix\n    bias_matrix = np.full((total_neurons, total_neurons), 0.5)\n\n    # Create boolean masks for all neurons in advance\n    masks = [neuron_ids == i for i in range(total_neurons)]\n\n    # Iterate over each pair of neurons\n    for i in range(total_neurons):\n        spikes_i = spike_times[masks[i]]\n        size_i = spikes_i.size\n\n        if size_i == 0:\n            continue  # Skip if neuron i has no spikes\n\n        for j in range(total_neurons):\n            if i == j:\n                continue  # Skip self-correlation\n\n            spikes_j = spike_times[masks[j]]\n            size_j = spikes_j.size\n\n            if size_j == 0:\n                continue  # Skip if neuron j has no spikes\n\n            crosscorr = crossCorr(spikes_i, spikes_j, 0.001, 100)\n\n            # Count how many times neuron i spikes before neuron j\n            before_count = crosscorr[:50].sum()\n            after_count = crosscorr[51:].sum()\n\n            # Only compute bias if we have any spikes between this neuron pair\n            # Otherwise, keep the default neutral value of 0.5\n            if before_count + after_count &gt; 0:\n                bias_matrix[i, j] = before_count / (before_count + after_count)\n            # else: keep default 0.5 (neither forward nor reverse bias)\n\n    return bias_matrix\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.position_estimator","title":"<code>position_estimator(posterior_prob, *bin_centers, method='com')</code>","text":"<p>Decode 1D or 2D position from posterior probability distributions.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_prob</code> <code>ndarray</code> <p>Posterior probability distributions over spatial bins for each time bin. For 1D: shape (n_time_bins, n_bins) For 2D: shape (n_time_bins, n_y_bins, n_x_bins) Each time slice should contain non-negative values.</p> required <code>*bin_centers</code> <code>ndarray</code> <p>Coordinate values for the center of each spatial bin. For 1D: single array of shape (n_bins,) For 2D: two arrays - y_bin_centers of shape (n_y_bins,) and         x_bin_centers of shape (n_x_bins,)</p> <code>()</code> <code>method</code> <code>str</code> <p>Decoding method to use. Options are: - \"com\" : Center of mass (weighted average) (default) - \"max\" : Maximum a posteriori (position of maximum probability)</p> <code>'com'</code> <p>Returns:</p> Name Type Description <code>position</code> <code>ndarray</code> <p>Decoded positions for each time bin. For 1D: shape (n_time_bins,) containing position coordinates For 2D: shape (n_time_bins, 2) where position[:, 0] contains         x-coordinates and position[:, 1] contains y-coordinates Time bins with zero probability sum are filled with NaN.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If method is not \"com\" or \"max\", or if dimensions don't match expectations.</p> Notes <p>For the center of mass method, probabilities are normalized before computing the weighted average. For time bins where all probabilities are zero, the decoded position is set to NaN.</p> <p>The function automatically detects whether to perform 1D or 2D decoding based on the shape of the posterior_prob array and number of bin_centers provided.</p> <p>Examples:</p> <p>1D example:</p> <pre><code>&gt;&gt;&gt; posterior_1d = np.random.rand(10, 20)  # 10 time bins, 20 spatial bins\n&gt;&gt;&gt; bin_centers = np.linspace(0, 19, 20)\n&gt;&gt;&gt; positions = decode_position(posterior_1d, bin_centers)\n&gt;&gt;&gt; positions.shape\n(10,)\n</code></pre> <p>2D example:</p> <pre><code>&gt;&gt;&gt; posterior_2d = np.random.rand(10, 5, 4)  # 10 time bins, 5x4 spatial grid\n&gt;&gt;&gt; y_centers = np.linspace(0, 4, 5)\n&gt;&gt;&gt; x_centers = np.linspace(0, 3, 4)\n&gt;&gt;&gt; positions = decode_position(posterior_2d, y_centers, x_centers)\n&gt;&gt;&gt; positions.shape\n(10, 2)\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def position_estimator(\n    posterior_prob: np.ndarray, *bin_centers: np.ndarray, method: str = \"com\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode 1D or 2D position from posterior probability distributions.\n\n    Parameters\n    ----------\n    posterior_prob : np.ndarray\n        Posterior probability distributions over spatial bins for each time bin.\n        For 1D: shape (n_time_bins, n_bins)\n        For 2D: shape (n_time_bins, n_y_bins, n_x_bins)\n        Each time slice should contain non-negative values.\n    *bin_centers : np.ndarray\n        Coordinate values for the center of each spatial bin.\n        For 1D: single array of shape (n_bins,)\n        For 2D: two arrays - y_bin_centers of shape (n_y_bins,) and\n                x_bin_centers of shape (n_x_bins,)\n    method : str, optional\n        Decoding method to use. Options are:\n        - \"com\" : Center of mass (weighted average) (default)\n        - \"max\" : Maximum a posteriori (position of maximum probability)\n\n    Returns\n    -------\n    position : np.ndarray\n        Decoded positions for each time bin.\n        For 1D: shape (n_time_bins,) containing position coordinates\n        For 2D: shape (n_time_bins, 2) where position[:, 0] contains\n                x-coordinates and position[:, 1] contains y-coordinates\n        Time bins with zero probability sum are filled with NaN.\n\n    Raises\n    ------\n    ValueError\n        If method is not \"com\" or \"max\", or if dimensions don't match expectations.\n\n    Notes\n    -----\n    For the center of mass method, probabilities are normalized before computing\n    the weighted average. For time bins where all probabilities are zero,\n    the decoded position is set to NaN.\n\n    The function automatically detects whether to perform 1D or 2D decoding\n    based on the shape of the posterior_prob array and number of bin_centers provided.\n\n    Examples\n    --------\n    1D example:\n    &gt;&gt;&gt; posterior_1d = np.random.rand(10, 20)  # 10 time bins, 20 spatial bins\n    &gt;&gt;&gt; bin_centers = np.linspace(0, 19, 20)\n    &gt;&gt;&gt; positions = decode_position(posterior_1d, bin_centers)\n    &gt;&gt;&gt; positions.shape\n    (10,)\n\n    2D example:\n    &gt;&gt;&gt; posterior_2d = np.random.rand(10, 5, 4)  # 10 time bins, 5x4 spatial grid\n    &gt;&gt;&gt; y_centers = np.linspace(0, 4, 5)\n    &gt;&gt;&gt; x_centers = np.linspace(0, 3, 4)\n    &gt;&gt;&gt; positions = decode_position(posterior_2d, y_centers, x_centers)\n    &gt;&gt;&gt; positions.shape\n    (10, 2)\n    \"\"\"\n    if method not in [\"com\", \"max\"]:\n        raise ValueError(f\"Method '{method}' not recognized. Use 'com' or 'max'.\")\n\n    n_dims = len(posterior_prob.shape) - 1  # Subtract time dimension\n    n_time_bins = posterior_prob.shape[0]\n\n    if n_dims == 1:\n        return _position_estimator_1d(\n            posterior_prob, bin_centers[0], method, n_time_bins\n        )\n    elif n_dims == 2:\n        if len(bin_centers) != 2:\n            raise ValueError(\n                \"For 2D decoding, provide exactly 2 bin_centers arrays (y_centers, x_centers)\"\n            )\n        return _position_estimator_2d(\n            posterior_prob, bin_centers[0], bin_centers[1], method, n_time_bins\n        )\n    else:\n        raise ValueError(f\"Only 1D and 2D decoding supported, got {n_dims}D\")\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.shuffle_and_score","title":"<code>shuffle_and_score(posterior_array, w, normalize, tc, ds, dp)</code>","text":"<p>Shuffle the posterior array and compute scores and weighted correlations.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_array</code> <code>ndarray</code> <p>The posterior probability array.</p> required <code>w</code> <code>ndarray</code> <p>Weights array.</p> required <code>normalize</code> <code>bool</code> <p>Whether to normalize the scores.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, float, float]</code> <p>Scores and weighted correlations for time-swapped and column-cycled arrays.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def shuffle_and_score(\n    posterior_array: np.ndarray,\n    w: np.ndarray,\n    normalize: bool,\n    tc: float,\n    ds: float,\n    dp: float,\n) -&gt; Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Shuffle the posterior array and compute scores and weighted correlations.\n\n    Parameters\n    ----------\n    posterior_array : np.ndarray\n        The posterior probability array.\n    w : np.ndarray\n        Weights array.\n    normalize : bool\n        Whether to normalize the scores.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, float, float]\n        Scores and weighted correlations for time-swapped and column-cycled arrays.\n    \"\"\"\n\n    posterior_ts = replay.time_swap_array(posterior_array)\n    posterior_cs = replay.column_cycle_array(posterior_array)\n\n    scores_time_swap = replay.trajectory_score_array(\n        posterior=posterior_ts, w=w, normalize=normalize\n    )\n    scores_col_cycle = replay.trajectory_score_array(\n        posterior=posterior_cs, w=w, normalize=normalize\n    )\n\n    weighted_corr_time_swap = weighted_correlation(posterior_ts)\n    weighted_corr_col_cycle = weighted_correlation(posterior_cs)\n\n    return (\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.trajectory_score_bst","title":"<code>trajectory_score_bst(bst, tuningcurve, w=None, n_shuffles=1000, weights=None, normalize=False, parallel=True)</code>","text":"<p>Calculate trajectory scores and weighted correlations for Bayesian spike train decoding.</p> <p>Parameters:</p> Name Type Description Default <code>bst</code> <code>BinnedSpikeTrainArray</code> <p>Binned spike train object.</p> required <code>tuningcurve</code> <code>TuningCurve1D</code> <p>Tuning curve object.</p> required <code>w</code> <code>Optional[int]</code> <p>Window size, by default None.</p> <code>None</code> <code>n_shuffles</code> <code>int</code> <p>Number of shuffles, by default 1000.</p> <code>1000</code> <code>weights</code> <code>Optional[ndarray]</code> <p>Weights array, by default None.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to normalize the scores, by default False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[</code> <p>Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray],</p> <code>]</code> <p>Scores and weighted correlations for original, time-swapped, and column-cycled arrays.</p> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def trajectory_score_bst(\n    bst: BinnedSpikeTrainArray,\n    tuningcurve: TuningCurve1D,\n    w: Optional[int] = None,\n    n_shuffles: int = 1000,\n    weights: Optional[np.ndarray] = None,\n    normalize: bool = False,\n    parallel: bool = True,\n) -&gt; Union[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    Tuple[np.ndarray, np.ndarray],\n]:\n    \"\"\"\n    Calculate trajectory scores and weighted correlations for Bayesian spike train decoding.\n\n    Parameters\n    ----------\n    bst : BinnedSpikeTrainArray\n        Binned spike train object.\n    tuningcurve : TuningCurve1D\n        Tuning curve object.\n    w : Optional[int], optional\n        Window size, by default None.\n    n_shuffles : int, optional\n        Number of shuffles, by default 1000.\n    weights : Optional[np.ndarray], optional\n        Weights array, by default None.\n    normalize : bool, optional\n        Whether to normalize the scores, by default False.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n\n    Returns\n    -------\n    Union[\n        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n        Tuple[np.ndarray, np.ndarray],\n    ]\n        Scores and weighted correlations for original, time-swapped, and column-cycled arrays.\n    \"\"\"\n\n    if w is None:\n        w = 0\n    if not float(w).is_integer:\n        raise ValueError(\"w has to be an integer!\")\n\n    if float(n_shuffles).is_integer:\n        n_shuffles = int(n_shuffles)\n    else:\n        raise ValueError(\"n_shuffles must be an integer!\")\n\n    posterior, bdries, _, _ = decode(bst=bst, ratemap=tuningcurve)\n\n    num_cores = 1\n\n    if parallel:\n        # all but one core\n        num_cores = multiprocessing.cpu_count() - 1\n\n    ds, dp = bst.ds, np.diff(tuningcurve.bins)[0]\n\n    (\n        scores,\n        weighted_corr,\n        scores_time_swap,\n        scores_col_cycle,\n        weighted_corr_time_swap,\n        weighted_corr_col_cycle,\n    ) = zip(\n        *Parallel(n_jobs=num_cores)(\n            delayed(_shuffle_and_score)(\n                posterior[:, bdries[idx] : bdries[idx + 1]],\n                tuningcurve,\n                w,\n                normalize,\n                ds,\n                dp,\n                n_shuffles,\n            )\n            for idx in range(bst.n_epochs)\n        )\n    )\n\n    if n_shuffles &gt; 0:\n        return (\n            np.array(scores),\n            np.array(weighted_corr),\n            np.array(scores_time_swap).T,\n            np.array(scores_col_cycle).T,\n            np.array(weighted_corr_time_swap).T,\n            np.array(weighted_corr_col_cycle).T,\n        )\n    return scores, weighted_corr\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.weighted_corr_2d","title":"<code>weighted_corr_2d(weights, x_coords=None, y_coords=None, time_coords=None)</code>","text":"<p>Calculate the weighted correlation between the X and Y dimensions of the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>ndarray</code> <p>A matrix of weights.</p> required <code>x_coords</code> <code>Optional[ndarray]</code> <p>X-values for each column and row, by default None.</p> <code>None</code> <code>y_coords</code> <code>Optional[ndarray]</code> <p>Y-values for each column and row, by default None.</p> <code>None</code> <code>time_coords</code> <code>Optional[ndarray]</code> <p>Time-values for each column and row, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, ndarray, ndarray, float, float, float, float]</code> <p>The weighted correlation coefficient, x trajectory, y trajectory, slope_x, slope_y, mean_x, mean_y.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; weights = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n&gt;&gt;&gt; x_coords = np.array([0, 1])\n&gt;&gt;&gt; y_coords = np.array([0, 1])\n&gt;&gt;&gt; time_coords = np.array([0, 1, 2])\n&gt;&gt;&gt; weighted_corr_2d(weights, x_coords, y_coords, time_coords)\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def weighted_corr_2d(\n    weights: np.ndarray,\n    x_coords: Optional[np.ndarray] = None,\n    y_coords: Optional[np.ndarray] = None,\n    time_coords: Optional[np.ndarray] = None,\n) -&gt; Tuple[float, np.ndarray, np.ndarray, float, float, float, float]:\n    \"\"\"\n    Calculate the weighted correlation between the X and Y dimensions of the matrix.\n\n    Parameters\n    ----------\n    weights : np.ndarray\n        A matrix of weights.\n    x_coords : Optional[np.ndarray], optional\n        X-values for each column and row, by default None.\n    y_coords : Optional[np.ndarray], optional\n        Y-values for each column and row, by default None.\n    time_coords : Optional[np.ndarray], optional\n        Time-values for each column and row, by default None.\n\n    Returns\n    -------\n    Tuple[float, np.ndarray, np.ndarray, float, float, float, float]\n        The weighted correlation coefficient, x trajectory, y trajectory,\n        slope_x, slope_y, mean_x, mean_y.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; weights = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n    &gt;&gt;&gt; x_coords = np.array([0, 1])\n    &gt;&gt;&gt; y_coords = np.array([0, 1])\n    &gt;&gt;&gt; time_coords = np.array([0, 1, 2])\n    &gt;&gt;&gt; weighted_corr_2d(weights, x_coords, y_coords, time_coords)\n\n    \"\"\"\n    x_dim, y_dim, t_dim = weights.shape\n    dtype = weights.dtype\n\n    x_coords = (\n        np.arange(x_dim, dtype=dtype)\n        if x_coords is None\n        else np.asarray(x_coords, dtype=dtype)\n    )\n    y_coords = (\n        np.arange(y_dim, dtype=dtype)\n        if y_coords is None\n        else np.asarray(y_coords, dtype=dtype)\n    )\n    time_coords = (\n        np.arange(t_dim, dtype=dtype)\n        if time_coords is None\n        else np.asarray(time_coords, dtype=dtype)\n    )\n\n    return __weighted_corr_2d_jit(weights, x_coords, y_coords, time_coords)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/replay/#neuro_py.ensemble.replay.weighted_correlation","title":"<code>weighted_correlation(posterior, time=None, place_bin_centers=None, return_full_output=False)</code>","text":"<p>Calculate the weighted correlation between time and place bin centers using a posterior probability matrix.</p> <p>Parameters:</p> Name Type Description Default <code>posterior</code> <code>ndarray</code> <p>A 2D numpy array representing the posterior probability matrix.</p> required <code>time</code> <code>Optional[ndarray]</code> <p>A 1D numpy array representing the time bins, by default None.</p> <code>None</code> <code>place_bin_centers</code> <code>Optional[ndarray]</code> <p>A 1D numpy array representing the place bin centers, by default None.</p> <code>None</code> <code>return_full_output</code> <code>bool</code> <p>If True, return trajectory, slopes, means, and intercept in addition to correlation, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[float, Tuple[float, ndarray, float, float, float, float]]</code> <p>If return_full_output is False:     The weighted correlation coefficient (float). If return_full_output is True:     Tuple of (correlation, place_trajectory, slope_place, mean_time, mean_place, intercept_place)     where:     - correlation: weighted correlation coefficient     - place_trajectory: place position at each time bin     - slope_place: slope of place vs time     - mean_time: weighted mean of time     - mean_place: weighted mean of place     - intercept_place: intercept of linear relationship (place = intercept + slope_place * time)</p> <p>Examples:</p> <p>Basic usage with just a posterior matrix:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; # Create a synthetic posterior with forward replay pattern\n&gt;&gt;&gt; n_place_bins, n_time_bins = 20, 10\n&gt;&gt;&gt; posterior = np.zeros((n_place_bins, n_time_bins))\n&gt;&gt;&gt; for t in range(n_time_bins):\n...     posterior[2*t:2*t+3, t] = 1.0  # diagonal pattern\n&gt;&gt;&gt; correlation = weighted_correlation(posterior)\n&gt;&gt;&gt; print(f\"Correlation: {correlation:.3f}\")\n</code></pre> <p>With custom time and place bin centers:</p> <pre><code>&gt;&gt;&gt; time = np.linspace(0, 1, n_time_bins)  # 1 second duration\n&gt;&gt;&gt; place_bin_centers = np.linspace(0, 100, n_place_bins)  # 100 cm track\n&gt;&gt;&gt; correlation = weighted_correlation(posterior, time, place_bin_centers)\n</code></pre> <p>Getting full output including trajectory and slope:</p> <pre><code>&gt;&gt;&gt; corr, traj, slope, mean_t, mean_p, intercept = weighted_correlation(\n...     posterior, time, place_bin_centers, return_full_output=True\n... )\n&gt;&gt;&gt; print(f\"Replay speed: {slope:.1f} cm/s\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.imshow(\n...    posterior,\n...    aspect=\"auto\",\n...    origin=\"lower\",\n...    extent=[time[0], time[-1], place_bin_centers[0], place_bin_centers[-1]],\n...   cmap=\"bone_r\"\n... )\n&gt;&gt;&gt; plt.colorbar(label=\"Posterior Probability Density\")\n&gt;&gt;&gt; plt.plot(time, slope * time + intercept, color=\"red\", linewidth=2, label=\"fit line\")\n&gt;&gt;&gt; plt.legend()\n&gt;&gt;&gt; plt.xlabel(\"Time (s)\")\n</code></pre> Source code in <code>neuro_py/ensemble/replay.py</code> <pre><code>def weighted_correlation(\n    posterior: np.ndarray,\n    time: Optional[np.ndarray] = None,\n    place_bin_centers: Optional[np.ndarray] = None,\n    return_full_output: bool = False,\n) -&gt; Union[float, Tuple[float, np.ndarray, float, float, float, float]]:\n    \"\"\"\n    Calculate the weighted correlation between time and place bin centers using a posterior probability matrix.\n\n    Parameters\n    ----------\n    posterior : np.ndarray\n        A 2D numpy array representing the posterior probability matrix.\n    time : Optional[np.ndarray], optional\n        A 1D numpy array representing the time bins, by default None.\n    place_bin_centers : Optional[np.ndarray], optional\n        A 1D numpy array representing the place bin centers, by default None.\n    return_full_output : bool, optional\n        If True, return trajectory, slopes, means, and intercept in addition to correlation, by default False.\n    Returns\n    -------\n    Union[float, Tuple[float, np.ndarray, float, float, float, float]]\n        If return_full_output is False:\n            The weighted correlation coefficient (float).\n        If return_full_output is True:\n            Tuple of (correlation, place_trajectory, slope_place, mean_time, mean_place, intercept_place)\n            where:\n            - correlation: weighted correlation coefficient\n            - place_trajectory: place position at each time bin\n            - slope_place: slope of place vs time\n            - mean_time: weighted mean of time\n            - mean_place: weighted mean of place\n            - intercept_place: intercept of linear relationship (place = intercept + slope_place * time)\n\n    Examples\n    --------\n    Basic usage with just a posterior matrix:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; # Create a synthetic posterior with forward replay pattern\n    &gt;&gt;&gt; n_place_bins, n_time_bins = 20, 10\n    &gt;&gt;&gt; posterior = np.zeros((n_place_bins, n_time_bins))\n    &gt;&gt;&gt; for t in range(n_time_bins):\n    ...     posterior[2*t:2*t+3, t] = 1.0  # diagonal pattern\n    &gt;&gt;&gt; correlation = weighted_correlation(posterior)\n    &gt;&gt;&gt; print(f\"Correlation: {correlation:.3f}\")\n\n    With custom time and place bin centers:\n\n    &gt;&gt;&gt; time = np.linspace(0, 1, n_time_bins)  # 1 second duration\n    &gt;&gt;&gt; place_bin_centers = np.linspace(0, 100, n_place_bins)  # 100 cm track\n    &gt;&gt;&gt; correlation = weighted_correlation(posterior, time, place_bin_centers)\n\n    Getting full output including trajectory and slope:\n\n    &gt;&gt;&gt; corr, traj, slope, mean_t, mean_p, intercept = weighted_correlation(\n    ...     posterior, time, place_bin_centers, return_full_output=True\n    ... )\n    &gt;&gt;&gt; print(f\"Replay speed: {slope:.1f} cm/s\")\n\n    &gt;&gt;&gt; plt.imshow(\n    ...    posterior,\n    ...    aspect=\"auto\",\n    ...    origin=\"lower\",\n    ...    extent=[time[0], time[-1], place_bin_centers[0], place_bin_centers[-1]],\n    ...   cmap=\"bone_r\"\n    ... )\n    &gt;&gt;&gt; plt.colorbar(label=\"Posterior Probability Density\")\n    &gt;&gt;&gt; plt.plot(time, slope * time + intercept, color=\"red\", linewidth=2, label=\"fit line\")\n    &gt;&gt;&gt; plt.legend()\n    &gt;&gt;&gt; plt.xlabel(\"Time (s)\")\n    \"\"\"\n\n    def _m(x, w) -&gt; float:\n        \"\"\"Weighted Mean\"\"\"\n        return np.sum(x * w) / np.sum(w)\n\n    def _cov(x, y, w) -&gt; float:\n        \"\"\"Weighted Covariance\"\"\"\n        return np.sum(w * (x - _m(x, w)) * (y - _m(y, w))) / np.sum(w)\n\n    def _corr(x, y, w) -&gt; float:\n        \"\"\"Weighted Correlation\"\"\"\n        return _cov(x, y, w) / np.sqrt(_cov(x, x, w) * _cov(y, y, w))\n\n    if time is None:\n        time = np.arange(posterior.shape[1])\n    if place_bin_centers is None:\n        place_bin_centers = np.arange(posterior.shape[0])\n\n    time = np.asarray(time)\n    place_bin_centers = place_bin_centers.squeeze()\n    posterior = np.array(posterior, copy=True)\n    posterior[np.isnan(posterior)] = 0.0\n\n    correlation = _corr(\n        time[:, np.newaxis], place_bin_centers[np.newaxis, :], posterior.T\n    )\n\n    if not return_full_output:\n        return correlation\n\n    # Compute full output (trajectory, slopes, means)\n    weights = posterior.T.flatten()\n    time_2d, place_2d = np.meshgrid(time, place_bin_centers, indexing=\"ij\")\n    time_flat = time_2d.flatten()\n    place_flat = place_2d.flatten()\n\n    # Compute weighted means\n    total_weight = np.sum(weights)\n\n    # Handle degenerate case: no weights\n    if total_weight == 0.0:\n        return (\n            np.nan,\n            np.full_like(time, np.nan),\n            np.nan,\n            np.nan,\n            np.nan,\n            np.nan,\n        )\n\n    mean_time = np.sum(weights * time_flat) / total_weight\n    mean_place = np.sum(weights * place_flat) / total_weight\n\n    # Compute covariances\n    cov_time_place = (\n        np.sum(weights * (time_flat - mean_time) * (place_flat - mean_place))\n        / total_weight\n    )\n    cov_time_time = np.sum(weights * (time_flat - mean_time) ** 2) / total_weight\n\n    # Handle degenerate case: no temporal variance\n    if cov_time_time == 0.0:\n        return (\n            np.nan,\n            np.full_like(time, np.nan),\n            np.nan,\n            mean_time,\n            mean_place,\n            np.nan,\n        )\n\n    # Compute slope and trajectory\n    slope_place = cov_time_place / cov_time_time\n    place_trajectory = mean_place + slope_place * (time - mean_time)\n    intercept_place = mean_place - slope_place * mean_time\n\n    return (\n        correlation,\n        place_trajectory,\n        slope_place,\n        mean_time,\n        mean_place,\n        intercept_place,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/similarity_index/","title":"neuro_py.ensemble.similarity_index","text":""},{"location":"reference/neuro_py/ensemble/similarity_index/#neuro_py.ensemble.similarity_index.similarity_index","title":"<code>similarity_index(patterns, n_shuffles=1000, parallel=True, groups=None, adjust_pvalue=True)</code>","text":"<p>Calculate the similarity index of a set of patterns.</p> <p>To use a quantitative criterion to compare assembly composition, a Similarity Index (SI) was defined as the absolute value of the inner product between the assembly patterns (unitary vectors) of two given assemblies, varying from 0 to 1. Thus, if two assemblies attribute large weights to the same neurons, SI will be large; if assemblies are orthogonal, SI will be zero.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>ndarray</code> <p>List of patterns (n patterns x n neurons).</p> required <code>n_shuffles</code> <code>int</code> <p>Number of shuffles to calculate the similarity index, by default 1000.</p> <code>1000</code> <code>parallel</code> <code>bool</code> <p>Whether to run in parallel, by default True.</p> <code>True</code> <code>groups</code> <code>ndarray</code> <p>List of groups for each pattern (n patterns, ), will return cross-group comparisons by default None.</p> <code>None</code> <code>adjust_pvalue</code> <code>bool</code> <p>Where to adjust p-values to control the false discovery rate.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>si: similarity index (n_combinations,) combos: list of all possible combinations of patterns (n_combinations, 2) pvalues: list of p-values for each pattern combination (n_combinations,)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; patterns = np.random.random_sample((60,20))\n&gt;&gt;&gt; si, combos, pvalues = similarity_index(patterns)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/similarity_index/#neuro_py.ensemble.similarity_index.similarity_index--with-groups","title":"with groups","text":"<pre><code>&gt;&gt;&gt; patterns = np.random.random_sample((60,20))\n&gt;&gt;&gt; groups = np.hstack([np.ones(20), np.ones(40)+1])\n&gt;&gt;&gt; si, combos, pvalues = similarity_index(patterns, groups=groups)\n</code></pre> References <p>Based on Almeida-Filho et al., 2014 to detect similar assemblies.</p> Source code in <code>neuro_py/ensemble/similarity_index.py</code> <pre><code>def similarity_index(\n    patterns: np.ndarray,\n    n_shuffles: int = 1000,\n    parallel: bool = True,\n    groups: np.ndarray = None,\n    adjust_pvalue: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate the similarity index of a set of patterns.\n\n    To use a quantitative criterion to compare assembly composition,\n    a Similarity Index (SI) was defined as the absolute value of the\n    inner product between the assembly patterns (unitary vectors) of\n    two given assemblies, varying from 0 to 1. Thus, if two assemblies\n    attribute large weights to the same neurons, SI will be large;\n    if assemblies are orthogonal, SI will be zero.\n\n    Parameters\n    ----------\n    patterns : np.ndarray\n        List of patterns (n patterns x n neurons).\n    n_shuffles : int, optional\n        Number of shuffles to calculate the similarity index, by default 1000.\n    parallel : bool, optional\n        Whether to run in parallel, by default True.\n    groups : np.ndarray, optional\n        List of groups for each pattern (n patterns, ), will return cross-group comparisons by default None.\n    adjust_pvalue : bool, optional\n        Where to adjust p-values to control the false discovery rate.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        si: similarity index (n_combinations,)\n        combos: list of all possible combinations of patterns (n_combinations, 2)\n        pvalues: list of p-values for each pattern combination (n_combinations,)\n\n    Examples\n    --------\n    &gt;&gt;&gt; patterns = np.random.random_sample((60,20))\n    &gt;&gt;&gt; si, combos, pvalues = similarity_index(patterns)\n\n    # with groups\n    &gt;&gt;&gt; patterns = np.random.random_sample((60,20))\n    &gt;&gt;&gt; groups = np.hstack([np.ones(20), np.ones(40)+1])\n    &gt;&gt;&gt; si, combos, pvalues = similarity_index(patterns, groups=groups)\n\n    References\n    ----------\n    Based on Almeida-Filho et al., 2014 to detect similar assemblies.\n\n    \"\"\"\n    # check to see if patterns are numpy arrays\n    if not isinstance(patterns, np.ndarray):\n        patterns = np.array(patterns)\n\n    if patterns.shape[0] &lt; 2:\n        raise ValueError(\"At least 2 patterns are required to compute similarity.\")\n\n    # set seed to ensure exact results between runs\n    np.random.seed(42)\n\n    # maximum number of n_shuffles based on number of neurons\n    n_shuffles = min(n_shuffles, int(math.factorial(patterns.shape[1])))\n\n    # Normalize patterns\n    patterns = patterns / np.linalg.norm(patterns, axis=1, keepdims=True)\n\n    # shuffle patterns over neurons\n    def shuffle_patterns(patterns):\n        return np.array([np.random.permutation(pattern) for pattern in patterns])\n\n    # Calculate absolute inner product between patterns\n    def get_si(patterns):\n        si = np.array(\n            [np.abs(np.inner(patterns[i], patterns[j])) for i, j in COMBINATIONS]\n        )\n        return si\n\n    # get all possible combinations of patterns\n    COMBINATIONS = np.array(list(itertools.combinations(range(patterns.shape[0]), 2)))\n\n    # calculate observed si\n    si = get_si(patterns)\n\n    # shuffle patterns and calculate si\n    if parallel:\n        num_cores = multiprocessing.cpu_count()\n        si_shuffles = Parallel(n_jobs=num_cores)(\n            delayed(get_si)(shuffle_patterns(patterns)) for _ in range(n_shuffles)\n        )\n    else:\n        si_shuffles = [get_si(shuffle_patterns(patterns)) for _ in range(n_shuffles)]\n\n    # calculate p-values for each pattern combination\n    _, pvalues, _ = get_significant_events(si, np.array(si_shuffles))\n\n    # Filter outputs to only include cross-group comparisons\n    if groups is not None:\n        # Ensure groups is a numpy array\n        groups = np.asarray(groups)\n\n        # Identify cross-group comparisons\n        cross_group_mask = groups[COMBINATIONS[:, 0]] != groups[COMBINATIONS[:, 1]]\n        si = si[cross_group_mask]\n        COMBINATIONS = COMBINATIONS[cross_group_mask]\n        pvalues = pvalues[cross_group_mask]\n\n    if adjust_pvalue:\n        pvalues = stats.false_discovery_control(pvalues)\n\n    return si, COMBINATIONS, pvalues\n</code></pre>"},{"location":"reference/neuro_py/ensemble/similaritymat/","title":"neuro_py.ensemble.similaritymat","text":""},{"location":"reference/neuro_py/ensemble/similaritymat/#neuro_py.ensemble.similaritymat.similaritymat","title":"<code>similaritymat(patternsX, patternsY=None, method='cosine', findpairs=False)</code>","text":"<p>Calculate the similarity matrix of co-activation patterns (assemblies).</p> <p>Parameters:</p> Name Type Description Default <code>patternsX</code> <code>ndarray</code> <p>Co-activation patterns (assemblies) - numpy array (assemblies, neurons).</p> required <code>patternsY</code> <code>Optional[ndarray]</code> <p>Co-activation patterns (assemblies) - numpy array (assemblies, neurons). If None, will compute similarity of patternsX to itself, by default None.</p> <code>None</code> <code>method</code> <code>str</code> <p>Defines similarity measure method, by default 'cosine'. 'cosine' - cosine similarity.</p> <code>'cosine'</code> <code>findpairs</code> <code>bool</code> <p>Maximizes main diagonal of the similarity matrix to define pairs from patterns X and Y. Returns rowind, colind which can be used to reorder patterns X and Y to maximize the diagonal, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tuple[ndarray, ndarray, ndarray]]</code> <p>Similarity matrix (assemblies from X, assemblies from Y). If findpairs is True, also returns rowind and colind.</p> Source code in <code>neuro_py/ensemble/similaritymat.py</code> <pre><code>def similaritymat(\n    patternsX: np.ndarray,\n    patternsY: Optional[np.ndarray] = None,\n    method: str = \"cosine\",\n    findpairs: bool = False,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n    \"\"\"\n    Calculate the similarity matrix of co-activation patterns (assemblies).\n\n    Parameters\n    ----------\n    patternsX : np.ndarray\n        Co-activation patterns (assemblies) - numpy array (assemblies, neurons).\n    patternsY : Optional[np.ndarray], optional\n        Co-activation patterns (assemblies) - numpy array (assemblies, neurons).\n        If None, will compute similarity of patternsX to itself, by default None.\n    method : str, optional\n        Defines similarity measure method, by default 'cosine'.\n        'cosine' - cosine similarity.\n    findpairs : bool, optional\n        Maximizes main diagonal of the similarity matrix to define pairs\n        from patterns X and Y. Returns rowind, colind which can be used to reorder\n        patterns X and Y to maximize the diagonal, by default False.\n\n    Returns\n    -------\n    Union[np.ndarray, Tuple[np.ndarray, np.ndarray, np.ndarray]]\n        Similarity matrix (assemblies from X, assemblies from Y).\n        If findpairs is True, also returns rowind and colind.\n    \"\"\"\n\n    if method != \"cosine\":\n        print(method + \" for similarity has not been implemented yet.\")\n        return\n\n    inputs = {\"X\": patternsX, \"Y\": patternsY}\n    simmat = getsim(**inputs)\n\n    if findpairs:\n\n        def fillmissingidxs(ind, n):\n            missing = list(set(np.arange(n)) - set(ind))\n            ind = np.array(list(ind) + missing)\n            return ind\n\n        rowind, colind = optimize.linear_sum_assignment(-simmat)\n\n        rowind = fillmissingidxs(rowind, np.size(simmat, 0))\n        colind = fillmissingidxs(colind, np.size(simmat, 1))\n\n        return simmat, rowind, colind\n    else:\n        return simmat\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/","title":"neuro_py.ensemble.decoding","text":""},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM","title":"<code>LSTM</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Long Short-Term Memory (LSTM) model.</p> <p>This class implements an LSTM model using PyTorch Lightning.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Dimensionality of output data, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int, int, float]</code> <p>Architectural parameters of the model (hidden_size, num_layers, dropout), by default (400, 1, 0.0)</p> <code>(400, 1, 0.0)</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias or not in the final linear layer, by default True</p> <code>True</code> <code>args</code> <code>Dict</code> <p>Additional arguments for model configuration, by default {}</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>lstm</code> <code>LSTM</code> <p>LSTM layer</p> <code>fc</code> <code>Linear</code> <p>Fully connected layer</p> <code>hidden_state</code> <code>Optional[Tensor]</code> <p>Hidden state of the LSTM</p> <code>cell_state</code> <code>Optional[Tensor]</code> <p>Cell state of the LSTM</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>class LSTM(L.LightningModule):\n    \"\"\"\n    Long Short-Term Memory (LSTM) model.\n\n    This class implements an LSTM model using PyTorch Lightning.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Dimensionality of output data, by default 2\n    hidden_dims : Tuple[int, int, float], optional\n        Architectural parameters of the model (hidden_size, num_layers, dropout),\n        by default (400, 1, 0.0)\n    use_bias : bool, optional\n        Whether to use bias or not in the final linear layer, by default True\n    args : Dict, optional\n        Additional arguments for model configuration, by default {}\n\n    Attributes\n    ----------\n    lstm : nn.LSTM\n        LSTM layer\n    fc : nn.Linear\n        Fully connected layer\n    hidden_state : Optional[torch.Tensor]\n        Hidden state of the LSTM\n    cell_state : Optional[torch.Tensor]\n        Cell state of the LSTM\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int, int, float] = (400, 1, 0.0),\n        use_bias: bool = True,\n        args: Dict = {},\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        if len(hidden_dims) != 3:\n            raise ValueError(\"`hidden_dims` should be of size 3\")\n        self.hidden_size, self.nlayers, self.dropout = hidden_dims\n        self.args = args\n\n        self.lstm = nn.LSTM(\n            input_size=in_dim,\n            hidden_size=self.hidden_size,\n            num_layers=self.nlayers,\n            batch_first=True,\n            dropout=self.dropout,\n            bidirectional=True,\n        )\n        self.fc = nn.Linear(\n            in_features=2 * self.hidden_size, out_features=out_dim, bias=use_bias\n        )\n        self.hidden_state: Optional[torch.Tensor] = None\n        self.cell_state: Optional[torch.Tensor] = None\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize model parameters.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / torch.math.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        init_params(self.fc)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor of shape (batch_size, sequence_length, input_dim)\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, output_dim)\n        \"\"\"\n        lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n            x, (self.hidden_state, self.cell_state)\n        )\n        lstm_out = lstm_out[:, -1, :].contiguous()\n        out = self.fc(lstm_out)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=1)\n        return out\n\n    def init_hidden(self, batch_size: int) -&gt; None:\n        \"\"\"\n        Initialize hidden state and cell state.\n\n        Parameters\n        ----------\n        batch_size : int\n            Batch size for initialization\n        \"\"\"\n        self.batch_size = batch_size\n        h0 = torch.zeros(\n            (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        c0 = torch.zeros(\n            (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        self.hidden_state = h0\n        self.cell_state = c0\n\n    def predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Make predictions using the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor\n\n        Returns\n        -------\n        torch.Tensor\n            Predicted output\n        \"\"\"\n        self.hidden_state = self.hidden_state.to(x.device)\n        self.cell_state = self.cell_state.to(x.device)\n        preds = []\n        batch_size = self.batch_size\n        for i in range(batch_size, x.shape[0] + batch_size, batch_size):\n            iptensor = x[i - batch_size : i]\n            if i &gt; x.shape[0]:\n                iptensor = F.pad(iptensor, (0, 0, 0, 0, 0, i - x.shape[0]))\n            pred_loc = self.forward(iptensor)\n            if i &gt; x.shape[0]:\n                pred_loc = pred_loc[: batch_size - (i - x.shape[0])]\n            preds.extend(pred_loc)\n        out = torch.stack(preds)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=1)\n        return out\n\n    def _step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def on_after_backward(self) -&gt; None:\n        \"\"\"Lightning method called after backpropagation.\"\"\"\n        self.hidden_state.detach_()\n        self.cell_state.detach_()\n\n    def validation_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        Tuple[List[torch.optim.Optimizer], List[Dict]]\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            steps_per_epoch=len(\n                self.trainer._data_connector._train_dataloader_source.dataloader()\n            ),\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize model parameters.</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize model parameters.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / torch.math.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    init_params(self.fc)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def _step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>Tuple[List[Optimizer], List[Dict]]</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    Tuple[List[torch.optim.Optimizer], List[Dict]]\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        steps_per_epoch=len(\n            self.trainer._data_connector._train_dataloader_source.dataloader()\n        ),\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, sequence_length, input_dim)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, output_dim)</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor of shape (batch_size, sequence_length, input_dim)\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, output_dim)\n    \"\"\"\n    lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n        x, (self.hidden_state, self.cell_state)\n    )\n    lstm_out = lstm_out[:, -1, :].contiguous()\n    out = self.fc(lstm_out)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.init_hidden","title":"<code>init_hidden(batch_size)</code>","text":"<p>Initialize hidden state and cell state.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for initialization</p> required Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def init_hidden(self, batch_size: int) -&gt; None:\n    \"\"\"\n    Initialize hidden state and cell state.\n\n    Parameters\n    ----------\n    batch_size : int\n        Batch size for initialization\n    \"\"\"\n    self.batch_size = batch_size\n    h0 = torch.zeros(\n        (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    c0 = torch.zeros(\n        (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    self.hidden_state = h0\n    self.cell_state = c0\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.on_after_backward","title":"<code>on_after_backward()</code>","text":"<p>Lightning method called after backpropagation.</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def on_after_backward(self) -&gt; None:\n    \"\"\"Lightning method called after backpropagation.\"\"\"\n    self.hidden_state.detach_()\n    self.cell_state.detach_()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.predict","title":"<code>predict(x)</code>","text":"<p>Make predictions using the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Predicted output</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Make predictions using the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor\n\n    Returns\n    -------\n    torch.Tensor\n        Predicted output\n    \"\"\"\n    self.hidden_state = self.hidden_state.to(x.device)\n    self.cell_state = self.cell_state.to(x.device)\n    preds = []\n    batch_size = self.batch_size\n    for i in range(batch_size, x.shape[0] + batch_size, batch_size):\n        iptensor = x[i - batch_size : i]\n        if i &gt; x.shape[0]:\n            iptensor = F.pad(iptensor, (0, 0, 0, 0, 0, i - x.shape[0]))\n        pred_loc = self.forward(iptensor)\n        if i &gt; x.shape[0]:\n            pred_loc = pred_loc[: batch_size - (i - x.shape[0])]\n        preds.extend(pred_loc)\n    out = torch.stack(preds)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def training_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.LSTM.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def validation_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM","title":"<code>M2MLSTM</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Many-to-Many Long Short-Term Memory (LSTM) model.</p> <p>This class implements a Many-to-Many LSTM model using PyTorch Lightning.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Number of output columns, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int, int, float]</code> <p>Architectural parameters of the model (hidden_size, num_layers, dropout), by default (400, 1, 0.0)</p> <code>(400, 1, 0.0)</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias or not in the final linear layer, by default True</p> <code>True</code> <code>args</code> <code>Dict</code> <p>Additional arguments for model configuration, by default {}</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>lstm</code> <code>LSTM</code> <p>LSTM layer</p> <code>fc</code> <code>Linear</code> <p>Fully connected layer</p> <code>hidden_state</code> <code>Optional[Tensor]</code> <p>Hidden state of the LSTM</p> <code>cell_state</code> <code>Optional[Tensor]</code> <p>Cell state of the LSTM</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>class M2MLSTM(L.LightningModule):\n    \"\"\"\n    Many-to-Many Long Short-Term Memory (LSTM) model.\n\n    This class implements a Many-to-Many LSTM model using PyTorch Lightning.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Number of output columns, by default 2\n    hidden_dims : Tuple[int, int, float], optional\n        Architectural parameters of the model (hidden_size, num_layers, dropout),\n        by default (400, 1, 0.0)\n    use_bias : bool, optional\n        Whether to use bias or not in the final linear layer, by default True\n    args : Dict, optional\n        Additional arguments for model configuration, by default {}\n\n    Attributes\n    ----------\n    lstm : nn.LSTM\n        LSTM layer\n    fc : nn.Linear\n        Fully connected layer\n    hidden_state : Optional[torch.Tensor]\n        Hidden state of the LSTM\n    cell_state : Optional[torch.Tensor]\n        Cell state of the LSTM\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int, int, float] = (400, 1, 0.0),\n        use_bias: bool = True,\n        args: Dict = {},\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        if len(hidden_dims) != 3:\n            raise ValueError(\"`hidden_dims` should be of size 3\")\n        self.hidden_size, self.nlayers, self.dropout = hidden_dims\n        self.args = args\n\n        self.lstm = nn.LSTM(\n            input_size=in_dim,\n            hidden_size=self.hidden_size,\n            num_layers=self.nlayers,\n            batch_first=True,\n            dropout=self.dropout,\n            bidirectional=False,\n        )\n        self.fc = nn.Linear(\n            in_features=self.hidden_size, out_features=out_dim, bias=use_bias\n        )\n        self.hidden_state: Optional[torch.Tensor] = None\n        self.cell_state: Optional[torch.Tensor] = None\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize model parameters.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / np.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        init_params(self.fc)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor of shape (batch_size, sequence_length, input_dim)\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, sequence_length, output_dim)\n        \"\"\"\n        B, L, N = x.shape\n        self.hidden_state = self.hidden_state.to(x.device)\n        self.cell_state = self.cell_state.to(x.device)\n        self.hidden_state.data.fill_(0.0)\n        self.cell_state.data.fill_(0.0)\n        lstm_outs = []\n        for i in range(L):\n            lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n                x[:, i].unsqueeze(1), (self.hidden_state, self.cell_state)\n            )\n            lstm_outs.append(lstm_out)\n\n        lstm_outs = torch.stack(lstm_outs, dim=1)  # B, L, N\n        out = self.fc(lstm_outs)\n        out = out.view(B, L, self.out_dim)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=-1)\n\n        return out\n\n    def init_hidden(self, batch_size: int) -&gt; None:\n        \"\"\"\n        Initialize hidden state and cell state.\n\n        Parameters\n        ----------\n        batch_size : int\n            Batch size for initialization\n        \"\"\"\n        self.batch_size = batch_size\n        self.hidden_state = torch.zeros(\n            (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        self.cell_state = torch.zeros(\n            (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n\n    def _step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def on_after_backward(self) -&gt; None:\n        \"\"\"Lightning method called after backpropagation.\"\"\"\n        self.hidden_state = self.hidden_state.detach()\n        self.cell_state = self.cell_state.detach()\n\n    def validation_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        Tuple[List[torch.optim.Optimizer], List[Dict]]\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            total_steps=self.trainer.estimated_stepping_batches,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize model parameters.</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize model parameters.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / np.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    init_params(self.fc)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def _step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>Tuple[List[Optimizer], List[Dict]]</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    Tuple[List[torch.optim.Optimizer], List[Dict]]\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        total_steps=self.trainer.estimated_stepping_batches,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, sequence_length, input_dim)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, sequence_length, output_dim)</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor of shape (batch_size, sequence_length, input_dim)\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, sequence_length, output_dim)\n    \"\"\"\n    B, L, N = x.shape\n    self.hidden_state = self.hidden_state.to(x.device)\n    self.cell_state = self.cell_state.to(x.device)\n    self.hidden_state.data.fill_(0.0)\n    self.cell_state.data.fill_(0.0)\n    lstm_outs = []\n    for i in range(L):\n        lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n            x[:, i].unsqueeze(1), (self.hidden_state, self.cell_state)\n        )\n        lstm_outs.append(lstm_out)\n\n    lstm_outs = torch.stack(lstm_outs, dim=1)  # B, L, N\n    out = self.fc(lstm_outs)\n    out = out.view(B, L, self.out_dim)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=-1)\n\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.init_hidden","title":"<code>init_hidden(batch_size)</code>","text":"<p>Initialize hidden state and cell state.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for initialization</p> required Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def init_hidden(self, batch_size: int) -&gt; None:\n    \"\"\"\n    Initialize hidden state and cell state.\n\n    Parameters\n    ----------\n    batch_size : int\n        Batch size for initialization\n    \"\"\"\n    self.batch_size = batch_size\n    self.hidden_state = torch.zeros(\n        (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    self.cell_state = torch.zeros(\n        (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.on_after_backward","title":"<code>on_after_backward()</code>","text":"<p>Lightning method called after backpropagation.</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def on_after_backward(self) -&gt; None:\n    \"\"\"Lightning method called after backpropagation.\"\"\"\n    self.hidden_state = self.hidden_state.detach()\n    self.cell_state = self.cell_state.detach()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def training_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.M2MLSTM.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def validation_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP","title":"<code>MLP</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Multi-Layer Perceptron (MLP) in PyTorch with an arbitrary number of hidden layers.</p> <p>This class implements an MLP model using PyTorch Lightning, allowing for flexible architecture with varying hidden layer sizes and dropout probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Dimensionality of output data, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>List[Union[int, float]]</code> <p>List containing architectural parameters of the model. If an element is an int, it represents a hidden layer of that size. If an element is a float, it represents a dropout layer with that probability. By default ()</p> <code>()</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias in all linear layers, by default True</p> <code>True</code> <code>args</code> <code>Optional[Dict]</code> <p>Dictionary containing the hyperparameters of the model, by default None</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>main</code> <code>Sequential</code> <p>The main sequential container of the MLP layers</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>class MLP(L.LightningModule):\n    \"\"\"\n    Multi-Layer Perceptron (MLP) in PyTorch with an arbitrary number of hidden layers.\n\n    This class implements an MLP model using PyTorch Lightning, allowing for flexible\n    architecture with varying hidden layer sizes and dropout probabilities.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Dimensionality of output data, by default 2\n    hidden_dims : List[Union[int, float]], optional\n        List containing architectural parameters of the model. If an element is\n        an int, it represents a hidden layer of that size. If an element is a float,\n        it represents a dropout layer with that probability. By default ()\n    use_bias : bool, optional\n        Whether to use bias in all linear layers, by default True\n    args : Optional[Dict], optional\n        Dictionary containing the hyperparameters of the model, by default None\n\n    Attributes\n    ----------\n    main : nn.Sequential\n        The main sequential container of the MLP layers\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: List[Union[int, float]] = (),\n        use_bias: bool = True,\n        args: Optional[Dict] = None,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        self.args = args if args is not None else {}\n        activations = (\n            nn.CELU\n            if self.args.get(\"activations\") is None\n            else self.args[\"activations\"]\n        )\n\n        layers = self._build_layers(in_dim, out_dim, hidden_dims, use_bias, activations)\n        self.main = nn.Sequential(*layers)\n        self._init_params()\n\n    def _build_layers(\n        self,\n        in_dim: int,\n        out_dim: int,\n        hidden_dims: List[Union[int, float]],\n        use_bias: bool,\n        activations: nn.Module,\n    ) -&gt; List[nn.Module]:\n        \"\"\"\n        Build the layers of the MLP.\n\n        Parameters\n        ----------\n        in_dim : int\n            Dimensionality of input data\n        out_dim : int\n            Dimensionality of output data\n        hidden_dims : List[Union[int, float]]\n            List of hidden layer sizes and dropout probabilities\n        use_bias : bool\n            Whether to use bias in linear layers\n        activations : nn.Module\n            Activation function to use\n\n        Returns\n        -------\n        List[nn.Module]\n            List of layers for the MLP\n        \"\"\"\n        if len(hidden_dims) == 0:\n            return [nn.Linear(in_dim, out_dim, bias=use_bias)]\n\n        layers = []\n        hidden_dims = [in_dim] + hidden_dims\n\n        for i, hidden_dim in enumerate(hidden_dims[:-1]):\n            if isinstance(hidden_dim, float):\n                continue\n            if isinstance(hidden_dims[i + 1], float):\n                layers.extend(\n                    [\n                        nn.Linear(hidden_dim, hidden_dims[i + 2], bias=use_bias),\n                        nn.Dropout(p=hidden_dims[i + 1]),\n                        activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                    ]\n                )\n            else:\n                layers.extend(\n                    [\n                        nn.Linear(hidden_dim, hidden_dims[i + 1], bias=use_bias),\n                        activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                    ]\n                )\n\n        layers.append(nn.Linear(hidden_dims[-1], out_dim, bias=use_bias))\n        if self.args.get(\"clf\", False):\n            layers.append(nn.LogSoftmax(dim=1))\n\n        return layers\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize the parameters of the model.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / torch.math.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        self.main.apply(init_params)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Defines the network structure and flow from input to output.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input data\n\n        Returns\n        -------\n        torch.Tensor\n            Output data\n        \"\"\"\n        return self.main(x)\n\n    def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        tuple\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(),\n            weight_decay=self.args[\"weight_decay\"],\n            betas=(0.9, 0.999),\n            amsgrad=True,\n        )\n        scheduler = torch.optim.lr_scheduler.CyclicLR(\n            optimizer,\n            base_lr=self.args[\"base_lr\"],\n            max_lr=self.args[\"lr\"],\n            step_size_up=self.args[\"scheduler_step_size_multiplier\"]\n            * self.args[\"num_training_batches\"],\n            cycle_momentum=False,\n            mode=\"triangular2\",\n            gamma=0.99994,\n            last_epoch=-1,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP._build_layers","title":"<code>_build_layers(in_dim, out_dim, hidden_dims, use_bias, activations)</code>","text":"<p>Build the layers of the MLP.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data</p> required <code>out_dim</code> <code>int</code> <p>Dimensionality of output data</p> required <code>hidden_dims</code> <code>List[Union[int, float]]</code> <p>List of hidden layer sizes and dropout probabilities</p> required <code>use_bias</code> <code>bool</code> <p>Whether to use bias in linear layers</p> required <code>activations</code> <code>Module</code> <p>Activation function to use</p> required <p>Returns:</p> Type Description <code>List[Module]</code> <p>List of layers for the MLP</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _build_layers(\n    self,\n    in_dim: int,\n    out_dim: int,\n    hidden_dims: List[Union[int, float]],\n    use_bias: bool,\n    activations: nn.Module,\n) -&gt; List[nn.Module]:\n    \"\"\"\n    Build the layers of the MLP.\n\n    Parameters\n    ----------\n    in_dim : int\n        Dimensionality of input data\n    out_dim : int\n        Dimensionality of output data\n    hidden_dims : List[Union[int, float]]\n        List of hidden layer sizes and dropout probabilities\n    use_bias : bool\n        Whether to use bias in linear layers\n    activations : nn.Module\n        Activation function to use\n\n    Returns\n    -------\n    List[nn.Module]\n        List of layers for the MLP\n    \"\"\"\n    if len(hidden_dims) == 0:\n        return [nn.Linear(in_dim, out_dim, bias=use_bias)]\n\n    layers = []\n    hidden_dims = [in_dim] + hidden_dims\n\n    for i, hidden_dim in enumerate(hidden_dims[:-1]):\n        if isinstance(hidden_dim, float):\n            continue\n        if isinstance(hidden_dims[i + 1], float):\n            layers.extend(\n                [\n                    nn.Linear(hidden_dim, hidden_dims[i + 2], bias=use_bias),\n                    nn.Dropout(p=hidden_dims[i + 1]),\n                    activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                ]\n            )\n        else:\n            layers.extend(\n                [\n                    nn.Linear(hidden_dim, hidden_dims[i + 1], bias=use_bias),\n                    activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                ]\n            )\n\n    layers.append(nn.Linear(hidden_dims[-1], out_dim, bias=use_bias))\n    if self.args.get(\"clf\", False):\n        layers.append(nn.LogSoftmax(dim=1))\n\n    return layers\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize the parameters of the model.</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize the parameters of the model.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / torch.math.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    self.main.apply(init_params)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def configure_optimizers(self):\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    tuple\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(),\n        weight_decay=self.args[\"weight_decay\"],\n        betas=(0.9, 0.999),\n        amsgrad=True,\n    )\n    scheduler = torch.optim.lr_scheduler.CyclicLR(\n        optimizer,\n        base_lr=self.args[\"base_lr\"],\n        max_lr=self.args[\"lr\"],\n        step_size_up=self.args[\"scheduler_step_size_multiplier\"]\n        * self.args[\"num_training_batches\"],\n        cycle_momentum=False,\n        mode=\"triangular2\",\n        gamma=0.99994,\n        last_epoch=-1,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP.forward","title":"<code>forward(x)</code>","text":"<p>Defines the network structure and flow from input to output.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output data</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Defines the network structure and flow from input to output.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input data\n\n    Returns\n    -------\n    torch.Tensor\n        Output data\n    \"\"\"\n    return self.main(x)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.MLP.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT","title":"<code>NDT</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Transformer encoder-based dynamical systems decoder.</p> <p>This class implements a Transformer-based decoder trained on MLM loss. It returns loss and predicted rates.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Number of output columns, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int]</code> <p>Architectural parameters of the model (dim_feedforward, num_layers, nhead, dropout, rate_dropout), by default [400, 1, 1, 0.0, 0.0]</p> <code>(400, 1, 1, 0.0, 0.0)</code> <code>max_context_len</code> <code>int</code> <p>Maximum context length, by default 2</p> <code>2</code> <code>args</code> <code>Optional[Dict]</code> <p>Dictionary containing the hyperparameters of the model, by default None</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>pos_encoder</code> <code>PositionalEncoding</code> <p>Positional encoding module</p> <code>transformer_encoder</code> <code>TransformerEncoder</code> <p>Transformer encoder module</p> <code>rate_dropout</code> <code>Dropout</code> <p>Dropout layer for rates</p> <code>decoder</code> <code>Sequential</code> <p>Decoder network</p> <code>src_mask</code> <code>Dict[str, Tensor]</code> <p>Dictionary to store source masks for different devices</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>class NDT(L.LightningModule):\n    \"\"\"\n    Transformer encoder-based dynamical systems decoder.\n\n    This class implements a Transformer-based decoder trained on MLM loss.\n    It returns loss and predicted rates.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Number of output columns, by default 2\n    hidden_dims : Tuple[int], optional\n        Architectural parameters of the model\n        (dim_feedforward, num_layers, nhead, dropout, rate_dropout),\n        by default [400, 1, 1, 0.0, 0.0]\n    max_context_len : int, optional\n        Maximum context length, by default 2\n    args : Optional[Dict], optional\n        Dictionary containing the hyperparameters of the model, by default None\n\n    Attributes\n    ----------\n    pos_encoder : PositionalEncoding\n        Positional encoding module\n    transformer_encoder : nn.TransformerEncoder\n        Transformer encoder module\n    rate_dropout : nn.Dropout\n        Dropout layer for rates\n    decoder : nn.Sequential\n        Decoder network\n    src_mask : Dict[str, torch.Tensor]\n        Dictionary to store source masks for different devices\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int] = (400, 1, 1, 0.0, 0.0),\n        max_context_len: int = 2,\n        args: Optional[Dict] = None,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.max_context_len = max_context_len\n        self.in_dim = in_dim\n        self.args = args if args is not None else {}\n        activations = (\n            nn.CELU\n            if self.args.get(\"activations\") is None\n            else self.args[\"activations\"]\n        )\n\n        self.src_mask: Dict[str, torch.Tensor] = {}\n\n        self.pos_encoder = PositionalEncoding(in_dim, max_context_len, self.args)\n\n        encoder_lyr = nn.TransformerEncoderLayer(\n            in_dim,\n            nhead=hidden_dims[2],\n            dim_feedforward=hidden_dims[0],\n            dropout=hidden_dims[3],\n            activation=nn.functional.relu,\n        )\n\n        self.transformer_encoder = nn.TransformerEncoder(\n            encoder_lyr, hidden_dims[1], nn.LayerNorm(in_dim)\n        )\n\n        self.rate_dropout = nn.Dropout(hidden_dims[4])\n\n        self.decoder = nn.Sequential(\n            nn.Linear(in_dim, 16), activations(), nn.Linear(16, out_dim)\n        )\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize the parameters of the decoder.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / np.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        self.decoder.apply(init_params)\n\n    def forward(\n        self, x: torch.Tensor, mask_labels: Optional[torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input data of shape (batch_size, seq_len, in_dim)\n        mask_labels : Optional[torch.Tensor], optional\n            Masking labels for the input data, by default None\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, seq_len, out_dim)\n        \"\"\"\n        x = x.permute(1, 0, 2)  # LxBxN\n        x = self.pos_encoder(x)\n        x_mask = self._get_or_generate_context_mask(x)\n        z = self.transformer_encoder(x, x_mask)\n        z = self.rate_dropout(z)\n        out = self.decoder(z).permute(1, 0, 2)  # B x L x out_dim\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=-1)\n        return out\n\n    def _get_or_generate_context_mask(self, src: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Get or generate the context mask for the input tensor.\n\n        Parameters\n        ----------\n        src : torch.Tensor\n            Input tensor\n\n        Returns\n        -------\n        torch.Tensor\n            Context mask for the input tensor\n        \"\"\"\n        context_forward = 4\n        size = src.size(0)  # T\n        mask = (\n            torch.triu(\n                torch.ones(size, size, device=src.device), diagonal=-context_forward\n            )\n            == 1\n        ).transpose(0, 1)\n        mask = mask.float()\n        self.src_mask[str(src.device)] = mask\n        return self.src_mask[str(src.device)]\n\n    def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; tuple:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        tuple\n            List of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            total_steps=self.trainer.estimated_stepping_batches,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT._get_or_generate_context_mask","title":"<code>_get_or_generate_context_mask(src)</code>","text":"<p>Get or generate the context mask for the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Input tensor</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Context mask for the input tensor</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _get_or_generate_context_mask(self, src: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Get or generate the context mask for the input tensor.\n\n    Parameters\n    ----------\n    src : torch.Tensor\n        Input tensor\n\n    Returns\n    -------\n    torch.Tensor\n        Context mask for the input tensor\n    \"\"\"\n    context_forward = 4\n    size = src.size(0)  # T\n    mask = (\n        torch.triu(\n            torch.ones(size, size, device=src.device), diagonal=-context_forward\n        )\n        == 1\n    ).transpose(0, 1)\n    mask = mask.float()\n    self.src_mask[str(src.device)] = mask\n    return self.src_mask[str(src.device)]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize the parameters of the decoder.</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize the parameters of the decoder.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / np.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    self.decoder.apply(init_params)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>List of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def configure_optimizers(self) -&gt; tuple:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    tuple\n        List of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        total_steps=self.trainer.estimated_stepping_batches,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT.forward","title":"<code>forward(x, mask_labels=None)</code>","text":"<p>Forward pass of the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data of shape (batch_size, seq_len, in_dim)</p> required <code>mask_labels</code> <code>Optional[Tensor]</code> <p>Masking labels for the input data, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, seq_len, out_dim)</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, mask_labels: Optional[torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input data of shape (batch_size, seq_len, in_dim)\n    mask_labels : Optional[torch.Tensor], optional\n        Masking labels for the input data, by default None\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, seq_len, out_dim)\n    \"\"\"\n    x = x.permute(1, 0, 2)  # LxBxN\n    x = self.pos_encoder(x)\n    x_mask = self._get_or_generate_context_mask(x)\n    z = self.transformer_encoder(x, x_mask)\n    z = self.rate_dropout(z)\n    out = self.decoder(z).permute(1, 0, 2)  # B x L x out_dim\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=-1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.NDT.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.create_model","title":"<code>create_model(hyperparams)</code>","text":"<p>Create a model based on the given hyperparameters.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing model hyperparameters.</p> required <p>Returns:</p> Type Description <code>Tuple[Any, LightningModule]</code> <p>The decoder class and instantiated model.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def create_model(hyperparams: Dict[str, Any]) -&gt; Tuple[Any, pl.LightningModule]:\n    \"\"\"\n    Create a model based on the given hyperparameters.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing model hyperparameters.\n\n    Returns\n    -------\n    Tuple[Any, pl.LightningModule]\n        The decoder class and instantiated model.\n    \"\"\"\n    decoder = eval(f\"{hyperparams['model']}\")\n    model = decoder(**hyperparams[\"model_args\"])\n\n    if \"LSTM\" in hyperparams[\"model\"]:\n        model.init_hidden(hyperparams[\"batch_size\"])\n        model.hidden_state = model.hidden_state.to(hyperparams[\"accelerator\"])\n        model.cell_state = model.cell_state.to(hyperparams[\"accelerator\"])\n\n    return decoder, model\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.decode","title":"<code>decode(ct, tc, occupancy, bin_size_s, uniform_prior=False)</code>","text":"<p>Decode position from spike counts in an N-dimensional spatial environment</p> <p>Parameters:</p> Name Type Description Default <code>ct</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape (n_bins, n_cells)</p> required <code>tc</code> <code>ndarray</code> <p>ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)</p> required <code>occupancy</code> <code>ndarray</code> <p>(N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)</p> required <code>bin_size_s</code> <code>float</code> <p>float, width of each time bin in seconds</p> required <code>uniform_prior</code> <code>bool</code> <p>bool, whether to use uniform prior, by default False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>p</code> <code>ndarray</code> <p>(N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)</p> <p>Examples:</p>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.decode--1d-example","title":"1D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.decode--2d-example","title":"2D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.decode--3d-example","title":"3D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre> Source code in <code>neuro_py/ensemble/decoding/bayesian.py</code> <pre><code>@njit(parallel=True, fastmath=True)\ndef decode(\n    ct: np.ndarray,\n    tc: np.ndarray,\n    occupancy: np.ndarray,\n    bin_size_s: float,\n    uniform_prior: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode position from spike counts in an N-dimensional spatial environment\n\n    Parameters\n    ----------\n    ct : ndarray\n        2D array, spike counts matrix with shape (n_bins, n_cells)\n    tc : ndarray\n        ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)\n    occupancy : ndarray\n        (N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)\n    bin_size_s : float\n        float, width of each time bin in seconds\n    uniform_prior : bool, optional\n        bool, whether to use uniform prior, by default False\n\n    Returns\n    ----------\n    p : ndarray\n        (N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)\n\n    Examples\n    ----------\n    # 1D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 2D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 3D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n    \"\"\"\n\n    # Ensure input arrays are contiguous for vectorization\n    ct = np.ascontiguousarray(ct)\n    tc = np.ascontiguousarray(tc)\n    occupancy = np.ascontiguousarray(occupancy)\n\n    # Validate input shapes\n    assert ct.ndim == 2, \"ct must be a 2D array with shape (n_bins, n_cells)\"\n    assert tc.ndim &gt;= 2, (\n        \"tc must be at least a 2D array with shape (n_xbins, ..., n_cells)\"\n    )\n    assert occupancy.ndim == tc.ndim - 1, (\n        \"occupancy must have one fewer dimension than tc\"\n    )\n    assert ct.shape[1] == tc.shape[-1], \"Number of cells in ct and tc must match\"\n\n    # Flatten spatial dimensions\n    n_cells = tc.shape[-1]\n    spatial_shape = tc.shape[:-1]  # Shape of spatial dimensions\n\n    # Calculate the total number of spatial bins\n    n_spatial_bins = 1\n    for dim in spatial_shape:\n        n_spatial_bins *= dim\n\n    tc_flat = tc.reshape(n_spatial_bins, n_cells)\n    occupancy_flat = occupancy.flatten()\n\n    if uniform_prior:\n        # Use uniform prior\n        occupancy_flat = np.ones_like(occupancy_flat)\n\n    # Precompute log values\n    log_tc_flat = np.log(tc_flat + 1e-10)  # add small value to avoid log(0)\n    log_p1 = -tc_flat.sum(axis=1) * bin_size_s\n    log_p2 = np.log(occupancy_flat / occupancy_flat.sum())\n\n    # Initialize the probability matrix\n    n_bins = ct.shape[0]\n    p = np.zeros((n_bins, n_spatial_bins))\n\n    # Vectorized calculation of log probabilities\n    for i in prange(n_bins):  # prange for parallel loop\n        log_likelihood = log_p1 + log_p2 + np.sum(log_tc_flat * ct[i, :], axis=1)\n        p[i, :] = np.exp(\n            log_likelihood - np.max(log_likelihood)\n        )  # Subtract max for numerical stability\n\n    # Normalize the probabilities along the spatial axis\n    p_sum = p.sum(axis=1)  # Sum over spatial bins\n    p = p / p_sum.reshape(-1, 1)  # Reshape p_sum to (n_bins, 1) for broadcasting\n\n    # Reshape the probabilities to the original spatial dimensions\n    p = p.reshape((n_bins,) + spatial_shape)\n\n    return p\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.evaluate_model","title":"<code>evaluate_model(hyperparams, ohe, predictor, X_test, y_test)</code>","text":"<p>Evaluate the model on test data.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing hyperparameters.</p> required <code>ohe</code> <code>OneHotEncoder</code> <p>One-hot encoder for categorical variables.</p> required <code>predictor</code> <code>Module</code> <p>The trained model.</p> required <code>X_test</code> <code>NDArray</code> <p>Test features.</p> required <code>y_test</code> <code>NDArray</code> <p>Test labels.</p> required <p>Returns:</p> Type Description <code>Tuple[Dict[str, float], NDArray]</code> <p>Evaluation metrics and model predictions.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def evaluate_model(\n    hyperparams: Dict[str, Any],\n    ohe: sklearn.preprocessing.OneHotEncoder,\n    predictor: torch.nn.Module,\n    X_test: NDArray,\n    y_test: NDArray,\n) -&gt; Tuple[Dict[str, float], NDArray]:\n    \"\"\"\n    Evaluate the model on test data.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing hyperparameters.\n    ohe : OneHotEncoder\n        One-hot encoder for categorical variables.\n    predictor : torch.nn.Module\n        The trained model.\n    X_test : NDArray\n        Test features.\n    y_test : NDArray\n        Test labels.\n\n    Returns\n    -------\n    Tuple[Dict[str, float], NDArray]\n        Evaluation metrics and model predictions.\n    \"\"\"\n    if hyperparams[\"model\"] in (\"M2MLSTM\", \"NDT\"):\n        out_dim = hyperparams[\"model_args\"][\"out_dim\"]\n        with torch.no_grad():\n            bv_preds_fold = [\n                predictor(torch.from_numpy(X.reshape(1, *X.shape)).type(torch.float32))\n                for X in X_test\n            ]\n        bv_preds_fold = np.vstack(\n            [\n                bv.squeeze().detach().cpu().numpy().reshape(-1, out_dim)\n                for bv in bv_preds_fold\n            ]\n        )\n    else:\n        bv_preds_fold = predictor(torch.from_numpy(X_test).type(torch.float32))\n        bv_preds_fold = bv_preds_fold.detach().cpu().numpy()\n\n    bv_preds_fold = copy.deepcopy(bv_preds_fold)\n\n    logits = bv_preds_fold\n    labels = np.vstack(y_test)\n    if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n        logits = ohe.inverse_transform(logits)\n        labels = ohe.inverse_transform(labels)\n        accuracy = sklearn.metrics.accuracy_score(labels, logits)\n        metrics = dict(accuracy=accuracy)\n        bv_preds_fold = logits\n    else:\n        coeff_determination = sklearn.metrics.r2_score(\n            labels, logits, multioutput=\"variance_weighted\"\n        )\n        rmse = sklearn.metrics.root_mean_squared_error(labels, logits)\n        metrics = dict(coeff_determination=coeff_determination, rmse=rmse)\n    return metrics, bv_preds_fold\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.format_trial_segs_nsv","title":"<code>format_trial_segs_nsv(nsv_train_normed, nsv_rest_normed, bv_train, bv_rest, predict_bv, bins_before=0, bins_current=1, bins_after=0)</code>","text":"<p>Format trial segments for neural state vectors.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_train_normed</code> <code>List[NDArray]</code> <p>Normalized neural state vectors for training.</p> required <code>nsv_rest_normed</code> <code>List[NDArray]</code> <p>Normalized neural state vectors for rest.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_rest</code> <code>List[NDArray]</code> <p>Behavioral state vectors for rest.</p> required <code>predict_bv</code> <code>List[int]</code> <p>Indices of behavioral state vectors to predict.</p> required <code>bins_before</code> <code>int</code> <p>Number of bins before the current bin, by default 0.</p> <code>0</code> <code>bins_current</code> <code>int</code> <p>Number of current bins, by default 1.</p> <code>1</code> <code>bins_after</code> <code>int</code> <p>Number of bins after the current bin, by default 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]</code> <p>Formatted trial segments for neural state vectors.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def format_trial_segs_nsv(\n    nsv_train_normed: List[NDArray],\n    nsv_rest_normed: List[NDArray],\n    bv_train: NDArray,\n    bv_rest: List[NDArray],\n    predict_bv: List[int],\n    bins_before: int = 0,\n    bins_current: int = 1,\n    bins_after: int = 0,\n) -&gt; Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]:\n    \"\"\"\n    Format trial segments for neural state vectors.\n\n    Parameters\n    ----------\n    nsv_train_normed : List[NDArray]\n        Normalized neural state vectors for training.\n    nsv_rest_normed : List[NDArray]\n        Normalized neural state vectors for rest.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_rest : List[NDArray]\n        Behavioral state vectors for rest.\n    predict_bv : List[int]\n        Indices of behavioral state vectors to predict.\n    bins_before : int, optional\n        Number of bins before the current bin, by default 0.\n    bins_current : int, optional\n        Number of current bins, by default 1.\n    bins_after : int, optional\n        Number of bins after the current bin, by default 0.\n\n    Returns\n    -------\n    Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]\n        Formatted trial segments for neural state vectors.\n    \"\"\"\n    is_2D = nsv_train_normed[0].ndim == 1\n    # Format for RNNs: covariate matrix including spike history from previous bins\n    X_train = np.concatenate(\n        _get_trial_spikes_with_no_overlap_history(\n            nsv_train_normed, bins_before, bins_after, bins_current\n        )\n    )\n    X_rest = []\n    for nsv_feats in nsv_rest_normed:\n        X_feats = np.concatenate(\n            _get_trial_spikes_with_no_overlap_history(\n                nsv_feats, bins_before, bins_after, bins_current\n            )\n        )\n        X_rest.append(X_feats)\n\n    # each \"neuron / time\" is a single feature\n    X_flat_train = X_train.reshape(\n        X_train.shape[0], (X_train.shape[1] * X_train.shape[2])\n    )\n    X_flat_rest = []\n    for X_feat in X_rest:\n        X_flat_feat = X_feat.reshape(\n            X_feat.shape[0], (X_feat.shape[1] * X_feat.shape[2])\n        )\n        X_flat_rest.append(X_flat_feat)\n\n    bv_train = bv_train if not is_2D else [bv_train]\n    y_train = np.concatenate(bv_train)\n    y_train = y_train[:, predict_bv]\n    y_rest = []\n    for bv_y in bv_rest:\n        bv_y = bv_y if not is_2D else [bv_y]\n        y = np.concatenate(bv_y)\n        y = y[:, predict_bv]\n        y_rest.append(y)\n\n    return X_train, X_rest, X_flat_train, X_flat_rest, y_train, y_rest\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.get_spikes_with_history","title":"<code>get_spikes_with_history(neural_data, bins_before, bins_after, bins_current=1)</code>","text":"<p>Create the covariate matrix of neural activity.</p> <p>Parameters:</p> Name Type Description Default <code>neural_data</code> <code>ndarray</code> <p>A matrix of size \"number of time bins\" x \"number of neurons\", representing the number of spikes in each time bin for each neuron.</p> required <code>bins_before</code> <code>int</code> <p>How many bins of neural data prior to the output are used for decoding.</p> required <code>bins_after</code> <code>int</code> <p>How many bins of neural data after the output are used for decoding.</p> required <code>bins_current</code> <code>int</code> <p>Whether to use the concurrent time bin of neural data for decoding, by default 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size \"number of total time bins\" x \"number of surrounding time bins used for prediction\" x \"number of neurons\".</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def get_spikes_with_history(\n    neural_data: np.ndarray, bins_before: int, bins_after: int, bins_current: int = 1\n) -&gt; np.ndarray:\n    \"\"\"\n    Create the covariate matrix of neural activity.\n\n    Parameters\n    ----------\n    neural_data : np.ndarray\n        A matrix of size \"number of time bins\" x \"number of neurons\",\n        representing the number of spikes in each time bin for each neuron.\n    bins_before : int\n        How many bins of neural data prior to the output are used for decoding.\n    bins_after : int\n        How many bins of neural data after the output are used for decoding.\n    bins_current : int, optional\n        Whether to use the concurrent time bin of neural data for decoding, by\n        default 1.\n\n    Returns\n    -------\n    np.ndarray\n        A matrix of size \"number of total time bins\" x \"number of surrounding\n        time bins used for prediction\" x \"number of neurons\".\n    \"\"\"\n    num_examples, num_neurons = neural_data.shape\n    surrounding_bins = bins_before + bins_after + bins_current\n    X = np.zeros([num_examples, surrounding_bins, num_neurons])\n\n    for i in range(num_examples - bins_before - bins_after):\n        start_idx = i\n        end_idx = start_idx + surrounding_bins\n        X[i + bins_before] = neural_data[start_idx:end_idx]\n\n    return X\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.minibatchify","title":"<code>minibatchify(Xtrain, ytrain, Xval, yval, Xtest, ytest, seed=0, batch_size=128, num_workers=5, modeltype='MLP')</code>","text":"<p>Create minibatches for training, validation, and testing.</p> <p>Parameters:</p> Name Type Description Default <code>Xtrain</code> <code>NDArray</code> <p>Training features.</p> required <code>ytrain</code> <code>NDArray</code> <p>Training labels.</p> required <code>Xval</code> <code>NDArray</code> <p>Validation features.</p> required <code>yval</code> <code>NDArray</code> <p>Validation labels.</p> required <code>Xtest</code> <code>NDArray</code> <p>Test features.</p> required <code>ytest</code> <code>NDArray</code> <p>Test labels.</p> required <code>seed</code> <code>int</code> <p>Random seed, by default 0.</p> <code>0</code> <code>batch_size</code> <code>int</code> <p>Batch size, by default 128.</p> <code>128</code> <code>num_workers</code> <code>int</code> <p>Number of workers for data loading, by default 5.</p> <code>5</code> <code>modeltype</code> <code>str</code> <p>Type of model, by default 'MLP'.</p> <code>'MLP'</code> <p>Returns:</p> Type Description <code>Tuple[DataLoader, DataLoader, DataLoader]</code> <p>DataLoaders for training, validation, and testing.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def minibatchify(\n    Xtrain: NDArray,\n    ytrain: NDArray,\n    Xval: NDArray,\n    yval: NDArray,\n    Xtest: NDArray,\n    ytest: NDArray,\n    seed: int = 0,\n    batch_size: int = 128,\n    num_workers: int = 5,\n    modeltype: str = \"MLP\",\n) -&gt; Tuple[\n    torch.utils.data.DataLoader,\n    torch.utils.data.DataLoader,\n    torch.utils.data.DataLoader,\n]:\n    \"\"\"\n    Create minibatches for training, validation, and testing.\n\n    Parameters\n    ----------\n    Xtrain : NDArray\n        Training features.\n    ytrain : NDArray\n        Training labels.\n    Xval : NDArray\n        Validation features.\n    yval : NDArray\n        Validation labels.\n    Xtest : NDArray\n        Test features.\n    ytest : NDArray\n        Test labels.\n    seed : int, optional\n        Random seed, by default 0.\n    batch_size : int, optional\n        Batch size, by default 128.\n    num_workers : int, optional\n        Number of workers for data loading, by default 5.\n    modeltype : str, optional\n        Type of model, by default 'MLP'.\n\n    Returns\n    -------\n    Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, torch.utils.data.DataLoader]\n        DataLoaders for training, validation, and testing.\n    \"\"\"\n    g_seed = torch.Generator()\n    g_seed.manual_seed(seed)\n    if Xtrain.ndim == 2:  # handle object arrays\n        Xtrain = Xtrain.astype(np.float32)\n        Xval = Xval.astype(np.float32)\n        Xtest = Xtest.astype(np.float32)\n        ytrain = ytrain.astype(np.float32)\n        yval = yval.astype(np.float32)\n        ytest = ytest.astype(np.float32)\n    train = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xtrain).type(torch.float32),\n        torch.from_numpy(ytrain).type(torch.float32),\n    )\n    val = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xval).type(torch.float32),\n        torch.from_numpy(yval).type(torch.float32),\n    )\n    test = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xtest).type(torch.float32),\n        torch.from_numpy(ytest).type(torch.float32),\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    val_loader = torch.utils.data.DataLoader(\n        val,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        test,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    return train_loader, val_loader, test_loader\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.normalize_format_trial_segs","title":"<code>normalize_format_trial_segs(nsv_train, nsv_rest, bv_train, bv_rest, predict_bv=[4, 5], bins_before=0, bins_current=1, bins_after=0, normparams=None)</code>","text":"<p>Normalize and format trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_train</code> <code>NDArray</code> <p>Neural state vectors for training.</p> required <code>nsv_rest</code> <code>List[NDArray]</code> <p>Neural state vectors for rest.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_rest</code> <code>List[NDArray]</code> <p>Behavioral state vectors for rest.</p> required <code>predict_bv</code> <code>List[int]</code> <p>Indices of behavioral state vectors to predict, by default [4, 5].</p> <code>[4, 5]</code> <code>bins_before</code> <code>int</code> <p>Number of bins before the current bin, by default 0.</p> <code>0</code> <code>bins_current</code> <code>int</code> <p>Number of current bins, by default 1.</p> <code>1</code> <code>bins_after</code> <code>int</code> <p>Number of bins after the current bin, by default 0.</p> <code>0</code> <code>normparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]]</code> <p>Normalized and formatted trial segments.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def normalize_format_trial_segs(\n    nsv_train: NDArray,\n    nsv_rest: List[NDArray],\n    bv_train: NDArray,\n    bv_rest: List[NDArray],\n    predict_bv: List[int] = [4, 5],\n    bins_before: int = 0,\n    bins_current: int = 1,\n    bins_after: int = 0,\n    normparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[\n    NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]\n]:\n    \"\"\"\n    Normalize and format trial segments.\n\n    Parameters\n    ----------\n    nsv_train : NDArray\n        Neural state vectors for training.\n    nsv_rest : List[NDArray]\n        Neural state vectors for rest.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_rest : List[NDArray]\n        Behavioral state vectors for rest.\n    predict_bv : List[int], optional\n        Indices of behavioral state vectors to predict, by default [4, 5].\n    bins_before : int, optional\n        Number of bins before the current bin, by default 0.\n    bins_current : int, optional\n        Number of current bins, by default 1.\n    bins_after : int, optional\n        Number of bins after the current bin, by default 0.\n    normparams : Optional[Dict[str, Any]], optional\n        Normalization parameters, by default None.\n\n    Returns\n    -------\n    Tuple[NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]]\n        Normalized and formatted trial segments.\n    \"\"\"\n    nsv_train_normed, nsv_rest_normed, norm_params = zscore_trial_segs(\n        nsv_train, nsv_rest, normparams\n    )\n\n    (X_train, X_rest, X_flat_train, X_flat_rest, y_train, y_rest) = (\n        format_trial_segs_nsv(\n            nsv_train_normed,\n            nsv_rest_normed,\n            bv_train,\n            bv_rest,\n            predict_bv,\n            bins_before,\n            bins_current,\n            bins_after,\n        )\n    )\n\n    # Zero-center outputs\n    y_train_mean = (\n        normparams[\"y_train_mean\"]\n        if normparams is not None\n        else np.mean(y_train, axis=0)\n    )\n    y_train = y_train - y_train_mean\n    y_centered_rest = []\n    for y in y_rest:\n        y_centered_rest.append(y - y_train_mean)\n\n    norm_params[\"y_train_mean\"] = y_train_mean\n\n    return (\n        X_train,\n        X_flat_train,\n        y_train,\n        tuple(zip(X_rest, X_flat_rest, y_centered_rest)),\n        norm_params,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.normalize_labels","title":"<code>normalize_labels(y_train, y_val, y_test)</code>","text":"<p>Normalize labels to integers in [0, n_classes).</p> <p>Parameters:</p> Name Type Description Default <code>y_train</code> <code>NDArray</code> <p>Training labels.</p> required <code>y_val</code> <code>NDArray</code> <p>Validation labels.</p> required <code>y_test</code> <code>NDArray</code> <p>Test labels.</p> required <p>Returns:</p> Type Description <code>Tuple[Tuple[NDArray, NDArray, NDArray], int]</code> <p>Normalized labels and number of classes.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def normalize_labels(\n    y_train: NDArray, y_val: NDArray, y_test: NDArray\n) -&gt; Tuple[Tuple[NDArray, NDArray, NDArray], int]:\n    \"\"\"\n    Normalize labels to integers in [0, n_classes).\n\n    Parameters\n    ----------\n    y_train : NDArray\n        Training labels.\n    y_val : NDArray\n        Validation labels.\n    y_test : NDArray\n        Test labels.\n\n    Returns\n    -------\n    Tuple[Tuple[NDArray, NDArray, NDArray], int]\n        Normalized labels and number of classes.\n    \"\"\"\n    # map labels to integers in [0, n_classes)\n    uniq_labels = np.unique(np.concatenate((y_train, y_val, y_test)))\n    n_classes = len(uniq_labels)\n    uniq_labels_idx_map = dict(zip(uniq_labels, range(n_classes)))\n    y_train = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_train)\n    y_val = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_val)\n    y_test = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_test)\n    return (y_train, y_val, y_test), n_classes\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.partition_indices","title":"<code>partition_indices(folds)</code>","text":"<p>Partition indices into train, validation, and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>folds</code> <code>List[ndarray]</code> <p>Indices for each fold.</p> required <p>Returns:</p> Type Description <code>List[Tuple[ndarray, ndarray, ndarray]]</code> <p>Train, validation, and test indices.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def partition_indices(\n    folds: List[np.ndarray],\n) -&gt; List[Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n    \"\"\"\n    Partition indices into train, validation, and test sets.\n\n    Parameters\n    ----------\n    folds : List[np.ndarray]\n        Indices for each fold.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray, np.ndarray]]\n        Train, validation, and test indices.\n    \"\"\"\n    partition_mask = np.zeros(len(folds), dtype=int)\n    partition_mask[0:2] = (2, 1)\n    folds_arr = np.asarray(folds, dtype=object)\n\n    partitions_indices = []\n    for i in range(len(folds)):\n        curr_pmask = np.roll(partition_mask, i)\n        train_indices = np.concatenate(folds_arr[curr_pmask == 0]).tolist()\n        val_indices = np.concatenate(folds_arr[curr_pmask == 1]).tolist()\n        test_indices = np.concatenate(folds_arr[curr_pmask == 2]).tolist()\n\n        partitions_indices.append((train_indices, val_indices, test_indices))\n    return partitions_indices\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.partition_sets","title":"<code>partition_sets(partitions_indices, nsv_trial_segs, bv_trial_segs)</code>","text":"<p>Partition neural state vectors and behavioral variables into train, validation, and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>partitions_indices</code> <code>List[Tuple[ndarray, ndarray, ndarray]]</code> <p>List of tuples containing indices of divided trials into train, validation, and test sets.</p> required <code>nsv_trial_segs</code> <code>Union[ndarray, DataFrame]</code> <p>Neural state vectors for each trial. Shape: [n_trials, n_timepoints, n_neurons] or [n_timepoints, n_neurons]</p> required <code>bv_trial_segs</code> <code>Union[ndarray, DataFrame]</code> <p>Behavioral variables for each trial. Shape: [n_trials, n_timepoints, n_bvars] or [n_timepoints, n_bvars]</p> required <p>Returns:</p> Type Description <code>List[Tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray]]</code> <p>List of tuples containing train, validation, and test sets for neural state vectors and behavioral variables.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def partition_sets(\n    partitions_indices: List[Tuple[np.ndarray, np.ndarray, np.ndarray]],\n    nsv_trial_segs: Union[np.ndarray, pd.DataFrame],\n    bv_trial_segs: Union[np.ndarray, pd.DataFrame],\n) -&gt; List[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n]:\n    \"\"\"\n    Partition neural state vectors and behavioral variables into train,\n    validation, and test sets.\n\n    Parameters\n    ----------\n    partitions_indices : List[Tuple[np.ndarray, np.ndarray, np.ndarray]]\n        List of tuples containing indices of divided trials into train,\n        validation, and test sets.\n    nsv_trial_segs : Union[np.ndarray, pd.DataFrame]\n        Neural state vectors for each trial.\n        Shape: [n_trials, n_timepoints, n_neurons] or [n_timepoints, n_neurons]\n    bv_trial_segs : Union[np.ndarray, pd.DataFrame]\n        Behavioral variables for each trial.\n        Shape: [n_trials, n_timepoints, n_bvars] or [n_timepoints, n_bvars]\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n        List of tuples containing train, validation, and test sets for neural\n        state vectors and behavioral variables.\n    \"\"\"\n    partitions = []\n    is_2D = nsv_trial_segs[0].ndim == 1\n    for train_indices, val_indices, test_indices in partitions_indices:\n        if is_2D:\n            if isinstance(nsv_trial_segs, pd.DataFrame):\n                nsv_trial_segs = nsv_trial_segs.loc\n                bv_trial_segs = bv_trial_segs.loc\n            train = nsv_trial_segs[train_indices]\n            val = nsv_trial_segs[val_indices]\n            test = nsv_trial_segs[test_indices]\n            train_bv = bv_trial_segs[train_indices]\n            val_bv = bv_trial_segs[val_indices]\n            test_bv = bv_trial_segs[test_indices]\n        else:\n            train = np.take(nsv_trial_segs, train_indices, axis=0)\n            val = np.take(nsv_trial_segs, val_indices, axis=0)\n            test = np.take(nsv_trial_segs, test_indices, axis=0)\n            train_bv = np.take(bv_trial_segs, train_indices, axis=0)\n            val_bv = np.take(bv_trial_segs, val_indices, axis=0)\n            test_bv = np.take(bv_trial_segs, test_indices, axis=0)\n\n        partitions.append((train, train_bv, val, val_bv, test, test_bv))\n    return partitions\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.predict_models_folds","title":"<code>predict_models_folds(partitions, hyperparams, bv_models_folds, foldnormparams)</code>","text":"<p>Predict and evaluate models across multiple folds.</p> <p>Parameters:</p> Name Type Description Default <code>partitions</code> <code>List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]]</code> <p>List of data partitions for each fold. Each partition contains: (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test)</p> required <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary of hyperparameters for the models.</p> required <code>bv_models_folds</code> <code>List[Any]</code> <p>List of trained models for each fold.</p> required <code>foldnormparams</code> <code>List[Dict[str, Any]]</code> <p>List of normalization parameters for each fold.</p> required <p>Returns:</p> Type Description <code>Tuple[List[NDArray], Dict[str, List[float]]]</code> <p>A tuple containing: - List of predictions for each fold - Dictionary of evaluation metrics for each fold</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def predict_models_folds(\n    partitions: List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]],\n    hyperparams: Dict[str, Any],\n    bv_models_folds: List[Any],\n    foldnormparams: List[Dict[str, Any]],\n) -&gt; Tuple[List[NDArray], Dict[str, List[float]]]:\n    \"\"\"\n    Predict and evaluate models across multiple folds.\n\n    Parameters\n    ----------\n    partitions : List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]]\n        List of data partitions for each fold. Each partition contains:\n        (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test)\n    hyperparams : Dict[str, Any]\n        Dictionary of hyperparameters for the models.\n    bv_models_folds : List[Any]\n        List of trained models for each fold.\n    foldnormparams : List[Dict[str, Any]]\n        List of normalization parameters for each fold.\n\n    Returns\n    -------\n    Tuple[List[NDArray], Dict[str, List[float]]]\n        A tuple containing:\n        - List of predictions for each fold\n        - Dictionary of evaluation metrics for each fold\n    \"\"\"\n    ohe = sklearn.preprocessing.OneHotEncoder()\n    bv_preds_folds = []\n    metrics_folds = dict()\n    for i, (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test) in enumerate(\n        partitions\n    ):\n        preprocessed_data = preprocess_data(\n            hyperparams,\n            ohe,\n            nsv_train,\n            nsv_val,\n            nsv_test,\n            bv_train,\n            bv_val,\n            bv_test,\n            foldnormparams[i],\n        )\n        (\n            (X_train, y_train, X_val, y_val, X_test, y_test),\n            (train_loader, val_loader, test_loader),\n            fold_norm_params,\n        ) = preprocessed_data\n        model = bv_models_folds[i]\n\n        model.eval()\n        predictor = model if hyperparams[\"model\"] != \"LSTM\" else model.predict\n        metrics, bv_preds_fold = evaluate_model(\n            hyperparams, ohe, predictor, X_test, y_test\n        )\n        bv_preds_folds.append(bv_preds_fold)\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            if \"accuracy\" not in metrics_folds:\n                metrics_folds[\"accuracy\"] = []\n            metrics_folds[\"accuracy\"].append(metrics[\"accuracy\"])\n        else:\n            coeff_determination = metrics[\"coeff_determination\"]\n            rmse = metrics[\"rmse\"]\n            if \"coeff_determination\" not in metrics_folds:\n                metrics_folds[\"coeff_determination\"] = []\n                metrics_folds[\"rmse\"] = []\n            metrics_folds[\"coeff_determination\"].append(coeff_determination)\n            metrics_folds[\"rmse\"].append(rmse)\n\n    return bv_preds_folds, metrics_folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.preprocess_data","title":"<code>preprocess_data(hyperparams, ohe, nsv_train, nsv_val, nsv_test, bv_train, bv_val, bv_test, foldnormparams=None)</code>","text":"<p>Preprocess the data for model training and evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing hyperparameters.</p> required <code>ohe</code> <code>OneHotEncoder</code> <p>One-hot encoder for categorical variables.</p> required <code>nsv_train</code> <code>NDArray</code> <p>Neural state vectors for training.</p> required <code>nsv_val</code> <code>NDArray</code> <p>Neural state vectors for validation.</p> required <code>nsv_test</code> <code>NDArray</code> <p>Neural state vectors for testing.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_val</code> <code>NDArray</code> <p>Behavioral state vectors for validation.</p> required <code>bv_test</code> <code>NDArray</code> <p>Behavioral state vectors for testing.</p> required <code>foldnormparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters for the current fold, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray], Tuple[DataLoader, DataLoader, DataLoader], Dict[str, Any]]</code> <p>Preprocessed data, data loaders, and normalization parameters.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def preprocess_data(\n    hyperparams: Dict[str, Any],\n    ohe: sklearn.preprocessing.OneHotEncoder,\n    nsv_train: NDArray,\n    nsv_val: NDArray,\n    nsv_test: NDArray,\n    bv_train: NDArray,\n    bv_val: NDArray,\n    bv_test: NDArray,\n    foldnormparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[\n    Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray],\n    Tuple[\n        torch.utils.data.DataLoader,\n        torch.utils.data.DataLoader,\n        torch.utils.data.DataLoader,\n    ],\n    Dict[str, Any],\n]:\n    \"\"\"\n    Preprocess the data for model training and evaluation.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing hyperparameters.\n    ohe : OneHotEncoder\n        One-hot encoder for categorical variables.\n    nsv_train : NDArray\n        Neural state vectors for training.\n    nsv_val : NDArray\n        Neural state vectors for validation.\n    nsv_test : NDArray\n        Neural state vectors for testing.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_val : NDArray\n        Behavioral state vectors for validation.\n    bv_test : NDArray\n        Behavioral state vectors for testing.\n    foldnormparams : Optional[Dict[str, Any]], optional\n        Normalization parameters for the current fold, by default None.\n\n    Returns\n    -------\n    Tuple[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray], Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, torch.utils.data.DataLoader], Dict[str, Any]]\n        Preprocessed data, data loaders, and normalization parameters.\n    \"\"\"\n    bins_before = hyperparams[\"bins_before\"]\n    bins_current = hyperparams[\"bins_current\"]\n    bins_after = hyperparams[\"bins_after\"]\n    is_2D = nsv_train[0].ndim == 1\n    if hyperparams[\"model\"] not in (\"M2MLSTM\", \"NDT\"):\n        (\n            X_cov_train,\n            X_flat_train,\n            y_train,\n            ((X_cov_val, X_flat_val, y_val), (X_cov_test, X_flat_test, y_test)),\n            fold_norm_params,\n        ) = normalize_format_trial_segs(\n            nsv_train,\n            (nsv_val, nsv_test),\n            bv_train,\n            (bv_val, bv_test),\n            predict_bv=hyperparams[\"behaviors\"],\n            bins_before=bins_before,\n            bins_current=bins_current,\n            bins_after=bins_after,\n            normparams=foldnormparams,\n        )\n        X_train = X_cov_train if hyperparams[\"model\"] == \"LSTM\" else X_flat_train\n        X_val = X_cov_val if hyperparams[\"model\"] == \"LSTM\" else X_flat_val\n        X_test = X_cov_test if hyperparams[\"model\"] == \"LSTM\" else X_flat_test\n\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            (y_train, y_val, y_test), n_classes = normalize_labels(\n                y_train, y_val, y_test\n            )\n            y_train = ohe.fit_transform(y_train).toarray()\n            y_val = ohe.transform(y_val).toarray()\n            y_test = ohe.transform(y_test).toarray()\n            hyperparams[\"model_args\"][\"out_dim\"] = n_classes\n            fold_norm_params[\"ohe\"] = ohe\n\n        train_loader, val_loader, test_loader = minibatchify(\n            X_train,\n            y_train,\n            X_val,\n            y_val,\n            X_test,\n            y_test,\n            seed=hyperparams[\"seed\"],\n            batch_size=hyperparams[\"batch_size\"],\n            num_workers=hyperparams[\"num_workers\"],\n            modeltype=hyperparams[\"model\"],\n        )\n        hyperparams[\"model_args\"][\"in_dim\"] = X_train.shape[-1]\n    else:\n        if is_2D:\n            nsv_train, bv_train = [nsv_train], [bv_train]\n            nsv_val, bv_val = [nsv_val], [bv_val]\n            nsv_test, bv_test = [nsv_test], [bv_test]\n        if type(bv_train[0]) is pd.DataFrame:\n            y_train = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_train]\n        else:\n            y_train = [y[:, hyperparams[\"behaviors\"]] for y in bv_train]\n        nbins_per_tseg = [len(y) for y in y_train]  # number of time bins in each trial\n        tseg_bounds_train = np.cumsum([0] + nbins_per_tseg)\n        if type(bv_val[0]) is pd.DataFrame:\n            y_val = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_val]\n        else:\n            y_val = [y[:, hyperparams[\"behaviors\"]] for y in bv_val]\n        nbins_per_tseg = [len(y) for y in y_val]\n        tseg_bounds_val = np.cumsum([0] + nbins_per_tseg)\n        if type(bv_test[0]) is pd.DataFrame:\n            y_test = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_test]\n        else:\n            y_test = [y[:, hyperparams[\"behaviors\"]] for y in bv_test]\n        nbins_per_tseg = [len(y) for y in y_test]\n        tseg_bounds_test = np.cumsum([0] + nbins_per_tseg)\n\n        (\n            _,\n            X_flat_train,\n            y_train,\n            ((_, X_flat_val, y_val), (_, X_flat_test, y_test)),\n            fold_norm_params,\n        ) = normalize_format_trial_segs(\n            nsv_train,\n            (nsv_val, nsv_test),\n            bv_train,\n            (bv_val, bv_test, bv_test),\n            predict_bv=hyperparams[\"behaviors\"],\n            bins_before=bins_before,\n            bins_current=bins_current,\n            bins_after=bins_after,\n            normparams=foldnormparams,\n        )\n        X_train = X_flat_train\n        X_val = X_flat_val\n        X_test = X_flat_test\n\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            (y_train, y_val, y_test), n_classes = normalize_labels(\n                y_train, y_val, y_test\n            )\n            y_train = ohe.fit_transform(y_train).toarray()\n            y_val = ohe.transform(y_val).toarray()\n            y_test = ohe.transform(y_test).toarray()\n            hyperparams[\"model_args\"][\"out_dim\"] = n_classes\n            fold_norm_params[\"ohe\"] = ohe\n\n        X_train_tsegs, y_train_tsegs = [], []\n        X_val_tsegs, y_val_tsegs = [], []\n        X_test_tsegs, y_test_tsegs = [], []\n        for i in range(1, len(tseg_bounds_train)):\n            X_train_tsegs.append(\n                X_train[tseg_bounds_train[i - 1] : tseg_bounds_train[i]]\n            )\n            y_train_tsegs.append(\n                y_train[tseg_bounds_train[i - 1] : tseg_bounds_train[i]]\n            )\n        for i in range(1, len(tseg_bounds_val)):\n            X_val_tsegs.append(X_val[tseg_bounds_val[i - 1] : tseg_bounds_val[i]])\n            y_val_tsegs.append(y_val[tseg_bounds_val[i - 1] : tseg_bounds_val[i]])\n        for i in range(1, len(tseg_bounds_test)):\n            X_test_tsegs.append(X_test[tseg_bounds_test[i - 1] : tseg_bounds_test[i]])\n            y_test_tsegs.append(y_test[tseg_bounds_test[i - 1] : tseg_bounds_test[i]])\n\n        X_train, y_train = X_train_tsegs, y_train_tsegs\n        X_val, y_val = X_val_tsegs, y_val_tsegs\n        X_test, y_test = X_test_tsegs, y_test_tsegs\n\n        train_dataset = NSVDataset(X_train, y_train)\n        val_dataset = NSVDataset(X_val, y_val)\n        test_dataset = NSVDataset(X_test, y_test)\n\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            shuffle=True,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        val_loader = torch.utils.data.DataLoader(\n            val_dataset,\n            shuffle=False,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        test_loader = torch.utils.data.DataLoader(\n            test_dataset,\n            shuffle=False,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        hyperparams[\"model_args\"][\"in_dim\"] = X_train[0].shape[-1]\n\n    return (\n        (X_train, y_train, X_val, y_val, X_test, y_test),\n        (train_loader, val_loader, test_loader),\n        fold_norm_params,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.seed_worker","title":"<code>seed_worker(worker_id)</code>","text":"<p>Seed a worker with the given ID for reproducibility in data loading.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>The ID of the worker to be seeded.</p> required Notes <p>This function is used to ensure reproducibility when using multi-process data loading.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def seed_worker(worker_id: int) -&gt; None:\n    \"\"\"\n    Seed a worker with the given ID for reproducibility in data loading.\n\n    Parameters\n    ----------\n    worker_id : int\n        The ID of the worker to be seeded.\n\n    Notes\n    -----\n    This function is used to ensure reproducibility when using multi-process data loading.\n    \"\"\"\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.shuffle_nsv_intrialsegs","title":"<code>shuffle_nsv_intrialsegs(nsv_trialsegs)</code>","text":"<p>Shuffle neural state variables within trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_trialsegs</code> <code>List[DataFrame]</code> <p>List of neural state variable trial segments.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Shuffled neural state variables.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def shuffle_nsv_intrialsegs(nsv_trialsegs: List[pd.DataFrame]) -&gt; NDArray:\n    \"\"\"\n    Shuffle neural state variables within trial segments.\n\n    Parameters\n    ----------\n    nsv_trialsegs : List[pd.DataFrame]\n        List of neural state variable trial segments.\n\n    Returns\n    -------\n    NDArray\n        Shuffled neural state variables.\n    \"\"\"\n    nsv_shuffled_intrialsegs = []\n    for nsv_tseg in nsv_trialsegs:\n        # shuffle the data\n        nsv_shuffled_intrialsegs.append(nsv_tseg.sample(frac=1).reset_index(drop=True))\n    return np.asarray(nsv_shuffled_intrialsegs, dtype=object)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.split_data","title":"<code>split_data(trial_nsvs, splitby, trainsize=0.8, seed=0)</code>","text":"<p>Split data into stratified folds.</p> <p>Parameters:</p> Name Type Description Default <code>trial_nsvs</code> <code>ndarray</code> <p>Neural state vectors for trials.</p> required <code>splitby</code> <code>ndarray</code> <p>Labels for stratification.</p> required <code>trainsize</code> <code>float</code> <p>Proportion of data to use for training, by default 0.8</p> <code>0.8</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility, by default 0</p> <code>0</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List of indices for each fold.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def split_data(\n    trial_nsvs: np.ndarray, splitby: np.ndarray, trainsize: float = 0.8, seed: int = 0\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Split data into stratified folds.\n\n    Parameters\n    ----------\n    trial_nsvs : np.ndarray\n        Neural state vectors for trials.\n    splitby : np.ndarray\n        Labels for stratification.\n    trainsize : float, optional\n        Proportion of data to use for training, by default 0.8\n    seed : int, optional\n        Random seed for reproducibility, by default 0\n\n    Returns\n    -------\n    List[np.ndarray]\n        List of indices for each fold.\n    \"\"\"\n    n_splits = int(np.round(1 / ((1 - trainsize) / 2)))\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    folds = [fold_indices for _, fold_indices in skf.split(trial_nsvs, splitby)]\n    return folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.train_model","title":"<code>train_model(partitions, hyperparams, resultspath=None, stop_partition=None)</code>","text":"<p>Train a DNN model on the given data partitions with in-built caching &amp; checkpointing.</p> <p>Parameters:</p> Name Type Description Default <code>partitions</code> <code>List[Tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray]]</code> <p>K-fold partitions of the data with the following format: [(nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test), ...] Each element of the list is a tuple of numpy arrays containing the with pairs of neural state vectors and behavioral variables for the training, validation, and test sets. Each array has the shape (ntrials, nbins, nfeats) where nfeats is the number of neurons for the neural state vectors and number of behavioral features to be predicted for the behavioral variables.</p> required <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing the hyperparameters for the model training.</p> required <code>resultspath</code> <code>Optional[str]</code> <p>Path to the directory where the trained models and logs will be saved.</p> <code>None</code> <code>stop_partition</code> <code>Optional[int]</code> <p>Index of the partition to stop training at. Only useful for debugging, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple containing the predicted behavioral variables for each fold, the trained models for each fold, the normalization parameters for each fold, and the evaluation metrics for each fold.</p> Notes <p>The hyperparameters dictionary should contain the following keys: - <code>model</code>: str, the type of the model to be trained. Multi-layer     Perceptron (MLP), Long Short-Term Memory (LSTM), many-to-many LSTM     (M2MLSTM), Transformer (NDT). - <code>model_args</code>: dict, the arguments to be passed to the model constructor.     The arguments should be in the format expected by the model constructor.     - <code>in_dim</code>: The number of input features.     - <code>out_dim</code>: The number of output features.     - <code>hidden_dims</code>: The number of hidden units each hidden layer of the         model. Can also take float values to specify the dropout rate.         - For LSTM and M2MLSTM, it should be a tuple of the hidden size,             the number of layers, and the dropout rate.             If the model is an MLP, it should be a list of hidden layer             sizes which can also take float values to specify the dropout             rate.         - If the model is an LSTM or M2MLSTM, it should be a list of the         hidden layer size, the number of layers, and the dropout rate.         - If the model is an NDT, it should be a list of the hidden layer             size, the number of layers, the number of attention heads, the             dropout rate for the encoder layer, and the dropout rate applied             before the decoder layer.     - <code>max_context_len</code>: The maximum context length for the transformer         model. Only used if the model is an NDT.     - <code>args</code>:         - <code>clf</code>: If True, the model is a classifier; otherwise, it is a             regressor.         - <code>activations</code>: The activation functions for each layer.         - <code>criterion</code>: The loss function to optimize.         - <code>epochs</code>: The number of complete passes through the training             dataset.         - <code>lr</code>: Controls how much to change the model in response to the             estimated error each time the model weights are updated. A             smaller value ensures stable convergence but may slow down             training, while a larger value speeds up training but risks             overshooting.         - <code>base_lr</code>: The initial learning rate for the learning rate             scheduler.         - <code>max_grad_norm</code>: The maximum norm of the gradients.         - <code>iters_to_accumulate</code>: The number of iterations to accumulate             gradients.         - <code>weight_decay</code>: The L2 regularization strength.         - <code>num_training_batches</code>: The number of training batches. If             None, the number of batches is calculated based on the batch             size and the length of the training data.         - <code>scheduler_step_size_multiplier</code>: The multiplier for the             learning rate scheduler step size. Higher values lead to             faster learning rate decay. - <code>bins_before</code>: int, the number of bins before the current bin to     include in the input data. - <code>bins_current</code>: int, the number of bins in the current time bin to     include in the input data. - <code>bins_after</code>: int, the number of bins after the current bin to include     in the input data. - <code>behaviors</code>: list, the indices of the columns of behavioral features     to be predicted. Selected behavioral variable must have homogenous     data types across all features (continuous for regression and     categorical for classification) - <code>batch_size</code>: int, the number of training examples utilized in one     iteration. Larger batch sizes offer stable gradient estimates but     require more memory, while smaller batches introduce noise that can     help escape local minima.     - When using M2MLSTM or NDT and input trials are of inconsistents         lengths, the batch size should be set to 1.     - M2MLSTM does not support batch_size != 1. - <code>num_workers</code>: int, The number of parallel processes to use for data     loading. Increasing the number of workers can speed up data loading     but may lead to memory issues. Too many workers can also slow down     the training process due to contention for resources. - <code>accelerator</code>: str, the device to use for training. Should be 'cuda' or     'cpu'. - <code>seed</code>: int, the random seed for reproducibility.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def train_model(\n    partitions: List[\n        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n    ],\n    hyperparams: Dict[str, Any],\n    resultspath: Optional[str] = None,\n    stop_partition: Optional[int] = None,\n) -&gt; Tuple[List[np.ndarray], List[Any], List[Dict[str, Any]], Dict[str, List[float]]]:\n    \"\"\"\n    Train a DNN model on the given data partitions with in-built caching &amp; checkpointing.\n\n    Parameters\n    ----------\n    partitions : List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n        K-fold partitions of the data with the following format:\n        [(nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test), ...]\n        Each element of the list is a tuple of numpy arrays containing the with\n        pairs of neural state vectors and behavioral variables for the training,\n        validation, and test sets. Each array has the shape\n        (ntrials, nbins, nfeats) where nfeats is the number of neurons for the\n        neural state vectors and number of behavioral features to be predicted\n        for the behavioral variables.\n    hyperparams : Dict[str, Any]\n        Dictionary containing the hyperparameters for the model training.\n    resultspath : Optional[str], default=None\n        Path to the directory where the trained models and logs will be saved.\n    stop_partition : Optional[int], default=None\n        Index of the partition to stop training at. Only useful for debugging,\n        by default None\n\n    Returns\n    -------\n    tuple\n        Tuple containing the predicted behavioral variables for each fold,\n        the trained models for each fold, the normalization parameters for each\n        fold, and the evaluation metrics for each fold.\n\n    Notes\n    -----\n    The hyperparameters dictionary should contain the following keys:\n    - `model`: str, the type of the model to be trained. Multi-layer\n        Perceptron (MLP), Long Short-Term Memory (LSTM), many-to-many LSTM\n        (M2MLSTM), Transformer (NDT).\n    - `model_args`: dict, the arguments to be passed to the model constructor.\n        The arguments should be in the format expected by the model constructor.\n        - `in_dim`: The number of input features.\n        - `out_dim`: The number of output features.\n        - `hidden_dims`: The number of hidden units each hidden layer of the\n            model. Can also take float values to specify the dropout rate.\n            - For LSTM and M2MLSTM, it should be a tuple of the hidden size,\n                the number of layers, and the dropout rate.\n                If the model is an MLP, it should be a list of hidden layer\n                sizes which can also take float values to specify the dropout\n                rate.\n            - If the model is an LSTM or M2MLSTM, it should be a list of the\n            hidden layer size, the number of layers, and the dropout rate.\n            - If the model is an NDT, it should be a list of the hidden layer\n                size, the number of layers, the number of attention heads, the\n                dropout rate for the encoder layer, and the dropout rate applied\n                before the decoder layer.\n        - `max_context_len`: The maximum context length for the transformer\n            model. Only used if the model is an NDT.\n        - `args`:\n            - `clf`: If True, the model is a classifier; otherwise, it is a\n                regressor.\n            - `activations`: The activation functions for each layer.\n            - `criterion`: The loss function to optimize.\n            - `epochs`: The number of complete passes through the training\n                dataset.\n            - `lr`: Controls how much to change the model in response to the\n                estimated error each time the model weights are updated. A\n                smaller value ensures stable convergence but may slow down\n                training, while a larger value speeds up training but risks\n                overshooting.\n            - `base_lr`: The initial learning rate for the learning rate\n                scheduler.\n            - `max_grad_norm`: The maximum norm of the gradients.\n            - `iters_to_accumulate`: The number of iterations to accumulate\n                gradients.\n            - `weight_decay`: The L2 regularization strength.\n            - `num_training_batches`: The number of training batches. If\n                None, the number of batches is calculated based on the batch\n                size and the length of the training data.\n            - `scheduler_step_size_multiplier`: The multiplier for the\n                learning rate scheduler step size. Higher values lead to\n                faster learning rate decay.\n    - `bins_before`: int, the number of bins before the current bin to\n        include in the input data.\n    - `bins_current`: int, the number of bins in the current time bin to\n        include in the input data.\n    - `bins_after`: int, the number of bins after the current bin to include\n        in the input data.\n    - `behaviors`: list, the indices of the columns of behavioral features\n        to be predicted. Selected behavioral variable must have homogenous\n        data types across all features (continuous for regression and\n        categorical for classification)\n    - `batch_size`: int, the number of training examples utilized in one\n        iteration. Larger batch sizes offer stable gradient estimates but\n        require more memory, while smaller batches introduce noise that can\n        help escape local minima.\n        - When using M2MLSTM or NDT and input trials are of inconsistents\n            lengths, the batch size should be set to 1.\n        - M2MLSTM does not support batch_size != 1.\n    - `num_workers`: int, The number of parallel processes to use for data\n        loading. Increasing the number of workers can speed up data loading\n        but may lead to memory issues. Too many workers can also slow down\n        the training process due to contention for resources.\n    - `accelerator`: str, the device to use for training. Should be 'cuda' or\n        'cpu'.\n    - `seed`: int, the random seed for reproducibility.\n    \"\"\"\n    ohe = sklearn.preprocessing.OneHotEncoder()\n    bv_preds_folds = []\n    bv_models_folds = []\n    norm_params_folds = []\n    metrics_folds = dict()  # dict with keys 'accuracy', 'coeff_determination', 'rmse' and values of length number of folds\n    for i, (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test) in enumerate(\n        partitions\n    ):\n        # shuffle nsv bins in between tsegs to generate baseline distribution for vector dev plots\n        preprocessed_data = preprocess_data(\n            hyperparams, ohe, nsv_train, nsv_val, nsv_test, bv_train, bv_val, bv_test\n        )\n        (\n            (X_train, y_train, X_val, y_val, X_test, y_test),\n            (train_loader, val_loader, test_loader),\n            fold_norm_params,\n        ) = preprocessed_data\n        hyperparams[\"model_args\"][\"args\"][\"num_training_batches\"] = len(train_loader)\n\n        decoder, model = create_model(hyperparams)\n\n        hyperparams_cp = copy.deepcopy(hyperparams)\n        del hyperparams_cp[\"model_args\"][\"args\"][\"epochs\"]\n        del hyperparams_cp[\"model_args\"][\"args\"][\"num_training_batches\"]\n        model_cache_name = zlib.crc32(str(hyperparams_cp).encode(\"utf-8\"))\n        best_ckpt_path = None\n        if resultspath is not None:\n            model_cache_path = os.path.join(\n                resultspath, \"models\", str(model_cache_name)\n            )\n            best_ckpt_name_file = os.path.join(model_cache_path, f\"{i}-best_model.txt\")\n            if os.path.exists(best_ckpt_name_file):\n                with open(best_ckpt_name_file, \"r\") as f:\n                    best_ckpt_path = f.read()\n\n        lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n        callbacks = [lr_monitor]\n        if resultspath is not None:\n            checkpoint_callback = pl.callbacks.ModelCheckpoint(\n                save_top_k=1,\n                monitor=\"val_loss\",\n                dirpath=model_cache_path,\n                filename=f\"{i}\" + \"-{epoch:02d}-{val_loss:.2f}\",\n            )\n            callbacks.append(checkpoint_callback)\n        logger = pl.loggers.TensorBoardLogger(\n            save_dir=\"logs\",\n            name=f\"{model_cache_name}-{i}\",\n        )\n        pl.seed_everything(hyperparams[\"seed\"], workers=True)\n        trainer = pl.Trainer(\n            accelerator=hyperparams[\"accelerator\"],\n            devices=\"auto\",\n            max_epochs=hyperparams[\"model_args\"][\"args\"][\"epochs\"],\n            gradient_clip_val=hyperparams[\"model_args\"][\"args\"][\"max_grad_norm\"],\n            accumulate_grad_batches=hyperparams[\"model_args\"][\"args\"][\n                \"iters_to_accumulate\"\n            ],\n            logger=logger,\n            callbacks=callbacks,\n            enable_progress_bar=False,\n            log_every_n_steps=5,\n            reload_dataloaders_every_n_epochs=1,\n        )\n        trainer.fit(model, train_loader, val_loader, ckpt_path=best_ckpt_path)\n        if resultspath is not None:\n            os.makedirs(model_cache_path, exist_ok=True)\n            with open(best_ckpt_name_file, \"w\") as f:\n                f.write(checkpoint_callback.best_model_path)\n        model.eval()\n        trainer.test(model, test_loader)\n        predictor = model if hyperparams[\"model\"] != \"LSTM\" else model.predict\n\n        metrics, bv_preds_fold = evaluate_model(\n            hyperparams, ohe, predictor, X_test, y_test\n        )\n        bv_preds_folds.append(bv_preds_fold)\n        bv_models_folds.append(model)\n        norm_params_folds.append(copy.deepcopy(fold_norm_params))\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            print(\"Accuracy:\", metrics[\"accuracy\"])\n            if \"accuracy\" not in metrics_folds:\n                metrics_folds[\"accuracy\"] = []\n            metrics_folds[\"accuracy\"].append(metrics[\"accuracy\"])\n        else:\n            coeff_determination = metrics[\"coeff_determination\"]\n            rmse = metrics[\"rmse\"]\n            print(\n                \"Variance weighed avg. coefficient of determination:\",\n                coeff_determination,\n            )\n            print(\"RMSE:\", rmse)\n\n            if \"coeff_determination\" not in metrics_folds:\n                metrics_folds[\"coeff_determination\"] = []\n                metrics_folds[\"rmse\"] = []\n            metrics_folds[\"coeff_determination\"].append(coeff_determination)\n            metrics_folds[\"rmse\"].append(rmse)\n\n        if stop_partition is not None and i == stop_partition:\n            break\n    return bv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/#neuro_py.ensemble.decoding.zscore_trial_segs","title":"<code>zscore_trial_segs(train, rest_feats=None, normparams=None)</code>","text":"<p>Z-score trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>train</code> <code>NDArray</code> <p>Training data.</p> required <code>rest_feats</code> <code>Optional[List[NDArray]]</code> <p>Rest features, by default None.</p> <code>None</code> <code>normparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, List[NDArray], Dict[str, Any]]</code> <p>Normalized train data, normalized rest features, and normalization parameters.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def zscore_trial_segs(\n    train: NDArray,\n    rest_feats: Optional[List[NDArray]] = None,\n    normparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[NDArray, List[NDArray], Dict[str, Any]]:\n    \"\"\"\n    Z-score trial segments.\n\n    Parameters\n    ----------\n    train : NDArray\n        Training data.\n    rest_feats : Optional[List[NDArray]], optional\n        Rest features, by default None.\n    normparams : Optional[Dict[str, Any]], optional\n        Normalization parameters, by default None.\n\n    Returns\n    -------\n    Tuple[NDArray, List[NDArray], Dict[str, Any]]\n        Normalized train data, normalized rest features, and normalization parameters.\n    \"\"\"\n    is_2D = train[0].ndim == 1\n    concat_train = train if is_2D else np.concatenate(train).astype(float)\n    train_mean = (\n        normparams[\"X_train_mean\"]\n        if normparams is not None\n        else bn.nanmean(concat_train, axis=0)\n    )\n    train_std = (\n        normparams[\"X_train_std\"]\n        if normparams is not None\n        else bn.nanstd(concat_train, axis=0)\n    )\n\n    train_notnan_cols = train_std != 0\n    train_nan_cols = ~train_notnan_cols\n    if is_2D:\n        normed_train = np.divide(train - train_mean, train_std, where=train_notnan_cols)\n        # if train is not jagged, it gets converted completely to object\n        # np.ndarray. Hence, cannot exclusively use normed_train.loc\n        if isinstance(normed_train, pd.DataFrame):\n            normed_train.loc[:, train_nan_cols] = 0\n        else:\n            normed_train[:, train_nan_cols] = 0\n    else:\n        normed_train = np.empty_like(train)\n        for i, nsvstseg in enumerate(train):\n            zscored = np.divide(\n                nsvstseg - train_mean, train_std, where=train_notnan_cols\n            )\n            if isinstance(zscored, pd.DataFrame):\n                zscored.loc[:, train_nan_cols] = 0\n            else:\n                zscored[:, train_nan_cols] = 0\n            normed_train[i] = zscored\n\n    normed_rest_feats = []\n    if rest_feats is not None:\n        for feats in rest_feats:\n            if is_2D:\n                normed_feats = np.divide(\n                    feats - train_mean, train_std, where=train_notnan_cols\n                )\n                if isinstance(normed_feats, pd.DataFrame):\n                    normed_feats.loc[:, train_nan_cols] = 0\n                else:\n                    normed_feats[:, train_nan_cols] = 0\n                normed_rest_feats.append(normed_feats)\n            else:\n                normed_feats = np.empty_like(feats)\n                for i, trialSegROI in enumerate(feats):\n                    zscored = np.divide(\n                        feats[i] - train_mean, train_std, where=train_notnan_cols\n                    )\n                    if isinstance(zscored, pd.DataFrame):\n                        zscored.loc[:, train_nan_cols] = 0\n                    else:\n                        zscored[:, train_nan_cols] = 0\n                    normed_feats[i] = zscored\n                normed_rest_feats.append(normed_feats)\n\n    return (\n        normed_train,\n        normed_rest_feats,\n        dict(\n            X_train_mean=train_mean,\n            X_train_std=train_std,\n            X_train_notnan_mask=train_notnan_cols,\n        ),\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/","title":"neuro_py.ensemble.decoding.bayesian","text":""},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode","title":"<code>decode(ct, tc, occupancy, bin_size_s, uniform_prior=False)</code>","text":"<p>Decode position from spike counts in an N-dimensional spatial environment</p> <p>Parameters:</p> Name Type Description Default <code>ct</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape (n_bins, n_cells)</p> required <code>tc</code> <code>ndarray</code> <p>ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)</p> required <code>occupancy</code> <code>ndarray</code> <p>(N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)</p> required <code>bin_size_s</code> <code>float</code> <p>float, width of each time bin in seconds</p> required <code>uniform_prior</code> <code>bool</code> <p>bool, whether to use uniform prior, by default False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>p</code> <code>ndarray</code> <p>(N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)</p> <p>Examples:</p>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode--1d-example","title":"1D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode--2d-example","title":"2D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode--3d-example","title":"3D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre> Source code in <code>neuro_py/ensemble/decoding/bayesian.py</code> <pre><code>@njit(parallel=True, fastmath=True)\ndef decode(\n    ct: np.ndarray,\n    tc: np.ndarray,\n    occupancy: np.ndarray,\n    bin_size_s: float,\n    uniform_prior: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode position from spike counts in an N-dimensional spatial environment\n\n    Parameters\n    ----------\n    ct : ndarray\n        2D array, spike counts matrix with shape (n_bins, n_cells)\n    tc : ndarray\n        ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)\n    occupancy : ndarray\n        (N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)\n    bin_size_s : float\n        float, width of each time bin in seconds\n    uniform_prior : bool, optional\n        bool, whether to use uniform prior, by default False\n\n    Returns\n    ----------\n    p : ndarray\n        (N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)\n\n    Examples\n    ----------\n    # 1D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 2D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 3D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n    \"\"\"\n\n    # Ensure input arrays are contiguous for vectorization\n    ct = np.ascontiguousarray(ct)\n    tc = np.ascontiguousarray(tc)\n    occupancy = np.ascontiguousarray(occupancy)\n\n    # Validate input shapes\n    assert ct.ndim == 2, \"ct must be a 2D array with shape (n_bins, n_cells)\"\n    assert tc.ndim &gt;= 2, (\n        \"tc must be at least a 2D array with shape (n_xbins, ..., n_cells)\"\n    )\n    assert occupancy.ndim == tc.ndim - 1, (\n        \"occupancy must have one fewer dimension than tc\"\n    )\n    assert ct.shape[1] == tc.shape[-1], \"Number of cells in ct and tc must match\"\n\n    # Flatten spatial dimensions\n    n_cells = tc.shape[-1]\n    spatial_shape = tc.shape[:-1]  # Shape of spatial dimensions\n\n    # Calculate the total number of spatial bins\n    n_spatial_bins = 1\n    for dim in spatial_shape:\n        n_spatial_bins *= dim\n\n    tc_flat = tc.reshape(n_spatial_bins, n_cells)\n    occupancy_flat = occupancy.flatten()\n\n    if uniform_prior:\n        # Use uniform prior\n        occupancy_flat = np.ones_like(occupancy_flat)\n\n    # Precompute log values\n    log_tc_flat = np.log(tc_flat + 1e-10)  # add small value to avoid log(0)\n    log_p1 = -tc_flat.sum(axis=1) * bin_size_s\n    log_p2 = np.log(occupancy_flat / occupancy_flat.sum())\n\n    # Initialize the probability matrix\n    n_bins = ct.shape[0]\n    p = np.zeros((n_bins, n_spatial_bins))\n\n    # Vectorized calculation of log probabilities\n    for i in prange(n_bins):  # prange for parallel loop\n        log_likelihood = log_p1 + log_p2 + np.sum(log_tc_flat * ct[i, :], axis=1)\n        p[i, :] = np.exp(\n            log_likelihood - np.max(log_likelihood)\n        )  # Subtract max for numerical stability\n\n    # Normalize the probabilities along the spatial axis\n    p_sum = p.sum(axis=1)  # Sum over spatial bins\n    p = p / p_sum.reshape(-1, 1)  # Reshape p_sum to (n_bins, 1) for broadcasting\n\n    # Reshape the probabilities to the original spatial dimensions\n    p = p.reshape((n_bins,) + spatial_shape)\n\n    return p\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode_with_prior_fallback","title":"<code>decode_with_prior_fallback(ct, tc, occupancy, bin_size_s, uniform_prior=False)</code>","text":"<p>Decode position from spike counts in an N-dimensional spatial environment</p> <p>Parameters:</p> Name Type Description Default <code>ct</code> <code>ndarray</code> <p>2D array, spike counts matrix with shape (n_bins, n_cells)</p> required <code>tc</code> <code>ndarray</code> <p>ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)</p> required <code>occupancy</code> <code>ndarray</code> <p>(N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)</p> required <code>bin_size_s</code> <code>float</code> <p>float, width of each time bin in seconds</p> required <code>uniform_prior</code> <code>bool</code> <p>bool, whether to use uniform prior, by default False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>p</code> <code>ndarray</code> <p>(N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)</p> <p>Examples:</p>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode_with_prior_fallback--1d-example","title":"1D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode_with_prior_fallback--2d-example","title":"2D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/bayesian/#neuro_py.ensemble.decoding.bayesian.decode_with_prior_fallback--3d-example","title":"3D example","text":"<pre><code>&gt;&gt;&gt; ct = np.random.rand(10, 5)\n&gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n&gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n&gt;&gt;&gt; bin_size_s = 0.1\n&gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n</code></pre> Source code in <code>neuro_py/ensemble/decoding/bayesian.py</code> <pre><code>@njit(parallel=True, fastmath=True, cache=True)\ndef decode_with_prior_fallback(\n    ct: np.ndarray,\n    tc: np.ndarray,\n    occupancy: np.ndarray,\n    bin_size_s: float,\n    uniform_prior: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode position from spike counts in an N-dimensional spatial environment\n\n    Parameters\n    ----------\n    ct : ndarray\n        2D array, spike counts matrix with shape (n_bins, n_cells)\n    tc : ndarray\n        ND array, ratemap matrix with shape (n_xbins, n_ybins, ..., n_cells)\n    occupancy : ndarray\n        (N-1)D array, occupancy matrix with shape (n_xbins, n_ybins, ...)\n    bin_size_s : float\n        float, width of each time bin in seconds\n    uniform_prior : bool, optional\n        bool, whether to use uniform prior, by default False\n\n    Returns\n    ----------\n    p : ndarray\n        (N+1)D array, decoded position probabilities matrix with shape (n_bins, n_xbins, n_ybins, ...)\n\n    Examples\n    ----------\n    # 1D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 2D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n\n    # 3D example\n    &gt;&gt;&gt; ct = np.random.rand(10, 5)\n    &gt;&gt;&gt; tc = np.random.rand(3, 3, 3, 5)\n    &gt;&gt;&gt; occupancy = np.random.rand(3, 3, 3)\n    &gt;&gt;&gt; bin_size_s = 0.1\n    &gt;&gt;&gt; p = decode(ct, tc, occupancy, bin_size_s)\n    \"\"\"\n\n    # Ensure input arrays are contiguous for vectorization\n    ct = np.ascontiguousarray(ct)\n    tc = np.ascontiguousarray(tc)\n    occupancy = np.ascontiguousarray(occupancy)\n\n    # Validate input shapes\n    assert ct.ndim == 2, \"ct must be a 2D array with shape (n_bins, n_cells)\"\n    assert tc.ndim &gt;= 2, (\n        \"tc must be at least a 2D array with shape (n_xbins, ..., n_cells)\"\n    )\n    assert occupancy.ndim == tc.ndim - 1, (\n        \"occupancy must have one fewer dimension than tc\"\n    )\n    assert ct.shape[1] == tc.shape[-1], \"Number of cells in ct and tc must match\"\n\n    # Flatten spatial dimensions\n    n_cells = tc.shape[-1]\n    spatial_shape = tc.shape[:-1]  # Shape of spatial dimensions\n\n    # Calculate the total number of spatial bins\n    n_spatial_bins = 1\n    for dim in spatial_shape:\n        n_spatial_bins *= dim\n\n    tc_flat = tc.reshape(n_spatial_bins, n_cells)\n    occupancy_flat = occupancy.flatten()\n\n    if uniform_prior:\n        # Use uniform prior\n        occupancy_flat = np.ones_like(occupancy_flat)\n\n    # Precompute log values\n    log_tc_flat = np.log(tc_flat + 1e-10)  # add small value to avoid log(0)\n    log_p1 = -tc_flat.sum(axis=1) * bin_size_s\n    log_p2 = np.log(occupancy_flat / occupancy_flat.sum())\n\n    # Initialize the probability matrix\n    n_bins = ct.shape[0]\n    p = np.zeros((n_bins, n_spatial_bins))\n\n    # Vectorized calculation of log probabilities\n    for i in prange(n_bins):  # prange for parallel loop\n        if not np.any(ct[i, :]):\n            p[i, :] = occupancy_flat / occupancy_flat.sum()\n            continue\n        log_likelihood = log_p1 + log_p2 + np.sum(log_tc_flat * ct[i, :], axis=1)\n        p[i, :] = np.exp(\n            log_likelihood - np.max(log_likelihood)\n        )  # Subtract max for numerical stability\n\n    # Normalize the probabilities along the spatial axis\n    p_sum = p.sum(axis=1)  # Sum over spatial bins\n    p = p / p_sum.reshape(-1, 1)  # Reshape p_sum to (n_bins, 1) for broadcasting\n\n    # Reshape the probabilities to the original spatial dimensions\n    p = p.reshape((n_bins,) + spatial_shape)\n\n    return p\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/","title":"neuro_py.ensemble.decoding.lstm","text":""},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM","title":"<code>LSTM</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Long Short-Term Memory (LSTM) model.</p> <p>This class implements an LSTM model using PyTorch Lightning.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Dimensionality of output data, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int, int, float]</code> <p>Architectural parameters of the model (hidden_size, num_layers, dropout), by default (400, 1, 0.0)</p> <code>(400, 1, 0.0)</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias or not in the final linear layer, by default True</p> <code>True</code> <code>args</code> <code>Dict</code> <p>Additional arguments for model configuration, by default {}</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>lstm</code> <code>LSTM</code> <p>LSTM layer</p> <code>fc</code> <code>Linear</code> <p>Fully connected layer</p> <code>hidden_state</code> <code>Optional[Tensor]</code> <p>Hidden state of the LSTM</p> <code>cell_state</code> <code>Optional[Tensor]</code> <p>Cell state of the LSTM</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>class LSTM(L.LightningModule):\n    \"\"\"\n    Long Short-Term Memory (LSTM) model.\n\n    This class implements an LSTM model using PyTorch Lightning.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Dimensionality of output data, by default 2\n    hidden_dims : Tuple[int, int, float], optional\n        Architectural parameters of the model (hidden_size, num_layers, dropout),\n        by default (400, 1, 0.0)\n    use_bias : bool, optional\n        Whether to use bias or not in the final linear layer, by default True\n    args : Dict, optional\n        Additional arguments for model configuration, by default {}\n\n    Attributes\n    ----------\n    lstm : nn.LSTM\n        LSTM layer\n    fc : nn.Linear\n        Fully connected layer\n    hidden_state : Optional[torch.Tensor]\n        Hidden state of the LSTM\n    cell_state : Optional[torch.Tensor]\n        Cell state of the LSTM\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int, int, float] = (400, 1, 0.0),\n        use_bias: bool = True,\n        args: Dict = {},\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        if len(hidden_dims) != 3:\n            raise ValueError(\"`hidden_dims` should be of size 3\")\n        self.hidden_size, self.nlayers, self.dropout = hidden_dims\n        self.args = args\n\n        self.lstm = nn.LSTM(\n            input_size=in_dim,\n            hidden_size=self.hidden_size,\n            num_layers=self.nlayers,\n            batch_first=True,\n            dropout=self.dropout,\n            bidirectional=True,\n        )\n        self.fc = nn.Linear(\n            in_features=2 * self.hidden_size, out_features=out_dim, bias=use_bias\n        )\n        self.hidden_state: Optional[torch.Tensor] = None\n        self.cell_state: Optional[torch.Tensor] = None\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize model parameters.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / torch.math.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        init_params(self.fc)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor of shape (batch_size, sequence_length, input_dim)\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, output_dim)\n        \"\"\"\n        lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n            x, (self.hidden_state, self.cell_state)\n        )\n        lstm_out = lstm_out[:, -1, :].contiguous()\n        out = self.fc(lstm_out)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=1)\n        return out\n\n    def init_hidden(self, batch_size: int) -&gt; None:\n        \"\"\"\n        Initialize hidden state and cell state.\n\n        Parameters\n        ----------\n        batch_size : int\n            Batch size for initialization\n        \"\"\"\n        self.batch_size = batch_size\n        h0 = torch.zeros(\n            (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        c0 = torch.zeros(\n            (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        self.hidden_state = h0\n        self.cell_state = c0\n\n    def predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Make predictions using the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor\n\n        Returns\n        -------\n        torch.Tensor\n            Predicted output\n        \"\"\"\n        self.hidden_state = self.hidden_state.to(x.device)\n        self.cell_state = self.cell_state.to(x.device)\n        preds = []\n        batch_size = self.batch_size\n        for i in range(batch_size, x.shape[0] + batch_size, batch_size):\n            iptensor = x[i - batch_size : i]\n            if i &gt; x.shape[0]:\n                iptensor = F.pad(iptensor, (0, 0, 0, 0, 0, i - x.shape[0]))\n            pred_loc = self.forward(iptensor)\n            if i &gt; x.shape[0]:\n                pred_loc = pred_loc[: batch_size - (i - x.shape[0])]\n            preds.extend(pred_loc)\n        out = torch.stack(preds)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=1)\n        return out\n\n    def _step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def on_after_backward(self) -&gt; None:\n        \"\"\"Lightning method called after backpropagation.\"\"\"\n        self.hidden_state.detach_()\n        self.cell_state.detach_()\n\n    def validation_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        Tuple[List[torch.optim.Optimizer], List[Dict]]\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            steps_per_epoch=len(\n                self.trainer._data_connector._train_dataloader_source.dataloader()\n            ),\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize model parameters.</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize model parameters.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / torch.math.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    init_params(self.fc)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def _step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>Tuple[List[Optimizer], List[Dict]]</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    Tuple[List[torch.optim.Optimizer], List[Dict]]\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        steps_per_epoch=len(\n            self.trainer._data_connector._train_dataloader_source.dataloader()\n        ),\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, sequence_length, input_dim)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, output_dim)</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor of shape (batch_size, sequence_length, input_dim)\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, output_dim)\n    \"\"\"\n    lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n        x, (self.hidden_state, self.cell_state)\n    )\n    lstm_out = lstm_out[:, -1, :].contiguous()\n    out = self.fc(lstm_out)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.init_hidden","title":"<code>init_hidden(batch_size)</code>","text":"<p>Initialize hidden state and cell state.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for initialization</p> required Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def init_hidden(self, batch_size: int) -&gt; None:\n    \"\"\"\n    Initialize hidden state and cell state.\n\n    Parameters\n    ----------\n    batch_size : int\n        Batch size for initialization\n    \"\"\"\n    self.batch_size = batch_size\n    h0 = torch.zeros(\n        (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    c0 = torch.zeros(\n        (2 * self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    self.hidden_state = h0\n    self.cell_state = c0\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.on_after_backward","title":"<code>on_after_backward()</code>","text":"<p>Lightning method called after backpropagation.</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def on_after_backward(self) -&gt; None:\n    \"\"\"Lightning method called after backpropagation.\"\"\"\n    self.hidden_state.detach_()\n    self.cell_state.detach_()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.predict","title":"<code>predict(x)</code>","text":"<p>Make predictions using the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Predicted output</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Make predictions using the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor\n\n    Returns\n    -------\n    torch.Tensor\n        Predicted output\n    \"\"\"\n    self.hidden_state = self.hidden_state.to(x.device)\n    self.cell_state = self.cell_state.to(x.device)\n    preds = []\n    batch_size = self.batch_size\n    for i in range(batch_size, x.shape[0] + batch_size, batch_size):\n        iptensor = x[i - batch_size : i]\n        if i &gt; x.shape[0]:\n            iptensor = F.pad(iptensor, (0, 0, 0, 0, 0, i - x.shape[0]))\n        pred_loc = self.forward(iptensor)\n        if i &gt; x.shape[0]:\n            pred_loc = pred_loc[: batch_size - (i - x.shape[0])]\n        preds.extend(pred_loc)\n    out = torch.stack(preds)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def training_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/lstm/#neuro_py.ensemble.decoding.lstm.LSTM.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/lstm.py</code> <pre><code>def validation_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/","title":"neuro_py.ensemble.decoding.m2mlstm","text":""},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM","title":"<code>M2MLSTM</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Many-to-Many Long Short-Term Memory (LSTM) model.</p> <p>This class implements a Many-to-Many LSTM model using PyTorch Lightning.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Number of output columns, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int, int, float]</code> <p>Architectural parameters of the model (hidden_size, num_layers, dropout), by default (400, 1, 0.0)</p> <code>(400, 1, 0.0)</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias or not in the final linear layer, by default True</p> <code>True</code> <code>args</code> <code>Dict</code> <p>Additional arguments for model configuration, by default {}</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>lstm</code> <code>LSTM</code> <p>LSTM layer</p> <code>fc</code> <code>Linear</code> <p>Fully connected layer</p> <code>hidden_state</code> <code>Optional[Tensor]</code> <p>Hidden state of the LSTM</p> <code>cell_state</code> <code>Optional[Tensor]</code> <p>Cell state of the LSTM</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>class M2MLSTM(L.LightningModule):\n    \"\"\"\n    Many-to-Many Long Short-Term Memory (LSTM) model.\n\n    This class implements a Many-to-Many LSTM model using PyTorch Lightning.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Number of output columns, by default 2\n    hidden_dims : Tuple[int, int, float], optional\n        Architectural parameters of the model (hidden_size, num_layers, dropout),\n        by default (400, 1, 0.0)\n    use_bias : bool, optional\n        Whether to use bias or not in the final linear layer, by default True\n    args : Dict, optional\n        Additional arguments for model configuration, by default {}\n\n    Attributes\n    ----------\n    lstm : nn.LSTM\n        LSTM layer\n    fc : nn.Linear\n        Fully connected layer\n    hidden_state : Optional[torch.Tensor]\n        Hidden state of the LSTM\n    cell_state : Optional[torch.Tensor]\n        Cell state of the LSTM\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int, int, float] = (400, 1, 0.0),\n        use_bias: bool = True,\n        args: Dict = {},\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        if len(hidden_dims) != 3:\n            raise ValueError(\"`hidden_dims` should be of size 3\")\n        self.hidden_size, self.nlayers, self.dropout = hidden_dims\n        self.args = args\n\n        self.lstm = nn.LSTM(\n            input_size=in_dim,\n            hidden_size=self.hidden_size,\n            num_layers=self.nlayers,\n            batch_first=True,\n            dropout=self.dropout,\n            bidirectional=False,\n        )\n        self.fc = nn.Linear(\n            in_features=self.hidden_size, out_features=out_dim, bias=use_bias\n        )\n        self.hidden_state: Optional[torch.Tensor] = None\n        self.cell_state: Optional[torch.Tensor] = None\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize model parameters.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / np.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        init_params(self.fc)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the LSTM model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor of shape (batch_size, sequence_length, input_dim)\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, sequence_length, output_dim)\n        \"\"\"\n        B, L, N = x.shape\n        self.hidden_state = self.hidden_state.to(x.device)\n        self.cell_state = self.cell_state.to(x.device)\n        self.hidden_state.data.fill_(0.0)\n        self.cell_state.data.fill_(0.0)\n        lstm_outs = []\n        for i in range(L):\n            lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n                x[:, i].unsqueeze(1), (self.hidden_state, self.cell_state)\n            )\n            lstm_outs.append(lstm_out)\n\n        lstm_outs = torch.stack(lstm_outs, dim=1)  # B, L, N\n        out = self.fc(lstm_outs)\n        out = out.view(B, L, self.out_dim)\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=-1)\n\n        return out\n\n    def init_hidden(self, batch_size: int) -&gt; None:\n        \"\"\"\n        Initialize hidden state and cell state.\n\n        Parameters\n        ----------\n        batch_size : int\n            Batch size for initialization\n        \"\"\"\n        self.batch_size = batch_size\n        self.hidden_state = torch.zeros(\n            (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n        self.cell_state = torch.zeros(\n            (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n        )\n\n    def _step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def on_after_backward(self) -&gt; None:\n        \"\"\"Lightning method called after backpropagation.\"\"\"\n        self.hidden_state = self.hidden_state.detach()\n        self.cell_state = self.cell_state.detach()\n\n    def validation_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(\n        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : Tuple[torch.Tensor, torch.Tensor]\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        Tuple[List[torch.optim.Optimizer], List[Dict]]\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            total_steps=self.trainer.estimated_stepping_batches,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize model parameters.</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize model parameters.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / np.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    init_params(self.fc)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def _step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>Tuple[List[Optimizer], List[Dict]]</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def configure_optimizers(self) -&gt; Tuple[List[torch.optim.Optimizer], List[Dict]]:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    Tuple[List[torch.optim.Optimizer], List[Dict]]\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        total_steps=self.trainer.estimated_stepping_batches,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the LSTM model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, sequence_length, input_dim)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, sequence_length, output_dim)</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the LSTM model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor of shape (batch_size, sequence_length, input_dim)\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, sequence_length, output_dim)\n    \"\"\"\n    B, L, N = x.shape\n    self.hidden_state = self.hidden_state.to(x.device)\n    self.cell_state = self.cell_state.to(x.device)\n    self.hidden_state.data.fill_(0.0)\n    self.cell_state.data.fill_(0.0)\n    lstm_outs = []\n    for i in range(L):\n        lstm_out, (self.hidden_state, self.cell_state) = self.lstm(\n            x[:, i].unsqueeze(1), (self.hidden_state, self.cell_state)\n        )\n        lstm_outs.append(lstm_out)\n\n    lstm_outs = torch.stack(lstm_outs, dim=1)  # B, L, N\n    out = self.fc(lstm_outs)\n    out = out.view(B, L, self.out_dim)\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=-1)\n\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.init_hidden","title":"<code>init_hidden(batch_size)</code>","text":"<p>Initialize hidden state and cell state.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch size for initialization</p> required Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def init_hidden(self, batch_size: int) -&gt; None:\n    \"\"\"\n    Initialize hidden state and cell state.\n\n    Parameters\n    ----------\n    batch_size : int\n        Batch size for initialization\n    \"\"\"\n    self.batch_size = batch_size\n    self.hidden_state = torch.zeros(\n        (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n    self.cell_state = torch.zeros(\n        (self.nlayers, batch_size, self.hidden_size), requires_grad=False\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.on_after_backward","title":"<code>on_after_backward()</code>","text":"<p>Lightning method called after backpropagation.</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def on_after_backward(self) -&gt; None:\n    \"\"\"Lightning method called after backpropagation.\"\"\"\n    self.hidden_state = self.hidden_state.detach()\n    self.cell_state = self.cell_state.detach()\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def training_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.M2MLSTM.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tuple[Tensor, Tensor]</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>def validation_step(\n    self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : Tuple[torch.Tensor, torch.Tensor]\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/m2mlstm/#neuro_py.ensemble.decoding.m2mlstm.NSVDataset","title":"<code>NSVDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Custom Dataset for neural state vector (binned spike train) data.</p> <p>Parameters:</p> Name Type Description Default <code>nsv</code> <code>List[ndarray]</code> <p>List of trial-segmented neural state vector arrays</p> required <code>dv</code> <code>List[ndarray]</code> <p>List of trial-segmented behavioral state vector arrays</p> required <p>Attributes:</p> Name Type Description <code>nsv</code> <code>List[ndarray]</code> <p>List of trial-segmented neural state vector arrays as float32</p> <code>dv</code> <code>List[ndarray]</code> <p>List of trial-segmented behavioral state vector arrays as float32</p> Source code in <code>neuro_py/ensemble/decoding/m2mlstm.py</code> <pre><code>class NSVDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Custom Dataset for neural state vector (binned spike train) data.\n\n    Parameters\n    ----------\n    nsv : List[np.ndarray]\n        List of trial-segmented neural state vector arrays\n    dv : List[np.ndarray]\n        List of trial-segmented behavioral state vector arrays\n\n    Attributes\n    ----------\n    nsv : List[np.ndarray]\n        List of trial-segmented neural state vector arrays as float32\n    dv : List[np.ndarray]\n        List of trial-segmented behavioral state vector arrays as float32\n    \"\"\"\n\n    def __init__(self, nsv: List[np.ndarray], dv: List[np.ndarray]):\n        self.nsv = [i.astype(np.float32) for i in nsv]\n        self.dv = [i.astype(np.float32) for i in dv]\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Get the length of the dataset.\n\n        Returns\n        -------\n        int\n            Number of samples in the dataset\n        \"\"\"\n        return len(self.nsv)\n\n    def __getitem__(self, idx: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get a sample from the dataset.\n\n        Parameters\n        ----------\n        idx : int\n            Index of the sample\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray]\n            Tuple containing NSV and DV arrays\n        \"\"\"\n        nsv, dv = self.nsv[idx], self.dv[idx]\n        return nsv, dv\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/","title":"neuro_py.ensemble.decoding.mlp","text":""},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP","title":"<code>MLP</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Multi-Layer Perceptron (MLP) in PyTorch with an arbitrary number of hidden layers.</p> <p>This class implements an MLP model using PyTorch Lightning, allowing for flexible architecture with varying hidden layer sizes and dropout probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Dimensionality of output data, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>List[Union[int, float]]</code> <p>List containing architectural parameters of the model. If an element is an int, it represents a hidden layer of that size. If an element is a float, it represents a dropout layer with that probability. By default ()</p> <code>()</code> <code>use_bias</code> <code>bool</code> <p>Whether to use bias in all linear layers, by default True</p> <code>True</code> <code>args</code> <code>Optional[Dict]</code> <p>Dictionary containing the hyperparameters of the model, by default None</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>main</code> <code>Sequential</code> <p>The main sequential container of the MLP layers</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>class MLP(L.LightningModule):\n    \"\"\"\n    Multi-Layer Perceptron (MLP) in PyTorch with an arbitrary number of hidden layers.\n\n    This class implements an MLP model using PyTorch Lightning, allowing for flexible\n    architecture with varying hidden layer sizes and dropout probabilities.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Dimensionality of output data, by default 2\n    hidden_dims : List[Union[int, float]], optional\n        List containing architectural parameters of the model. If an element is\n        an int, it represents a hidden layer of that size. If an element is a float,\n        it represents a dropout layer with that probability. By default ()\n    use_bias : bool, optional\n        Whether to use bias in all linear layers, by default True\n    args : Optional[Dict], optional\n        Dictionary containing the hyperparameters of the model, by default None\n\n    Attributes\n    ----------\n    main : nn.Sequential\n        The main sequential container of the MLP layers\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: List[Union[int, float]] = (),\n        use_bias: bool = True,\n        args: Optional[Dict] = None,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.in_dim = in_dim\n        self.out_dim = out_dim\n        self.args = args if args is not None else {}\n        activations = (\n            nn.CELU\n            if self.args.get(\"activations\") is None\n            else self.args[\"activations\"]\n        )\n\n        layers = self._build_layers(in_dim, out_dim, hidden_dims, use_bias, activations)\n        self.main = nn.Sequential(*layers)\n        self._init_params()\n\n    def _build_layers(\n        self,\n        in_dim: int,\n        out_dim: int,\n        hidden_dims: List[Union[int, float]],\n        use_bias: bool,\n        activations: nn.Module,\n    ) -&gt; List[nn.Module]:\n        \"\"\"\n        Build the layers of the MLP.\n\n        Parameters\n        ----------\n        in_dim : int\n            Dimensionality of input data\n        out_dim : int\n            Dimensionality of output data\n        hidden_dims : List[Union[int, float]]\n            List of hidden layer sizes and dropout probabilities\n        use_bias : bool\n            Whether to use bias in linear layers\n        activations : nn.Module\n            Activation function to use\n\n        Returns\n        -------\n        List[nn.Module]\n            List of layers for the MLP\n        \"\"\"\n        if len(hidden_dims) == 0:\n            return [nn.Linear(in_dim, out_dim, bias=use_bias)]\n\n        layers = []\n        hidden_dims = [in_dim] + hidden_dims\n\n        for i, hidden_dim in enumerate(hidden_dims[:-1]):\n            if isinstance(hidden_dim, float):\n                continue\n            if isinstance(hidden_dims[i + 1], float):\n                layers.extend(\n                    [\n                        nn.Linear(hidden_dim, hidden_dims[i + 2], bias=use_bias),\n                        nn.Dropout(p=hidden_dims[i + 1]),\n                        activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                    ]\n                )\n            else:\n                layers.extend(\n                    [\n                        nn.Linear(hidden_dim, hidden_dims[i + 1], bias=use_bias),\n                        activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                    ]\n                )\n\n        layers.append(nn.Linear(hidden_dims[-1], out_dim, bias=use_bias))\n        if self.args.get(\"clf\", False):\n            layers.append(nn.LogSoftmax(dim=1))\n\n        return layers\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize the parameters of the model.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / torch.math.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        self.main.apply(init_params)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Defines the network structure and flow from input to output.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input data\n\n        Returns\n        -------\n        torch.Tensor\n            Output data\n        \"\"\"\n        return self.main(x)\n\n    def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        tuple\n            Tuple containing a list of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(),\n            weight_decay=self.args[\"weight_decay\"],\n            betas=(0.9, 0.999),\n            amsgrad=True,\n        )\n        scheduler = torch.optim.lr_scheduler.CyclicLR(\n            optimizer,\n            base_lr=self.args[\"base_lr\"],\n            max_lr=self.args[\"lr\"],\n            step_size_up=self.args[\"scheduler_step_size_multiplier\"]\n            * self.args[\"num_training_batches\"],\n            cycle_momentum=False,\n            mode=\"triangular2\",\n            gamma=0.99994,\n            last_epoch=-1,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP._build_layers","title":"<code>_build_layers(in_dim, out_dim, hidden_dims, use_bias, activations)</code>","text":"<p>Build the layers of the MLP.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data</p> required <code>out_dim</code> <code>int</code> <p>Dimensionality of output data</p> required <code>hidden_dims</code> <code>List[Union[int, float]]</code> <p>List of hidden layer sizes and dropout probabilities</p> required <code>use_bias</code> <code>bool</code> <p>Whether to use bias in linear layers</p> required <code>activations</code> <code>Module</code> <p>Activation function to use</p> required <p>Returns:</p> Type Description <code>List[Module]</code> <p>List of layers for the MLP</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _build_layers(\n    self,\n    in_dim: int,\n    out_dim: int,\n    hidden_dims: List[Union[int, float]],\n    use_bias: bool,\n    activations: nn.Module,\n) -&gt; List[nn.Module]:\n    \"\"\"\n    Build the layers of the MLP.\n\n    Parameters\n    ----------\n    in_dim : int\n        Dimensionality of input data\n    out_dim : int\n        Dimensionality of output data\n    hidden_dims : List[Union[int, float]]\n        List of hidden layer sizes and dropout probabilities\n    use_bias : bool\n        Whether to use bias in linear layers\n    activations : nn.Module\n        Activation function to use\n\n    Returns\n    -------\n    List[nn.Module]\n        List of layers for the MLP\n    \"\"\"\n    if len(hidden_dims) == 0:\n        return [nn.Linear(in_dim, out_dim, bias=use_bias)]\n\n    layers = []\n    hidden_dims = [in_dim] + hidden_dims\n\n    for i, hidden_dim in enumerate(hidden_dims[:-1]):\n        if isinstance(hidden_dim, float):\n            continue\n        if isinstance(hidden_dims[i + 1], float):\n            layers.extend(\n                [\n                    nn.Linear(hidden_dim, hidden_dims[i + 2], bias=use_bias),\n                    nn.Dropout(p=hidden_dims[i + 1]),\n                    activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                ]\n            )\n        else:\n            layers.extend(\n                [\n                    nn.Linear(hidden_dim, hidden_dims[i + 1], bias=use_bias),\n                    activations() if i &lt; len(hidden_dims) - 1 else nn.Tanh(),\n                ]\n            )\n\n    layers.append(nn.Linear(hidden_dims[-1], out_dim, bias=use_bias))\n    if self.args.get(\"clf\", False):\n        layers.append(nn.LogSoftmax(dim=1))\n\n    return layers\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize the parameters of the model.</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize the parameters of the model.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / torch.math.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    self.main.apply(init_params)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple containing a list of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def configure_optimizers(self):\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    tuple\n        Tuple containing a list of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(),\n        weight_decay=self.args[\"weight_decay\"],\n        betas=(0.9, 0.999),\n        amsgrad=True,\n    )\n    scheduler = torch.optim.lr_scheduler.CyclicLR(\n        optimizer,\n        base_lr=self.args[\"base_lr\"],\n        max_lr=self.args[\"lr\"],\n        step_size_up=self.args[\"scheduler_step_size_multiplier\"]\n        * self.args[\"num_training_batches\"],\n        cycle_momentum=False,\n        mode=\"triangular2\",\n        gamma=0.99994,\n        last_epoch=-1,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP.forward","title":"<code>forward(x)</code>","text":"<p>Defines the network structure and flow from input to output.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output data</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Defines the network structure and flow from input to output.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input data\n\n    Returns\n    -------\n    torch.Tensor\n        Output data\n    \"\"\"\n    return self.main(x)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/mlp/#neuro_py.ensemble.decoding.mlp.MLP.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/mlp.py</code> <pre><code>def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/","title":"neuro_py.ensemble.decoding.pipeline","text":""},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline._get_trial_spikes_with_no_overlap_history","title":"<code>_get_trial_spikes_with_no_overlap_history(X, bins_before, bins_after, bins_current)</code>","text":"<p>Get trial spikes with no overlap history.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>NDArray</code> <p>Input binned spike data.</p> required <code>bins_before</code> <code>int</code> <p>Number of bins before the current bin.</p> required <code>bins_after</code> <code>int</code> <p>Number of bins after the current bin.</p> required <code>bins_current</code> <code>int</code> <p>Number of current bins.</p> required <p>Returns:</p> Type Description <code>List[NDArray]</code> <p>List of trial covariates with no overlap history.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def _get_trial_spikes_with_no_overlap_history(\n    X: NDArray, bins_before: int, bins_after: int, bins_current: int\n) -&gt; List[NDArray]:\n    \"\"\"\n    Get trial spikes with no overlap history.\n\n    Parameters\n    ----------\n    X : NDArray\n        Input binned spike data.\n    bins_before : int\n        Number of bins before the current bin.\n    bins_after : int\n        Number of bins after the current bin.\n    bins_current : int\n        Number of current bins.\n\n    Returns\n    -------\n    List[NDArray]\n        List of trial covariates with no overlap history.\n    \"\"\"\n    nonoverlap_trial_covariates = []\n    if X.ndim == 2:\n        X_cov = get_spikes_with_history(X, bins_before, bins_after, bins_current)\n        nonoverlap_trial_covariates.append(X_cov)\n    else:\n        for X_trial in X:\n            X_cov = get_spikes_with_history(\n                np.asarray(X_trial), bins_before, bins_after, bins_current\n            )\n            nonoverlap_trial_covariates.append(X_cov)\n    return nonoverlap_trial_covariates\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.create_model","title":"<code>create_model(hyperparams)</code>","text":"<p>Create a model based on the given hyperparameters.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing model hyperparameters.</p> required <p>Returns:</p> Type Description <code>Tuple[Any, LightningModule]</code> <p>The decoder class and instantiated model.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def create_model(hyperparams: Dict[str, Any]) -&gt; Tuple[Any, pl.LightningModule]:\n    \"\"\"\n    Create a model based on the given hyperparameters.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing model hyperparameters.\n\n    Returns\n    -------\n    Tuple[Any, pl.LightningModule]\n        The decoder class and instantiated model.\n    \"\"\"\n    decoder = eval(f\"{hyperparams['model']}\")\n    model = decoder(**hyperparams[\"model_args\"])\n\n    if \"LSTM\" in hyperparams[\"model\"]:\n        model.init_hidden(hyperparams[\"batch_size\"])\n        model.hidden_state = model.hidden_state.to(hyperparams[\"accelerator\"])\n        model.cell_state = model.cell_state.to(hyperparams[\"accelerator\"])\n\n    return decoder, model\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.evaluate_model","title":"<code>evaluate_model(hyperparams, ohe, predictor, X_test, y_test)</code>","text":"<p>Evaluate the model on test data.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing hyperparameters.</p> required <code>ohe</code> <code>OneHotEncoder</code> <p>One-hot encoder for categorical variables.</p> required <code>predictor</code> <code>Module</code> <p>The trained model.</p> required <code>X_test</code> <code>NDArray</code> <p>Test features.</p> required <code>y_test</code> <code>NDArray</code> <p>Test labels.</p> required <p>Returns:</p> Type Description <code>Tuple[Dict[str, float], NDArray]</code> <p>Evaluation metrics and model predictions.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def evaluate_model(\n    hyperparams: Dict[str, Any],\n    ohe: sklearn.preprocessing.OneHotEncoder,\n    predictor: torch.nn.Module,\n    X_test: NDArray,\n    y_test: NDArray,\n) -&gt; Tuple[Dict[str, float], NDArray]:\n    \"\"\"\n    Evaluate the model on test data.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing hyperparameters.\n    ohe : OneHotEncoder\n        One-hot encoder for categorical variables.\n    predictor : torch.nn.Module\n        The trained model.\n    X_test : NDArray\n        Test features.\n    y_test : NDArray\n        Test labels.\n\n    Returns\n    -------\n    Tuple[Dict[str, float], NDArray]\n        Evaluation metrics and model predictions.\n    \"\"\"\n    if hyperparams[\"model\"] in (\"M2MLSTM\", \"NDT\"):\n        out_dim = hyperparams[\"model_args\"][\"out_dim\"]\n        with torch.no_grad():\n            bv_preds_fold = [\n                predictor(torch.from_numpy(X.reshape(1, *X.shape)).type(torch.float32))\n                for X in X_test\n            ]\n        bv_preds_fold = np.vstack(\n            [\n                bv.squeeze().detach().cpu().numpy().reshape(-1, out_dim)\n                for bv in bv_preds_fold\n            ]\n        )\n    else:\n        bv_preds_fold = predictor(torch.from_numpy(X_test).type(torch.float32))\n        bv_preds_fold = bv_preds_fold.detach().cpu().numpy()\n\n    bv_preds_fold = copy.deepcopy(bv_preds_fold)\n\n    logits = bv_preds_fold\n    labels = np.vstack(y_test)\n    if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n        logits = ohe.inverse_transform(logits)\n        labels = ohe.inverse_transform(labels)\n        accuracy = sklearn.metrics.accuracy_score(labels, logits)\n        metrics = dict(accuracy=accuracy)\n        bv_preds_fold = logits\n    else:\n        coeff_determination = sklearn.metrics.r2_score(\n            labels, logits, multioutput=\"variance_weighted\"\n        )\n        rmse = sklearn.metrics.root_mean_squared_error(labels, logits)\n        metrics = dict(coeff_determination=coeff_determination, rmse=rmse)\n    return metrics, bv_preds_fold\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.format_trial_segs_nsv","title":"<code>format_trial_segs_nsv(nsv_train_normed, nsv_rest_normed, bv_train, bv_rest, predict_bv, bins_before=0, bins_current=1, bins_after=0)</code>","text":"<p>Format trial segments for neural state vectors.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_train_normed</code> <code>List[NDArray]</code> <p>Normalized neural state vectors for training.</p> required <code>nsv_rest_normed</code> <code>List[NDArray]</code> <p>Normalized neural state vectors for rest.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_rest</code> <code>List[NDArray]</code> <p>Behavioral state vectors for rest.</p> required <code>predict_bv</code> <code>List[int]</code> <p>Indices of behavioral state vectors to predict.</p> required <code>bins_before</code> <code>int</code> <p>Number of bins before the current bin, by default 0.</p> <code>0</code> <code>bins_current</code> <code>int</code> <p>Number of current bins, by default 1.</p> <code>1</code> <code>bins_after</code> <code>int</code> <p>Number of bins after the current bin, by default 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]</code> <p>Formatted trial segments for neural state vectors.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def format_trial_segs_nsv(\n    nsv_train_normed: List[NDArray],\n    nsv_rest_normed: List[NDArray],\n    bv_train: NDArray,\n    bv_rest: List[NDArray],\n    predict_bv: List[int],\n    bins_before: int = 0,\n    bins_current: int = 1,\n    bins_after: int = 0,\n) -&gt; Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]:\n    \"\"\"\n    Format trial segments for neural state vectors.\n\n    Parameters\n    ----------\n    nsv_train_normed : List[NDArray]\n        Normalized neural state vectors for training.\n    nsv_rest_normed : List[NDArray]\n        Normalized neural state vectors for rest.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_rest : List[NDArray]\n        Behavioral state vectors for rest.\n    predict_bv : List[int]\n        Indices of behavioral state vectors to predict.\n    bins_before : int, optional\n        Number of bins before the current bin, by default 0.\n    bins_current : int, optional\n        Number of current bins, by default 1.\n    bins_after : int, optional\n        Number of bins after the current bin, by default 0.\n\n    Returns\n    -------\n    Tuple[NDArray, List[NDArray], NDArray, List[NDArray], NDArray, List[NDArray]]\n        Formatted trial segments for neural state vectors.\n    \"\"\"\n    is_2D = nsv_train_normed[0].ndim == 1\n    # Format for RNNs: covariate matrix including spike history from previous bins\n    X_train = np.concatenate(\n        _get_trial_spikes_with_no_overlap_history(\n            nsv_train_normed, bins_before, bins_after, bins_current\n        )\n    )\n    X_rest = []\n    for nsv_feats in nsv_rest_normed:\n        X_feats = np.concatenate(\n            _get_trial_spikes_with_no_overlap_history(\n                nsv_feats, bins_before, bins_after, bins_current\n            )\n        )\n        X_rest.append(X_feats)\n\n    # each \"neuron / time\" is a single feature\n    X_flat_train = X_train.reshape(\n        X_train.shape[0], (X_train.shape[1] * X_train.shape[2])\n    )\n    X_flat_rest = []\n    for X_feat in X_rest:\n        X_flat_feat = X_feat.reshape(\n            X_feat.shape[0], (X_feat.shape[1] * X_feat.shape[2])\n        )\n        X_flat_rest.append(X_flat_feat)\n\n    bv_train = bv_train if not is_2D else [bv_train]\n    y_train = np.concatenate(bv_train)\n    y_train = y_train[:, predict_bv]\n    y_rest = []\n    for bv_y in bv_rest:\n        bv_y = bv_y if not is_2D else [bv_y]\n        y = np.concatenate(bv_y)\n        y = y[:, predict_bv]\n        y_rest.append(y)\n\n    return X_train, X_rest, X_flat_train, X_flat_rest, y_train, y_rest\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.get_spikes_with_history","title":"<code>get_spikes_with_history(neural_data, bins_before, bins_after, bins_current=1)</code>","text":"<p>Create the covariate matrix of neural activity.</p> <p>Parameters:</p> Name Type Description Default <code>neural_data</code> <code>ndarray</code> <p>A matrix of size \"number of time bins\" x \"number of neurons\", representing the number of spikes in each time bin for each neuron.</p> required <code>bins_before</code> <code>int</code> <p>How many bins of neural data prior to the output are used for decoding.</p> required <code>bins_after</code> <code>int</code> <p>How many bins of neural data after the output are used for decoding.</p> required <code>bins_current</code> <code>int</code> <p>Whether to use the concurrent time bin of neural data for decoding, by default 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A matrix of size \"number of total time bins\" x \"number of surrounding time bins used for prediction\" x \"number of neurons\".</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def get_spikes_with_history(\n    neural_data: np.ndarray, bins_before: int, bins_after: int, bins_current: int = 1\n) -&gt; np.ndarray:\n    \"\"\"\n    Create the covariate matrix of neural activity.\n\n    Parameters\n    ----------\n    neural_data : np.ndarray\n        A matrix of size \"number of time bins\" x \"number of neurons\",\n        representing the number of spikes in each time bin for each neuron.\n    bins_before : int\n        How many bins of neural data prior to the output are used for decoding.\n    bins_after : int\n        How many bins of neural data after the output are used for decoding.\n    bins_current : int, optional\n        Whether to use the concurrent time bin of neural data for decoding, by\n        default 1.\n\n    Returns\n    -------\n    np.ndarray\n        A matrix of size \"number of total time bins\" x \"number of surrounding\n        time bins used for prediction\" x \"number of neurons\".\n    \"\"\"\n    num_examples, num_neurons = neural_data.shape\n    surrounding_bins = bins_before + bins_after + bins_current\n    X = np.zeros([num_examples, surrounding_bins, num_neurons])\n\n    for i in range(num_examples - bins_before - bins_after):\n        start_idx = i\n        end_idx = start_idx + surrounding_bins\n        X[i + bins_before] = neural_data[start_idx:end_idx]\n\n    return X\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.minibatchify","title":"<code>minibatchify(Xtrain, ytrain, Xval, yval, Xtest, ytest, seed=0, batch_size=128, num_workers=5, modeltype='MLP')</code>","text":"<p>Create minibatches for training, validation, and testing.</p> <p>Parameters:</p> Name Type Description Default <code>Xtrain</code> <code>NDArray</code> <p>Training features.</p> required <code>ytrain</code> <code>NDArray</code> <p>Training labels.</p> required <code>Xval</code> <code>NDArray</code> <p>Validation features.</p> required <code>yval</code> <code>NDArray</code> <p>Validation labels.</p> required <code>Xtest</code> <code>NDArray</code> <p>Test features.</p> required <code>ytest</code> <code>NDArray</code> <p>Test labels.</p> required <code>seed</code> <code>int</code> <p>Random seed, by default 0.</p> <code>0</code> <code>batch_size</code> <code>int</code> <p>Batch size, by default 128.</p> <code>128</code> <code>num_workers</code> <code>int</code> <p>Number of workers for data loading, by default 5.</p> <code>5</code> <code>modeltype</code> <code>str</code> <p>Type of model, by default 'MLP'.</p> <code>'MLP'</code> <p>Returns:</p> Type Description <code>Tuple[DataLoader, DataLoader, DataLoader]</code> <p>DataLoaders for training, validation, and testing.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def minibatchify(\n    Xtrain: NDArray,\n    ytrain: NDArray,\n    Xval: NDArray,\n    yval: NDArray,\n    Xtest: NDArray,\n    ytest: NDArray,\n    seed: int = 0,\n    batch_size: int = 128,\n    num_workers: int = 5,\n    modeltype: str = \"MLP\",\n) -&gt; Tuple[\n    torch.utils.data.DataLoader,\n    torch.utils.data.DataLoader,\n    torch.utils.data.DataLoader,\n]:\n    \"\"\"\n    Create minibatches for training, validation, and testing.\n\n    Parameters\n    ----------\n    Xtrain : NDArray\n        Training features.\n    ytrain : NDArray\n        Training labels.\n    Xval : NDArray\n        Validation features.\n    yval : NDArray\n        Validation labels.\n    Xtest : NDArray\n        Test features.\n    ytest : NDArray\n        Test labels.\n    seed : int, optional\n        Random seed, by default 0.\n    batch_size : int, optional\n        Batch size, by default 128.\n    num_workers : int, optional\n        Number of workers for data loading, by default 5.\n    modeltype : str, optional\n        Type of model, by default 'MLP'.\n\n    Returns\n    -------\n    Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, torch.utils.data.DataLoader]\n        DataLoaders for training, validation, and testing.\n    \"\"\"\n    g_seed = torch.Generator()\n    g_seed.manual_seed(seed)\n    if Xtrain.ndim == 2:  # handle object arrays\n        Xtrain = Xtrain.astype(np.float32)\n        Xval = Xval.astype(np.float32)\n        Xtest = Xtest.astype(np.float32)\n        ytrain = ytrain.astype(np.float32)\n        yval = yval.astype(np.float32)\n        ytest = ytest.astype(np.float32)\n    train = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xtrain).type(torch.float32),\n        torch.from_numpy(ytrain).type(torch.float32),\n    )\n    val = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xval).type(torch.float32),\n        torch.from_numpy(yval).type(torch.float32),\n    )\n    test = torch.utils.data.TensorDataset(\n        torch.from_numpy(Xtest).type(torch.float32),\n        torch.from_numpy(ytest).type(torch.float32),\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    val_loader = torch.utils.data.DataLoader(\n        val,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        test,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        drop_last=(modeltype == \"LSTM\"),\n        worker_init_fn=seed_worker,\n        generator=g_seed,\n    )\n\n    return train_loader, val_loader, test_loader\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.normalize_format_trial_segs","title":"<code>normalize_format_trial_segs(nsv_train, nsv_rest, bv_train, bv_rest, predict_bv=[4, 5], bins_before=0, bins_current=1, bins_after=0, normparams=None)</code>","text":"<p>Normalize and format trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_train</code> <code>NDArray</code> <p>Neural state vectors for training.</p> required <code>nsv_rest</code> <code>List[NDArray]</code> <p>Neural state vectors for rest.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_rest</code> <code>List[NDArray]</code> <p>Behavioral state vectors for rest.</p> required <code>predict_bv</code> <code>List[int]</code> <p>Indices of behavioral state vectors to predict, by default [4, 5].</p> <code>[4, 5]</code> <code>bins_before</code> <code>int</code> <p>Number of bins before the current bin, by default 0.</p> <code>0</code> <code>bins_current</code> <code>int</code> <p>Number of current bins, by default 1.</p> <code>1</code> <code>bins_after</code> <code>int</code> <p>Number of bins after the current bin, by default 0.</p> <code>0</code> <code>normparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]]</code> <p>Normalized and formatted trial segments.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def normalize_format_trial_segs(\n    nsv_train: NDArray,\n    nsv_rest: List[NDArray],\n    bv_train: NDArray,\n    bv_rest: List[NDArray],\n    predict_bv: List[int] = [4, 5],\n    bins_before: int = 0,\n    bins_current: int = 1,\n    bins_after: int = 0,\n    normparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[\n    NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]\n]:\n    \"\"\"\n    Normalize and format trial segments.\n\n    Parameters\n    ----------\n    nsv_train : NDArray\n        Neural state vectors for training.\n    nsv_rest : List[NDArray]\n        Neural state vectors for rest.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_rest : List[NDArray]\n        Behavioral state vectors for rest.\n    predict_bv : List[int], optional\n        Indices of behavioral state vectors to predict, by default [4, 5].\n    bins_before : int, optional\n        Number of bins before the current bin, by default 0.\n    bins_current : int, optional\n        Number of current bins, by default 1.\n    bins_after : int, optional\n        Number of bins after the current bin, by default 0.\n    normparams : Optional[Dict[str, Any]], optional\n        Normalization parameters, by default None.\n\n    Returns\n    -------\n    Tuple[NDArray, NDArray, NDArray, List[Tuple[NDArray, NDArray, NDArray]], Dict[str, Any]]\n        Normalized and formatted trial segments.\n    \"\"\"\n    nsv_train_normed, nsv_rest_normed, norm_params = zscore_trial_segs(\n        nsv_train, nsv_rest, normparams\n    )\n\n    (X_train, X_rest, X_flat_train, X_flat_rest, y_train, y_rest) = (\n        format_trial_segs_nsv(\n            nsv_train_normed,\n            nsv_rest_normed,\n            bv_train,\n            bv_rest,\n            predict_bv,\n            bins_before,\n            bins_current,\n            bins_after,\n        )\n    )\n\n    # Zero-center outputs\n    y_train_mean = (\n        normparams[\"y_train_mean\"]\n        if normparams is not None\n        else np.mean(y_train, axis=0)\n    )\n    y_train = y_train - y_train_mean\n    y_centered_rest = []\n    for y in y_rest:\n        y_centered_rest.append(y - y_train_mean)\n\n    norm_params[\"y_train_mean\"] = y_train_mean\n\n    return (\n        X_train,\n        X_flat_train,\n        y_train,\n        tuple(zip(X_rest, X_flat_rest, y_centered_rest)),\n        norm_params,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.normalize_labels","title":"<code>normalize_labels(y_train, y_val, y_test)</code>","text":"<p>Normalize labels to integers in [0, n_classes).</p> <p>Parameters:</p> Name Type Description Default <code>y_train</code> <code>NDArray</code> <p>Training labels.</p> required <code>y_val</code> <code>NDArray</code> <p>Validation labels.</p> required <code>y_test</code> <code>NDArray</code> <p>Test labels.</p> required <p>Returns:</p> Type Description <code>Tuple[Tuple[NDArray, NDArray, NDArray], int]</code> <p>Normalized labels and number of classes.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def normalize_labels(\n    y_train: NDArray, y_val: NDArray, y_test: NDArray\n) -&gt; Tuple[Tuple[NDArray, NDArray, NDArray], int]:\n    \"\"\"\n    Normalize labels to integers in [0, n_classes).\n\n    Parameters\n    ----------\n    y_train : NDArray\n        Training labels.\n    y_val : NDArray\n        Validation labels.\n    y_test : NDArray\n        Test labels.\n\n    Returns\n    -------\n    Tuple[Tuple[NDArray, NDArray, NDArray], int]\n        Normalized labels and number of classes.\n    \"\"\"\n    # map labels to integers in [0, n_classes)\n    uniq_labels = np.unique(np.concatenate((y_train, y_val, y_test)))\n    n_classes = len(uniq_labels)\n    uniq_labels_idx_map = dict(zip(uniq_labels, range(n_classes)))\n    y_train = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_train)\n    y_val = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_val)\n    y_test = np.vectorize(lambda v: uniq_labels_idx_map[v])(y_test)\n    return (y_train, y_val, y_test), n_classes\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.predict_models_folds","title":"<code>predict_models_folds(partitions, hyperparams, bv_models_folds, foldnormparams)</code>","text":"<p>Predict and evaluate models across multiple folds.</p> <p>Parameters:</p> Name Type Description Default <code>partitions</code> <code>List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]]</code> <p>List of data partitions for each fold. Each partition contains: (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test)</p> required <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary of hyperparameters for the models.</p> required <code>bv_models_folds</code> <code>List[Any]</code> <p>List of trained models for each fold.</p> required <code>foldnormparams</code> <code>List[Dict[str, Any]]</code> <p>List of normalization parameters for each fold.</p> required <p>Returns:</p> Type Description <code>Tuple[List[NDArray], Dict[str, List[float]]]</code> <p>A tuple containing: - List of predictions for each fold - Dictionary of evaluation metrics for each fold</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def predict_models_folds(\n    partitions: List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]],\n    hyperparams: Dict[str, Any],\n    bv_models_folds: List[Any],\n    foldnormparams: List[Dict[str, Any]],\n) -&gt; Tuple[List[NDArray], Dict[str, List[float]]]:\n    \"\"\"\n    Predict and evaluate models across multiple folds.\n\n    Parameters\n    ----------\n    partitions : List[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray]]\n        List of data partitions for each fold. Each partition contains:\n        (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test)\n    hyperparams : Dict[str, Any]\n        Dictionary of hyperparameters for the models.\n    bv_models_folds : List[Any]\n        List of trained models for each fold.\n    foldnormparams : List[Dict[str, Any]]\n        List of normalization parameters for each fold.\n\n    Returns\n    -------\n    Tuple[List[NDArray], Dict[str, List[float]]]\n        A tuple containing:\n        - List of predictions for each fold\n        - Dictionary of evaluation metrics for each fold\n    \"\"\"\n    ohe = sklearn.preprocessing.OneHotEncoder()\n    bv_preds_folds = []\n    metrics_folds = dict()\n    for i, (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test) in enumerate(\n        partitions\n    ):\n        preprocessed_data = preprocess_data(\n            hyperparams,\n            ohe,\n            nsv_train,\n            nsv_val,\n            nsv_test,\n            bv_train,\n            bv_val,\n            bv_test,\n            foldnormparams[i],\n        )\n        (\n            (X_train, y_train, X_val, y_val, X_test, y_test),\n            (train_loader, val_loader, test_loader),\n            fold_norm_params,\n        ) = preprocessed_data\n        model = bv_models_folds[i]\n\n        model.eval()\n        predictor = model if hyperparams[\"model\"] != \"LSTM\" else model.predict\n        metrics, bv_preds_fold = evaluate_model(\n            hyperparams, ohe, predictor, X_test, y_test\n        )\n        bv_preds_folds.append(bv_preds_fold)\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            if \"accuracy\" not in metrics_folds:\n                metrics_folds[\"accuracy\"] = []\n            metrics_folds[\"accuracy\"].append(metrics[\"accuracy\"])\n        else:\n            coeff_determination = metrics[\"coeff_determination\"]\n            rmse = metrics[\"rmse\"]\n            if \"coeff_determination\" not in metrics_folds:\n                metrics_folds[\"coeff_determination\"] = []\n                metrics_folds[\"rmse\"] = []\n            metrics_folds[\"coeff_determination\"].append(coeff_determination)\n            metrics_folds[\"rmse\"].append(rmse)\n\n    return bv_preds_folds, metrics_folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.preprocess_data","title":"<code>preprocess_data(hyperparams, ohe, nsv_train, nsv_val, nsv_test, bv_train, bv_val, bv_test, foldnormparams=None)</code>","text":"<p>Preprocess the data for model training and evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing hyperparameters.</p> required <code>ohe</code> <code>OneHotEncoder</code> <p>One-hot encoder for categorical variables.</p> required <code>nsv_train</code> <code>NDArray</code> <p>Neural state vectors for training.</p> required <code>nsv_val</code> <code>NDArray</code> <p>Neural state vectors for validation.</p> required <code>nsv_test</code> <code>NDArray</code> <p>Neural state vectors for testing.</p> required <code>bv_train</code> <code>NDArray</code> <p>Behavioral state vectors for training.</p> required <code>bv_val</code> <code>NDArray</code> <p>Behavioral state vectors for validation.</p> required <code>bv_test</code> <code>NDArray</code> <p>Behavioral state vectors for testing.</p> required <code>foldnormparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters for the current fold, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray], Tuple[DataLoader, DataLoader, DataLoader], Dict[str, Any]]</code> <p>Preprocessed data, data loaders, and normalization parameters.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def preprocess_data(\n    hyperparams: Dict[str, Any],\n    ohe: sklearn.preprocessing.OneHotEncoder,\n    nsv_train: NDArray,\n    nsv_val: NDArray,\n    nsv_test: NDArray,\n    bv_train: NDArray,\n    bv_val: NDArray,\n    bv_test: NDArray,\n    foldnormparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[\n    Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray],\n    Tuple[\n        torch.utils.data.DataLoader,\n        torch.utils.data.DataLoader,\n        torch.utils.data.DataLoader,\n    ],\n    Dict[str, Any],\n]:\n    \"\"\"\n    Preprocess the data for model training and evaluation.\n\n    Parameters\n    ----------\n    hyperparams : Dict[str, Any]\n        Dictionary containing hyperparameters.\n    ohe : OneHotEncoder\n        One-hot encoder for categorical variables.\n    nsv_train : NDArray\n        Neural state vectors for training.\n    nsv_val : NDArray\n        Neural state vectors for validation.\n    nsv_test : NDArray\n        Neural state vectors for testing.\n    bv_train : NDArray\n        Behavioral state vectors for training.\n    bv_val : NDArray\n        Behavioral state vectors for validation.\n    bv_test : NDArray\n        Behavioral state vectors for testing.\n    foldnormparams : Optional[Dict[str, Any]], optional\n        Normalization parameters for the current fold, by default None.\n\n    Returns\n    -------\n    Tuple[Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray], Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, torch.utils.data.DataLoader], Dict[str, Any]]\n        Preprocessed data, data loaders, and normalization parameters.\n    \"\"\"\n    bins_before = hyperparams[\"bins_before\"]\n    bins_current = hyperparams[\"bins_current\"]\n    bins_after = hyperparams[\"bins_after\"]\n    is_2D = nsv_train[0].ndim == 1\n    if hyperparams[\"model\"] not in (\"M2MLSTM\", \"NDT\"):\n        (\n            X_cov_train,\n            X_flat_train,\n            y_train,\n            ((X_cov_val, X_flat_val, y_val), (X_cov_test, X_flat_test, y_test)),\n            fold_norm_params,\n        ) = normalize_format_trial_segs(\n            nsv_train,\n            (nsv_val, nsv_test),\n            bv_train,\n            (bv_val, bv_test),\n            predict_bv=hyperparams[\"behaviors\"],\n            bins_before=bins_before,\n            bins_current=bins_current,\n            bins_after=bins_after,\n            normparams=foldnormparams,\n        )\n        X_train = X_cov_train if hyperparams[\"model\"] == \"LSTM\" else X_flat_train\n        X_val = X_cov_val if hyperparams[\"model\"] == \"LSTM\" else X_flat_val\n        X_test = X_cov_test if hyperparams[\"model\"] == \"LSTM\" else X_flat_test\n\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            (y_train, y_val, y_test), n_classes = normalize_labels(\n                y_train, y_val, y_test\n            )\n            y_train = ohe.fit_transform(y_train).toarray()\n            y_val = ohe.transform(y_val).toarray()\n            y_test = ohe.transform(y_test).toarray()\n            hyperparams[\"model_args\"][\"out_dim\"] = n_classes\n            fold_norm_params[\"ohe\"] = ohe\n\n        train_loader, val_loader, test_loader = minibatchify(\n            X_train,\n            y_train,\n            X_val,\n            y_val,\n            X_test,\n            y_test,\n            seed=hyperparams[\"seed\"],\n            batch_size=hyperparams[\"batch_size\"],\n            num_workers=hyperparams[\"num_workers\"],\n            modeltype=hyperparams[\"model\"],\n        )\n        hyperparams[\"model_args\"][\"in_dim\"] = X_train.shape[-1]\n    else:\n        if is_2D:\n            nsv_train, bv_train = [nsv_train], [bv_train]\n            nsv_val, bv_val = [nsv_val], [bv_val]\n            nsv_test, bv_test = [nsv_test], [bv_test]\n        if type(bv_train[0]) is pd.DataFrame:\n            y_train = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_train]\n        else:\n            y_train = [y[:, hyperparams[\"behaviors\"]] for y in bv_train]\n        nbins_per_tseg = [len(y) for y in y_train]  # number of time bins in each trial\n        tseg_bounds_train = np.cumsum([0] + nbins_per_tseg)\n        if type(bv_val[0]) is pd.DataFrame:\n            y_val = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_val]\n        else:\n            y_val = [y[:, hyperparams[\"behaviors\"]] for y in bv_val]\n        nbins_per_tseg = [len(y) for y in y_val]\n        tseg_bounds_val = np.cumsum([0] + nbins_per_tseg)\n        if type(bv_test[0]) is pd.DataFrame:\n            y_test = [y.values[:, hyperparams[\"behaviors\"]] for y in bv_test]\n        else:\n            y_test = [y[:, hyperparams[\"behaviors\"]] for y in bv_test]\n        nbins_per_tseg = [len(y) for y in y_test]\n        tseg_bounds_test = np.cumsum([0] + nbins_per_tseg)\n\n        (\n            _,\n            X_flat_train,\n            y_train,\n            ((_, X_flat_val, y_val), (_, X_flat_test, y_test)),\n            fold_norm_params,\n        ) = normalize_format_trial_segs(\n            nsv_train,\n            (nsv_val, nsv_test),\n            bv_train,\n            (bv_val, bv_test, bv_test),\n            predict_bv=hyperparams[\"behaviors\"],\n            bins_before=bins_before,\n            bins_current=bins_current,\n            bins_after=bins_after,\n            normparams=foldnormparams,\n        )\n        X_train = X_flat_train\n        X_val = X_flat_val\n        X_test = X_flat_test\n\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            (y_train, y_val, y_test), n_classes = normalize_labels(\n                y_train, y_val, y_test\n            )\n            y_train = ohe.fit_transform(y_train).toarray()\n            y_val = ohe.transform(y_val).toarray()\n            y_test = ohe.transform(y_test).toarray()\n            hyperparams[\"model_args\"][\"out_dim\"] = n_classes\n            fold_norm_params[\"ohe\"] = ohe\n\n        X_train_tsegs, y_train_tsegs = [], []\n        X_val_tsegs, y_val_tsegs = [], []\n        X_test_tsegs, y_test_tsegs = [], []\n        for i in range(1, len(tseg_bounds_train)):\n            X_train_tsegs.append(\n                X_train[tseg_bounds_train[i - 1] : tseg_bounds_train[i]]\n            )\n            y_train_tsegs.append(\n                y_train[tseg_bounds_train[i - 1] : tseg_bounds_train[i]]\n            )\n        for i in range(1, len(tseg_bounds_val)):\n            X_val_tsegs.append(X_val[tseg_bounds_val[i - 1] : tseg_bounds_val[i]])\n            y_val_tsegs.append(y_val[tseg_bounds_val[i - 1] : tseg_bounds_val[i]])\n        for i in range(1, len(tseg_bounds_test)):\n            X_test_tsegs.append(X_test[tseg_bounds_test[i - 1] : tseg_bounds_test[i]])\n            y_test_tsegs.append(y_test[tseg_bounds_test[i - 1] : tseg_bounds_test[i]])\n\n        X_train, y_train = X_train_tsegs, y_train_tsegs\n        X_val, y_val = X_val_tsegs, y_val_tsegs\n        X_test, y_test = X_test_tsegs, y_test_tsegs\n\n        train_dataset = NSVDataset(X_train, y_train)\n        val_dataset = NSVDataset(X_val, y_val)\n        test_dataset = NSVDataset(X_test, y_test)\n\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            shuffle=True,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        val_loader = torch.utils.data.DataLoader(\n            val_dataset,\n            shuffle=False,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        test_loader = torch.utils.data.DataLoader(\n            test_dataset,\n            shuffle=False,\n            num_workers=hyperparams[\"num_workers\"],\n            batch_size=1,\n        )\n        hyperparams[\"model_args\"][\"in_dim\"] = X_train[0].shape[-1]\n\n    return (\n        (X_train, y_train, X_val, y_val, X_test, y_test),\n        (train_loader, val_loader, test_loader),\n        fold_norm_params,\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.seed_worker","title":"<code>seed_worker(worker_id)</code>","text":"<p>Seed a worker with the given ID for reproducibility in data loading.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>The ID of the worker to be seeded.</p> required Notes <p>This function is used to ensure reproducibility when using multi-process data loading.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def seed_worker(worker_id: int) -&gt; None:\n    \"\"\"\n    Seed a worker with the given ID for reproducibility in data loading.\n\n    Parameters\n    ----------\n    worker_id : int\n        The ID of the worker to be seeded.\n\n    Notes\n    -----\n    This function is used to ensure reproducibility when using multi-process data loading.\n    \"\"\"\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.shuffle_nsv_intrialsegs","title":"<code>shuffle_nsv_intrialsegs(nsv_trialsegs)</code>","text":"<p>Shuffle neural state variables within trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>nsv_trialsegs</code> <code>List[DataFrame]</code> <p>List of neural state variable trial segments.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Shuffled neural state variables.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def shuffle_nsv_intrialsegs(nsv_trialsegs: List[pd.DataFrame]) -&gt; NDArray:\n    \"\"\"\n    Shuffle neural state variables within trial segments.\n\n    Parameters\n    ----------\n    nsv_trialsegs : List[pd.DataFrame]\n        List of neural state variable trial segments.\n\n    Returns\n    -------\n    NDArray\n        Shuffled neural state variables.\n    \"\"\"\n    nsv_shuffled_intrialsegs = []\n    for nsv_tseg in nsv_trialsegs:\n        # shuffle the data\n        nsv_shuffled_intrialsegs.append(nsv_tseg.sample(frac=1).reset_index(drop=True))\n    return np.asarray(nsv_shuffled_intrialsegs, dtype=object)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.train_model","title":"<code>train_model(partitions, hyperparams, resultspath=None, stop_partition=None)</code>","text":"<p>Train a DNN model on the given data partitions with in-built caching &amp; checkpointing.</p> <p>Parameters:</p> Name Type Description Default <code>partitions</code> <code>List[Tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray]]</code> <p>K-fold partitions of the data with the following format: [(nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test), ...] Each element of the list is a tuple of numpy arrays containing the with pairs of neural state vectors and behavioral variables for the training, validation, and test sets. Each array has the shape (ntrials, nbins, nfeats) where nfeats is the number of neurons for the neural state vectors and number of behavioral features to be predicted for the behavioral variables.</p> required <code>hyperparams</code> <code>Dict[str, Any]</code> <p>Dictionary containing the hyperparameters for the model training.</p> required <code>resultspath</code> <code>Optional[str]</code> <p>Path to the directory where the trained models and logs will be saved.</p> <code>None</code> <code>stop_partition</code> <code>Optional[int]</code> <p>Index of the partition to stop training at. Only useful for debugging, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple containing the predicted behavioral variables for each fold, the trained models for each fold, the normalization parameters for each fold, and the evaluation metrics for each fold.</p> Notes <p>The hyperparameters dictionary should contain the following keys: - <code>model</code>: str, the type of the model to be trained. Multi-layer     Perceptron (MLP), Long Short-Term Memory (LSTM), many-to-many LSTM     (M2MLSTM), Transformer (NDT). - <code>model_args</code>: dict, the arguments to be passed to the model constructor.     The arguments should be in the format expected by the model constructor.     - <code>in_dim</code>: The number of input features.     - <code>out_dim</code>: The number of output features.     - <code>hidden_dims</code>: The number of hidden units each hidden layer of the         model. Can also take float values to specify the dropout rate.         - For LSTM and M2MLSTM, it should be a tuple of the hidden size,             the number of layers, and the dropout rate.             If the model is an MLP, it should be a list of hidden layer             sizes which can also take float values to specify the dropout             rate.         - If the model is an LSTM or M2MLSTM, it should be a list of the         hidden layer size, the number of layers, and the dropout rate.         - If the model is an NDT, it should be a list of the hidden layer             size, the number of layers, the number of attention heads, the             dropout rate for the encoder layer, and the dropout rate applied             before the decoder layer.     - <code>max_context_len</code>: The maximum context length for the transformer         model. Only used if the model is an NDT.     - <code>args</code>:         - <code>clf</code>: If True, the model is a classifier; otherwise, it is a             regressor.         - <code>activations</code>: The activation functions for each layer.         - <code>criterion</code>: The loss function to optimize.         - <code>epochs</code>: The number of complete passes through the training             dataset.         - <code>lr</code>: Controls how much to change the model in response to the             estimated error each time the model weights are updated. A             smaller value ensures stable convergence but may slow down             training, while a larger value speeds up training but risks             overshooting.         - <code>base_lr</code>: The initial learning rate for the learning rate             scheduler.         - <code>max_grad_norm</code>: The maximum norm of the gradients.         - <code>iters_to_accumulate</code>: The number of iterations to accumulate             gradients.         - <code>weight_decay</code>: The L2 regularization strength.         - <code>num_training_batches</code>: The number of training batches. If             None, the number of batches is calculated based on the batch             size and the length of the training data.         - <code>scheduler_step_size_multiplier</code>: The multiplier for the             learning rate scheduler step size. Higher values lead to             faster learning rate decay. - <code>bins_before</code>: int, the number of bins before the current bin to     include in the input data. - <code>bins_current</code>: int, the number of bins in the current time bin to     include in the input data. - <code>bins_after</code>: int, the number of bins after the current bin to include     in the input data. - <code>behaviors</code>: list, the indices of the columns of behavioral features     to be predicted. Selected behavioral variable must have homogenous     data types across all features (continuous for regression and     categorical for classification) - <code>batch_size</code>: int, the number of training examples utilized in one     iteration. Larger batch sizes offer stable gradient estimates but     require more memory, while smaller batches introduce noise that can     help escape local minima.     - When using M2MLSTM or NDT and input trials are of inconsistents         lengths, the batch size should be set to 1.     - M2MLSTM does not support batch_size != 1. - <code>num_workers</code>: int, The number of parallel processes to use for data     loading. Increasing the number of workers can speed up data loading     but may lead to memory issues. Too many workers can also slow down     the training process due to contention for resources. - <code>accelerator</code>: str, the device to use for training. Should be 'cuda' or     'cpu'. - <code>seed</code>: int, the random seed for reproducibility.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def train_model(\n    partitions: List[\n        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n    ],\n    hyperparams: Dict[str, Any],\n    resultspath: Optional[str] = None,\n    stop_partition: Optional[int] = None,\n) -&gt; Tuple[List[np.ndarray], List[Any], List[Dict[str, Any]], Dict[str, List[float]]]:\n    \"\"\"\n    Train a DNN model on the given data partitions with in-built caching &amp; checkpointing.\n\n    Parameters\n    ----------\n    partitions : List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n        K-fold partitions of the data with the following format:\n        [(nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test), ...]\n        Each element of the list is a tuple of numpy arrays containing the with\n        pairs of neural state vectors and behavioral variables for the training,\n        validation, and test sets. Each array has the shape\n        (ntrials, nbins, nfeats) where nfeats is the number of neurons for the\n        neural state vectors and number of behavioral features to be predicted\n        for the behavioral variables.\n    hyperparams : Dict[str, Any]\n        Dictionary containing the hyperparameters for the model training.\n    resultspath : Optional[str], default=None\n        Path to the directory where the trained models and logs will be saved.\n    stop_partition : Optional[int], default=None\n        Index of the partition to stop training at. Only useful for debugging,\n        by default None\n\n    Returns\n    -------\n    tuple\n        Tuple containing the predicted behavioral variables for each fold,\n        the trained models for each fold, the normalization parameters for each\n        fold, and the evaluation metrics for each fold.\n\n    Notes\n    -----\n    The hyperparameters dictionary should contain the following keys:\n    - `model`: str, the type of the model to be trained. Multi-layer\n        Perceptron (MLP), Long Short-Term Memory (LSTM), many-to-many LSTM\n        (M2MLSTM), Transformer (NDT).\n    - `model_args`: dict, the arguments to be passed to the model constructor.\n        The arguments should be in the format expected by the model constructor.\n        - `in_dim`: The number of input features.\n        - `out_dim`: The number of output features.\n        - `hidden_dims`: The number of hidden units each hidden layer of the\n            model. Can also take float values to specify the dropout rate.\n            - For LSTM and M2MLSTM, it should be a tuple of the hidden size,\n                the number of layers, and the dropout rate.\n                If the model is an MLP, it should be a list of hidden layer\n                sizes which can also take float values to specify the dropout\n                rate.\n            - If the model is an LSTM or M2MLSTM, it should be a list of the\n            hidden layer size, the number of layers, and the dropout rate.\n            - If the model is an NDT, it should be a list of the hidden layer\n                size, the number of layers, the number of attention heads, the\n                dropout rate for the encoder layer, and the dropout rate applied\n                before the decoder layer.\n        - `max_context_len`: The maximum context length for the transformer\n            model. Only used if the model is an NDT.\n        - `args`:\n            - `clf`: If True, the model is a classifier; otherwise, it is a\n                regressor.\n            - `activations`: The activation functions for each layer.\n            - `criterion`: The loss function to optimize.\n            - `epochs`: The number of complete passes through the training\n                dataset.\n            - `lr`: Controls how much to change the model in response to the\n                estimated error each time the model weights are updated. A\n                smaller value ensures stable convergence but may slow down\n                training, while a larger value speeds up training but risks\n                overshooting.\n            - `base_lr`: The initial learning rate for the learning rate\n                scheduler.\n            - `max_grad_norm`: The maximum norm of the gradients.\n            - `iters_to_accumulate`: The number of iterations to accumulate\n                gradients.\n            - `weight_decay`: The L2 regularization strength.\n            - `num_training_batches`: The number of training batches. If\n                None, the number of batches is calculated based on the batch\n                size and the length of the training data.\n            - `scheduler_step_size_multiplier`: The multiplier for the\n                learning rate scheduler step size. Higher values lead to\n                faster learning rate decay.\n    - `bins_before`: int, the number of bins before the current bin to\n        include in the input data.\n    - `bins_current`: int, the number of bins in the current time bin to\n        include in the input data.\n    - `bins_after`: int, the number of bins after the current bin to include\n        in the input data.\n    - `behaviors`: list, the indices of the columns of behavioral features\n        to be predicted. Selected behavioral variable must have homogenous\n        data types across all features (continuous for regression and\n        categorical for classification)\n    - `batch_size`: int, the number of training examples utilized in one\n        iteration. Larger batch sizes offer stable gradient estimates but\n        require more memory, while smaller batches introduce noise that can\n        help escape local minima.\n        - When using M2MLSTM or NDT and input trials are of inconsistents\n            lengths, the batch size should be set to 1.\n        - M2MLSTM does not support batch_size != 1.\n    - `num_workers`: int, The number of parallel processes to use for data\n        loading. Increasing the number of workers can speed up data loading\n        but may lead to memory issues. Too many workers can also slow down\n        the training process due to contention for resources.\n    - `accelerator`: str, the device to use for training. Should be 'cuda' or\n        'cpu'.\n    - `seed`: int, the random seed for reproducibility.\n    \"\"\"\n    ohe = sklearn.preprocessing.OneHotEncoder()\n    bv_preds_folds = []\n    bv_models_folds = []\n    norm_params_folds = []\n    metrics_folds = dict()  # dict with keys 'accuracy', 'coeff_determination', 'rmse' and values of length number of folds\n    for i, (nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test) in enumerate(\n        partitions\n    ):\n        # shuffle nsv bins in between tsegs to generate baseline distribution for vector dev plots\n        preprocessed_data = preprocess_data(\n            hyperparams, ohe, nsv_train, nsv_val, nsv_test, bv_train, bv_val, bv_test\n        )\n        (\n            (X_train, y_train, X_val, y_val, X_test, y_test),\n            (train_loader, val_loader, test_loader),\n            fold_norm_params,\n        ) = preprocessed_data\n        hyperparams[\"model_args\"][\"args\"][\"num_training_batches\"] = len(train_loader)\n\n        decoder, model = create_model(hyperparams)\n\n        hyperparams_cp = copy.deepcopy(hyperparams)\n        del hyperparams_cp[\"model_args\"][\"args\"][\"epochs\"]\n        del hyperparams_cp[\"model_args\"][\"args\"][\"num_training_batches\"]\n        model_cache_name = zlib.crc32(str(hyperparams_cp).encode(\"utf-8\"))\n        best_ckpt_path = None\n        if resultspath is not None:\n            model_cache_path = os.path.join(\n                resultspath, \"models\", str(model_cache_name)\n            )\n            best_ckpt_name_file = os.path.join(model_cache_path, f\"{i}-best_model.txt\")\n            if os.path.exists(best_ckpt_name_file):\n                with open(best_ckpt_name_file, \"r\") as f:\n                    best_ckpt_path = f.read()\n\n        lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n        callbacks = [lr_monitor]\n        if resultspath is not None:\n            checkpoint_callback = pl.callbacks.ModelCheckpoint(\n                save_top_k=1,\n                monitor=\"val_loss\",\n                dirpath=model_cache_path,\n                filename=f\"{i}\" + \"-{epoch:02d}-{val_loss:.2f}\",\n            )\n            callbacks.append(checkpoint_callback)\n        logger = pl.loggers.TensorBoardLogger(\n            save_dir=\"logs\",\n            name=f\"{model_cache_name}-{i}\",\n        )\n        pl.seed_everything(hyperparams[\"seed\"], workers=True)\n        trainer = pl.Trainer(\n            accelerator=hyperparams[\"accelerator\"],\n            devices=\"auto\",\n            max_epochs=hyperparams[\"model_args\"][\"args\"][\"epochs\"],\n            gradient_clip_val=hyperparams[\"model_args\"][\"args\"][\"max_grad_norm\"],\n            accumulate_grad_batches=hyperparams[\"model_args\"][\"args\"][\n                \"iters_to_accumulate\"\n            ],\n            logger=logger,\n            callbacks=callbacks,\n            enable_progress_bar=False,\n            log_every_n_steps=5,\n            reload_dataloaders_every_n_epochs=1,\n        )\n        trainer.fit(model, train_loader, val_loader, ckpt_path=best_ckpt_path)\n        if resultspath is not None:\n            os.makedirs(model_cache_path, exist_ok=True)\n            with open(best_ckpt_name_file, \"w\") as f:\n                f.write(checkpoint_callback.best_model_path)\n        model.eval()\n        trainer.test(model, test_loader)\n        predictor = model if hyperparams[\"model\"] != \"LSTM\" else model.predict\n\n        metrics, bv_preds_fold = evaluate_model(\n            hyperparams, ohe, predictor, X_test, y_test\n        )\n        bv_preds_folds.append(bv_preds_fold)\n        bv_models_folds.append(model)\n        norm_params_folds.append(copy.deepcopy(fold_norm_params))\n        if hyperparams[\"model_args\"][\"args\"][\"clf\"]:\n            print(\"Accuracy:\", metrics[\"accuracy\"])\n            if \"accuracy\" not in metrics_folds:\n                metrics_folds[\"accuracy\"] = []\n            metrics_folds[\"accuracy\"].append(metrics[\"accuracy\"])\n        else:\n            coeff_determination = metrics[\"coeff_determination\"]\n            rmse = metrics[\"rmse\"]\n            print(\n                \"Variance weighed avg. coefficient of determination:\",\n                coeff_determination,\n            )\n            print(\"RMSE:\", rmse)\n\n            if \"coeff_determination\" not in metrics_folds:\n                metrics_folds[\"coeff_determination\"] = []\n                metrics_folds[\"rmse\"] = []\n            metrics_folds[\"coeff_determination\"].append(coeff_determination)\n            metrics_folds[\"rmse\"].append(rmse)\n\n        if stop_partition is not None and i == stop_partition:\n            break\n    return bv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/pipeline/#neuro_py.ensemble.decoding.pipeline.zscore_trial_segs","title":"<code>zscore_trial_segs(train, rest_feats=None, normparams=None)</code>","text":"<p>Z-score trial segments.</p> <p>Parameters:</p> Name Type Description Default <code>train</code> <code>NDArray</code> <p>Training data.</p> required <code>rest_feats</code> <code>Optional[List[NDArray]]</code> <p>Rest features, by default None.</p> <code>None</code> <code>normparams</code> <code>Optional[Dict[str, Any]]</code> <p>Normalization parameters, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, List[NDArray], Dict[str, Any]]</code> <p>Normalized train data, normalized rest features, and normalization parameters.</p> Source code in <code>neuro_py/ensemble/decoding/pipeline.py</code> <pre><code>def zscore_trial_segs(\n    train: NDArray,\n    rest_feats: Optional[List[NDArray]] = None,\n    normparams: Optional[Dict[str, Any]] = None,\n) -&gt; Tuple[NDArray, List[NDArray], Dict[str, Any]]:\n    \"\"\"\n    Z-score trial segments.\n\n    Parameters\n    ----------\n    train : NDArray\n        Training data.\n    rest_feats : Optional[List[NDArray]], optional\n        Rest features, by default None.\n    normparams : Optional[Dict[str, Any]], optional\n        Normalization parameters, by default None.\n\n    Returns\n    -------\n    Tuple[NDArray, List[NDArray], Dict[str, Any]]\n        Normalized train data, normalized rest features, and normalization parameters.\n    \"\"\"\n    is_2D = train[0].ndim == 1\n    concat_train = train if is_2D else np.concatenate(train).astype(float)\n    train_mean = (\n        normparams[\"X_train_mean\"]\n        if normparams is not None\n        else bn.nanmean(concat_train, axis=0)\n    )\n    train_std = (\n        normparams[\"X_train_std\"]\n        if normparams is not None\n        else bn.nanstd(concat_train, axis=0)\n    )\n\n    train_notnan_cols = train_std != 0\n    train_nan_cols = ~train_notnan_cols\n    if is_2D:\n        normed_train = np.divide(train - train_mean, train_std, where=train_notnan_cols)\n        # if train is not jagged, it gets converted completely to object\n        # np.ndarray. Hence, cannot exclusively use normed_train.loc\n        if isinstance(normed_train, pd.DataFrame):\n            normed_train.loc[:, train_nan_cols] = 0\n        else:\n            normed_train[:, train_nan_cols] = 0\n    else:\n        normed_train = np.empty_like(train)\n        for i, nsvstseg in enumerate(train):\n            zscored = np.divide(\n                nsvstseg - train_mean, train_std, where=train_notnan_cols\n            )\n            if isinstance(zscored, pd.DataFrame):\n                zscored.loc[:, train_nan_cols] = 0\n            else:\n                zscored[:, train_nan_cols] = 0\n            normed_train[i] = zscored\n\n    normed_rest_feats = []\n    if rest_feats is not None:\n        for feats in rest_feats:\n            if is_2D:\n                normed_feats = np.divide(\n                    feats - train_mean, train_std, where=train_notnan_cols\n                )\n                if isinstance(normed_feats, pd.DataFrame):\n                    normed_feats.loc[:, train_nan_cols] = 0\n                else:\n                    normed_feats[:, train_nan_cols] = 0\n                normed_rest_feats.append(normed_feats)\n            else:\n                normed_feats = np.empty_like(feats)\n                for i, trialSegROI in enumerate(feats):\n                    zscored = np.divide(\n                        feats[i] - train_mean, train_std, where=train_notnan_cols\n                    )\n                    if isinstance(zscored, pd.DataFrame):\n                        zscored.loc[:, train_nan_cols] = 0\n                    else:\n                        zscored[:, train_nan_cols] = 0\n                    normed_feats[i] = zscored\n                normed_rest_feats.append(normed_feats)\n\n    return (\n        normed_train,\n        normed_rest_feats,\n        dict(\n            X_train_mean=train_mean,\n            X_train_std=train_std,\n            X_train_notnan_mask=train_notnan_cols,\n        ),\n    )\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/preprocess/","title":"neuro_py.ensemble.decoding.preprocess","text":""},{"location":"reference/neuro_py/ensemble/decoding/preprocess/#neuro_py.ensemble.decoding.preprocess.partition_indices","title":"<code>partition_indices(folds)</code>","text":"<p>Partition indices into train, validation, and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>folds</code> <code>List[ndarray]</code> <p>Indices for each fold.</p> required <p>Returns:</p> Type Description <code>List[Tuple[ndarray, ndarray, ndarray]]</code> <p>Train, validation, and test indices.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def partition_indices(\n    folds: List[np.ndarray],\n) -&gt; List[Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n    \"\"\"\n    Partition indices into train, validation, and test sets.\n\n    Parameters\n    ----------\n    folds : List[np.ndarray]\n        Indices for each fold.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray, np.ndarray]]\n        Train, validation, and test indices.\n    \"\"\"\n    partition_mask = np.zeros(len(folds), dtype=int)\n    partition_mask[0:2] = (2, 1)\n    folds_arr = np.asarray(folds, dtype=object)\n\n    partitions_indices = []\n    for i in range(len(folds)):\n        curr_pmask = np.roll(partition_mask, i)\n        train_indices = np.concatenate(folds_arr[curr_pmask == 0]).tolist()\n        val_indices = np.concatenate(folds_arr[curr_pmask == 1]).tolist()\n        test_indices = np.concatenate(folds_arr[curr_pmask == 2]).tolist()\n\n        partitions_indices.append((train_indices, val_indices, test_indices))\n    return partitions_indices\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/preprocess/#neuro_py.ensemble.decoding.preprocess.partition_sets","title":"<code>partition_sets(partitions_indices, nsv_trial_segs, bv_trial_segs)</code>","text":"<p>Partition neural state vectors and behavioral variables into train, validation, and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>partitions_indices</code> <code>List[Tuple[ndarray, ndarray, ndarray]]</code> <p>List of tuples containing indices of divided trials into train, validation, and test sets.</p> required <code>nsv_trial_segs</code> <code>Union[ndarray, DataFrame]</code> <p>Neural state vectors for each trial. Shape: [n_trials, n_timepoints, n_neurons] or [n_timepoints, n_neurons]</p> required <code>bv_trial_segs</code> <code>Union[ndarray, DataFrame]</code> <p>Behavioral variables for each trial. Shape: [n_trials, n_timepoints, n_bvars] or [n_timepoints, n_bvars]</p> required <p>Returns:</p> Type Description <code>List[Tuple[ndarray, ndarray, ndarray, ndarray, ndarray, ndarray]]</code> <p>List of tuples containing train, validation, and test sets for neural state vectors and behavioral variables.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def partition_sets(\n    partitions_indices: List[Tuple[np.ndarray, np.ndarray, np.ndarray]],\n    nsv_trial_segs: Union[np.ndarray, pd.DataFrame],\n    bv_trial_segs: Union[np.ndarray, pd.DataFrame],\n) -&gt; List[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n]:\n    \"\"\"\n    Partition neural state vectors and behavioral variables into train,\n    validation, and test sets.\n\n    Parameters\n    ----------\n    partitions_indices : List[Tuple[np.ndarray, np.ndarray, np.ndarray]]\n        List of tuples containing indices of divided trials into train,\n        validation, and test sets.\n    nsv_trial_segs : Union[np.ndarray, pd.DataFrame]\n        Neural state vectors for each trial.\n        Shape: [n_trials, n_timepoints, n_neurons] or [n_timepoints, n_neurons]\n    bv_trial_segs : Union[np.ndarray, pd.DataFrame]\n        Behavioral variables for each trial.\n        Shape: [n_trials, n_timepoints, n_bvars] or [n_timepoints, n_bvars]\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n        List of tuples containing train, validation, and test sets for neural\n        state vectors and behavioral variables.\n    \"\"\"\n    partitions = []\n    is_2D = nsv_trial_segs[0].ndim == 1\n    for train_indices, val_indices, test_indices in partitions_indices:\n        if is_2D:\n            if isinstance(nsv_trial_segs, pd.DataFrame):\n                nsv_trial_segs = nsv_trial_segs.loc\n                bv_trial_segs = bv_trial_segs.loc\n            train = nsv_trial_segs[train_indices]\n            val = nsv_trial_segs[val_indices]\n            test = nsv_trial_segs[test_indices]\n            train_bv = bv_trial_segs[train_indices]\n            val_bv = bv_trial_segs[val_indices]\n            test_bv = bv_trial_segs[test_indices]\n        else:\n            train = np.take(nsv_trial_segs, train_indices, axis=0)\n            val = np.take(nsv_trial_segs, val_indices, axis=0)\n            test = np.take(nsv_trial_segs, test_indices, axis=0)\n            train_bv = np.take(bv_trial_segs, train_indices, axis=0)\n            val_bv = np.take(bv_trial_segs, val_indices, axis=0)\n            test_bv = np.take(bv_trial_segs, test_indices, axis=0)\n\n        partitions.append((train, train_bv, val, val_bv, test, test_bv))\n    return partitions\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/preprocess/#neuro_py.ensemble.decoding.preprocess.split_data","title":"<code>split_data(trial_nsvs, splitby, trainsize=0.8, seed=0)</code>","text":"<p>Split data into stratified folds.</p> <p>Parameters:</p> Name Type Description Default <code>trial_nsvs</code> <code>ndarray</code> <p>Neural state vectors for trials.</p> required <code>splitby</code> <code>ndarray</code> <p>Labels for stratification.</p> required <code>trainsize</code> <code>float</code> <p>Proportion of data to use for training, by default 0.8</p> <code>0.8</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility, by default 0</p> <code>0</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List of indices for each fold.</p> Source code in <code>neuro_py/ensemble/decoding/preprocess.py</code> <pre><code>def split_data(\n    trial_nsvs: np.ndarray, splitby: np.ndarray, trainsize: float = 0.8, seed: int = 0\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Split data into stratified folds.\n\n    Parameters\n    ----------\n    trial_nsvs : np.ndarray\n        Neural state vectors for trials.\n    splitby : np.ndarray\n        Labels for stratification.\n    trainsize : float, optional\n        Proportion of data to use for training, by default 0.8\n    seed : int, optional\n        Random seed for reproducibility, by default 0\n\n    Returns\n    -------\n    List[np.ndarray]\n        List of indices for each fold.\n    \"\"\"\n    n_splits = int(np.round(1 / ((1 - trainsize) / 2)))\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    folds = [fold_indices for _, fold_indices in skf.split(trial_nsvs, splitby)]\n    return folds\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/","title":"neuro_py.ensemble.decoding.transformer","text":""},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT","title":"<code>NDT</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Transformer encoder-based dynamical systems decoder.</p> <p>This class implements a Transformer-based decoder trained on MLM loss. It returns loss and predicted rates.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Dimensionality of input data, by default 100</p> <code>100</code> <code>out_dim</code> <code>int</code> <p>Number of output columns, by default 2</p> <code>2</code> <code>hidden_dims</code> <code>Tuple[int]</code> <p>Architectural parameters of the model (dim_feedforward, num_layers, nhead, dropout, rate_dropout), by default [400, 1, 1, 0.0, 0.0]</p> <code>(400, 1, 1, 0.0, 0.0)</code> <code>max_context_len</code> <code>int</code> <p>Maximum context length, by default 2</p> <code>2</code> <code>args</code> <code>Optional[Dict]</code> <p>Dictionary containing the hyperparameters of the model, by default None</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>pos_encoder</code> <code>PositionalEncoding</code> <p>Positional encoding module</p> <code>transformer_encoder</code> <code>TransformerEncoder</code> <p>Transformer encoder module</p> <code>rate_dropout</code> <code>Dropout</code> <p>Dropout layer for rates</p> <code>decoder</code> <code>Sequential</code> <p>Decoder network</p> <code>src_mask</code> <code>Dict[str, Tensor]</code> <p>Dictionary to store source masks for different devices</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>class NDT(L.LightningModule):\n    \"\"\"\n    Transformer encoder-based dynamical systems decoder.\n\n    This class implements a Transformer-based decoder trained on MLM loss.\n    It returns loss and predicted rates.\n\n    Parameters\n    ----------\n    in_dim : int, optional\n        Dimensionality of input data, by default 100\n    out_dim : int, optional\n        Number of output columns, by default 2\n    hidden_dims : Tuple[int], optional\n        Architectural parameters of the model\n        (dim_feedforward, num_layers, nhead, dropout, rate_dropout),\n        by default [400, 1, 1, 0.0, 0.0]\n    max_context_len : int, optional\n        Maximum context length, by default 2\n    args : Optional[Dict], optional\n        Dictionary containing the hyperparameters of the model, by default None\n\n    Attributes\n    ----------\n    pos_encoder : PositionalEncoding\n        Positional encoding module\n    transformer_encoder : nn.TransformerEncoder\n        Transformer encoder module\n    rate_dropout : nn.Dropout\n        Dropout layer for rates\n    decoder : nn.Sequential\n        Decoder network\n    src_mask : Dict[str, torch.Tensor]\n        Dictionary to store source masks for different devices\n    \"\"\"\n\n    def __init__(\n        self,\n        in_dim: int = 100,\n        out_dim: int = 2,\n        hidden_dims: Tuple[int] = (400, 1, 1, 0.0, 0.0),\n        max_context_len: int = 2,\n        args: Optional[Dict] = None,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.max_context_len = max_context_len\n        self.in_dim = in_dim\n        self.args = args if args is not None else {}\n        activations = (\n            nn.CELU\n            if self.args.get(\"activations\") is None\n            else self.args[\"activations\"]\n        )\n\n        self.src_mask: Dict[str, torch.Tensor] = {}\n\n        self.pos_encoder = PositionalEncoding(in_dim, max_context_len, self.args)\n\n        encoder_lyr = nn.TransformerEncoderLayer(\n            in_dim,\n            nhead=hidden_dims[2],\n            dim_feedforward=hidden_dims[0],\n            dropout=hidden_dims[3],\n            activation=nn.functional.relu,\n        )\n\n        self.transformer_encoder = nn.TransformerEncoder(\n            encoder_lyr, hidden_dims[1], nn.LayerNorm(in_dim)\n        )\n\n        self.rate_dropout = nn.Dropout(hidden_dims[4])\n\n        self.decoder = nn.Sequential(\n            nn.Linear(in_dim, 16), activations(), nn.Linear(16, out_dim)\n        )\n\n        self._init_params()\n\n    def _init_params(self) -&gt; None:\n        \"\"\"Initialize the parameters of the decoder.\"\"\"\n\n        def init_params(m: nn.Module) -&gt; None:\n            if isinstance(m, nn.Linear):\n                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n                if m.bias is not None:\n                    fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                    bound = 1 / np.sqrt(fan_in)\n                    nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n        self.decoder.apply(init_params)\n\n    def forward(\n        self, x: torch.Tensor, mask_labels: Optional[torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the model.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input data of shape (batch_size, seq_len, in_dim)\n        mask_labels : Optional[torch.Tensor], optional\n            Masking labels for the input data, by default None\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor of shape (batch_size, seq_len, out_dim)\n        \"\"\"\n        x = x.permute(1, 0, 2)  # LxBxN\n        x = self.pos_encoder(x)\n        x_mask = self._get_or_generate_context_mask(x)\n        z = self.transformer_encoder(x, x_mask)\n        z = self.rate_dropout(z)\n        out = self.decoder(z).permute(1, 0, 2)  # B x L x out_dim\n        if self.args.get(\"clf\", False):\n            out = F.log_softmax(out, dim=-1)\n        return out\n\n    def _get_or_generate_context_mask(self, src: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Get or generate the context mask for the input tensor.\n\n        Parameters\n        ----------\n        src : torch.Tensor\n            Input tensor\n\n        Returns\n        -------\n        torch.Tensor\n            Context mask for the input tensor\n        \"\"\"\n        context_forward = 4\n        size = src.size(0)  # T\n        mask = (\n            torch.triu(\n                torch.ones(size, size, device=src.device), diagonal=-context_forward\n            )\n            == 1\n        ).transpose(0, 1)\n        mask = mask.float()\n        self.src_mask[str(src.device)] = mask\n        return self.src_mask[str(src.device)]\n\n    def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single step (forward pass + loss calculation).\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        xs, ys = batch\n        outs = self(xs)\n        loss = self.args[\"criterion\"](outs, ys)\n        return loss\n\n    def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for training step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for validation step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def test_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Lightning method for test step.\n\n        Parameters\n        ----------\n        batch : tuple\n            Batch of input data and labels\n        batch_idx : int\n            Index of the current batch\n\n        Returns\n        -------\n        torch.Tensor\n            Computed loss\n        \"\"\"\n        loss = self._step(batch, batch_idx)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self) -&gt; tuple:\n        \"\"\"\n        Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        tuple\n            List of optimizers and a list of scheduler configurations\n        \"\"\"\n        optimizer = torch.optim.AdamW(\n            self.parameters(), weight_decay=self.args[\"weight_decay\"]\n        )\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            max_lr=self.args[\"lr\"],\n            epochs=self.args[\"epochs\"],\n            total_steps=self.trainer.estimated_stepping_batches,\n        )\n        lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n        return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT._get_or_generate_context_mask","title":"<code>_get_or_generate_context_mask(src)</code>","text":"<p>Get or generate the context mask for the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Input tensor</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Context mask for the input tensor</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _get_or_generate_context_mask(self, src: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Get or generate the context mask for the input tensor.\n\n    Parameters\n    ----------\n    src : torch.Tensor\n        Input tensor\n\n    Returns\n    -------\n    torch.Tensor\n        Context mask for the input tensor\n    \"\"\"\n    context_forward = 4\n    size = src.size(0)  # T\n    mask = (\n        torch.triu(\n            torch.ones(size, size, device=src.device), diagonal=-context_forward\n        )\n        == 1\n    ).transpose(0, 1)\n    mask = mask.float()\n    self.src_mask[str(src.device)] = mask\n    return self.src_mask[str(src.device)]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT._init_params","title":"<code>_init_params()</code>","text":"<p>Initialize the parameters of the decoder.</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _init_params(self) -&gt; None:\n    \"\"\"Initialize the parameters of the decoder.\"\"\"\n\n    def init_params(m: nn.Module) -&gt; None:\n        if isinstance(m, nn.Linear):\n            torch.nn.init.kaiming_uniform_(m.weight, nonlinearity=\"leaky_relu\")\n            if m.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n                bound = 1 / np.sqrt(fan_in)\n                nn.init.uniform_(m.bias, -bound, bound)  # LeCunn init\n\n    self.decoder.apply(init_params)\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Perform a single step (forward pass + loss calculation).</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def _step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single step (forward pass + loss calculation).\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    xs, ys = batch\n    outs = self(xs)\n    loss = self.args[\"criterion\"](outs, ys)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>List of optimizers and a list of scheduler configurations</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def configure_optimizers(self) -&gt; tuple:\n    \"\"\"\n    Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    tuple\n        List of optimizers and a list of scheduler configurations\n    \"\"\"\n    optimizer = torch.optim.AdamW(\n        self.parameters(), weight_decay=self.args[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=self.args[\"lr\"],\n        epochs=self.args[\"epochs\"],\n        total_steps=self.trainer.estimated_stepping_batches,\n    )\n    lr_scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n    return [optimizer], [lr_scheduler]\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT.forward","title":"<code>forward(x, mask_labels=None)</code>","text":"<p>Forward pass of the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data of shape (batch_size, seq_len, in_dim)</p> required <code>mask_labels</code> <code>Optional[Tensor]</code> <p>Masking labels for the input data, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape (batch_size, seq_len, out_dim)</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, mask_labels: Optional[torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the model.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input data of shape (batch_size, seq_len, in_dim)\n    mask_labels : Optional[torch.Tensor], optional\n        Masking labels for the input data, by default None\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor of shape (batch_size, seq_len, out_dim)\n    \"\"\"\n    x = x.permute(1, 0, 2)  # LxBxN\n    x = self.pos_encoder(x)\n    x_mask = self._get_or_generate_context_mask(x)\n    z = self.transformer_encoder(x, x_mask)\n    z = self.rate_dropout(z)\n    out = self.decoder(z).permute(1, 0, 2)  # B x L x out_dim\n    if self.args.get(\"clf\", False):\n        out = F.log_softmax(out, dim=-1)\n    return out\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Lightning method for training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def training_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for training step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"train_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.NDT.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Lightning method for validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple</code> <p>Batch of input data and labels</p> required <code>batch_idx</code> <code>int</code> <p>Index of the current batch</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Computed loss</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def validation_step(self, batch: tuple, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Lightning method for validation step.\n\n    Parameters\n    ----------\n    batch : tuple\n        Batch of input data and labels\n    batch_idx : int\n        Index of the current batch\n\n    Returns\n    -------\n    torch.Tensor\n        Computed loss\n    \"\"\"\n    loss = self._step(batch, batch_idx)\n    self.log(\"val_loss\", loss)\n    return loss\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.PositionalEncoding","title":"<code>PositionalEncoding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Positional Encoding module for Transformer models.</p> <p>Parameters:</p> Name Type Description Default <code>in_dim</code> <code>int</code> <p>Input dimension of the model</p> required <code>max_context_len</code> <code>int</code> <p>Maximum context length</p> required <code>args</code> <code>Dict</code> <p>Additional arguments (not used in this implementation)</p> required <p>Attributes:</p> Name Type Description <code>pe</code> <code>Tensor</code> <p>Positional encoding tensor</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>class PositionalEncoding(nn.Module):\n    \"\"\"\n    Positional Encoding module for Transformer models.\n\n    Parameters\n    ----------\n    in_dim : int\n        Input dimension of the model\n    max_context_len : int\n        Maximum context length\n    args : Dict\n        Additional arguments (not used in this implementation)\n\n    Attributes\n    ----------\n    pe : torch.Tensor\n        Positional encoding tensor\n    \"\"\"\n\n    def __init__(self, in_dim: int, max_context_len: int, args: Dict):\n        super().__init__()\n        pe = torch.zeros(max_context_len, in_dim)\n        position = torch.arange(0, max_context_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, in_dim, 2).float() * (-np.log(1e4) / in_dim)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)  # t x 1 x d\n        self.register_buffer(\"pe\", pe)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Add positional encoding to the input tensor.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor of shape (seq_len, batch_size, in_dim)\n\n        Returns\n        -------\n        torch.Tensor\n            Input tensor with added positional encoding\n        \"\"\"\n        self.pe = self.pe.to(x.device)\n        x = x + self.pe[: x.size(0), :]  # t x 1 x d, # t x b x d\n        return x\n</code></pre>"},{"location":"reference/neuro_py/ensemble/decoding/transformer/#neuro_py.ensemble.decoding.transformer.PositionalEncoding.forward","title":"<code>forward(x)</code>","text":"<p>Add positional encoding to the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (seq_len, batch_size, in_dim)</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Input tensor with added positional encoding</p> Source code in <code>neuro_py/ensemble/decoding/transformer.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Add positional encoding to the input tensor.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor of shape (seq_len, batch_size, in_dim)\n\n    Returns\n    -------\n    torch.Tensor\n        Input tensor with added positional encoding\n    \"\"\"\n    self.pe = self.pe.to(x.device)\n    x = x + self.pe[: x.size(0), :]  # t x 1 x d, # t x b x d\n    return x\n</code></pre>"},{"location":"reference/neuro_py/io/","title":"neuro_py.io","text":""},{"location":"reference/neuro_py/io/#neuro_py.io.LFPLoader","title":"<code>LFPLoader</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple class to load LFP or wideband data from a recording folder.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the recording folder.</p> required <code>channels</code> <code>Union[int, list, None]</code> <p>Channel number or list of channel numbers, by default None (load all channels memmap).</p> <code>None</code> <code>ext</code> <code>str</code> <p>File extension, by default \"lfp\".</p> <code>'lfp'</code> <code>epoch</code> <code>Union[ndarray, EpochArray, None]</code> <p>Epoch array or ndarray, by default None (load all data).</p> <code>None</code> <p>Returns:</p> Type Description <code>AnalogSignalArray</code> <p>Analog signal array of shape (n_channels, n_samples).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # load lfp file\n&gt;&gt;&gt; basepath = r\"X:/data/Barrage/NN10/day10\"\n&gt;&gt;&gt; lfp = loading.LFPLoader(basepath,ext=\"lfp\")\n&gt;&gt;&gt; lfp\n    &lt;AnalogSignalArray at 0x25ba1576640: 128 signals&gt; for a total of 5:33:58:789 hours\n</code></pre> <pre><code>&gt;&gt;&gt; # Loading dat file\n&gt;&gt;&gt; dat = loading.LFPLoader(basepath,ext=\"dat\")\n&gt;&gt;&gt; dat\n    &lt;AnalogSignalArray at 0x25ba4fedc40: 128 signals&gt; for a total of 5:33:58:790 hours\n&gt;&gt;&gt; dat.lfp.data.shape\n    (128, 400775808)\n&gt;&gt;&gt; type(dat.lfp.data)\n    numpy.memmap\n</code></pre> Source code in <code>neuro_py/io/loading.py</code> <pre><code>class LFPLoader(object):\n    \"\"\"\n    Simple class to load LFP or wideband data from a recording folder.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the recording folder.\n    channels : Union[int, list, None], optional\n        Channel number or list of channel numbers, by default None (load all channels memmap).\n    ext : str, optional\n        File extension, by default \"lfp\".\n    epoch : Union[np.ndarray, nel.EpochArray, None], optional\n        Epoch array or ndarray, by default None (load all data).\n\n    Returns\n    -------\n    nelpy.AnalogSignalArray\n        Analog signal array of shape (n_channels, n_samples).\n\n    Examples\n    --------\n    &gt;&gt;&gt; # load lfp file\n    &gt;&gt;&gt; basepath = r\"X:/data/Barrage/NN10/day10\"\n    &gt;&gt;&gt; lfp = loading.LFPLoader(basepath,ext=\"lfp\")\n    &gt;&gt;&gt; lfp\n        &lt;AnalogSignalArray at 0x25ba1576640: 128 signals&gt; for a total of 5:33:58:789 hours\n\n    &gt;&gt;&gt; # Loading dat file\n    &gt;&gt;&gt; dat = loading.LFPLoader(basepath,ext=\"dat\")\n    &gt;&gt;&gt; dat\n        &lt;AnalogSignalArray at 0x25ba4fedc40: 128 signals&gt; for a total of 5:33:58:790 hours\n    &gt;&gt;&gt; dat.lfp.data.shape\n        (128, 400775808)\n    &gt;&gt;&gt; type(dat.lfp.data)\n        numpy.memmap\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: str,\n        channels: Union[int, list, None] = None,\n        ext: str = \"lfp\",\n        epoch: Union[np.ndarray, nel.EpochArray, None] = None,\n    ) -&gt; None:\n        self.basepath = basepath  # path to the recording folder\n        self.channels = channels  # channel number or list of channel numbers\n        self.ext = ext  # lfp or dat\n        self.epoch = epoch\n\n        # get xml data\n        self.get_xml_data()\n\n        # set sampling rate based on the extension of the file (lfp or dat)\n        if self.ext == \"dat\":\n            self.fs = self.fs_dat\n\n        # load lfp\n        self.load_lfp()\n\n    def get_xml_data(self) -&gt; None:\n        nChannels, fs, fs_dat, shank_to_channel = loadXML(self.basepath)\n        self.nChannels = nChannels\n        self.fs = fs\n        self.fs_dat = fs_dat\n        self.shank_to_channel = shank_to_channel\n\n    def load_lfp(self) -&gt; None:\n        lfp, timestep = loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            channel=self.channels,\n            frequency=self.fs,\n            ext=self.ext,\n        )\n\n        if isinstance(self.epoch, nel.EpochArray):\n            intervals = self.epoch.data\n        elif isinstance(self.epoch, np.ndarray):\n            intervals = self.epoch\n            if intervals.ndim == 1:\n                intervals = intervals[np.newaxis, :]\n        else:\n            intervals = np.array([0, timestep.shape[0] / self.fs])[np.newaxis, :]\n\n        idx = in_intervals(timestep, intervals)\n\n        # if loading all, don't index as to preserve memmap\n        if idx.all():\n            self.lfp = nel.AnalogSignalArray(\n                data=lfp.T,\n                timestamps=timestep,\n                fs=self.fs,\n                support=nel.EpochArray(intervals),\n            )\n        else:\n            self.lfp = nel.AnalogSignalArray(\n                data=lfp[idx, None].T,\n                timestamps=timestep[idx],\n                fs=self.fs,\n                support=nel.EpochArray(\n                    np.array([min(timestep[idx]), max(timestep[idx])])\n                ),\n            )\n\n    def __repr__(self) -&gt; None:\n        return self.lfp.__repr__()\n\n    def get_phase(self, band2filter: list = [6, 12], ford: int = 3) -&gt; np.ndarray:\n        \"\"\"\n        Get the phase of the LFP signal using a bandpass filter and Hilbert transform.\n\n        Parameters\n        ----------\n        band2filter : list, optional\n            The frequency band to filter, by default [6, 12].\n        ford : int, optional\n            The order of the Butterworth filter, by default 3.\n\n        Returns\n        -------\n        np.ndarray\n            The phase of the LFP signal.\n        \"\"\"\n        band2filter = np.array(band2filter, dtype=float)\n        b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n        filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n        return np.angle(signal.hilbert(filt_sig))\n\n    def get_freq_phase_amp(\n        self, band2filter: list = [6, 12], ford: int = 3, kernel_size: int = 13\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.\n\n        Parameters\n        ----------\n        band2filter : list, optional\n            The frequency band to filter, by default [6, 12].\n        ford : int, optional\n            The order of the Butterworth filter, by default 3.\n        kernel_size : int, optional\n            The kernel size for the median filter, by default 13.\n\n        Returns\n        -------\n        filt_sig : np.ndarray\n            The filtered signal.\n        phase : np.ndarray\n            The phase of the LFP signal.\n        amplitude : np.ndarray\n            The amplitude of the LFP signal.\n        amplitude_filtered : np.ndarray\n            The filtered amplitude of the LFP signal.\n        frequency : np.ndarray\n            The instantaneous frequency of the LFP signal.\n        \"\"\"\n\n        band2filter = np.array(band2filter, dtype=float)\n\n        b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n\n        filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n        phase = np.angle(signal.hilbert(filt_sig))\n        amplitude = np.abs(signal.hilbert(filt_sig))\n        amplitude_filtered = signal.filtfilt(b, a, amplitude, padtype=\"odd\")\n\n        # calculate the frequency\n        # median filter to smooth the unwrapped phase (this is to avoid jumps in the frequency)\n        filtered_signal = signal.medfilt2d(\n            np.unwrap(phase), kernel_size=[1, kernel_size]\n        )\n\n        # Calculate the derivative of the unwrapped phase to get frequency\n        dt = np.diff(self.lfp.abscissa_vals)\n        if np.allclose(dt, dt[0]):  # Check if sampling is uniform\n            dt = dt[0]  # Use a single scalar for uniform sampling\n        else:\n            dt = np.hstack((dt[0], dt))  # Use an array for non-uniform sampling\n        derivative = np.gradient(filtered_signal, dt, axis=-1)\n        frequency = derivative / (2 * np.pi)\n\n        return filt_sig, phase, amplitude, amplitude_filtered, frequency\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.LFPLoader.get_freq_phase_amp","title":"<code>get_freq_phase_amp(band2filter=[6, 12], ford=3, kernel_size=13)</code>","text":"<p>Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.</p> <p>Parameters:</p> Name Type Description Default <code>band2filter</code> <code>list</code> <p>The frequency band to filter, by default [6, 12].</p> <code>[6, 12]</code> <code>ford</code> <code>int</code> <p>The order of the Butterworth filter, by default 3.</p> <code>3</code> <code>kernel_size</code> <code>int</code> <p>The kernel size for the median filter, by default 13.</p> <code>13</code> <p>Returns:</p> Name Type Description <code>filt_sig</code> <code>ndarray</code> <p>The filtered signal.</p> <code>phase</code> <code>ndarray</code> <p>The phase of the LFP signal.</p> <code>amplitude</code> <code>ndarray</code> <p>The amplitude of the LFP signal.</p> <code>amplitude_filtered</code> <code>ndarray</code> <p>The filtered amplitude of the LFP signal.</p> <code>frequency</code> <code>ndarray</code> <p>The instantaneous frequency of the LFP signal.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_freq_phase_amp(\n    self, band2filter: list = [6, 12], ford: int = 3, kernel_size: int = 13\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.\n\n    Parameters\n    ----------\n    band2filter : list, optional\n        The frequency band to filter, by default [6, 12].\n    ford : int, optional\n        The order of the Butterworth filter, by default 3.\n    kernel_size : int, optional\n        The kernel size for the median filter, by default 13.\n\n    Returns\n    -------\n    filt_sig : np.ndarray\n        The filtered signal.\n    phase : np.ndarray\n        The phase of the LFP signal.\n    amplitude : np.ndarray\n        The amplitude of the LFP signal.\n    amplitude_filtered : np.ndarray\n        The filtered amplitude of the LFP signal.\n    frequency : np.ndarray\n        The instantaneous frequency of the LFP signal.\n    \"\"\"\n\n    band2filter = np.array(band2filter, dtype=float)\n\n    b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n\n    filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n    phase = np.angle(signal.hilbert(filt_sig))\n    amplitude = np.abs(signal.hilbert(filt_sig))\n    amplitude_filtered = signal.filtfilt(b, a, amplitude, padtype=\"odd\")\n\n    # calculate the frequency\n    # median filter to smooth the unwrapped phase (this is to avoid jumps in the frequency)\n    filtered_signal = signal.medfilt2d(\n        np.unwrap(phase), kernel_size=[1, kernel_size]\n    )\n\n    # Calculate the derivative of the unwrapped phase to get frequency\n    dt = np.diff(self.lfp.abscissa_vals)\n    if np.allclose(dt, dt[0]):  # Check if sampling is uniform\n        dt = dt[0]  # Use a single scalar for uniform sampling\n    else:\n        dt = np.hstack((dt[0], dt))  # Use an array for non-uniform sampling\n    derivative = np.gradient(filtered_signal, dt, axis=-1)\n    frequency = derivative / (2 * np.pi)\n\n    return filt_sig, phase, amplitude, amplitude_filtered, frequency\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.LFPLoader.get_phase","title":"<code>get_phase(band2filter=[6, 12], ford=3)</code>","text":"<p>Get the phase of the LFP signal using a bandpass filter and Hilbert transform.</p> <p>Parameters:</p> Name Type Description Default <code>band2filter</code> <code>list</code> <p>The frequency band to filter, by default [6, 12].</p> <code>[6, 12]</code> <code>ford</code> <code>int</code> <p>The order of the Butterworth filter, by default 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The phase of the LFP signal.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_phase(self, band2filter: list = [6, 12], ford: int = 3) -&gt; np.ndarray:\n    \"\"\"\n    Get the phase of the LFP signal using a bandpass filter and Hilbert transform.\n\n    Parameters\n    ----------\n    band2filter : list, optional\n        The frequency band to filter, by default [6, 12].\n    ford : int, optional\n        The order of the Butterworth filter, by default 3.\n\n    Returns\n    -------\n    np.ndarray\n        The phase of the LFP signal.\n    \"\"\"\n    band2filter = np.array(band2filter, dtype=float)\n    b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n    filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n    return np.angle(signal.hilbert(filt_sig))\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.add_animal_id","title":"<code>add_animal_id(df)</code>","text":"<p>Add animal_id column to a dataframe based on the basepath column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe with a basepath column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Dataframe with an additional animal_id column.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def add_animal_id(df: pd.core.frame.DataFrame) -&gt; pd.core.frame.DataFrame:\n    \"\"\"\n    Add animal_id column to a dataframe based on the basepath column.\n\n    Parameters\n    ----------\n    df : pd.core.frame.DataFrame\n        Dataframe with a basepath column.\n\n    Returns\n    -------\n    pd.core.frame.DataFrame\n        Dataframe with an additional animal_id column.\n    \"\"\"\n    df[\"animal_id\"] = df.basepath.map(\n        dict([(basepath, get_animal_id(basepath)) for basepath in df.basepath.unique()])\n    )\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.epoch_to_mat","title":"<code>epoch_to_mat(epoch, basepath, epoch_name, detection_name=None)</code>","text":"<p>Save an EpochArray to a .mat file in the Cell Explorer format.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>EpochArray to save.</p> required <code>basepath</code> <code>str</code> <p>Basepath to save the file to.</p> required <code>epoch_name</code> <code>str</code> <p>Name of the epoch.</p> required <code>detection_name</code> <code>Union[None, str]</code> <p>Name of the detection, by default None.</p> <code>None</code> Source code in <code>neuro_py/io/saving.py</code> <pre><code>def epoch_to_mat(\n    epoch: nel.EpochArray,\n    basepath: str,\n    epoch_name: str,\n    detection_name: Union[None, str] = None,\n) -&gt; None:\n    \"\"\"\n    Save an EpochArray to a .mat file in the Cell Explorer format.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        EpochArray to save.\n    basepath : str\n        Basepath to save the file to.\n    epoch_name : str\n        Name of the epoch.\n    detection_name : Union[None, str], optional\n        Name of the detection, by default None.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + epoch_name + \".events.mat\"\n    )\n    data = {}\n    data[epoch_name] = {}\n\n    data[epoch_name][\"timestamps\"] = epoch.data\n\n    # check if only single epoch\n    if epoch.data.ndim == 1:\n        data[epoch_name][\"peaks\"] = np.median(epoch.data, axis=0)\n    else:\n        data[epoch_name][\"peaks\"] = np.median(epoch.data, axis=1)\n\n    data[epoch_name][\"amplitudes\"] = []\n    data[epoch_name][\"amplitudeUnits\"] = []\n    data[epoch_name][\"eventID\"] = []\n    data[epoch_name][\"eventIDlabels\"] = []\n    data[epoch_name][\"eventIDbinary\"] = []\n\n    # check if only single epoch\n    if epoch.data.ndim == 1:\n        data[epoch_name][\"duration\"] = epoch.data[1] - epoch.data[0]\n    else:\n        data[epoch_name][\"duration\"] = epoch.durations\n\n    data[epoch_name][\"center\"] = data[epoch_name][\"peaks\"]\n    data[epoch_name][\"detectorinfo\"] = {}\n    if detection_name is None:\n        data[epoch_name][\"detectorinfo\"][\"detectorname\"] = []\n    else:\n        data[epoch_name][\"detectorinfo\"][\"detectorname\"] = detection_name\n    data[epoch_name][\"detectorinfo\"][\"detectionparms\"] = []\n    data[epoch_name][\"detectorinfo\"][\"detectionintervals\"] = []\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.get_animal_id","title":"<code>get_animal_id(basepath)</code>","text":"<p>Return animal ID from basepath using basename.session.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to session folder.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Animal ID.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_animal_id(basepath: str) -&gt; str:\n    \"\"\"\n    Return animal ID from basepath using basename.session.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to session folder.\n\n    Returns\n    -------\n    str\n        Animal ID.\n    \"\"\"\n    try:\n        filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename)\n    return data[\"session\"][0][0][\"animal\"][0][0][\"name\"][0]\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.loadLFP","title":"<code>loadLFP(basepath, n_channels=90, channel=None, frequency=1250.0, precision='int16', ext='lfp', filename=None)</code>","text":"<p>Load LFP data from a specified file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the LFP file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels, by default 90.</p> <code>90</code> <code>channel</code> <code>Optional[Union[int, list]]</code> <p>Specific channel(s) to load, by default None.</p> <code>None</code> <code>frequency</code> <code>float</code> <p>Sampling frequency, by default 1250.0.</p> <code>1250.0</code> <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>ext</code> <code>str</code> <p>File extension, by default \"lfp\".</p> <code>'lfp'</code> <code>filename</code> <code>Optional[str]</code> <p>Name of the file to load, located in basepath, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Tuple[ndarray, ndarray]]</code> <p>Data and corresponding timestamps.</p> Notes <p>If both .lfp and .eeg files are present, .lfp file is prioritized. If neither are present, returns None.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def loadLFP(\n    basepath: str,\n    n_channels: int = 90,\n    channel: Union[int, None] = None,\n    frequency: float = 1250.0,\n    precision: str = \"int16\",\n    ext: str = \"lfp\",\n    filename: str = None,  # name of file to load, located in basepath\n):\n    \"\"\"\n    Load LFP data from a specified file.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the LFP file.\n    n_channels : int, optional\n        Number of channels, by default 90.\n    channel : Optional[Union[int, list]], optional\n        Specific channel(s) to load, by default None.\n    frequency : float, optional\n        Sampling frequency, by default 1250.0.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    ext : str, optional\n        File extension, by default \"lfp\".\n    filename : Optional[str], optional\n        Name of the file to load, located in basepath, by default None.\n\n    Returns\n    -------\n    Optional[Tuple[np.ndarray, np.ndarray]]\n        Data and corresponding timestamps.\n\n    Notes\n    -----\n    If both .lfp and .eeg files are present, .lfp file is prioritized.\n    If neither are present, returns None.\n    \"\"\"\n    if filename is not None:\n        path = os.path.join(basepath, filename)\n    else:\n        path = \"\"\n        if ext == \"lfp\":\n            path = os.path.join(basepath, os.path.basename(basepath) + \".lfp\")\n            if not os.path.exists(path):\n                path = os.path.join(basepath, os.path.basename(basepath) + \".eeg\")\n        if ext == \"dat\":\n            path = os.path.join(basepath, os.path.basename(basepath) + \".dat\")\n\n    # check if saved file exists\n    if not os.path.exists(path):\n        warnings.warn(\"file does not exist\")\n        return\n    if channel is None:\n        n_channels = int(n_channels)\n\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        data = np.memmap(path, np.int16, \"r\", shape=(n_samples, n_channels))\n        timestep = np.arange(0, n_samples) / frequency\n        return data, timestep\n\n    if type(channel) is not list:\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        with open(path, \"rb\") as f:\n            data = np.fromfile(f, np.int16).reshape((n_samples, n_channels))[:, channel]\n            timestep = np.arange(0, len(data)) / frequency\n            # check if lfp time stamps exist\n            lfp_ts_path = os.path.join(\n                os.path.dirname(os.path.abspath(path)), \"lfp_ts.npy\"\n            )\n            if os.path.exists(lfp_ts_path):\n                timestep = np.load(lfp_ts_path).reshape(-1)\n\n            return data, timestep\n\n    elif type(channel) is list:\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        with open(path, \"rb\") as f:\n            data = np.fromfile(f, np.int16).reshape((n_samples, n_channels))[:, channel]\n            timestep = np.arange(0, len(data)) / frequency\n            # check if lfp time stamps exist\n            lfp_ts_path = os.path.join(\n                os.path.dirname(os.path.abspath(path)), \"lfp_ts.npy\"\n            )\n            if os.path.exists(lfp_ts_path):\n                timestep = np.load(lfp_ts_path).reshape(-1)\n            return data, timestep\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.loadXML","title":"<code>loadXML(basepath)</code>","text":"<p>Load XML file and extract relevant information.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder session containing the XML file.</p> required <p>Returns:</p> Type Description <code>Union[Tuple[int, int, int, Dict[int, list]], None]</code> <p>A tuple containing: - The number of channels (int) - The sampling frequency of the dat file (int) - The sampling frequency of the eeg file (int) - The mappings shanks to channels as a dict (Dict[int, list])</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def loadXML(basepath: str) -&gt; Union[Tuple[int, int, int, Dict[int, list]], None]:\n    \"\"\"\n    Load XML file and extract relevant information.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder session containing the XML file.\n\n    Returns\n    -------\n    Union[Tuple[int, int, int, Dict[int, list]], None]\n        A tuple containing:\n        - The number of channels (int)\n        - The sampling frequency of the dat file (int)\n        - The sampling frequency of the eeg file (int)\n        - The mappings shanks to channels as a dict (Dict[int, list])\n    \"\"\"\n    # check if saved file exists\n    try:\n        basename = os.path.basename(basepath)\n        filename = glob.glob(os.path.join(basepath, basename + \".xml\"))[0]\n    except Exception:\n        warnings.warn(\"xml file does not exist\")\n        return\n\n    xmldoc = minidom.parse(filename)\n    nChannels = (\n        xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n        .getElementsByTagName(\"nChannels\")[0]\n        .firstChild.data\n    )\n    fs_dat = (\n        xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n        .getElementsByTagName(\"samplingRate\")[0]\n        .firstChild.data\n    )\n    fs = (\n        xmldoc.getElementsByTagName(\"fieldPotentials\")[0]\n        .getElementsByTagName(\"lfpSamplingRate\")[0]\n        .firstChild.data\n    )\n\n    shank_to_channel = {}\n    groups = (\n        xmldoc.getElementsByTagName(\"anatomicalDescription\")[0]\n        .getElementsByTagName(\"channelGroups\")[0]\n        .getElementsByTagName(\"group\")\n    )\n    for i in range(len(groups)):\n        shank_to_channel[i] = [\n            int(child.firstChild.data)\n            for child in groups[i].getElementsByTagName(\"channel\")\n        ]\n    return int(nChannels), int(fs), int(fs_dat), shank_to_channel\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_SWRunitMetrics","title":"<code>load_SWRunitMetrics(basepath)</code>","text":"<p>Load SWRunitMetrics.mat into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the SWRunitMetrics.mat file.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - particip: the probability of participation into ripples for each unit - FRall: mean firing rate during ripples - FRparticip: mean firing rate for ripples with at least 1 spike - nSpkAll: mean number of spikes in all ripples - nSpkParticip: mean number of spikes in ripples with at least 1 spike - epoch: behavioral epoch label</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_SWRunitMetrics(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load SWRunitMetrics.mat into a pandas DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the SWRunitMetrics.mat file.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - particip: the probability of participation into ripples for each unit\n        - FRall: mean firing rate during ripples\n        - FRparticip: mean firing rate for ripples with at least 1 spike\n        - nSpkAll: mean number of spikes in all ripples\n        - nSpkParticip: mean number of spikes in ripples with at least 1 spike\n        - epoch: behavioral epoch label\n    \"\"\"\n\n    def extract_swr_epoch_data(data, epoch):\n        # get var names\n        dt = data[\"SWRunitMetrics\"][epoch][0][0].dtype\n\n        df2 = pd.DataFrame()\n\n        # get n units\n        # there might be other fields within here like the epoch timestamps\n        # skip those by returning empty df\n        try:\n            n_cells = data[\"SWRunitMetrics\"][epoch][0][0][0][\"particip\"][0].shape[0]\n        except Exception:\n            return df2\n\n        for dn in dt.names:\n            if (data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].shape[1] == 1) &amp; (\n                data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].shape[0] == n_cells\n            ):\n                df2[dn] = data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].T[0]\n        df2[\"epoch\"] = epoch\n        return df2\n\n    try:\n        filename = glob.glob(os.path.join(basepath, \"*.SWRunitMetrics.mat\"))[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename)\n\n    df2 = pd.DataFrame()\n    # loop through each available epoch and pull out contents\n    for epoch in data[\"SWRunitMetrics\"].dtype.names:\n        if data[\"SWRunitMetrics\"][epoch][0][0].size &gt; 0:  # not empty\n            # call content extractor\n            df_ = extract_swr_epoch_data(data, epoch)\n\n            # append conents to overall data frame\n            if df_.size &gt; 0:\n                df2 = pd.concat([df2, df_], ignore_index=True)\n\n    return df2\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_SleepState_states","title":"<code>load_SleepState_states(basepath, return_epoch_array=False, states_list=['WAKEstate', 'NREMstate', 'REMstate', 'THETA', 'nonTHETA'])</code>","text":"<p>Loader of SleepState.states.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the SleepState.states.mat file.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, return an dict of EpochArrays, by default False.</p> <code>False</code> <code>states_list</code> <code>list</code> <p>List of states to load, by default [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"].</p> <code>['WAKEstate', 'NREMstate', 'REMstate', 'THETA', 'nonTHETA']</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the contents of the SleepState.states.mat file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_SleepState_states(\n    basepath: str,\n    return_epoch_array: bool = False,\n    states_list: list = [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"],\n) -&gt; dict:\n    \"\"\"\n    Loader of SleepState.states.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the SleepState.states.mat file.\n    return_epoch_array : bool, optional\n        If True, return an dict of EpochArrays, by default False.\n    states_list : list, optional\n        List of states to load, by default [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"].\n\n    Returns\n    -------\n    dict\n        Dictionary containing the contents of the SleepState.states.mat file.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".SleepState.states.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return None\n\n    # load cell_metrics file\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # get epoch id\n    statenames = data[\"SleepState\"][\"idx\"][\"statenames\"]\n    statenames_cleaned = np.array([x if isinstance(x, str) else \"\" for x in statenames])\n    try:\n        wake_id = np.where(statenames_cleaned == \"WAKE\")[0][0] + 1\n    except IndexError:\n        wake_id = None\n    try:\n        rem_id = np.where(statenames_cleaned == \"REM\")[0][0] + 1\n    except IndexError:\n        rem_id = None\n    try:\n        nrem_id = np.where(statenames_cleaned == \"NREM\")[0][0] + 1\n    except IndexError:\n        nrem_id = None\n\n    # get states and timestamps vectors\n    states = data[\"SleepState\"][\"idx\"][\"states\"]\n    timestamps = data[\"SleepState\"][\"idx\"][\"timestamps\"]\n\n    # set up dict\n    dict_ = {\n        \"wake_id\": wake_id,\n        \"rem_id\": rem_id,\n        \"nrem_id\": nrem_id,\n        \"states\": states,\n        \"timestamps\": timestamps,\n    }\n\n    # iter through states and add to dict\n    dt = data[\"SleepState\"][\"ints\"]\n    for dn in dt.keys():\n        dict_[dn] = data[\"SleepState\"][\"ints\"][dn]\n\n    if not return_epoch_array:\n        return dict_\n    else:\n        epoch_df = load_epoch(basepath)\n        # get session bounds to provide support\n        session_domain = nel.EpochArray(\n            [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n        )\n        states_dict = {}\n        for state in states_list:\n            states_dict[state] = nel.EpochArray(\n                dict_.get(state, []), domain=session_domain\n            )\n        return states_dict\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_all_cell_metrics","title":"<code>load_all_cell_metrics(basepaths)</code>","text":"<p>Load cell metrics from multiple sessions.</p> <p>Parameters:</p> Name Type Description Default <code>basepaths</code> <code>List[str]</code> <p>List of basepaths, can be a pandas column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated pandas DataFrame with metrics.</p> Notes <p>To get waveforms, spike times, etc., use load_cell_metrics.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_all_cell_metrics(basepaths: List[str]) -&gt; pd.DataFrame:\n    \"\"\"\n    Load cell metrics from multiple sessions.\n\n    Parameters\n    ----------\n    basepaths : List[str]\n        List of basepaths, can be a pandas column.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated pandas DataFrame with metrics.\n\n    Notes\n    -----\n    To get waveforms, spike times, etc., use load_cell_metrics.\n    \"\"\"\n\n    # to speed up, use parallel\n    num_cores = multiprocessing.cpu_count()\n    cell_metrics = Parallel(n_jobs=num_cores)(\n        delayed(load_cell_metrics)(basepath, True) for basepath in basepaths\n    )\n\n    return pd.concat(cell_metrics, ignore_index=True)\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_animal_behavior","title":"<code>load_animal_behavior(basepath, alternative_file=None)</code>","text":"<p>load_animal_behavior loads basename.animal.behavior.mat files created by general_behavior_file.m The output is a pandas data frame with [time,x,y,z,linearized,speed,acceleration,trials,epochs]</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>alternative_file</code> <code>Union[str, None]</code> <p>Alternative file name to load, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - time: timestamps - x: x-coordinate - y: y-coordinate - z: z-coordinate - linearized: linearized position - speed: speed of the animal - acceleration: acceleration of the animal - trials: trial numbers - epochs: epoch names - environment: environment names</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_animal_behavior(\n    basepath: str, alternative_file: Union[str, None] = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    load_animal_behavior loads basename.animal.behavior.mat files created by general_behavior_file.m\n    The output is a pandas data frame with [time,x,y,z,linearized,speed,acceleration,trials,epochs]\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    alternative_file : Union[str, None], optional\n        Alternative file name to load, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - time: timestamps\n        - x: x-coordinate\n        - y: y-coordinate\n        - z: z-coordinate\n        - linearized: linearized position\n        - speed: speed of the animal\n        - acceleration: acceleration of the animal\n        - trials: trial numbers\n        - epochs: epoch names\n        - environment: environment names\n    \"\"\"\n    df = pd.DataFrame()\n\n    if alternative_file is None:\n        try:\n            filename = glob.glob(os.path.join(basepath, \"*.animal.behavior.mat\"))[0]\n        except Exception:\n            warnings.warn(\"file does not exist\")\n            return df\n    else:\n        try:\n            filename = glob.glob(\n                os.path.join(basepath, \"*\" + alternative_file + \".mat\")\n            )[0]\n        except Exception:\n            warnings.warn(\"file does not exist\")\n            return df\n\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    def _assign_column(col_name: str, values) -&gt; None:\n        if col_name in df.columns:\n            raise ValueError(\n                f\"Column '{col_name}' already exists in behavior dataframe; refusing to overwrite.\"\n            )\n        df[col_name] = values\n\n    # add timestamps first which provide the correct shape of df\n    # here, I'm naming them time, but this should be deprecated\n    _assign_column(\"time\", data[\"behavior\"][\"timestamps\"])\n\n    # add all other position coordinates to df (will add everything it can within position)\n    if \"position\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"position\"], dict\n    ):\n        for key in data[\"behavior\"][\"position\"].keys():\n            values = data[\"behavior\"][\"position\"][key]\n            # Skip empty arrays and non-array values (e.g., nested dicts)\n            if isinstance(values, dict):\n                continue\n            if isinstance(values, (list, np.ndarray)) and len(values) == 0:\n                continue\n            _assign_column(key, values)\n\n    # handle SpatialSeries containers (position/pupil/orientation, etc.)\n    if \"SpatialSeries\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"SpatialSeries\"], dict\n    ):\n        spatial_series = data[\"behavior\"][\"SpatialSeries\"]\n        for series_name, series in spatial_series.items():\n            if not isinstance(series, dict):\n                continue\n            for key, values in series.items():\n                if key in {\"units\", \"resolution\", \"referenceFrame\", \"coordinateSystem\"}:\n                    continue\n                if isinstance(values, dict):\n                    continue\n                if isinstance(values, (list, np.ndarray)):\n                    arr = np.asarray(values)\n                    if arr.ndim &gt; 1:\n                        continue\n                    if arr.ndim == 1 and len(arr) != len(df):\n                        continue\n                if series_name == \"position\":\n                    _assign_column(key, values)\n                else:\n                    _assign_column(f\"{series_name}_{key}\", values)\n\n    # add other fields from behavior to df (acceleration,speed,states)\n    for key in data[\"behavior\"].keys():\n        if key in {\"position\", \"SpatialSeries\", \"timeSeries\", \"trials\"}:\n            continue\n        values = data[\"behavior\"][key]\n        if isinstance(values, dict):\n            continue\n        if isinstance(values, (list, np.ndarray)):\n            arr = np.asarray(values)\n            if arr.ndim &gt; 1:\n                continue\n            if arr.ndim == 1 and len(arr) != len(df):\n                continue\n        _assign_column(key, values)\n\n    # add speed and acceleration (only if we have x and y coordinates and enough samples)\n    if (\n        \"speed\" not in df.columns\n        and \"x\" in df.columns\n        and \"y\" in df.columns\n        and len(df) &gt; 1\n    ):\n        _assign_column(\"speed\", get_speed(df[[\"x\", \"y\"]].values, df.time.values))\n    if (\n        \"acceleration\" not in df.columns and \"speed\" in df.columns and len(df) &gt; 1\n    ):  # using backward difference\n        acc = np.zeros(len(df))\n        acc[1:] = np.diff(df[\"speed\"]) / np.diff(df[\"time\"])\n        _assign_column(\"acceleration\", acc)\n\n    if \"trials\" in data[\"behavior\"]:\n        trials = data[\"behavior\"][\"trials\"]\n        # If trials is a struct/dict, support common fields\n        if isinstance(trials, dict):\n            if \"trials\" in trials and isinstance(trials[\"trials\"], (list, np.ndarray)):\n                arr = np.asarray(trials[\"trials\"])\n                if arr.ndim == 1 and len(arr) == len(df):\n                    _assign_column(\"trials\", arr)\n            elif {\n                \"start\",\n                \"stop\",\n            }.issubset(trials.keys()) or {\"starts\", \"stops\"}.issubset(trials.keys()):\n                starts = trials.get(\"start\", trials.get(\"starts\"))\n                stops = trials.get(\"stop\", trials.get(\"stops\"))\n                try:\n                    starts = np.asarray(starts).astype(float)\n                    stops = np.asarray(stops).astype(float)\n                    if len(df) &gt; 0:\n                        trial_col = np.full(len(df), np.nan)\n                        for t in range(len(starts)):\n                            idx = (df.time &gt;= starts[t]) &amp; (df.time &lt;= stops[t])\n                            trial_col[idx] = t\n                        _assign_column(\"trials\", trial_col)\n                except Exception:\n                    # Trials metadata can be malformed or inconsistent across sources; skip silently.\n                    pass\n        else:\n            try:\n                if len(df) &gt; 0:\n                    trial_col = np.full(len(df), np.nan)\n                    for t in range(trials.shape[0]):\n                        idx = (df.time &gt;= trials[t, 0]) &amp; (df.time &lt;= trials[t, 1])\n                        trial_col[idx] = t\n                    _assign_column(\"trials\", trial_col)\n            except Exception:\n                # Trials arrays may be ragged or have unexpected shapes; skip silently.\n                pass\n\n    # add timeSeries entries when present\n    if \"timeSeries\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"timeSeries\"], dict\n    ):\n        for key, values in data[\"behavior\"][\"timeSeries\"].items():\n            if isinstance(values, dict):\n                continue\n            if isinstance(values, (list, np.ndarray)):\n                arr = np.asarray(values)\n                if arr.ndim &gt; 1:\n                    continue\n                if arr.ndim == 1 and len(arr) != len(df):\n                    continue\n            _assign_column(f\"timeSeries_{key}\", values)\n\n    # Initialize epoch columns with object dtype to hold strings\n    if \"epochs\" in df.columns or \"environment\" in df.columns:\n        raise ValueError(\"Column overwrite detected for 'epochs' or 'environment'.\")\n    _assign_column(\"epochs\", pd.Series([None] * len(df), dtype=object))\n    _assign_column(\"environment\", pd.Series([None] * len(df), dtype=object))\n\n    # Only process epochs if df is not empty\n    if len(df) &gt; 0:\n        epochs = load_epoch(basepath)\n        for t in range(epochs.shape[0]):\n            idx = (df.time &gt;= epochs.startTime.iloc[t]) &amp; (\n                df.time &lt;= epochs.stopTime.iloc[t]\n            )\n            if idx.any():\n                df.loc[idx, \"epochs\"] = epochs.name.iloc[t]\n                df.loc[idx, \"environment\"] = epochs.environment.iloc[t]\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_barrage_events","title":"<code>load_barrage_events(basepath, return_epoch_array=False, restrict_to_nrem=True, min_duration=0.0)</code>","text":"<p>Load barrage events from the .HSEn2.events.mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Basepath to the session folder.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, return an EpochArray instead of a DataFrame, by default False</p> <code>False</code> <code>restrict_to_nrem</code> <code>bool</code> <p>If True, restrict to NREM sleep, by default True</p> <code>True</code> <code>min_duration</code> <code>float</code> <p>Minimum duration of a barrage, by default 0.0</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with barrage events.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_barrage_events(\n    basepath: str,\n    return_epoch_array: bool = False,\n    restrict_to_nrem: bool = True,\n    min_duration: float = 0.0,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load barrage events from the .HSEn2.events.mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        Basepath to the session folder.\n    return_epoch_array : bool, optional\n        If True, return an EpochArray instead of a DataFrame, by default False\n    restrict_to_nrem : bool, optional\n        If True, restrict to NREM sleep, by default True\n    min_duration : float, optional\n        Minimum duration of a barrage, by default 0.0\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with barrage events.\n    \"\"\"\n\n    # locate barrage file\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".HSEn2.events.mat\")\n\n    # check if file exists\n    if os.path.exists(filename) is False:\n        warnings.warn(\"No barrage file found for {}\".format(basepath))\n        if return_epoch_array:\n            return nel.EpochArray()\n        return pd.DataFrame()\n\n    # load data from file and extract relevant data\n    data = sio.loadmat(filename, simplify_cells=True)\n    data = data[\"HSEn2\"]\n\n    # convert to DataFrame\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"timestamps\"][:, 0]\n    df[\"stop\"] = data[\"timestamps\"][:, 1]\n    df[\"peaks\"] = data[\"peaks\"]\n    df[\"duration\"] = data[\"timestamps\"][:, 1] - data[\"timestamps\"][:, 0]\n\n    # restrict to NREM sleep\n    if restrict_to_nrem:\n        state_dict = load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"]).expand(2)\n        idx = in_intervals(df[\"start\"].values, nrem_epochs.data)\n        df = df[idx].reset_index(drop=True)\n\n    # restrict to barrages with a minimum duration\n    df = df[df.duration &gt; min_duration].reset_index(drop=True)\n\n    # make sure each barrage has some ca2 activity\n    # load ca2 pyr cells\n    st, _ = load_spikes(basepath, putativeCellType=\"Pyr\", brainRegion=\"CA2\")\n    # bin spikes into barrages\n    bst = get_participation(st.data, df[\"start\"].values, df[\"stop\"].values)\n    # keep only barrages with some activity\n    df = df[np.sum(bst &gt; 0, axis=0) &gt; 0].reset_index(drop=True)\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"barrage\")\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_basic_data","title":"<code>load_basic_data(basepath)</code>","text":"<p>Load basic data from the specified basepath.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>Tuple[DataFrame, dict, DataFrame, float]</code> <ul> <li>cell_metrics: DataFrame containing cell metrics.</li> <li>data: Dictionary containing additional data.</li> <li>ripples: DataFrame containing ripple events.</li> <li>fs_dat: Sampling rate of the data.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_basic_data(basepath: str) -&gt; Tuple[pd.DataFrame, dict, pd.DataFrame, float]:\n    \"\"\"\n    Load basic data from the specified basepath.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, dict, pd.DataFrame, float]\n        - cell_metrics: DataFrame containing cell metrics.\n        - data: Dictionary containing additional data.\n        - ripples: DataFrame containing ripple events.\n        - fs_dat: Sampling rate of the data.\n    \"\"\"\n    try:\n        nChannels, fs, fs_dat, shank_to_channel = loadXML(basepath)\n    except Exception:\n        fs_dat = load_extracellular_metadata(basepath).get(\"sr\")\n\n    ripples = load_ripples_events(basepath)\n    cell_metrics, data = load_cell_metrics(basepath)\n\n    return cell_metrics, data, ripples, fs_dat\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_brain_regions","title":"<code>load_brain_regions(basepath, out_format='dict')</code>","text":"<p>Loads brain region info from cell explorer basename.session and stores in dict (default) or DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>out_format</code> <code>str</code> <p>Output format, either 'dict' or 'DataFrame', by default 'dict'.</p> <code>'dict'</code> <p>Returns:</p> Type Description <code>Union[dict, DataFrame]</code> <p>Dictionary or DataFrame with brain region information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; brainRegions = load_brain_regions(\"Z:\\Data\\GirardeauG\\Rat09\\Rat09-20140327\")\n&gt;&gt;&gt; print(brainRegions.keys())\ndict_keys(['CA1', 'Unknown', 'blv', 'bmp', 'ven'])\n&gt;&gt;&gt; print(brainRegions['CA1'].keys())\ndict_keys(['channels', 'electrodeGroups'])\n&gt;&gt;&gt; print(brainRegions['CA1']['channels'])\n[145 146 147 148 149 153 155 157 150 151 154 159 156 152 158 160 137 140\n129 136 138 134 130 132 142 143 144 141 131 139 133 135]\n&gt;&gt;&gt; print(brainRegions['CA1']['electrodeGroups'])\n    [17 18 19 20]\n</code></pre> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_brain_regions(\n    basepath: str, out_format: str = \"dict\"\n) -&gt; Union[dict, pd.DataFrame]:\n    \"\"\"\n    Loads brain region info from cell explorer basename.session and stores in dict (default) or DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    out_format : str, optional\n        Output format, either 'dict' or 'DataFrame', by default 'dict'.\n\n    Returns\n    -------\n    Union[dict, pd.DataFrame]\n        Dictionary or DataFrame with brain region information.\n\n    Examples\n    -------\n    &gt;&gt;&gt; brainRegions = load_brain_regions(\"Z:\\\\Data\\\\GirardeauG\\\\Rat09\\\\Rat09-20140327\")\n    &gt;&gt;&gt; print(brainRegions.keys())\n    dict_keys(['CA1', 'Unknown', 'blv', 'bmp', 'ven'])\n    &gt;&gt;&gt; print(brainRegions['CA1'].keys())\n    dict_keys(['channels', 'electrodeGroups'])\n    &gt;&gt;&gt; print(brainRegions['CA1']['channels'])\n    [145 146 147 148 149 153 155 157 150 151 154 159 156 152 158 160 137 140\n    129 136 138 134 130 132 142 143 144 141 131 139 133 135]\n    &gt;&gt;&gt; print(brainRegions['CA1']['electrodeGroups'])\n        [17 18 19 20]\n    \"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n\n    if not os.path.exists(filename):\n        warnings.warn(f\"file {filename} does not exist\")\n        if out_format == \"DataFrame\":\n            return pd.DataFrame()\n        else:\n            return {}\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    data = data[\"session\"]\n\n    if \"brainRegions\" not in data.keys():\n        warnings.warn(\"brainRegions not found in file\")\n        if out_format == \"DataFrame\":\n            return pd.DataFrame()\n        else:\n            return {}\n\n    brainRegions = {}\n    for region in data[\"brainRegions\"].keys():\n        if len(data[\"brainRegions\"][region]) == 0:\n            continue\n        channels = data[\"brainRegions\"][region][\"channels\"] - 1\n        try:\n            electrodeGroups = data[\"brainRegions\"][region][\"electrodeGroups\"]\n        except Exception:\n            electrodeGroups = np.nan\n\n        brainRegions[region] = {\n            \"channels\": channels,\n            \"electrodeGroups\": electrodeGroups,\n        }\n\n    if out_format == \"DataFrame\":  # return as DataFrame\n        # get channel order from electrodeGroups in session file\n        shank_to_channel = data[\"extracellular\"][\"electrodeGroups\"][\"channels\"] - 1\n\n        # check if nested array for multi shank\n        if is_nested(shank_to_channel) or shank_to_channel.ndim &gt; 1:\n            channels = np.hstack(shank_to_channel)\n            shanks = np.hstack(\n                [\n                    np.repeat(i, len(shank_to_channel[i]))\n                    for i in range(len(shank_to_channel))\n                ]\n            )\n        else:\n            channels = shank_to_channel\n            shanks = np.zeros(len(channels))\n\n        mapped_df = pd.DataFrame(columns=[\"channels\", \"region\"])\n        mapped_df[\"channels\"] = channels\n        mapped_df[\"region\"] = \"Unknown\"\n        mapped_df[\"shank\"] = shanks\n\n        for key in brainRegions.keys():\n            idx = np.isin(channels, brainRegions[key][\"channels\"])\n            mapped_df.loc[idx, \"region\"] = key\n\n        # save channel as zero-indexed\n        mapped_df[\"channels\"] = mapped_df[\"channels\"]\n\n        return mapped_df.reset_index(drop=True)\n\n    elif out_format == \"dict\":\n        return brainRegions\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_cell_metrics","title":"<code>load_cell_metrics(basepath, only_metrics=False)</code>","text":"<p>Loader of cell-explorer cell_metrics.cellinfo.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to folder with cell_metrics.cellinfo.mat.</p> required <code>only_metrics</code> <code>bool</code> <p>If True, only metrics are loaded, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, Tuple[DataFrame, dict]]</code> <p>DataFrame of single unit features and a dictionary with data that does not fit nicely into a DataFrame (waveforms, acgs, epochs, etc.).</p> Notes <p>See https://cellexplorer.org/datastructure/standard-cell-metrics/ for details.</p> <p>TODO: Extract all fields from cell_metrics.cellinfo. There are more items that can be extracted.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_cell_metrics(\n    basepath: str, only_metrics: bool = False\n) -&gt; Union[pd.DataFrame, Tuple[pd.DataFrame, dict]]:\n    \"\"\"\n    Loader of cell-explorer cell_metrics.cellinfo.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to folder with cell_metrics.cellinfo.mat.\n    only_metrics : bool, optional\n        If True, only metrics are loaded, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, Tuple[pd.DataFrame, dict]]\n        DataFrame of single unit features and a dictionary with data that does not fit nicely into a DataFrame (waveforms, acgs, epochs, etc.).\n\n    Notes\n    -----\n    See https://cellexplorer.org/datastructure/standard-cell-metrics/ for details.\n\n    TODO: Extract all fields from cell_metrics.cellinfo. There are more items that can be extracted.\n    \"\"\"\n\n    def extract_epochs(data):\n        startTime = [\n            ep[\"startTime\"][0][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n        stopTime = [\n            ep[\"stopTime\"][0][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n        name = [\n            ep[\"name\"][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n\n        epochs = pd.DataFrame()\n        epochs[\"name\"] = name\n        epochs[\"startTime\"] = startTime\n        epochs[\"stopTime\"] = stopTime\n        return epochs\n\n    def extract_events(data):\n        psth = {}\n        for dt in data[\"cell_metrics\"][\"events\"][0][0].dtype.names:\n            psth[dt] = pd.DataFrame(\n                index=data[\"cell_metrics\"][\"general\"][0][0][0][\"events\"][0][dt][0][0][\n                    \"x_bins\"\n                ][0][0].T[0]\n                / 1000,\n                data=np.hstack(data[\"cell_metrics\"][\"events\"][0][0][dt][0][0][0]),\n            )\n        return psth\n\n    def extract_general(data):\n        # extract fr per unit with lag zero to ripple\n        try:\n            ripple_fr = [\n                ev.T[0]\n                for ev in data[\"cell_metrics\"][\"events\"][0][0][\"ripples\"][0][0][0]\n            ]\n        except Exception:\n            ripple_fr = []\n        # extract spikes times\n        spikes = [\n            spk.T[0] for spk in data[\"cell_metrics\"][\"spikes\"][0][0][\"times\"][0][0][0]\n        ]\n        # extract epochs\n        try:\n            epochs = extract_epochs(data)\n        except Exception:\n            epochs = []\n\n        # extract events\n        try:\n            events_psth = extract_events(data)\n        except Exception:\n            events_psth = []\n\n        # extract avg waveforms\n        try:\n            waveforms = np.vstack(\n                data[\"cell_metrics\"][\"waveforms\"][0][0][\"filt\"][0][0][0]\n            )\n        except Exception:\n            try:\n                waveforms = [\n                    w.T for w in data[\"cell_metrics\"][\"waveforms\"][0][0][0][0][0][0]\n                ]\n            except Exception:\n                waveforms = [w.T for w in data[\"cell_metrics\"][\"waveforms\"][0][0][0]]\n        # extract chanCoords\n        try:\n            chanCoords_x = data[\"cell_metrics\"][\"general\"][0][0][\"chanCoords\"][0][0][0][\n                0\n            ][\"x\"].T[0]\n            chanCoords_y = data[\"cell_metrics\"][\"general\"][0][0][\"chanCoords\"][0][0][0][\n                0\n            ][\"y\"].T[0]\n        except Exception:\n            chanCoords_x = []\n            chanCoords_y = []\n\n        # add to dictionary\n        data_ = {\n            \"acg_wide\": data[\"cell_metrics\"][\"acg\"][0][0][\"wide\"][0][0],\n            \"acg_narrow\": data[\"cell_metrics\"][\"acg\"][0][0][\"narrow\"][0][0],\n            \"acg_log10\": data[\"cell_metrics\"][\"acg\"][0][0][\"log10\"][0][0],\n            \"ripple_fr\": ripple_fr,\n            \"chanCoords_x\": chanCoords_x,\n            \"chanCoords_y\": chanCoords_y,\n            \"epochs\": epochs,\n            \"spikes\": spikes,\n            \"waveforms\": waveforms,\n            \"events_psth\": events_psth,\n        }\n        return data_\n\n    def un_nest_df(df):\n        # Un-nest some strings are nested within brackets (a better solution exists...)\n        # locate and iterate objects in df\n        for item in df.keys()[df.dtypes == \"object\"]:\n            # if you can get the size of the first item with [0], it is nested\n            # otherwise it fails and is not nested\n            try:\n                df[item][0][0].size\n                # the below line is from: https://www.py4u.net/discuss/140913\n                df[item] = df[item].str.get(0)\n            except Exception:\n                continue\n        return df\n\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".cell_metrics.cellinfo.mat\"\n    )\n    # filename = glob.glob(os.path.join(basepath, \"*.cell_metrics.cellinfo.mat\"))[0]\n\n    # check if saved file exists\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        if only_metrics:\n            return None\n        return None, None\n\n    # load cell_metrics file\n    data = sio.loadmat(filename)\n\n    # construct data frame with features per neuron\n    df = {}\n    # count units\n    n_cells = data[\"cell_metrics\"][\"UID\"][0][0][0].size\n    dt = data[\"cell_metrics\"].dtype\n    for dn in dt.names:\n        # check if var has the right n of units and is a vector\n        try:\n            if (data[\"cell_metrics\"][dn][0][0][0][0].size == 1) &amp; (\n                data[\"cell_metrics\"][dn][0][0][0].size == n_cells\n            ):\n                # check if nested within brackets\n                try:\n                    df[dn] = [\n                        value[0] if len(value) == 1 else value\n                        for value in data[\"cell_metrics\"][dn][0][0][0]\n                    ]\n                except Exception:\n                    df[dn] = data[\"cell_metrics\"][dn][0][0][0]\n        except Exception:\n            continue\n\n    df = pd.DataFrame(df)\n\n    # load in tag\n    # check if tags exist within cell_metrics\n    if \"tags\" in data.get(\"cell_metrics\").dtype.names:\n        # get names of each tag\n        dt = data[\"cell_metrics\"][\"tags\"][0][0].dtype\n        if len(dt) &gt; 0:\n            # iter through each tag\n            for dn in dt.names:\n                # set up column for tag\n                df[\"tags_\" + dn] = [False] * df.shape[0]\n                # iter through uid\n                for uid in data[\"cell_metrics\"][\"tags\"][0][0][dn][0][0].flatten():\n                    df.loc[df.UID == uid, \"tags_\" + dn] = True\n\n    # add bad unit tag for legacy\n    df[\"bad_unit\"] = [False] * df.shape[0]\n    if \"tags_Bad\" in df.keys():\n        df.bad_unit = df.tags_Bad\n        df.bad_unit = df.bad_unit.replace({np.nan: False})\n\n    # add data from general metrics\n    df[\"basename\"] = data[\"cell_metrics\"][\"general\"][0][0][\"basename\"][0][0][0]\n    df[\"basepath\"] = basepath\n    df[\"sex\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"sex\"][0][0][0]\n    df[\"species\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"species\"][0][\n        0\n    ][0]\n    df[\"strain\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"strain\"][0][\n        0\n    ][0]\n    try:\n        df[\"geneticLine\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\n            \"geneticLine\"\n        ][0][0][0]\n    except Exception:\n        pass\n    df[\"cellCount\"] = data[\"cell_metrics\"][\"general\"][0][0][\"cellCount\"][0][0][0][0]\n\n    # fix nesting issue for strings\n    df = un_nest_df(df)\n\n    # convert nans within tags columns to false\n    cols = df.filter(regex=\"tags_\").columns\n    df[cols] = df[cols].replace({np.nan: False})\n\n    if only_metrics:\n        return df\n\n    # extract other general data and put into dict\n    data_ = extract_general(data)\n\n    return df, data_\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_channel_tags","title":"<code>load_channel_tags(basepath)</code>","text":"<p>Load channel tags from session file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the directory containing the session file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of channel tags from the session file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_channel_tags(basepath: str) -&gt; dict:\n    \"\"\"\n    Load channel tags from session file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the directory containing the session file.\n\n    Returns\n    -------\n    dict\n        A dictionary of channel tags from the session file.\n    \"\"\"\n    filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n    data = sio.loadmat(filename, simplify_cells=True)\n    return data[\"session\"][\"channelTags\"]\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_deepSuperficialfromRipple","title":"<code>load_deepSuperficialfromRipple(basepath, bypass_mismatch_exception=False)</code>","text":"<p>Load deepSuperficialfromRipple file created by classification_DeepSuperficial.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>bypass_mismatch_exception</code> <code>bool</code> <p>If True, bypass the mismatch exception, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, ndarray, ndarray]</code> <ul> <li>channel_df: DataFrame containing channel information.</li> <li>ripple_average: Array containing average ripple traces.</li> <li>ripple_time_axis: Array containing ripple time axis.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_deepSuperficialfromRipple(\n    basepath: str, bypass_mismatch_exception: bool = False\n) -&gt; Tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n    \"\"\"\n    Load deepSuperficialfromRipple file created by classification_DeepSuperficial.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    bypass_mismatch_exception : bool, optional\n        If True, bypass the mismatch exception, by default False.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, np.ndarray, np.ndarray]\n        - channel_df: DataFrame containing channel information.\n        - ripple_average: Array containing average ripple traces.\n        - ripple_time_axis: Array containing ripple time axis.\n    \"\"\"\n    # locate .mat file\n    file_type = \"*.deepSuperficialfromRipple.channelinfo.mat\"\n    filename = glob.glob(basepath + os.sep + file_type)[0]\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    channel_df = pd.DataFrame()\n    name = \"deepSuperficialfromRipple\"\n\n    # sometimes more channels positons will be in deepSuperficialfromRipple than in xml\n    #   this is because they used channel id as an index.\n    channel_df = pd.DataFrame()\n    channels = np.hstack(data[name][\"channel\"][0][0]) * np.nan\n    shanks = np.hstack(data[name][\"channel\"][0][0]) * np.nan\n\n    channels_, shanks_ = zip(\n        *[\n            (values[0], np.tile(shank, len(values[0])))\n            for shank, values in enumerate(data[name][\"ripple_channels\"][0][0][0])\n        ]\n    )\n    channel_sort_idx = np.hstack(channels_) - 1\n    channels[channel_sort_idx] = np.hstack(channels_)\n    shanks[channel_sort_idx] = np.hstack(shanks_) + 1\n\n    channel_df[\"channel\"] = channels\n    channel_df.loc[np.arange(len(channel_sort_idx)), \"channel_sort_idx\"] = (\n        channel_sort_idx\n    )\n    channel_df[\"shank\"] = shanks\n\n    # add distance from pyr layer (will only be accurate if polarity rev)\n    channel_df[\"channelDistance\"] = data[name][\"channelDistance\"][0][0].T[0]\n\n    # add channel class (deep or superficial)\n    channelClass = []\n    for item in data[name][\"channelClass\"][0][0]:\n        try:\n            channelClass.append(item[0][0])\n        except Exception:\n            channelClass.append(\"unknown\")\n    channel_df[\"channelClass\"] = channelClass\n\n    # add if shank has polarity reversal\n    for shank in channel_df.shank.unique():\n        if channel_df[channel_df.shank == shank].channelClass.unique().shape[0] == 2:\n            channel_df.loc[channel_df.shank == shank, \"polarity_reversal\"] = True\n        else:\n            channel_df.loc[channel_df.shank == shank, \"polarity_reversal\"] = False\n\n    # add ripple and sharp wave features\n    labels = [\"ripple_power\", \"ripple_amplitude\", \"SWR_diff\", \"SWR_amplitude\"]\n    for label in labels:\n        try:\n            channel_df.loc[channel_sort_idx, label] = np.hstack(\n                data[name][label][0][0][0]\n            )[0]\n        except Exception:\n            x = np.arange(len(channel_sort_idx)) * np.nan\n            x[0 : len(np.hstack(data[name][label][0][0][0])[0])] = np.hstack(\n                data[name][label][0][0][0]\n            )[0]\n            channel_df.loc[channel_sort_idx, label] = x\n\n    # pull put avg ripple traces and ts\n    ripple_time_axis = data[name][\"ripple_time_axis\"][0][0][0]\n    ripple_average = np.ones([channel_df.shape[0], len(ripple_time_axis)]) * np.nan\n\n    rip_map = []\n    for ch, values in zip(channels_, data[name][\"ripple_average\"][0][0][0]):\n        if values.shape[1] &gt; 0:\n            rip_map.append(values)\n        else:\n            rip_map.append(np.zeros([len(ripple_time_axis), len(ch)]) * np.nan)\n\n    ripple_average[channel_sort_idx] = np.hstack(rip_map).T\n\n    brainRegions = load_brain_regions(basepath)\n    for key, value in brainRegions.items():\n        if (\"ca1\" in key.lower()) | (\"ca2\" in key.lower()):\n            for shank in value[\"electrodeGroups\"]:\n                channel_df.loc[channel_df.shank == shank, \"ca1_shank\"] = True\n\n    if (ripple_average.shape[0] != channel_df.shape[0]) &amp; (\n        not bypass_mismatch_exception\n    ):\n        raise Exception(\n            \"size mismatch \"\n            + str(np.hstack(ripple_average).shape[1])\n            + \" and \"\n            + str(channel_df.shape[0])\n        )\n\n    channel_df[\"basepath\"] = basepath\n\n    return channel_df, ripple_average, ripple_time_axis\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_dentate_spikes","title":"<code>load_dentate_spikes(basepath, dentate_spike_type=['DS1', 'DS2'], manual_events=True, return_epoch_array=False)</code>","text":"<p>Load info from DS*.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where DS*.events.mat is located.</p> required <code>dentate_spike_type</code> <code>List[str]</code> <p>List of DS types to load, by default [\"DS1\", \"DS2\"].</p> <code>['DS1', 'DS2']</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of DS - stop: end time of DS - peaks: peak time of DS - amplitude: envelope value at peak time - duration: DS duration - detectorName: the name of DS detector used - basepath: path name - basename: session id - animal: animal id</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_dentate_spikes(\n    basepath: str,\n    dentate_spike_type: List[str] = [\"DS1\", \"DS2\"],\n    manual_events: bool = True,\n    return_epoch_array: bool = False,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from DS*.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where DS*.events.mat is located.\n    dentate_spike_type : List[str], optional\n        List of DS types to load, by default [\"DS1\", \"DS2\"].\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of DS\n        - stop: end time of DS\n        - peaks: peak time of DS\n        - amplitude: envelope value at peak time\n        - duration: DS duration\n        - detectorName: the name of DS detector used\n        - basepath: path name\n        - basename: session id\n        - animal: animal id\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    def extract_data(s_type, data, manual_events):\n        # make data frame of known fields\n        df = pd.DataFrame()\n        df[\"start\"] = data[s_type][\"timestamps\"][:, 0]\n        df[\"stop\"] = data[s_type][\"timestamps\"][:, 1]\n        df[\"peaks\"] = data[s_type][\"peaks\"]\n        df[\"event_label\"] = s_type\n        df[\"amplitude\"] = data[s_type][\"amplitudes\"]\n        df[\"duration\"] = data[s_type][\"duration\"]\n        df[\"amplitudeUnits\"] = data[s_type][\"amplitudeUnits\"]\n        df[\"detectorName\"] = data[s_type][\"detectorinfo\"][\"detectorname\"]\n        df[\"ml_channel\"] = data[s_type][\"detectorinfo\"][\"ml_channel\"]\n        df[\"h_channel\"] = data[s_type][\"detectorinfo\"][\"h_channel\"]\n\n        # remove flagged ripples, if exist\n        try:\n            df.drop(\n                labels=np.array(data[s_type][\"flagged\"]).T - 1,\n                axis=0,\n                inplace=True,\n            )\n            df.reset_index(inplace=True)\n        except Exception:\n            pass\n\n        # adding manual events\n        if manual_events:\n            try:\n                df = _add_manual_events(df, data[s_type][\"added\"])\n            except Exception:\n                pass\n        return df\n\n    # locate .mat file\n    df = pd.DataFrame()\n    for s_type in dentate_spike_type:\n        filename = glob.glob(basepath + os.sep + \"*\" + s_type + \".events.mat\")\n        if len(filename) == 0:\n            continue\n        # load matfile\n        filename = filename[0]\n        data = sio.loadmat(filename, simplify_cells=True)\n        # pull out data\n        df = pd.concat(\n            [df, extract_data(s_type, data, manual_events)], ignore_index=True\n        )\n\n    if df.shape[0] == 0:\n        return df\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"dentate_spike\")\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_emg","title":"<code>load_emg(basepath, threshold=0.9)</code>","text":"<p>Load EMG data from basename.EMGFromLFP.LFP.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>threshold</code> <code>float</code> <p>Threshold for high epochs (low will be &lt; threshold). Default is 0.9.</p> <code>0.9</code> <p>Returns:</p> Name Type Description <code>emg</code> <code>AnalogSignalArray</code> <p>EMG data.</p> <code>high_emg_epoch</code> <code>EpochArray</code> <p>High EMG epochs.</p> <code>low_emg_epoch</code> <code>EpochArray</code> <p>Low EMG epochs.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_emg(\n    basepath: str, threshold: float = 0.9\n) -&gt; Tuple[nel.AnalogSignalArray, nel.EpochArray, nel.EpochArray]:\n    \"\"\"\n    Load EMG data from basename.EMGFromLFP.LFP.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    threshold : float, optional\n        Threshold for high epochs (low will be &lt; threshold). Default is 0.9.\n\n    Returns\n    -------\n    emg : nel.AnalogSignalArray\n        EMG data.\n    high_emg_epoch : nel.EpochArray\n        High EMG epochs.\n    low_emg_epoch : nel.EpochArray\n        Low EMG epochs.\n    \"\"\"\n    # locate .mat file\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".EMGFromLFP.LFP.mat\"\n    )\n\n    # load matfile\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # put emg data into AnalogSignalArray\n    emg = nel.AnalogSignalArray(\n        data=data[\"EMGFromLFP\"][\"data\"], timestamps=data[\"EMGFromLFP\"][\"timestamps\"]\n    )\n\n    # get high and low emg epochs\n    high_emg_epoch = find_interval(emg.data.flatten() &gt; threshold)\n    high_emg_epoch = nel.EpochArray(emg.abscissa_vals[high_emg_epoch])\n\n    low_emg_epoch = find_interval(emg.data.flatten() &lt; threshold)\n    low_emg_epoch = nel.EpochArray(emg.abscissa_vals[low_emg_epoch])\n\n    return emg, high_emg_epoch, low_emg_epoch\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_epoch","title":"<code>load_epoch(basepath)</code>","text":"<p>Loads epoch info from cell explorer basename.session and stores in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - name: name of the epoch - startTime: start time of the epoch - stopTime: stop time of the epoch - environment: environment during the epoch - manipulation: manipulation during the epoch - behavioralParadigm: behavioral paradigm during the epoch - stimuli: stimuli during the epoch - notes: notes about the epoch - basepath: path to the session folder</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_epoch(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads epoch info from cell explorer basename.session and stores in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - name: name of the epoch\n        - startTime: start time of the epoch\n        - stopTime: stop time of the epoch\n        - environment: environment during the epoch\n        - manipulation: manipulation during the epoch\n        - behavioralParadigm: behavioral paradigm during the epoch\n        - stimuli: stimuli during the epoch\n        - notes: notes about the epoch\n        - basepath: path to the session folder\n    \"\"\"\n\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n\n    if not os.path.exists(filename):\n        warnings.warn(f\"file {filename} does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    def add_columns(df):\n        \"\"\"add columns to df if they don't exist\"\"\"\n        needed_columns = [\n            \"name\",\n            \"startTime\",\n            \"stopTime\",\n            \"environment\",\n            \"manipulation\",\n            \"behavioralParadigm\",\n            \"stimuli\",\n            \"notes\",\n        ]\n        for col in needed_columns:\n            if col not in df.columns:\n                df[col] = np.nan\n        return df\n\n    try:\n        epoch_df = pd.DataFrame(data[\"session\"][\"epochs\"])\n        epoch_df = add_columns(epoch_df)\n        epoch_df[\"basepath\"] = basepath\n        return epoch_df\n    except Exception:\n        epoch_df = pd.DataFrame([data[\"session\"][\"epochs\"]])\n        epoch_df = add_columns(epoch_df)\n        epoch_df[\"basepath\"] = basepath\n        return epoch_df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_events","title":"<code>load_events(basepath, epoch_name, load_pandas=False)</code>","text":"<p>Load events from basename.epoch_name.events.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>epoch_name</code> <code>str</code> <p>Name of epoch to load.</p> required <p>Returns:</p> Name Type Description <code>events</code> <code>EpochArray or None or DataFrame</code> <p>Events, or None if the file does not exist.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_events(\n    basepath: str, epoch_name: str, load_pandas=False\n) -&gt; Union[nel.EpochArray, None, pd.DataFrame]:\n    \"\"\"\n    Load events from basename.epoch_name.events.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    epoch_name : str\n        Name of epoch to load.\n\n    Returns\n    -------\n    events : nel.EpochArray or None or pd.DataFrame\n        Events, or None if the file does not exist.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + epoch_name + \".events.mat\"\n    )\n    # check if filename exist\n    if not os.path.exists(filename):\n        return None\n\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    if load_pandas:\n        n_events = data[epoch_name][\"timestamps\"].shape[0]\n\n        event_df = pd.DataFrame(\n            data[epoch_name][\"timestamps\"], columns=[\"starts\", \"stops\"]\n        )\n        for key in data[epoch_name].keys():\n            if (\n                isinstance(data[epoch_name][key], np.ndarray)\n                and data[epoch_name][key].shape[0] == n_events\n                and data[epoch_name][key].ndim == 1\n            ):\n                event_df[key] = data[epoch_name][key]\n        return event_df\n\n    return nel.EpochArray(data[epoch_name][\"timestamps\"])\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_extracellular_metadata","title":"<code>load_extracellular_metadata(basepath)</code>","text":"<p>Load extracellular metadata from session file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the directory containing the session file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of extracellular metadata from the session file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_extracellular_metadata(basepath: str) -&gt; dict:\n    \"\"\"\n    Load extracellular metadata from session file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the directory containing the session file.\n\n    Returns\n    -------\n    dict\n        A dictionary of extracellular metadata from the session file.\n    \"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n    # check if filename exist\n    if not os.path.exists(filename):\n        return {}\n    data = sio.loadmat(filename, simplify_cells=True)\n    return data[\"session\"][\"extracellular\"]\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_ied_events","title":"<code>load_ied_events(basepath, manual_events=True, return_epoch_array=False)</code>","text":"<p>Load info from ripples.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where ripples.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of ripple - stop: end time of ripple - center: center time of ripple - peaks: peak time of ripple</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_ied_events(\n    basepath: str, manual_events: bool = True, return_epoch_array: bool = False\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from ripples.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where ripples.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of ripple\n        - stop: end time of ripple\n        - center: center time of ripple\n        - peaks: peak time of ripple\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    # locate .mat file\n    try:\n        filename = glob.glob(basepath + os.sep + \"*IED.events.mat\")[0]\n    except Exception:\n        try:\n            filename = glob.glob(basepath + os.sep + \"*interictal_spikes.events.mat\")[0]\n        except Exception:\n            # warnings.warn(\"file does not exist\")\n            return pd.DataFrame()\n\n    df = pd.DataFrame()\n\n    data = sio.loadmat(filename, simplify_cells=True)\n    struct_name = list(data.keys())[-1]\n    df[\"start\"] = data[struct_name][\"timestamps\"][:, 0]\n    df[\"stop\"] = data[struct_name][\"timestamps\"][:, 1]\n    df[\"center\"] = data[struct_name][\"peaks\"]\n    df[\"peaks\"] = data[struct_name][\"peaks\"]\n\n    # remove flagged ripples, if exist\n    try:\n        df.drop(\n            labels=np.array(data[struct_name][\"flagged\"]).T - 1,\n            axis=0,\n            inplace=True,\n        )\n        df.reset_index(inplace=True)\n    except Exception:\n        pass\n\n    # adding manual events\n    if manual_events:\n        try:\n            df = _add_manual_events(df, data[struct_name][\"added\"])\n        except Exception:\n            pass\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"ied\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_manipulation","title":"<code>load_manipulation(basepath, struct_name=None, return_epoch_array=True, merge_gap=None)</code>","text":"<p>Loads the data from the basename.eventName.manipulations.mat file and returns a pandas dataframe.</p> <p>file structure defined here:     https://cellexplorer.org/datastructure/data-structure-and-format/#manipulations</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the basename.eventName.manipulations.mat file.</p> required <code>struct_name</code> <code>Union[str, None]</code> <p>Name of the structure in the mat file to load. If None, loads all the manipulation files, by default None.</p> <code>None</code> <code>return_epoch_array</code> <code>bool</code> <p>If True, returns only the epoch array, by default True.</p> <code>True</code> <code>merge_gap</code> <code>Union[int, None]</code> <p>If not None, merges the epochs that are separated by less than merge_gap (sec). return_epoch_array must be True, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame or EpochArray with the manipulation data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n&gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=False)\n&gt;&gt;&gt; df_manipulation.head(2)\n</code></pre> <p>.. table:: Manipulation Data     :widths: auto</p> <pre><code>====== ========== ========== ========== ========== ========== ========================\n    start      stop       peaks      center     duration    amplitude     amplitudeUnits\n====== ========== ========== ========== ========== ========== ========================\n8426.83650  8426.84845  8426.842475  8426.842475  0.01195   19651       pulse_respect_baseline\n8426.85245  8426.86745  8426.859950  8426.859950  0.01500   17516       pulse_respect_baseline\n====== ========== ========== ========== ========== ========== ========================\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n&gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=True)\n&gt;&gt;&gt; df_manipulation\n</code></pre> <p> of length 1:25:656 minutes Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_manipulation(\n    basepath: str,\n    struct_name: Union[str, None] = None,\n    return_epoch_array: bool = True,\n    merge_gap: Union[int, None] = None,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Loads the data from the basename.eventName.manipulations.mat file and returns a pandas dataframe.\n\n    file structure defined here:\n        https://cellexplorer.org/datastructure/data-structure-and-format/#manipulations\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the basename.eventName.manipulations.mat file.\n    struct_name : Union[str, None], optional\n        Name of the structure in the mat file to load. If None, loads all the manipulation files, by default None.\n    return_epoch_array : bool, optional\n        If True, returns only the epoch array, by default True.\n    merge_gap : Union[int, None], optional\n        If not None, merges the epochs that are separated by less than merge_gap (sec). return_epoch_array must be True, by default None.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame or EpochArray with the manipulation data.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n    &gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=False)\n    &gt;&gt;&gt; df_manipulation.head(2)\n\n    .. table:: Manipulation Data\n        :widths: auto\n\n        ====== ========== ========== ========== ========== ========== ========================\n            start      stop       peaks      center     duration    amplitude     amplitudeUnits\n        ====== ========== ========== ========== ========== ========== ========================\n        8426.83650  8426.84845  8426.842475  8426.842475  0.01195   19651       pulse_respect_baseline\n        8426.85245  8426.86745  8426.859950  8426.859950  0.01500   17516       pulse_respect_baseline\n        ====== ========== ========== ========== ========== ========== ========================\n\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n    &gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=True)\n    &gt;&gt;&gt; df_manipulation\n\n    &lt;EpochArray at 0x1faba577520: 5,774 epochs&gt; of length 1:25:656 minutes\n    \"\"\"\n    try:\n        if struct_name is None:\n            filename = glob.glob(basepath + os.sep + \"*manipulation.mat\")\n            print(filename)\n            if len(filename) &gt; 1:\n                raise ValueError(\n                    \"multi-file not implemented yet...than one manipulation file found\"\n                )\n            filename = filename[0]\n        else:\n            filename = glob.glob(\n                basepath + os.sep + \"*\" + struct_name + \".manipulation.mat\"\n            )[0]\n    except Exception:\n        return None\n    # load matfile\n    data = sio.loadmat(filename)\n\n    if struct_name is None:\n        struct_name = list(data.keys())[-1]\n\n    df = pd.DataFrame()\n    df[\"start\"] = data[struct_name][\"timestamps\"][0][0][:, 0]\n    df[\"stop\"] = data[struct_name][\"timestamps\"][0][0][:, 1]\n    df[\"peaks\"] = data[struct_name][\"peaks\"][0][0]\n    df[\"center\"] = data[struct_name][\"center\"][0][0]\n    df[\"duration\"] = data[struct_name][\"duration\"][0][0]\n    df[\"amplitude\"] = data[struct_name][\"amplitude\"][0][0]\n    df[\"amplitudeUnits\"] = data[struct_name][\"amplitudeUnits\"][0][0][0]\n\n    # extract event label names\n    eventIDlabels = []\n    for name in data[struct_name][\"eventIDlabels\"][0][0][0]:\n        eventIDlabels.append(name[0])\n\n    # extract numeric category labels associated with label names\n    eventID = np.array(data[struct_name][\"eventID\"][0][0]).ravel()\n\n    # add eventIDlabels and eventID to df\n    for ev_label, ev_num in zip(eventIDlabels, np.unique(eventID)):\n        df.loc[eventID == ev_num, \"ev_label\"] = ev_label\n\n    if return_epoch_array:\n        # get session epochs to add support for epochs\n        epoch_df = load_epoch(basepath)\n        # get session bounds to provide support\n        session_bounds = nel.EpochArray(\n            [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n        )\n        # if many types of manipulations, add them to dictinary\n        if df.ev_label.unique().size &gt; 1:\n            manipulation_epoch = {}\n            for label in df.ev_label.unique():\n                manipulation_epoch_ = nel.EpochArray(\n                    np.array(\n                        [\n                            df[df.ev_label == label][\"start\"],\n                            df[df.ev_label == label][\"stop\"],\n                        ]\n                    ).T,\n                    domain=session_bounds,\n                )\n                if merge_gap is not None:\n                    manipulation_epoch_ = manipulation_epoch_.merge(gap=merge_gap)\n\n                manipulation_epoch[label] = manipulation_epoch_\n        else:\n            manipulation_epoch = nel.EpochArray(\n                np.array([df[\"start\"], df[\"stop\"]]).T, domain=session_bounds\n            )\n            if merge_gap is not None:\n                manipulation_epoch = manipulation_epoch.merge(gap=merge_gap)\n\n        return manipulation_epoch\n    else:\n        return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_mua_events","title":"<code>load_mua_events(basepath)</code>","text":"<p>Loads the MUA data from the basepath. Meant to load .mat file created by find_HSE.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The path to the folder containing the MUA data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The pandas DataFrame containing the MUA data.</p> TODO <p>If none exist in basepath, create one.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_mua_events(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads the MUA data from the basepath.\n    Meant to load .mat file created by find_HSE.m.\n\n    Parameters\n    ----------\n    basepath : str\n        The path to the folder containing the MUA data.\n\n    Returns\n    -------\n    pd.DataFrame\n        The pandas DataFrame containing the MUA data.\n\n    TODO\n    ----\n    If none exist in basepath, create one.\n    \"\"\"\n\n    # locate .mat file\n    try:\n        filename = glob.glob(basepath + os.sep + \"*mua_ca1_pyr.events.mat\")[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    # pull out and package data\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"HSE\"][\"timestamps\"][0][0][:, 0]\n    df[\"stop\"] = data[\"HSE\"][\"timestamps\"][0][0][:, 1]\n    df[\"peaks\"] = data[\"HSE\"][\"peaks\"][0][0]\n    df[\"center\"] = data[\"HSE\"][\"center\"][0][0]\n    df[\"duration\"] = data[\"HSE\"][\"duration\"][0][0]\n    df[\"amplitude\"] = data[\"HSE\"][\"amplitudes\"][0][0]\n    df[\"amplitudeUnits\"] = data[\"HSE\"][\"amplitudeUnits\"][0][0][0]\n    df[\"detectorName\"] = data[\"HSE\"][\"detectorinfo\"][0][0][\"detectorname\"][0][0][0]\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_position","title":"<code>load_position(basepath, fs=39.0625)</code>","text":"<p>Load position data from a .whl file in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the directory containing the .whl file.</p> required <code>fs</code> <code>float</code> <p>Sampling frequency, by default 39.0625.</p> <code>39.0625</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, float]</code> <p>DataFrame containing position data and the sampling frequency.</p> Notes <p>If the directory does not exist or contains no .whl files, the function will exit.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_position(basepath: str, fs: float = 39.0625) -&gt; Tuple[pd.DataFrame, float]:\n    \"\"\"\n    Load position data from a .whl file in the specified directory.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the directory containing the .whl file.\n    fs : float, optional\n        Sampling frequency, by default 39.0625.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, float]\n        DataFrame containing position data and the sampling frequency.\n\n    Notes\n    -----\n    If the directory does not exist or contains no .whl files, the function will exit.\n    \"\"\"\n    if not os.path.exists(basepath):\n        print(\"The path \" + basepath + \" doesn't exist; Exiting ...\")\n        sys.exit()\n    listdir = os.listdir(basepath)\n    whlfiles = [f for f in listdir if f.endswith(\".whl\")]\n    if not len(whlfiles):\n        print(\"Folder contains no whl files; Exiting ...\")\n        sys.exit()\n    new_path = os.path.join(basepath, whlfiles[0])\n    df = pd.read_csv(new_path, delimiter=\"\\t\", header=0, names=[\"x1\", \"y1\", \"x2\", \"y2\"])\n    df[df == -1] = np.nan\n    return df, fs\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_probe_layout","title":"<code>load_probe_layout(basepath)</code>","text":"<p>Load electrode coordinates and grouping from the session.extracellular.mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Name Type Description <code>probe_layout</code> <code>DataFrame</code> <p>DataFrame with x, y coordinates and shank number.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_probe_layout(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load electrode coordinates and grouping from the session.extracellular.mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    probe_layout : pd.DataFrame\n        DataFrame with x, y coordinates and shank number.\n    \"\"\"\n\n    # load session file\n    filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    x = data[\"session\"][\"extracellular\"][\"chanCoords\"][\"x\"]\n    y = data[\"session\"][\"extracellular\"][\"chanCoords\"][\"y\"]\n\n    if (len(x) == 0) &amp; (len(y) == 0):\n        warnings.warn(\n            \"The coordinates are empty in session.extracellular.chanCoords. Returning None - check session file\"\n        )\n        return None\n\n    electrode_groups = data[\"session\"][\"extracellular\"][\"electrodeGroups\"][\"channels\"]\n\n    # for each group in electrodeGroups\n    mapped_shanks = []\n    mapped_channels = []\n\n    n_groups = data[\"session\"][\"extracellular\"][\"nElectrodeGroups\"]\n\n    if n_groups &gt; 1:\n        # loop through electrode groups\n        for group_i in np.arange(n_groups):\n            mapped_channels.append(\n                electrode_groups[group_i] - 1\n            )  # -1 to make 0 indexed\n            mapped_shanks.append(np.repeat(group_i, len(electrode_groups[group_i])))\n\n    elif n_groups == 1:\n        mapped_channels.append(electrode_groups - 1)  # -1 to make 0 indexed\n        mapped_shanks.append(\n            np.repeat(0, len(electrode_groups))\n        )  # electrode group for single shank always 0\n\n    #  unpack to lists\n    mapped_channels = list(chain(*mapped_channels))\n    shanks = list(chain(*mapped_shanks))\n\n    # get shank in same dimension as channels\n    shanks = np.expand_dims(shanks, axis=1)\n\n    probe_layout = (\n        pd.DataFrame({\"x\": x.flatten(), \"y\": y.flatten()})\n        .iloc[mapped_channels]\n        .reset_index(drop=True)\n    )\n    probe_layout[\"shank\"] = shanks\n    probe_layout[\"channels\"] = mapped_channels\n\n    return probe_layout\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_ripples_events","title":"<code>load_ripples_events(basepath, return_epoch_array=False, manual_events=True)</code>","text":"<p>Load info from ripples.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where ripples.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of ripple - stop: end time of ripple - peaks: peak time of ripple - amplitude: envelope value at peak time - duration: ripple duration - frequency: instant frequency at peak - detectorName: the name of ripple detector used - event_spk_thres: 1 or 0 for if a mua threshold was used - basepath: path name - basename: session id - animal: animal id</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_ripples_events(\n    basepath: str, return_epoch_array: bool = False, manual_events: bool = True\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from ripples.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where ripples.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of ripple\n        - stop: end time of ripple\n        - peaks: peak time of ripple\n        - amplitude: envelope value at peak time\n        - duration: ripple duration\n        - frequency: instant frequency at peak\n        - detectorName: the name of ripple detector used\n        - event_spk_thres: 1 or 0 for if a mua threshold was used\n        - basepath: path name\n        - basename: session id\n        - animal: animal id\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    # locate .mat file\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".ripples.events.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    # make data frame of known fields\n    df = pd.DataFrame()\n    try:\n        df[\"start\"] = data[\"ripples\"][\"timestamps\"][0][0][:, 0]\n        df[\"stop\"] = data[\"ripples\"][\"timestamps\"][0][0][:, 1]\n    except Exception:\n        df[\"start\"] = data[\"ripples\"][\"times\"][0][0][:, 0]\n        df[\"stop\"] = data[\"ripples\"][\"times\"][0][0][:, 1]\n\n    for name in [\"peaks\", \"amplitude\", \"duration\", \"frequency\", \"peakNormedPower\"]:\n        try:\n            df[name] = data[\"ripples\"][name][0][0]\n        except Exception:\n            df[name] = np.nan\n\n    if df.duration.isna().all():\n        df[\"duration\"] = df.stop - df.start\n\n    try:\n        df[\"detectorName\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\"detectorname\"][0][\n            0\n        ][0]\n    except Exception:\n        try:\n            df[\"detectorName\"] = data[\"ripples\"][\"detectorName\"][0][0][0]\n        except Exception:\n            df[\"detectorName\"] = \"unknown\"\n\n    # find ripple channel (this can be in several places depending on the file)\n    try:\n        df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\"detectionparms\"][\n            0\n        ][0][\"Channels\"][0][0][0][0]\n    except Exception:\n        try:\n            df[\"ripple_channel\"] = data[\"ripples\"][\"detectorParams\"][0][0][\"channel\"][\n                0\n            ][0][0][0]\n        except Exception:\n            try:\n                df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                    \"detectionparms\"\n                ][0][0][\"channel\"][0][0][0][0]\n            except Exception:\n                try:\n                    df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                        \"detectionparms\"\n                    ][0][0][\"ripple_channel\"][0][0][0][0]\n                except Exception:\n                    try:\n                        df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                            \"detectionchannel1\"\n                        ][0][0][0][0]\n                    except Exception:\n                        df[\"ripple_channel\"] = np.nan\n\n    # remove flagged ripples, if exist\n    try:\n        df.drop(\n            labels=np.array(data[\"ripples\"][\"flagged\"][0][0]).T[0] - 1,\n            axis=0,\n            inplace=True,\n        )\n        df.reset_index(inplace=True)\n    except Exception:\n        pass\n\n    # adding manual events\n    if manual_events:\n        try:\n            df = _add_manual_events(df, data[\"ripples\"][\"added\"][0][0].T[0])\n        except Exception:\n            pass\n\n    # adding if ripples were restricted by spikes\n    dt = data[\"ripples\"].dtype\n    if \"eventSpikingParameters\" in dt.names:\n        df[\"event_spk_thres\"] = 1\n    else:\n        df[\"event_spk_thres\"] = 0\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"ripples\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_spikes","title":"<code>load_spikes(basepath, putativeCellType=[], brainRegion=[], remove_bad_unit=True, brain_state=[], other_metric=None, other_metric_value=None, support=None, remove_unstable=False, stable_interval_width=600)</code>","text":"<p>Load specific cells' spike times.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>putativeCellType</code> <code>List[str]</code> <p>List of putative cell types to restrict spikes to, by default [].</p> <code>[]</code> <code>brainRegion</code> <code>List[str]</code> <p>List of brain regions to restrict spikes to, by default [].</p> <code>[]</code> <code>remove_bad_unit</code> <code>bool</code> <p>If True, do not load bad cells (tagged in CE), by default True.</p> <code>True</code> <code>brain_state</code> <code>List[str]</code> <p>List of brain states to restrict spikes to, by default [].</p> <code>[]</code> <code>other_metric</code> <code>Union[str, None]</code> <p>Metric to restrict spikes to, by default None.</p> <code>None</code> <code>other_metric_value</code> <code>Union[str, None]</code> <p>Value of the metric to restrict spikes to, by default None.</p> <code>None</code> <code>support</code> <code>Union[EpochArray, None]</code> <p>Time support to provide, by default None.</p> <code>None</code> <code>remove_unstable</code> <code>bool</code> <p>If True, remove unstable cells, by default False.</p> <code>False</code> <code>stable_interval_width</code> <code>int</code> <p>Width of the stable interval in seconds, by default 600.</p> <code>600</code> <p>Returns:</p> Type Description <code>Tuple[Union[SpikeTrainArray, None], Union[DataFrame, None]]</code> <p>Spike train array and cell metrics DataFrame.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_spikes(\n    basepath: str,\n    putativeCellType: List[str] = [],\n    brainRegion: List[str] = [],\n    remove_bad_unit: bool = True,\n    brain_state: List[str] = [],\n    other_metric: Union[str, None] = None,\n    other_metric_value: Union[str, None] = None,\n    support: Union[nel.EpochArray, None] = None,\n    remove_unstable: bool = False,\n    stable_interval_width: int = 600,\n) -&gt; Tuple[Union[nel.SpikeTrainArray, None], Union[pd.DataFrame, None]]:\n    \"\"\"\n    Load specific cells' spike times.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    putativeCellType : List[str], optional\n        List of putative cell types to restrict spikes to, by default [].\n    brainRegion : List[str], optional\n        List of brain regions to restrict spikes to, by default [].\n    remove_bad_unit : bool, optional\n        If True, do not load bad cells (tagged in CE), by default True.\n    brain_state : List[str], optional\n        List of brain states to restrict spikes to, by default [].\n    other_metric : Union[str, None], optional\n        Metric to restrict spikes to, by default None.\n    other_metric_value : Union[str, None], optional\n        Value of the metric to restrict spikes to, by default None.\n    support : Union[nel.EpochArray, None], optional\n        Time support to provide, by default None.\n    remove_unstable : bool, optional\n        If True, remove unstable cells, by default False.\n    stable_interval_width : int, optional\n        Width of the stable interval in seconds, by default 600.\n\n    Returns\n    -------\n    Tuple[Union[nel.SpikeTrainArray, None], Union[pd.DataFrame, None]]\n        Spike train array and cell metrics DataFrame.\n    \"\"\"\n    if not isinstance(putativeCellType, list):\n        putativeCellType = [putativeCellType]\n    if not isinstance(brainRegion, list):\n        brainRegion = [brainRegion]\n\n    # get sample rate from session\n    fs_dat = load_extracellular_metadata(basepath).get(\"sr\", None)\n\n    if fs_dat is None:\n        return None, None\n\n    # load cell metrics and spike data\n    cell_metrics, data = load_cell_metrics(basepath)\n\n    if cell_metrics is None or data is None:\n        return None, None\n\n    # put spike data into array st\n    st = np.array(data[\"spikes\"], dtype=object)\n\n    # restrict cell metrics\n    if len(putativeCellType) &gt; 0:\n        restrict_idx = []\n        for cell_type in putativeCellType:\n            restrict_idx.append(\n                cell_metrics.putativeCellType.str.contains(cell_type).values\n            )\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if len(brainRegion) &gt; 0:\n        restrict_idx = []\n        for brain_region in brainRegion:\n            restrict_idx.append(\n                cell_metrics.brainRegion.str.contains(brain_region).values\n            )\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    # restrict cell metrics by arbitrary metric\n    if other_metric is not None:\n        # make other_metric_value a list if not already\n        if not isinstance(other_metric, list):\n            other_metric = [other_metric]\n        if not isinstance(other_metric_value, list):\n            other_metric_value = [other_metric_value]\n        # check that other_metric_value is the same length as other_metric\n        if len(other_metric) != len(other_metric_value):\n            raise ValueError(\n                \"other_metric and other_metric_value must be of same length\"\n            )\n\n        restrict_idx = []\n        for metric, value in zip(other_metric, other_metric_value):\n            restrict_idx.append(cell_metrics[metric].str.contains(value).values)\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if remove_bad_unit:\n        # bad units will be tagged true, so only keep false values\n        restrict_idx = ~cell_metrics.bad_unit.values\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if remove_unstable and len(st) &gt; 0:\n        starts = np.arange(\n            np.hstack(st).min(),\n            np.hstack(st).max() - stable_interval_width,\n            stable_interval_width,\n        )\n        stops = starts + stable_interval_width\n\n        bst = npy.process.count_in_interval(st, starts, stops, \"counts\")\n        if bst.shape[1] == 0:\n            restrict_idx = np.ones(len(st), dtype=bool)\n        else:\n            zero_intervals = np.sum(bst == 0, axis=1)\n            active_intervals = np.sum(bst &gt; 0, axis=1)\n            # allow for 1 unstable interval max, and require at least 2 active intervals\n            restrict_idx = (zero_intervals &lt; 2) &amp; (active_intervals &gt;= 2)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    # get spike train array\n    try:\n        if support is not None:\n            st = nel.SpikeTrainArray(timestamps=st, fs=fs_dat, support=support)\n        else:\n            st = nel.SpikeTrainArray(timestamps=st, fs=fs_dat)\n    except Exception:  # if only single cell... should prob just skip session\n        if support is not None:\n            st = nel.SpikeTrainArray(timestamps=st[0], fs=fs_dat, support=support)\n        else:\n            st = nel.SpikeTrainArray(timestamps=st[0], fs=fs_dat)\n\n    if len(brain_state) &gt; 0:\n        # get brain states\n        brain_states = [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"]\n        if brain_state not in brain_states:\n            assert print(\"not correct brain state. Pick one\", brain_states)\n        else:\n            state_dict = load_SleepState_states(basepath)\n            state_epoch = nel.EpochArray(state_dict[brain_state])\n            st = st[state_epoch]\n\n    return st, cell_metrics\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_theta_cycles","title":"<code>load_theta_cycles(basepath, return_epoch_array=False)</code>","text":"<p>Load theta cycles calculated from auto_theta_cycles.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where thetacycles.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of theta cycle - stop: end time of theta cycle - duration: theta cycle duration - center: center time of theta cycle - trough: trough time of theta cycle - theta_channel: the theta channel used for detection</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_theta_cycles(\n    basepath: str, return_epoch_array: bool = False\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load theta cycles calculated from auto_theta_cycles.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where thetacycles.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of theta cycle\n        - stop: end time of theta cycle\n        - duration: theta cycle duration\n        - center: center time of theta cycle\n        - trough: trough time of theta cycle\n        - theta_channel: the theta channel used for detection\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".thetacycles.events.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        if return_epoch_array:\n            return nel.EpochArray()\n        return pd.DataFrame()\n\n    data = sio.loadmat(filename, simplify_cells=True)\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"thetacycles\"][\"timestamps\"][:, 0]\n    df[\"stop\"] = data[\"thetacycles\"][\"timestamps\"][:, 1]\n    df[\"duration\"] = data[\"thetacycles\"][\"duration\"]\n    df[\"center\"] = data[\"thetacycles\"][\"center\"]\n    df[\"trough\"] = data[\"thetacycles\"][\"peaks\"]\n    df[\"theta_channel\"] = data[\"thetacycles\"][\"detectorinfo\"][\"theta_channel\"]\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"theta_cycles\")\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_theta_rem_shift","title":"<code>load_theta_rem_shift(basepath)</code>","text":"<p>Load theta REM shift data from get_rem_shift.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where theta_rem_shift.mat is located.</p> required <p>Returns:</p> Type Description <code>Tuple[DataFrame, dict]</code> <p>DataFrame with the following fields: - UID: unique identifier for each unit - circ_dist: circular distance - rem_shift: REM shift - non_rem_shift: non-REM shift - m_rem: mean phase locking value during REM - r_rem: resultant vector length during REM - k_rem: concentration parameter during REM - p_rem: p-value of phase locking during REM - mode_rem: mode of phase locking during REM - m_wake: mean phase locking value during wake - r_wake: resultant vector length during wake - k_wake: concentration parameter during wake - p_wake: p-value of phase locking during wake - mode_wake: mode of phase locking during wake</p> <code>dict</code> <p>Dictionary with phase distributions and spike phases for REM and wake states.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_theta_rem_shift(basepath: str) -&gt; Tuple[pd.DataFrame, dict]:\n    \"\"\"\n    Load theta REM shift data from get_rem_shift.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where theta_rem_shift.mat is located.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, dict]\n        DataFrame with the following fields:\n        - UID: unique identifier for each unit\n        - circ_dist: circular distance\n        - rem_shift: REM shift\n        - non_rem_shift: non-REM shift\n        - m_rem: mean phase locking value during REM\n        - r_rem: resultant vector length during REM\n        - k_rem: concentration parameter during REM\n        - p_rem: p-value of phase locking during REM\n        - mode_rem: mode of phase locking during REM\n        - m_wake: mean phase locking value during wake\n        - r_wake: resultant vector length during wake\n        - k_wake: concentration parameter during wake\n        - p_wake: p-value of phase locking during wake\n        - mode_wake: mode of phase locking during wake\n\n    dict\n        Dictionary with phase distributions and spike phases for REM and wake states.\n    \"\"\"\n    try:\n        filename = glob.glob(basepath + os.sep + \"*theta_rem_shift.mat\")[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame(), np.nan\n\n    data = sio.loadmat(filename)\n\n    df = pd.DataFrame()\n\n    df[\"UID\"] = data[\"rem_shift_data\"][\"UID\"][0][0][0]\n    df[\"circ_dist\"] = data[\"rem_shift_data\"][\"circ_dist\"][0][0][0]\n    df[\"rem_shift\"] = data[\"rem_shift_data\"][\"rem_shift\"][0][0][0]\n    df[\"non_rem_shift\"] = data[\"rem_shift_data\"][\"non_rem_shift\"][0][0][0]\n\n    # rem metrics\n    df[\"m_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"m\"][0][0][0]\n    df[\"r_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"r\"][0][0][0]\n    df[\"k_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"k\"][0][0][0]\n    df[\"p_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"p\"][0][0][0]\n    df[\"mode_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][\n        0\n    ][0][\"mode\"][0][0][0]\n\n    # wake metrics\n    df[\"m_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"m\"][0][0][0]\n    df[\"r_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"r\"][0][0][0]\n    df[\"k_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"k\"][0][0][0]\n    df[\"p_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"p\"][0][0][0]\n    df[\"mode_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\n        \"phasestats\"\n    ][0][0][\"mode\"][0][0][0]\n\n    def get_distros(data, state):\n        return np.vstack(data[\"rem_shift_data\"][state][0][0][\"phasedistros\"][0][0].T)\n\n    def get_spikephases(data, state):\n        return data[\"rem_shift_data\"][state][0][0][\"spkphases\"][0][0][0]\n\n    # add to dictionary\n    data_dict = {\n        \"rem\": {\n            \"phasedistros\": get_distros(data, \"PhaseLockingData_rem\"),\n            \"spkphases\": get_spikephases(data, \"PhaseLockingData_rem\"),\n        },\n        \"wake\": {\n            \"phasedistros\": get_distros(data, \"PhaseLockingData_wake\"),\n            \"spkphases\": get_spikephases(data, \"PhaseLockingData_wake\"),\n        },\n    }\n\n    return df, data_dict\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.load_trials","title":"<code>load_trials(basepath)</code>","text":"<p>Loads trials from cell explorer basename.animal.behavior and stores in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - startTime: start time of the trial, in seconds - stopTime: stop time of the trial, in seconds - trialsID: ID of the trial</p> References <p>https://cellexplorer.org/datastructure/data-structure-and-format/#behavior</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_trials(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads trials from cell explorer basename.animal.behavior and stores in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - startTime: start time of the trial, in seconds\n        - stopTime: stop time of the trial, in seconds\n        - trialsID: ID of the trial\n\n    References\n    ----------\n    https://cellexplorer.org/datastructure/data-structure-and-format/#behavior\n    \"\"\"\n\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    if \"trials\" not in data[\"behavior\"].keys():\n        warnings.warn(\"trials not found in file\")\n        return pd.DataFrame()\n\n    # current standard is\n    #   behavior.trials.*name of trial*.start\n    #   behavior.trials.*name of trial*.stop\n    if (\n        isinstance(data[\"behavior\"][\"trials\"], dict)\n        and \"starts\" in data[\"behavior\"][\"trials\"].keys()\n        and \"stops\" in data[\"behavior\"][\"trials\"].keys()\n    ):\n        df = pd.DataFrame(\n            data=np.array(\n                [\n                    data[\"behavior\"][\"trials\"][\"starts\"],\n                    data[\"behavior\"][\"trials\"][\"stops\"],\n                ]\n            ).T\n        )\n        df.columns = [\"startTime\", \"stopTime\"]\n        df[\"trialsID\"] = data[\"behavior\"][\"trials\"][\"stateName\"]\n\n    # old standard\n    #   behavior.trials.*[starts,stops]*\n    else:\n        # check if trials is empty\n        if len(data[\"behavior\"][\"trials\"]) == 0:\n            warnings.warn(\"trials is empty\")\n            return pd.DataFrame()\n        try:\n            df = pd.DataFrame(data=data[\"behavior\"][\"trials\"])\n            df.columns = [\"startTime\", \"stopTime\"]\n            # check if trialsID exists\n            if \"trialsID\" in data[\"behavior\"].keys():\n                df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n        except Exception:\n            df = pd.DataFrame(data=[data[\"behavior\"][\"trials\"]])\n            df.columns = [\"startTime\", \"stopTime\"]\n            # check if trialsID exists\n            if \"trialsID\" in data[\"behavior\"].keys():\n                if type(data[\"behavior\"][\"trialsID\"]) is str:\n                    df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n\n                elif len(data[\"behavior\"][\"trialsID\"]) == df.shape[0]:\n                    df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n                else:\n                    warnings.warn(\"trials or trialsID not correct shape\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/#neuro_py.io.writeNeuroscopeEvents","title":"<code>writeNeuroscopeEvents(path, ep, name)</code>","text":"<p>Write events to a Neuroscope-compatible file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the output file.</p> required <code>ep</code> <code>Any</code> <p>Epoch data containing start and end times.</p> required <code>name</code> <code>str</code> <p>Name of the event.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def writeNeuroscopeEvents(path: str, ep: Any, name: str) -&gt; None:\n    \"\"\"\n    Write events to a Neuroscope-compatible file.\n\n    Parameters\n    ----------\n    path : str\n        Path to the output file.\n    ep : Any\n        Epoch data containing start and end times.\n    name : str\n        Name of the event.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    f = open(path, \"w\")\n    for i in range(len(ep)):\n        f.writelines(\n            str(ep.as_units(\"ms\").iloc[i][\"start\"])\n            + \" \"\n            + name\n            + \" start \"\n            + str(1)\n            + \"\\n\"\n        )\n        # f.writelines(str(ep.as_units('ms').iloc[i]['peak']) + \" \"+name+\" start \"+ str(1)+\"\\n\")\n        f.writelines(\n            str(ep.as_units(\"ms\").iloc[i][\"end\"]) + \" \" + name + \" end \" + str(1) + \"\\n\"\n        )\n    f.close()\n</code></pre>"},{"location":"reference/neuro_py/io/loading/","title":"neuro_py.io.loading","text":"<p>Loading functions for cell explorer format</p>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.LFPLoader","title":"<code>LFPLoader</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple class to load LFP or wideband data from a recording folder.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the recording folder.</p> required <code>channels</code> <code>Union[int, list, None]</code> <p>Channel number or list of channel numbers, by default None (load all channels memmap).</p> <code>None</code> <code>ext</code> <code>str</code> <p>File extension, by default \"lfp\".</p> <code>'lfp'</code> <code>epoch</code> <code>Union[ndarray, EpochArray, None]</code> <p>Epoch array or ndarray, by default None (load all data).</p> <code>None</code> <p>Returns:</p> Type Description <code>AnalogSignalArray</code> <p>Analog signal array of shape (n_channels, n_samples).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # load lfp file\n&gt;&gt;&gt; basepath = r\"X:/data/Barrage/NN10/day10\"\n&gt;&gt;&gt; lfp = loading.LFPLoader(basepath,ext=\"lfp\")\n&gt;&gt;&gt; lfp\n    &lt;AnalogSignalArray at 0x25ba1576640: 128 signals&gt; for a total of 5:33:58:789 hours\n</code></pre> <pre><code>&gt;&gt;&gt; # Loading dat file\n&gt;&gt;&gt; dat = loading.LFPLoader(basepath,ext=\"dat\")\n&gt;&gt;&gt; dat\n    &lt;AnalogSignalArray at 0x25ba4fedc40: 128 signals&gt; for a total of 5:33:58:790 hours\n&gt;&gt;&gt; dat.lfp.data.shape\n    (128, 400775808)\n&gt;&gt;&gt; type(dat.lfp.data)\n    numpy.memmap\n</code></pre> Source code in <code>neuro_py/io/loading.py</code> <pre><code>class LFPLoader(object):\n    \"\"\"\n    Simple class to load LFP or wideband data from a recording folder.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the recording folder.\n    channels : Union[int, list, None], optional\n        Channel number or list of channel numbers, by default None (load all channels memmap).\n    ext : str, optional\n        File extension, by default \"lfp\".\n    epoch : Union[np.ndarray, nel.EpochArray, None], optional\n        Epoch array or ndarray, by default None (load all data).\n\n    Returns\n    -------\n    nelpy.AnalogSignalArray\n        Analog signal array of shape (n_channels, n_samples).\n\n    Examples\n    --------\n    &gt;&gt;&gt; # load lfp file\n    &gt;&gt;&gt; basepath = r\"X:/data/Barrage/NN10/day10\"\n    &gt;&gt;&gt; lfp = loading.LFPLoader(basepath,ext=\"lfp\")\n    &gt;&gt;&gt; lfp\n        &lt;AnalogSignalArray at 0x25ba1576640: 128 signals&gt; for a total of 5:33:58:789 hours\n\n    &gt;&gt;&gt; # Loading dat file\n    &gt;&gt;&gt; dat = loading.LFPLoader(basepath,ext=\"dat\")\n    &gt;&gt;&gt; dat\n        &lt;AnalogSignalArray at 0x25ba4fedc40: 128 signals&gt; for a total of 5:33:58:790 hours\n    &gt;&gt;&gt; dat.lfp.data.shape\n        (128, 400775808)\n    &gt;&gt;&gt; type(dat.lfp.data)\n        numpy.memmap\n    \"\"\"\n\n    def __init__(\n        self,\n        basepath: str,\n        channels: Union[int, list, None] = None,\n        ext: str = \"lfp\",\n        epoch: Union[np.ndarray, nel.EpochArray, None] = None,\n    ) -&gt; None:\n        self.basepath = basepath  # path to the recording folder\n        self.channels = channels  # channel number or list of channel numbers\n        self.ext = ext  # lfp or dat\n        self.epoch = epoch\n\n        # get xml data\n        self.get_xml_data()\n\n        # set sampling rate based on the extension of the file (lfp or dat)\n        if self.ext == \"dat\":\n            self.fs = self.fs_dat\n\n        # load lfp\n        self.load_lfp()\n\n    def get_xml_data(self) -&gt; None:\n        nChannels, fs, fs_dat, shank_to_channel = loadXML(self.basepath)\n        self.nChannels = nChannels\n        self.fs = fs\n        self.fs_dat = fs_dat\n        self.shank_to_channel = shank_to_channel\n\n    def load_lfp(self) -&gt; None:\n        lfp, timestep = loadLFP(\n            self.basepath,\n            n_channels=self.nChannels,\n            channel=self.channels,\n            frequency=self.fs,\n            ext=self.ext,\n        )\n\n        if isinstance(self.epoch, nel.EpochArray):\n            intervals = self.epoch.data\n        elif isinstance(self.epoch, np.ndarray):\n            intervals = self.epoch\n            if intervals.ndim == 1:\n                intervals = intervals[np.newaxis, :]\n        else:\n            intervals = np.array([0, timestep.shape[0] / self.fs])[np.newaxis, :]\n\n        idx = in_intervals(timestep, intervals)\n\n        # if loading all, don't index as to preserve memmap\n        if idx.all():\n            self.lfp = nel.AnalogSignalArray(\n                data=lfp.T,\n                timestamps=timestep,\n                fs=self.fs,\n                support=nel.EpochArray(intervals),\n            )\n        else:\n            self.lfp = nel.AnalogSignalArray(\n                data=lfp[idx, None].T,\n                timestamps=timestep[idx],\n                fs=self.fs,\n                support=nel.EpochArray(\n                    np.array([min(timestep[idx]), max(timestep[idx])])\n                ),\n            )\n\n    def __repr__(self) -&gt; None:\n        return self.lfp.__repr__()\n\n    def get_phase(self, band2filter: list = [6, 12], ford: int = 3) -&gt; np.ndarray:\n        \"\"\"\n        Get the phase of the LFP signal using a bandpass filter and Hilbert transform.\n\n        Parameters\n        ----------\n        band2filter : list, optional\n            The frequency band to filter, by default [6, 12].\n        ford : int, optional\n            The order of the Butterworth filter, by default 3.\n\n        Returns\n        -------\n        np.ndarray\n            The phase of the LFP signal.\n        \"\"\"\n        band2filter = np.array(band2filter, dtype=float)\n        b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n        filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n        return np.angle(signal.hilbert(filt_sig))\n\n    def get_freq_phase_amp(\n        self, band2filter: list = [6, 12], ford: int = 3, kernel_size: int = 13\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.\n\n        Parameters\n        ----------\n        band2filter : list, optional\n            The frequency band to filter, by default [6, 12].\n        ford : int, optional\n            The order of the Butterworth filter, by default 3.\n        kernel_size : int, optional\n            The kernel size for the median filter, by default 13.\n\n        Returns\n        -------\n        filt_sig : np.ndarray\n            The filtered signal.\n        phase : np.ndarray\n            The phase of the LFP signal.\n        amplitude : np.ndarray\n            The amplitude of the LFP signal.\n        amplitude_filtered : np.ndarray\n            The filtered amplitude of the LFP signal.\n        frequency : np.ndarray\n            The instantaneous frequency of the LFP signal.\n        \"\"\"\n\n        band2filter = np.array(band2filter, dtype=float)\n\n        b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n\n        filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n        phase = np.angle(signal.hilbert(filt_sig))\n        amplitude = np.abs(signal.hilbert(filt_sig))\n        amplitude_filtered = signal.filtfilt(b, a, amplitude, padtype=\"odd\")\n\n        # calculate the frequency\n        # median filter to smooth the unwrapped phase (this is to avoid jumps in the frequency)\n        filtered_signal = signal.medfilt2d(\n            np.unwrap(phase), kernel_size=[1, kernel_size]\n        )\n\n        # Calculate the derivative of the unwrapped phase to get frequency\n        dt = np.diff(self.lfp.abscissa_vals)\n        if np.allclose(dt, dt[0]):  # Check if sampling is uniform\n            dt = dt[0]  # Use a single scalar for uniform sampling\n        else:\n            dt = np.hstack((dt[0], dt))  # Use an array for non-uniform sampling\n        derivative = np.gradient(filtered_signal, dt, axis=-1)\n        frequency = derivative / (2 * np.pi)\n\n        return filt_sig, phase, amplitude, amplitude_filtered, frequency\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.LFPLoader.get_freq_phase_amp","title":"<code>get_freq_phase_amp(band2filter=[6, 12], ford=3, kernel_size=13)</code>","text":"<p>Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.</p> <p>Parameters:</p> Name Type Description Default <code>band2filter</code> <code>list</code> <p>The frequency band to filter, by default [6, 12].</p> <code>[6, 12]</code> <code>ford</code> <code>int</code> <p>The order of the Butterworth filter, by default 3.</p> <code>3</code> <code>kernel_size</code> <code>int</code> <p>The kernel size for the median filter, by default 13.</p> <code>13</code> <p>Returns:</p> Name Type Description <code>filt_sig</code> <code>ndarray</code> <p>The filtered signal.</p> <code>phase</code> <code>ndarray</code> <p>The phase of the LFP signal.</p> <code>amplitude</code> <code>ndarray</code> <p>The amplitude of the LFP signal.</p> <code>amplitude_filtered</code> <code>ndarray</code> <p>The filtered amplitude of the LFP signal.</p> <code>frequency</code> <code>ndarray</code> <p>The instantaneous frequency of the LFP signal.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_freq_phase_amp(\n    self, band2filter: list = [6, 12], ford: int = 3, kernel_size: int = 13\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Get the filtered signal, phase, amplitude, and filtered amplitude of the LFP signal.\n\n    Parameters\n    ----------\n    band2filter : list, optional\n        The frequency band to filter, by default [6, 12].\n    ford : int, optional\n        The order of the Butterworth filter, by default 3.\n    kernel_size : int, optional\n        The kernel size for the median filter, by default 13.\n\n    Returns\n    -------\n    filt_sig : np.ndarray\n        The filtered signal.\n    phase : np.ndarray\n        The phase of the LFP signal.\n    amplitude : np.ndarray\n        The amplitude of the LFP signal.\n    amplitude_filtered : np.ndarray\n        The filtered amplitude of the LFP signal.\n    frequency : np.ndarray\n        The instantaneous frequency of the LFP signal.\n    \"\"\"\n\n    band2filter = np.array(band2filter, dtype=float)\n\n    b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n\n    filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n    phase = np.angle(signal.hilbert(filt_sig))\n    amplitude = np.abs(signal.hilbert(filt_sig))\n    amplitude_filtered = signal.filtfilt(b, a, amplitude, padtype=\"odd\")\n\n    # calculate the frequency\n    # median filter to smooth the unwrapped phase (this is to avoid jumps in the frequency)\n    filtered_signal = signal.medfilt2d(\n        np.unwrap(phase), kernel_size=[1, kernel_size]\n    )\n\n    # Calculate the derivative of the unwrapped phase to get frequency\n    dt = np.diff(self.lfp.abscissa_vals)\n    if np.allclose(dt, dt[0]):  # Check if sampling is uniform\n        dt = dt[0]  # Use a single scalar for uniform sampling\n    else:\n        dt = np.hstack((dt[0], dt))  # Use an array for non-uniform sampling\n    derivative = np.gradient(filtered_signal, dt, axis=-1)\n    frequency = derivative / (2 * np.pi)\n\n    return filt_sig, phase, amplitude, amplitude_filtered, frequency\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.LFPLoader.get_phase","title":"<code>get_phase(band2filter=[6, 12], ford=3)</code>","text":"<p>Get the phase of the LFP signal using a bandpass filter and Hilbert transform.</p> <p>Parameters:</p> Name Type Description Default <code>band2filter</code> <code>list</code> <p>The frequency band to filter, by default [6, 12].</p> <code>[6, 12]</code> <code>ford</code> <code>int</code> <p>The order of the Butterworth filter, by default 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The phase of the LFP signal.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_phase(self, band2filter: list = [6, 12], ford: int = 3) -&gt; np.ndarray:\n    \"\"\"\n    Get the phase of the LFP signal using a bandpass filter and Hilbert transform.\n\n    Parameters\n    ----------\n    band2filter : list, optional\n        The frequency band to filter, by default [6, 12].\n    ford : int, optional\n        The order of the Butterworth filter, by default 3.\n\n    Returns\n    -------\n    np.ndarray\n        The phase of the LFP signal.\n    \"\"\"\n    band2filter = np.array(band2filter, dtype=float)\n    b, a = signal.butter(ford, band2filter / (self.fs / 2), btype=\"bandpass\")\n    filt_sig = signal.filtfilt(b, a, self.lfp.data, padtype=\"odd\")\n    return np.angle(signal.hilbert(filt_sig))\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading._add_manual_events","title":"<code>_add_manual_events(df, added_ts)</code>","text":"<p>Add new rows to a dataframe representing manual events (from Neuroscope2) with durations equal to the mean duration of the existing events.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input dataframe, with at least two columns called 'start' and 'stop', representing the start and stop times of the events.</p> required <code>added_ts</code> <code>list</code> <p>A list of timestamps representing the peaks of the new events to be added to the dataframe.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The modified dataframe with the new rows added and sorted by the 'peaks' column.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def _add_manual_events(df: pd.DataFrame, added_ts: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Add new rows to a dataframe representing manual events (from Neuroscope2)\n    with durations equal to the mean duration of the existing events.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input dataframe, with at least two columns called 'start' and 'stop',\n        representing the start and stop times of the events.\n    added_ts : list\n        A list of timestamps representing the peaks of the new events to be added\n        to the dataframe.\n\n    Returns\n    -------\n    pd.DataFrame\n        The modified dataframe with the new rows added and sorted by the 'peaks' column.\n    \"\"\"\n    # Calculate the mean duration of the existing events\n    mean_duration = (df[\"stop\"] - df[\"start\"]).mean()\n\n    # Create a new dataframe with a 'peaks' column equal to the added_ts values\n    df_added = pd.DataFrame()\n    df_added[\"peaks\"] = added_ts\n\n    # Calculate the start and stop times of the new events based on the mean duration\n    df_added[\"start\"] = added_ts - mean_duration / 2\n    df_added[\"stop\"] = added_ts + mean_duration / 2\n\n    # Calculate the duration of the new events as the mean duration\n    df_added[\"duration\"] = df_added.stop.values - df_added.start.values\n\n    # Append the new events to the original dataframe\n    df = pd.concat([df, df_added], ignore_index=True)\n\n    # Sort the dataframe by the 'peaks' column\n    df.sort_values(by=[\"peaks\"], ignore_index=True, inplace=True)\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.add_animal_id","title":"<code>add_animal_id(df)</code>","text":"<p>Add animal_id column to a dataframe based on the basepath column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe with a basepath column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Dataframe with an additional animal_id column.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def add_animal_id(df: pd.core.frame.DataFrame) -&gt; pd.core.frame.DataFrame:\n    \"\"\"\n    Add animal_id column to a dataframe based on the basepath column.\n\n    Parameters\n    ----------\n    df : pd.core.frame.DataFrame\n        Dataframe with a basepath column.\n\n    Returns\n    -------\n    pd.core.frame.DataFrame\n        Dataframe with an additional animal_id column.\n    \"\"\"\n    df[\"animal_id\"] = df.basepath.map(\n        dict([(basepath, get_animal_id(basepath)) for basepath in df.basepath.unique()])\n    )\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.get_animal_id","title":"<code>get_animal_id(basepath)</code>","text":"<p>Return animal ID from basepath using basename.session.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to session folder.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Animal ID.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def get_animal_id(basepath: str) -&gt; str:\n    \"\"\"\n    Return animal ID from basepath using basename.session.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to session folder.\n\n    Returns\n    -------\n    str\n        Animal ID.\n    \"\"\"\n    try:\n        filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename)\n    return data[\"session\"][0][0][\"animal\"][0][0][\"name\"][0]\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.loadLFP","title":"<code>loadLFP(basepath, n_channels=90, channel=None, frequency=1250.0, precision='int16', ext='lfp', filename=None)</code>","text":"<p>Load LFP data from a specified file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the LFP file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels, by default 90.</p> <code>90</code> <code>channel</code> <code>Optional[Union[int, list]]</code> <p>Specific channel(s) to load, by default None.</p> <code>None</code> <code>frequency</code> <code>float</code> <p>Sampling frequency, by default 1250.0.</p> <code>1250.0</code> <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>ext</code> <code>str</code> <p>File extension, by default \"lfp\".</p> <code>'lfp'</code> <code>filename</code> <code>Optional[str]</code> <p>Name of the file to load, located in basepath, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Tuple[ndarray, ndarray]]</code> <p>Data and corresponding timestamps.</p> Notes <p>If both .lfp and .eeg files are present, .lfp file is prioritized. If neither are present, returns None.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def loadLFP(\n    basepath: str,\n    n_channels: int = 90,\n    channel: Union[int, None] = None,\n    frequency: float = 1250.0,\n    precision: str = \"int16\",\n    ext: str = \"lfp\",\n    filename: str = None,  # name of file to load, located in basepath\n):\n    \"\"\"\n    Load LFP data from a specified file.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the LFP file.\n    n_channels : int, optional\n        Number of channels, by default 90.\n    channel : Optional[Union[int, list]], optional\n        Specific channel(s) to load, by default None.\n    frequency : float, optional\n        Sampling frequency, by default 1250.0.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    ext : str, optional\n        File extension, by default \"lfp\".\n    filename : Optional[str], optional\n        Name of the file to load, located in basepath, by default None.\n\n    Returns\n    -------\n    Optional[Tuple[np.ndarray, np.ndarray]]\n        Data and corresponding timestamps.\n\n    Notes\n    -----\n    If both .lfp and .eeg files are present, .lfp file is prioritized.\n    If neither are present, returns None.\n    \"\"\"\n    if filename is not None:\n        path = os.path.join(basepath, filename)\n    else:\n        path = \"\"\n        if ext == \"lfp\":\n            path = os.path.join(basepath, os.path.basename(basepath) + \".lfp\")\n            if not os.path.exists(path):\n                path = os.path.join(basepath, os.path.basename(basepath) + \".eeg\")\n        if ext == \"dat\":\n            path = os.path.join(basepath, os.path.basename(basepath) + \".dat\")\n\n    # check if saved file exists\n    if not os.path.exists(path):\n        warnings.warn(\"file does not exist\")\n        return\n    if channel is None:\n        n_channels = int(n_channels)\n\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        data = np.memmap(path, np.int16, \"r\", shape=(n_samples, n_channels))\n        timestep = np.arange(0, n_samples) / frequency\n        return data, timestep\n\n    if type(channel) is not list:\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        with open(path, \"rb\") as f:\n            data = np.fromfile(f, np.int16).reshape((n_samples, n_channels))[:, channel]\n            timestep = np.arange(0, len(data)) / frequency\n            # check if lfp time stamps exist\n            lfp_ts_path = os.path.join(\n                os.path.dirname(os.path.abspath(path)), \"lfp_ts.npy\"\n            )\n            if os.path.exists(lfp_ts_path):\n                timestep = np.load(lfp_ts_path).reshape(-1)\n\n            return data, timestep\n\n    elif type(channel) is list:\n        f = open(path, \"rb\")\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        bytes_size = 2\n\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n        f.close()\n        with open(path, \"rb\") as f:\n            data = np.fromfile(f, np.int16).reshape((n_samples, n_channels))[:, channel]\n            timestep = np.arange(0, len(data)) / frequency\n            # check if lfp time stamps exist\n            lfp_ts_path = os.path.join(\n                os.path.dirname(os.path.abspath(path)), \"lfp_ts.npy\"\n            )\n            if os.path.exists(lfp_ts_path):\n                timestep = np.load(lfp_ts_path).reshape(-1)\n            return data, timestep\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.loadXML","title":"<code>loadXML(basepath)</code>","text":"<p>Load XML file and extract relevant information.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder session containing the XML file.</p> required <p>Returns:</p> Type Description <code>Union[Tuple[int, int, int, Dict[int, list]], None]</code> <p>A tuple containing: - The number of channels (int) - The sampling frequency of the dat file (int) - The sampling frequency of the eeg file (int) - The mappings shanks to channels as a dict (Dict[int, list])</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def loadXML(basepath: str) -&gt; Union[Tuple[int, int, int, Dict[int, list]], None]:\n    \"\"\"\n    Load XML file and extract relevant information.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder session containing the XML file.\n\n    Returns\n    -------\n    Union[Tuple[int, int, int, Dict[int, list]], None]\n        A tuple containing:\n        - The number of channels (int)\n        - The sampling frequency of the dat file (int)\n        - The sampling frequency of the eeg file (int)\n        - The mappings shanks to channels as a dict (Dict[int, list])\n    \"\"\"\n    # check if saved file exists\n    try:\n        basename = os.path.basename(basepath)\n        filename = glob.glob(os.path.join(basepath, basename + \".xml\"))[0]\n    except Exception:\n        warnings.warn(\"xml file does not exist\")\n        return\n\n    xmldoc = minidom.parse(filename)\n    nChannels = (\n        xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n        .getElementsByTagName(\"nChannels\")[0]\n        .firstChild.data\n    )\n    fs_dat = (\n        xmldoc.getElementsByTagName(\"acquisitionSystem\")[0]\n        .getElementsByTagName(\"samplingRate\")[0]\n        .firstChild.data\n    )\n    fs = (\n        xmldoc.getElementsByTagName(\"fieldPotentials\")[0]\n        .getElementsByTagName(\"lfpSamplingRate\")[0]\n        .firstChild.data\n    )\n\n    shank_to_channel = {}\n    groups = (\n        xmldoc.getElementsByTagName(\"anatomicalDescription\")[0]\n        .getElementsByTagName(\"channelGroups\")[0]\n        .getElementsByTagName(\"group\")\n    )\n    for i in range(len(groups)):\n        shank_to_channel[i] = [\n            int(child.firstChild.data)\n            for child in groups[i].getElementsByTagName(\"channel\")\n        ]\n    return int(nChannels), int(fs), int(fs_dat), shank_to_channel\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_SWRunitMetrics","title":"<code>load_SWRunitMetrics(basepath)</code>","text":"<p>Load SWRunitMetrics.mat into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the SWRunitMetrics.mat file.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - particip: the probability of participation into ripples for each unit - FRall: mean firing rate during ripples - FRparticip: mean firing rate for ripples with at least 1 spike - nSpkAll: mean number of spikes in all ripples - nSpkParticip: mean number of spikes in ripples with at least 1 spike - epoch: behavioral epoch label</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_SWRunitMetrics(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load SWRunitMetrics.mat into a pandas DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the SWRunitMetrics.mat file.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - particip: the probability of participation into ripples for each unit\n        - FRall: mean firing rate during ripples\n        - FRparticip: mean firing rate for ripples with at least 1 spike\n        - nSpkAll: mean number of spikes in all ripples\n        - nSpkParticip: mean number of spikes in ripples with at least 1 spike\n        - epoch: behavioral epoch label\n    \"\"\"\n\n    def extract_swr_epoch_data(data, epoch):\n        # get var names\n        dt = data[\"SWRunitMetrics\"][epoch][0][0].dtype\n\n        df2 = pd.DataFrame()\n\n        # get n units\n        # there might be other fields within here like the epoch timestamps\n        # skip those by returning empty df\n        try:\n            n_cells = data[\"SWRunitMetrics\"][epoch][0][0][0][\"particip\"][0].shape[0]\n        except Exception:\n            return df2\n\n        for dn in dt.names:\n            if (data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].shape[1] == 1) &amp; (\n                data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].shape[0] == n_cells\n            ):\n                df2[dn] = data[\"SWRunitMetrics\"][epoch][0][0][0][dn][0].T[0]\n        df2[\"epoch\"] = epoch\n        return df2\n\n    try:\n        filename = glob.glob(os.path.join(basepath, \"*.SWRunitMetrics.mat\"))[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename)\n\n    df2 = pd.DataFrame()\n    # loop through each available epoch and pull out contents\n    for epoch in data[\"SWRunitMetrics\"].dtype.names:\n        if data[\"SWRunitMetrics\"][epoch][0][0].size &gt; 0:  # not empty\n            # call content extractor\n            df_ = extract_swr_epoch_data(data, epoch)\n\n            # append conents to overall data frame\n            if df_.size &gt; 0:\n                df2 = pd.concat([df2, df_], ignore_index=True)\n\n    return df2\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_SleepState_states","title":"<code>load_SleepState_states(basepath, return_epoch_array=False, states_list=['WAKEstate', 'NREMstate', 'REMstate', 'THETA', 'nonTHETA'])</code>","text":"<p>Loader of SleepState.states.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the SleepState.states.mat file.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, return an dict of EpochArrays, by default False.</p> <code>False</code> <code>states_list</code> <code>list</code> <p>List of states to load, by default [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"].</p> <code>['WAKEstate', 'NREMstate', 'REMstate', 'THETA', 'nonTHETA']</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the contents of the SleepState.states.mat file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_SleepState_states(\n    basepath: str,\n    return_epoch_array: bool = False,\n    states_list: list = [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"],\n) -&gt; dict:\n    \"\"\"\n    Loader of SleepState.states.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the SleepState.states.mat file.\n    return_epoch_array : bool, optional\n        If True, return an dict of EpochArrays, by default False.\n    states_list : list, optional\n        List of states to load, by default [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"].\n\n    Returns\n    -------\n    dict\n        Dictionary containing the contents of the SleepState.states.mat file.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".SleepState.states.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return None\n\n    # load cell_metrics file\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # get epoch id\n    statenames = data[\"SleepState\"][\"idx\"][\"statenames\"]\n    statenames_cleaned = np.array([x if isinstance(x, str) else \"\" for x in statenames])\n    try:\n        wake_id = np.where(statenames_cleaned == \"WAKE\")[0][0] + 1\n    except IndexError:\n        wake_id = None\n    try:\n        rem_id = np.where(statenames_cleaned == \"REM\")[0][0] + 1\n    except IndexError:\n        rem_id = None\n    try:\n        nrem_id = np.where(statenames_cleaned == \"NREM\")[0][0] + 1\n    except IndexError:\n        nrem_id = None\n\n    # get states and timestamps vectors\n    states = data[\"SleepState\"][\"idx\"][\"states\"]\n    timestamps = data[\"SleepState\"][\"idx\"][\"timestamps\"]\n\n    # set up dict\n    dict_ = {\n        \"wake_id\": wake_id,\n        \"rem_id\": rem_id,\n        \"nrem_id\": nrem_id,\n        \"states\": states,\n        \"timestamps\": timestamps,\n    }\n\n    # iter through states and add to dict\n    dt = data[\"SleepState\"][\"ints\"]\n    for dn in dt.keys():\n        dict_[dn] = data[\"SleepState\"][\"ints\"][dn]\n\n    if not return_epoch_array:\n        return dict_\n    else:\n        epoch_df = load_epoch(basepath)\n        # get session bounds to provide support\n        session_domain = nel.EpochArray(\n            [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n        )\n        states_dict = {}\n        for state in states_list:\n            states_dict[state] = nel.EpochArray(\n                dict_.get(state, []), domain=session_domain\n            )\n        return states_dict\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_all_cell_metrics","title":"<code>load_all_cell_metrics(basepaths)</code>","text":"<p>Load cell metrics from multiple sessions.</p> <p>Parameters:</p> Name Type Description Default <code>basepaths</code> <code>List[str]</code> <p>List of basepaths, can be a pandas column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated pandas DataFrame with metrics.</p> Notes <p>To get waveforms, spike times, etc., use load_cell_metrics.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_all_cell_metrics(basepaths: List[str]) -&gt; pd.DataFrame:\n    \"\"\"\n    Load cell metrics from multiple sessions.\n\n    Parameters\n    ----------\n    basepaths : List[str]\n        List of basepaths, can be a pandas column.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated pandas DataFrame with metrics.\n\n    Notes\n    -----\n    To get waveforms, spike times, etc., use load_cell_metrics.\n    \"\"\"\n\n    # to speed up, use parallel\n    num_cores = multiprocessing.cpu_count()\n    cell_metrics = Parallel(n_jobs=num_cores)(\n        delayed(load_cell_metrics)(basepath, True) for basepath in basepaths\n    )\n\n    return pd.concat(cell_metrics, ignore_index=True)\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_animal_behavior","title":"<code>load_animal_behavior(basepath, alternative_file=None)</code>","text":"<p>load_animal_behavior loads basename.animal.behavior.mat files created by general_behavior_file.m The output is a pandas data frame with [time,x,y,z,linearized,speed,acceleration,trials,epochs]</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>alternative_file</code> <code>Union[str, None]</code> <p>Alternative file name to load, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - time: timestamps - x: x-coordinate - y: y-coordinate - z: z-coordinate - linearized: linearized position - speed: speed of the animal - acceleration: acceleration of the animal - trials: trial numbers - epochs: epoch names - environment: environment names</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_animal_behavior(\n    basepath: str, alternative_file: Union[str, None] = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    load_animal_behavior loads basename.animal.behavior.mat files created by general_behavior_file.m\n    The output is a pandas data frame with [time,x,y,z,linearized,speed,acceleration,trials,epochs]\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    alternative_file : Union[str, None], optional\n        Alternative file name to load, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - time: timestamps\n        - x: x-coordinate\n        - y: y-coordinate\n        - z: z-coordinate\n        - linearized: linearized position\n        - speed: speed of the animal\n        - acceleration: acceleration of the animal\n        - trials: trial numbers\n        - epochs: epoch names\n        - environment: environment names\n    \"\"\"\n    df = pd.DataFrame()\n\n    if alternative_file is None:\n        try:\n            filename = glob.glob(os.path.join(basepath, \"*.animal.behavior.mat\"))[0]\n        except Exception:\n            warnings.warn(\"file does not exist\")\n            return df\n    else:\n        try:\n            filename = glob.glob(\n                os.path.join(basepath, \"*\" + alternative_file + \".mat\")\n            )[0]\n        except Exception:\n            warnings.warn(\"file does not exist\")\n            return df\n\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    def _assign_column(col_name: str, values) -&gt; None:\n        if col_name in df.columns:\n            raise ValueError(\n                f\"Column '{col_name}' already exists in behavior dataframe; refusing to overwrite.\"\n            )\n        df[col_name] = values\n\n    # add timestamps first which provide the correct shape of df\n    # here, I'm naming them time, but this should be deprecated\n    _assign_column(\"time\", data[\"behavior\"][\"timestamps\"])\n\n    # add all other position coordinates to df (will add everything it can within position)\n    if \"position\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"position\"], dict\n    ):\n        for key in data[\"behavior\"][\"position\"].keys():\n            values = data[\"behavior\"][\"position\"][key]\n            # Skip empty arrays and non-array values (e.g., nested dicts)\n            if isinstance(values, dict):\n                continue\n            if isinstance(values, (list, np.ndarray)) and len(values) == 0:\n                continue\n            _assign_column(key, values)\n\n    # handle SpatialSeries containers (position/pupil/orientation, etc.)\n    if \"SpatialSeries\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"SpatialSeries\"], dict\n    ):\n        spatial_series = data[\"behavior\"][\"SpatialSeries\"]\n        for series_name, series in spatial_series.items():\n            if not isinstance(series, dict):\n                continue\n            for key, values in series.items():\n                if key in {\"units\", \"resolution\", \"referenceFrame\", \"coordinateSystem\"}:\n                    continue\n                if isinstance(values, dict):\n                    continue\n                if isinstance(values, (list, np.ndarray)):\n                    arr = np.asarray(values)\n                    if arr.ndim &gt; 1:\n                        continue\n                    if arr.ndim == 1 and len(arr) != len(df):\n                        continue\n                if series_name == \"position\":\n                    _assign_column(key, values)\n                else:\n                    _assign_column(f\"{series_name}_{key}\", values)\n\n    # add other fields from behavior to df (acceleration,speed,states)\n    for key in data[\"behavior\"].keys():\n        if key in {\"position\", \"SpatialSeries\", \"timeSeries\", \"trials\"}:\n            continue\n        values = data[\"behavior\"][key]\n        if isinstance(values, dict):\n            continue\n        if isinstance(values, (list, np.ndarray)):\n            arr = np.asarray(values)\n            if arr.ndim &gt; 1:\n                continue\n            if arr.ndim == 1 and len(arr) != len(df):\n                continue\n        _assign_column(key, values)\n\n    # add speed and acceleration (only if we have x and y coordinates and enough samples)\n    if (\n        \"speed\" not in df.columns\n        and \"x\" in df.columns\n        and \"y\" in df.columns\n        and len(df) &gt; 1\n    ):\n        _assign_column(\"speed\", get_speed(df[[\"x\", \"y\"]].values, df.time.values))\n    if (\n        \"acceleration\" not in df.columns and \"speed\" in df.columns and len(df) &gt; 1\n    ):  # using backward difference\n        acc = np.zeros(len(df))\n        acc[1:] = np.diff(df[\"speed\"]) / np.diff(df[\"time\"])\n        _assign_column(\"acceleration\", acc)\n\n    if \"trials\" in data[\"behavior\"]:\n        trials = data[\"behavior\"][\"trials\"]\n        # If trials is a struct/dict, support common fields\n        if isinstance(trials, dict):\n            if \"trials\" in trials and isinstance(trials[\"trials\"], (list, np.ndarray)):\n                arr = np.asarray(trials[\"trials\"])\n                if arr.ndim == 1 and len(arr) == len(df):\n                    _assign_column(\"trials\", arr)\n            elif {\n                \"start\",\n                \"stop\",\n            }.issubset(trials.keys()) or {\"starts\", \"stops\"}.issubset(trials.keys()):\n                starts = trials.get(\"start\", trials.get(\"starts\"))\n                stops = trials.get(\"stop\", trials.get(\"stops\"))\n                try:\n                    starts = np.asarray(starts).astype(float)\n                    stops = np.asarray(stops).astype(float)\n                    if len(df) &gt; 0:\n                        trial_col = np.full(len(df), np.nan)\n                        for t in range(len(starts)):\n                            idx = (df.time &gt;= starts[t]) &amp; (df.time &lt;= stops[t])\n                            trial_col[idx] = t\n                        _assign_column(\"trials\", trial_col)\n                except Exception:\n                    # Trials metadata can be malformed or inconsistent across sources; skip silently.\n                    pass\n        else:\n            try:\n                if len(df) &gt; 0:\n                    trial_col = np.full(len(df), np.nan)\n                    for t in range(trials.shape[0]):\n                        idx = (df.time &gt;= trials[t, 0]) &amp; (df.time &lt;= trials[t, 1])\n                        trial_col[idx] = t\n                    _assign_column(\"trials\", trial_col)\n            except Exception:\n                # Trials arrays may be ragged or have unexpected shapes; skip silently.\n                pass\n\n    # add timeSeries entries when present\n    if \"timeSeries\" in data[\"behavior\"] and isinstance(\n        data[\"behavior\"][\"timeSeries\"], dict\n    ):\n        for key, values in data[\"behavior\"][\"timeSeries\"].items():\n            if isinstance(values, dict):\n                continue\n            if isinstance(values, (list, np.ndarray)):\n                arr = np.asarray(values)\n                if arr.ndim &gt; 1:\n                    continue\n                if arr.ndim == 1 and len(arr) != len(df):\n                    continue\n            _assign_column(f\"timeSeries_{key}\", values)\n\n    # Initialize epoch columns with object dtype to hold strings\n    if \"epochs\" in df.columns or \"environment\" in df.columns:\n        raise ValueError(\"Column overwrite detected for 'epochs' or 'environment'.\")\n    _assign_column(\"epochs\", pd.Series([None] * len(df), dtype=object))\n    _assign_column(\"environment\", pd.Series([None] * len(df), dtype=object))\n\n    # Only process epochs if df is not empty\n    if len(df) &gt; 0:\n        epochs = load_epoch(basepath)\n        for t in range(epochs.shape[0]):\n            idx = (df.time &gt;= epochs.startTime.iloc[t]) &amp; (\n                df.time &lt;= epochs.stopTime.iloc[t]\n            )\n            if idx.any():\n                df.loc[idx, \"epochs\"] = epochs.name.iloc[t]\n                df.loc[idx, \"environment\"] = epochs.environment.iloc[t]\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_barrage_events","title":"<code>load_barrage_events(basepath, return_epoch_array=False, restrict_to_nrem=True, min_duration=0.0)</code>","text":"<p>Load barrage events from the .HSEn2.events.mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Basepath to the session folder.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, return an EpochArray instead of a DataFrame, by default False</p> <code>False</code> <code>restrict_to_nrem</code> <code>bool</code> <p>If True, restrict to NREM sleep, by default True</p> <code>True</code> <code>min_duration</code> <code>float</code> <p>Minimum duration of a barrage, by default 0.0</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with barrage events.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_barrage_events(\n    basepath: str,\n    return_epoch_array: bool = False,\n    restrict_to_nrem: bool = True,\n    min_duration: float = 0.0,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load barrage events from the .HSEn2.events.mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        Basepath to the session folder.\n    return_epoch_array : bool, optional\n        If True, return an EpochArray instead of a DataFrame, by default False\n    restrict_to_nrem : bool, optional\n        If True, restrict to NREM sleep, by default True\n    min_duration : float, optional\n        Minimum duration of a barrage, by default 0.0\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with barrage events.\n    \"\"\"\n\n    # locate barrage file\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".HSEn2.events.mat\")\n\n    # check if file exists\n    if os.path.exists(filename) is False:\n        warnings.warn(\"No barrage file found for {}\".format(basepath))\n        if return_epoch_array:\n            return nel.EpochArray()\n        return pd.DataFrame()\n\n    # load data from file and extract relevant data\n    data = sio.loadmat(filename, simplify_cells=True)\n    data = data[\"HSEn2\"]\n\n    # convert to DataFrame\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"timestamps\"][:, 0]\n    df[\"stop\"] = data[\"timestamps\"][:, 1]\n    df[\"peaks\"] = data[\"peaks\"]\n    df[\"duration\"] = data[\"timestamps\"][:, 1] - data[\"timestamps\"][:, 0]\n\n    # restrict to NREM sleep\n    if restrict_to_nrem:\n        state_dict = load_SleepState_states(basepath)\n        nrem_epochs = nel.EpochArray(state_dict[\"NREMstate\"]).expand(2)\n        idx = in_intervals(df[\"start\"].values, nrem_epochs.data)\n        df = df[idx].reset_index(drop=True)\n\n    # restrict to barrages with a minimum duration\n    df = df[df.duration &gt; min_duration].reset_index(drop=True)\n\n    # make sure each barrage has some ca2 activity\n    # load ca2 pyr cells\n    st, _ = load_spikes(basepath, putativeCellType=\"Pyr\", brainRegion=\"CA2\")\n    # bin spikes into barrages\n    bst = get_participation(st.data, df[\"start\"].values, df[\"stop\"].values)\n    # keep only barrages with some activity\n    df = df[np.sum(bst &gt; 0, axis=0) &gt; 0].reset_index(drop=True)\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"barrage\")\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_basic_data","title":"<code>load_basic_data(basepath)</code>","text":"<p>Load basic data from the specified basepath.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>Tuple[DataFrame, dict, DataFrame, float]</code> <ul> <li>cell_metrics: DataFrame containing cell metrics.</li> <li>data: Dictionary containing additional data.</li> <li>ripples: DataFrame containing ripple events.</li> <li>fs_dat: Sampling rate of the data.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_basic_data(basepath: str) -&gt; Tuple[pd.DataFrame, dict, pd.DataFrame, float]:\n    \"\"\"\n    Load basic data from the specified basepath.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, dict, pd.DataFrame, float]\n        - cell_metrics: DataFrame containing cell metrics.\n        - data: Dictionary containing additional data.\n        - ripples: DataFrame containing ripple events.\n        - fs_dat: Sampling rate of the data.\n    \"\"\"\n    try:\n        nChannels, fs, fs_dat, shank_to_channel = loadXML(basepath)\n    except Exception:\n        fs_dat = load_extracellular_metadata(basepath).get(\"sr\")\n\n    ripples = load_ripples_events(basepath)\n    cell_metrics, data = load_cell_metrics(basepath)\n\n    return cell_metrics, data, ripples, fs_dat\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_brain_regions","title":"<code>load_brain_regions(basepath, out_format='dict')</code>","text":"<p>Loads brain region info from cell explorer basename.session and stores in dict (default) or DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>out_format</code> <code>str</code> <p>Output format, either 'dict' or 'DataFrame', by default 'dict'.</p> <code>'dict'</code> <p>Returns:</p> Type Description <code>Union[dict, DataFrame]</code> <p>Dictionary or DataFrame with brain region information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; brainRegions = load_brain_regions(\"Z:\\Data\\GirardeauG\\Rat09\\Rat09-20140327\")\n&gt;&gt;&gt; print(brainRegions.keys())\ndict_keys(['CA1', 'Unknown', 'blv', 'bmp', 'ven'])\n&gt;&gt;&gt; print(brainRegions['CA1'].keys())\ndict_keys(['channels', 'electrodeGroups'])\n&gt;&gt;&gt; print(brainRegions['CA1']['channels'])\n[145 146 147 148 149 153 155 157 150 151 154 159 156 152 158 160 137 140\n129 136 138 134 130 132 142 143 144 141 131 139 133 135]\n&gt;&gt;&gt; print(brainRegions['CA1']['electrodeGroups'])\n    [17 18 19 20]\n</code></pre> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_brain_regions(\n    basepath: str, out_format: str = \"dict\"\n) -&gt; Union[dict, pd.DataFrame]:\n    \"\"\"\n    Loads brain region info from cell explorer basename.session and stores in dict (default) or DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    out_format : str, optional\n        Output format, either 'dict' or 'DataFrame', by default 'dict'.\n\n    Returns\n    -------\n    Union[dict, pd.DataFrame]\n        Dictionary or DataFrame with brain region information.\n\n    Examples\n    -------\n    &gt;&gt;&gt; brainRegions = load_brain_regions(\"Z:\\\\Data\\\\GirardeauG\\\\Rat09\\\\Rat09-20140327\")\n    &gt;&gt;&gt; print(brainRegions.keys())\n    dict_keys(['CA1', 'Unknown', 'blv', 'bmp', 'ven'])\n    &gt;&gt;&gt; print(brainRegions['CA1'].keys())\n    dict_keys(['channels', 'electrodeGroups'])\n    &gt;&gt;&gt; print(brainRegions['CA1']['channels'])\n    [145 146 147 148 149 153 155 157 150 151 154 159 156 152 158 160 137 140\n    129 136 138 134 130 132 142 143 144 141 131 139 133 135]\n    &gt;&gt;&gt; print(brainRegions['CA1']['electrodeGroups'])\n        [17 18 19 20]\n    \"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n\n    if not os.path.exists(filename):\n        warnings.warn(f\"file {filename} does not exist\")\n        if out_format == \"DataFrame\":\n            return pd.DataFrame()\n        else:\n            return {}\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    data = data[\"session\"]\n\n    if \"brainRegions\" not in data.keys():\n        warnings.warn(\"brainRegions not found in file\")\n        if out_format == \"DataFrame\":\n            return pd.DataFrame()\n        else:\n            return {}\n\n    brainRegions = {}\n    for region in data[\"brainRegions\"].keys():\n        if len(data[\"brainRegions\"][region]) == 0:\n            continue\n        channels = data[\"brainRegions\"][region][\"channels\"] - 1\n        try:\n            electrodeGroups = data[\"brainRegions\"][region][\"electrodeGroups\"]\n        except Exception:\n            electrodeGroups = np.nan\n\n        brainRegions[region] = {\n            \"channels\": channels,\n            \"electrodeGroups\": electrodeGroups,\n        }\n\n    if out_format == \"DataFrame\":  # return as DataFrame\n        # get channel order from electrodeGroups in session file\n        shank_to_channel = data[\"extracellular\"][\"electrodeGroups\"][\"channels\"] - 1\n\n        # check if nested array for multi shank\n        if is_nested(shank_to_channel) or shank_to_channel.ndim &gt; 1:\n            channels = np.hstack(shank_to_channel)\n            shanks = np.hstack(\n                [\n                    np.repeat(i, len(shank_to_channel[i]))\n                    for i in range(len(shank_to_channel))\n                ]\n            )\n        else:\n            channels = shank_to_channel\n            shanks = np.zeros(len(channels))\n\n        mapped_df = pd.DataFrame(columns=[\"channels\", \"region\"])\n        mapped_df[\"channels\"] = channels\n        mapped_df[\"region\"] = \"Unknown\"\n        mapped_df[\"shank\"] = shanks\n\n        for key in brainRegions.keys():\n            idx = np.isin(channels, brainRegions[key][\"channels\"])\n            mapped_df.loc[idx, \"region\"] = key\n\n        # save channel as zero-indexed\n        mapped_df[\"channels\"] = mapped_df[\"channels\"]\n\n        return mapped_df.reset_index(drop=True)\n\n    elif out_format == \"dict\":\n        return brainRegions\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_cell_metrics","title":"<code>load_cell_metrics(basepath, only_metrics=False)</code>","text":"<p>Loader of cell-explorer cell_metrics.cellinfo.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to folder with cell_metrics.cellinfo.mat.</p> required <code>only_metrics</code> <code>bool</code> <p>If True, only metrics are loaded, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, Tuple[DataFrame, dict]]</code> <p>DataFrame of single unit features and a dictionary with data that does not fit nicely into a DataFrame (waveforms, acgs, epochs, etc.).</p> Notes <p>See https://cellexplorer.org/datastructure/standard-cell-metrics/ for details.</p> <p>TODO: Extract all fields from cell_metrics.cellinfo. There are more items that can be extracted.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_cell_metrics(\n    basepath: str, only_metrics: bool = False\n) -&gt; Union[pd.DataFrame, Tuple[pd.DataFrame, dict]]:\n    \"\"\"\n    Loader of cell-explorer cell_metrics.cellinfo.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to folder with cell_metrics.cellinfo.mat.\n    only_metrics : bool, optional\n        If True, only metrics are loaded, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, Tuple[pd.DataFrame, dict]]\n        DataFrame of single unit features and a dictionary with data that does not fit nicely into a DataFrame (waveforms, acgs, epochs, etc.).\n\n    Notes\n    -----\n    See https://cellexplorer.org/datastructure/standard-cell-metrics/ for details.\n\n    TODO: Extract all fields from cell_metrics.cellinfo. There are more items that can be extracted.\n    \"\"\"\n\n    def extract_epochs(data):\n        startTime = [\n            ep[\"startTime\"][0][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n        stopTime = [\n            ep[\"stopTime\"][0][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n        name = [\n            ep[\"name\"][0][0][0]\n            for ep in data[\"cell_metrics\"][\"general\"][0][0][\"epochs\"][0][0][0]\n        ]\n\n        epochs = pd.DataFrame()\n        epochs[\"name\"] = name\n        epochs[\"startTime\"] = startTime\n        epochs[\"stopTime\"] = stopTime\n        return epochs\n\n    def extract_events(data):\n        psth = {}\n        for dt in data[\"cell_metrics\"][\"events\"][0][0].dtype.names:\n            psth[dt] = pd.DataFrame(\n                index=data[\"cell_metrics\"][\"general\"][0][0][0][\"events\"][0][dt][0][0][\n                    \"x_bins\"\n                ][0][0].T[0]\n                / 1000,\n                data=np.hstack(data[\"cell_metrics\"][\"events\"][0][0][dt][0][0][0]),\n            )\n        return psth\n\n    def extract_general(data):\n        # extract fr per unit with lag zero to ripple\n        try:\n            ripple_fr = [\n                ev.T[0]\n                for ev in data[\"cell_metrics\"][\"events\"][0][0][\"ripples\"][0][0][0]\n            ]\n        except Exception:\n            ripple_fr = []\n        # extract spikes times\n        spikes = [\n            spk.T[0] for spk in data[\"cell_metrics\"][\"spikes\"][0][0][\"times\"][0][0][0]\n        ]\n        # extract epochs\n        try:\n            epochs = extract_epochs(data)\n        except Exception:\n            epochs = []\n\n        # extract events\n        try:\n            events_psth = extract_events(data)\n        except Exception:\n            events_psth = []\n\n        # extract avg waveforms\n        try:\n            waveforms = np.vstack(\n                data[\"cell_metrics\"][\"waveforms\"][0][0][\"filt\"][0][0][0]\n            )\n        except Exception:\n            try:\n                waveforms = [\n                    w.T for w in data[\"cell_metrics\"][\"waveforms\"][0][0][0][0][0][0]\n                ]\n            except Exception:\n                waveforms = [w.T for w in data[\"cell_metrics\"][\"waveforms\"][0][0][0]]\n        # extract chanCoords\n        try:\n            chanCoords_x = data[\"cell_metrics\"][\"general\"][0][0][\"chanCoords\"][0][0][0][\n                0\n            ][\"x\"].T[0]\n            chanCoords_y = data[\"cell_metrics\"][\"general\"][0][0][\"chanCoords\"][0][0][0][\n                0\n            ][\"y\"].T[0]\n        except Exception:\n            chanCoords_x = []\n            chanCoords_y = []\n\n        # add to dictionary\n        data_ = {\n            \"acg_wide\": data[\"cell_metrics\"][\"acg\"][0][0][\"wide\"][0][0],\n            \"acg_narrow\": data[\"cell_metrics\"][\"acg\"][0][0][\"narrow\"][0][0],\n            \"acg_log10\": data[\"cell_metrics\"][\"acg\"][0][0][\"log10\"][0][0],\n            \"ripple_fr\": ripple_fr,\n            \"chanCoords_x\": chanCoords_x,\n            \"chanCoords_y\": chanCoords_y,\n            \"epochs\": epochs,\n            \"spikes\": spikes,\n            \"waveforms\": waveforms,\n            \"events_psth\": events_psth,\n        }\n        return data_\n\n    def un_nest_df(df):\n        # Un-nest some strings are nested within brackets (a better solution exists...)\n        # locate and iterate objects in df\n        for item in df.keys()[df.dtypes == \"object\"]:\n            # if you can get the size of the first item with [0], it is nested\n            # otherwise it fails and is not nested\n            try:\n                df[item][0][0].size\n                # the below line is from: https://www.py4u.net/discuss/140913\n                df[item] = df[item].str.get(0)\n            except Exception:\n                continue\n        return df\n\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".cell_metrics.cellinfo.mat\"\n    )\n    # filename = glob.glob(os.path.join(basepath, \"*.cell_metrics.cellinfo.mat\"))[0]\n\n    # check if saved file exists\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        if only_metrics:\n            return None\n        return None, None\n\n    # load cell_metrics file\n    data = sio.loadmat(filename)\n\n    # construct data frame with features per neuron\n    df = {}\n    # count units\n    n_cells = data[\"cell_metrics\"][\"UID\"][0][0][0].size\n    dt = data[\"cell_metrics\"].dtype\n    for dn in dt.names:\n        # check if var has the right n of units and is a vector\n        try:\n            if (data[\"cell_metrics\"][dn][0][0][0][0].size == 1) &amp; (\n                data[\"cell_metrics\"][dn][0][0][0].size == n_cells\n            ):\n                # check if nested within brackets\n                try:\n                    df[dn] = [\n                        value[0] if len(value) == 1 else value\n                        for value in data[\"cell_metrics\"][dn][0][0][0]\n                    ]\n                except Exception:\n                    df[dn] = data[\"cell_metrics\"][dn][0][0][0]\n        except Exception:\n            continue\n\n    df = pd.DataFrame(df)\n\n    # load in tag\n    # check if tags exist within cell_metrics\n    if \"tags\" in data.get(\"cell_metrics\").dtype.names:\n        # get names of each tag\n        dt = data[\"cell_metrics\"][\"tags\"][0][0].dtype\n        if len(dt) &gt; 0:\n            # iter through each tag\n            for dn in dt.names:\n                # set up column for tag\n                df[\"tags_\" + dn] = [False] * df.shape[0]\n                # iter through uid\n                for uid in data[\"cell_metrics\"][\"tags\"][0][0][dn][0][0].flatten():\n                    df.loc[df.UID == uid, \"tags_\" + dn] = True\n\n    # add bad unit tag for legacy\n    df[\"bad_unit\"] = [False] * df.shape[0]\n    if \"tags_Bad\" in df.keys():\n        df.bad_unit = df.tags_Bad\n        df.bad_unit = df.bad_unit.replace({np.nan: False})\n\n    # add data from general metrics\n    df[\"basename\"] = data[\"cell_metrics\"][\"general\"][0][0][\"basename\"][0][0][0]\n    df[\"basepath\"] = basepath\n    df[\"sex\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"sex\"][0][0][0]\n    df[\"species\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"species\"][0][\n        0\n    ][0]\n    df[\"strain\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\"strain\"][0][\n        0\n    ][0]\n    try:\n        df[\"geneticLine\"] = data[\"cell_metrics\"][\"general\"][0][0][\"animal\"][0][0][\n            \"geneticLine\"\n        ][0][0][0]\n    except Exception:\n        pass\n    df[\"cellCount\"] = data[\"cell_metrics\"][\"general\"][0][0][\"cellCount\"][0][0][0][0]\n\n    # fix nesting issue for strings\n    df = un_nest_df(df)\n\n    # convert nans within tags columns to false\n    cols = df.filter(regex=\"tags_\").columns\n    df[cols] = df[cols].replace({np.nan: False})\n\n    if only_metrics:\n        return df\n\n    # extract other general data and put into dict\n    data_ = extract_general(data)\n\n    return df, data_\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_channel_tags","title":"<code>load_channel_tags(basepath)</code>","text":"<p>Load channel tags from session file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the directory containing the session file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of channel tags from the session file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_channel_tags(basepath: str) -&gt; dict:\n    \"\"\"\n    Load channel tags from session file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the directory containing the session file.\n\n    Returns\n    -------\n    dict\n        A dictionary of channel tags from the session file.\n    \"\"\"\n    filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n    data = sio.loadmat(filename, simplify_cells=True)\n    return data[\"session\"][\"channelTags\"]\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_deepSuperficialfromRipple","title":"<code>load_deepSuperficialfromRipple(basepath, bypass_mismatch_exception=False)</code>","text":"<p>Load deepSuperficialfromRipple file created by classification_DeepSuperficial.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>bypass_mismatch_exception</code> <code>bool</code> <p>If True, bypass the mismatch exception, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, ndarray, ndarray]</code> <ul> <li>channel_df: DataFrame containing channel information.</li> <li>ripple_average: Array containing average ripple traces.</li> <li>ripple_time_axis: Array containing ripple time axis.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_deepSuperficialfromRipple(\n    basepath: str, bypass_mismatch_exception: bool = False\n) -&gt; Tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n    \"\"\"\n    Load deepSuperficialfromRipple file created by classification_DeepSuperficial.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    bypass_mismatch_exception : bool, optional\n        If True, bypass the mismatch exception, by default False.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, np.ndarray, np.ndarray]\n        - channel_df: DataFrame containing channel information.\n        - ripple_average: Array containing average ripple traces.\n        - ripple_time_axis: Array containing ripple time axis.\n    \"\"\"\n    # locate .mat file\n    file_type = \"*.deepSuperficialfromRipple.channelinfo.mat\"\n    filename = glob.glob(basepath + os.sep + file_type)[0]\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    channel_df = pd.DataFrame()\n    name = \"deepSuperficialfromRipple\"\n\n    # sometimes more channels positons will be in deepSuperficialfromRipple than in xml\n    #   this is because they used channel id as an index.\n    channel_df = pd.DataFrame()\n    channels = np.hstack(data[name][\"channel\"][0][0]) * np.nan\n    shanks = np.hstack(data[name][\"channel\"][0][0]) * np.nan\n\n    channels_, shanks_ = zip(\n        *[\n            (values[0], np.tile(shank, len(values[0])))\n            for shank, values in enumerate(data[name][\"ripple_channels\"][0][0][0])\n        ]\n    )\n    channel_sort_idx = np.hstack(channels_) - 1\n    channels[channel_sort_idx] = np.hstack(channels_)\n    shanks[channel_sort_idx] = np.hstack(shanks_) + 1\n\n    channel_df[\"channel\"] = channels\n    channel_df.loc[np.arange(len(channel_sort_idx)), \"channel_sort_idx\"] = (\n        channel_sort_idx\n    )\n    channel_df[\"shank\"] = shanks\n\n    # add distance from pyr layer (will only be accurate if polarity rev)\n    channel_df[\"channelDistance\"] = data[name][\"channelDistance\"][0][0].T[0]\n\n    # add channel class (deep or superficial)\n    channelClass = []\n    for item in data[name][\"channelClass\"][0][0]:\n        try:\n            channelClass.append(item[0][0])\n        except Exception:\n            channelClass.append(\"unknown\")\n    channel_df[\"channelClass\"] = channelClass\n\n    # add if shank has polarity reversal\n    for shank in channel_df.shank.unique():\n        if channel_df[channel_df.shank == shank].channelClass.unique().shape[0] == 2:\n            channel_df.loc[channel_df.shank == shank, \"polarity_reversal\"] = True\n        else:\n            channel_df.loc[channel_df.shank == shank, \"polarity_reversal\"] = False\n\n    # add ripple and sharp wave features\n    labels = [\"ripple_power\", \"ripple_amplitude\", \"SWR_diff\", \"SWR_amplitude\"]\n    for label in labels:\n        try:\n            channel_df.loc[channel_sort_idx, label] = np.hstack(\n                data[name][label][0][0][0]\n            )[0]\n        except Exception:\n            x = np.arange(len(channel_sort_idx)) * np.nan\n            x[0 : len(np.hstack(data[name][label][0][0][0])[0])] = np.hstack(\n                data[name][label][0][0][0]\n            )[0]\n            channel_df.loc[channel_sort_idx, label] = x\n\n    # pull put avg ripple traces and ts\n    ripple_time_axis = data[name][\"ripple_time_axis\"][0][0][0]\n    ripple_average = np.ones([channel_df.shape[0], len(ripple_time_axis)]) * np.nan\n\n    rip_map = []\n    for ch, values in zip(channels_, data[name][\"ripple_average\"][0][0][0]):\n        if values.shape[1] &gt; 0:\n            rip_map.append(values)\n        else:\n            rip_map.append(np.zeros([len(ripple_time_axis), len(ch)]) * np.nan)\n\n    ripple_average[channel_sort_idx] = np.hstack(rip_map).T\n\n    brainRegions = load_brain_regions(basepath)\n    for key, value in brainRegions.items():\n        if (\"ca1\" in key.lower()) | (\"ca2\" in key.lower()):\n            for shank in value[\"electrodeGroups\"]:\n                channel_df.loc[channel_df.shank == shank, \"ca1_shank\"] = True\n\n    if (ripple_average.shape[0] != channel_df.shape[0]) &amp; (\n        not bypass_mismatch_exception\n    ):\n        raise Exception(\n            \"size mismatch \"\n            + str(np.hstack(ripple_average).shape[1])\n            + \" and \"\n            + str(channel_df.shape[0])\n        )\n\n    channel_df[\"basepath\"] = basepath\n\n    return channel_df, ripple_average, ripple_time_axis\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_dentate_spikes","title":"<code>load_dentate_spikes(basepath, dentate_spike_type=['DS1', 'DS2'], manual_events=True, return_epoch_array=False)</code>","text":"<p>Load info from DS*.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where DS*.events.mat is located.</p> required <code>dentate_spike_type</code> <code>List[str]</code> <p>List of DS types to load, by default [\"DS1\", \"DS2\"].</p> <code>['DS1', 'DS2']</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of DS - stop: end time of DS - peaks: peak time of DS - amplitude: envelope value at peak time - duration: DS duration - detectorName: the name of DS detector used - basepath: path name - basename: session id - animal: animal id</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_dentate_spikes(\n    basepath: str,\n    dentate_spike_type: List[str] = [\"DS1\", \"DS2\"],\n    manual_events: bool = True,\n    return_epoch_array: bool = False,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from DS*.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where DS*.events.mat is located.\n    dentate_spike_type : List[str], optional\n        List of DS types to load, by default [\"DS1\", \"DS2\"].\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of DS\n        - stop: end time of DS\n        - peaks: peak time of DS\n        - amplitude: envelope value at peak time\n        - duration: DS duration\n        - detectorName: the name of DS detector used\n        - basepath: path name\n        - basename: session id\n        - animal: animal id\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    def extract_data(s_type, data, manual_events):\n        # make data frame of known fields\n        df = pd.DataFrame()\n        df[\"start\"] = data[s_type][\"timestamps\"][:, 0]\n        df[\"stop\"] = data[s_type][\"timestamps\"][:, 1]\n        df[\"peaks\"] = data[s_type][\"peaks\"]\n        df[\"event_label\"] = s_type\n        df[\"amplitude\"] = data[s_type][\"amplitudes\"]\n        df[\"duration\"] = data[s_type][\"duration\"]\n        df[\"amplitudeUnits\"] = data[s_type][\"amplitudeUnits\"]\n        df[\"detectorName\"] = data[s_type][\"detectorinfo\"][\"detectorname\"]\n        df[\"ml_channel\"] = data[s_type][\"detectorinfo\"][\"ml_channel\"]\n        df[\"h_channel\"] = data[s_type][\"detectorinfo\"][\"h_channel\"]\n\n        # remove flagged ripples, if exist\n        try:\n            df.drop(\n                labels=np.array(data[s_type][\"flagged\"]).T - 1,\n                axis=0,\n                inplace=True,\n            )\n            df.reset_index(inplace=True)\n        except Exception:\n            pass\n\n        # adding manual events\n        if manual_events:\n            try:\n                df = _add_manual_events(df, data[s_type][\"added\"])\n            except Exception:\n                pass\n        return df\n\n    # locate .mat file\n    df = pd.DataFrame()\n    for s_type in dentate_spike_type:\n        filename = glob.glob(basepath + os.sep + \"*\" + s_type + \".events.mat\")\n        if len(filename) == 0:\n            continue\n        # load matfile\n        filename = filename[0]\n        data = sio.loadmat(filename, simplify_cells=True)\n        # pull out data\n        df = pd.concat(\n            [df, extract_data(s_type, data, manual_events)], ignore_index=True\n        )\n\n    if df.shape[0] == 0:\n        return df\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"dentate_spike\")\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_emg","title":"<code>load_emg(basepath, threshold=0.9)</code>","text":"<p>Load EMG data from basename.EMGFromLFP.LFP.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>threshold</code> <code>float</code> <p>Threshold for high epochs (low will be &lt; threshold). Default is 0.9.</p> <code>0.9</code> <p>Returns:</p> Name Type Description <code>emg</code> <code>AnalogSignalArray</code> <p>EMG data.</p> <code>high_emg_epoch</code> <code>EpochArray</code> <p>High EMG epochs.</p> <code>low_emg_epoch</code> <code>EpochArray</code> <p>Low EMG epochs.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_emg(\n    basepath: str, threshold: float = 0.9\n) -&gt; Tuple[nel.AnalogSignalArray, nel.EpochArray, nel.EpochArray]:\n    \"\"\"\n    Load EMG data from basename.EMGFromLFP.LFP.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    threshold : float, optional\n        Threshold for high epochs (low will be &lt; threshold). Default is 0.9.\n\n    Returns\n    -------\n    emg : nel.AnalogSignalArray\n        EMG data.\n    high_emg_epoch : nel.EpochArray\n        High EMG epochs.\n    low_emg_epoch : nel.EpochArray\n        Low EMG epochs.\n    \"\"\"\n    # locate .mat file\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".EMGFromLFP.LFP.mat\"\n    )\n\n    # load matfile\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    # put emg data into AnalogSignalArray\n    emg = nel.AnalogSignalArray(\n        data=data[\"EMGFromLFP\"][\"data\"], timestamps=data[\"EMGFromLFP\"][\"timestamps\"]\n    )\n\n    # get high and low emg epochs\n    high_emg_epoch = find_interval(emg.data.flatten() &gt; threshold)\n    high_emg_epoch = nel.EpochArray(emg.abscissa_vals[high_emg_epoch])\n\n    low_emg_epoch = find_interval(emg.data.flatten() &lt; threshold)\n    low_emg_epoch = nel.EpochArray(emg.abscissa_vals[low_emg_epoch])\n\n    return emg, high_emg_epoch, low_emg_epoch\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_epoch","title":"<code>load_epoch(basepath)</code>","text":"<p>Loads epoch info from cell explorer basename.session and stores in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - name: name of the epoch - startTime: start time of the epoch - stopTime: stop time of the epoch - environment: environment during the epoch - manipulation: manipulation during the epoch - behavioralParadigm: behavioral paradigm during the epoch - stimuli: stimuli during the epoch - notes: notes about the epoch - basepath: path to the session folder</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_epoch(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads epoch info from cell explorer basename.session and stores in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - name: name of the epoch\n        - startTime: start time of the epoch\n        - stopTime: stop time of the epoch\n        - environment: environment during the epoch\n        - manipulation: manipulation during the epoch\n        - behavioralParadigm: behavioral paradigm during the epoch\n        - stimuli: stimuli during the epoch\n        - notes: notes about the epoch\n        - basepath: path to the session folder\n    \"\"\"\n\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n\n    if not os.path.exists(filename):\n        warnings.warn(f\"file {filename} does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    def add_columns(df):\n        \"\"\"add columns to df if they don't exist\"\"\"\n        needed_columns = [\n            \"name\",\n            \"startTime\",\n            \"stopTime\",\n            \"environment\",\n            \"manipulation\",\n            \"behavioralParadigm\",\n            \"stimuli\",\n            \"notes\",\n        ]\n        for col in needed_columns:\n            if col not in df.columns:\n                df[col] = np.nan\n        return df\n\n    try:\n        epoch_df = pd.DataFrame(data[\"session\"][\"epochs\"])\n        epoch_df = add_columns(epoch_df)\n        epoch_df[\"basepath\"] = basepath\n        return epoch_df\n    except Exception:\n        epoch_df = pd.DataFrame([data[\"session\"][\"epochs\"]])\n        epoch_df = add_columns(epoch_df)\n        epoch_df[\"basepath\"] = basepath\n        return epoch_df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_events","title":"<code>load_events(basepath, epoch_name, load_pandas=False)</code>","text":"<p>Load events from basename.epoch_name.events.mat.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>epoch_name</code> <code>str</code> <p>Name of epoch to load.</p> required <p>Returns:</p> Name Type Description <code>events</code> <code>EpochArray or None or DataFrame</code> <p>Events, or None if the file does not exist.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_events(\n    basepath: str, epoch_name: str, load_pandas=False\n) -&gt; Union[nel.EpochArray, None, pd.DataFrame]:\n    \"\"\"\n    Load events from basename.epoch_name.events.mat.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    epoch_name : str\n        Name of epoch to load.\n\n    Returns\n    -------\n    events : nel.EpochArray or None or pd.DataFrame\n        Events, or None if the file does not exist.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + epoch_name + \".events.mat\"\n    )\n    # check if filename exist\n    if not os.path.exists(filename):\n        return None\n\n    data = sio.loadmat(filename, simplify_cells=True)\n\n    if load_pandas:\n        n_events = data[epoch_name][\"timestamps\"].shape[0]\n\n        event_df = pd.DataFrame(\n            data[epoch_name][\"timestamps\"], columns=[\"starts\", \"stops\"]\n        )\n        for key in data[epoch_name].keys():\n            if (\n                isinstance(data[epoch_name][key], np.ndarray)\n                and data[epoch_name][key].shape[0] == n_events\n                and data[epoch_name][key].ndim == 1\n            ):\n                event_df[key] = data[epoch_name][key]\n        return event_df\n\n    return nel.EpochArray(data[epoch_name][\"timestamps\"])\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_extracellular_metadata","title":"<code>load_extracellular_metadata(basepath)</code>","text":"<p>Load extracellular metadata from session file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path to the directory containing the session file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of extracellular metadata from the session file.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_extracellular_metadata(basepath: str) -&gt; dict:\n    \"\"\"\n    Load extracellular metadata from session file.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path to the directory containing the session file.\n\n    Returns\n    -------\n    dict\n        A dictionary of extracellular metadata from the session file.\n    \"\"\"\n    filename = os.path.join(basepath, os.path.basename(basepath) + \".session.mat\")\n    # check if filename exist\n    if not os.path.exists(filename):\n        return {}\n    data = sio.loadmat(filename, simplify_cells=True)\n    return data[\"session\"][\"extracellular\"]\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_ied_events","title":"<code>load_ied_events(basepath, manual_events=True, return_epoch_array=False)</code>","text":"<p>Load info from ripples.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where ripples.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of ripple - stop: end time of ripple - center: center time of ripple - peaks: peak time of ripple</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_ied_events(\n    basepath: str, manual_events: bool = True, return_epoch_array: bool = False\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from ripples.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where ripples.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of ripple\n        - stop: end time of ripple\n        - center: center time of ripple\n        - peaks: peak time of ripple\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    # locate .mat file\n    try:\n        filename = glob.glob(basepath + os.sep + \"*IED.events.mat\")[0]\n    except Exception:\n        try:\n            filename = glob.glob(basepath + os.sep + \"*interictal_spikes.events.mat\")[0]\n        except Exception:\n            # warnings.warn(\"file does not exist\")\n            return pd.DataFrame()\n\n    df = pd.DataFrame()\n\n    data = sio.loadmat(filename, simplify_cells=True)\n    struct_name = list(data.keys())[-1]\n    df[\"start\"] = data[struct_name][\"timestamps\"][:, 0]\n    df[\"stop\"] = data[struct_name][\"timestamps\"][:, 1]\n    df[\"center\"] = data[struct_name][\"peaks\"]\n    df[\"peaks\"] = data[struct_name][\"peaks\"]\n\n    # remove flagged ripples, if exist\n    try:\n        df.drop(\n            labels=np.array(data[struct_name][\"flagged\"]).T - 1,\n            axis=0,\n            inplace=True,\n        )\n        df.reset_index(inplace=True)\n    except Exception:\n        pass\n\n    # adding manual events\n    if manual_events:\n        try:\n            df = _add_manual_events(df, data[struct_name][\"added\"])\n        except Exception:\n            pass\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"ied\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_manipulation","title":"<code>load_manipulation(basepath, struct_name=None, return_epoch_array=True, merge_gap=None)</code>","text":"<p>Loads the data from the basename.eventName.manipulations.mat file and returns a pandas dataframe.</p> <p>file structure defined here:     https://cellexplorer.org/datastructure/data-structure-and-format/#manipulations</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the basename.eventName.manipulations.mat file.</p> required <code>struct_name</code> <code>Union[str, None]</code> <p>Name of the structure in the mat file to load. If None, loads all the manipulation files, by default None.</p> <code>None</code> <code>return_epoch_array</code> <code>bool</code> <p>If True, returns only the epoch array, by default True.</p> <code>True</code> <code>merge_gap</code> <code>Union[int, None]</code> <p>If not None, merges the epochs that are separated by less than merge_gap (sec). return_epoch_array must be True, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame or EpochArray with the manipulation data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n&gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=False)\n&gt;&gt;&gt; df_manipulation.head(2)\n</code></pre> <p>.. table:: Manipulation Data     :widths: auto</p> <pre><code>====== ========== ========== ========== ========== ========== ========================\n    start      stop       peaks      center     duration    amplitude     amplitudeUnits\n====== ========== ========== ========== ========== ========== ========================\n8426.83650  8426.84845  8426.842475  8426.842475  0.01195   19651       pulse_respect_baseline\n8426.85245  8426.86745  8426.859950  8426.859950  0.01500   17516       pulse_respect_baseline\n====== ========== ========== ========== ========== ========== ========================\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n&gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=True)\n&gt;&gt;&gt; df_manipulation\n</code></pre> <p> of length 1:25:656 minutes Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_manipulation(\n    basepath: str,\n    struct_name: Union[str, None] = None,\n    return_epoch_array: bool = True,\n    merge_gap: Union[int, None] = None,\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Loads the data from the basename.eventName.manipulations.mat file and returns a pandas dataframe.\n\n    file structure defined here:\n        https://cellexplorer.org/datastructure/data-structure-and-format/#manipulations\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the basename.eventName.manipulations.mat file.\n    struct_name : Union[str, None], optional\n        Name of the structure in the mat file to load. If None, loads all the manipulation files, by default None.\n    return_epoch_array : bool, optional\n        If True, returns only the epoch array, by default True.\n    merge_gap : Union[int, None], optional\n        If not None, merges the epochs that are separated by less than merge_gap (sec). return_epoch_array must be True, by default None.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame or EpochArray with the manipulation data.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n    &gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=False)\n    &gt;&gt;&gt; df_manipulation.head(2)\n\n    .. table:: Manipulation Data\n        :widths: auto\n\n        ====== ========== ========== ========== ========== ========== ========================\n            start      stop       peaks      center     duration    amplitude     amplitudeUnits\n        ====== ========== ========== ========== ========== ========== ========================\n        8426.83650  8426.84845  8426.842475  8426.842475  0.01195   19651       pulse_respect_baseline\n        8426.85245  8426.86745  8426.859950  8426.859950  0.01500   17516       pulse_respect_baseline\n        ====== ========== ========== ========== ========== ========== ========================\n\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\Can\\OML22\\day8\"\n    &gt;&gt;&gt; df_manipulation = load_manipulation(basepath, struct_name=\"optoStim\", return_epoch_array=True)\n    &gt;&gt;&gt; df_manipulation\n\n    &lt;EpochArray at 0x1faba577520: 5,774 epochs&gt; of length 1:25:656 minutes\n    \"\"\"\n    try:\n        if struct_name is None:\n            filename = glob.glob(basepath + os.sep + \"*manipulation.mat\")\n            print(filename)\n            if len(filename) &gt; 1:\n                raise ValueError(\n                    \"multi-file not implemented yet...than one manipulation file found\"\n                )\n            filename = filename[0]\n        else:\n            filename = glob.glob(\n                basepath + os.sep + \"*\" + struct_name + \".manipulation.mat\"\n            )[0]\n    except Exception:\n        return None\n    # load matfile\n    data = sio.loadmat(filename)\n\n    if struct_name is None:\n        struct_name = list(data.keys())[-1]\n\n    df = pd.DataFrame()\n    df[\"start\"] = data[struct_name][\"timestamps\"][0][0][:, 0]\n    df[\"stop\"] = data[struct_name][\"timestamps\"][0][0][:, 1]\n    df[\"peaks\"] = data[struct_name][\"peaks\"][0][0]\n    df[\"center\"] = data[struct_name][\"center\"][0][0]\n    df[\"duration\"] = data[struct_name][\"duration\"][0][0]\n    df[\"amplitude\"] = data[struct_name][\"amplitude\"][0][0]\n    df[\"amplitudeUnits\"] = data[struct_name][\"amplitudeUnits\"][0][0][0]\n\n    # extract event label names\n    eventIDlabels = []\n    for name in data[struct_name][\"eventIDlabels\"][0][0][0]:\n        eventIDlabels.append(name[0])\n\n    # extract numeric category labels associated with label names\n    eventID = np.array(data[struct_name][\"eventID\"][0][0]).ravel()\n\n    # add eventIDlabels and eventID to df\n    for ev_label, ev_num in zip(eventIDlabels, np.unique(eventID)):\n        df.loc[eventID == ev_num, \"ev_label\"] = ev_label\n\n    if return_epoch_array:\n        # get session epochs to add support for epochs\n        epoch_df = load_epoch(basepath)\n        # get session bounds to provide support\n        session_bounds = nel.EpochArray(\n            [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n        )\n        # if many types of manipulations, add them to dictinary\n        if df.ev_label.unique().size &gt; 1:\n            manipulation_epoch = {}\n            for label in df.ev_label.unique():\n                manipulation_epoch_ = nel.EpochArray(\n                    np.array(\n                        [\n                            df[df.ev_label == label][\"start\"],\n                            df[df.ev_label == label][\"stop\"],\n                        ]\n                    ).T,\n                    domain=session_bounds,\n                )\n                if merge_gap is not None:\n                    manipulation_epoch_ = manipulation_epoch_.merge(gap=merge_gap)\n\n                manipulation_epoch[label] = manipulation_epoch_\n        else:\n            manipulation_epoch = nel.EpochArray(\n                np.array([df[\"start\"], df[\"stop\"]]).T, domain=session_bounds\n            )\n            if merge_gap is not None:\n                manipulation_epoch = manipulation_epoch.merge(gap=merge_gap)\n\n        return manipulation_epoch\n    else:\n        return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_mua_events","title":"<code>load_mua_events(basepath)</code>","text":"<p>Loads the MUA data from the basepath. Meant to load .mat file created by find_HSE.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The path to the folder containing the MUA data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The pandas DataFrame containing the MUA data.</p> TODO <p>If none exist in basepath, create one.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_mua_events(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads the MUA data from the basepath.\n    Meant to load .mat file created by find_HSE.m.\n\n    Parameters\n    ----------\n    basepath : str\n        The path to the folder containing the MUA data.\n\n    Returns\n    -------\n    pd.DataFrame\n        The pandas DataFrame containing the MUA data.\n\n    TODO\n    ----\n    If none exist in basepath, create one.\n    \"\"\"\n\n    # locate .mat file\n    try:\n        filename = glob.glob(basepath + os.sep + \"*mua_ca1_pyr.events.mat\")[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    # pull out and package data\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"HSE\"][\"timestamps\"][0][0][:, 0]\n    df[\"stop\"] = data[\"HSE\"][\"timestamps\"][0][0][:, 1]\n    df[\"peaks\"] = data[\"HSE\"][\"peaks\"][0][0]\n    df[\"center\"] = data[\"HSE\"][\"center\"][0][0]\n    df[\"duration\"] = data[\"HSE\"][\"duration\"][0][0]\n    df[\"amplitude\"] = data[\"HSE\"][\"amplitudes\"][0][0]\n    df[\"amplitudeUnits\"] = data[\"HSE\"][\"amplitudeUnits\"][0][0][0]\n    df[\"detectorName\"] = data[\"HSE\"][\"detectorinfo\"][0][0][\"detectorname\"][0][0][0]\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_position","title":"<code>load_position(basepath, fs=39.0625)</code>","text":"<p>Load position data from a .whl file in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the directory containing the .whl file.</p> required <code>fs</code> <code>float</code> <p>Sampling frequency, by default 39.0625.</p> <code>39.0625</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, float]</code> <p>DataFrame containing position data and the sampling frequency.</p> Notes <p>If the directory does not exist or contains no .whl files, the function will exit.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_position(basepath: str, fs: float = 39.0625) -&gt; Tuple[pd.DataFrame, float]:\n    \"\"\"\n    Load position data from a .whl file in the specified directory.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the directory containing the .whl file.\n    fs : float, optional\n        Sampling frequency, by default 39.0625.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, float]\n        DataFrame containing position data and the sampling frequency.\n\n    Notes\n    -----\n    If the directory does not exist or contains no .whl files, the function will exit.\n    \"\"\"\n    if not os.path.exists(basepath):\n        print(\"The path \" + basepath + \" doesn't exist; Exiting ...\")\n        sys.exit()\n    listdir = os.listdir(basepath)\n    whlfiles = [f for f in listdir if f.endswith(\".whl\")]\n    if not len(whlfiles):\n        print(\"Folder contains no whl files; Exiting ...\")\n        sys.exit()\n    new_path = os.path.join(basepath, whlfiles[0])\n    df = pd.read_csv(new_path, delimiter=\"\\t\", header=0, names=[\"x1\", \"y1\", \"x2\", \"y2\"])\n    df[df == -1] = np.nan\n    return df, fs\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_probe_layout","title":"<code>load_probe_layout(basepath)</code>","text":"<p>Load electrode coordinates and grouping from the session.extracellular.mat file.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Name Type Description <code>probe_layout</code> <code>DataFrame</code> <p>DataFrame with x, y coordinates and shank number.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_probe_layout(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Load electrode coordinates and grouping from the session.extracellular.mat file.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    probe_layout : pd.DataFrame\n        DataFrame with x, y coordinates and shank number.\n    \"\"\"\n\n    # load session file\n    filename = glob.glob(os.path.join(basepath, \"*.session.mat\"))[0]\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    x = data[\"session\"][\"extracellular\"][\"chanCoords\"][\"x\"]\n    y = data[\"session\"][\"extracellular\"][\"chanCoords\"][\"y\"]\n\n    if (len(x) == 0) &amp; (len(y) == 0):\n        warnings.warn(\n            \"The coordinates are empty in session.extracellular.chanCoords. Returning None - check session file\"\n        )\n        return None\n\n    electrode_groups = data[\"session\"][\"extracellular\"][\"electrodeGroups\"][\"channels\"]\n\n    # for each group in electrodeGroups\n    mapped_shanks = []\n    mapped_channels = []\n\n    n_groups = data[\"session\"][\"extracellular\"][\"nElectrodeGroups\"]\n\n    if n_groups &gt; 1:\n        # loop through electrode groups\n        for group_i in np.arange(n_groups):\n            mapped_channels.append(\n                electrode_groups[group_i] - 1\n            )  # -1 to make 0 indexed\n            mapped_shanks.append(np.repeat(group_i, len(electrode_groups[group_i])))\n\n    elif n_groups == 1:\n        mapped_channels.append(electrode_groups - 1)  # -1 to make 0 indexed\n        mapped_shanks.append(\n            np.repeat(0, len(electrode_groups))\n        )  # electrode group for single shank always 0\n\n    #  unpack to lists\n    mapped_channels = list(chain(*mapped_channels))\n    shanks = list(chain(*mapped_shanks))\n\n    # get shank in same dimension as channels\n    shanks = np.expand_dims(shanks, axis=1)\n\n    probe_layout = (\n        pd.DataFrame({\"x\": x.flatten(), \"y\": y.flatten()})\n        .iloc[mapped_channels]\n        .reset_index(drop=True)\n    )\n    probe_layout[\"shank\"] = shanks\n    probe_layout[\"channels\"] = mapped_channels\n\n    return probe_layout\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_ripples_events","title":"<code>load_ripples_events(basepath, return_epoch_array=False, manual_events=True)</code>","text":"<p>Load info from ripples.events.mat and store within a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where ripples.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <code>manual_events</code> <code>bool</code> <p>If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of ripple - stop: end time of ripple - peaks: peak time of ripple - amplitude: envelope value at peak time - duration: ripple duration - frequency: instant frequency at peak - detectorName: the name of ripple detector used - event_spk_thres: 1 or 0 for if a mua threshold was used - basepath: path name - basename: session id - animal: animal id</p> Notes <ul> <li>Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.</li> </ul> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_ripples_events(\n    basepath: str, return_epoch_array: bool = False, manual_events: bool = True\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load info from ripples.events.mat and store within a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where ripples.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n    manual_events : bool, optional\n        If True, add manually added events from Neuroscope2 (interval will be calculated from mean event duration), by default True.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of ripple\n        - stop: end time of ripple\n        - peaks: peak time of ripple\n        - amplitude: envelope value at peak time\n        - duration: ripple duration\n        - frequency: instant frequency at peak\n        - detectorName: the name of ripple detector used\n        - event_spk_thres: 1 or 0 for if a mua threshold was used\n        - basepath: path name\n        - basename: session id\n        - animal: animal id\n\n    Notes\n    -----\n    * Note that basepath/basename/animal relies on specific folder structure and may be incorrect for some data structures.\n    \"\"\"\n\n    # locate .mat file\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".ripples.events.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load matfile\n    data = sio.loadmat(filename)\n\n    # make data frame of known fields\n    df = pd.DataFrame()\n    try:\n        df[\"start\"] = data[\"ripples\"][\"timestamps\"][0][0][:, 0]\n        df[\"stop\"] = data[\"ripples\"][\"timestamps\"][0][0][:, 1]\n    except Exception:\n        df[\"start\"] = data[\"ripples\"][\"times\"][0][0][:, 0]\n        df[\"stop\"] = data[\"ripples\"][\"times\"][0][0][:, 1]\n\n    for name in [\"peaks\", \"amplitude\", \"duration\", \"frequency\", \"peakNormedPower\"]:\n        try:\n            df[name] = data[\"ripples\"][name][0][0]\n        except Exception:\n            df[name] = np.nan\n\n    if df.duration.isna().all():\n        df[\"duration\"] = df.stop - df.start\n\n    try:\n        df[\"detectorName\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\"detectorname\"][0][\n            0\n        ][0]\n    except Exception:\n        try:\n            df[\"detectorName\"] = data[\"ripples\"][\"detectorName\"][0][0][0]\n        except Exception:\n            df[\"detectorName\"] = \"unknown\"\n\n    # find ripple channel (this can be in several places depending on the file)\n    try:\n        df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\"detectionparms\"][\n            0\n        ][0][\"Channels\"][0][0][0][0]\n    except Exception:\n        try:\n            df[\"ripple_channel\"] = data[\"ripples\"][\"detectorParams\"][0][0][\"channel\"][\n                0\n            ][0][0][0]\n        except Exception:\n            try:\n                df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                    \"detectionparms\"\n                ][0][0][\"channel\"][0][0][0][0]\n            except Exception:\n                try:\n                    df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                        \"detectionparms\"\n                    ][0][0][\"ripple_channel\"][0][0][0][0]\n                except Exception:\n                    try:\n                        df[\"ripple_channel\"] = data[\"ripples\"][\"detectorinfo\"][0][0][\n                            \"detectionchannel1\"\n                        ][0][0][0][0]\n                    except Exception:\n                        df[\"ripple_channel\"] = np.nan\n\n    # remove flagged ripples, if exist\n    try:\n        df.drop(\n            labels=np.array(data[\"ripples\"][\"flagged\"][0][0]).T[0] - 1,\n            axis=0,\n            inplace=True,\n        )\n        df.reset_index(inplace=True)\n    except Exception:\n        pass\n\n    # adding manual events\n    if manual_events:\n        try:\n            df = _add_manual_events(df, data[\"ripples\"][\"added\"][0][0].T[0])\n        except Exception:\n            pass\n\n    # adding if ripples were restricted by spikes\n    dt = data[\"ripples\"].dtype\n    if \"eventSpikingParameters\" in dt.names:\n        df[\"event_spk_thres\"] = 1\n    else:\n        df[\"event_spk_thres\"] = 0\n\n    # get basename and animal\n    normalized_path = os.path.normpath(filename)\n    path_components = normalized_path.split(os.sep)\n    df[\"basepath\"] = basepath\n    df[\"basename\"] = path_components[-2]\n    df[\"animal\"] = path_components[-3]\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"ripples\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_spikes","title":"<code>load_spikes(basepath, putativeCellType=[], brainRegion=[], remove_bad_unit=True, brain_state=[], other_metric=None, other_metric_value=None, support=None, remove_unstable=False, stable_interval_width=600)</code>","text":"<p>Load specific cells' spike times.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <code>putativeCellType</code> <code>List[str]</code> <p>List of putative cell types to restrict spikes to, by default [].</p> <code>[]</code> <code>brainRegion</code> <code>List[str]</code> <p>List of brain regions to restrict spikes to, by default [].</p> <code>[]</code> <code>remove_bad_unit</code> <code>bool</code> <p>If True, do not load bad cells (tagged in CE), by default True.</p> <code>True</code> <code>brain_state</code> <code>List[str]</code> <p>List of brain states to restrict spikes to, by default [].</p> <code>[]</code> <code>other_metric</code> <code>Union[str, None]</code> <p>Metric to restrict spikes to, by default None.</p> <code>None</code> <code>other_metric_value</code> <code>Union[str, None]</code> <p>Value of the metric to restrict spikes to, by default None.</p> <code>None</code> <code>support</code> <code>Union[EpochArray, None]</code> <p>Time support to provide, by default None.</p> <code>None</code> <code>remove_unstable</code> <code>bool</code> <p>If True, remove unstable cells, by default False.</p> <code>False</code> <code>stable_interval_width</code> <code>int</code> <p>Width of the stable interval in seconds, by default 600.</p> <code>600</code> <p>Returns:</p> Type Description <code>Tuple[Union[SpikeTrainArray, None], Union[DataFrame, None]]</code> <p>Spike train array and cell metrics DataFrame.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_spikes(\n    basepath: str,\n    putativeCellType: List[str] = [],\n    brainRegion: List[str] = [],\n    remove_bad_unit: bool = True,\n    brain_state: List[str] = [],\n    other_metric: Union[str, None] = None,\n    other_metric_value: Union[str, None] = None,\n    support: Union[nel.EpochArray, None] = None,\n    remove_unstable: bool = False,\n    stable_interval_width: int = 600,\n) -&gt; Tuple[Union[nel.SpikeTrainArray, None], Union[pd.DataFrame, None]]:\n    \"\"\"\n    Load specific cells' spike times.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n    putativeCellType : List[str], optional\n        List of putative cell types to restrict spikes to, by default [].\n    brainRegion : List[str], optional\n        List of brain regions to restrict spikes to, by default [].\n    remove_bad_unit : bool, optional\n        If True, do not load bad cells (tagged in CE), by default True.\n    brain_state : List[str], optional\n        List of brain states to restrict spikes to, by default [].\n    other_metric : Union[str, None], optional\n        Metric to restrict spikes to, by default None.\n    other_metric_value : Union[str, None], optional\n        Value of the metric to restrict spikes to, by default None.\n    support : Union[nel.EpochArray, None], optional\n        Time support to provide, by default None.\n    remove_unstable : bool, optional\n        If True, remove unstable cells, by default False.\n    stable_interval_width : int, optional\n        Width of the stable interval in seconds, by default 600.\n\n    Returns\n    -------\n    Tuple[Union[nel.SpikeTrainArray, None], Union[pd.DataFrame, None]]\n        Spike train array and cell metrics DataFrame.\n    \"\"\"\n    if not isinstance(putativeCellType, list):\n        putativeCellType = [putativeCellType]\n    if not isinstance(brainRegion, list):\n        brainRegion = [brainRegion]\n\n    # get sample rate from session\n    fs_dat = load_extracellular_metadata(basepath).get(\"sr\", None)\n\n    if fs_dat is None:\n        return None, None\n\n    # load cell metrics and spike data\n    cell_metrics, data = load_cell_metrics(basepath)\n\n    if cell_metrics is None or data is None:\n        return None, None\n\n    # put spike data into array st\n    st = np.array(data[\"spikes\"], dtype=object)\n\n    # restrict cell metrics\n    if len(putativeCellType) &gt; 0:\n        restrict_idx = []\n        for cell_type in putativeCellType:\n            restrict_idx.append(\n                cell_metrics.putativeCellType.str.contains(cell_type).values\n            )\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if len(brainRegion) &gt; 0:\n        restrict_idx = []\n        for brain_region in brainRegion:\n            restrict_idx.append(\n                cell_metrics.brainRegion.str.contains(brain_region).values\n            )\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    # restrict cell metrics by arbitrary metric\n    if other_metric is not None:\n        # make other_metric_value a list if not already\n        if not isinstance(other_metric, list):\n            other_metric = [other_metric]\n        if not isinstance(other_metric_value, list):\n            other_metric_value = [other_metric_value]\n        # check that other_metric_value is the same length as other_metric\n        if len(other_metric) != len(other_metric_value):\n            raise ValueError(\n                \"other_metric and other_metric_value must be of same length\"\n            )\n\n        restrict_idx = []\n        for metric, value in zip(other_metric, other_metric_value):\n            restrict_idx.append(cell_metrics[metric].str.contains(value).values)\n        restrict_idx = np.any(restrict_idx, axis=0)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if remove_bad_unit:\n        # bad units will be tagged true, so only keep false values\n        restrict_idx = ~cell_metrics.bad_unit.values\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    if remove_unstable and len(st) &gt; 0:\n        starts = np.arange(\n            np.hstack(st).min(),\n            np.hstack(st).max() - stable_interval_width,\n            stable_interval_width,\n        )\n        stops = starts + stable_interval_width\n\n        bst = npy.process.count_in_interval(st, starts, stops, \"counts\")\n        if bst.shape[1] == 0:\n            restrict_idx = np.ones(len(st), dtype=bool)\n        else:\n            zero_intervals = np.sum(bst == 0, axis=1)\n            active_intervals = np.sum(bst &gt; 0, axis=1)\n            # allow for 1 unstable interval max, and require at least 2 active intervals\n            restrict_idx = (zero_intervals &lt; 2) &amp; (active_intervals &gt;= 2)\n        cell_metrics = cell_metrics[restrict_idx]\n        st = st[restrict_idx]\n\n    # get spike train array\n    try:\n        if support is not None:\n            st = nel.SpikeTrainArray(timestamps=st, fs=fs_dat, support=support)\n        else:\n            st = nel.SpikeTrainArray(timestamps=st, fs=fs_dat)\n    except Exception:  # if only single cell... should prob just skip session\n        if support is not None:\n            st = nel.SpikeTrainArray(timestamps=st[0], fs=fs_dat, support=support)\n        else:\n            st = nel.SpikeTrainArray(timestamps=st[0], fs=fs_dat)\n\n    if len(brain_state) &gt; 0:\n        # get brain states\n        brain_states = [\"WAKEstate\", \"NREMstate\", \"REMstate\", \"THETA\", \"nonTHETA\"]\n        if brain_state not in brain_states:\n            assert print(\"not correct brain state. Pick one\", brain_states)\n        else:\n            state_dict = load_SleepState_states(basepath)\n            state_epoch = nel.EpochArray(state_dict[brain_state])\n            st = st[state_epoch]\n\n    return st, cell_metrics\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_theta_cycles","title":"<code>load_theta_cycles(basepath, return_epoch_array=False)</code>","text":"<p>Load theta cycles calculated from auto_theta_cycles.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where thetacycles.events.mat is located.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, the output will be an EpochArray, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[DataFrame, EpochArray]</code> <p>DataFrame with the following fields: - start: start time of theta cycle - stop: end time of theta cycle - duration: theta cycle duration - center: center time of theta cycle - trough: trough time of theta cycle - theta_channel: the theta channel used for detection</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_theta_cycles(\n    basepath: str, return_epoch_array: bool = False\n) -&gt; Union[pd.DataFrame, nel.EpochArray]:\n    \"\"\"\n    Load theta cycles calculated from auto_theta_cycles.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where thetacycles.events.mat is located.\n    return_epoch_array : bool, optional\n        If True, the output will be an EpochArray, by default False.\n\n    Returns\n    -------\n    Union[pd.DataFrame, nel.EpochArray]\n        DataFrame with the following fields:\n        - start: start time of theta cycle\n        - stop: end time of theta cycle\n        - duration: theta cycle duration\n        - center: center time of theta cycle\n        - trough: trough time of theta cycle\n        - theta_channel: the theta channel used for detection\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".thetacycles.events.mat\"\n    )\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        if return_epoch_array:\n            return nel.EpochArray()\n        return pd.DataFrame()\n\n    data = sio.loadmat(filename, simplify_cells=True)\n    df = pd.DataFrame()\n    df[\"start\"] = data[\"thetacycles\"][\"timestamps\"][:, 0]\n    df[\"stop\"] = data[\"thetacycles\"][\"timestamps\"][:, 1]\n    df[\"duration\"] = data[\"thetacycles\"][\"duration\"]\n    df[\"center\"] = data[\"thetacycles\"][\"center\"]\n    df[\"trough\"] = data[\"thetacycles\"][\"peaks\"]\n    df[\"theta_channel\"] = data[\"thetacycles\"][\"detectorinfo\"][\"theta_channel\"]\n\n    if return_epoch_array:\n        return nel.EpochArray([np.array([df.start, df.stop]).T], label=\"theta_cycles\")\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_theta_rem_shift","title":"<code>load_theta_rem_shift(basepath)</code>","text":"<p>Load theta REM shift data from get_rem_shift.m.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to your session where theta_rem_shift.mat is located.</p> required <p>Returns:</p> Type Description <code>Tuple[DataFrame, dict]</code> <p>DataFrame with the following fields: - UID: unique identifier for each unit - circ_dist: circular distance - rem_shift: REM shift - non_rem_shift: non-REM shift - m_rem: mean phase locking value during REM - r_rem: resultant vector length during REM - k_rem: concentration parameter during REM - p_rem: p-value of phase locking during REM - mode_rem: mode of phase locking during REM - m_wake: mean phase locking value during wake - r_wake: resultant vector length during wake - k_wake: concentration parameter during wake - p_wake: p-value of phase locking during wake - mode_wake: mode of phase locking during wake</p> <code>dict</code> <p>Dictionary with phase distributions and spike phases for REM and wake states.</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_theta_rem_shift(basepath: str) -&gt; Tuple[pd.DataFrame, dict]:\n    \"\"\"\n    Load theta REM shift data from get_rem_shift.m.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to your session where theta_rem_shift.mat is located.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, dict]\n        DataFrame with the following fields:\n        - UID: unique identifier for each unit\n        - circ_dist: circular distance\n        - rem_shift: REM shift\n        - non_rem_shift: non-REM shift\n        - m_rem: mean phase locking value during REM\n        - r_rem: resultant vector length during REM\n        - k_rem: concentration parameter during REM\n        - p_rem: p-value of phase locking during REM\n        - mode_rem: mode of phase locking during REM\n        - m_wake: mean phase locking value during wake\n        - r_wake: resultant vector length during wake\n        - k_wake: concentration parameter during wake\n        - p_wake: p-value of phase locking during wake\n        - mode_wake: mode of phase locking during wake\n\n    dict\n        Dictionary with phase distributions and spike phases for REM and wake states.\n    \"\"\"\n    try:\n        filename = glob.glob(basepath + os.sep + \"*theta_rem_shift.mat\")[0]\n    except Exception:\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame(), np.nan\n\n    data = sio.loadmat(filename)\n\n    df = pd.DataFrame()\n\n    df[\"UID\"] = data[\"rem_shift_data\"][\"UID\"][0][0][0]\n    df[\"circ_dist\"] = data[\"rem_shift_data\"][\"circ_dist\"][0][0][0]\n    df[\"rem_shift\"] = data[\"rem_shift_data\"][\"rem_shift\"][0][0][0]\n    df[\"non_rem_shift\"] = data[\"rem_shift_data\"][\"non_rem_shift\"][0][0][0]\n\n    # rem metrics\n    df[\"m_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"m\"][0][0][0]\n    df[\"r_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"r\"][0][0][0]\n    df[\"k_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"k\"][0][0][0]\n    df[\"p_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][0][\n        0\n    ][\"p\"][0][0][0]\n    df[\"mode_rem\"] = data[\"rem_shift_data\"][\"PhaseLockingData_rem\"][0][0][\"phasestats\"][\n        0\n    ][0][\"mode\"][0][0][0]\n\n    # wake metrics\n    df[\"m_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"m\"][0][0][0]\n    df[\"r_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"r\"][0][0][0]\n    df[\"k_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"k\"][0][0][0]\n    df[\"p_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\"phasestats\"][\n        0\n    ][0][\"p\"][0][0][0]\n    df[\"mode_wake\"] = data[\"rem_shift_data\"][\"PhaseLockingData_wake\"][0][0][\n        \"phasestats\"\n    ][0][0][\"mode\"][0][0][0]\n\n    def get_distros(data, state):\n        return np.vstack(data[\"rem_shift_data\"][state][0][0][\"phasedistros\"][0][0].T)\n\n    def get_spikephases(data, state):\n        return data[\"rem_shift_data\"][state][0][0][\"spkphases\"][0][0][0]\n\n    # add to dictionary\n    data_dict = {\n        \"rem\": {\n            \"phasedistros\": get_distros(data, \"PhaseLockingData_rem\"),\n            \"spkphases\": get_spikephases(data, \"PhaseLockingData_rem\"),\n        },\n        \"wake\": {\n            \"phasedistros\": get_distros(data, \"PhaseLockingData_wake\"),\n            \"spkphases\": get_spikephases(data, \"PhaseLockingData_wake\"),\n        },\n    }\n\n    return df, data_dict\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.load_trials","title":"<code>load_trials(basepath)</code>","text":"<p>Loads trials from cell explorer basename.animal.behavior and stores in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session folder.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with the following fields: - startTime: start time of the trial, in seconds - stopTime: stop time of the trial, in seconds - trialsID: ID of the trial</p> References <p>https://cellexplorer.org/datastructure/data-structure-and-format/#behavior</p> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def load_trials(basepath: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads trials from cell explorer basename.animal.behavior and stores in a DataFrame.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session folder.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame with the following fields:\n        - startTime: start time of the trial, in seconds\n        - stopTime: stop time of the trial, in seconds\n        - trialsID: ID of the trial\n\n    References\n    ----------\n    https://cellexplorer.org/datastructure/data-structure-and-format/#behavior\n    \"\"\"\n\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".animal.behavior.mat\"\n    )\n\n    if not os.path.exists(filename):\n        warnings.warn(\"file does not exist\")\n        return pd.DataFrame()\n\n    # load file\n    data = sio.loadmat(filename, simplify_cells=True)\n    if \"trials\" not in data[\"behavior\"].keys():\n        warnings.warn(\"trials not found in file\")\n        return pd.DataFrame()\n\n    # current standard is\n    #   behavior.trials.*name of trial*.start\n    #   behavior.trials.*name of trial*.stop\n    if (\n        isinstance(data[\"behavior\"][\"trials\"], dict)\n        and \"starts\" in data[\"behavior\"][\"trials\"].keys()\n        and \"stops\" in data[\"behavior\"][\"trials\"].keys()\n    ):\n        df = pd.DataFrame(\n            data=np.array(\n                [\n                    data[\"behavior\"][\"trials\"][\"starts\"],\n                    data[\"behavior\"][\"trials\"][\"stops\"],\n                ]\n            ).T\n        )\n        df.columns = [\"startTime\", \"stopTime\"]\n        df[\"trialsID\"] = data[\"behavior\"][\"trials\"][\"stateName\"]\n\n    # old standard\n    #   behavior.trials.*[starts,stops]*\n    else:\n        # check if trials is empty\n        if len(data[\"behavior\"][\"trials\"]) == 0:\n            warnings.warn(\"trials is empty\")\n            return pd.DataFrame()\n        try:\n            df = pd.DataFrame(data=data[\"behavior\"][\"trials\"])\n            df.columns = [\"startTime\", \"stopTime\"]\n            # check if trialsID exists\n            if \"trialsID\" in data[\"behavior\"].keys():\n                df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n        except Exception:\n            df = pd.DataFrame(data=[data[\"behavior\"][\"trials\"]])\n            df.columns = [\"startTime\", \"stopTime\"]\n            # check if trialsID exists\n            if \"trialsID\" in data[\"behavior\"].keys():\n                if type(data[\"behavior\"][\"trialsID\"]) is str:\n                    df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n\n                elif len(data[\"behavior\"][\"trialsID\"]) == df.shape[0]:\n                    df[\"trialsID\"] = data[\"behavior\"][\"trialsID\"]\n                else:\n                    warnings.warn(\"trials or trialsID not correct shape\")\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/io/loading/#neuro_py.io.loading.writeNeuroscopeEvents","title":"<code>writeNeuroscopeEvents(path, ep, name)</code>","text":"<p>Write events to a Neuroscope-compatible file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the output file.</p> required <code>ep</code> <code>Any</code> <p>Epoch data containing start and end times.</p> required <code>name</code> <code>str</code> <p>Name of the event.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/io/loading.py</code> <pre><code>def writeNeuroscopeEvents(path: str, ep: Any, name: str) -&gt; None:\n    \"\"\"\n    Write events to a Neuroscope-compatible file.\n\n    Parameters\n    ----------\n    path : str\n        Path to the output file.\n    ep : Any\n        Epoch data containing start and end times.\n    name : str\n        Name of the event.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    f = open(path, \"w\")\n    for i in range(len(ep)):\n        f.writelines(\n            str(ep.as_units(\"ms\").iloc[i][\"start\"])\n            + \" \"\n            + name\n            + \" start \"\n            + str(1)\n            + \"\\n\"\n        )\n        # f.writelines(str(ep.as_units('ms').iloc[i]['peak']) + \" \"+name+\" start \"+ str(1)+\"\\n\")\n        f.writelines(\n            str(ep.as_units(\"ms\").iloc[i][\"end\"]) + \" \" + name + \" end \" + str(1) + \"\\n\"\n        )\n    f.close()\n</code></pre>"},{"location":"reference/neuro_py/io/saving/","title":"neuro_py.io.saving","text":""},{"location":"reference/neuro_py/io/saving/#neuro_py.io.saving.epoch_to_mat","title":"<code>epoch_to_mat(epoch, basepath, epoch_name, detection_name=None)</code>","text":"<p>Save an EpochArray to a .mat file in the Cell Explorer format.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>EpochArray to save.</p> required <code>basepath</code> <code>str</code> <p>Basepath to save the file to.</p> required <code>epoch_name</code> <code>str</code> <p>Name of the epoch.</p> required <code>detection_name</code> <code>Union[None, str]</code> <p>Name of the detection, by default None.</p> <code>None</code> Source code in <code>neuro_py/io/saving.py</code> <pre><code>def epoch_to_mat(\n    epoch: nel.EpochArray,\n    basepath: str,\n    epoch_name: str,\n    detection_name: Union[None, str] = None,\n) -&gt; None:\n    \"\"\"\n    Save an EpochArray to a .mat file in the Cell Explorer format.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        EpochArray to save.\n    basepath : str\n        Basepath to save the file to.\n    epoch_name : str\n        Name of the epoch.\n    detection_name : Union[None, str], optional\n        Name of the detection, by default None.\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + epoch_name + \".events.mat\"\n    )\n    data = {}\n    data[epoch_name] = {}\n\n    data[epoch_name][\"timestamps\"] = epoch.data\n\n    # check if only single epoch\n    if epoch.data.ndim == 1:\n        data[epoch_name][\"peaks\"] = np.median(epoch.data, axis=0)\n    else:\n        data[epoch_name][\"peaks\"] = np.median(epoch.data, axis=1)\n\n    data[epoch_name][\"amplitudes\"] = []\n    data[epoch_name][\"amplitudeUnits\"] = []\n    data[epoch_name][\"eventID\"] = []\n    data[epoch_name][\"eventIDlabels\"] = []\n    data[epoch_name][\"eventIDbinary\"] = []\n\n    # check if only single epoch\n    if epoch.data.ndim == 1:\n        data[epoch_name][\"duration\"] = epoch.data[1] - epoch.data[0]\n    else:\n        data[epoch_name][\"duration\"] = epoch.durations\n\n    data[epoch_name][\"center\"] = data[epoch_name][\"peaks\"]\n    data[epoch_name][\"detectorinfo\"] = {}\n    if detection_name is None:\n        data[epoch_name][\"detectorinfo\"][\"detectorname\"] = []\n    else:\n        data[epoch_name][\"detectorinfo\"][\"detectorname\"] = detection_name\n    data[epoch_name][\"detectorinfo\"][\"detectionparms\"] = []\n    data[epoch_name][\"detectorinfo\"][\"detectionintervals\"] = []\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/lfp/","title":"neuro_py.lfp","text":""},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.clean_lfp","title":"<code>clean_lfp(lfp, t=None, thresholds=(5, 10), artifact_time_expand=(0.25, 0.1), return_bad_intervals=False)</code>","text":"<p>Remove artefacts and noise from a local field potential (LFP) signal.</p> <p>Parameters:</p> Name Type Description Default <code>lfp</code> <code>AnalogSignalArray</code> <p>The LFP signal to be cleaned. Single signal only.</p> required <code>thresholds</code> <code>tuple of float</code> <p>A tuple of two thresholds for detecting artefacts and noise. The first threshold is used to detect large global artefacts by finding values in the z-scored LFP signal that deviate by more than the threshold number of sigmas from the mean. The second threshold is used to detect noise by finding values in the derivative of the z-scored LFP signal that are greater than the threshold. Default is (5, 10).</p> <code>(5, 10)</code> <code>artifact_time_expand</code> <code>tuple of float</code> <p>A tuple of two time intervals around detected artefacts and noise. The first interval is used to expand the detected large global artefacts. The second interval is used to expand the detected noise. Default is (0.25, 0.1).</p> <code>(0.25, 0.1)</code> <code>return_bad_intervals</code> <code>bool</code> <p>If True, also returns intervals of artefacts and noise as an <code>nel.EpochArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tuple[ndarray, EpochArray]]</code> <p>The cleaned LFP signal. If <code>return_bad_intervals</code> is True, also returns an <code>nel.EpochArray</code> representing the intervals of artefacts and noise.</p> Notes <p>Based on https://github.com/ayalab1/neurocode/blob/master/lfp/CleanLFP.m by Ralitsa Todorova</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lfp = nel.AnalogSignalArray(data=np.random.randn(1250), timestamps=np.arange(1250)/1250)\n&gt;&gt;&gt; clean_lfp(lfp)\narray([-1.73104885,  1.08192036,  1.40332741, ..., -2.78671212,\n    -1.63661574, -1.10868426])\n</code></pre> Source code in <code>neuro_py/lfp/preprocessing.py</code> <pre><code>def clean_lfp(\n    lfp: Union[nel.AnalogSignalArray, np.ndarray],\n    t: np.ndarray = None,\n    thresholds: Tuple[float, float] = (5, 10),\n    artifact_time_expand: Tuple[float, float] = (0.25, 0.1),\n    return_bad_intervals: bool = False,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, nel.EpochArray]]:\n    \"\"\"\n    Remove artefacts and noise from a local field potential (LFP) signal.\n\n    Parameters\n    ----------\n    lfp : nel.AnalogSignalArray\n        The LFP signal to be cleaned. Single signal only.\n    thresholds : tuple of float, optional\n        A tuple of two thresholds for detecting artefacts and noise. The first threshold is used to detect large global\n        artefacts by finding values in the z-scored LFP signal that deviate by more than the threshold number of sigmas\n        from the mean. The second threshold is used to detect noise by finding values in the derivative of the z-scored\n        LFP signal that are greater than the threshold. Default is (5, 10).\n    artifact_time_expand : tuple of float, optional\n        A tuple of two time intervals around detected artefacts and noise. The first interval is used to expand the detected\n        large global artefacts. The second interval is used to expand the detected noise. Default is (0.25, 0.1).\n    return_bad_intervals : bool, optional\n        If True, also returns intervals of artefacts and noise as an `nel.EpochArray`. Default is False.\n\n    Returns\n    -------\n    Union[np.ndarray, Tuple[np.ndarray, nel.EpochArray]]\n        The cleaned LFP signal. If `return_bad_intervals` is True, also returns an `nel.EpochArray`\n        representing the intervals of artefacts and noise.\n\n    Notes\n    -----\n    Based on https://github.com/ayalab1/neurocode/blob/master/lfp/CleanLFP.m by Ralitsa Todorova\n\n    Examples\n    --------\n    &gt;&gt;&gt; lfp = nel.AnalogSignalArray(data=np.random.randn(1250), timestamps=np.arange(1250)/1250)\n    &gt;&gt;&gt; clean_lfp(lfp)\n    array([-1.73104885,  1.08192036,  1.40332741, ..., -2.78671212,\n        -1.63661574, -1.10868426])\n    \"\"\"\n    threshold1 = thresholds[0]  # in sigmas deviating from the mean\n    aroundArtefact1 = artifact_time_expand[\n        0\n    ]  # interval to expand large global artefacts\n\n    threshold2 = thresholds[1]  # for derivative of z-scored signal\n    aroundArtefact2 = artifact_time_expand[1]  # interval to expand detected noise\n\n    if isinstance(lfp, nel.AnalogSignalArray):\n        t = lfp.time  # time points of LFP signal\n        values = lfp.copy().data.flatten()  # values of LFP signal\n        z = lfp.zscore().data.flatten()  # z-scored values of LFP signal\n    elif isinstance(lfp, np.ndarray):\n        if t is None:\n            raise ValueError(\"t must be provided when lfp is np.ndarray\")\n        values = lfp.flatten()\n        z = (values - np.mean(values)) / np.std(values)\n    else:\n        raise ValueError(\"lfp must be nel.AnalogSignalArray or np.ndarray\")\n\n    d = np.append(np.diff(z), 0)  # derivative of z-scored LFP signal\n\n    # Detect large global artefacts [0]\n    artefactInterval = t[\n        np.array(intervals.find_interval(np.abs(z) &gt; threshold1), dtype=int)\n    ]\n    artefactInterval = nel.EpochArray(artefactInterval)\n    if not artefactInterval.isempty:\n        artefactInterval = artefactInterval.expand(aroundArtefact1)\n\n    # Find noise using the derivative of the z-scored signal [1]\n    noisyInterval = t[\n        np.array(intervals.find_interval(np.abs(d) &gt; threshold2), dtype=int)\n    ]\n    noisyInterval = nel.EpochArray(noisyInterval)\n    if not noisyInterval.isempty:\n        noisyInterval = noisyInterval.expand(aroundArtefact2)\n\n    # Combine intervals for artefacts and noise\n    bad = (artefactInterval | noisyInterval).merge()\n\n    if bad.isempty:\n        return values\n\n    # Find timestamps within intervals for artefacts and noise\n    in_interval = intervals.in_intervals(t, bad.data)\n\n    # Interpolate values for timestamps within intervals for artefacts and noise\n    values[in_interval] = np.interp(\n        t[in_interval], t[~in_interval], values[~in_interval]\n    )\n\n    return (values, bad) if return_bad_intervals else values\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.event_triggered_wavelet","title":"<code>event_triggered_wavelet(signal, timestamps, events, max_lag=1, freq_min=4, freq_max=100, freq_step=4, return_pandas=False, parallel=True, whiten=True, whiten_order=2, fs=None, **kwargs)</code>","text":"<p>Compute the event-triggered wavelet transform of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>1d array</code> <p>Time series.</p> required <code>timestamps</code> <code>1d array</code> <p>Time points for each sample in the signal.</p> required <code>events</code> <code>1d array</code> <p>Time points of events.</p> required <code>max_lag</code> <code>float</code> <p>Maximum lag to consider, in seconds.</p> <code>1</code> <code>freq_min</code> <code>float</code> <p>Minimum frequency to consider, in Hz.</p> <code>4</code> <code>freq_max</code> <code>float</code> <p>Maximum frequency to consider, in Hz.</p> <code>100</code> <code>freq_step</code> <code>float</code> <p>Step size for frequency range, in Hz.</p> <code>4</code> <code>return_pandas</code> <code>bool</code> <p>If True, return the output as pandas objects.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>If True, use parallel processing to compute the wavelet transform.</p> <code>True</code> <code>whiten</code> <code>bool</code> <p>If True, whiten the signal before computing the wavelet transform.</p> <code>True</code> <code>whiten_order</code> <code>int</code> <p>Order of the autoregressive model used for whitening.</p> <code>2</code> <code>fs</code> <code>float</code> <p>Sampling rate, in Hz.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments to pass to <code>compute_wavelet_transform</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>mwt</code> <code>2d array</code> <p>Time frequency representation of the input signal.</p> <code>sigs</code> <code>1d array</code> <p>Average signal.</p> <code>times</code> <code>1d array</code> <p>Time points for each sample in the output.</p> <code>freqs</code> <code>1d array</code> <p>Frequencies used in the wavelet transform.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.lfp.spectral import event_triggered_wavelet\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_34_20240503\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load lfp\n&gt;&gt;&gt; nChannels, fs, _, _ = loading.loadXML(basepath)\n&gt;&gt;&gt; # Load the LFP data\n&gt;&gt;&gt; lfp, ts = loading.loadLFP(basepath, n_channels=nChannels,\n&gt;&gt;&gt;                channel=23,\n&gt;&gt;&gt;                frequency=fs)\n&gt;&gt;&gt; # load events\n&gt;&gt;&gt; opto = loading.load_events(basepath, epoch_name=\"optoStim\")\n&gt;&gt;&gt; opto = opto.merge(gap=.1)\n</code></pre> <pre><code>&gt;&gt;&gt; # compute event triggered averate\n&gt;&gt;&gt; mwt, sigs, times, freqs = event_triggered_wavelet(\n&gt;&gt;&gt;    lfp,\n&gt;&gt;&gt;    ts,\n&gt;&gt;&gt;    opto.starts,\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; # plot\n&gt;&gt;&gt; plt.figure(figsize=set_size(\"thesis\", fraction=1, subplots=(1, 1)))\n</code></pre> <pre><code>&gt;&gt;&gt; im = plt.imshow(\n&gt;&gt;&gt;     abs(mwt),\n&gt;&gt;&gt;     aspect=\"auto\",\n&gt;&gt;&gt;     extent=[times[0], times[-1], freqs[-1], freqs[0]],\n&gt;&gt;&gt;     cmap=\"magma\",\n&gt;&gt;&gt;     vmax=600,\n&gt;&gt;&gt;     vmin=50,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; plt.axhline(23, color=\"orange\", linestyle=\"--\", label=\"23hz\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.yscale(\"log\")\n&gt;&gt;&gt; # move legend outside of plot\n&gt;&gt;&gt; plt.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1), frameon=False)\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().invert_yaxis()\n</code></pre> <pre><code>&gt;&gt;&gt; plt.colorbar(location=\"top\", label=\"Power (uV^2)\")\n&gt;&gt;&gt; # move colorbar more to the left\n&gt;&gt;&gt; plt.gcf().axes[1].set_position([0.5, 0.8, 0.4, 0.6])\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().set_ylabel(\"Frequency (Hz)\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().set_xlabel(\"Time from opto stim (s)\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.twinx()\n&gt;&gt;&gt; plt.yscale(\"linear\")\n&gt;&gt;&gt; plt.axvline(0, color=\"k\", linestyle=\"--\")\n&gt;&gt;&gt; plt.axvline(0.5, color=\"k\", linestyle=\"--\")\n&gt;&gt;&gt; plt.plot(times, sigs, \"w\", linewidth=0.5)\n</code></pre> <pre><code>&gt;&gt;&gt; # plt.gca().set_xlabel('Time (s)')\n&gt;&gt;&gt; plt.gca().set_ylabel(\"Voltage (uV)\")\n&gt;&gt;&gt; plt.gca().set_title(\"PFC during 23Hz stim in behavior\", y=1)\n</code></pre> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def event_triggered_wavelet(\n    signal: np.ndarray,\n    timestamps: np.ndarray,\n    events: np.ndarray,\n    max_lag: float = 1,\n    freq_min: float = 4,\n    freq_max: float = 100,\n    freq_step: float = 4,\n    return_pandas: bool = False,\n    parallel: bool = True,\n    whiten: bool = True,\n    whiten_order: int = 2,\n    fs: Optional[float] = None,\n    **kwargs,\n) -&gt; Union[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    Tuple[pd.DataFrame, pd.Series],\n]:\n    \"\"\"\n    Compute the event-triggered wavelet transform of a signal.\n\n    Parameters\n    ----------\n    signal : 1d array\n        Time series.\n    timestamps : 1d array\n        Time points for each sample in the signal.\n    events : 1d array\n        Time points of events.\n    max_lag : float\n        Maximum lag to consider, in seconds.\n    freq_min : float\n        Minimum frequency to consider, in Hz.\n    freq_max : float\n        Maximum frequency to consider, in Hz.\n    freq_step : float\n        Step size for frequency range, in Hz.\n    return_pandas : bool\n        If True, return the output as pandas objects.\n    parallel : bool\n        If True, use parallel processing to compute the wavelet transform.\n    whiten : bool\n        If True, whiten the signal before computing the wavelet transform.\n    whiten_order : int\n        Order of the autoregressive model used for whitening.\n    fs : float\n        Sampling rate, in Hz.\n    kwargs\n        Additional keyword arguments to pass to `compute_wavelet_transform`.\n\n    Returns\n    -------\n    mwt : 2d array\n        Time frequency representation of the input signal.\n    sigs : 1d array\n        Average signal.\n    times : 1d array\n        Time points for each sample in the output.\n    freqs : 1d array\n        Frequencies used in the wavelet transform.\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.lfp.spectral import event_triggered_wavelet\n\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\hpc_ctx_project\\\\HP04\\\\day_34_20240503\"\n\n    &gt;&gt;&gt; # load lfp\n    &gt;&gt;&gt; nChannels, fs, _, _ = loading.loadXML(basepath)\n    &gt;&gt;&gt; # Load the LFP data\n    &gt;&gt;&gt; lfp, ts = loading.loadLFP(basepath, n_channels=nChannels,\n    &gt;&gt;&gt;                channel=23,\n    &gt;&gt;&gt;                frequency=fs)\n    &gt;&gt;&gt; # load events\n    &gt;&gt;&gt; opto = loading.load_events(basepath, epoch_name=\"optoStim\")\n    &gt;&gt;&gt; opto = opto.merge(gap=.1)\n\n    &gt;&gt;&gt; # compute event triggered averate\n    &gt;&gt;&gt; mwt, sigs, times, freqs = event_triggered_wavelet(\n    &gt;&gt;&gt;    lfp,\n    &gt;&gt;&gt;    ts,\n    &gt;&gt;&gt;    opto.starts,\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; # plot\n    &gt;&gt;&gt; plt.figure(figsize=set_size(\"thesis\", fraction=1, subplots=(1, 1)))\n\n    &gt;&gt;&gt; im = plt.imshow(\n    &gt;&gt;&gt;     abs(mwt),\n    &gt;&gt;&gt;     aspect=\"auto\",\n    &gt;&gt;&gt;     extent=[times[0], times[-1], freqs[-1], freqs[0]],\n    &gt;&gt;&gt;     cmap=\"magma\",\n    &gt;&gt;&gt;     vmax=600,\n    &gt;&gt;&gt;     vmin=50,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; plt.axhline(23, color=\"orange\", linestyle=\"--\", label=\"23hz\")\n\n    &gt;&gt;&gt; plt.yscale(\"log\")\n    &gt;&gt;&gt; # move legend outside of plot\n    &gt;&gt;&gt; plt.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1), frameon=False)\n\n    &gt;&gt;&gt; plt.gca().invert_yaxis()\n\n    &gt;&gt;&gt; plt.colorbar(location=\"top\", label=\"Power (uV^2)\")\n    &gt;&gt;&gt; # move colorbar more to the left\n    &gt;&gt;&gt; plt.gcf().axes[1].set_position([0.5, 0.8, 0.4, 0.6])\n\n\n    &gt;&gt;&gt; plt.gca().set_ylabel(\"Frequency (Hz)\")\n\n    &gt;&gt;&gt; plt.gca().set_xlabel(\"Time from opto stim (s)\")\n\n    &gt;&gt;&gt; plt.twinx()\n    &gt;&gt;&gt; plt.yscale(\"linear\")\n    &gt;&gt;&gt; plt.axvline(0, color=\"k\", linestyle=\"--\")\n    &gt;&gt;&gt; plt.axvline(0.5, color=\"k\", linestyle=\"--\")\n    &gt;&gt;&gt; plt.plot(times, sigs, \"w\", linewidth=0.5)\n\n\n    &gt;&gt;&gt; # plt.gca().set_xlabel('Time (s)')\n    &gt;&gt;&gt; plt.gca().set_ylabel(\"Voltage (uV)\")\n    &gt;&gt;&gt; plt.gca().set_title(\"PFC during 23Hz stim in behavior\", y=1)\n    \"\"\"\n\n    signal_ = signal.copy()\n    if whiten:\n        signal_ = whiten_lfp(signal, order=whiten_order)\n\n    # set up frequency range\n    freqs = np.arange(freq_min, freq_max, freq_step)\n    # set up time range\n    if fs is None:\n        ds = timestamps[1] - timestamps[0]\n        fs = 1 / ds\n    # Create times array based on the sample rate (fs)\n    times = np.arange(-max_lag, max_lag, 1 / fs)\n    # Number of samples corresponding to the time window around each event\n    n_samples = int(max_lag * 2 * fs)\n\n    # Ensure the length of times matches n_samples\n    if len(times) != n_samples:\n        times = np.linspace(-max_lag, max_lag, n_samples)\n\n    n_freqs = len(freqs)\n    n_samples = len(times)\n\n    # set up mwt and sigs to store results\n    mwt = np.zeros((n_freqs, n_samples))\n    sigs = np.zeros(n_samples)\n\n    event_i = 0\n\n    def process_event(start):\n        nonlocal event_i\n        nonlocal mwt\n        nonlocal sigs\n\n        if start + max_lag &gt; timestamps.max() or start - max_lag &lt; timestamps.min():\n            return None, None\n\n        idx = (timestamps &gt;= start - max_lag) &amp; (timestamps &lt;= start + max_lag)\n\n        mwt_partial = np.abs(\n            compute_wavelet_transform(sig=signal_[idx], fs=fs, freqs=freqs, **kwargs)\n        )\n\n        return mwt_partial, signal[idx]\n\n    if parallel:\n        with ThreadPoolExecutor() as executor:\n            results = list(executor.map(process_event, events))\n\n        for mwt_partial, sig_partial in results:\n            if mwt_partial is not None:\n                # samples might be missing if the event is too close to the edge\n                if mwt_partial.shape[1] != n_samples:\n                    continue\n                mwt += mwt_partial\n                sigs += sig_partial\n                event_i += 1\n    else:\n        for start in events:\n            mwt_partial, sig_partial = process_event(start)\n            if mwt_partial is not None:\n                mwt += mwt_partial\n                sigs += sig_partial\n                event_i += 1\n\n    mwt /= event_i\n    sigs /= event_i\n\n    if return_pandas:\n        mwt = pd.DataFrame(mwt.T, index=times, columns=freqs)\n        sigs = pd.Series(sigs, index=times)\n        return mwt, sigs\n    else:\n        return mwt, sigs, times, freqs\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.filter_signal","title":"<code>filter_signal(sig, fs, pass_type, f_range, filter_type='fir', n_cycles=3, n_seconds=None, butterworth_order=4, remove_edges=True)</code>","text":"<p>Filter a neural signal using an FIR or IIR filter.</p> <p>Parameters:</p> Name Type Description Default <code>sig</code> <code>ndarray</code> <p>Time series to be filtered. N signals x M samples array.</p> required <code>fs</code> <code>float</code> <p>Sampling rate, in Hz.</p> required <code>pass_type</code> <code>(bandpass, bandstop, lowpass, highpass)</code> <p>Type of filter to apply.</p> <code>'bandpass'</code> <code>f_range</code> <code>float or tuple of float</code> <p>Frequency range for filtering. For 'lowpass' and 'highpass', a single float can be provided. For 'bandpass' and 'bandstop', a tuple specifying (f_low, f_high) is required.</p> required <code>filter_type</code> <code>(fir, iir)</code> <p>Type of filter to apply: 'fir' for FIR or 'iir' for IIR (Butterworth). Default is 'fir'.</p> <code>'fir'</code> <code>n_cycles</code> <code>int</code> <p>Number of cycles to define the kernel length for FIR filters. Default is 3.</p> <code>3</code> <code>n_seconds</code> <code>float</code> <p>Length of the FIR filter in seconds. Overrides <code>n_cycles</code> if specified. Ignored for IIR.</p> <code>None</code> <code>butterworth_order</code> <code>int</code> <p>Order of the Butterworth filter. Only applies to IIR filters. Default is 4.</p> <code>4</code> <code>remove_edges</code> <code>bool</code> <p>If True, replace samples within half the kernel length with NaN (FIR filters only). Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series.</p> <p>Examples:</p> <p>Apply a lowpass FIR filter to a signal:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; from your_module import filter_signal\n&gt;&gt;&gt; fs = 1000  # Sampling rate (Hz)\n&gt;&gt;&gt; t = np.linspace(0, 1, fs, endpoint=False)\n&gt;&gt;&gt; sig = np.sin(2 * np.pi * 1 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)  # Signal with 1Hz and 50Hz components\n&gt;&gt;&gt; pass_type = 'lowpass'\n&gt;&gt;&gt; f_range = 10  # Lowpass filter at 10 Hz\n&gt;&gt;&gt; filt_sig = filter_signal(sig, fs, pass_type, f_range, filter_type='fir')\n&gt;&gt;&gt; plt.plot(t, sig, label='Original Signal')\n&gt;&gt;&gt; plt.plot(t, filt_sig, label='Filtered Signal')\n&gt;&gt;&gt; plt.legend()\n&gt;&gt;&gt; plt.show()\n</code></pre> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def filter_signal(\n    sig: np.ndarray,\n    fs: float,\n    pass_type: str,\n    f_range: Union[float, Tuple[float, float]],\n    filter_type: str = \"fir\",\n    n_cycles: int = 3,\n    n_seconds: Optional[float] = None,\n    butterworth_order: int = 4,\n    remove_edges: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"\n    Filter a neural signal using an FIR or IIR filter.\n\n    Parameters\n    ----------\n    sig : np.ndarray\n        Time series to be filtered. N signals x M samples array.\n    fs : float\n        Sampling rate, in Hz.\n    pass_type : {'bandpass', 'bandstop', 'lowpass', 'highpass'}\n        Type of filter to apply.\n    f_range : float or tuple of float\n        Frequency range for filtering. For 'lowpass' and 'highpass', a single float can be provided.\n        For 'bandpass' and 'bandstop', a tuple specifying (f_low, f_high) is required.\n    filter_type : {'fir', 'iir'}, optional\n        Type of filter to apply: 'fir' for FIR or 'iir' for IIR (Butterworth). Default is 'fir'.\n    n_cycles : int, optional\n        Number of cycles to define the kernel length for FIR filters. Default is 3.\n    n_seconds : float, optional\n        Length of the FIR filter in seconds. Overrides `n_cycles` if specified. Ignored for IIR.\n    butterworth_order : int, optional\n        Order of the Butterworth filter. Only applies to IIR filters. Default is 4.\n    remove_edges : bool, optional\n        If True, replace samples within half the kernel length with NaN (FIR filters only). Default is True.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered time series.\n\n    Examples\n    --------\n    Apply a lowpass FIR filter to a signal:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; from your_module import filter_signal\n    &gt;&gt;&gt; fs = 1000  # Sampling rate (Hz)\n    &gt;&gt;&gt; t = np.linspace(0, 1, fs, endpoint=False)\n    &gt;&gt;&gt; sig = np.sin(2 * np.pi * 1 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)  # Signal with 1Hz and 50Hz components\n    &gt;&gt;&gt; pass_type = 'lowpass'\n    &gt;&gt;&gt; f_range = 10  # Lowpass filter at 10 Hz\n    &gt;&gt;&gt; filt_sig = filter_signal(sig, fs, pass_type, f_range, filter_type='fir')\n    &gt;&gt;&gt; plt.plot(t, sig, label='Original Signal')\n    &gt;&gt;&gt; plt.plot(t, filt_sig, label='Filtered Signal')\n    &gt;&gt;&gt; plt.legend()\n    &gt;&gt;&gt; plt.show()\n    \"\"\"\n\n    # Validate pass_type\n    if pass_type not in [\"bandpass\", \"bandstop\", \"lowpass\", \"highpass\"]:\n        raise ValueError(\n            \"`pass_type` must be one of: 'bandpass', 'bandstop', 'lowpass', 'highpass'.\"\n        )\n\n    # Ensure `f_range` is properly defined for the filter type\n    if isinstance(f_range, (int, float)):\n        if pass_type == \"lowpass\":\n            f_range = (None, f_range)  # Convert single value to tuple for lowpass\n        elif pass_type == \"highpass\":\n            f_range = (f_range, None)  # Convert single value to tuple for highpass\n        else:\n            raise ValueError(\n                \"`f_range` must be a tuple for 'bandpass' or 'bandstop' filters.\"\n            )\n\n    # Validate bandpass/bandstop filters\n    if pass_type in [\"bandpass\", \"bandstop\"]:\n        if not isinstance(f_range, tuple) or f_range[0] is None or f_range[1] is None:\n            raise ValueError(\n                \"Both frequencies must be specified for 'bandpass' and 'bandstop' filters.\"\n            )\n\n    # Nyquist frequency\n    nyquist = fs / 2\n\n    # FIR filter implementation\n    if filter_type == \"fir\":\n        # Compute filter kernel length\n        if n_seconds is not None:\n            kernel_len = int(n_seconds * fs)\n        else:\n            kernel_len = (\n                int((n_cycles / f_range[0]) * fs)\n                if f_range[0]\n                else int((n_cycles / f_range[1]) * fs)\n            )\n        if kernel_len % 2 == 0:\n            kernel_len += 1  # Ensure kernel length is odd\n\n        # Define FIR filter coefficients\n        if pass_type in [\"bandpass\", \"bandstop\"]:\n            fir_coefs = firwin(\n                kernel_len,\n                [f_range[0] / nyquist, f_range[1] / nyquist],\n                pass_zero=(pass_type == \"bandstop\"),\n            )\n        elif pass_type == \"lowpass\":\n            fir_coefs = firwin(kernel_len, f_range[1] / nyquist, pass_zero=True)\n        elif pass_type == \"highpass\":\n            fir_coefs = firwin(kernel_len, f_range[0] / nyquist, pass_zero=False)\n\n        # Apply the FIR filter\n        if len(sig.shape) == 1:\n            sig_filt = np.convolve(sig, fir_coefs, mode=\"same\")\n        else:\n            sig_filt = np.vstack(\n                [np.convolve(sig_, fir_coefs, mode=\"same\") for sig_ in sig]\n            )\n\n    # IIR filter implementation\n    elif filter_type == \"iir\":\n        # Design a Butterworth filter\n        if pass_type in [\"bandpass\", \"bandstop\"]:\n            b, a = butter(\n                butterworth_order,\n                [f_range[0] / nyquist, f_range[1] / nyquist],\n                btype=pass_type,\n            )\n        elif pass_type == \"lowpass\":\n            b, a = butter(butterworth_order, f_range[1] / nyquist, btype=\"low\")\n        elif pass_type == \"highpass\":\n            b, a = butter(butterworth_order, f_range[0] / nyquist, btype=\"high\")\n\n        # Apply the IIR filter\n        sig_filt = filtfilt(b, a, sig)\n\n    else:\n        raise ValueError(\"`filter_type` must be 'fir' or 'iir'.\")\n\n    # Optionally remove edges\n    if remove_edges and filter_type == \"fir\":\n        edge_len = kernel_len // 2\n        sig_filt[:edge_len] = np.nan\n        sig_filt[-edge_len:] = np.nan\n\n    return sig_filt\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.get_coords","title":"<code>get_coords(basepath, shank=0)</code>","text":"<p>Get the coordinates of the channels from the probe layout.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the basepath.</p> required <code>shank</code> <code>int</code> <p>Shank to get the coordinates from, by default 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates of the channels.</p> Source code in <code>neuro_py/lfp/CSD.py</code> <pre><code>def get_coords(basepath: str, shank: int = 0) -&gt; np.ndarray:\n    \"\"\"\n    Get the coordinates of the channels from the probe layout.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the basepath.\n    shank : int, optional\n        Shank to get the coordinates from, by default 0.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates of the channels.\n    \"\"\"\n    import quantities as pq\n\n    # load the probe layout\n    probe_layout = loading.load_probe_layout(basepath)\n\n    # get the coordinates of the channels\n    coords = probe_layout.loc[shank == probe_layout.shank, \"y\"].values\n\n    # rescale the coordinates so none are negative and in mm\n    rescaled_coords = (coords - coords.min()) * pq.mm\n\n    # add dimension to coords to make it (nchannels,1)\n    rescaled_coords = rescaled_coords[:, np.newaxis]\n\n    return rescaled_coords\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.get_csd","title":"<code>get_csd(basepath, data, shank, fs=1250, diam=0.015, method='DeltaiCSD', channel_offset=0.046)</code>","text":"<p>compute the CSD for a given basepath and data using elephant estimate_csd.</p> <p>Klas H. Pettersen, Anna Devor, Istvan Ulbert, Anders M. Dale, Gaute T. Einevoll, Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities, Journal of Neuroscience Methods, Volume 154, Issues 1-2, 30 June 2006, Pages 116-133, ISSN 0165-0270, http://dx.doi.org/10.1016/j.jneumeth.2005.12.005.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>path to the basepath</p> required <code>data</code> <code>array</code> <p>data to compute the CSD on [channels x time]</p> required <code>fs</code> <code>int</code> <p>sampling rate of the data, by default 1250 Hz</p> <code>1250</code> <code>diam</code> <code>float</code> <p>diameter of the electrode, by default 0.015 mm</p> <code>0.015</code> <code>method</code> <code>str</code> <p>method to compute the CSD, by default 'DeltaiCSD'</p> <code>'DeltaiCSD'</code> <p>Returns:</p> Type Description <code>AnalogSignal</code> <p>CSD signal</p> Dependencies <p>get_coords, estimate_csd (Elephant), neo, quantities</p> Source code in <code>neuro_py/lfp/CSD.py</code> <pre><code>def get_csd(\n    basepath, data, shank, fs=1250, diam=0.015, method=\"DeltaiCSD\", channel_offset=0.046\n):\n    \"\"\"\n    compute the CSD for a given basepath and data using elephant estimate_csd.\n\n    Klas H. Pettersen, Anna Devor, Istvan Ulbert, Anders M. Dale, Gaute T. Einevoll,\n    Current-source density estimation based on inversion of electrostatic forward\n    solution: Effects of finite extent of neuronal activity and conductivity\n    discontinuities, Journal of Neuroscience Methods, Volume 154, Issues 1-2,\n    30 June 2006, Pages 116-133, ISSN 0165-0270,\n    http://dx.doi.org/10.1016/j.jneumeth.2005.12.005.\n\n    Parameters\n    ----------\n    basepath : str\n        path to the basepath\n    data : np.array\n        data to compute the CSD on [channels x time]\n    fs : int, optional\n        sampling rate of the data, by default 1250 Hz\n    diam : float, optional\n        diameter of the electrode, by default 0.015 mm\n    method : str, optional\n        method to compute the CSD, by default 'DeltaiCSD'\n\n    Returns\n    -------\n    neo.AnalogSignal\n        CSD signal\n\n    Dependencies\n    ------------\n    get_coords, estimate_csd (Elephant), neo, quantities\n\n    \"\"\"\n    import quantities as pq\n    from elephant.current_source_density import estimate_csd\n    from neo import AnalogSignal\n\n    coords = get_coords(basepath, shank=shank)\n\n    signal = AnalogSignal(\n        data,\n        units=\"mV\",\n        t_start=0 * pq.s,\n        sampling_rate=fs * pq.Hz,\n        dtype=float,\n    )\n\n    if method == \"DeltaiCSD\":\n        csd = estimate_csd(signal, coordinates=coords, diam=diam * pq.mm, method=method)\n\n    elif method == \"StandardCSD\":\n        # create coordinates for the CSD\n        coords = np.zeros(data.shape[1])\n        for idx, i in enumerate(coords):\n            if idx == 0:\n                coords[idx] = 0\n            else:\n                coords[idx] = coords[idx - 1] + channel_offset\n\n        coords = coords * pq.mm\n\n        # add dimension to coords to make it (64,1)\n        coords = coords[:, np.newaxis]\n\n        csd = estimate_csd(signal, coordinates=coords, method=method)\n\n    elif method == \"KD1CSD\":\n        # create coordinates for the CSD\n        coords = np.zeros(data.shape[1])\n        for idx, i in enumerate(coords):\n            if idx == 0:\n                coords[idx] = 0\n            else:\n                coords[idx] = coords[idx - 1] + channel_offset\n\n        coords = coords * pq.mm\n\n        # add dimension to coords to make it (64,1)\n        coords = coords[:, np.newaxis]\n        csd = estimate_csd(signal, coordinates=coords, method=method)\n\n    return csd\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.get_theta_channel","title":"<code>get_theta_channel(basepath, tag='CA1so')</code>","text":"<p>Get the theta channel for the specified brain region. First looks in channel_tags, then in brain regions. If not found or all channels are bad, returns None.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading data.</p> required <code>tag</code> <code>str</code> <p>The tag identifying the brain region. Default is \"CA1so\".</p> <code>'CA1so'</code> <p>Returns:</p> Type Description <code>int or None</code> <p>The index of the theta channel (0-based), or None if not found or all channels are bad.</p> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def get_theta_channel(basepath: str, tag: str = \"CA1so\") -&gt; Optional[int]:\n    \"\"\"\n    Get the theta channel for the specified brain region. First looks in channel_tags, then in brain regions.\n    If not found or all channels are bad, returns None.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading data.\n    tag : str, optional\n        The tag identifying the brain region. Default is \"CA1so\".\n\n    Returns\n    -------\n    int or None\n        The index of the theta channel (0-based), or None if not found or all channels are bad.\n    \"\"\"\n    brain_region = loading.load_brain_regions(basepath)\n    channel_tags = loading.load_channel_tags(basepath)\n\n    # First, check in channel_tags\n    if tag in channel_tags:\n        ch = channel_tags[tag][\"channels\"] - 1  # correct for 0-based indexing\n        if isinstance(ch, (np.ndarray, list)) and len(ch) &gt; 1:\n            print(\n                f\"Multiple theta channels found for {tag} in {basepath}. Using the first one.\"\n            )\n            ch = ch[0]\n        return int(ch)\n\n    # Then try brain_region\n    if tag in brain_region:\n        print(\n            f\"Input tag: {tag} not found in {basepath} channel_tags. Looking in brain regions.\"\n        )\n        region_chan = brain_region[tag][\"channels\"] - 1  # 0-based indexing\n\n        # Ensure iterable\n        if isinstance(region_chan, (int, np.integer)):\n            region_chan = np.array([region_chan])\n        else:\n            region_chan = np.asarray(region_chan)\n\n        bad_ch = channel_tags.get(\"Bad\", {}).get(\"channels\", [])\n        bad_ch = np.asarray(bad_ch)\n\n        for chan in region_chan:\n            if chan not in bad_ch:\n                print(\n                    f\"Multiple theta channels found for {tag} in {basepath}. Using the first good one.\"\n                )\n                return int(chan)\n\n        print(f\"Input tag: {tag} found in brain regions but all channels are bad.\")\n        return None\n\n    print(f\"Input tag: {tag} not found in {basepath} channel_tags or brain regions.\")\n    return None\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.get_theta_cycles","title":"<code>get_theta_cycles(basepath, theta_freq=(6, 10), lowpass=48, detection_params=None, ch=None, tag=['CA1so', 'CA1sp'])</code>","text":"<p>Detect theta cycles in LFP data and save the results.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading LFP data.</p> required <code>theta_freq</code> <code>tuple</code> <p>Frequency range for theta detection (default is (6, 10)).</p> <code>(6, 10)</code> <code>lowpass</code> <code>int</code> <p>Cut-off frequency for low-pass filtering (default is 48).</p> <code>48</code> <code>detection_params</code> <code>dict or None</code> <p>Parameters for theta detection (default is None).</p> <code>None</code> <code>ch</code> <code>int or None</code> <p>Channel used for theta detection (default is None).</p> <code>None</code> <code>tag</code> <code>list</code> <p>List of tags to identify the theta channel (default is [\"CA1so\", \"CA1sp\"]). The function will first try to find the channel using the first tag, then the second.</p> <code>['CA1so', 'CA1sp']</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def get_theta_cycles(\n    basepath: str,\n    theta_freq: Tuple[int, int] = (6, 10),\n    lowpass: int = 48,\n    detection_params: Optional[dict] = None,\n    ch: Optional[int] = None,\n    tag: Optional[list] = [\"CA1so\", \"CA1sp\"],\n) -&gt; Optional[None]:\n    \"\"\"\n    Detect theta cycles in LFP data and save the results.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading LFP data.\n    theta_freq : tuple, optional\n        Frequency range for theta detection (default is (6, 10)).\n    lowpass : int, optional\n        Cut-off frequency for low-pass filtering (default is 48).\n    detection_params : dict or None, optional\n        Parameters for theta detection (default is None).\n    ch : int or None, optional\n        Channel used for theta detection (default is None).\n    tag : list, optional\n        List of tags to identify the theta channel (default is [\"CA1so\", \"CA1sp\"]).\n        The function will first try to find the channel using the first tag, then the second.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # import bycycle, hidden import to avoid mandatory dependency\n    from bycycle import Bycycle\n\n    # load lfp as memmap\n    lfp, ts, fs = process_lfp(basepath)\n\n    # get theta channel - default chooses CA1so\n    if ch is None:\n        ch = get_theta_channel(basepath, tag=tag[0])\n\n    if ch is None:\n        ch = get_theta_channel(basepath, tag=tag[1])\n\n    if ch is None:\n        Warning(\"No theta channel found\")\n        return None\n\n    # per bycycle documentation, low-pass filter signal before running bycycle 4x the frequency of interest\n    filt_sig = filter_signal(lfp[:, ch], fs, \"lowpass\", lowpass, remove_edges=False)\n\n    # for detecting theta epochs\n    if detection_params is None:\n        thresholds = {\n            \"amp_fraction\": 0.1,\n            \"amp_consistency\": 0.4,\n            \"period_consistency\": 0.5,\n            \"monotonicity\": 0.6,\n            \"min_n_cycles\": 3,\n        }\n    else:\n        thresholds = detection_params\n\n    # initialize bycycle object\n    bm = Bycycle(thresholds=thresholds)\n    bm.fit(filt_sig, fs, theta_freq)\n\n    save_theta_cycles(bm.df_features, ts, basepath, detection_params=thresholds, ch=ch)\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.process_lfp","title":"<code>process_lfp(basepath)</code>","text":"<p>Process and load Local Field Potential (LFP) data.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading LFP data.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the LFP data, timestamps, and sampling frequency.</p> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def process_lfp(basepath: str) -&gt; Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Process and load Local Field Potential (LFP) data.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading LFP data.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the LFP data, timestamps, and sampling frequency.\n    \"\"\"\n    nChannels, fs, _, _ = loading.loadXML(basepath)\n\n    lfp, ts = loading.loadLFP(\n        basepath, n_channels=nChannels, channel=None, frequency=fs\n    )\n    return lfp, ts, fs\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.save_theta_cycles","title":"<code>save_theta_cycles(df, ts, basepath, detection_params, ch, event_name='thetacycles', detection_name=None)</code>","text":"<p>Save theta cycles detected using bycycle to a .mat file in the cell explorer format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The bycycle dataframe containing theta cycle features.</p> required <code>ts</code> <code>ndarray</code> <p>Timestamps of the LFP data.</p> required <code>basepath</code> <code>str</code> <p>Base path to save the file to.</p> required <code>detection_params</code> <code>dict</code> <p>Dictionary of detection parameters.</p> required <code>ch</code> <code>int</code> <p>Channel used for theta detection.</p> required <code>event_name</code> <code>str</code> <p>Name of the events (default is \"thetacycles\").</p> <code>'thetacycles'</code> <code>detection_name</code> <code>str or None</code> <p>Name of the detection (default is None).</p> <code>None</code> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def save_theta_cycles(\n    df: pd.DataFrame,\n    ts: np.ndarray,\n    basepath: str,\n    detection_params: dict,\n    ch: int,\n    event_name: str = \"thetacycles\",\n    detection_name: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Save theta cycles detected using bycycle to a .mat file in the cell explorer format.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The bycycle dataframe containing theta cycle features.\n    ts : np.ndarray\n        Timestamps of the LFP data.\n    basepath : str\n        Base path to save the file to.\n    detection_params : dict\n        Dictionary of detection parameters.\n    ch : int\n        Channel used for theta detection.\n    event_name : str, optional\n        Name of the events (default is \"thetacycles\").\n    detection_name : str or None, optional\n        Name of the detection (default is None).\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + event_name + \".events.mat\"\n    )\n    data = {}\n    data[event_name] = {}\n\n    # create variables that will be saved\n    timestamps = np.array(\n        [ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]\n    )\n    peaks = ts[df.sample_last_trough.values[1:]]\n    amplitudes = df.band_amp.values[1:]\n    duration = np.diff(\n        np.array([ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]),\n        axis=0,\n    )\n    center = np.median(\n        np.array([ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]),\n        axis=0,\n    )\n\n    # limit to cycles using is_burst\n    timestamps = timestamps[:, df.is_burst.values[1:]]\n    peaks = peaks[df.is_burst.values[1:]]\n    amplitudes = amplitudes[df.is_burst.values[1:]]\n    duration = duration[:, df.is_burst.values[1:]]\n    center = center[df.is_burst.values[1:]]\n\n    # save start_ts and stop_ts as 2d array\n    data[event_name][\"timestamps\"] = timestamps.T\n    data[event_name][\"peaks\"] = peaks.T\n    data[event_name][\"amplitudes\"] = amplitudes.T\n    data[event_name][\"amplitudeUnits\"] = \"mV\"\n    data[event_name][\"eventID\"] = []\n    data[event_name][\"eventIDlabels\"] = []\n    data[event_name][\"eventIDbinary\"] = []\n\n    # check if only single epoch\n    data[event_name][\"duration\"] = duration.T\n\n    data[event_name][\"center\"] = center.T\n    data[event_name][\"detectorinfo\"] = {}\n    if detection_name is None:\n        data[event_name][\"detectorinfo\"][\"detectorname\"] = []\n    else:\n        data[event_name][\"detectorinfo\"][\"detectorname\"] = detection_name\n    data[event_name][\"detectorinfo\"][\"detectionparms\"] = detection_params\n    data[event_name][\"detectorinfo\"][\"detectionintervals\"] = []\n    data[event_name][\"detectorinfo\"][\"theta_channel\"] = ch\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/lfp/#neuro_py.lfp.whiten_lfp","title":"<code>whiten_lfp(lfp, order=2)</code>","text":"<p>Perform temporal whitening of Local Field Potential (LFP) data using an Autoregressive (AR) model.</p> <p>This function applies temporal whitening to LFP data by fitting an AR model of the specified order and using the model to remove temporal correlations, resulting in a 'whitened' signal.</p> <p>Parameters:</p> Name Type Description Default <code>lfp</code> <code>ndarray</code> <p>A 1D numpy array containing the LFP data.</p> required <code>order</code> <code>(int, optional(default=2))</code> <p>The order of the AR model to be used for whitening the LFP data.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The temporally whitened LFP data as a 1D numpy array.</p> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def whiten_lfp(lfp: np.ndarray, order: int = 2) -&gt; np.ndarray:\n    \"\"\"\n    Perform temporal whitening of Local Field Potential (LFP) data using an Autoregressive (AR) model.\n\n    This function applies temporal whitening to LFP data by fitting an AR model of the specified order\n    and using the model to remove temporal correlations, resulting in a 'whitened' signal.\n\n    Parameters\n    ----------\n    lfp : ndarray\n        A 1D numpy array containing the LFP data.\n    order : int, optional (default=2)\n        The order of the AR model to be used for whitening the LFP data.\n\n    Returns\n    -------\n    ndarray\n        The temporally whitened LFP data as a 1D numpy array.\n    \"\"\"\n\n    rho, _ = yule_walker(lfp, order=order)\n\n    a = np.concatenate(([1.0], -rho))\n\n    # Apply the whitening filter to the LFP data and return the result as a 1D array\n    return signal.convolve(lfp, a, \"same\")\n</code></pre>"},{"location":"reference/neuro_py/lfp/CSD/","title":"neuro_py.lfp.CSD","text":""},{"location":"reference/neuro_py/lfp/CSD/#neuro_py.lfp.CSD.get_coords","title":"<code>get_coords(basepath, shank=0)</code>","text":"<p>Get the coordinates of the channels from the probe layout.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the basepath.</p> required <code>shank</code> <code>int</code> <p>Shank to get the coordinates from, by default 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates of the channels.</p> Source code in <code>neuro_py/lfp/CSD.py</code> <pre><code>def get_coords(basepath: str, shank: int = 0) -&gt; np.ndarray:\n    \"\"\"\n    Get the coordinates of the channels from the probe layout.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the basepath.\n    shank : int, optional\n        Shank to get the coordinates from, by default 0.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates of the channels.\n    \"\"\"\n    import quantities as pq\n\n    # load the probe layout\n    probe_layout = loading.load_probe_layout(basepath)\n\n    # get the coordinates of the channels\n    coords = probe_layout.loc[shank == probe_layout.shank, \"y\"].values\n\n    # rescale the coordinates so none are negative and in mm\n    rescaled_coords = (coords - coords.min()) * pq.mm\n\n    # add dimension to coords to make it (nchannels,1)\n    rescaled_coords = rescaled_coords[:, np.newaxis]\n\n    return rescaled_coords\n</code></pre>"},{"location":"reference/neuro_py/lfp/CSD/#neuro_py.lfp.CSD.get_csd","title":"<code>get_csd(basepath, data, shank, fs=1250, diam=0.015, method='DeltaiCSD', channel_offset=0.046)</code>","text":"<p>compute the CSD for a given basepath and data using elephant estimate_csd.</p> <p>Klas H. Pettersen, Anna Devor, Istvan Ulbert, Anders M. Dale, Gaute T. Einevoll, Current-source density estimation based on inversion of electrostatic forward solution: Effects of finite extent of neuronal activity and conductivity discontinuities, Journal of Neuroscience Methods, Volume 154, Issues 1-2, 30 June 2006, Pages 116-133, ISSN 0165-0270, http://dx.doi.org/10.1016/j.jneumeth.2005.12.005.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>path to the basepath</p> required <code>data</code> <code>array</code> <p>data to compute the CSD on [channels x time]</p> required <code>fs</code> <code>int</code> <p>sampling rate of the data, by default 1250 Hz</p> <code>1250</code> <code>diam</code> <code>float</code> <p>diameter of the electrode, by default 0.015 mm</p> <code>0.015</code> <code>method</code> <code>str</code> <p>method to compute the CSD, by default 'DeltaiCSD'</p> <code>'DeltaiCSD'</code> <p>Returns:</p> Type Description <code>AnalogSignal</code> <p>CSD signal</p> Dependencies <p>get_coords, estimate_csd (Elephant), neo, quantities</p> Source code in <code>neuro_py/lfp/CSD.py</code> <pre><code>def get_csd(\n    basepath, data, shank, fs=1250, diam=0.015, method=\"DeltaiCSD\", channel_offset=0.046\n):\n    \"\"\"\n    compute the CSD for a given basepath and data using elephant estimate_csd.\n\n    Klas H. Pettersen, Anna Devor, Istvan Ulbert, Anders M. Dale, Gaute T. Einevoll,\n    Current-source density estimation based on inversion of electrostatic forward\n    solution: Effects of finite extent of neuronal activity and conductivity\n    discontinuities, Journal of Neuroscience Methods, Volume 154, Issues 1-2,\n    30 June 2006, Pages 116-133, ISSN 0165-0270,\n    http://dx.doi.org/10.1016/j.jneumeth.2005.12.005.\n\n    Parameters\n    ----------\n    basepath : str\n        path to the basepath\n    data : np.array\n        data to compute the CSD on [channels x time]\n    fs : int, optional\n        sampling rate of the data, by default 1250 Hz\n    diam : float, optional\n        diameter of the electrode, by default 0.015 mm\n    method : str, optional\n        method to compute the CSD, by default 'DeltaiCSD'\n\n    Returns\n    -------\n    neo.AnalogSignal\n        CSD signal\n\n    Dependencies\n    ------------\n    get_coords, estimate_csd (Elephant), neo, quantities\n\n    \"\"\"\n    import quantities as pq\n    from elephant.current_source_density import estimate_csd\n    from neo import AnalogSignal\n\n    coords = get_coords(basepath, shank=shank)\n\n    signal = AnalogSignal(\n        data,\n        units=\"mV\",\n        t_start=0 * pq.s,\n        sampling_rate=fs * pq.Hz,\n        dtype=float,\n    )\n\n    if method == \"DeltaiCSD\":\n        csd = estimate_csd(signal, coordinates=coords, diam=diam * pq.mm, method=method)\n\n    elif method == \"StandardCSD\":\n        # create coordinates for the CSD\n        coords = np.zeros(data.shape[1])\n        for idx, i in enumerate(coords):\n            if idx == 0:\n                coords[idx] = 0\n            else:\n                coords[idx] = coords[idx - 1] + channel_offset\n\n        coords = coords * pq.mm\n\n        # add dimension to coords to make it (64,1)\n        coords = coords[:, np.newaxis]\n\n        csd = estimate_csd(signal, coordinates=coords, method=method)\n\n    elif method == \"KD1CSD\":\n        # create coordinates for the CSD\n        coords = np.zeros(data.shape[1])\n        for idx, i in enumerate(coords):\n            if idx == 0:\n                coords[idx] = 0\n            else:\n                coords[idx] = coords[idx - 1] + channel_offset\n\n        coords = coords * pq.mm\n\n        # add dimension to coords to make it (64,1)\n        coords = coords[:, np.newaxis]\n        csd = estimate_csd(signal, coordinates=coords, method=method)\n\n    return csd\n</code></pre>"},{"location":"reference/neuro_py/lfp/preprocessing/","title":"neuro_py.lfp.preprocessing","text":""},{"location":"reference/neuro_py/lfp/preprocessing/#neuro_py.lfp.preprocessing.clean_lfp","title":"<code>clean_lfp(lfp, t=None, thresholds=(5, 10), artifact_time_expand=(0.25, 0.1), return_bad_intervals=False)</code>","text":"<p>Remove artefacts and noise from a local field potential (LFP) signal.</p> <p>Parameters:</p> Name Type Description Default <code>lfp</code> <code>AnalogSignalArray</code> <p>The LFP signal to be cleaned. Single signal only.</p> required <code>thresholds</code> <code>tuple of float</code> <p>A tuple of two thresholds for detecting artefacts and noise. The first threshold is used to detect large global artefacts by finding values in the z-scored LFP signal that deviate by more than the threshold number of sigmas from the mean. The second threshold is used to detect noise by finding values in the derivative of the z-scored LFP signal that are greater than the threshold. Default is (5, 10).</p> <code>(5, 10)</code> <code>artifact_time_expand</code> <code>tuple of float</code> <p>A tuple of two time intervals around detected artefacts and noise. The first interval is used to expand the detected large global artefacts. The second interval is used to expand the detected noise. Default is (0.25, 0.1).</p> <code>(0.25, 0.1)</code> <code>return_bad_intervals</code> <code>bool</code> <p>If True, also returns intervals of artefacts and noise as an <code>nel.EpochArray</code>. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tuple[ndarray, EpochArray]]</code> <p>The cleaned LFP signal. If <code>return_bad_intervals</code> is True, also returns an <code>nel.EpochArray</code> representing the intervals of artefacts and noise.</p> Notes <p>Based on https://github.com/ayalab1/neurocode/blob/master/lfp/CleanLFP.m by Ralitsa Todorova</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lfp = nel.AnalogSignalArray(data=np.random.randn(1250), timestamps=np.arange(1250)/1250)\n&gt;&gt;&gt; clean_lfp(lfp)\narray([-1.73104885,  1.08192036,  1.40332741, ..., -2.78671212,\n    -1.63661574, -1.10868426])\n</code></pre> Source code in <code>neuro_py/lfp/preprocessing.py</code> <pre><code>def clean_lfp(\n    lfp: Union[nel.AnalogSignalArray, np.ndarray],\n    t: np.ndarray = None,\n    thresholds: Tuple[float, float] = (5, 10),\n    artifact_time_expand: Tuple[float, float] = (0.25, 0.1),\n    return_bad_intervals: bool = False,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, nel.EpochArray]]:\n    \"\"\"\n    Remove artefacts and noise from a local field potential (LFP) signal.\n\n    Parameters\n    ----------\n    lfp : nel.AnalogSignalArray\n        The LFP signal to be cleaned. Single signal only.\n    thresholds : tuple of float, optional\n        A tuple of two thresholds for detecting artefacts and noise. The first threshold is used to detect large global\n        artefacts by finding values in the z-scored LFP signal that deviate by more than the threshold number of sigmas\n        from the mean. The second threshold is used to detect noise by finding values in the derivative of the z-scored\n        LFP signal that are greater than the threshold. Default is (5, 10).\n    artifact_time_expand : tuple of float, optional\n        A tuple of two time intervals around detected artefacts and noise. The first interval is used to expand the detected\n        large global artefacts. The second interval is used to expand the detected noise. Default is (0.25, 0.1).\n    return_bad_intervals : bool, optional\n        If True, also returns intervals of artefacts and noise as an `nel.EpochArray`. Default is False.\n\n    Returns\n    -------\n    Union[np.ndarray, Tuple[np.ndarray, nel.EpochArray]]\n        The cleaned LFP signal. If `return_bad_intervals` is True, also returns an `nel.EpochArray`\n        representing the intervals of artefacts and noise.\n\n    Notes\n    -----\n    Based on https://github.com/ayalab1/neurocode/blob/master/lfp/CleanLFP.m by Ralitsa Todorova\n\n    Examples\n    --------\n    &gt;&gt;&gt; lfp = nel.AnalogSignalArray(data=np.random.randn(1250), timestamps=np.arange(1250)/1250)\n    &gt;&gt;&gt; clean_lfp(lfp)\n    array([-1.73104885,  1.08192036,  1.40332741, ..., -2.78671212,\n        -1.63661574, -1.10868426])\n    \"\"\"\n    threshold1 = thresholds[0]  # in sigmas deviating from the mean\n    aroundArtefact1 = artifact_time_expand[\n        0\n    ]  # interval to expand large global artefacts\n\n    threshold2 = thresholds[1]  # for derivative of z-scored signal\n    aroundArtefact2 = artifact_time_expand[1]  # interval to expand detected noise\n\n    if isinstance(lfp, nel.AnalogSignalArray):\n        t = lfp.time  # time points of LFP signal\n        values = lfp.copy().data.flatten()  # values of LFP signal\n        z = lfp.zscore().data.flatten()  # z-scored values of LFP signal\n    elif isinstance(lfp, np.ndarray):\n        if t is None:\n            raise ValueError(\"t must be provided when lfp is np.ndarray\")\n        values = lfp.flatten()\n        z = (values - np.mean(values)) / np.std(values)\n    else:\n        raise ValueError(\"lfp must be nel.AnalogSignalArray or np.ndarray\")\n\n    d = np.append(np.diff(z), 0)  # derivative of z-scored LFP signal\n\n    # Detect large global artefacts [0]\n    artefactInterval = t[\n        np.array(intervals.find_interval(np.abs(z) &gt; threshold1), dtype=int)\n    ]\n    artefactInterval = nel.EpochArray(artefactInterval)\n    if not artefactInterval.isempty:\n        artefactInterval = artefactInterval.expand(aroundArtefact1)\n\n    # Find noise using the derivative of the z-scored signal [1]\n    noisyInterval = t[\n        np.array(intervals.find_interval(np.abs(d) &gt; threshold2), dtype=int)\n    ]\n    noisyInterval = nel.EpochArray(noisyInterval)\n    if not noisyInterval.isempty:\n        noisyInterval = noisyInterval.expand(aroundArtefact2)\n\n    # Combine intervals for artefacts and noise\n    bad = (artefactInterval | noisyInterval).merge()\n\n    if bad.isempty:\n        return values\n\n    # Find timestamps within intervals for artefacts and noise\n    in_interval = intervals.in_intervals(t, bad.data)\n\n    # Interpolate values for timestamps within intervals for artefacts and noise\n    values[in_interval] = np.interp(\n        t[in_interval], t[~in_interval], values[~in_interval]\n    )\n\n    return (values, bad) if return_bad_intervals else values\n</code></pre>"},{"location":"reference/neuro_py/lfp/spectral/","title":"neuro_py.lfp.spectral","text":""},{"location":"reference/neuro_py/lfp/spectral/#neuro_py.lfp.spectral.compute_wavelet_transform","title":"<code>compute_wavelet_transform(sig, fs, freqs, wavelet='cmor', center_frequency=0.5, bandwidth_frequency=1.5, method='conv')</code>","text":"<p>Compute the time-frequency representation of a signal using Morlet wavelets via PyWavelets.</p> <p>Parameters:</p> Name Type Description Default <code>sig</code> <code>ndarray</code> <p>Time series data (1D array).</p> required <code>fs</code> <code>float</code> <p>Sampling rate, in Hz.</p> required <code>freqs</code> <code>Union[ndarray, List[float], Tuple[float, float, Optional[float]]]</code> <p>Frequencies to analyze with Morlet wavelets. - If an array or list, specifies exact frequency values. - If a tuple, defines a frequency range as <code>(freq_start, freq_stop[, freq_step])</code>.     The <code>freq_step</code> is optional and defaults to 1. Range is inclusive of <code>freq_stop</code>.</p> required <code>wavelet</code> <code>str</code> <p>The name of the wavelet to use for the CWT. Default is 'cmor'. - wavelist = pywt.wavelist(kind='continuous') to get a list of available wavelets.</p> <code>'cmor'</code> <code>center_frequency</code> <code>float</code> <p>The center frequency of the Morlet wavelet.</p> <code>0.5</code> <code>bandwidth_frequency</code> <code>float</code> <p>The bandwidth of the Morlet wavelet.</p> <code>1.5</code> <code>method</code> <code>(conv, fft)</code> <p>The method used to compute the CWT. Can be any of:     - <code>conv</code> uses <code>numpy.convolve</code>.     - <code>fft</code> uses frequency domain convolution.     - <code>auto</code> uses automatic selection based on an estimate of the       computational complexity at each scale.</p> <code>'conv'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The time-frequency representation of the input signal. Shape is <code>(n_freqs, n_time_points)</code>.</p> Notes <p>This function uses <code>pywt.cwt</code> with Morlet wavelets to compute the time-frequency representation.</p> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def compute_wavelet_transform(\n    sig: np.ndarray,\n    fs: float,\n    freqs: Union[np.ndarray, List[float], Tuple[float, float, Optional[float]]],\n    wavelet: str = \"cmor\",\n    center_frequency: float = 0.5,\n    bandwidth_frequency: float = 1.5,\n    method=\"conv\",\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the time-frequency representation of a signal using Morlet wavelets via PyWavelets.\n\n    Parameters\n    ----------\n    sig : np.ndarray\n        Time series data (1D array).\n    fs : float\n        Sampling rate, in Hz.\n    freqs : Union[np.ndarray, List[float], Tuple[float, float, Optional[float]]]\n        Frequencies to analyze with Morlet wavelets.\n        - If an array or list, specifies exact frequency values.\n        - If a tuple, defines a frequency range as `(freq_start, freq_stop[, freq_step])`.\n            The `freq_step` is optional and defaults to 1. Range is inclusive of `freq_stop`.\n    wavelet : str, optional\n        The name of the wavelet to use for the CWT. Default is 'cmor'.\n        - wavelist = pywt.wavelist(kind='continuous') to get a list of available wavelets.\n    center_frequency : float, optional\n        The center frequency of the Morlet wavelet.\n    bandwidth_frequency : float, optional\n        The bandwidth of the Morlet wavelet.\n    method : {'conv', 'fft'}, optional\n        The method used to compute the CWT. Can be any of:\n            - ``conv`` uses ``numpy.convolve``.\n            - ``fft`` uses frequency domain convolution.\n            - ``auto`` uses automatic selection based on an estimate of the\n              computational complexity at each scale.\n    Returns\n    -------\n    np.ndarray\n        The time-frequency representation of the input signal. Shape is `(n_freqs, n_time_points)`.\n\n    Notes\n    -----\n    This function uses `pywt.cwt` with Morlet wavelets to compute the time-frequency representation.\n    \"\"\"\n\n    # Convert the frequency range to an array if it is given as a list or tuple\n    if isinstance(freqs, (tuple, list)):\n        freqs = (\n            np.arange(*freqs)\n            if len(freqs) == 3\n            else np.linspace(freqs[0], freqs[1], 100)\n        )\n\n    # Time step\n    dt = 1 / fs\n\n    # Define the wavelet name\n    wavelet_name = f\"{wavelet}{center_frequency}-{bandwidth_frequency}\"\n\n    # Convert frequencies to scales\n    scales = pywt.frequency2scale(wavelet_name, freqs / fs)\n\n    # Perform the Continuous Wavelet Transform\n    coefficients, _ = pywt.cwt(\n        sig, scales, wavelet_name, sampling_period=dt, method=method\n    )\n\n    return coefficients\n</code></pre>"},{"location":"reference/neuro_py/lfp/spectral/#neuro_py.lfp.spectral.event_triggered_wavelet","title":"<code>event_triggered_wavelet(signal, timestamps, events, max_lag=1, freq_min=4, freq_max=100, freq_step=4, return_pandas=False, parallel=True, whiten=True, whiten_order=2, fs=None, **kwargs)</code>","text":"<p>Compute the event-triggered wavelet transform of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>1d array</code> <p>Time series.</p> required <code>timestamps</code> <code>1d array</code> <p>Time points for each sample in the signal.</p> required <code>events</code> <code>1d array</code> <p>Time points of events.</p> required <code>max_lag</code> <code>float</code> <p>Maximum lag to consider, in seconds.</p> <code>1</code> <code>freq_min</code> <code>float</code> <p>Minimum frequency to consider, in Hz.</p> <code>4</code> <code>freq_max</code> <code>float</code> <p>Maximum frequency to consider, in Hz.</p> <code>100</code> <code>freq_step</code> <code>float</code> <p>Step size for frequency range, in Hz.</p> <code>4</code> <code>return_pandas</code> <code>bool</code> <p>If True, return the output as pandas objects.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>If True, use parallel processing to compute the wavelet transform.</p> <code>True</code> <code>whiten</code> <code>bool</code> <p>If True, whiten the signal before computing the wavelet transform.</p> <code>True</code> <code>whiten_order</code> <code>int</code> <p>Order of the autoregressive model used for whitening.</p> <code>2</code> <code>fs</code> <code>float</code> <p>Sampling rate, in Hz.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments to pass to <code>compute_wavelet_transform</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>mwt</code> <code>2d array</code> <p>Time frequency representation of the input signal.</p> <code>sigs</code> <code>1d array</code> <p>Average signal.</p> <code>times</code> <code>1d array</code> <p>Time points for each sample in the output.</p> <code>freqs</code> <code>1d array</code> <p>Frequencies used in the wavelet transform.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.lfp.spectral import event_triggered_wavelet\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_34_20240503\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load lfp\n&gt;&gt;&gt; nChannels, fs, _, _ = loading.loadXML(basepath)\n&gt;&gt;&gt; # Load the LFP data\n&gt;&gt;&gt; lfp, ts = loading.loadLFP(basepath, n_channels=nChannels,\n&gt;&gt;&gt;                channel=23,\n&gt;&gt;&gt;                frequency=fs)\n&gt;&gt;&gt; # load events\n&gt;&gt;&gt; opto = loading.load_events(basepath, epoch_name=\"optoStim\")\n&gt;&gt;&gt; opto = opto.merge(gap=.1)\n</code></pre> <pre><code>&gt;&gt;&gt; # compute event triggered averate\n&gt;&gt;&gt; mwt, sigs, times, freqs = event_triggered_wavelet(\n&gt;&gt;&gt;    lfp,\n&gt;&gt;&gt;    ts,\n&gt;&gt;&gt;    opto.starts,\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; # plot\n&gt;&gt;&gt; plt.figure(figsize=set_size(\"thesis\", fraction=1, subplots=(1, 1)))\n</code></pre> <pre><code>&gt;&gt;&gt; im = plt.imshow(\n&gt;&gt;&gt;     abs(mwt),\n&gt;&gt;&gt;     aspect=\"auto\",\n&gt;&gt;&gt;     extent=[times[0], times[-1], freqs[-1], freqs[0]],\n&gt;&gt;&gt;     cmap=\"magma\",\n&gt;&gt;&gt;     vmax=600,\n&gt;&gt;&gt;     vmin=50,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; plt.axhline(23, color=\"orange\", linestyle=\"--\", label=\"23hz\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.yscale(\"log\")\n&gt;&gt;&gt; # move legend outside of plot\n&gt;&gt;&gt; plt.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1), frameon=False)\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().invert_yaxis()\n</code></pre> <pre><code>&gt;&gt;&gt; plt.colorbar(location=\"top\", label=\"Power (uV^2)\")\n&gt;&gt;&gt; # move colorbar more to the left\n&gt;&gt;&gt; plt.gcf().axes[1].set_position([0.5, 0.8, 0.4, 0.6])\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().set_ylabel(\"Frequency (Hz)\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.gca().set_xlabel(\"Time from opto stim (s)\")\n</code></pre> <pre><code>&gt;&gt;&gt; plt.twinx()\n&gt;&gt;&gt; plt.yscale(\"linear\")\n&gt;&gt;&gt; plt.axvline(0, color=\"k\", linestyle=\"--\")\n&gt;&gt;&gt; plt.axvline(0.5, color=\"k\", linestyle=\"--\")\n&gt;&gt;&gt; plt.plot(times, sigs, \"w\", linewidth=0.5)\n</code></pre> <pre><code>&gt;&gt;&gt; # plt.gca().set_xlabel('Time (s)')\n&gt;&gt;&gt; plt.gca().set_ylabel(\"Voltage (uV)\")\n&gt;&gt;&gt; plt.gca().set_title(\"PFC during 23Hz stim in behavior\", y=1)\n</code></pre> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def event_triggered_wavelet(\n    signal: np.ndarray,\n    timestamps: np.ndarray,\n    events: np.ndarray,\n    max_lag: float = 1,\n    freq_min: float = 4,\n    freq_max: float = 100,\n    freq_step: float = 4,\n    return_pandas: bool = False,\n    parallel: bool = True,\n    whiten: bool = True,\n    whiten_order: int = 2,\n    fs: Optional[float] = None,\n    **kwargs,\n) -&gt; Union[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    Tuple[pd.DataFrame, pd.Series],\n]:\n    \"\"\"\n    Compute the event-triggered wavelet transform of a signal.\n\n    Parameters\n    ----------\n    signal : 1d array\n        Time series.\n    timestamps : 1d array\n        Time points for each sample in the signal.\n    events : 1d array\n        Time points of events.\n    max_lag : float\n        Maximum lag to consider, in seconds.\n    freq_min : float\n        Minimum frequency to consider, in Hz.\n    freq_max : float\n        Maximum frequency to consider, in Hz.\n    freq_step : float\n        Step size for frequency range, in Hz.\n    return_pandas : bool\n        If True, return the output as pandas objects.\n    parallel : bool\n        If True, use parallel processing to compute the wavelet transform.\n    whiten : bool\n        If True, whiten the signal before computing the wavelet transform.\n    whiten_order : int\n        Order of the autoregressive model used for whitening.\n    fs : float\n        Sampling rate, in Hz.\n    kwargs\n        Additional keyword arguments to pass to `compute_wavelet_transform`.\n\n    Returns\n    -------\n    mwt : 2d array\n        Time frequency representation of the input signal.\n    sigs : 1d array\n        Average signal.\n    times : 1d array\n        Time points for each sample in the output.\n    freqs : 1d array\n        Frequencies used in the wavelet transform.\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.lfp.spectral import event_triggered_wavelet\n\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\hpc_ctx_project\\\\HP04\\\\day_34_20240503\"\n\n    &gt;&gt;&gt; # load lfp\n    &gt;&gt;&gt; nChannels, fs, _, _ = loading.loadXML(basepath)\n    &gt;&gt;&gt; # Load the LFP data\n    &gt;&gt;&gt; lfp, ts = loading.loadLFP(basepath, n_channels=nChannels,\n    &gt;&gt;&gt;                channel=23,\n    &gt;&gt;&gt;                frequency=fs)\n    &gt;&gt;&gt; # load events\n    &gt;&gt;&gt; opto = loading.load_events(basepath, epoch_name=\"optoStim\")\n    &gt;&gt;&gt; opto = opto.merge(gap=.1)\n\n    &gt;&gt;&gt; # compute event triggered averate\n    &gt;&gt;&gt; mwt, sigs, times, freqs = event_triggered_wavelet(\n    &gt;&gt;&gt;    lfp,\n    &gt;&gt;&gt;    ts,\n    &gt;&gt;&gt;    opto.starts,\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; # plot\n    &gt;&gt;&gt; plt.figure(figsize=set_size(\"thesis\", fraction=1, subplots=(1, 1)))\n\n    &gt;&gt;&gt; im = plt.imshow(\n    &gt;&gt;&gt;     abs(mwt),\n    &gt;&gt;&gt;     aspect=\"auto\",\n    &gt;&gt;&gt;     extent=[times[0], times[-1], freqs[-1], freqs[0]],\n    &gt;&gt;&gt;     cmap=\"magma\",\n    &gt;&gt;&gt;     vmax=600,\n    &gt;&gt;&gt;     vmin=50,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; plt.axhline(23, color=\"orange\", linestyle=\"--\", label=\"23hz\")\n\n    &gt;&gt;&gt; plt.yscale(\"log\")\n    &gt;&gt;&gt; # move legend outside of plot\n    &gt;&gt;&gt; plt.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1), frameon=False)\n\n    &gt;&gt;&gt; plt.gca().invert_yaxis()\n\n    &gt;&gt;&gt; plt.colorbar(location=\"top\", label=\"Power (uV^2)\")\n    &gt;&gt;&gt; # move colorbar more to the left\n    &gt;&gt;&gt; plt.gcf().axes[1].set_position([0.5, 0.8, 0.4, 0.6])\n\n\n    &gt;&gt;&gt; plt.gca().set_ylabel(\"Frequency (Hz)\")\n\n    &gt;&gt;&gt; plt.gca().set_xlabel(\"Time from opto stim (s)\")\n\n    &gt;&gt;&gt; plt.twinx()\n    &gt;&gt;&gt; plt.yscale(\"linear\")\n    &gt;&gt;&gt; plt.axvline(0, color=\"k\", linestyle=\"--\")\n    &gt;&gt;&gt; plt.axvline(0.5, color=\"k\", linestyle=\"--\")\n    &gt;&gt;&gt; plt.plot(times, sigs, \"w\", linewidth=0.5)\n\n\n    &gt;&gt;&gt; # plt.gca().set_xlabel('Time (s)')\n    &gt;&gt;&gt; plt.gca().set_ylabel(\"Voltage (uV)\")\n    &gt;&gt;&gt; plt.gca().set_title(\"PFC during 23Hz stim in behavior\", y=1)\n    \"\"\"\n\n    signal_ = signal.copy()\n    if whiten:\n        signal_ = whiten_lfp(signal, order=whiten_order)\n\n    # set up frequency range\n    freqs = np.arange(freq_min, freq_max, freq_step)\n    # set up time range\n    if fs is None:\n        ds = timestamps[1] - timestamps[0]\n        fs = 1 / ds\n    # Create times array based on the sample rate (fs)\n    times = np.arange(-max_lag, max_lag, 1 / fs)\n    # Number of samples corresponding to the time window around each event\n    n_samples = int(max_lag * 2 * fs)\n\n    # Ensure the length of times matches n_samples\n    if len(times) != n_samples:\n        times = np.linspace(-max_lag, max_lag, n_samples)\n\n    n_freqs = len(freqs)\n    n_samples = len(times)\n\n    # set up mwt and sigs to store results\n    mwt = np.zeros((n_freqs, n_samples))\n    sigs = np.zeros(n_samples)\n\n    event_i = 0\n\n    def process_event(start):\n        nonlocal event_i\n        nonlocal mwt\n        nonlocal sigs\n\n        if start + max_lag &gt; timestamps.max() or start - max_lag &lt; timestamps.min():\n            return None, None\n\n        idx = (timestamps &gt;= start - max_lag) &amp; (timestamps &lt;= start + max_lag)\n\n        mwt_partial = np.abs(\n            compute_wavelet_transform(sig=signal_[idx], fs=fs, freqs=freqs, **kwargs)\n        )\n\n        return mwt_partial, signal[idx]\n\n    if parallel:\n        with ThreadPoolExecutor() as executor:\n            results = list(executor.map(process_event, events))\n\n        for mwt_partial, sig_partial in results:\n            if mwt_partial is not None:\n                # samples might be missing if the event is too close to the edge\n                if mwt_partial.shape[1] != n_samples:\n                    continue\n                mwt += mwt_partial\n                sigs += sig_partial\n                event_i += 1\n    else:\n        for start in events:\n            mwt_partial, sig_partial = process_event(start)\n            if mwt_partial is not None:\n                mwt += mwt_partial\n                sigs += sig_partial\n                event_i += 1\n\n    mwt /= event_i\n    sigs /= event_i\n\n    if return_pandas:\n        mwt = pd.DataFrame(mwt.T, index=times, columns=freqs)\n        sigs = pd.Series(sigs, index=times)\n        return mwt, sigs\n    else:\n        return mwt, sigs, times, freqs\n</code></pre>"},{"location":"reference/neuro_py/lfp/spectral/#neuro_py.lfp.spectral.filter_signal","title":"<code>filter_signal(sig, fs, pass_type, f_range, filter_type='fir', n_cycles=3, n_seconds=None, butterworth_order=4, remove_edges=True)</code>","text":"<p>Filter a neural signal using an FIR or IIR filter.</p> <p>Parameters:</p> Name Type Description Default <code>sig</code> <code>ndarray</code> <p>Time series to be filtered. N signals x M samples array.</p> required <code>fs</code> <code>float</code> <p>Sampling rate, in Hz.</p> required <code>pass_type</code> <code>(bandpass, bandstop, lowpass, highpass)</code> <p>Type of filter to apply.</p> <code>'bandpass'</code> <code>f_range</code> <code>float or tuple of float</code> <p>Frequency range for filtering. For 'lowpass' and 'highpass', a single float can be provided. For 'bandpass' and 'bandstop', a tuple specifying (f_low, f_high) is required.</p> required <code>filter_type</code> <code>(fir, iir)</code> <p>Type of filter to apply: 'fir' for FIR or 'iir' for IIR (Butterworth). Default is 'fir'.</p> <code>'fir'</code> <code>n_cycles</code> <code>int</code> <p>Number of cycles to define the kernel length for FIR filters. Default is 3.</p> <code>3</code> <code>n_seconds</code> <code>float</code> <p>Length of the FIR filter in seconds. Overrides <code>n_cycles</code> if specified. Ignored for IIR.</p> <code>None</code> <code>butterworth_order</code> <code>int</code> <p>Order of the Butterworth filter. Only applies to IIR filters. Default is 4.</p> <code>4</code> <code>remove_edges</code> <code>bool</code> <p>If True, replace samples within half the kernel length with NaN (FIR filters only). Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered time series.</p> <p>Examples:</p> <p>Apply a lowpass FIR filter to a signal:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; from your_module import filter_signal\n&gt;&gt;&gt; fs = 1000  # Sampling rate (Hz)\n&gt;&gt;&gt; t = np.linspace(0, 1, fs, endpoint=False)\n&gt;&gt;&gt; sig = np.sin(2 * np.pi * 1 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)  # Signal with 1Hz and 50Hz components\n&gt;&gt;&gt; pass_type = 'lowpass'\n&gt;&gt;&gt; f_range = 10  # Lowpass filter at 10 Hz\n&gt;&gt;&gt; filt_sig = filter_signal(sig, fs, pass_type, f_range, filter_type='fir')\n&gt;&gt;&gt; plt.plot(t, sig, label='Original Signal')\n&gt;&gt;&gt; plt.plot(t, filt_sig, label='Filtered Signal')\n&gt;&gt;&gt; plt.legend()\n&gt;&gt;&gt; plt.show()\n</code></pre> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def filter_signal(\n    sig: np.ndarray,\n    fs: float,\n    pass_type: str,\n    f_range: Union[float, Tuple[float, float]],\n    filter_type: str = \"fir\",\n    n_cycles: int = 3,\n    n_seconds: Optional[float] = None,\n    butterworth_order: int = 4,\n    remove_edges: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"\n    Filter a neural signal using an FIR or IIR filter.\n\n    Parameters\n    ----------\n    sig : np.ndarray\n        Time series to be filtered. N signals x M samples array.\n    fs : float\n        Sampling rate, in Hz.\n    pass_type : {'bandpass', 'bandstop', 'lowpass', 'highpass'}\n        Type of filter to apply.\n    f_range : float or tuple of float\n        Frequency range for filtering. For 'lowpass' and 'highpass', a single float can be provided.\n        For 'bandpass' and 'bandstop', a tuple specifying (f_low, f_high) is required.\n    filter_type : {'fir', 'iir'}, optional\n        Type of filter to apply: 'fir' for FIR or 'iir' for IIR (Butterworth). Default is 'fir'.\n    n_cycles : int, optional\n        Number of cycles to define the kernel length for FIR filters. Default is 3.\n    n_seconds : float, optional\n        Length of the FIR filter in seconds. Overrides `n_cycles` if specified. Ignored for IIR.\n    butterworth_order : int, optional\n        Order of the Butterworth filter. Only applies to IIR filters. Default is 4.\n    remove_edges : bool, optional\n        If True, replace samples within half the kernel length with NaN (FIR filters only). Default is True.\n\n    Returns\n    -------\n    np.ndarray\n        Filtered time series.\n\n    Examples\n    --------\n    Apply a lowpass FIR filter to a signal:\n\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; from your_module import filter_signal\n    &gt;&gt;&gt; fs = 1000  # Sampling rate (Hz)\n    &gt;&gt;&gt; t = np.linspace(0, 1, fs, endpoint=False)\n    &gt;&gt;&gt; sig = np.sin(2 * np.pi * 1 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)  # Signal with 1Hz and 50Hz components\n    &gt;&gt;&gt; pass_type = 'lowpass'\n    &gt;&gt;&gt; f_range = 10  # Lowpass filter at 10 Hz\n    &gt;&gt;&gt; filt_sig = filter_signal(sig, fs, pass_type, f_range, filter_type='fir')\n    &gt;&gt;&gt; plt.plot(t, sig, label='Original Signal')\n    &gt;&gt;&gt; plt.plot(t, filt_sig, label='Filtered Signal')\n    &gt;&gt;&gt; plt.legend()\n    &gt;&gt;&gt; plt.show()\n    \"\"\"\n\n    # Validate pass_type\n    if pass_type not in [\"bandpass\", \"bandstop\", \"lowpass\", \"highpass\"]:\n        raise ValueError(\n            \"`pass_type` must be one of: 'bandpass', 'bandstop', 'lowpass', 'highpass'.\"\n        )\n\n    # Ensure `f_range` is properly defined for the filter type\n    if isinstance(f_range, (int, float)):\n        if pass_type == \"lowpass\":\n            f_range = (None, f_range)  # Convert single value to tuple for lowpass\n        elif pass_type == \"highpass\":\n            f_range = (f_range, None)  # Convert single value to tuple for highpass\n        else:\n            raise ValueError(\n                \"`f_range` must be a tuple for 'bandpass' or 'bandstop' filters.\"\n            )\n\n    # Validate bandpass/bandstop filters\n    if pass_type in [\"bandpass\", \"bandstop\"]:\n        if not isinstance(f_range, tuple) or f_range[0] is None or f_range[1] is None:\n            raise ValueError(\n                \"Both frequencies must be specified for 'bandpass' and 'bandstop' filters.\"\n            )\n\n    # Nyquist frequency\n    nyquist = fs / 2\n\n    # FIR filter implementation\n    if filter_type == \"fir\":\n        # Compute filter kernel length\n        if n_seconds is not None:\n            kernel_len = int(n_seconds * fs)\n        else:\n            kernel_len = (\n                int((n_cycles / f_range[0]) * fs)\n                if f_range[0]\n                else int((n_cycles / f_range[1]) * fs)\n            )\n        if kernel_len % 2 == 0:\n            kernel_len += 1  # Ensure kernel length is odd\n\n        # Define FIR filter coefficients\n        if pass_type in [\"bandpass\", \"bandstop\"]:\n            fir_coefs = firwin(\n                kernel_len,\n                [f_range[0] / nyquist, f_range[1] / nyquist],\n                pass_zero=(pass_type == \"bandstop\"),\n            )\n        elif pass_type == \"lowpass\":\n            fir_coefs = firwin(kernel_len, f_range[1] / nyquist, pass_zero=True)\n        elif pass_type == \"highpass\":\n            fir_coefs = firwin(kernel_len, f_range[0] / nyquist, pass_zero=False)\n\n        # Apply the FIR filter\n        if len(sig.shape) == 1:\n            sig_filt = np.convolve(sig, fir_coefs, mode=\"same\")\n        else:\n            sig_filt = np.vstack(\n                [np.convolve(sig_, fir_coefs, mode=\"same\") for sig_ in sig]\n            )\n\n    # IIR filter implementation\n    elif filter_type == \"iir\":\n        # Design a Butterworth filter\n        if pass_type in [\"bandpass\", \"bandstop\"]:\n            b, a = butter(\n                butterworth_order,\n                [f_range[0] / nyquist, f_range[1] / nyquist],\n                btype=pass_type,\n            )\n        elif pass_type == \"lowpass\":\n            b, a = butter(butterworth_order, f_range[1] / nyquist, btype=\"low\")\n        elif pass_type == \"highpass\":\n            b, a = butter(butterworth_order, f_range[0] / nyquist, btype=\"high\")\n\n        # Apply the IIR filter\n        sig_filt = filtfilt(b, a, sig)\n\n    else:\n        raise ValueError(\"`filter_type` must be 'fir' or 'iir'.\")\n\n    # Optionally remove edges\n    if remove_edges and filter_type == \"fir\":\n        edge_len = kernel_len // 2\n        sig_filt[:edge_len] = np.nan\n        sig_filt[-edge_len:] = np.nan\n\n    return sig_filt\n</code></pre>"},{"location":"reference/neuro_py/lfp/spectral/#neuro_py.lfp.spectral.whiten_lfp","title":"<code>whiten_lfp(lfp, order=2)</code>","text":"<p>Perform temporal whitening of Local Field Potential (LFP) data using an Autoregressive (AR) model.</p> <p>This function applies temporal whitening to LFP data by fitting an AR model of the specified order and using the model to remove temporal correlations, resulting in a 'whitened' signal.</p> <p>Parameters:</p> Name Type Description Default <code>lfp</code> <code>ndarray</code> <p>A 1D numpy array containing the LFP data.</p> required <code>order</code> <code>(int, optional(default=2))</code> <p>The order of the AR model to be used for whitening the LFP data.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The temporally whitened LFP data as a 1D numpy array.</p> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def whiten_lfp(lfp: np.ndarray, order: int = 2) -&gt; np.ndarray:\n    \"\"\"\n    Perform temporal whitening of Local Field Potential (LFP) data using an Autoregressive (AR) model.\n\n    This function applies temporal whitening to LFP data by fitting an AR model of the specified order\n    and using the model to remove temporal correlations, resulting in a 'whitened' signal.\n\n    Parameters\n    ----------\n    lfp : ndarray\n        A 1D numpy array containing the LFP data.\n    order : int, optional (default=2)\n        The order of the AR model to be used for whitening the LFP data.\n\n    Returns\n    -------\n    ndarray\n        The temporally whitened LFP data as a 1D numpy array.\n    \"\"\"\n\n    rho, _ = yule_walker(lfp, order=order)\n\n    a = np.concatenate(([1.0], -rho))\n\n    # Apply the whitening filter to the LFP data and return the result as a 1D array\n    return signal.convolve(lfp, a, \"same\")\n</code></pre>"},{"location":"reference/neuro_py/lfp/spectral/#neuro_py.lfp.spectral.yule_walker","title":"<code>yule_walker(x, order=1, method='adjusted', df=None, inv=False, demean=True)</code>","text":"<p>Estimate autoregressive (AR) parameters using the Yule-Walker equations.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>A 1D array containing the input sequence.</p> required <code>order</code> <code>int</code> <p>The order of the autoregressive process. Default is 1.</p> <code>1</code> <code>method</code> <code>(adjusted, mle)</code> <p>Determines the denominator in the estimate of the autocorrelation function (ACF) at lag <code>k</code>. - If \"mle\", the denominator is <code>n = x.shape[0]</code>. - If \"adjusted\", the denominator is <code>n - k</code>. Default is \"adjusted\".</p> <code>\"adjusted\"</code> <code>df</code> <code>int</code> <p>Specifies the degrees of freedom. If <code>df</code> is supplied, it is used in place of <code>n</code>. Default is None.</p> <code>None</code> <code>inv</code> <code>bool</code> <p>If True, the inverse of the autocorrelation matrix is also returned. Default is False.</p> <code>False</code> <code>demean</code> <code>bool</code> <p>If True, the mean is subtracted from <code>x</code> before estimation. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>ndarray</code> <p>AR coefficients of size <code>(order,)</code> computed using the Yule-Walker method.</p> <code>sigma</code> <code>float</code> <p>The estimate of the residual standard deviation.</p> <code>inv_matrix</code> <code>(ndarray, optional)</code> <p>The inverse of the autocorrelation matrix (only returned if <code>inv=True</code>).</p> Notes <p>The function solves the Yule-Walker equations to compute the autoregressive coefficients of an AR process.</p> <ul> <li>The Toeplitz matrix of autocorrelations is constructed for solving the equations.</li> <li>If the autocorrelation matrix is singular, the pseudoinverse (<code>pinv</code>) is used as a fallback.</li> <li>For further details, see the AR model Wikipedia page.</li> </ul> See Also <p>statsmodels.regression.linear_model.yule_walker : Original implementation in statsmodels.</p> <p>Examples:</p> <p>Estimate AR(2) coefficients from a time series:</p> <pre><code>&gt;&gt;&gt; x = np.random.randn(1000)\n&gt;&gt;&gt; rho, sigma = yule_walker(x, order=2)\n</code></pre> <p>Estimate AR(3) coefficients and get the autocorrelation matrix inverse:</p> <pre><code>&gt;&gt;&gt; rho, sigma, inv_matrix = yule_walker(x, order=3, inv=True)\n</code></pre> Source code in <code>neuro_py/lfp/spectral.py</code> <pre><code>def yule_walker(\n    x: Union[np.ndarray, list],\n    order: int = 1,\n    method: str = \"adjusted\",\n    df: Optional[int] = None,\n    inv: bool = False,\n    demean: bool = True,\n) -&gt; Union[Tuple[np.ndarray, float], Tuple[np.ndarray, float, np.ndarray]]:\n    \"\"\"\n    Estimate autoregressive (AR) parameters using the Yule-Walker equations.\n\n    Parameters\n    ----------\n    x : array_like\n        A 1D array containing the input sequence.\n    order : int, optional\n        The order of the autoregressive process. Default is 1.\n    method : {\"adjusted\", \"mle\"}, optional\n        Determines the denominator in the estimate of the autocorrelation function (ACF) at lag `k`.\n        - If \"mle\", the denominator is `n = x.shape[0]`.\n        - If \"adjusted\", the denominator is `n - k`.\n        Default is \"adjusted\".\n    df : int, optional\n        Specifies the degrees of freedom. If `df` is supplied, it is used in place of `n`. Default is None.\n    inv : bool, optional\n        If True, the inverse of the autocorrelation matrix is also returned. Default is False.\n    demean : bool, optional\n        If True, the mean is subtracted from `x` before estimation. Default is True.\n\n    Returns\n    -------\n    rho : np.ndarray\n        AR coefficients of size `(order,)` computed using the Yule-Walker method.\n    sigma : float\n        The estimate of the residual standard deviation.\n    inv_matrix : np.ndarray, optional\n        The inverse of the autocorrelation matrix (only returned if `inv=True`).\n\n    Notes\n    -----\n    The function solves the Yule-Walker equations to compute the autoregressive coefficients of an AR process.\n\n    - The Toeplitz matrix of autocorrelations is constructed for solving the equations.\n    - If the autocorrelation matrix is singular, the pseudoinverse (`pinv`) is used as a fallback.\n    - For further details, see the [AR model Wikipedia page](https://en.wikipedia.org/wiki/Autoregressive_moving_average_model).\n\n    See Also\n    --------\n    statsmodels.regression.linear_model.yule_walker : Original implementation in statsmodels.\n\n    Examples\n    --------\n    Estimate AR(2) coefficients from a time series:\n\n    &gt;&gt;&gt; x = np.random.randn(1000)\n    &gt;&gt;&gt; rho, sigma = yule_walker(x, order=2)\n\n    Estimate AR(3) coefficients and get the autocorrelation matrix inverse:\n\n    &gt;&gt;&gt; rho, sigma, inv_matrix = yule_walker(x, order=3, inv=True)\n    \"\"\"\n\n    if method not in (\"adjusted\", \"mle\"):\n        raise ValueError(\"ACF estimation method must be 'adjusted' or 'MLE'\")\n    x = np.array(x, dtype=np.float64)\n    if demean:\n        x -= x.mean()\n    n = df or x.shape[0]\n\n    # this handles df_resid ie., n - p\n    adj_needed = method == \"adjusted\"\n\n    if x.ndim &gt; 1 and x.shape[1] != 1:\n        raise ValueError(\"expecting a vector to estimate AR parameters\")\n    r = np.zeros(order + 1, np.float64)\n    r[0] = (x**2).sum() / n\n    for k in range(1, order + 1):\n        r[k] = (x[0:-k] * x[k:]).sum() / (n - k * adj_needed)\n    R = toeplitz(r[:-1])\n\n    try:\n        rho = np.linalg.solve(R, r[1:])\n    except np.linalg.LinAlgError as err:\n        if \"Singular matrix\" in str(err):\n            warnings.warn(\"Matrix is singular. Using pinv.\")\n            rho = np.linalg.pinv(R) @ r[1:]\n        else:\n            raise\n\n    sigmasq = r[0] - (r[1:] * rho).sum()\n    if not np.isnan(sigmasq) and sigmasq &gt; 0:\n        sigma = np.sqrt(sigmasq)\n    else:\n        sigma = np.nan\n    if inv:\n        return rho, sigma, np.linalg.inv(R)\n    else:\n        return rho, sigma\n</code></pre>"},{"location":"reference/neuro_py/lfp/theta_cycles/","title":"neuro_py.lfp.theta_cycles","text":""},{"location":"reference/neuro_py/lfp/theta_cycles/#neuro_py.lfp.theta_cycles.get_ep_from_df","title":"<code>get_ep_from_df(df, ts)</code>","text":"<p>Extract epochs of theta oscillations from a bycycle dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The dataframe containing burst detection results.</p> required <code>ts</code> <code>ndarray</code> <p>Timestamps of the LFP data.</p> required <p>Returns:</p> Type Description <code>EpochArray</code> <p>An array of theta epochs.</p> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def get_ep_from_df(df: pd.DataFrame, ts: np.ndarray) -&gt; nel.EpochArray:\n    \"\"\"\n    Extract epochs of theta oscillations from a bycycle dataframe.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The dataframe containing burst detection results.\n    ts : np.ndarray\n        Timestamps of the LFP data.\n\n    Returns\n    -------\n    nel.EpochArray\n        An array of theta epochs.\n    \"\"\"\n    index_for_oscilation_epoch = find_interval(df.is_burst)\n    start = []\n    stop = []\n    for idx in index_for_oscilation_epoch:\n        start.append(df.sample_peak[idx[0]])\n        stop.append(df.sample_peak[idx[1]])\n\n    # convert list to array\n    start = np.array(start)\n    stop = np.array(stop)\n\n    # index ts get get start and end ts for each oscillation epoch\n\n    start_ts = ts[start]\n    stop_ts = ts[stop]\n\n    theta_epoch = nel.EpochArray([np.array([start_ts, stop_ts]).T])\n\n    return theta_epoch\n</code></pre>"},{"location":"reference/neuro_py/lfp/theta_cycles/#neuro_py.lfp.theta_cycles.get_theta_channel","title":"<code>get_theta_channel(basepath, tag='CA1so')</code>","text":"<p>Get the theta channel for the specified brain region. First looks in channel_tags, then in brain regions. If not found or all channels are bad, returns None.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading data.</p> required <code>tag</code> <code>str</code> <p>The tag identifying the brain region. Default is \"CA1so\".</p> <code>'CA1so'</code> <p>Returns:</p> Type Description <code>int or None</code> <p>The index of the theta channel (0-based), or None if not found or all channels are bad.</p> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def get_theta_channel(basepath: str, tag: str = \"CA1so\") -&gt; Optional[int]:\n    \"\"\"\n    Get the theta channel for the specified brain region. First looks in channel_tags, then in brain regions.\n    If not found or all channels are bad, returns None.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading data.\n    tag : str, optional\n        The tag identifying the brain region. Default is \"CA1so\".\n\n    Returns\n    -------\n    int or None\n        The index of the theta channel (0-based), or None if not found or all channels are bad.\n    \"\"\"\n    brain_region = loading.load_brain_regions(basepath)\n    channel_tags = loading.load_channel_tags(basepath)\n\n    # First, check in channel_tags\n    if tag in channel_tags:\n        ch = channel_tags[tag][\"channels\"] - 1  # correct for 0-based indexing\n        if isinstance(ch, (np.ndarray, list)) and len(ch) &gt; 1:\n            print(\n                f\"Multiple theta channels found for {tag} in {basepath}. Using the first one.\"\n            )\n            ch = ch[0]\n        return int(ch)\n\n    # Then try brain_region\n    if tag in brain_region:\n        print(\n            f\"Input tag: {tag} not found in {basepath} channel_tags. Looking in brain regions.\"\n        )\n        region_chan = brain_region[tag][\"channels\"] - 1  # 0-based indexing\n\n        # Ensure iterable\n        if isinstance(region_chan, (int, np.integer)):\n            region_chan = np.array([region_chan])\n        else:\n            region_chan = np.asarray(region_chan)\n\n        bad_ch = channel_tags.get(\"Bad\", {}).get(\"channels\", [])\n        bad_ch = np.asarray(bad_ch)\n\n        for chan in region_chan:\n            if chan not in bad_ch:\n                print(\n                    f\"Multiple theta channels found for {tag} in {basepath}. Using the first good one.\"\n                )\n                return int(chan)\n\n        print(f\"Input tag: {tag} found in brain regions but all channels are bad.\")\n        return None\n\n    print(f\"Input tag: {tag} not found in {basepath} channel_tags or brain regions.\")\n    return None\n</code></pre>"},{"location":"reference/neuro_py/lfp/theta_cycles/#neuro_py.lfp.theta_cycles.get_theta_cycles","title":"<code>get_theta_cycles(basepath, theta_freq=(6, 10), lowpass=48, detection_params=None, ch=None, tag=['CA1so', 'CA1sp'])</code>","text":"<p>Detect theta cycles in LFP data and save the results.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading LFP data.</p> required <code>theta_freq</code> <code>tuple</code> <p>Frequency range for theta detection (default is (6, 10)).</p> <code>(6, 10)</code> <code>lowpass</code> <code>int</code> <p>Cut-off frequency for low-pass filtering (default is 48).</p> <code>48</code> <code>detection_params</code> <code>dict or None</code> <p>Parameters for theta detection (default is None).</p> <code>None</code> <code>ch</code> <code>int or None</code> <p>Channel used for theta detection (default is None).</p> <code>None</code> <code>tag</code> <code>list</code> <p>List of tags to identify the theta channel (default is [\"CA1so\", \"CA1sp\"]). The function will first try to find the channel using the first tag, then the second.</p> <code>['CA1so', 'CA1sp']</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def get_theta_cycles(\n    basepath: str,\n    theta_freq: Tuple[int, int] = (6, 10),\n    lowpass: int = 48,\n    detection_params: Optional[dict] = None,\n    ch: Optional[int] = None,\n    tag: Optional[list] = [\"CA1so\", \"CA1sp\"],\n) -&gt; Optional[None]:\n    \"\"\"\n    Detect theta cycles in LFP data and save the results.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading LFP data.\n    theta_freq : tuple, optional\n        Frequency range for theta detection (default is (6, 10)).\n    lowpass : int, optional\n        Cut-off frequency for low-pass filtering (default is 48).\n    detection_params : dict or None, optional\n        Parameters for theta detection (default is None).\n    ch : int or None, optional\n        Channel used for theta detection (default is None).\n    tag : list, optional\n        List of tags to identify the theta channel (default is [\"CA1so\", \"CA1sp\"]).\n        The function will first try to find the channel using the first tag, then the second.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # import bycycle, hidden import to avoid mandatory dependency\n    from bycycle import Bycycle\n\n    # load lfp as memmap\n    lfp, ts, fs = process_lfp(basepath)\n\n    # get theta channel - default chooses CA1so\n    if ch is None:\n        ch = get_theta_channel(basepath, tag=tag[0])\n\n    if ch is None:\n        ch = get_theta_channel(basepath, tag=tag[1])\n\n    if ch is None:\n        Warning(\"No theta channel found\")\n        return None\n\n    # per bycycle documentation, low-pass filter signal before running bycycle 4x the frequency of interest\n    filt_sig = filter_signal(lfp[:, ch], fs, \"lowpass\", lowpass, remove_edges=False)\n\n    # for detecting theta epochs\n    if detection_params is None:\n        thresholds = {\n            \"amp_fraction\": 0.1,\n            \"amp_consistency\": 0.4,\n            \"period_consistency\": 0.5,\n            \"monotonicity\": 0.6,\n            \"min_n_cycles\": 3,\n        }\n    else:\n        thresholds = detection_params\n\n    # initialize bycycle object\n    bm = Bycycle(thresholds=thresholds)\n    bm.fit(filt_sig, fs, theta_freq)\n\n    save_theta_cycles(bm.df_features, ts, basepath, detection_params=thresholds, ch=ch)\n</code></pre>"},{"location":"reference/neuro_py/lfp/theta_cycles/#neuro_py.lfp.theta_cycles.process_lfp","title":"<code>process_lfp(basepath)</code>","text":"<p>Process and load Local Field Potential (LFP) data.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for loading LFP data.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the LFP data, timestamps, and sampling frequency.</p> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def process_lfp(basepath: str) -&gt; Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\n    Process and load Local Field Potential (LFP) data.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for loading LFP data.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the LFP data, timestamps, and sampling frequency.\n    \"\"\"\n    nChannels, fs, _, _ = loading.loadXML(basepath)\n\n    lfp, ts = loading.loadLFP(\n        basepath, n_channels=nChannels, channel=None, frequency=fs\n    )\n    return lfp, ts, fs\n</code></pre>"},{"location":"reference/neuro_py/lfp/theta_cycles/#neuro_py.lfp.theta_cycles.save_theta_cycles","title":"<code>save_theta_cycles(df, ts, basepath, detection_params, ch, event_name='thetacycles', detection_name=None)</code>","text":"<p>Save theta cycles detected using bycycle to a .mat file in the cell explorer format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The bycycle dataframe containing theta cycle features.</p> required <code>ts</code> <code>ndarray</code> <p>Timestamps of the LFP data.</p> required <code>basepath</code> <code>str</code> <p>Base path to save the file to.</p> required <code>detection_params</code> <code>dict</code> <p>Dictionary of detection parameters.</p> required <code>ch</code> <code>int</code> <p>Channel used for theta detection.</p> required <code>event_name</code> <code>str</code> <p>Name of the events (default is \"thetacycles\").</p> <code>'thetacycles'</code> <code>detection_name</code> <code>str or None</code> <p>Name of the detection (default is None).</p> <code>None</code> Source code in <code>neuro_py/lfp/theta_cycles.py</code> <pre><code>def save_theta_cycles(\n    df: pd.DataFrame,\n    ts: np.ndarray,\n    basepath: str,\n    detection_params: dict,\n    ch: int,\n    event_name: str = \"thetacycles\",\n    detection_name: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Save theta cycles detected using bycycle to a .mat file in the cell explorer format.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The bycycle dataframe containing theta cycle features.\n    ts : np.ndarray\n        Timestamps of the LFP data.\n    basepath : str\n        Base path to save the file to.\n    detection_params : dict\n        Dictionary of detection parameters.\n    ch : int\n        Channel used for theta detection.\n    event_name : str, optional\n        Name of the events (default is \"thetacycles\").\n    detection_name : str or None, optional\n        Name of the detection (default is None).\n    \"\"\"\n    filename = os.path.join(\n        basepath, os.path.basename(basepath) + \".\" + event_name + \".events.mat\"\n    )\n    data = {}\n    data[event_name] = {}\n\n    # create variables that will be saved\n    timestamps = np.array(\n        [ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]\n    )\n    peaks = ts[df.sample_last_trough.values[1:]]\n    amplitudes = df.band_amp.values[1:]\n    duration = np.diff(\n        np.array([ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]),\n        axis=0,\n    )\n    center = np.median(\n        np.array([ts[df.sample_peak.values[:-1]], ts[df.sample_peak.values[1:]]]),\n        axis=0,\n    )\n\n    # limit to cycles using is_burst\n    timestamps = timestamps[:, df.is_burst.values[1:]]\n    peaks = peaks[df.is_burst.values[1:]]\n    amplitudes = amplitudes[df.is_burst.values[1:]]\n    duration = duration[:, df.is_burst.values[1:]]\n    center = center[df.is_burst.values[1:]]\n\n    # save start_ts and stop_ts as 2d array\n    data[event_name][\"timestamps\"] = timestamps.T\n    data[event_name][\"peaks\"] = peaks.T\n    data[event_name][\"amplitudes\"] = amplitudes.T\n    data[event_name][\"amplitudeUnits\"] = \"mV\"\n    data[event_name][\"eventID\"] = []\n    data[event_name][\"eventIDlabels\"] = []\n    data[event_name][\"eventIDbinary\"] = []\n\n    # check if only single epoch\n    data[event_name][\"duration\"] = duration.T\n\n    data[event_name][\"center\"] = center.T\n    data[event_name][\"detectorinfo\"] = {}\n    if detection_name is None:\n        data[event_name][\"detectorinfo\"][\"detectorname\"] = []\n    else:\n        data[event_name][\"detectorinfo\"][\"detectorname\"] = detection_name\n    data[event_name][\"detectorinfo\"][\"detectionparms\"] = detection_params\n    data[event_name][\"detectorinfo\"][\"detectionintervals\"] = []\n    data[event_name][\"detectorinfo\"][\"theta_channel\"] = ch\n\n    savemat(filename, data, long_field_names=True)\n</code></pre>"},{"location":"reference/neuro_py/plotting/","title":"neuro_py.plotting","text":""},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.AngleAnnotation","title":"<code>AngleAnnotation</code>","text":"<p>               Bases: <code>Arc</code></p> <p>Draws an arc between two vectors which appears circular in display space.</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>class AngleAnnotation(Arc):\n    \"\"\"\n    Draws an arc between two vectors which appears circular in display space.\n    \"\"\"\n\n    def __init__(\n        self,\n        xy,\n        p1,\n        p2,\n        size=75,\n        unit=\"points\",\n        ax=None,\n        text=\"\",\n        textposition=\"inside\",\n        text_kw=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        xy, p1, p2 : tuple or array of two floats\n            Center position and two points. Angle annotation is drawn between\n            the two vectors connecting *p1* and *p2* with *xy*, respectively.\n            Units are data coordinates.\n\n        size : float\n            Diameter of the angle annotation in units specified by *unit*.\n\n        unit : str\n            One of the following strings to specify the unit of *size*:\n\n            * \"pixels\": pixels\n            * \"points\": points, use points instead of pixels to not have a\n              dependence on the DPI\n            * \"axes width\", \"axes height\": relative units of Axes width, height\n            * \"axes min\", \"axes max\": minimum or maximum of relative Axes\n              width, height\n\n        ax : `matplotlib.axes.Axes`\n            The Axes to add the angle annotation to.\n\n        text : str\n            The text to mark the angle with.\n\n        textposition : {\"inside\", \"outside\", \"edge\"}\n            Whether to show the text in- or outside the arc. \"edge\" can be used\n            for custom positions anchored at the arc's edge.\n\n        text_kw : dict\n            Dictionary of arguments passed to the Annotation.\n\n        **kwargs\n            Further parameters are passed to `matplotlib.patches.Arc`. Use this\n            to specify, color, linewidth etc. of the arc.\n\n        \"\"\"\n        self.ax = ax or plt.gca()\n        self._xydata = xy  # in data coordinates\n        self.vec1 = p1\n        self.vec2 = p2\n        self.size = size\n        self.unit = unit\n        self.textposition = textposition\n\n        super().__init__(\n            self._xydata,\n            size,\n            size,\n            angle=0.0,\n            theta1=self.theta1,\n            theta2=self.theta2,\n            **kwargs,\n        )\n\n        self.set_transform(IdentityTransform())\n        self.ax.add_patch(self)\n\n        self.kw = dict(\n            ha=\"center\",\n            va=\"center\",\n            xycoords=IdentityTransform(),\n            xytext=(0, 0),\n            textcoords=\"offset points\",\n            annotation_clip=True,\n        )\n        self.kw.update(text_kw or {})\n        self.text = ax.annotate(text, xy=self._center, **self.kw)\n\n    def get_size(self):\n        factor = 1.0\n        if self.unit == \"points\":\n            factor = self.ax.figure.dpi / 72.0\n        elif self.unit[:4] == \"axes\":\n            b = TransformedBbox(Bbox.unit(), self.ax.transAxes)\n            dic = {\n                \"max\": max(b.width, b.height),\n                \"min\": min(b.width, b.height),\n                \"width\": b.width,\n                \"height\": b.height,\n            }\n            factor = dic[self.unit[5:]]\n        return self.size * factor\n\n    def set_size(self, size):\n        self.size = size\n\n    def get_center_in_pixels(self):\n        \"\"\"return center in pixels\"\"\"\n        return self.ax.transData.transform(self._xydata)\n\n    def set_center(self, xy):\n        \"\"\"set center in data coordinates\"\"\"\n        self._xydata = xy\n\n    def get_theta(self, vec):\n        vec_in_pixels = self.ax.transData.transform(vec) - self._center\n        return np.rad2deg(np.arctan2(vec_in_pixels[1], vec_in_pixels[0]))\n\n    def get_theta1(self):\n        return self.get_theta(self.vec1)\n\n    def get_theta2(self):\n        return self.get_theta(self.vec2)\n\n    def set_theta(self, angle):\n        pass\n\n    # Redefine attributes of the Arc to always give values in pixel space\n    _center = property(get_center_in_pixels, set_center)\n    theta1 = property(get_theta1, set_theta)\n    theta2 = property(get_theta2, set_theta)\n    width = property(get_size, set_size)\n    height = property(get_size, set_size)\n\n    # The following two methods are needed to update the text position.\n    def draw(self, renderer):\n        self.update_text()\n        super().draw(renderer)\n\n    def update_text(self):\n        c = self._center\n        s = self.get_size()\n        angle_span = (self.theta2 - self.theta1) % 360\n        angle = np.deg2rad(self.theta1 + angle_span / 2)\n        r = s / 2\n        if self.textposition == \"inside\":\n            r = s / np.interp(angle_span, [60, 90, 135, 180], [3.3, 3.5, 3.8, 4])\n        self.text.xy = c + r * np.array([np.cos(angle), np.sin(angle)])\n        if self.textposition == \"outside\":\n\n            def R90(a, r, w, h):\n                if a &lt; np.arctan(h / 2 / (r + w / 2)):\n                    return np.sqrt((r + w / 2) ** 2 + (np.tan(a) * (r + w / 2)) ** 2)\n                else:\n                    c = np.sqrt((w / 2) ** 2 + (h / 2) ** 2)\n                    T = np.arcsin(c * np.cos(np.pi / 2 - a + np.arcsin(h / 2 / c)) / r)\n                    xy = r * np.array([np.cos(a + T), np.sin(a + T)])\n                    xy += np.array([w / 2, h / 2])\n                    return np.sqrt(np.sum(xy**2))\n\n            def R(a, r, w, h):\n                aa = (a % (np.pi / 4)) * ((a % (np.pi / 2)) &lt;= np.pi / 4) + (\n                    np.pi / 4 - (a % (np.pi / 4))\n                ) * ((a % (np.pi / 2)) &gt;= np.pi / 4)\n                return R90(aa, r, *[w, h][:: int(np.sign(np.cos(2 * a)))])\n\n            bbox = self.text.get_window_extent()\n            X = R(angle, r, bbox.width, bbox.height)\n            trans = self.ax.figure.dpi_scale_trans.inverted()\n            offs = trans.transform(((X - s / 2), 0))[0] * 72\n            self.text.set_position([offs * np.cos(angle), offs * np.sin(angle)])\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.AngleAnnotation.get_center_in_pixels","title":"<code>get_center_in_pixels()</code>","text":"<p>return center in pixels</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>def get_center_in_pixels(self):\n    \"\"\"return center in pixels\"\"\"\n    return self.ax.transData.transform(self._xydata)\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.AngleAnnotation.set_center","title":"<code>set_center(xy)</code>","text":"<p>set center in data coordinates</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>def set_center(self, xy):\n    \"\"\"set center in data coordinates\"\"\"\n    self._xydata = xy\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.adjust_box_widths","title":"<code>adjust_box_widths(g, fac)</code>","text":"<p>Adjust the widths of boxes in a Seaborn-generated boxplot.</p> <p>This function iterates through the axes of the provided FacetGrid and modifies the widths of the boxplot boxes by a specified factor.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>FacetGrid</code> <p>The FacetGrid object containing the boxplot.</p> required <code>fac</code> <code>float</code> <p>The factor by which to adjust the box widths. A value &lt; 1 will narrow the boxes, while &gt; 1 will widen them.</p> required <p>Returns:</p> Type Description <code>None</code> <p>The function modifies the box widths in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import seaborn as sns\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; tips = sns.load_dataset(\"tips\")\n&gt;&gt;&gt; g = sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n&gt;&gt;&gt; adjust_box_widths(g, 0.5)  # Narrow the boxes by 50%\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def adjust_box_widths(g: sns.axisgrid.FacetGrid, fac: float) -&gt; None:\n    \"\"\"\n    Adjust the widths of boxes in a Seaborn-generated boxplot.\n\n    This function iterates through the axes of the provided FacetGrid\n    and modifies the widths of the boxplot boxes by a specified factor.\n\n    Parameters\n    ----------\n    g : seaborn.axisgrid.FacetGrid\n        The FacetGrid object containing the boxplot.\n    fac : float\n        The factor by which to adjust the box widths.\n        A value &lt; 1 will narrow the boxes, while &gt; 1 will widen them.\n\n    Returns\n    -------\n    None\n        The function modifies the box widths in place.\n\n    Examples\n    -------\n    &gt;&gt;&gt; import seaborn as sns\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; tips = sns.load_dataset(\"tips\")\n    &gt;&gt;&gt; g = sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n    &gt;&gt;&gt; adjust_box_widths(g, 0.5)  # Narrow the boxes by 50%\n    \"\"\"\n\n    # iterating through Axes instances\n    for ax in g.axes:\n        # iterating through axes artists:\n        for c in ax.get_children():\n            # searching for PathPatches\n            if isinstance(c, PathPatch):\n                # getting current width of box:\n                p = c.get_path()\n                verts = p.vertices\n                verts_sub = verts[:-1]\n                xmin = np.min(verts_sub[:, 0])\n                xmax = np.max(verts_sub[:, 0])\n                xmid = 0.5 * (xmin + xmax)\n                xhalf = 0.5 * (xmax - xmin)\n\n                # setting new width of box\n                xmin_new = xmid - fac * xhalf\n                xmax_new = xmid + fac * xhalf\n                verts_sub[verts_sub[:, 0] == xmin, 0] = xmin_new\n                verts_sub[verts_sub[:, 0] == xmax, 0] = xmax_new\n\n                # setting new width of median line\n                for line in ax.lines:\n                    if np.all(line.get_xdata() == [xmin, xmax]):\n                        line.set_xdata([xmin_new, xmax_new])\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.lighten_color","title":"<code>lighten_color(color, amount=0.5)</code>","text":"<p>Lightens a hex color by blending it with white by a given percentage.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>str</code> <p>Hex color code (e.g., '#AABBCC').</p> required <code>amount</code> <code>float</code> <p>Fraction of the lightening, where 0 is no change and 1 is white, by default 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>str</code> <p>Lightened hex color code (e.g., '#FFFFFF').</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the color string is not a valid hex code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lighten_color(\"#AABBCC\", 0.3)\n'#c3cfdb'\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def lighten_color(color: str, amount: float = 0.5) -&gt; str:\n    \"\"\"\n    Lightens a hex color by blending it with white by a given percentage.\n\n    Parameters\n    ----------\n    color : str\n        Hex color code (e.g., '#AABBCC').\n    amount : float, optional\n        Fraction of the lightening, where 0 is no change and 1 is white, by default 0.5.\n\n    Returns\n    -------\n    str\n        Lightened hex color code (e.g., '#FFFFFF').\n\n    Raises\n    ------\n    ValueError\n        If the color string is not a valid hex code.\n\n    Examples\n    -------\n    &gt;&gt;&gt; lighten_color(\"#AABBCC\", 0.3)\n    '#c3cfdb'\n    \"\"\"\n    try:\n        c = color.lstrip(\"#\")\n        c = tuple(int(c[i : i + 2], 16) for i in (0, 2, 4))\n        c = (\n            int((1 - amount) * c[0] + amount * 255),\n            int((1 - amount) * c[1] + amount * 255),\n            int((1 - amount) * c[2] + amount * 255),\n        )\n        return \"#%02x%02x%02x\" % c\n    except ValueError:\n        return color\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.paired_lines","title":"<code>paired_lines(data, x, y, hue=None, units=None, order=None, hue_order=None, style=None, style_order=None, style_map=None, set_labels=True, dodge=True, dodge_width=0.2, color=None, palette=None, alpha=0.5, lw=1, ax=None, zorder=0, **kwargs)</code>","text":"<p>Draw lines connecting paired points within each x-category.</p> <p>Designed to complement seaborn boxplot/stripplot for visualizing paired data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input data.</p> required <code>x</code> <code>str</code> <p>Column name for x-axis categories.</p> required <code>y</code> <code>str</code> <p>Column name for y-axis values.</p> required <code>hue</code> <code>str</code> <p>Column to separate points within each x-category (e.g., two maze conditions). When provided alone: connects points across hue values within each x-category. When provided with units: connects points with the same unit but different hue values within each x-category.</p> <code>None</code> <code>units</code> <code>str</code> <p>Column that defines which points belong together (e.g., unique_basepath). When provided alone: connects points across x-categories with the same unit. When provided with hue: groups by (x, units) and connects across hue values.</p> <code>None</code> <code>order</code> <code>list</code> <p>Order of x-axis categories (matches seaborn convention).</p> <code>None</code> <code>hue_order</code> <code>list</code> <p>Order of hue levels. If provided, points will be connected in this order.</p> <code>None</code> <code>style</code> <code>str</code> <p>Column to map to line style (e.g., linestyle). Mimics seaborn's style mapping.</p> <code>None</code> <code>style_order</code> <code>list</code> <p>Order of style levels. If provided, styles will follow this order.</p> <code>None</code> <code>style_map</code> <code>dict or list</code> <p>Mapping from style level to matplotlib linestyle. If a list is provided, it will be cycled across style levels.</p> <code>None</code> <code>set_labels</code> <code>bool</code> <p>If True, set x and y labels when not already present on the axes.</p> <code>True</code> <code>dodge</code> <code>bool</code> <p>Apply dodge offset like seaborn's dodge parameter.</p> <code>True</code> <code>dodge_width</code> <code>float</code> <p>Width of the dodge offset between hue categories.</p> <code>0.2</code> <code>color</code> <code>str</code> <p>Line color. If None and palette is not provided, defaults to \"gray\". Ignored if palette is provided.</p> <code>None</code> <code>palette</code> <code>str, list, or dict</code> <p>Color palette for lines. Can be a seaborn palette name, list of colors, or dict mapping units to colors. If provided, overrides color parameter.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Line transparency.</p> <code>0.5</code> <code>lw</code> <code>float</code> <p>Line width.</p> <code>1</code> <code>ax</code> <code>matplotlib Axes</code> <p>Axes to plot on. Defaults to current axes.</p> <code>None</code> <code>zorder</code> <code>int</code> <p>Z-order for the lines.</p> <code>0</code> <code>**kwargs</code> <code>additional keyword arguments</code> <p>Passed to matplotlib's plot() function (e.g., linestyle, marker, etc.).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>matplotlib Axes</code> Notes <p>The function supports three execution modes depending on parameters:</p> <ol> <li>Units only (units provided, hue=None): Connects lines across x-categories    for each unit, useful for tracking individual subjects/units across conditions.</li> <li>Hue only (hue provided, units=None): Connects points across different hue    values within each x-category, useful for showing transitions across levels.</li> <li>Units + Hue (both provided): Groups by (x, units) and connects points    across hue values, allowing unit-specific lines colored/styled by hue.</li> </ol> <p>If <code>data</code> contains multiple rows with the same combination of <code>x</code>, <code>units</code>, and (if used) <code>hue</code>, the implementation selects the first matching value internally and ignores additional duplicates. If this is not the desired behavior, aggregate or deduplicate the data for each (<code>x</code>, <code>units</code>, <code>hue</code>) combination before calling this function.</p> <p>Examples:</p> <p>Basic usage connecting points across conditions:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; import seaborn as sns\n&gt;&gt;&gt; data = pd.DataFrame({\n...     'condition': ['A', 'B', 'A', 'B'],\n...     'value': [1, 2, 1.5, 2.5],\n...     'subject': ['S1', 'S1', 'S2', 'S2']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.boxplot(data=data, x='condition', y='value', ax=ax)\n&gt;&gt;&gt; sns.stripplot(data=data, x='condition', y='value', ax=ax, color='k', alpha=0.6)\n&gt;&gt;&gt; paired_lines(data, x='condition', y='value', units='subject', ax=ax, color='gray')\n</code></pre> <p>With hue to separate paired points by a second variable (e.g., maze type):</p> <pre><code>&gt;&gt;&gt; data_hue = pd.DataFrame({\n...     'condition': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n...     'value': [1, 2, 1.5, 2.5, 0.9, 2.1, 1.2, 2.3],\n...     'subject': ['S1', 'S1', 'S2', 'S2', 'S1', 'S1', 'S2', 'S2'],\n...     'maze': ['M1', 'M1', 'M1', 'M1', 'M2', 'M2', 'M2', 'M2']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.boxplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax)\n&gt;&gt;&gt; sns.stripplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax, color='k', alpha=0.3, dodge=True)\n&gt;&gt;&gt; paired_lines(data_hue, x='condition', y='value', hue='maze', units='subject',\n...               palette=['red', 'blue'], ax=ax)\n</code></pre> <p>With hue only (connecting across hue values within each x-category):</p> <pre><code>&gt;&gt;&gt; data_device = pd.DataFrame({\n...     'trial': ['A', 'A', 'A', 'B', 'B', 'B'],\n...     'value': [1.0, 1.5, 1.2, 2.0, 2.5, 2.3],\n...     'device': ['X', 'Y', 'Z', 'X', 'Y', 'Z']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.stripplot(data=data_device, x='trial', y='value', hue='device', jitter=0, dodge=True, ax=ax)\n&gt;&gt;&gt; paired_lines(data_device, x='trial', y='value', hue='device', ax=ax, color='gray')\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def paired_lines(\n    data: pd.DataFrame,\n    x: str,\n    y: str,\n    hue: Optional[str] = None,\n    units: Optional[str] = None,\n    order: Optional[List[Hashable]] = None,\n    hue_order: Optional[List[Hashable]] = None,\n    style: Optional[str] = None,\n    style_order: Optional[List[Hashable]] = None,\n    style_map: Optional[Union[Dict[str, str], List[str]]] = None,\n    set_labels: bool = True,\n    dodge: bool = True,\n    dodge_width: float = 0.2,\n    color: Optional[str] = None,\n    palette: Optional[Union[str, List[str], dict]] = None,\n    alpha: float = 0.5,\n    lw: float = 1,\n    ax: Optional[matplotlib.axes.Axes] = None,\n    zorder: int = 0,\n    **kwargs: Any,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"\n    Draw lines connecting paired points within each x-category.\n\n    Designed to complement seaborn boxplot/stripplot for visualizing paired data.\n\n    Parameters\n    ----------\n    data : DataFrame\n        Input data.\n    x : str\n        Column name for x-axis categories.\n    y : str\n        Column name for y-axis values.\n    hue : str, optional\n        Column to separate points within each x-category (e.g., two maze conditions).\n        When provided alone: connects points across hue values within each x-category.\n        When provided with units: connects points with the same unit but different hue\n        values within each x-category.\n    units : str, optional\n        Column that defines which points belong together (e.g., unique_basepath).\n        When provided alone: connects points across x-categories with the same unit.\n        When provided with hue: groups by (x, units) and connects across hue values.\n    order : list, optional\n        Order of x-axis categories (matches seaborn convention).\n    hue_order : list, optional\n        Order of hue levels. If provided, points will be connected in this order.\n    style : str, optional\n        Column to map to line style (e.g., linestyle). Mimics seaborn's style mapping.\n    style_order : list, optional\n        Order of style levels. If provided, styles will follow this order.\n    style_map : dict or list, optional\n        Mapping from style level to matplotlib linestyle. If a list is provided,\n        it will be cycled across style levels.\n    set_labels : bool, default True\n        If True, set x and y labels when not already present on the axes.\n    dodge : bool, default True\n        Apply dodge offset like seaborn's dodge parameter.\n    dodge_width : float, default 0.2\n        Width of the dodge offset between hue categories.\n    color : str, optional\n        Line color. If None and palette is not provided, defaults to \"gray\".\n        Ignored if palette is provided.\n    palette : str, list, or dict, optional\n        Color palette for lines. Can be a seaborn palette name, list of colors,\n        or dict mapping units to colors. If provided, overrides color parameter.\n    alpha : float, default 0.5\n        Line transparency.\n    lw : float, default 1\n        Line width.\n    ax : matplotlib Axes, optional\n        Axes to plot on. Defaults to current axes.\n    zorder : int, default 0\n        Z-order for the lines.\n    **kwargs : additional keyword arguments\n        Passed to matplotlib's plot() function (e.g., linestyle, marker, etc.).\n\n    Returns\n    -------\n    ax : matplotlib Axes\n\n    Notes\n    -----\n    The function supports three execution modes depending on parameters:\n\n    1. **Units only** (units provided, hue=None): Connects lines across x-categories\n       for each unit, useful for tracking individual subjects/units across conditions.\n    2. **Hue only** (hue provided, units=None): Connects points across different hue\n       values within each x-category, useful for showing transitions across levels.\n    3. **Units + Hue** (both provided): Groups by (x, units) and connects points\n       across hue values, allowing unit-specific lines colored/styled by hue.\n\n    If ``data`` contains multiple rows with the same combination of ``x``,\n    ``units``, and (if used) ``hue``, the implementation selects the first\n    matching value internally and ignores additional duplicates. If this is\n    not the desired behavior, aggregate or deduplicate the data for each\n    (``x``, ``units``, ``hue``) combination before calling this function.\n\n    Examples\n    --------\n    Basic usage connecting points across conditions:\n\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; import seaborn as sns\n    &gt;&gt;&gt; data = pd.DataFrame({\n    ...     'condition': ['A', 'B', 'A', 'B'],\n    ...     'value': [1, 2, 1.5, 2.5],\n    ...     'subject': ['S1', 'S1', 'S2', 'S2']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.boxplot(data=data, x='condition', y='value', ax=ax)\n    &gt;&gt;&gt; sns.stripplot(data=data, x='condition', y='value', ax=ax, color='k', alpha=0.6)\n    &gt;&gt;&gt; paired_lines(data, x='condition', y='value', units='subject', ax=ax, color='gray')\n\n    With hue to separate paired points by a second variable (e.g., maze type):\n\n    &gt;&gt;&gt; data_hue = pd.DataFrame({\n    ...     'condition': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n    ...     'value': [1, 2, 1.5, 2.5, 0.9, 2.1, 1.2, 2.3],\n    ...     'subject': ['S1', 'S1', 'S2', 'S2', 'S1', 'S1', 'S2', 'S2'],\n    ...     'maze': ['M1', 'M1', 'M1', 'M1', 'M2', 'M2', 'M2', 'M2']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.boxplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax)\n    &gt;&gt;&gt; sns.stripplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax, color='k', alpha=0.3, dodge=True)\n    &gt;&gt;&gt; paired_lines(data_hue, x='condition', y='value', hue='maze', units='subject',\n    ...               palette=['red', 'blue'], ax=ax)\n\n    With hue only (connecting across hue values within each x-category):\n\n    &gt;&gt;&gt; data_device = pd.DataFrame({\n    ...     'trial': ['A', 'A', 'A', 'B', 'B', 'B'],\n    ...     'value': [1.0, 1.5, 1.2, 2.0, 2.5, 2.3],\n    ...     'device': ['X', 'Y', 'Z', 'X', 'Y', 'Z']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.stripplot(data=data_device, x='trial', y='value', hue='device', jitter=0, dodge=True, ax=ax)\n    &gt;&gt;&gt; paired_lines(data_device, x='trial', y='value', hue='device', ax=ax, color='gray')\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Validate required columns\n    required_cols = {x, y}\n    for optional_col in (hue, units, style):\n        if optional_col is not None:\n            required_cols.add(optional_col)\n    missing_cols = [col for col in required_cols if col not in data.columns]\n    if missing_cols:\n        raise ValueError(f\"paired_lines: missing required columns: {missing_cols}\")\n\n    if order is None:\n        order = data[x].unique()\n    else:\n        unknown_x = [val for val in data[x].unique() if val not in order]\n        if unknown_x:\n            raise ValueError(\n                f\"paired_lines: x contains categories not in 'order': {unknown_x}\"\n            )\n\n    x_lookup = {label: i for i, label in enumerate(order)}\n\n    # Get hue values\n    if hue:\n        if hue_order is None:\n            hue_vals = sorted(data[hue].unique())\n        else:\n            hue_vals = hue_order\n            unknown_hue = [val for val in data[hue].unique() if val not in hue_order]\n            if unknown_hue:\n                raise ValueError(\n                    f\"paired_lines: hue contains categories not in 'hue_order': {unknown_hue}\"\n                )\n    else:\n        hue_vals = [None]\n\n    # Warn on duplicate rows for (x, units, hue) combinations\n    dup_keys = [x]\n    if units:\n        dup_keys.append(units)\n    if hue:\n        dup_keys.append(hue)\n    dup_counts = data.groupby(dup_keys, dropna=False).size()\n    num_dup_groups = int((dup_counts &gt; 1).sum())\n    if num_dup_groups:\n        warnings.warn(\n            (\n                f\"paired_lines: detected {num_dup_groups} duplicate group(s) for \"\n                f\"combinations of {tuple(dup_keys)}; selecting the first value per group. \"\n                \"Consider aggregating or deduplicating your data.\"\n            ),\n            UserWarning,\n        )\n\n    # Get style values and mapping\n    if style:\n        if style_order is None:\n            style_vals = sorted(data[style].dropna().unique())\n        else:\n            style_vals = style_order\n\n        if style_map is None:\n            default_styles = [\"-\", \"--\", \"-.\", \":\"]\n            style_map_resolved = {\n                val: sty for val, sty in zip(style_vals, cycle(default_styles))\n            }\n        elif isinstance(style_map, list):\n            style_map_resolved = {\n                val: sty for val, sty in zip(style_vals, cycle(style_map))\n            }\n        else:\n            style_map_resolved = style_map\n    else:\n        style_map_resolved = None\n\n    # Compute dodge offset\n    effective_dodge_width = dodge_width if dodge and hue else 0\n\n    # Set up color mapping\n    if palette is not None:\n        if isinstance(palette, str):\n            # Seaborn palette name\n            colors = sns.color_palette(\n                palette, n_colors=len(data[units].unique()) if units else 1\n            )\n            if units:\n                unit_vals = sorted(data[units].unique())\n                color_map = dict(zip(unit_vals, colors))\n            else:\n                color_map = None\n        elif isinstance(palette, dict):\n            color_map = palette\n        elif isinstance(palette, list):\n            if units:\n                unit_vals = sorted(data[units].unique())\n                color_map = dict(zip(unit_vals, palette))\n            else:\n                color_map = None\n        else:\n            color_map = None\n    else:\n        color_map = None\n        if color is None:\n            color = \"gray\"\n\n    if hue:\n        # With hue: group by x and units, connect across hue values within each x-category\n        if units:\n            groupby_cols = [x, units]\n        else:\n            groupby_cols = [x]\n\n        for group_key, g in data.groupby(groupby_cols, sort=False):\n            if units:\n                x_cat, unit_val = group_key\n            else:\n                # When grouping by single column as list, pandas returns 1-tuple\n                x_cat = group_key[0] if isinstance(group_key, tuple) else group_key\n                unit_val = None\n\n            if x_cat not in x_lookup:\n                continue\n\n            # Determine line color for this unit\n            if color_map and unit_val is not None:\n                line_color = color_map.get(unit_val, color)\n            else:\n                line_color = color\n\n            # Determine line style\n            plot_kwargs = dict(kwargs)\n            if style_map_resolved is not None:\n                style_val = g[style].iloc[0]\n                line_style = style_map_resolved.get(style_val, \"-\")\n                plot_kwargs.pop(\"linestyle\", None)\n                plot_kwargs.pop(\"ls\", None)\n                plot_kwargs[\"linestyle\"] = line_style\n\n            x0 = x_lookup[x_cat]\n\n            # Get data for each hue value in order\n            hue_data = []\n            for hue_val in hue_vals:\n                mask = g[hue] == hue_val\n                if mask.any():\n                    hue_data.append((hue_val, g[mask][y].values[0]))\n\n            # Connect consecutive pairs\n            if len(hue_data) &gt;= 2:\n                # Calculate x positions with dodge\n                n_hue = len(hue_vals)\n                if n_hue &gt; 1:\n                    hue_offsets = np.linspace(\n                        -effective_dodge_width, effective_dodge_width, n_hue\n                    )\n                else:\n                    hue_offsets = [0]\n\n                hue_to_offset = {\n                    hue_val: offset for hue_val, offset in zip(hue_vals, hue_offsets)\n                }\n\n                # Draw lines between consecutive pairs\n                for i in range(len(hue_data) - 1):\n                    hue_val1, y1 = hue_data[i]\n                    hue_val2, y2 = hue_data[i + 1]\n\n                    x1 = x0 + hue_to_offset[hue_val1]\n                    x2 = x0 + hue_to_offset[hue_val2]\n\n                    ax.plot(\n                        [x1, x2],\n                        [y1, y2],\n                        color=line_color,\n                        alpha=alpha,\n                        lw=lw,\n                        zorder=zorder,\n                        **plot_kwargs,\n                    )\n    else:\n        # No hue: group by units only, connect across x-categories\n        if units:\n            for unit_val, g in data.groupby(units, sort=False):\n                # Determine line color for this unit\n                if color_map and unit_val is not None:\n                    line_color = color_map.get(unit_val, color)\n                else:\n                    line_color = color\n\n                plot_kwargs = dict(kwargs)\n                if style_map_resolved is not None:\n                    style_val = g[style].iloc[0]\n                    line_style = style_map_resolved.get(style_val, \"-\")\n                    plot_kwargs.pop(\"linestyle\", None)\n                    plot_kwargs.pop(\"ls\", None)\n                    plot_kwargs[\"linestyle\"] = line_style\n\n                # Get data for each x-category in order\n                x_data = []\n                for x_cat in order:\n                    mask = g[x] == x_cat\n                    if mask.any():\n                        x_pos = x_lookup[x_cat]\n                        y_val = g[mask][y].values[0]\n                        x_data.append((x_pos, y_val))\n\n                # Connect consecutive points across x-categories\n                if len(x_data) &gt;= 2:\n                    for i in range(len(x_data) - 1):\n                        x1, y1 = x_data[i]\n                        x2, y2 = x_data[i + 1]\n\n                        ax.plot(\n                            [x1, x2],\n                            [y1, y2],\n                            color=line_color,\n                            alpha=alpha,\n                            lw=lw,\n                            zorder=zorder,\n                            **plot_kwargs,\n                        )\n        else:\n            # No units and no hue: just connect points in order across x-categories\n            x_data = []\n            for x_cat in order:\n                mask = data[x] == x_cat\n                if mask.any():\n                    x_pos = x_lookup[x_cat]\n                    y_val = data[mask][y].values[0]\n                    x_data.append((x_pos, y_val))\n\n            # Connect consecutive points\n            if len(x_data) &gt;= 2:\n                # Compute plot kwargs and style once, since they do not change across segments\n                plot_kwargs = dict(kwargs)\n                if style_map_resolved is not None:\n                    style_val = data[style].iloc[0]\n                    line_style = style_map_resolved.get(style_val, \"-\")\n                    plot_kwargs.pop(\"linestyle\", None)\n                    plot_kwargs.pop(\"ls\", None)\n                    plot_kwargs[\"linestyle\"] = line_style\n\n                for i in range(len(x_data) - 1):\n                    x1, y1 = x_data[i]\n                    x2, y2 = x_data[i + 1]\n\n                    ax.plot(\n                        [x1, x2],\n                        [y1, y2],\n                        color=color,\n                        alpha=alpha,\n                        lw=lw,\n                        zorder=zorder,\n                        **plot_kwargs,\n                    )\n\n    # Adjust categorical axis like seaborn does: set ticks, labels, and limits\n    # Since we plot with numeric positions internally, we explicitly set the labels\n    n_categories = len(order)\n    ax.set_xticks(range(n_categories))\n    ax.set_xticklabels(order)\n    ax.set_xlim(-0.5, n_categories - 0.5, auto=None)\n\n    # Set axis labels if requested and not already set\n    if set_labels:\n        if not ax.get_xlabel():\n            ax.set_xlabel(x)\n        if not ax.get_ylabel():\n            ax.set_ylabel(y)\n\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.plot_events","title":"<code>plot_events(events, labels, cmap='tab20', gridlines=True, alpha=0.75, ax=None)</code>","text":"<p>Plot multiple event epochs as colored spans on a time axis.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>list of nelpy EpochArray</code> <p>List of EpochArrays representing events.</p> required <code>labels</code> <code>list of str</code> <p>List of labels for each event type.</p> required <code>cmap</code> <code>str</code> <p>Colormap for the event spans, by default 'tab20'.</p> <code>'tab20'</code> <code>gridlines</code> <code>bool</code> <p>Whether to plot horizontal gridlines, by default True.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>Transparency of event spans, by default 0.75.</p> <code>0.75</code> <code>ax</code> <code>Axes or None</code> <p>Matplotlib Axes to plot on. If None, the current axis will be used, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis with the plotted events.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # load sleep states\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; # make nelpy epoch arrays\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(state_dict['NREMstate'])\n&gt;&gt;&gt; wake_epochs = nel.EpochArray(state_dict['WAKEstate'])\n&gt;&gt;&gt; rem_epochs = nel.EpochArray(state_dict['REMstate'])\n&gt;&gt;&gt; # add to list\n&gt;&gt;&gt; events = [nrem_epochs, wake_epochs, rem_epochs]\n&gt;&gt;&gt; # plot\n&gt;&gt;&gt; plt.figure(figsize=(20, 5))\n&gt;&gt;&gt; plot_events(events, ['nrem', 'wake', 'rem'])\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_events(\n    events: List[EpochArray],\n    labels: List[str],\n    cmap: str = \"tab20\",\n    gridlines: bool = True,\n    alpha: float = 0.75,\n    ax: Union[plt.Axes, None] = None,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot multiple event epochs as colored spans on a time axis.\n\n    Parameters\n    ----------\n    events : list of nelpy EpochArray\n        List of EpochArrays representing events.\n    labels : list of str\n        List of labels for each event type.\n    cmap : str, optional\n        Colormap for the event spans, by default 'tab20'.\n    gridlines : bool, optional\n        Whether to plot horizontal gridlines, by default True.\n    alpha : float, optional\n        Transparency of event spans, by default 0.75.\n    ax : plt.Axes or None, optional\n        Matplotlib Axes to plot on. If None, the current axis will be used, by default None.\n\n    Returns\n    -------\n    plt.Axes\n        The axis with the plotted events.\n\n    Examples\n    -------\n    &gt;&gt;&gt; # load sleep states\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; # make nelpy epoch arrays\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(state_dict['NREMstate'])\n    &gt;&gt;&gt; wake_epochs = nel.EpochArray(state_dict['WAKEstate'])\n    &gt;&gt;&gt; rem_epochs = nel.EpochArray(state_dict['REMstate'])\n    &gt;&gt;&gt; # add to list\n    &gt;&gt;&gt; events = [nrem_epochs, wake_epochs, rem_epochs]\n    &gt;&gt;&gt; # plot\n    &gt;&gt;&gt; plt.figure(figsize=(20, 5))\n    &gt;&gt;&gt; plot_events(events, ['nrem', 'wake', 'rem'])\n    \"\"\"\n    # get colormap\n    cmap = matplotlib.cm.get_cmap(cmap)\n\n    # set up y axis\n    y = np.linspace(0, 1, len(events) + 1)\n\n    # set up ax if not provided\n    if ax is None:\n        ax = plt.gca()\n\n    # iter over each event\n    for i, evt in enumerate(events):\n        # add horizontal line underneath\n        if gridlines:\n            ax.axhline(y[i] + np.diff(y)[0] / 2, color=\"k\", zorder=-100, alpha=0.1)\n\n        # plot events\n        for pair in range(evt.n_intervals):\n            ax.axvspan(\n                evt.starts[pair],\n                evt.stops[pair],\n                y[i],\n                y[i + 1],\n                alpha=alpha,\n                color=cmap(i * 0.1),\n            )\n\n    ax.set_yticks(y[:-1] + np.diff(y)[0] / 2)\n    ax.set_yticklabels(labels)\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.plot_joint_peth","title":"<code>plot_joint_peth(peth_1, peth_2, ts, smooth_std=2, labels=['peth_1', 'peth_2', 'event'])</code>","text":"<p>Plot joint peri-event time histograms (PETHs) and the difference between the observed and expected responses.</p> <p>Parameters:</p> Name Type Description Default <code>peth_1</code> <code>ndarray</code> <p>Peri-event time histogram (PETH) for the first event. Shape: (n_events, n_time_points).</p> required <code>peth_2</code> <code>ndarray</code> <p>Peri-event time histogram (PETH) for the second event. Shape: (n_events, n_time_points).</p> required <code>ts</code> <code>ndarray</code> <p>Time vector for the PETHs.</p> required <code>smooth_std</code> <code>float</code> <p>Standard deviation of the Gaussian kernel used to smooth the PETHs. Default is 2.</p> <code>2</code> <code>labels</code> <code>List[str]</code> <p>Labels for the PETHs. Default is [\"peth_1\", \"peth_2\", \"event\"].</p> <code>['peth_1', 'peth_2', 'event']</code> <p>Returns:</p> Type Description <code>Tuple[Figure, ndarray]</code> <p>Figure and axes objects for the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; peth_1 = np.random.rand(10, 100)  # Example data for peth_1\n&gt;&gt;&gt; peth_2 = np.random.rand(10, 100)  # Example data for peth_2\n&gt;&gt;&gt; ts = np.linspace(-1, 1, 100)  # Example time vector\n&gt;&gt;&gt; plot_joint_peth(peth_1, peth_2, ts)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def plot_joint_peth(\n    peth_1: np.ndarray,\n    peth_2: np.ndarray,\n    ts: np.ndarray,\n    smooth_std: float = 2,\n    labels: list = [\"peth_1\", \"peth_2\", \"event\"],\n) -&gt; Tuple[plt.Figure, np.ndarray]:\n    \"\"\"\n    Plot joint peri-event time histograms (PETHs) and the difference between the observed and expected responses.\n\n    Parameters\n    ----------\n    peth_1 : np.ndarray\n        Peri-event time histogram (PETH) for the first event. Shape: (n_events, n_time_points).\n    peth_2 : np.ndarray\n        Peri-event time histogram (PETH) for the second event. Shape: (n_events, n_time_points).\n    ts : np.ndarray\n        Time vector for the PETHs.\n    smooth_std : float, optional\n        Standard deviation of the Gaussian kernel used to smooth the PETHs. Default is 2.\n    labels : List[str], optional\n        Labels for the PETHs. Default is [\"peth_1\", \"peth_2\", \"event\"].\n\n    Returns\n    -------\n    Tuple[plt.Figure, np.ndarray]\n        Figure and axes objects for the plot.\n\n    Examples\n    -------\n    &gt;&gt;&gt; peth_1 = np.random.rand(10, 100)  # Example data for peth_1\n    &gt;&gt;&gt; peth_2 = np.random.rand(10, 100)  # Example data for peth_2\n    &gt;&gt;&gt; ts = np.linspace(-1, 1, 100)  # Example time vector\n    &gt;&gt;&gt; plot_joint_peth(peth_1, peth_2, ts)\n\n    \"\"\"\n\n    window = [ts[0], ts[-1]]\n\n    joint, expected, difference = joint_peth(peth_1, peth_2, smooth_std=smooth_std)\n\n    # get average of diagonals\n    corrected = average_diagonal(difference.T)\n    # get center values of corrected_2\n    corrected = corrected[\n        difference.shape[1] // 2 : (difference.shape[1] // 2) + difference.shape[1]\n    ]\n\n    fig, ax = plt.subplots(\n        2,\n        4,\n        figsize=(12, 4),\n        gridspec_kw={\"width_ratios\": [0.25, 1, 1, 1], \"height_ratios\": [0.25, 1]},\n    )\n    # space between panels\n    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n    ax[1, 1].imshow(\n        joint,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n\n    ax[0, 1].plot(\n        np.linspace(window[0], window[-1], len(joint)), joint.mean(axis=0), color=\"k\"\n    )\n    ax[0, 1].set_ylabel(f\"{labels[1]} rate\")\n    ax[0, 1].axvline(0, ls=\"--\", color=\"k\")\n\n    ax[1, 0].plot(\n        joint.mean(axis=1), np.linspace(window[0], window[-1], len(joint)), color=\"k\"\n    )\n    ax[1, 0].axhline(0, ls=\"--\", color=\"k\")\n    ax[1, 0].set_xlabel(f\"{labels[0]} rate\")\n\n    # plt.colorbar(f)\n    ax[1, 2].imshow(\n        expected,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n    ax[1, 2].set_title(\"Expected\")\n\n    ax[1, 3].imshow(\n        difference,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n\n    ax[0, 3].set_title(f\"corrected {labels[0]} response to {labels[1]}\")\n    ax[0, 3].plot(\n        np.linspace(window[0], window[-1], len(corrected)),\n        corrected,\n        color=\"k\",\n    )\n    ax[0, 3].set_xlim(window[0], window[-1])\n    ax[0, 3].axvline(0, ls=\"--\", color=\"k\")\n\n    for a in ax[1, 1:].ravel():\n        a.plot([-1, 1], [-1, 1], \"k--\")\n        a.axvline(0, c=\"w\", ls=\"--\")\n        a.axhline(0, c=\"w\", ls=\"--\")\n        a.set_xlim(window[0], window[-1])\n        a.set_ylim(window[0], window[-1])\n    ax[0, 0].axis(\"off\")\n    ax[0, 2].axis(\"off\")\n\n    ax[1, 1].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n    ax[1, 2].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n    ax[1, 3].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n\n    ax[1, 0].set_ylabel(f\"{labels[0]} time from {labels[-1]} (s)\")\n\n    # turn off x ticsk\n    ax[0, 1].set_xticks([])\n    ax[0, 3].set_xticks([])\n\n    ax[1, 1].set_yticks([])\n    ax[1, 2].set_yticks([])\n    ax[1, 3].set_yticks([])\n\n    ax[0, 3].set_xlabel(\"obs - expected\")\n\n    sns.despine()\n\n    return fig, ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.plot_peth","title":"<code>plot_peth(peth, ax=None, smooth=False, smooth_window=0.3, smooth_std=5, smooth_win_type='gaussian', **kwargs)</code>","text":"<p>Plot a peri-event time histogram (PETH). Assumes that the index is time and the columns are trials/cells/etc.</p> <p>Parameters:</p> Name Type Description Default <code>peth</code> <code>DataFrame</code> <p>Peri-event time histogram to plot.</p> required <code>ax</code> <code>Axes</code> <p>Axis to plot on, by default None.</p> <code>None</code> <code>smooth</code> <code>bool</code> <p>Whether to apply smoothing to the data, by default False.</p> <code>False</code> <code>smooth_window</code> <code>float</code> <p>Window size for smoothing (in the same units as the index), by default 0.30.</p> <code>0.3</code> <code>smooth_std</code> <code>int</code> <p>Standard deviation of the smoothing window, by default 5.</p> <code>5</code> <code>smooth_win_type</code> <code>str</code> <p>The type of smoothing window to use, by default 'gaussian'.</p> <code>'gaussian'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to seaborn.lineplot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axis with the plotted PETH.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If peth is not a pandas DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.plotting.events import plot_peth\n&gt;&gt;&gt; from neuro_py.process import peri_event\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath)\n&gt;&gt;&gt; ripple_epochs = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; ripple_peth = peri_event.compute_psth(st.data, ripple_epochs.starts)\n&gt;&gt;&gt; plot_peth(ripple_peth)\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_peth(\n    peth: pd.DataFrame,\n    ax: Optional[plt.Axes] = None,\n    smooth: bool = False,\n    smooth_window: float = 0.30,\n    smooth_std: int = 5,\n    smooth_win_type: str = \"gaussian\",\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot a peri-event time histogram (PETH).\n    Assumes that the index is time and the columns are trials/cells/etc.\n\n    Parameters\n    ----------\n    peth : pd.DataFrame\n        Peri-event time histogram to plot.\n    ax : matplotlib.axes.Axes, optional\n        Axis to plot on, by default None.\n    smooth : bool, optional\n        Whether to apply smoothing to the data, by default False.\n    smooth_window : float, optional\n        Window size for smoothing (in the same units as the index), by default 0.30.\n    smooth_std : int, optional\n        Standard deviation of the smoothing window, by default 5.\n    smooth_win_type : str, optional\n        The type of smoothing window to use, by default 'gaussian'.\n    **kwargs\n        Additional keyword arguments to pass to seaborn.lineplot.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        Axis with the plotted PETH.\n\n    Raises\n    ------\n    TypeError\n        If peth is not a pandas DataFrame.\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.plotting.events import plot_peth\n    &gt;&gt;&gt; from neuro_py.process import peri_event\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath)\n    &gt;&gt;&gt; ripple_epochs = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; ripple_peth = peri_event.compute_psth(st.data, ripple_epochs.starts)\n    &gt;&gt;&gt; plot_peth(ripple_peth)\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # verify peth is a dataframe\n    if not isinstance(peth, pd.DataFrame):\n        raise TypeError(\"peth must be a pandas dataframe\")\n\n    if smooth:\n        # convert window to samples\n        smooth_window = int(smooth_window / np.diff(peth.index)[0])\n        # smooth the peth\n        peth = (\n            peth.rolling(\n                window=smooth_window,\n                win_type=smooth_win_type,\n                center=True,\n                min_periods=1,\n            )\n            .mean(std=smooth_std)\n            .copy()\n        )\n\n    # melt the dataframe so that the index is time and there is a column for each trial/cell/etc.\n    peth_long = pd.melt(peth.reset_index(), id_vars=[\"index\"], value_name=\"peth\")\n\n    # plot the peth as a lineplot with seaborn\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=FutureWarning)\n        lineplot_ax = sns.lineplot(data=peth_long, x=\"index\", y=\"peth\", ax=ax, **kwargs)\n\n    ax.set_xlabel(\"Time (s)\")\n    sns.despine(ax=ax)\n    return lineplot_ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.plot_peth_fast","title":"<code>plot_peth_fast(peth, ts=None, ax=None, ci=0.95, smooth=False, smooth_window=0.3, smooth_std=5, smooth_win_type='gaussian', alpha=0.2, estimator=np.nanmean, n_boot=1000, random_state=None, **kwargs)</code>","text":"<p>Plot a peri-event time histogram (PETH) quickly with estimator flexibility. Assumes that the index is time and the columns are trials/cells/etc.</p> <p>Parameters:</p> Name Type Description Default <code>peth</code> <code>DataFrame or ndarray</code> <p>PETH to plot. Rows are time, columns are trials/cells/etc.</p> required <code>ts</code> <code>ndarray</code> <p>Time points to plot, by default None</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Axis to plot on, by default None</p> <code>None</code> <code>ci</code> <code>float</code> <p>Confidence interval to plot, by default 0.95</p> <code>0.95</code> <code>smooth</code> <code>bool</code> <p>Whether to smooth the PETH, by default False</p> <code>False</code> <code>smooth_window</code> <code>float</code> <p>Window to smooth the PETH, by default 0.30</p> <code>0.3</code> <code>smooth_std</code> <code>int</code> <p>Standard deviation of the smoothing window, by default 5</p> <code>5</code> <code>smooth_win_type</code> <code>str</code> <p>Type of smoothing window, by default \"gaussian\"</p> <code>'gaussian'</code> <code>alpha</code> <code>float</code> <p>Transparency of the confidence interval, by default 0.2</p> <code>0.2</code> <code>estimator</code> <code>Callable</code> <p>Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.</p> <code>nanmean</code> <code>n_boot</code> <code>int</code> <p>Number of bootstrap samples for CI if estimator is not mean (default: 1000)</p> <code>1000</code> <code>random_state</code> <code>int</code> <p>Random seed for bootstrapping</p> <code>None</code> <code>**kwargs</code> <p>Keyword arguments to pass to ax.plot</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axis with plot</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import bottleneck as bn\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from neuro_py.plotting.events import plot_peth_fast\n&gt;&gt;&gt; # Simulate PETH data: 100 time points, 20 trials\n&gt;&gt;&gt; peth = np.random.randn(100, 20)\n&gt;&gt;&gt; plot_peth_fast(peth)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=bn.nanmedian)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=np.nanmedian)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=lambda x, axis: np.nanpercentile(x, 25, axis=axis))\n&gt;&gt;&gt; ts = np.linspace(-1, 1, 100)\n&gt;&gt;&gt; df = pd.DataFrame(peth, index=ts)\n&gt;&gt;&gt; plot_peth_fast(df)\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_peth_fast(\n    peth: Union[pd.DataFrame, np.ndarray],\n    ts: Union[np.ndarray, None] = None,\n    ax: Union[plt.Axes, None] = None,\n    ci: float = 0.95,\n    smooth: bool = False,\n    smooth_window: float = 0.30,\n    smooth_std: int = 5,\n    smooth_win_type: str = \"gaussian\",\n    alpha: float = 0.2,\n    estimator: Callable = np.nanmean,\n    n_boot: int = 1000,\n    random_state: Optional[int] = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot a peri-event time histogram (PETH) quickly with estimator flexibility.\n    Assumes that the index is time and the columns are trials/cells/etc.\n\n    Parameters\n    ----------\n    peth : pd.DataFrame or np.ndarray\n        PETH to plot. Rows are time, columns are trials/cells/etc.\n    ts : np.ndarray, optional\n        Time points to plot, by default None\n    ax : plt.Axes, optional\n        Axis to plot on, by default None\n    ci : float, optional\n        Confidence interval to plot, by default 0.95\n    smooth : bool, optional\n        Whether to smooth the PETH, by default False\n    smooth_window : float, optional\n        Window to smooth the PETH, by default 0.30\n    smooth_std : int, optional\n        Standard deviation of the smoothing window, by default 5\n    smooth_win_type : str, optional\n        Type of smoothing window, by default \"gaussian\"\n    alpha : float, optional\n        Transparency of the confidence interval, by default 0.2\n    estimator : Callable, optional\n        Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.\n    n_boot : int, optional\n        Number of bootstrap samples for CI if estimator is not mean (default: 1000)\n    random_state : int, optional\n        Random seed for bootstrapping\n    **kwargs\n        Keyword arguments to pass to ax.plot\n\n    Returns\n    -------\n    plt.Axes\n        Axis with plot\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import bottleneck as bn\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from neuro_py.plotting.events import plot_peth_fast\n    &gt;&gt;&gt; # Simulate PETH data: 100 time points, 20 trials\n    &gt;&gt;&gt; peth = np.random.randn(100, 20)\n    &gt;&gt;&gt; plot_peth_fast(peth)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=bn.nanmedian)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=np.nanmedian)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=lambda x, axis: np.nanpercentile(x, 25, axis=axis))\n    &gt;&gt;&gt; ts = np.linspace(-1, 1, 100)\n    &gt;&gt;&gt; df = pd.DataFrame(peth, index=ts)\n    &gt;&gt;&gt; plot_peth_fast(df)\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    if not isinstance(peth, pd.DataFrame):\n        if ts is None:\n            ts = np.arange(peth.shape[0])\n        if len(ts) == peth.shape[1]:\n            peth = peth.T\n        peth = pd.DataFrame(index=ts, columns=np.arange(peth.shape[1]), data=peth)\n\n    if smooth:\n        smooth_window = int(smooth_window / np.diff(peth.index)[0])\n        peth = (\n            peth.rolling(\n                window=smooth_window,\n                win_type=smooth_win_type,\n                center=True,\n                min_periods=1,\n            )\n            .mean(std=smooth_std)\n            .copy()\n        )\n\n    # Central tendency\n    center = estimator(peth.values if hasattr(peth, \"values\") else peth, axis=1)\n    ax.plot(peth.index, center, **kwargs)\n    kwargs.pop(\"label\", None)\n\n    # Confidence interval\n    if estimator in (np.nanmean, bn.nanmean, np.nanmedian, bn.nanmedian):\n        lower, upper = confidence_intervals(peth.values.T, conf=ci, estimator=estimator)\n    else:\n        rng = np.random.default_rng(random_state)\n        boot_stats = np.empty((n_boot, peth.shape[0]))\n        for i in range(n_boot):\n            sample_idx = rng.integers(0, peth.shape[1], size=peth.shape[1])\n            boot_stats[i] = estimator(peth.values[:, sample_idx], axis=1)\n        lower = np.percentile(boot_stats, 100 * (1 - ci) / 2, axis=0)\n        upper = np.percentile(boot_stats, 100 * (1 + ci) / 2, axis=0)\n    ax.fill_between(peth.index, lower, upper, alpha=alpha, **kwargs)\n    ax.set_xlabel(\"Time (s)\")\n    sns.despine(ax=ax)\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.restore_natural_scale","title":"<code>restore_natural_scale(ax, min_, max_, n_steps=4, x_axis=True, y_axis=True)</code>","text":"<p>Converts logarithmic scale ticks to natural scale (base 10) for the specified axes.</p> <p>This function sets the ticks on the specified axes to be evenly spaced in the logarithmic scale and converts them back to the natural scale for display.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axis to modify.</p> required <code>min_</code> <code>float</code> <p>The minimum value for the ticks in logarithmic scale.</p> required <code>max_</code> <code>float</code> <p>The maximum value for the ticks in logarithmic scale.</p> required <code>n_steps</code> <code>int</code> <p>The number of ticks to create, by default 4.</p> <code>4</code> <code>x_axis</code> <code>bool</code> <p>If True, adjust the x-axis, by default True.</p> <code>True</code> <code>y_axis</code> <code>bool</code> <p>If True, adjust the y-axis, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>This function modifies the axis ticks in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax.set_xscale('log10')\n&gt;&gt;&gt; ax.plot(np.log10([1, 10, 100]), np.log10([1, 10, 100]))\n&gt;&gt;&gt; restore_natural_scale(ax, 0, 2)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def restore_natural_scale(\n    ax: matplotlib.axes.Axes,\n    min_: float,\n    max_: float,\n    n_steps: int = 4,\n    x_axis: bool = True,\n    y_axis: bool = True,\n) -&gt; None:\n    \"\"\"\n    Converts logarithmic scale ticks to natural scale (base 10) for the specified axes.\n\n    This function sets the ticks on the specified axes to be evenly spaced\n    in the logarithmic scale and converts them back to the natural scale\n    for display.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes\n        The axis to modify.\n    min_ : float\n        The minimum value for the ticks in logarithmic scale.\n    max_ : float\n        The maximum value for the ticks in logarithmic scale.\n    n_steps : int, optional\n        The number of ticks to create, by default 4.\n    x_axis : bool, optional\n        If True, adjust the x-axis, by default True.\n    y_axis : bool, optional\n        If True, adjust the y-axis, by default True.\n\n    Returns\n    -------\n    None\n        This function modifies the axis ticks in place.\n\n    Examples\n    -------\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; ax.set_xscale('log10')\n    &gt;&gt;&gt; ax.plot(np.log10([1, 10, 100]), np.log10([1, 10, 100]))\n    &gt;&gt;&gt; restore_natural_scale(ax, 0, 2)\n    \"\"\"\n    ticks = np.linspace(min_, max_, n_steps)\n\n    if x_axis:\n        ax.set_xticks(ticks)\n        ax.set_xticklabels(np.round(10**ticks, 3))\n\n    if y_axis:\n        ax.set_yticks(ticks)\n        ax.set_yticklabels(np.round(10**ticks, 3))\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.set_equal_axis_range","title":"<code>set_equal_axis_range(ax1, ax2)</code>","text":"<p>Synchronizes the x and y axis ranges between two matplotlib axes.</p> <p>Parameters:</p> Name Type Description Default <code>ax1</code> <code>Axes</code> <p>The first axis to synchronize.</p> required <code>ax2</code> <code>Axes</code> <p>The second axis to synchronize.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; fig, (ax1, ax2) = plt.subplots(1, 2)\n&gt;&gt;&gt; ax1.plot([1, 2, 3], [4, 5, 6])\n&gt;&gt;&gt; ax2.plot([1, 2, 3], [2, 3, 4])\n&gt;&gt;&gt; set_equal_axis_range(ax1, ax2)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_equal_axis_range(ax1: plt.Axes, ax2: plt.Axes) -&gt; None:\n    \"\"\"\n    Synchronizes the x and y axis ranges between two matplotlib axes.\n\n    Parameters\n    ----------\n    ax1 : matplotlib.axes.Axes\n        The first axis to synchronize.\n    ax2 : matplotlib.axes.Axes\n        The second axis to synchronize.\n\n    Examples\n    -------\n    &gt;&gt;&gt; fig, (ax1, ax2) = plt.subplots(1, 2)\n    &gt;&gt;&gt; ax1.plot([1, 2, 3], [4, 5, 6])\n    &gt;&gt;&gt; ax2.plot([1, 2, 3], [2, 3, 4])\n    &gt;&gt;&gt; set_equal_axis_range(ax1, ax2)\n    \"\"\"\n    # Get x and y axis limits for both axes\n    axis_x_values = np.hstack(np.array((ax1.get_xlim(), ax2.get_xlim())))\n    axis_y_values = np.hstack(np.array((ax1.get_ylim(), ax2.get_ylim())))\n\n    ax1.set_xlim(axis_x_values.min(), axis_x_values.max())\n    ax1.set_ylim(axis_y_values.min(), axis_y_values.max())\n    ax2.set_xlim(axis_x_values.min(), axis_x_values.max())\n    ax2.set_ylim(axis_y_values.min(), axis_y_values.max())\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.set_plotting_defaults","title":"<code>set_plotting_defaults()</code>","text":"<p>Set default plotting parameters for matplotlib with LaTeX-style fonts.</p> <p>This function updates matplotlib's plotting style to use serif fonts, sets font sizes for various elements, and ensures that SVG output uses non-embedded fonts for better compatibility.</p> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_plotting_defaults() -&gt; None:\n    \"\"\"\n    Set default plotting parameters for matplotlib with LaTeX-style fonts.\n\n    This function updates matplotlib's plotting style to use serif fonts,\n    sets font sizes for various elements, and ensures that SVG output uses\n    non-embedded fonts for better compatibility.\n    \"\"\"\n    tex_fonts = {\n        \"font.family\": \"serif\",\n        \"axes.labelsize\": 10,\n        \"font.size\": 10,\n        \"legend.fontsize\": 8,\n        \"xtick.labelsize\": 8,\n        \"ytick.labelsize\": 8,\n        \"svg.fonttype\": \"none\",\n    }\n\n    plt.style.use(\"default\")\n    plt.rcParams.update(tex_fonts)\n</code></pre>"},{"location":"reference/neuro_py/plotting/#neuro_py.plotting.set_size","title":"<code>set_size(width, fraction=1, subplots=(1, 1))</code>","text":"<p>Set figure dimensions to avoid scaling in LaTeX.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>float or str</code> <p>Document width in points (float) or predefined document type (str). Supported types: 'thesis', 'beamer', 'paper'.</p> required <code>fraction</code> <code>float</code> <p>Fraction of the width which you wish the figure to occupy, by default 1.</p> <code>1</code> <code>subplots</code> <code>tuple of int</code> <p>Number of rows and columns of subplots, by default (1, 1).</p> <code>(1, 1)</code> <p>Returns:</p> Type Description <code>tuple of float</code> <p>Dimensions of the figure in inches (width, height).</p> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_size(\n    width: Union[float, str], fraction: float = 1, subplots: Tuple[int, int] = (1, 1)\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Set figure dimensions to avoid scaling in LaTeX.\n\n    Parameters\n    ----------\n    width : float or str\n        Document width in points (float) or predefined document type (str).\n        Supported types: 'thesis', 'beamer', 'paper'.\n    fraction : float, optional\n        Fraction of the width which you wish the figure to occupy, by default 1.\n    subplots : tuple of int, optional\n        Number of rows and columns of subplots, by default (1, 1).\n\n    Returns\n    -------\n    tuple of float\n        Dimensions of the figure in inches (width, height).\n    \"\"\"\n    if width == \"thesis\":\n        width_pt = 426.79135\n    elif width == \"beamer\":\n        width_pt = 307.28987\n    elif width == \"paper\":\n        width_pt = 595.276\n    else:\n        width_pt = width\n\n    # Width of figure (in pts)\n    fig_width_pt = width_pt * fraction\n    # Convert from pt to inches\n    inches_per_pt = 1 / 72.27\n\n    # Golden ratio to set aesthetic figure height\n    # https://disq.us/p/2940ij3\n    golden_ratio = (5**0.5 - 1) / 2\n\n    # Figure width in inches\n    fig_width_in = fig_width_pt * inches_per_pt\n    # Figure height in inches\n    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n\n    return (fig_width_in, fig_height_in)\n</code></pre>"},{"location":"reference/neuro_py/plotting/decorators/","title":"neuro_py.plotting.decorators","text":""},{"location":"reference/neuro_py/plotting/decorators/#neuro_py.plotting.decorators.AngleAnnotation","title":"<code>AngleAnnotation</code>","text":"<p>               Bases: <code>Arc</code></p> <p>Draws an arc between two vectors which appears circular in display space.</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>class AngleAnnotation(Arc):\n    \"\"\"\n    Draws an arc between two vectors which appears circular in display space.\n    \"\"\"\n\n    def __init__(\n        self,\n        xy,\n        p1,\n        p2,\n        size=75,\n        unit=\"points\",\n        ax=None,\n        text=\"\",\n        textposition=\"inside\",\n        text_kw=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        xy, p1, p2 : tuple or array of two floats\n            Center position and two points. Angle annotation is drawn between\n            the two vectors connecting *p1* and *p2* with *xy*, respectively.\n            Units are data coordinates.\n\n        size : float\n            Diameter of the angle annotation in units specified by *unit*.\n\n        unit : str\n            One of the following strings to specify the unit of *size*:\n\n            * \"pixels\": pixels\n            * \"points\": points, use points instead of pixels to not have a\n              dependence on the DPI\n            * \"axes width\", \"axes height\": relative units of Axes width, height\n            * \"axes min\", \"axes max\": minimum or maximum of relative Axes\n              width, height\n\n        ax : `matplotlib.axes.Axes`\n            The Axes to add the angle annotation to.\n\n        text : str\n            The text to mark the angle with.\n\n        textposition : {\"inside\", \"outside\", \"edge\"}\n            Whether to show the text in- or outside the arc. \"edge\" can be used\n            for custom positions anchored at the arc's edge.\n\n        text_kw : dict\n            Dictionary of arguments passed to the Annotation.\n\n        **kwargs\n            Further parameters are passed to `matplotlib.patches.Arc`. Use this\n            to specify, color, linewidth etc. of the arc.\n\n        \"\"\"\n        self.ax = ax or plt.gca()\n        self._xydata = xy  # in data coordinates\n        self.vec1 = p1\n        self.vec2 = p2\n        self.size = size\n        self.unit = unit\n        self.textposition = textposition\n\n        super().__init__(\n            self._xydata,\n            size,\n            size,\n            angle=0.0,\n            theta1=self.theta1,\n            theta2=self.theta2,\n            **kwargs,\n        )\n\n        self.set_transform(IdentityTransform())\n        self.ax.add_patch(self)\n\n        self.kw = dict(\n            ha=\"center\",\n            va=\"center\",\n            xycoords=IdentityTransform(),\n            xytext=(0, 0),\n            textcoords=\"offset points\",\n            annotation_clip=True,\n        )\n        self.kw.update(text_kw or {})\n        self.text = ax.annotate(text, xy=self._center, **self.kw)\n\n    def get_size(self):\n        factor = 1.0\n        if self.unit == \"points\":\n            factor = self.ax.figure.dpi / 72.0\n        elif self.unit[:4] == \"axes\":\n            b = TransformedBbox(Bbox.unit(), self.ax.transAxes)\n            dic = {\n                \"max\": max(b.width, b.height),\n                \"min\": min(b.width, b.height),\n                \"width\": b.width,\n                \"height\": b.height,\n            }\n            factor = dic[self.unit[5:]]\n        return self.size * factor\n\n    def set_size(self, size):\n        self.size = size\n\n    def get_center_in_pixels(self):\n        \"\"\"return center in pixels\"\"\"\n        return self.ax.transData.transform(self._xydata)\n\n    def set_center(self, xy):\n        \"\"\"set center in data coordinates\"\"\"\n        self._xydata = xy\n\n    def get_theta(self, vec):\n        vec_in_pixels = self.ax.transData.transform(vec) - self._center\n        return np.rad2deg(np.arctan2(vec_in_pixels[1], vec_in_pixels[0]))\n\n    def get_theta1(self):\n        return self.get_theta(self.vec1)\n\n    def get_theta2(self):\n        return self.get_theta(self.vec2)\n\n    def set_theta(self, angle):\n        pass\n\n    # Redefine attributes of the Arc to always give values in pixel space\n    _center = property(get_center_in_pixels, set_center)\n    theta1 = property(get_theta1, set_theta)\n    theta2 = property(get_theta2, set_theta)\n    width = property(get_size, set_size)\n    height = property(get_size, set_size)\n\n    # The following two methods are needed to update the text position.\n    def draw(self, renderer):\n        self.update_text()\n        super().draw(renderer)\n\n    def update_text(self):\n        c = self._center\n        s = self.get_size()\n        angle_span = (self.theta2 - self.theta1) % 360\n        angle = np.deg2rad(self.theta1 + angle_span / 2)\n        r = s / 2\n        if self.textposition == \"inside\":\n            r = s / np.interp(angle_span, [60, 90, 135, 180], [3.3, 3.5, 3.8, 4])\n        self.text.xy = c + r * np.array([np.cos(angle), np.sin(angle)])\n        if self.textposition == \"outside\":\n\n            def R90(a, r, w, h):\n                if a &lt; np.arctan(h / 2 / (r + w / 2)):\n                    return np.sqrt((r + w / 2) ** 2 + (np.tan(a) * (r + w / 2)) ** 2)\n                else:\n                    c = np.sqrt((w / 2) ** 2 + (h / 2) ** 2)\n                    T = np.arcsin(c * np.cos(np.pi / 2 - a + np.arcsin(h / 2 / c)) / r)\n                    xy = r * np.array([np.cos(a + T), np.sin(a + T)])\n                    xy += np.array([w / 2, h / 2])\n                    return np.sqrt(np.sum(xy**2))\n\n            def R(a, r, w, h):\n                aa = (a % (np.pi / 4)) * ((a % (np.pi / 2)) &lt;= np.pi / 4) + (\n                    np.pi / 4 - (a % (np.pi / 4))\n                ) * ((a % (np.pi / 2)) &gt;= np.pi / 4)\n                return R90(aa, r, *[w, h][:: int(np.sign(np.cos(2 * a)))])\n\n            bbox = self.text.get_window_extent()\n            X = R(angle, r, bbox.width, bbox.height)\n            trans = self.ax.figure.dpi_scale_trans.inverted()\n            offs = trans.transform(((X - s / 2), 0))[0] * 72\n            self.text.set_position([offs * np.cos(angle), offs * np.sin(angle)])\n</code></pre>"},{"location":"reference/neuro_py/plotting/decorators/#neuro_py.plotting.decorators.AngleAnnotation.get_center_in_pixels","title":"<code>get_center_in_pixels()</code>","text":"<p>return center in pixels</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>def get_center_in_pixels(self):\n    \"\"\"return center in pixels\"\"\"\n    return self.ax.transData.transform(self._xydata)\n</code></pre>"},{"location":"reference/neuro_py/plotting/decorators/#neuro_py.plotting.decorators.AngleAnnotation.set_center","title":"<code>set_center(xy)</code>","text":"<p>set center in data coordinates</p> Source code in <code>neuro_py/plotting/decorators.py</code> <pre><code>def set_center(self, xy):\n    \"\"\"set center in data coordinates\"\"\"\n    self._xydata = xy\n</code></pre>"},{"location":"reference/neuro_py/plotting/events/","title":"neuro_py.plotting.events","text":""},{"location":"reference/neuro_py/plotting/events/#neuro_py.plotting.events.plot_events","title":"<code>plot_events(events, labels, cmap='tab20', gridlines=True, alpha=0.75, ax=None)</code>","text":"<p>Plot multiple event epochs as colored spans on a time axis.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>list of nelpy EpochArray</code> <p>List of EpochArrays representing events.</p> required <code>labels</code> <code>list of str</code> <p>List of labels for each event type.</p> required <code>cmap</code> <code>str</code> <p>Colormap for the event spans, by default 'tab20'.</p> <code>'tab20'</code> <code>gridlines</code> <code>bool</code> <p>Whether to plot horizontal gridlines, by default True.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>Transparency of event spans, by default 0.75.</p> <code>0.75</code> <code>ax</code> <code>Axes or None</code> <p>Matplotlib Axes to plot on. If None, the current axis will be used, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis with the plotted events.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # load sleep states\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; # make nelpy epoch arrays\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(state_dict['NREMstate'])\n&gt;&gt;&gt; wake_epochs = nel.EpochArray(state_dict['WAKEstate'])\n&gt;&gt;&gt; rem_epochs = nel.EpochArray(state_dict['REMstate'])\n&gt;&gt;&gt; # add to list\n&gt;&gt;&gt; events = [nrem_epochs, wake_epochs, rem_epochs]\n&gt;&gt;&gt; # plot\n&gt;&gt;&gt; plt.figure(figsize=(20, 5))\n&gt;&gt;&gt; plot_events(events, ['nrem', 'wake', 'rem'])\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_events(\n    events: List[EpochArray],\n    labels: List[str],\n    cmap: str = \"tab20\",\n    gridlines: bool = True,\n    alpha: float = 0.75,\n    ax: Union[plt.Axes, None] = None,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot multiple event epochs as colored spans on a time axis.\n\n    Parameters\n    ----------\n    events : list of nelpy EpochArray\n        List of EpochArrays representing events.\n    labels : list of str\n        List of labels for each event type.\n    cmap : str, optional\n        Colormap for the event spans, by default 'tab20'.\n    gridlines : bool, optional\n        Whether to plot horizontal gridlines, by default True.\n    alpha : float, optional\n        Transparency of event spans, by default 0.75.\n    ax : plt.Axes or None, optional\n        Matplotlib Axes to plot on. If None, the current axis will be used, by default None.\n\n    Returns\n    -------\n    plt.Axes\n        The axis with the plotted events.\n\n    Examples\n    -------\n    &gt;&gt;&gt; # load sleep states\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; # make nelpy epoch arrays\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(state_dict['NREMstate'])\n    &gt;&gt;&gt; wake_epochs = nel.EpochArray(state_dict['WAKEstate'])\n    &gt;&gt;&gt; rem_epochs = nel.EpochArray(state_dict['REMstate'])\n    &gt;&gt;&gt; # add to list\n    &gt;&gt;&gt; events = [nrem_epochs, wake_epochs, rem_epochs]\n    &gt;&gt;&gt; # plot\n    &gt;&gt;&gt; plt.figure(figsize=(20, 5))\n    &gt;&gt;&gt; plot_events(events, ['nrem', 'wake', 'rem'])\n    \"\"\"\n    # get colormap\n    cmap = matplotlib.cm.get_cmap(cmap)\n\n    # set up y axis\n    y = np.linspace(0, 1, len(events) + 1)\n\n    # set up ax if not provided\n    if ax is None:\n        ax = plt.gca()\n\n    # iter over each event\n    for i, evt in enumerate(events):\n        # add horizontal line underneath\n        if gridlines:\n            ax.axhline(y[i] + np.diff(y)[0] / 2, color=\"k\", zorder=-100, alpha=0.1)\n\n        # plot events\n        for pair in range(evt.n_intervals):\n            ax.axvspan(\n                evt.starts[pair],\n                evt.stops[pair],\n                y[i],\n                y[i + 1],\n                alpha=alpha,\n                color=cmap(i * 0.1),\n            )\n\n    ax.set_yticks(y[:-1] + np.diff(y)[0] / 2)\n    ax.set_yticklabels(labels)\n</code></pre>"},{"location":"reference/neuro_py/plotting/events/#neuro_py.plotting.events.plot_peth","title":"<code>plot_peth(peth, ax=None, smooth=False, smooth_window=0.3, smooth_std=5, smooth_win_type='gaussian', **kwargs)</code>","text":"<p>Plot a peri-event time histogram (PETH). Assumes that the index is time and the columns are trials/cells/etc.</p> <p>Parameters:</p> Name Type Description Default <code>peth</code> <code>DataFrame</code> <p>Peri-event time histogram to plot.</p> required <code>ax</code> <code>Axes</code> <p>Axis to plot on, by default None.</p> <code>None</code> <code>smooth</code> <code>bool</code> <p>Whether to apply smoothing to the data, by default False.</p> <code>False</code> <code>smooth_window</code> <code>float</code> <p>Window size for smoothing (in the same units as the index), by default 0.30.</p> <code>0.3</code> <code>smooth_std</code> <code>int</code> <p>Standard deviation of the smoothing window, by default 5.</p> <code>5</code> <code>smooth_win_type</code> <code>str</code> <p>The type of smoothing window to use, by default 'gaussian'.</p> <code>'gaussian'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to seaborn.lineplot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axis with the plotted PETH.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If peth is not a pandas DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.plotting.events import plot_peth\n&gt;&gt;&gt; from neuro_py.process import peri_event\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath)\n&gt;&gt;&gt; ripple_epochs = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; ripple_peth = peri_event.compute_psth(st.data, ripple_epochs.starts)\n&gt;&gt;&gt; plot_peth(ripple_peth)\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_peth(\n    peth: pd.DataFrame,\n    ax: Optional[plt.Axes] = None,\n    smooth: bool = False,\n    smooth_window: float = 0.30,\n    smooth_std: int = 5,\n    smooth_win_type: str = \"gaussian\",\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot a peri-event time histogram (PETH).\n    Assumes that the index is time and the columns are trials/cells/etc.\n\n    Parameters\n    ----------\n    peth : pd.DataFrame\n        Peri-event time histogram to plot.\n    ax : matplotlib.axes.Axes, optional\n        Axis to plot on, by default None.\n    smooth : bool, optional\n        Whether to apply smoothing to the data, by default False.\n    smooth_window : float, optional\n        Window size for smoothing (in the same units as the index), by default 0.30.\n    smooth_std : int, optional\n        Standard deviation of the smoothing window, by default 5.\n    smooth_win_type : str, optional\n        The type of smoothing window to use, by default 'gaussian'.\n    **kwargs\n        Additional keyword arguments to pass to seaborn.lineplot.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        Axis with the plotted PETH.\n\n    Raises\n    ------\n    TypeError\n        If peth is not a pandas DataFrame.\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.plotting.events import plot_peth\n    &gt;&gt;&gt; from neuro_py.process import peri_event\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath)\n    &gt;&gt;&gt; ripple_epochs = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; ripple_peth = peri_event.compute_psth(st.data, ripple_epochs.starts)\n    &gt;&gt;&gt; plot_peth(ripple_peth)\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # verify peth is a dataframe\n    if not isinstance(peth, pd.DataFrame):\n        raise TypeError(\"peth must be a pandas dataframe\")\n\n    if smooth:\n        # convert window to samples\n        smooth_window = int(smooth_window / np.diff(peth.index)[0])\n        # smooth the peth\n        peth = (\n            peth.rolling(\n                window=smooth_window,\n                win_type=smooth_win_type,\n                center=True,\n                min_periods=1,\n            )\n            .mean(std=smooth_std)\n            .copy()\n        )\n\n    # melt the dataframe so that the index is time and there is a column for each trial/cell/etc.\n    peth_long = pd.melt(peth.reset_index(), id_vars=[\"index\"], value_name=\"peth\")\n\n    # plot the peth as a lineplot with seaborn\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=FutureWarning)\n        lineplot_ax = sns.lineplot(data=peth_long, x=\"index\", y=\"peth\", ax=ax, **kwargs)\n\n    ax.set_xlabel(\"Time (s)\")\n    sns.despine(ax=ax)\n    return lineplot_ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/events/#neuro_py.plotting.events.plot_peth_fast","title":"<code>plot_peth_fast(peth, ts=None, ax=None, ci=0.95, smooth=False, smooth_window=0.3, smooth_std=5, smooth_win_type='gaussian', alpha=0.2, estimator=np.nanmean, n_boot=1000, random_state=None, **kwargs)</code>","text":"<p>Plot a peri-event time histogram (PETH) quickly with estimator flexibility. Assumes that the index is time and the columns are trials/cells/etc.</p> <p>Parameters:</p> Name Type Description Default <code>peth</code> <code>DataFrame or ndarray</code> <p>PETH to plot. Rows are time, columns are trials/cells/etc.</p> required <code>ts</code> <code>ndarray</code> <p>Time points to plot, by default None</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Axis to plot on, by default None</p> <code>None</code> <code>ci</code> <code>float</code> <p>Confidence interval to plot, by default 0.95</p> <code>0.95</code> <code>smooth</code> <code>bool</code> <p>Whether to smooth the PETH, by default False</p> <code>False</code> <code>smooth_window</code> <code>float</code> <p>Window to smooth the PETH, by default 0.30</p> <code>0.3</code> <code>smooth_std</code> <code>int</code> <p>Standard deviation of the smoothing window, by default 5</p> <code>5</code> <code>smooth_win_type</code> <code>str</code> <p>Type of smoothing window, by default \"gaussian\"</p> <code>'gaussian'</code> <code>alpha</code> <code>float</code> <p>Transparency of the confidence interval, by default 0.2</p> <code>0.2</code> <code>estimator</code> <code>Callable</code> <p>Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.</p> <code>nanmean</code> <code>n_boot</code> <code>int</code> <p>Number of bootstrap samples for CI if estimator is not mean (default: 1000)</p> <code>1000</code> <code>random_state</code> <code>int</code> <p>Random seed for bootstrapping</p> <code>None</code> <code>**kwargs</code> <p>Keyword arguments to pass to ax.plot</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axis with plot</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import bottleneck as bn\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from neuro_py.plotting.events import plot_peth_fast\n&gt;&gt;&gt; # Simulate PETH data: 100 time points, 20 trials\n&gt;&gt;&gt; peth = np.random.randn(100, 20)\n&gt;&gt;&gt; plot_peth_fast(peth)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=bn.nanmedian)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=np.nanmedian)\n&gt;&gt;&gt; plot_peth_fast(peth, estimator=lambda x, axis: np.nanpercentile(x, 25, axis=axis))\n&gt;&gt;&gt; ts = np.linspace(-1, 1, 100)\n&gt;&gt;&gt; df = pd.DataFrame(peth, index=ts)\n&gt;&gt;&gt; plot_peth_fast(df)\n</code></pre> Source code in <code>neuro_py/plotting/events.py</code> <pre><code>def plot_peth_fast(\n    peth: Union[pd.DataFrame, np.ndarray],\n    ts: Union[np.ndarray, None] = None,\n    ax: Union[plt.Axes, None] = None,\n    ci: float = 0.95,\n    smooth: bool = False,\n    smooth_window: float = 0.30,\n    smooth_std: int = 5,\n    smooth_win_type: str = \"gaussian\",\n    alpha: float = 0.2,\n    estimator: Callable = np.nanmean,\n    n_boot: int = 1000,\n    random_state: Optional[int] = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Plot a peri-event time histogram (PETH) quickly with estimator flexibility.\n    Assumes that the index is time and the columns are trials/cells/etc.\n\n    Parameters\n    ----------\n    peth : pd.DataFrame or np.ndarray\n        PETH to plot. Rows are time, columns are trials/cells/etc.\n    ts : np.ndarray, optional\n        Time points to plot, by default None\n    ax : plt.Axes, optional\n        Axis to plot on, by default None\n    ci : float, optional\n        Confidence interval to plot, by default 0.95\n    smooth : bool, optional\n        Whether to smooth the PETH, by default False\n    smooth_window : float, optional\n        Window to smooth the PETH, by default 0.30\n    smooth_std : int, optional\n        Standard deviation of the smoothing window, by default 5\n    smooth_win_type : str, optional\n        Type of smoothing window, by default \"gaussian\"\n    alpha : float, optional\n        Transparency of the confidence interval, by default 0.2\n    estimator : Callable, optional\n        Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.\n    n_boot : int, optional\n        Number of bootstrap samples for CI if estimator is not mean (default: 1000)\n    random_state : int, optional\n        Random seed for bootstrapping\n    **kwargs\n        Keyword arguments to pass to ax.plot\n\n    Returns\n    -------\n    plt.Axes\n        Axis with plot\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; import bottleneck as bn\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from neuro_py.plotting.events import plot_peth_fast\n    &gt;&gt;&gt; # Simulate PETH data: 100 time points, 20 trials\n    &gt;&gt;&gt; peth = np.random.randn(100, 20)\n    &gt;&gt;&gt; plot_peth_fast(peth)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=bn.nanmedian)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=np.nanmedian)\n    &gt;&gt;&gt; plot_peth_fast(peth, estimator=lambda x, axis: np.nanpercentile(x, 25, axis=axis))\n    &gt;&gt;&gt; ts = np.linspace(-1, 1, 100)\n    &gt;&gt;&gt; df = pd.DataFrame(peth, index=ts)\n    &gt;&gt;&gt; plot_peth_fast(df)\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    if not isinstance(peth, pd.DataFrame):\n        if ts is None:\n            ts = np.arange(peth.shape[0])\n        if len(ts) == peth.shape[1]:\n            peth = peth.T\n        peth = pd.DataFrame(index=ts, columns=np.arange(peth.shape[1]), data=peth)\n\n    if smooth:\n        smooth_window = int(smooth_window / np.diff(peth.index)[0])\n        peth = (\n            peth.rolling(\n                window=smooth_window,\n                win_type=smooth_win_type,\n                center=True,\n                min_periods=1,\n            )\n            .mean(std=smooth_std)\n            .copy()\n        )\n\n    # Central tendency\n    center = estimator(peth.values if hasattr(peth, \"values\") else peth, axis=1)\n    ax.plot(peth.index, center, **kwargs)\n    kwargs.pop(\"label\", None)\n\n    # Confidence interval\n    if estimator in (np.nanmean, bn.nanmean, np.nanmedian, bn.nanmedian):\n        lower, upper = confidence_intervals(peth.values.T, conf=ci, estimator=estimator)\n    else:\n        rng = np.random.default_rng(random_state)\n        boot_stats = np.empty((n_boot, peth.shape[0]))\n        for i in range(n_boot):\n            sample_idx = rng.integers(0, peth.shape[1], size=peth.shape[1])\n            boot_stats[i] = estimator(peth.values[:, sample_idx], axis=1)\n        lower = np.percentile(boot_stats, 100 * (1 - ci) / 2, axis=0)\n        upper = np.percentile(boot_stats, 100 * (1 + ci) / 2, axis=0)\n    ax.fill_between(peth.index, lower, upper, alpha=alpha, **kwargs)\n    ax.set_xlabel(\"Time (s)\")\n    sns.despine(ax=ax)\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/","title":"neuro_py.plotting.figure_helpers","text":""},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.adjust_box_widths","title":"<code>adjust_box_widths(g, fac)</code>","text":"<p>Adjust the widths of boxes in a Seaborn-generated boxplot.</p> <p>This function iterates through the axes of the provided FacetGrid and modifies the widths of the boxplot boxes by a specified factor.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>FacetGrid</code> <p>The FacetGrid object containing the boxplot.</p> required <code>fac</code> <code>float</code> <p>The factor by which to adjust the box widths. A value &lt; 1 will narrow the boxes, while &gt; 1 will widen them.</p> required <p>Returns:</p> Type Description <code>None</code> <p>The function modifies the box widths in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import seaborn as sns\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; tips = sns.load_dataset(\"tips\")\n&gt;&gt;&gt; g = sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n&gt;&gt;&gt; adjust_box_widths(g, 0.5)  # Narrow the boxes by 50%\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def adjust_box_widths(g: sns.axisgrid.FacetGrid, fac: float) -&gt; None:\n    \"\"\"\n    Adjust the widths of boxes in a Seaborn-generated boxplot.\n\n    This function iterates through the axes of the provided FacetGrid\n    and modifies the widths of the boxplot boxes by a specified factor.\n\n    Parameters\n    ----------\n    g : seaborn.axisgrid.FacetGrid\n        The FacetGrid object containing the boxplot.\n    fac : float\n        The factor by which to adjust the box widths.\n        A value &lt; 1 will narrow the boxes, while &gt; 1 will widen them.\n\n    Returns\n    -------\n    None\n        The function modifies the box widths in place.\n\n    Examples\n    -------\n    &gt;&gt;&gt; import seaborn as sns\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; tips = sns.load_dataset(\"tips\")\n    &gt;&gt;&gt; g = sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n    &gt;&gt;&gt; adjust_box_widths(g, 0.5)  # Narrow the boxes by 50%\n    \"\"\"\n\n    # iterating through Axes instances\n    for ax in g.axes:\n        # iterating through axes artists:\n        for c in ax.get_children():\n            # searching for PathPatches\n            if isinstance(c, PathPatch):\n                # getting current width of box:\n                p = c.get_path()\n                verts = p.vertices\n                verts_sub = verts[:-1]\n                xmin = np.min(verts_sub[:, 0])\n                xmax = np.max(verts_sub[:, 0])\n                xmid = 0.5 * (xmin + xmax)\n                xhalf = 0.5 * (xmax - xmin)\n\n                # setting new width of box\n                xmin_new = xmid - fac * xhalf\n                xmax_new = xmid + fac * xhalf\n                verts_sub[verts_sub[:, 0] == xmin, 0] = xmin_new\n                verts_sub[verts_sub[:, 0] == xmax, 0] = xmax_new\n\n                # setting new width of median line\n                for line in ax.lines:\n                    if np.all(line.get_xdata() == [xmin, xmax]):\n                        line.set_xdata([xmin_new, xmax_new])\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.lighten_color","title":"<code>lighten_color(color, amount=0.5)</code>","text":"<p>Lightens a hex color by blending it with white by a given percentage.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>str</code> <p>Hex color code (e.g., '#AABBCC').</p> required <code>amount</code> <code>float</code> <p>Fraction of the lightening, where 0 is no change and 1 is white, by default 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>str</code> <p>Lightened hex color code (e.g., '#FFFFFF').</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the color string is not a valid hex code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lighten_color(\"#AABBCC\", 0.3)\n'#c3cfdb'\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def lighten_color(color: str, amount: float = 0.5) -&gt; str:\n    \"\"\"\n    Lightens a hex color by blending it with white by a given percentage.\n\n    Parameters\n    ----------\n    color : str\n        Hex color code (e.g., '#AABBCC').\n    amount : float, optional\n        Fraction of the lightening, where 0 is no change and 1 is white, by default 0.5.\n\n    Returns\n    -------\n    str\n        Lightened hex color code (e.g., '#FFFFFF').\n\n    Raises\n    ------\n    ValueError\n        If the color string is not a valid hex code.\n\n    Examples\n    -------\n    &gt;&gt;&gt; lighten_color(\"#AABBCC\", 0.3)\n    '#c3cfdb'\n    \"\"\"\n    try:\n        c = color.lstrip(\"#\")\n        c = tuple(int(c[i : i + 2], 16) for i in (0, 2, 4))\n        c = (\n            int((1 - amount) * c[0] + amount * 255),\n            int((1 - amount) * c[1] + amount * 255),\n            int((1 - amount) * c[2] + amount * 255),\n        )\n        return \"#%02x%02x%02x\" % c\n    except ValueError:\n        return color\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.paired_lines","title":"<code>paired_lines(data, x, y, hue=None, units=None, order=None, hue_order=None, style=None, style_order=None, style_map=None, set_labels=True, dodge=True, dodge_width=0.2, color=None, palette=None, alpha=0.5, lw=1, ax=None, zorder=0, **kwargs)</code>","text":"<p>Draw lines connecting paired points within each x-category.</p> <p>Designed to complement seaborn boxplot/stripplot for visualizing paired data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input data.</p> required <code>x</code> <code>str</code> <p>Column name for x-axis categories.</p> required <code>y</code> <code>str</code> <p>Column name for y-axis values.</p> required <code>hue</code> <code>str</code> <p>Column to separate points within each x-category (e.g., two maze conditions). When provided alone: connects points across hue values within each x-category. When provided with units: connects points with the same unit but different hue values within each x-category.</p> <code>None</code> <code>units</code> <code>str</code> <p>Column that defines which points belong together (e.g., unique_basepath). When provided alone: connects points across x-categories with the same unit. When provided with hue: groups by (x, units) and connects across hue values.</p> <code>None</code> <code>order</code> <code>list</code> <p>Order of x-axis categories (matches seaborn convention).</p> <code>None</code> <code>hue_order</code> <code>list</code> <p>Order of hue levels. If provided, points will be connected in this order.</p> <code>None</code> <code>style</code> <code>str</code> <p>Column to map to line style (e.g., linestyle). Mimics seaborn's style mapping.</p> <code>None</code> <code>style_order</code> <code>list</code> <p>Order of style levels. If provided, styles will follow this order.</p> <code>None</code> <code>style_map</code> <code>dict or list</code> <p>Mapping from style level to matplotlib linestyle. If a list is provided, it will be cycled across style levels.</p> <code>None</code> <code>set_labels</code> <code>bool</code> <p>If True, set x and y labels when not already present on the axes.</p> <code>True</code> <code>dodge</code> <code>bool</code> <p>Apply dodge offset like seaborn's dodge parameter.</p> <code>True</code> <code>dodge_width</code> <code>float</code> <p>Width of the dodge offset between hue categories.</p> <code>0.2</code> <code>color</code> <code>str</code> <p>Line color. If None and palette is not provided, defaults to \"gray\". Ignored if palette is provided.</p> <code>None</code> <code>palette</code> <code>str, list, or dict</code> <p>Color palette for lines. Can be a seaborn palette name, list of colors, or dict mapping units to colors. If provided, overrides color parameter.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Line transparency.</p> <code>0.5</code> <code>lw</code> <code>float</code> <p>Line width.</p> <code>1</code> <code>ax</code> <code>matplotlib Axes</code> <p>Axes to plot on. Defaults to current axes.</p> <code>None</code> <code>zorder</code> <code>int</code> <p>Z-order for the lines.</p> <code>0</code> <code>**kwargs</code> <code>additional keyword arguments</code> <p>Passed to matplotlib's plot() function (e.g., linestyle, marker, etc.).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>matplotlib Axes</code> Notes <p>The function supports three execution modes depending on parameters:</p> <ol> <li>Units only (units provided, hue=None): Connects lines across x-categories    for each unit, useful for tracking individual subjects/units across conditions.</li> <li>Hue only (hue provided, units=None): Connects points across different hue    values within each x-category, useful for showing transitions across levels.</li> <li>Units + Hue (both provided): Groups by (x, units) and connects points    across hue values, allowing unit-specific lines colored/styled by hue.</li> </ol> <p>If <code>data</code> contains multiple rows with the same combination of <code>x</code>, <code>units</code>, and (if used) <code>hue</code>, the implementation selects the first matching value internally and ignores additional duplicates. If this is not the desired behavior, aggregate or deduplicate the data for each (<code>x</code>, <code>units</code>, <code>hue</code>) combination before calling this function.</p> <p>Examples:</p> <p>Basic usage connecting points across conditions:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; import seaborn as sns\n&gt;&gt;&gt; data = pd.DataFrame({\n...     'condition': ['A', 'B', 'A', 'B'],\n...     'value': [1, 2, 1.5, 2.5],\n...     'subject': ['S1', 'S1', 'S2', 'S2']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.boxplot(data=data, x='condition', y='value', ax=ax)\n&gt;&gt;&gt; sns.stripplot(data=data, x='condition', y='value', ax=ax, color='k', alpha=0.6)\n&gt;&gt;&gt; paired_lines(data, x='condition', y='value', units='subject', ax=ax, color='gray')\n</code></pre> <p>With hue to separate paired points by a second variable (e.g., maze type):</p> <pre><code>&gt;&gt;&gt; data_hue = pd.DataFrame({\n...     'condition': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n...     'value': [1, 2, 1.5, 2.5, 0.9, 2.1, 1.2, 2.3],\n...     'subject': ['S1', 'S1', 'S2', 'S2', 'S1', 'S1', 'S2', 'S2'],\n...     'maze': ['M1', 'M1', 'M1', 'M1', 'M2', 'M2', 'M2', 'M2']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.boxplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax)\n&gt;&gt;&gt; sns.stripplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax, color='k', alpha=0.3, dodge=True)\n&gt;&gt;&gt; paired_lines(data_hue, x='condition', y='value', hue='maze', units='subject',\n...               palette=['red', 'blue'], ax=ax)\n</code></pre> <p>With hue only (connecting across hue values within each x-category):</p> <pre><code>&gt;&gt;&gt; data_device = pd.DataFrame({\n...     'trial': ['A', 'A', 'A', 'B', 'B', 'B'],\n...     'value': [1.0, 1.5, 1.2, 2.0, 2.5, 2.3],\n...     'device': ['X', 'Y', 'Z', 'X', 'Y', 'Z']\n... })\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; sns.stripplot(data=data_device, x='trial', y='value', hue='device', jitter=0, dodge=True, ax=ax)\n&gt;&gt;&gt; paired_lines(data_device, x='trial', y='value', hue='device', ax=ax, color='gray')\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def paired_lines(\n    data: pd.DataFrame,\n    x: str,\n    y: str,\n    hue: Optional[str] = None,\n    units: Optional[str] = None,\n    order: Optional[List[Hashable]] = None,\n    hue_order: Optional[List[Hashable]] = None,\n    style: Optional[str] = None,\n    style_order: Optional[List[Hashable]] = None,\n    style_map: Optional[Union[Dict[str, str], List[str]]] = None,\n    set_labels: bool = True,\n    dodge: bool = True,\n    dodge_width: float = 0.2,\n    color: Optional[str] = None,\n    palette: Optional[Union[str, List[str], dict]] = None,\n    alpha: float = 0.5,\n    lw: float = 1,\n    ax: Optional[matplotlib.axes.Axes] = None,\n    zorder: int = 0,\n    **kwargs: Any,\n) -&gt; matplotlib.axes.Axes:\n    \"\"\"\n    Draw lines connecting paired points within each x-category.\n\n    Designed to complement seaborn boxplot/stripplot for visualizing paired data.\n\n    Parameters\n    ----------\n    data : DataFrame\n        Input data.\n    x : str\n        Column name for x-axis categories.\n    y : str\n        Column name for y-axis values.\n    hue : str, optional\n        Column to separate points within each x-category (e.g., two maze conditions).\n        When provided alone: connects points across hue values within each x-category.\n        When provided with units: connects points with the same unit but different hue\n        values within each x-category.\n    units : str, optional\n        Column that defines which points belong together (e.g., unique_basepath).\n        When provided alone: connects points across x-categories with the same unit.\n        When provided with hue: groups by (x, units) and connects across hue values.\n    order : list, optional\n        Order of x-axis categories (matches seaborn convention).\n    hue_order : list, optional\n        Order of hue levels. If provided, points will be connected in this order.\n    style : str, optional\n        Column to map to line style (e.g., linestyle). Mimics seaborn's style mapping.\n    style_order : list, optional\n        Order of style levels. If provided, styles will follow this order.\n    style_map : dict or list, optional\n        Mapping from style level to matplotlib linestyle. If a list is provided,\n        it will be cycled across style levels.\n    set_labels : bool, default True\n        If True, set x and y labels when not already present on the axes.\n    dodge : bool, default True\n        Apply dodge offset like seaborn's dodge parameter.\n    dodge_width : float, default 0.2\n        Width of the dodge offset between hue categories.\n    color : str, optional\n        Line color. If None and palette is not provided, defaults to \"gray\".\n        Ignored if palette is provided.\n    palette : str, list, or dict, optional\n        Color palette for lines. Can be a seaborn palette name, list of colors,\n        or dict mapping units to colors. If provided, overrides color parameter.\n    alpha : float, default 0.5\n        Line transparency.\n    lw : float, default 1\n        Line width.\n    ax : matplotlib Axes, optional\n        Axes to plot on. Defaults to current axes.\n    zorder : int, default 0\n        Z-order for the lines.\n    **kwargs : additional keyword arguments\n        Passed to matplotlib's plot() function (e.g., linestyle, marker, etc.).\n\n    Returns\n    -------\n    ax : matplotlib Axes\n\n    Notes\n    -----\n    The function supports three execution modes depending on parameters:\n\n    1. **Units only** (units provided, hue=None): Connects lines across x-categories\n       for each unit, useful for tracking individual subjects/units across conditions.\n    2. **Hue only** (hue provided, units=None): Connects points across different hue\n       values within each x-category, useful for showing transitions across levels.\n    3. **Units + Hue** (both provided): Groups by (x, units) and connects points\n       across hue values, allowing unit-specific lines colored/styled by hue.\n\n    If ``data`` contains multiple rows with the same combination of ``x``,\n    ``units``, and (if used) ``hue``, the implementation selects the first\n    matching value internally and ignores additional duplicates. If this is\n    not the desired behavior, aggregate or deduplicate the data for each\n    (``x``, ``units``, ``hue``) combination before calling this function.\n\n    Examples\n    --------\n    Basic usage connecting points across conditions:\n\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; import seaborn as sns\n    &gt;&gt;&gt; data = pd.DataFrame({\n    ...     'condition': ['A', 'B', 'A', 'B'],\n    ...     'value': [1, 2, 1.5, 2.5],\n    ...     'subject': ['S1', 'S1', 'S2', 'S2']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.boxplot(data=data, x='condition', y='value', ax=ax)\n    &gt;&gt;&gt; sns.stripplot(data=data, x='condition', y='value', ax=ax, color='k', alpha=0.6)\n    &gt;&gt;&gt; paired_lines(data, x='condition', y='value', units='subject', ax=ax, color='gray')\n\n    With hue to separate paired points by a second variable (e.g., maze type):\n\n    &gt;&gt;&gt; data_hue = pd.DataFrame({\n    ...     'condition': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n    ...     'value': [1, 2, 1.5, 2.5, 0.9, 2.1, 1.2, 2.3],\n    ...     'subject': ['S1', 'S1', 'S2', 'S2', 'S1', 'S1', 'S2', 'S2'],\n    ...     'maze': ['M1', 'M1', 'M1', 'M1', 'M2', 'M2', 'M2', 'M2']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.boxplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax)\n    &gt;&gt;&gt; sns.stripplot(data=data_hue, x='condition', y='value', hue='maze', ax=ax, color='k', alpha=0.3, dodge=True)\n    &gt;&gt;&gt; paired_lines(data_hue, x='condition', y='value', hue='maze', units='subject',\n    ...               palette=['red', 'blue'], ax=ax)\n\n    With hue only (connecting across hue values within each x-category):\n\n    &gt;&gt;&gt; data_device = pd.DataFrame({\n    ...     'trial': ['A', 'A', 'A', 'B', 'B', 'B'],\n    ...     'value': [1.0, 1.5, 1.2, 2.0, 2.5, 2.3],\n    ...     'device': ['X', 'Y', 'Z', 'X', 'Y', 'Z']\n    ... })\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; sns.stripplot(data=data_device, x='trial', y='value', hue='device', jitter=0, dodge=True, ax=ax)\n    &gt;&gt;&gt; paired_lines(data_device, x='trial', y='value', hue='device', ax=ax, color='gray')\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Validate required columns\n    required_cols = {x, y}\n    for optional_col in (hue, units, style):\n        if optional_col is not None:\n            required_cols.add(optional_col)\n    missing_cols = [col for col in required_cols if col not in data.columns]\n    if missing_cols:\n        raise ValueError(f\"paired_lines: missing required columns: {missing_cols}\")\n\n    if order is None:\n        order = data[x].unique()\n    else:\n        unknown_x = [val for val in data[x].unique() if val not in order]\n        if unknown_x:\n            raise ValueError(\n                f\"paired_lines: x contains categories not in 'order': {unknown_x}\"\n            )\n\n    x_lookup = {label: i for i, label in enumerate(order)}\n\n    # Get hue values\n    if hue:\n        if hue_order is None:\n            hue_vals = sorted(data[hue].unique())\n        else:\n            hue_vals = hue_order\n            unknown_hue = [val for val in data[hue].unique() if val not in hue_order]\n            if unknown_hue:\n                raise ValueError(\n                    f\"paired_lines: hue contains categories not in 'hue_order': {unknown_hue}\"\n                )\n    else:\n        hue_vals = [None]\n\n    # Warn on duplicate rows for (x, units, hue) combinations\n    dup_keys = [x]\n    if units:\n        dup_keys.append(units)\n    if hue:\n        dup_keys.append(hue)\n    dup_counts = data.groupby(dup_keys, dropna=False).size()\n    num_dup_groups = int((dup_counts &gt; 1).sum())\n    if num_dup_groups:\n        warnings.warn(\n            (\n                f\"paired_lines: detected {num_dup_groups} duplicate group(s) for \"\n                f\"combinations of {tuple(dup_keys)}; selecting the first value per group. \"\n                \"Consider aggregating or deduplicating your data.\"\n            ),\n            UserWarning,\n        )\n\n    # Get style values and mapping\n    if style:\n        if style_order is None:\n            style_vals = sorted(data[style].dropna().unique())\n        else:\n            style_vals = style_order\n\n        if style_map is None:\n            default_styles = [\"-\", \"--\", \"-.\", \":\"]\n            style_map_resolved = {\n                val: sty for val, sty in zip(style_vals, cycle(default_styles))\n            }\n        elif isinstance(style_map, list):\n            style_map_resolved = {\n                val: sty for val, sty in zip(style_vals, cycle(style_map))\n            }\n        else:\n            style_map_resolved = style_map\n    else:\n        style_map_resolved = None\n\n    # Compute dodge offset\n    effective_dodge_width = dodge_width if dodge and hue else 0\n\n    # Set up color mapping\n    if palette is not None:\n        if isinstance(palette, str):\n            # Seaborn palette name\n            colors = sns.color_palette(\n                palette, n_colors=len(data[units].unique()) if units else 1\n            )\n            if units:\n                unit_vals = sorted(data[units].unique())\n                color_map = dict(zip(unit_vals, colors))\n            else:\n                color_map = None\n        elif isinstance(palette, dict):\n            color_map = palette\n        elif isinstance(palette, list):\n            if units:\n                unit_vals = sorted(data[units].unique())\n                color_map = dict(zip(unit_vals, palette))\n            else:\n                color_map = None\n        else:\n            color_map = None\n    else:\n        color_map = None\n        if color is None:\n            color = \"gray\"\n\n    if hue:\n        # With hue: group by x and units, connect across hue values within each x-category\n        if units:\n            groupby_cols = [x, units]\n        else:\n            groupby_cols = [x]\n\n        for group_key, g in data.groupby(groupby_cols, sort=False):\n            if units:\n                x_cat, unit_val = group_key\n            else:\n                # When grouping by single column as list, pandas returns 1-tuple\n                x_cat = group_key[0] if isinstance(group_key, tuple) else group_key\n                unit_val = None\n\n            if x_cat not in x_lookup:\n                continue\n\n            # Determine line color for this unit\n            if color_map and unit_val is not None:\n                line_color = color_map.get(unit_val, color)\n            else:\n                line_color = color\n\n            # Determine line style\n            plot_kwargs = dict(kwargs)\n            if style_map_resolved is not None:\n                style_val = g[style].iloc[0]\n                line_style = style_map_resolved.get(style_val, \"-\")\n                plot_kwargs.pop(\"linestyle\", None)\n                plot_kwargs.pop(\"ls\", None)\n                plot_kwargs[\"linestyle\"] = line_style\n\n            x0 = x_lookup[x_cat]\n\n            # Get data for each hue value in order\n            hue_data = []\n            for hue_val in hue_vals:\n                mask = g[hue] == hue_val\n                if mask.any():\n                    hue_data.append((hue_val, g[mask][y].values[0]))\n\n            # Connect consecutive pairs\n            if len(hue_data) &gt;= 2:\n                # Calculate x positions with dodge\n                n_hue = len(hue_vals)\n                if n_hue &gt; 1:\n                    hue_offsets = np.linspace(\n                        -effective_dodge_width, effective_dodge_width, n_hue\n                    )\n                else:\n                    hue_offsets = [0]\n\n                hue_to_offset = {\n                    hue_val: offset for hue_val, offset in zip(hue_vals, hue_offsets)\n                }\n\n                # Draw lines between consecutive pairs\n                for i in range(len(hue_data) - 1):\n                    hue_val1, y1 = hue_data[i]\n                    hue_val2, y2 = hue_data[i + 1]\n\n                    x1 = x0 + hue_to_offset[hue_val1]\n                    x2 = x0 + hue_to_offset[hue_val2]\n\n                    ax.plot(\n                        [x1, x2],\n                        [y1, y2],\n                        color=line_color,\n                        alpha=alpha,\n                        lw=lw,\n                        zorder=zorder,\n                        **plot_kwargs,\n                    )\n    else:\n        # No hue: group by units only, connect across x-categories\n        if units:\n            for unit_val, g in data.groupby(units, sort=False):\n                # Determine line color for this unit\n                if color_map and unit_val is not None:\n                    line_color = color_map.get(unit_val, color)\n                else:\n                    line_color = color\n\n                plot_kwargs = dict(kwargs)\n                if style_map_resolved is not None:\n                    style_val = g[style].iloc[0]\n                    line_style = style_map_resolved.get(style_val, \"-\")\n                    plot_kwargs.pop(\"linestyle\", None)\n                    plot_kwargs.pop(\"ls\", None)\n                    plot_kwargs[\"linestyle\"] = line_style\n\n                # Get data for each x-category in order\n                x_data = []\n                for x_cat in order:\n                    mask = g[x] == x_cat\n                    if mask.any():\n                        x_pos = x_lookup[x_cat]\n                        y_val = g[mask][y].values[0]\n                        x_data.append((x_pos, y_val))\n\n                # Connect consecutive points across x-categories\n                if len(x_data) &gt;= 2:\n                    for i in range(len(x_data) - 1):\n                        x1, y1 = x_data[i]\n                        x2, y2 = x_data[i + 1]\n\n                        ax.plot(\n                            [x1, x2],\n                            [y1, y2],\n                            color=line_color,\n                            alpha=alpha,\n                            lw=lw,\n                            zorder=zorder,\n                            **plot_kwargs,\n                        )\n        else:\n            # No units and no hue: just connect points in order across x-categories\n            x_data = []\n            for x_cat in order:\n                mask = data[x] == x_cat\n                if mask.any():\n                    x_pos = x_lookup[x_cat]\n                    y_val = data[mask][y].values[0]\n                    x_data.append((x_pos, y_val))\n\n            # Connect consecutive points\n            if len(x_data) &gt;= 2:\n                # Compute plot kwargs and style once, since they do not change across segments\n                plot_kwargs = dict(kwargs)\n                if style_map_resolved is not None:\n                    style_val = data[style].iloc[0]\n                    line_style = style_map_resolved.get(style_val, \"-\")\n                    plot_kwargs.pop(\"linestyle\", None)\n                    plot_kwargs.pop(\"ls\", None)\n                    plot_kwargs[\"linestyle\"] = line_style\n\n                for i in range(len(x_data) - 1):\n                    x1, y1 = x_data[i]\n                    x2, y2 = x_data[i + 1]\n\n                    ax.plot(\n                        [x1, x2],\n                        [y1, y2],\n                        color=color,\n                        alpha=alpha,\n                        lw=lw,\n                        zorder=zorder,\n                        **plot_kwargs,\n                    )\n\n    # Adjust categorical axis like seaborn does: set ticks, labels, and limits\n    # Since we plot with numeric positions internally, we explicitly set the labels\n    n_categories = len(order)\n    ax.set_xticks(range(n_categories))\n    ax.set_xticklabels(order)\n    ax.set_xlim(-0.5, n_categories - 0.5, auto=None)\n\n    # Set axis labels if requested and not already set\n    if set_labels:\n        if not ax.get_xlabel():\n            ax.set_xlabel(x)\n        if not ax.get_ylabel():\n            ax.set_ylabel(y)\n\n    return ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.plot_joint_peth","title":"<code>plot_joint_peth(peth_1, peth_2, ts, smooth_std=2, labels=['peth_1', 'peth_2', 'event'])</code>","text":"<p>Plot joint peri-event time histograms (PETHs) and the difference between the observed and expected responses.</p> <p>Parameters:</p> Name Type Description Default <code>peth_1</code> <code>ndarray</code> <p>Peri-event time histogram (PETH) for the first event. Shape: (n_events, n_time_points).</p> required <code>peth_2</code> <code>ndarray</code> <p>Peri-event time histogram (PETH) for the second event. Shape: (n_events, n_time_points).</p> required <code>ts</code> <code>ndarray</code> <p>Time vector for the PETHs.</p> required <code>smooth_std</code> <code>float</code> <p>Standard deviation of the Gaussian kernel used to smooth the PETHs. Default is 2.</p> <code>2</code> <code>labels</code> <code>List[str]</code> <p>Labels for the PETHs. Default is [\"peth_1\", \"peth_2\", \"event\"].</p> <code>['peth_1', 'peth_2', 'event']</code> <p>Returns:</p> Type Description <code>Tuple[Figure, ndarray]</code> <p>Figure and axes objects for the plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; peth_1 = np.random.rand(10, 100)  # Example data for peth_1\n&gt;&gt;&gt; peth_2 = np.random.rand(10, 100)  # Example data for peth_2\n&gt;&gt;&gt; ts = np.linspace(-1, 1, 100)  # Example time vector\n&gt;&gt;&gt; plot_joint_peth(peth_1, peth_2, ts)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def plot_joint_peth(\n    peth_1: np.ndarray,\n    peth_2: np.ndarray,\n    ts: np.ndarray,\n    smooth_std: float = 2,\n    labels: list = [\"peth_1\", \"peth_2\", \"event\"],\n) -&gt; Tuple[plt.Figure, np.ndarray]:\n    \"\"\"\n    Plot joint peri-event time histograms (PETHs) and the difference between the observed and expected responses.\n\n    Parameters\n    ----------\n    peth_1 : np.ndarray\n        Peri-event time histogram (PETH) for the first event. Shape: (n_events, n_time_points).\n    peth_2 : np.ndarray\n        Peri-event time histogram (PETH) for the second event. Shape: (n_events, n_time_points).\n    ts : np.ndarray\n        Time vector for the PETHs.\n    smooth_std : float, optional\n        Standard deviation of the Gaussian kernel used to smooth the PETHs. Default is 2.\n    labels : List[str], optional\n        Labels for the PETHs. Default is [\"peth_1\", \"peth_2\", \"event\"].\n\n    Returns\n    -------\n    Tuple[plt.Figure, np.ndarray]\n        Figure and axes objects for the plot.\n\n    Examples\n    -------\n    &gt;&gt;&gt; peth_1 = np.random.rand(10, 100)  # Example data for peth_1\n    &gt;&gt;&gt; peth_2 = np.random.rand(10, 100)  # Example data for peth_2\n    &gt;&gt;&gt; ts = np.linspace(-1, 1, 100)  # Example time vector\n    &gt;&gt;&gt; plot_joint_peth(peth_1, peth_2, ts)\n\n    \"\"\"\n\n    window = [ts[0], ts[-1]]\n\n    joint, expected, difference = joint_peth(peth_1, peth_2, smooth_std=smooth_std)\n\n    # get average of diagonals\n    corrected = average_diagonal(difference.T)\n    # get center values of corrected_2\n    corrected = corrected[\n        difference.shape[1] // 2 : (difference.shape[1] // 2) + difference.shape[1]\n    ]\n\n    fig, ax = plt.subplots(\n        2,\n        4,\n        figsize=(12, 4),\n        gridspec_kw={\"width_ratios\": [0.25, 1, 1, 1], \"height_ratios\": [0.25, 1]},\n    )\n    # space between panels\n    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n    ax[1, 1].imshow(\n        joint,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n\n    ax[0, 1].plot(\n        np.linspace(window[0], window[-1], len(joint)), joint.mean(axis=0), color=\"k\"\n    )\n    ax[0, 1].set_ylabel(f\"{labels[1]} rate\")\n    ax[0, 1].axvline(0, ls=\"--\", color=\"k\")\n\n    ax[1, 0].plot(\n        joint.mean(axis=1), np.linspace(window[0], window[-1], len(joint)), color=\"k\"\n    )\n    ax[1, 0].axhline(0, ls=\"--\", color=\"k\")\n    ax[1, 0].set_xlabel(f\"{labels[0]} rate\")\n\n    # plt.colorbar(f)\n    ax[1, 2].imshow(\n        expected,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n    ax[1, 2].set_title(\"Expected\")\n\n    ax[1, 3].imshow(\n        difference,\n        aspect=\"auto\",\n        interpolation=\"nearest\",\n        origin=\"lower\",\n        extent=[window[0], window[-1], window[0], window[-1]],\n    )\n\n    ax[0, 3].set_title(f\"corrected {labels[0]} response to {labels[1]}\")\n    ax[0, 3].plot(\n        np.linspace(window[0], window[-1], len(corrected)),\n        corrected,\n        color=\"k\",\n    )\n    ax[0, 3].set_xlim(window[0], window[-1])\n    ax[0, 3].axvline(0, ls=\"--\", color=\"k\")\n\n    for a in ax[1, 1:].ravel():\n        a.plot([-1, 1], [-1, 1], \"k--\")\n        a.axvline(0, c=\"w\", ls=\"--\")\n        a.axhline(0, c=\"w\", ls=\"--\")\n        a.set_xlim(window[0], window[-1])\n        a.set_ylim(window[0], window[-1])\n    ax[0, 0].axis(\"off\")\n    ax[0, 2].axis(\"off\")\n\n    ax[1, 1].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n    ax[1, 2].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n    ax[1, 3].set_xlabel(f\"{labels[1]} time from {labels[-1]} (s)\")\n\n    ax[1, 0].set_ylabel(f\"{labels[0]} time from {labels[-1]} (s)\")\n\n    # turn off x ticsk\n    ax[0, 1].set_xticks([])\n    ax[0, 3].set_xticks([])\n\n    ax[1, 1].set_yticks([])\n    ax[1, 2].set_yticks([])\n    ax[1, 3].set_yticks([])\n\n    ax[0, 3].set_xlabel(\"obs - expected\")\n\n    sns.despine()\n\n    return fig, ax\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.restore_natural_scale","title":"<code>restore_natural_scale(ax, min_, max_, n_steps=4, x_axis=True, y_axis=True)</code>","text":"<p>Converts logarithmic scale ticks to natural scale (base 10) for the specified axes.</p> <p>This function sets the ticks on the specified axes to be evenly spaced in the logarithmic scale and converts them back to the natural scale for display.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axis to modify.</p> required <code>min_</code> <code>float</code> <p>The minimum value for the ticks in logarithmic scale.</p> required <code>max_</code> <code>float</code> <p>The maximum value for the ticks in logarithmic scale.</p> required <code>n_steps</code> <code>int</code> <p>The number of ticks to create, by default 4.</p> <code>4</code> <code>x_axis</code> <code>bool</code> <p>If True, adjust the x-axis, by default True.</p> <code>True</code> <code>y_axis</code> <code>bool</code> <p>If True, adjust the y-axis, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>This function modifies the axis ticks in place.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import matplotlib.pyplot as plt\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; ax.set_xscale('log10')\n&gt;&gt;&gt; ax.plot(np.log10([1, 10, 100]), np.log10([1, 10, 100]))\n&gt;&gt;&gt; restore_natural_scale(ax, 0, 2)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def restore_natural_scale(\n    ax: matplotlib.axes.Axes,\n    min_: float,\n    max_: float,\n    n_steps: int = 4,\n    x_axis: bool = True,\n    y_axis: bool = True,\n) -&gt; None:\n    \"\"\"\n    Converts logarithmic scale ticks to natural scale (base 10) for the specified axes.\n\n    This function sets the ticks on the specified axes to be evenly spaced\n    in the logarithmic scale and converts them back to the natural scale\n    for display.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes\n        The axis to modify.\n    min_ : float\n        The minimum value for the ticks in logarithmic scale.\n    max_ : float\n        The maximum value for the ticks in logarithmic scale.\n    n_steps : int, optional\n        The number of ticks to create, by default 4.\n    x_axis : bool, optional\n        If True, adjust the x-axis, by default True.\n    y_axis : bool, optional\n        If True, adjust the y-axis, by default True.\n\n    Returns\n    -------\n    None\n        This function modifies the axis ticks in place.\n\n    Examples\n    -------\n    &gt;&gt;&gt; import matplotlib.pyplot as plt\n    &gt;&gt;&gt; fig, ax = plt.subplots()\n    &gt;&gt;&gt; ax.set_xscale('log10')\n    &gt;&gt;&gt; ax.plot(np.log10([1, 10, 100]), np.log10([1, 10, 100]))\n    &gt;&gt;&gt; restore_natural_scale(ax, 0, 2)\n    \"\"\"\n    ticks = np.linspace(min_, max_, n_steps)\n\n    if x_axis:\n        ax.set_xticks(ticks)\n        ax.set_xticklabels(np.round(10**ticks, 3))\n\n    if y_axis:\n        ax.set_yticks(ticks)\n        ax.set_yticklabels(np.round(10**ticks, 3))\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.set_equal_axis_range","title":"<code>set_equal_axis_range(ax1, ax2)</code>","text":"<p>Synchronizes the x and y axis ranges between two matplotlib axes.</p> <p>Parameters:</p> Name Type Description Default <code>ax1</code> <code>Axes</code> <p>The first axis to synchronize.</p> required <code>ax2</code> <code>Axes</code> <p>The second axis to synchronize.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; fig, (ax1, ax2) = plt.subplots(1, 2)\n&gt;&gt;&gt; ax1.plot([1, 2, 3], [4, 5, 6])\n&gt;&gt;&gt; ax2.plot([1, 2, 3], [2, 3, 4])\n&gt;&gt;&gt; set_equal_axis_range(ax1, ax2)\n</code></pre> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_equal_axis_range(ax1: plt.Axes, ax2: plt.Axes) -&gt; None:\n    \"\"\"\n    Synchronizes the x and y axis ranges between two matplotlib axes.\n\n    Parameters\n    ----------\n    ax1 : matplotlib.axes.Axes\n        The first axis to synchronize.\n    ax2 : matplotlib.axes.Axes\n        The second axis to synchronize.\n\n    Examples\n    -------\n    &gt;&gt;&gt; fig, (ax1, ax2) = plt.subplots(1, 2)\n    &gt;&gt;&gt; ax1.plot([1, 2, 3], [4, 5, 6])\n    &gt;&gt;&gt; ax2.plot([1, 2, 3], [2, 3, 4])\n    &gt;&gt;&gt; set_equal_axis_range(ax1, ax2)\n    \"\"\"\n    # Get x and y axis limits for both axes\n    axis_x_values = np.hstack(np.array((ax1.get_xlim(), ax2.get_xlim())))\n    axis_y_values = np.hstack(np.array((ax1.get_ylim(), ax2.get_ylim())))\n\n    ax1.set_xlim(axis_x_values.min(), axis_x_values.max())\n    ax1.set_ylim(axis_y_values.min(), axis_y_values.max())\n    ax2.set_xlim(axis_x_values.min(), axis_x_values.max())\n    ax2.set_ylim(axis_y_values.min(), axis_y_values.max())\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.set_plotting_defaults","title":"<code>set_plotting_defaults()</code>","text":"<p>Set default plotting parameters for matplotlib with LaTeX-style fonts.</p> <p>This function updates matplotlib's plotting style to use serif fonts, sets font sizes for various elements, and ensures that SVG output uses non-embedded fonts for better compatibility.</p> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_plotting_defaults() -&gt; None:\n    \"\"\"\n    Set default plotting parameters for matplotlib with LaTeX-style fonts.\n\n    This function updates matplotlib's plotting style to use serif fonts,\n    sets font sizes for various elements, and ensures that SVG output uses\n    non-embedded fonts for better compatibility.\n    \"\"\"\n    tex_fonts = {\n        \"font.family\": \"serif\",\n        \"axes.labelsize\": 10,\n        \"font.size\": 10,\n        \"legend.fontsize\": 8,\n        \"xtick.labelsize\": 8,\n        \"ytick.labelsize\": 8,\n        \"svg.fonttype\": \"none\",\n    }\n\n    plt.style.use(\"default\")\n    plt.rcParams.update(tex_fonts)\n</code></pre>"},{"location":"reference/neuro_py/plotting/figure_helpers/#neuro_py.plotting.figure_helpers.set_size","title":"<code>set_size(width, fraction=1, subplots=(1, 1))</code>","text":"<p>Set figure dimensions to avoid scaling in LaTeX.</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>float or str</code> <p>Document width in points (float) or predefined document type (str). Supported types: 'thesis', 'beamer', 'paper'.</p> required <code>fraction</code> <code>float</code> <p>Fraction of the width which you wish the figure to occupy, by default 1.</p> <code>1</code> <code>subplots</code> <code>tuple of int</code> <p>Number of rows and columns of subplots, by default (1, 1).</p> <code>(1, 1)</code> <p>Returns:</p> Type Description <code>tuple of float</code> <p>Dimensions of the figure in inches (width, height).</p> Source code in <code>neuro_py/plotting/figure_helpers.py</code> <pre><code>def set_size(\n    width: Union[float, str], fraction: float = 1, subplots: Tuple[int, int] = (1, 1)\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Set figure dimensions to avoid scaling in LaTeX.\n\n    Parameters\n    ----------\n    width : float or str\n        Document width in points (float) or predefined document type (str).\n        Supported types: 'thesis', 'beamer', 'paper'.\n    fraction : float, optional\n        Fraction of the width which you wish the figure to occupy, by default 1.\n    subplots : tuple of int, optional\n        Number of rows and columns of subplots, by default (1, 1).\n\n    Returns\n    -------\n    tuple of float\n        Dimensions of the figure in inches (width, height).\n    \"\"\"\n    if width == \"thesis\":\n        width_pt = 426.79135\n    elif width == \"beamer\":\n        width_pt = 307.28987\n    elif width == \"paper\":\n        width_pt = 595.276\n    else:\n        width_pt = width\n\n    # Width of figure (in pts)\n    fig_width_pt = width_pt * fraction\n    # Convert from pt to inches\n    inches_per_pt = 1 / 72.27\n\n    # Golden ratio to set aesthetic figure height\n    # https://disq.us/p/2940ij3\n    golden_ratio = (5**0.5 - 1) / 2\n\n    # Figure width in inches\n    fig_width_in = fig_width_pt * inches_per_pt\n    # Figure height in inches\n    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n\n    return (fig_width_in, fig_height_in)\n</code></pre>"},{"location":"reference/neuro_py/process/","title":"neuro_py.process","text":""},{"location":"reference/neuro_py/process/#neuro_py.process.acf_power","title":"<code>acf_power(acf, norm=True)</code>","text":"<p>Compute the power spectrum of the signal by calculating the FFT of the autocorrelation function (ACF).</p> <p>Parameters:</p> Name Type Description Default <code>acf</code> <code>ndarray</code> <p>1D array of counts for the ACF.</p> required <code>norm</code> <code>bool</code> <p>If True, normalize the power spectrum. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>psd</code> <code>ndarray</code> <p>1D array representing the power spectrum of the signal.</p> Notes <p>The power spectrum is computed by taking the Fourier Transform of the ACF, then squaring the absolute values of the FFT result. The Nyquist frequency is accounted for by returning only the first half of the spectrum.</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def acf_power(acf: np.ndarray, norm: Optional[bool] = True) -&gt; np.ndarray:\n    \"\"\"\n    Compute the power spectrum of the signal by calculating the FFT of the autocorrelation function (ACF).\n\n    Parameters\n    ----------\n    acf : np.ndarray\n        1D array of counts for the ACF.\n    norm : bool, optional\n        If True, normalize the power spectrum. Default is True.\n\n    Returns\n    -------\n    psd : np.ndarray\n        1D array representing the power spectrum of the signal.\n\n    Notes\n    -----\n    The power spectrum is computed by taking the Fourier Transform of the ACF,\n    then squaring the absolute values of the FFT result.\n    The Nyquist frequency is accounted for by returning only the first half of the spectrum.\n    \"\"\"\n\n    # Take the FFT\n    fft = np.fft.fft(acf)\n\n    # Compute the power spectrum\n    pow = np.abs(fft) ** 2\n\n    # Account for Nyquist frequency\n    psd = pow[: pow.shape[0] // 2]\n\n    # Normalize if required\n    if norm:\n        psd = psd / np.trapezoid(psd)\n\n    return psd\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.average_diagonal","title":"<code>average_diagonal(mat)</code>","text":"<p>Average values over all offset diagonals of a 2D array.</p> <p>Parameters:</p> Name Type Description Default <code>mat</code> <code>ndarray</code> <p>2D array from which to compute the average values over diagonals.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>ndarray</code> <p>1D array containing the average values over all offset diagonals.</p> Notes <p>The method used for computing averages is based on the concept of accumulating values along each diagonal offset and then dividing by the number of elements in each diagonal.</p> Reference <p>https://stackoverflow.com/questions/71362928/average-values-over-all-offset-diagonals</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def average_diagonal(mat: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Average values over all offset diagonals of a 2D array.\n\n    Parameters\n    ----------\n    mat : np.ndarray\n        2D array from which to compute the average values over diagonals.\n\n    Returns\n    -------\n    output : np.ndarray\n        1D array containing the average values over all offset diagonals.\n\n    Notes\n    -----\n    The method used for computing averages is based on the concept of\n    accumulating values along each diagonal offset and then dividing by\n    the number of elements in each diagonal.\n\n    Reference\n    ---------\n    https://stackoverflow.com/questions/71362928/average-values-over-all-offset-diagonals\n    \"\"\"\n    n = mat.shape[0]\n    output = np.zeros(n * 2 - 1, dtype=np.float64)\n    for i in range(n - 1, -1, -1):\n        output[i : i + n] += mat[n - 1 - i]\n    output[0:n] /= np.arange(1, n + 1, 1, dtype=np.float64)\n    output[n:] /= np.arange(n - 1, 0, -1, dtype=np.float64)\n    return output\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.circular_shift","title":"<code>circular_shift(m, s)</code>","text":"<p>Circularly shift matrix rows or columns by specified amounts.</p> <p>Each matrix row (or column) is circularly shifted by a different amount.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>ndarray</code> <p>Matrix to rotate. Should be a 2D array.</p> required <code>s</code> <code>ndarray</code> <p>Shift amounts for each row (horizontal vector) or column (vertical vector). Should be a 1D array.</p> required <p>Returns:</p> Name Type Description <code>shifted</code> <code>ndarray</code> <p>Matrix <code>m</code> with rows (or columns) circularly shifted by the amounts in <code>s</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>s</code> is not a vector of integers or if <code>m</code> is not a 2D matrix. If the sizes of <code>m</code> and <code>s</code> are incompatible.</p> Notes <p>This function is adapted from CircularShift.m, Copyright (C) 2012 by Micha\u00ebl Zugaro.</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def circular_shift(m: np.ndarray, s: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Circularly shift matrix rows or columns by specified amounts.\n\n    Each matrix row (or column) is circularly shifted by a different amount.\n\n    Parameters\n    ----------\n    m : np.ndarray\n        Matrix to rotate. Should be a 2D array.\n    s : np.ndarray\n        Shift amounts for each row (horizontal vector) or column (vertical vector).\n        Should be a 1D array.\n\n    Returns\n    -------\n    shifted : np.ndarray\n        Matrix `m` with rows (or columns) circularly shifted by the amounts in `s`.\n\n    Raises\n    ------\n    ValueError\n        If `s` is not a vector of integers or if `m` is not a 2D matrix.\n        If the sizes of `m` and `s` are incompatible.\n\n    Notes\n    -----\n    This function is adapted from CircularShift.m, Copyright (C) 2012 by Micha\u00ebl Zugaro.\n    \"\"\"\n    # Check number of parameters\n    if len(s.shape) != 1:\n        raise ValueError(\"Second parameter is not a vector of integers.\")\n    if len(m.shape) != 2:\n        raise ValueError(\"First parameter is not a 2D matrix.\")\n\n    mm, nm = m.shape\n    # if s is 1d array, add dimension\n    if len(s.shape) == 1:\n        s = s[np.newaxis, :]\n    ms, ns = s.shape\n\n    # Check parameter sizes\n    if mm != ms and nm != ns:\n        raise ValueError(\"Incompatible parameter sizes.\")\n\n    # The algorithm below works along columns; transpose if necessary\n    s = -np.ravel(s)\n    if ns == 1:\n        m = m.T\n        mm, nm = m.shape\n\n    # Shift matrix S, where Sij is the vertical shift for element ij\n    shift = np.tile(s, (mm, 1))\n\n    # Before we start, each element Mij has a linear index Aij.\n    # After circularly shifting the rows, it will have a linear index Bij.\n    # We now construct Bij.\n\n    # First, create matrix C where each item Cij = i (row number)\n    lines = np.tile(np.arange(mm)[:, np.newaxis], (1, nm))\n    # Next, update C so that Cij becomes the target row number (after circular shift)\n    lines = np.mod(lines + shift, mm)\n    # lines[lines == 0] = mm\n    # Finally, transform Cij into a linear index, yielding Bij\n    indices = lines + np.tile(np.arange(nm) * mm, (mm, 1))\n\n    # Circular shift (reshape so that it is not transformed into a vector)\n    shifted = m.ravel()[(indices.flatten() - 1).astype(int)].reshape(mm, nm)\n\n    # flip matrix right to left\n    # shifted = np.fliplr(shifted)\n\n    shifted = np.flipud(shifted)\n\n    # Transpose back if necessary\n    if ns == 1:\n        shifted = shifted.T\n\n    return shifted\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.compute_AutoCorrs","title":"<code>compute_AutoCorrs(spks, binsize=0.001, nbins=100)</code>","text":"<p>Compute autocorrelations for spike trains.</p> <p>Parameters:</p> Name Type Description Default <code>spks</code> <code>ndarray</code> <p>Nested ndarrays where each array contains the spike times for one neuron.</p> required <code>binsize</code> <code>float</code> <p>The size of each bin in seconds, by default 0.001 (1 ms).</p> <code>0.001</code> <code>nbins</code> <code>int</code> <p>The number of bins for the autocorrelation, by default 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame where each column represents the autocorrelation of the corresponding neuron. The index is the time lag, and the values are the autocorrelations.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def compute_AutoCorrs(\n    spks: np.ndarray, binsize: float = 0.001, nbins: int = 100\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute autocorrelations for spike trains.\n\n    Parameters\n    ----------\n    spks : np.ndarray\n        Nested ndarrays where each array contains the spike times for one neuron.\n    binsize : float, optional\n        The size of each bin in seconds, by default 0.001 (1 ms).\n    nbins : int, optional\n        The number of bins for the autocorrelation, by default 100.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame where each column represents the autocorrelation of the corresponding neuron.\n        The index is the time lag, and the values are the autocorrelations.\n    \"\"\"\n    # First let's prepare a pandas dataframe to receive the data\n    times = np.arange(0, binsize * (nbins + 1), binsize) - (nbins * binsize) / 2\n    autocorrs = pd.DataFrame(index=times, columns=np.arange(len(spks)))\n\n    # Now we can iterate over the dictionnary of spikes\n    for i, s in enumerate(spks):\n        if len(s) == 0:\n            continue\n        # Explicitly convert to float64 array to ensure proper typing for numba jit\n        s_arr = np.asarray(s, dtype=np.float64)\n        # Calling the crossCorr function\n        autocorrs[i] = crossCorr(s_arr, s_arr, binsize, nbins)\n\n    # And don't forget to replace the 0 ms for 0\n    autocorrs.loc[0] = 0.0\n    return autocorrs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.compute_cross_correlogram","title":"<code>compute_cross_correlogram(X, dt=1.0, window=0.5)</code>","text":"<p>Compute pairwise cross-correlograms between signals in an array.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>N-dimensional array of shape (n_signals, n_timepoints) representing the signals.</p> required <code>dt</code> <code>float</code> <p>Time step between samples in seconds, default is 1.0.</p> <code>1.0</code> <code>window</code> <code>float</code> <p>Window size in seconds for the cross-correlogram. The output will include values within +/- window from the center. If None, returns the full correlogram.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Pairwise cross-correlogram with time lags as the index and signal pairs as columns.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def compute_cross_correlogram(\n    X: np.ndarray, dt: float = 1.0, window: float = 0.5\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute pairwise cross-correlograms between signals in an array.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        N-dimensional array of shape (n_signals, n_timepoints) representing the signals.\n    dt : float, optional\n        Time step between samples in seconds, default is 1.0.\n    window : float, optional\n        Window size in seconds for the cross-correlogram. The output will include values\n        within +/- window from the center. If None, returns the full correlogram.\n\n    Returns\n    -------\n    pd.DataFrame\n        Pairwise cross-correlogram with time lags as the index and signal pairs as columns.\n    \"\"\"\n\n    crosscorrs = {}\n    pairs = list(itertools.combinations(np.arange(X.shape[0]), 2))\n    for i, j in pairs:\n        auc = signal.correlate(X[i], X[j])\n        times = signal.correlation_lags(len(X[i]), len(X[j])) * dt\n        # normalize by coeff\n        normalizer = np.sqrt((X[i] ** 2).sum(axis=0) * (X[j] ** 2).sum(axis=0))\n        auc /= normalizer\n\n        crosscorrs[(i, j)] = pd.Series(index=times, data=auc, dtype=\"float32\")\n    crosscorrs = pd.DataFrame.from_dict(crosscorrs)\n\n    if window is None:\n        return crosscorrs\n    else:\n        return crosscorrs[(crosscorrs.index &gt;= -window) &amp; (crosscorrs.index &lt;= window)]\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.compute_image_spread","title":"<code>compute_image_spread(X, exponent=2, normalize=True)</code>","text":"<p>Compute the spread of an image using the square root of a weighted moment.</p> <p>The spread is calculated as the square root of a weighted moment of the image, where the weights are derived from the deviations of each pixel from the center of mass (COM) of the image.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A 2D numpy array of shape (numBinsY, numBinsX). If <code>normalize</code> is True, the input is assumed to represent a probability distribution.</p> required <code>exponent</code> <code>float</code> <p>The exponent used in the moment calculation. Default is 2.</p> <code>2</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the input array so that its sum is 1. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>spread</code> <code>float</code> <p>The computed spread, defined as the square root of the weighted moment.</p> <code>image_moment</code> <code>float</code> <p>The raw weighted moment of the image.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n&gt;&gt;&gt; spread, image_moment = compute_image_spread(X, exponent=2)\n&gt;&gt;&gt; print(spread)\n0.5704157028642128\n&gt;&gt;&gt; print(image_moment)\n0.325374074074074\n</code></pre> References <p>Widloski &amp; Foster, 2022</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def compute_image_spread(\n    X: np.ndarray, exponent: float = 2, normalize: bool = True\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Compute the spread of an image using the square root of a weighted moment.\n\n    The spread is calculated as the square root of a weighted moment of the image,\n    where the weights are derived from the deviations of each pixel from the\n    center of mass (COM) of the image.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A 2D numpy array of shape (numBinsY, numBinsX). If `normalize` is True,\n        the input is assumed to represent a probability distribution.\n    exponent : float, optional\n        The exponent used in the moment calculation. Default is 2.\n    normalize : bool, optional\n        If True, normalize the input array so that its sum is 1. Default is True.\n\n    Returns\n    -------\n    spread : float\n        The computed spread, defined as the square root of the weighted moment.\n    image_moment : float\n        The raw weighted moment of the image.\n\n    Examples\n    --------\n    &gt;&gt;&gt; X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n    &gt;&gt;&gt; spread, image_moment = compute_image_spread(X, exponent=2)\n    &gt;&gt;&gt; print(spread)\n    0.5704157028642128\n    &gt;&gt;&gt; print(image_moment)\n    0.325374074074074\n\n    References\n    ----------\n    Widloski &amp; Foster, 2022\n    \"\"\"\n    if np.allclose(X, 0):\n        return np.nan, np.nan  # Return NaN if the input is all zero\n\n    if normalize:\n        X = X / np.nansum(X)  # Normalize the input\n\n    numBinsY, numBinsX = X.shape\n\n    # Compute center of mass (COM) for the X (columns) direction.\n    cols = np.arange(1, numBinsX + 1)\n    sumX = np.nansum(X, axis=0)  # sum over rows, shape: (numBinsX,)\n    totalX = np.nansum(sumX)\n    # Add a small correction term\n    comX = np.nansum(sumX * cols) / totalX + 0.5 / numBinsX\n\n    # Compute center of mass for the Y (rows) direction.\n    rows = np.arange(1, numBinsY + 1)\n    sumY = np.nansum(X, axis=1)  # sum over columns, shape: (numBinsY,)\n    totalY = np.nansum(sumY)\n    comY = np.nansum(sumY * rows) / totalY + 0.5 / numBinsY\n\n    # Create a meshgrid for the bin indices (using 1-indexing like MATLAB)\n    XX, YY = np.meshgrid(np.arange(1, numBinsX + 1), np.arange(1, numBinsY + 1))\n\n    # Compute the weighted moment using the product of the deviations raised to the given exponent.\n    # For each bin, we compute:\n    #     |XX - comX|^exponent * |YY - comY|^exponent * X(i,j)\n    moment = np.nansum(\n        (np.abs(XX - comX) ** exponent) * (np.abs(YY - comY) ** exponent) * X\n    )\n\n    # Normalize by the total probability.\n    image_moment = moment / np.nansum(X)\n\n    # The spread is the square root of the image moment.\n    spread = np.sqrt(image_moment)\n\n    return spread, image_moment\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.compute_psth","title":"<code>compute_psth(data, event, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Compute the Peri-Stimulus Time Histogram (PSTH) for discrete-time events.</p> <p>This function calculates the PSTH for a given set of discrete-time events (e.g. spike times) aligned to specific reference events. The PSTH provides time-resolved rates (Hz) in response to the events over a defined time window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>An array of discrete-time events (e.g. spike times) for multiple trials, with each trial in a separate row.</p> required <code>event</code> <code>ndarray</code> <p>An array of reference event times to which the data are aligned.</p> required <code>bin_width</code> <code>float</code> <p>Width of each time bin in seconds (default is 0.002 seconds).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>Number of bins to create for the histogram (default is 100).</p> <code>100</code> <code>window</code> <code>list</code> <p>Time window around each event to consider for the PSTH. If None, a symmetric window is created based on <code>n_bins</code> and <code>bin_width</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the PSTH, indexed by time bins and columns representing each trial's PSTH.</p> Notes <p>If the specified window is not symmetric around 0, it is adjusted to be symmetric. Each trial's times must be sorted in ascending order. This function relies on <code>crossCorr</code>, which uses binary search and assumes sorted input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spikes = np.array([[0.1, 0.15, 0.2], [0.1, 0.12, 0.13]])\n&gt;&gt;&gt; event = np.array([0.1, 0.3])\n&gt;&gt;&gt; psth = compute_psth(spikes, event)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def compute_psth(\n    data: np.ndarray,\n    event: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: list = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute the Peri-Stimulus Time Histogram (PSTH) for discrete-time events.\n\n    This function calculates the PSTH for a given set of discrete-time events\n    (e.g. spike times) aligned to specific reference events. The PSTH provides\n    time-resolved **rates (Hz)** in response to the events over a defined time window.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        An array of discrete-time events (e.g. spike times) for multiple trials,\n        with each trial in a separate row.\n    event : np.ndarray\n        An array of reference event times to which the data are aligned.\n    bin_width : float, optional\n        Width of each time bin in seconds (default is 0.002 seconds).\n    n_bins : int, optional\n        Number of bins to create for the histogram (default is 100).\n    window : list, optional\n        Time window around each event to consider for the PSTH. If None, a\n        symmetric window is created based on `n_bins` and `bin_width`.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the PSTH, indexed by time bins and columns\n        representing each trial's PSTH.\n\n    Notes\n    -----\n    If the specified window is not symmetric around 0, it is adjusted to be symmetric.\n    Each trial's times must be sorted in ascending order. This function\n    relies on `crossCorr`, which uses binary search and assumes sorted input.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spikes = np.array([[0.1, 0.15, 0.2], [0.1, 0.12, 0.13]])\n    &gt;&gt;&gt; event = np.array([0.1, 0.3])\n    &gt;&gt;&gt; psth = compute_psth(spikes, event)\n    \"\"\"\n    if window is not None:\n        window_original = None\n        # check if window is symmetric around 0, if not make it so\n        mid = (window[1] - window[0]) / 2.0\n        is_symmetric = np.isclose(mid, window[1]) and np.isclose(-mid, window[0])\n        if not is_symmetric:\n            window_original = np.array(window)\n            window = [-np.max(np.abs(window)), np.max(np.abs(window))]\n\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        n_bins = len(times) - 1\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    ccg = pd.DataFrame(index=times, columns=np.arange(len(data)))\n    # Now we can iterate over trials\n    for i, s in enumerate(data):\n        # Ensure spike times are float64 for numba compatibility\n        s = np.asarray(s, dtype=np.float64)\n        ccg[i] = crossCorr(event, s, bin_width, n_bins)\n\n    # if window was not symmetric, remove the extra bins\n    if window is not None:\n        if window_original is not None:\n            ccg = ccg.loc[window_original[0] : window_original[1], :]\n    return ccg\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.corrcc","title":"<code>corrcc(alpha1, alpha2, axis=None)</code>","text":"<p>Circular correlation coefficient for two circular random variables.</p> <p>Parameters:</p> Name Type Description Default <code>alpha1</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>alpha2</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>axis</code> <code>Optional[int]</code> <p>The axis along which to compute the correlation coefficient. If None, compute over the entire array (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-circular correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n&gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n&gt;&gt;&gt; rho, pval = corrcc(alpha1, alpha2)\n&gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n</code></pre> Notes <p>The function computes the correlation between two sets of angles using a method that adjusts for circular data. The significance of the correlation coefficient is tested using the fact that the test statistic is approximately normally distributed.</p> References <p>Jammalamadaka et al (2001)</p> <p>Original code: https://github.com/circstat/pycircstat Modified by: Salman Qasim, 11/12/2018</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def corrcc(\n    alpha1: np.ndarray, alpha2: np.ndarray, axis: Optional[int] = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Circular correlation coefficient for two circular random variables.\n\n    Parameters\n    ----------\n    alpha1 : np.ndarray\n        Sample of angles in radians.\n    alpha2 : np.ndarray\n        Sample of angles in radians.\n    axis : Optional[int], optional\n        The axis along which to compute the correlation coefficient.\n        If None, compute over the entire array (default is None).\n\n    Returns\n    -------\n    rho : float\n        Circular-circular correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n\n    Examples\n    --------\n    &gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n    &gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n    &gt;&gt;&gt; rho, pval = corrcc(alpha1, alpha2)\n    &gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n\n    Notes\n    -----\n    The function computes the correlation between two sets of angles using a\n    method that adjusts for circular data. The significance of the correlation\n    coefficient is tested using the fact that the test statistic is approximately\n    normally distributed.\n\n    References\n    ----------\n    Jammalamadaka et al (2001)\n\n    Original code: https://github.com/circstat/pycircstat\n    Modified by: Salman Qasim, 11/12/2018\n    \"\"\"\n    assert alpha1.shape == alpha2.shape, \"Input dimensions do not match.\"\n\n    n = len(alpha1)\n\n    # center data on circular mean\n    alpha1_centered, alpha2_centered = pcs.center(alpha1, alpha2, axis=axis)\n\n    num = np.sum(np.sin(alpha1_centered) * np.sin(alpha2_centered), axis=axis)\n    den = np.sqrt(\n        np.sum(np.sin(alpha1_centered) ** 2, axis=axis)\n        * np.sum(np.sin(alpha2_centered) ** 2, axis=axis)\n    )\n    # compute correlation coefficient from p. 176\n    rho = num / den\n\n    # Modification:\n    # significance of this correlation coefficient can be tested using the fact that Z is approx. normal\n\n    l20 = np.mean(np.sin(alpha1_centered) ** 2)\n    l02 = np.mean(np.sin(alpha2_centered) ** 2)\n    l22 = np.mean((np.sin(alpha1_centered) ** 2) * (np.sin(alpha2_centered) ** 2))\n    z = np.sqrt((n * l20 * l02) / l22) * rho\n    pval = 2 * (1 - sp.stats.norm.cdf(np.abs(z)))  # two-sided test\n\n    return rho, pval\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.corrcc_uniform","title":"<code>corrcc_uniform(alpha1, alpha2, axis=None)</code>","text":"<p>Circular correlation coefficient for two circular random variables. Use this function if at least one of the variables may follow a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha1</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>alpha2</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>axis</code> <code>Optional[int]</code> <p>The axis along which to compute the correlation coefficient. If None, compute over the entire array (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-circular correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> Notes <p>This method accounts for cases where one or both of the circular variables may follow a uniform distribution. The significance of the correlation coefficient is tested using a normal approximation of the Z statistic.</p> References <p>Jammalamadaka, et al (2001).</p> <p>Original code: https://github.com/circstat/pycircstat Modified by: Salman Qasim, 11/12/2018 https://github.com/HoniSanders/measure_phaseprec/blob/master/cl_corr.m</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n&gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n&gt;&gt;&gt; rho, pval = corrcc_uniform(alpha1, alpha2)\n&gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n</code></pre> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def corrcc_uniform(\n    alpha1: np.ndarray, alpha2: np.ndarray, axis: Optional[int] = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Circular correlation coefficient for two circular random variables.\n    Use this function if at least one of the variables may follow a uniform distribution.\n\n    Parameters\n    ----------\n    alpha1 : np.ndarray\n        Sample of angles in radians.\n    alpha2 : np.ndarray\n        Sample of angles in radians.\n    axis : Optional[int], optional\n        The axis along which to compute the correlation coefficient.\n        If None, compute over the entire array (default is None).\n\n    Returns\n    -------\n    rho : float\n        Circular-circular correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n\n    Notes\n    -----\n    This method accounts for cases where one or both of the circular variables\n    may follow a uniform distribution. The significance of the correlation coefficient\n    is tested using a normal approximation of the Z statistic.\n\n    References\n    ----------\n    Jammalamadaka, et al (2001).\n\n    Original code: https://github.com/circstat/pycircstat\n    Modified by: Salman Qasim, 11/12/2018\n    https://github.com/HoniSanders/measure_phaseprec/blob/master/cl_corr.m\n\n    Examples\n    --------\n    &gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n    &gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n    &gt;&gt;&gt; rho, pval = corrcc_uniform(alpha1, alpha2)\n    &gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n    \"\"\"\n\n    assert alpha1.shape == alpha2.shape, \"Input dimensions do not match.\"\n\n    n = len(alpha1)\n\n    # center data on circular mean\n    alpha1_centered, alpha2_centered = pcs.center(alpha1, alpha2, axis=axis)\n\n    # One of the sample means is not well defined due to uniform distribution of data\n    # so take the difference of the resultant vector length for the sum and difference\n    # of the alphas\n    num = pcs.resultant_vector_length(alpha1 - alpha2) - pcs.resultant_vector_length(\n        alpha1 + alpha2\n    )\n    den = 2 * np.sqrt(\n        np.sum(np.sin(alpha1_centered) ** 2, axis=axis)\n        * np.sum(np.sin(alpha2_centered) ** 2, axis=axis)\n    )\n    rho = n * num / den\n    # significance of this correlation coefficient can be tested using the fact that Z\n    # is approx. normal\n\n    l20 = np.mean(np.sin(alpha1_centered) ** 2)\n    l02 = np.mean(np.sin(alpha2_centered) ** 2)\n    l22 = np.mean((np.sin(alpha1_centered) ** 2) * (np.sin(alpha2_centered) ** 2))\n    z = np.sqrt((n * l20 * l02) / l22) * rho\n    pval = 2 * (1 - sp.stats.norm.cdf(np.abs(z)))  # two-sided test\n\n    return rho, pval\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.count_events","title":"<code>count_events(events, time_ref, time_range)</code>","text":"<p>Count the number of events that occur within a given time range after each reference event.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>ndarray</code> <p>A 1D array of event times.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>time_range</code> <code>tuple of (float, float)</code> <p>A tuple containing the start and end times of the time range.</p> required <p>Returns:</p> Name Type Description <code>counts</code> <code>ndarray</code> <p>A 1D array of event counts, one for each reference time (same length as time_ref).</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def count_events(\n    events: np.ndarray, time_ref: np.ndarray, time_range: Tuple[float, float]\n) -&gt; np.ndarray:\n    \"\"\"\n    Count the number of events that occur within a given time range after each reference event.\n\n    Parameters\n    ----------\n    events : np.ndarray\n        A 1D array of event times.\n    time_ref : np.ndarray\n        A 1D array of reference times.\n    time_range : tuple of (float, float)\n        A tuple containing the start and end times of the time range.\n\n    Returns\n    -------\n    counts : np.ndarray\n        A 1D array of event counts, one for each reference time (same length as time_ref).\n    \"\"\"\n    # Initialize an array to store the event counts\n    counts = np.zeros_like(time_ref)\n\n    # Iterate over the reference times\n    for i, r in enumerate(time_ref):\n        # Check if any events occur within the time range\n        idx = (events &gt; r + time_range[0]) &amp; (events &lt; r + time_range[1])\n        # Increment the event count if any events are found\n        counts[i] = len(events[idx])\n\n    return counts\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.count_in_interval","title":"<code>count_in_interval(data, event_starts, event_stops, par_type='counts')</code>","text":"<p>Count discrete-time events in specified intervals and return a matrix where each column represents counts for each discrete-time event series over given epochs.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A jagged array where each element contains discrete-time events times for a series (e.g. spike times for a neuron). (n series x variable length event times).</p> required <code>event_starts</code> <code>ndarray</code> <p>A 1D array containing the start times of events.</p> required <code>event_stops</code> <code>ndarray</code> <p>A 1D array containing the stop times of events.</p> required <code>par_type</code> <code>str</code> <p>The type of count calculation to perform: - 'counts': returns raw counts of spikes in the intervals. - 'binary': returns a binary matrix indicating presence (1) or absence (0) of spikes. - 'rate': returns the firing rate calculated as counts divided by the interval duration. Defaults to 'binary'.</p> <code>'counts'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array (n series x n epochs) where each column shows the counts (or binary values or rates) per series for each epoch.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create spike trains for 3 units with different spike times\n&gt;&gt;&gt; unit_1_spikes = np.array([0.1, 0.3, 0.5, 1.2, 1.8])\n&gt;&gt;&gt; unit_2_spikes = np.array([0.2, 0.8, 1.5])\n&gt;&gt;&gt; unit_3_spikes = np.array([0.05, 0.4, 0.9, 1.1])\n&gt;&gt;&gt; st = np.array([unit_1_spikes, unit_2_spikes, unit_3_spikes], dtype=object)\n&gt;&gt;&gt; # Define two events with their start and stop times\n&gt;&gt;&gt; event_starts = np.array([0.0, 1.0])\n&gt;&gt;&gt; event_stops = np.array([0.7, 2.0])\n&gt;&gt;&gt; # Count spikes in each interval\n&gt;&gt;&gt; counts = count_in_interval(st, event_starts, event_stops, par_type='counts')\n&gt;&gt;&gt; print(counts)\n[[3. 2.]\n [1. 1.]\n [2. 1.]]\n&gt;&gt;&gt; # Get binary presence/absence\n&gt;&gt;&gt; binary = count_in_interval(st, event_starts, event_stops, par_type='binary')\n&gt;&gt;&gt; print(binary)\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\n&gt;&gt;&gt; # Calculate firing rates\n&gt;&gt;&gt; rates = count_in_interval(st, event_starts, event_stops, par_type='firing_rate')\n&gt;&gt;&gt; print(rates)\n[[4.28571429 2.   ]\n [1.42857143 1.   ]\n [2.85714286 1.   ]]\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def count_in_interval(\n    data: np.ndarray,\n    event_starts: np.ndarray,\n    event_stops: np.ndarray,\n    par_type: str = \"counts\",\n) -&gt; np.ndarray:\n    \"\"\"\n    Count discrete-time events in specified intervals and return a matrix where each\n    column represents counts for each discrete-time event series over given epochs.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A jagged array where each element contains discrete-time events times for\n        a series (e.g. spike times for a neuron). (n series x variable length event times).\n\n    event_starts : np.ndarray\n        A 1D array containing the start times of events.\n\n    event_stops : np.ndarray\n        A 1D array containing the stop times of events.\n\n    par_type : str, optional\n        The type of count calculation to perform:\n        - 'counts': returns raw counts of spikes in the intervals.\n        - 'binary': returns a binary matrix indicating presence (1) or absence (0) of spikes.\n        - 'rate': returns the firing rate calculated as counts divided by the interval duration.\n        Defaults to 'binary'.\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array (n series x n epochs) where each column shows the counts\n        (or binary values or rates) per series for each epoch.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; # Create spike trains for 3 units with different spike times\n    &gt;&gt;&gt; unit_1_spikes = np.array([0.1, 0.3, 0.5, 1.2, 1.8])\n    &gt;&gt;&gt; unit_2_spikes = np.array([0.2, 0.8, 1.5])\n    &gt;&gt;&gt; unit_3_spikes = np.array([0.05, 0.4, 0.9, 1.1])\n    &gt;&gt;&gt; st = np.array([unit_1_spikes, unit_2_spikes, unit_3_spikes], dtype=object)\n    &gt;&gt;&gt; # Define two events with their start and stop times\n    &gt;&gt;&gt; event_starts = np.array([0.0, 1.0])\n    &gt;&gt;&gt; event_stops = np.array([0.7, 2.0])\n    &gt;&gt;&gt; # Count spikes in each interval\n    &gt;&gt;&gt; counts = count_in_interval(st, event_starts, event_stops, par_type='counts')\n    &gt;&gt;&gt; print(counts)\n    [[3. 2.]\n     [1. 1.]\n     [2. 1.]]\n    &gt;&gt;&gt; # Get binary presence/absence\n    &gt;&gt;&gt; binary = count_in_interval(st, event_starts, event_stops, par_type='binary')\n    &gt;&gt;&gt; print(binary)\n    [[1. 1.]\n     [1. 1.]\n     [1. 1.]]\n    &gt;&gt;&gt; # Calculate firing rates\n    &gt;&gt;&gt; rates = count_in_interval(st, event_starts, event_stops, par_type='firing_rate')\n    &gt;&gt;&gt; print(rates)\n    [[4.28571429 2.   ]\n     [1.42857143 1.   ]\n     [2.85714286 1.   ]]\n    \"\"\"\n    # convert to numpy array\n    event_starts, event_stops = np.array(event_starts), np.array(event_stops)\n\n    # initialize matrix\n    unit_mat = np.zeros((len(data), (len(event_starts))))\n\n    # loop over units and bin spikes into epochs\n    for i, s in enumerate(data):\n        idx1 = np.searchsorted(s, event_starts, \"right\")\n        idx2 = np.searchsorted(s, event_stops, \"left\")\n        unit_mat[i, :] = idx2 - idx1\n\n    par_type_funcs = {\n        \"counts\": lambda x: x,\n        \"binary\": lambda x: (x &gt; 0) * 1,\n        \"firing_rate\": lambda x: x / (event_stops - event_starts),\n    }\n    calc_func = par_type_funcs[par_type]\n    unit_mat = calc_func(unit_mat)\n\n    return unit_mat\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.crossCorr","title":"<code>crossCorr(t1, t2, binsize, nbins)</code>","text":"<p>Compute a cross-correlogram using independent event-wise histograms.</p> <p>This is the standard definition of a cross-correlogram: each reference event (t1) independently computes a histogram of all target timestamps (t2) relative to it. Each t2 sample can contribute to every t1 event (no \"consumption\").</p> <p>Efficient O(nt1 * (log(nt2) + nt2)) implementation using binary search for initial positioning, then single-pass binning per event.</p> <p>Parameters:</p> Name Type Description Default <code>t1</code> <code>ndarray</code> <p>Reference events (can be unsorted, any order).</p> required <code>t2</code> <code>ndarray</code> <p>Target timestamps (must be sorted in ascending order).</p> required <code>binsize</code> <code>float</code> <p>Bin width in seconds.</p> required <code>nbins</code> <code>int</code> <p>Number of bins (will be adjusted to be odd).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized cross-correlogram (rate in Hz). Shape (nbins,) where nbins is adjusted to be odd.</p> Notes <p>True cross-correlogram: each t2 sample contributes to every t1 event. Order of t1 does not affect the result. Suitable for spike-to-event analysis (e.g., spikes relative to ripples).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t1 = np.array([1.0, 2.0])\n&gt;&gt;&gt; t2 = np.sort(np.array([1.1, 1.3, 2.1, 2.3]))\n&gt;&gt;&gt; result = crossCorr(t1, t2, binsize=0.2, nbins=4)\n&gt;&gt;&gt; result.shape\n(5,)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef crossCorr(\n    t1: np.ndarray,\n    t2: np.ndarray,\n    binsize: float,\n    nbins: int,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute a cross-correlogram using independent event-wise histograms.\n\n    This is the standard definition of a cross-correlogram: each reference event (t1)\n    independently computes a histogram of all target timestamps (t2) relative to it.\n    Each t2 sample can contribute to every t1 event (no \"consumption\").\n\n    Efficient O(nt1 * (log(nt2) + nt2)) implementation using binary search for\n    initial positioning, then single-pass binning per event.\n\n    Parameters\n    ----------\n    t1 : np.ndarray\n        Reference events (can be unsorted, any order).\n    t2 : np.ndarray\n        Target timestamps (must be sorted in ascending order).\n    binsize : float\n        Bin width in seconds.\n    nbins : int\n        Number of bins (will be adjusted to be odd).\n\n    Returns\n    -------\n    np.ndarray\n        Normalized cross-correlogram (rate in Hz).\n        Shape (nbins,) where nbins is adjusted to be odd.\n\n    Notes\n    -----\n    True cross-correlogram: each t2 sample contributes to every t1 event.\n    Order of t1 does not affect the result.\n    Suitable for spike-to-event analysis (e.g., spikes relative to ripples).\n\n    Examples\n    --------\n    &gt;&gt;&gt; t1 = np.array([1.0, 2.0])\n    &gt;&gt;&gt; t2 = np.sort(np.array([1.1, 1.3, 2.1, 2.3]))\n    &gt;&gt;&gt; result = crossCorr(t1, t2, binsize=0.2, nbins=4)\n    &gt;&gt;&gt; result.shape\n    (5,)\n    \"\"\"\n    # Ensure nbins is odd\n    nbins = int(nbins)\n    if np.floor(nbins / 2) * 2 == nbins:\n        nbins = nbins + 1\n\n    nt1 = len(t1)\n    nt2 = len(t2)\n\n    w = (nbins / 2) * binsize\n    C = np.zeros(nbins)\n\n    # For each reference event, independently compute histogram\n    for i1 in range(nt1):\n        lbound = t1[i1] - w\n        ubound = lbound + nbins * binsize\n\n        # Binary search to find first t2 sample in window\n        left = 0\n        right = nt2\n        while left &lt; right:\n            mid = (left + right) // 2\n            if t2[mid] &lt; lbound:\n                left = mid + 1\n            else:\n                right = mid\n\n        # Single pass through t2 samples in this event's window\n        # Bin each sample directly using its offset from lbound\n        k = left\n        while k &lt; nt2 and t2[k] &lt; ubound:\n            bin_j = int((t2[k] - lbound) / binsize)\n            if 0 &lt;= bin_j &lt; nbins:\n                C[bin_j] += 1\n            k += 1\n\n    # Normalize by number of events and bin width\n    C = C / (nt1 * binsize)\n\n    return C\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.decode_file_path","title":"<code>decode_file_path(save_file)</code>","text":"<p>Decode an encoded file path to retrieve the original session path.</p> <p>Parameters:</p> Name Type Description Default <code>save_file</code> <code>str</code> <p>Encoded file path that includes the original session path.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Original session path before encoding.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; save_file = r\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n&gt;&gt;&gt; decode_file_path(save_file)\n\"Z:\\Data\\AYAold\\AB3\\AB3_38_41\"\n</code></pre> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def decode_file_path(save_file: str) -&gt; str:\n    \"\"\"\n    Decode an encoded file path to retrieve the original session path.\n\n    Parameters\n    ----------\n    save_file : str\n        Encoded file path that includes the original session path.\n\n    Returns\n    -------\n    str\n        Original session path before encoding.\n\n    Examples\n    -------\n    &gt;&gt;&gt; save_file = r\"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\\\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n    &gt;&gt;&gt; decode_file_path(save_file)\n    \"Z:\\\\Data\\\\AYAold\\\\AB3\\\\AB3_38_41\"\n    \"\"\"\n\n    # get basepath from save_file\n    basepath = os.path.basename(save_file).replace(\"___\", \"/\").replace(\"---\", \":\")\n    # also remove file extension\n    basepath = os.path.splitext(basepath)[0]\n\n    # Convert to OS-appropriate path separators\n    basepath = basepath.replace(\"/\", os.sep)\n\n    return basepath\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.deconvolve_peth","title":"<code>deconvolve_peth(signal, events, bin_width=0.002, n_bins=100)</code>","text":"<p>Perform deconvolution of a peri-event time histogram (PETH) signal.</p> <p>This function calculates the deconvolved signal based on the input signal and events.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>An array representing the discrete events.</p> required <code>events</code> <code>ndarray</code> <p>An array representing the discrete events.</p> required <code>bin_width</code> <code>float</code> <p>The width of a time bin in seconds (default is 0.002 seconds).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins to use in the PETH (default is 100 bins).</p> <code>100</code> <p>Returns:</p> Name Type Description <code>deconvolved</code> <code>ndarray</code> <p>An array representing the deconvolved signal.</p> <code>times</code> <code>ndarray</code> <p>An array representing the time points corresponding to the bins.</p> Notes <p>Based on DeconvolvePETH.m from https://github.com/ayalab1/neurocode/blob/master/spikes/DeconvolvePETH.m</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def deconvolve_peth(\n    signal: np.ndarray, events: np.ndarray, bin_width: float = 0.002, n_bins: int = 100\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Perform deconvolution of a peri-event time histogram (PETH) signal.\n\n    This function calculates the deconvolved signal based on the input signal and events.\n\n    Parameters\n    ----------\n    signal : np.ndarray\n        An array representing the discrete events.\n    events : np.ndarray\n        An array representing the discrete events.\n    bin_width : float, optional\n        The width of a time bin in seconds (default is 0.002 seconds).\n    n_bins : int, optional\n        The number of bins to use in the PETH (default is 100 bins).\n\n    Returns\n    -------\n    deconvolved : np.ndarray\n        An array representing the deconvolved signal.\n    times : np.ndarray\n        An array representing the time points corresponding to the bins.\n\n    Notes\n    -----\n    Based on DeconvolvePETH.m from https://github.com/ayalab1/neurocode/blob/master/spikes/DeconvolvePETH.m\n    \"\"\"\n\n    # calculate time lags for peth\n    times = np.linspace(-(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1)\n\n    # Calculate the autocorrelogram of the signal and the PETH of the events and the signal\n    autocorrelogram = crossCorr(signal, signal, bin_width, n_bins * 2)\n    raw_peth = crossCorr(events, signal, bin_width, n_bins * 2)\n\n    # If raw_peth all zeros, return zeros\n    if not raw_peth.any():\n        return np.zeros(len(times)), times\n\n    # Subtract the mean value from the raw_peth\n    const = np.mean(raw_peth)\n    raw_peth = raw_peth - const\n\n    # Calculate the Toeplitz matrix using the autocorrelogram and\n    #   the cross-correlation of the autocorrelogram\n    T0 = toeplitz(\n        autocorrelogram,\n        np.hstack([autocorrelogram[0], np.zeros(len(autocorrelogram) - 1)]),\n    )\n    T = T0[n_bins:, : n_bins + 1]\n\n    # Calculate the deconvolved signal by solving a linear equation\n    deconvolved = np.linalg.solve(\n        T, raw_peth[int(n_bins / 2) : int(n_bins / 2 * 3 + 1)].T + const / len(events)\n    )\n\n    return deconvolved, times\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.dpsschk","title":"<code>dpsschk(tapers, N, Fs)</code>","text":"<p>Check and generate DPSS tapers.</p> <p>Parameters:</p> Name Type Description Default <code>tapers</code> <code>Union[ndarray, Tuple[float, int]]</code> <p>Input can be either an array representing [NW, K] or a tuple with the number of tapers and the maximum number of tapers.</p> required <code>N</code> <code>int</code> <p>Number of points for FFT.</p> required <code>Fs</code> <code>float</code> <p>Sampling frequency.</p> required <p>Returns:</p> Name Type Description <code>tapers</code> <code>ndarray</code> <p>Tapers matrix, shape [tapers, eigenvalues].</p> Notes <p>The function computes DPSS (Discrete Prolate Spheroidal Sequences) tapers and scales them by the square root of the sampling frequency.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def dpsschk(\n    tapers: Union[np.ndarray, Tuple[float, int]], N: int, Fs: float\n) -&gt; np.ndarray:\n    \"\"\"\n    Check and generate DPSS tapers.\n\n    Parameters\n    ----------\n    tapers : Union[np.ndarray, Tuple[float, int]]\n        Input can be either an array representing [NW, K] or a tuple with\n        the number of tapers and the maximum number of tapers.\n    N : int\n        Number of points for FFT.\n    Fs : float\n        Sampling frequency.\n\n    Returns\n    -------\n    tapers : np.ndarray\n        Tapers matrix, shape [tapers, eigenvalues].\n\n    Notes\n    -----\n    The function computes DPSS (Discrete Prolate Spheroidal Sequences) tapers\n    and scales them by the square root of the sampling frequency.\n    \"\"\"\n    tapers, eigs = dpss(N, NW=tapers[0], Kmax=tapers[1], sym=False, return_ratios=True)\n    tapers = tapers * np.sqrt(Fs)\n    tapers = tapers.T\n    return tapers\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.encode_file_path","title":"<code>encode_file_path(basepath, save_path, format_type='pickle')</code>","text":"<p>Encode file path to be used as a filename.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session to be encoded.</p> required <code>save_path</code> <code>str</code> <p>Directory where the encoded file will be saved.</p> required <code>format_type</code> <code>str</code> <p>File format type (\"pickle\" or \"hdf5\"). Defaults to \"pickle\".</p> <code>'pickle'</code> <p>Returns:</p> Type Description <code>str</code> <p>Encoded file path suitable for use as a filename.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\AYAold\\AB3\\AB3_38_41\"\n&gt;&gt;&gt; save_path = r\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\"\n&gt;&gt;&gt; encode_file_path(basepath, save_path)\n\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n</code></pre> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def encode_file_path(basepath: str, save_path: str, format_type: str = \"pickle\") -&gt; str:\n    \"\"\"\n    Encode file path to be used as a filename.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session to be encoded.\n    save_path : str\n        Directory where the encoded file will be saved.\n    format_type : str, optional\n        File format type (\"pickle\" or \"hdf5\"). Defaults to \"pickle\".\n\n    Returns\n    -------\n    str\n        Encoded file path suitable for use as a filename.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\AYAold\\\\AB3\\\\AB3_38_41\"\n    &gt;&gt;&gt; save_path = r\"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\"\n    &gt;&gt;&gt; encode_file_path(basepath, save_path)\n    \"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\\\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n    \"\"\"\n    # Normalize path separators to forward slashes for consistent encoding\n    basepath = basepath.replace(\"\\\\\", \"/\")\n    save_path = os.path.normpath(save_path)\n\n    # Encode with consistent separators\n    encoded_name = basepath.replace(\"/\", \"___\").replace(\":\", \"---\")\n\n    # Add extension\n    extension = \".h5\" if format_type == \"hdf5\" else \".pkl\"\n    encoded_name += extension\n\n    # Join using os.path.join for proper OS-specific path joining\n    return os.path.join(save_path, encoded_name)\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.event_spiking_threshold","title":"<code>event_spiking_threshold(spikes, events, window=[-0.5, 0.5], event_size=0.1, spiking_thres=0, binsize=0.01, sigma=0.02, min_units=6, show_fig=False)</code>","text":"<p>event_spiking_threshold: filter events based on spiking threshold</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>SpikeTrainArray</code> <p>Spike train array of neurons.</p> required <code>events</code> <code>ndarray</code> <p>Event times in seconds.</p> required <code>window</code> <code>list of float</code> <p>Time window (in seconds) to compute event-triggered average, by default [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>event_size</code> <code>float</code> <p>Time window (in seconds) around event to measure firing response, by default 0.1.</p> <code>0.1</code> <code>spiking_thres</code> <code>float</code> <p>Spiking threshold in z-score units, by default 0.</p> <code>0</code> <code>binsize</code> <code>float</code> <p>Bin size (in seconds) for time-binning the spike trains, by default 0.01.</p> <code>0.01</code> <code>sigma</code> <code>float</code> <p>Standard deviation (in seconds) for Gaussian smoothing of spike counts, by default 0.02.</p> <code>0.02</code> <code>min_units</code> <code>int</code> <p>Minimum number of units required to compute event-triggered average, by default 6.</p> <code>6</code> <code>show_fig</code> <code>bool</code> <p>If True, plots the figure of event-triggered spiking activity, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean array indicating valid events that meet the spiking threshold.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP04\\day_32_20240430\"\n&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=False)\n&gt;&gt;&gt; st, cell_metrics = loading.load_spikes(\n        basepath,\n        brainRegion=\"CA1\",\n        support=nel.EpochArray([0, loading.load_epoch(basepath).iloc[-1].stopTime])\n    )\n&gt;&gt;&gt; idx = event_spiking_threshold(st, ripples.peaks.values, show_fig=True)\n&gt;&gt;&gt; print(f\"Number of valid ripples: {idx.sum()} out of {len(ripples)}\")\nNumber of valid ripples: 9244 out of 12655\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_spiking_threshold(\n    spikes: SpikeTrainArray,\n    events: np.ndarray,\n    window: list = [-0.5, 0.5],\n    event_size: float = 0.1,\n    spiking_thres: float = 0,\n    binsize: float = 0.01,\n    sigma: float = 0.02,\n    min_units: int = 6,\n    show_fig: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    event_spiking_threshold: filter events based on spiking threshold\n\n    Parameters\n    ----------\n    spikes : nel.SpikeTrainArray\n        Spike train array of neurons.\n    events : np.ndarray\n        Event times in seconds.\n    window : list of float, optional\n        Time window (in seconds) to compute event-triggered average, by default [-0.5, 0.5].\n    event_size : float, optional\n        Time window (in seconds) around event to measure firing response, by default 0.1.\n    spiking_thres : float, optional\n        Spiking threshold in z-score units, by default 0.\n    binsize : float, optional\n        Bin size (in seconds) for time-binning the spike trains, by default 0.01.\n    sigma : float, optional\n        Standard deviation (in seconds) for Gaussian smoothing of spike counts, by default 0.02.\n    min_units : int, optional\n        Minimum number of units required to compute event-triggered average, by default 6.\n    show_fig : bool, optional\n        If True, plots the figure of event-triggered spiking activity, by default False.\n\n    Returns\n    -------\n    np.ndarray\n        Boolean array indicating valid events that meet the spiking threshold.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"U:\\\\data\\\\hpc_ctx_project\\\\HP04\\\\day_32_20240430\"\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=False)\n    &gt;&gt;&gt; st, cell_metrics = loading.load_spikes(\n            basepath,\n            brainRegion=\"CA1\",\n            support=nel.EpochArray([0, loading.load_epoch(basepath).iloc[-1].stopTime])\n        )\n    &gt;&gt;&gt; idx = event_spiking_threshold(st, ripples.peaks.values, show_fig=True)\n    &gt;&gt;&gt; print(f\"Number of valid ripples: {idx.sum()} out of {len(ripples)}\")\n    Number of valid ripples: 9244 out of 12655\n\n    \"\"\"\n\n    # check if there are enough units to compute a confident event triggered average\n    if spikes.n_active &lt; min_units:\n        return np.ones(len(events), dtype=bool)\n\n    # bin spikes\n    bst = spikes.bin(ds=binsize).smooth(sigma=sigma)\n    # sum over all neurons and zscore\n    bst = bst.data.sum(axis=0)\n    bst = (bst - bst.mean()) / bst.std()\n    # get event triggered average\n    avg_signal, time_lags = event_triggered_average_fast(\n        bst[np.newaxis, :],\n        events,\n        sampling_rate=int(1 / binsize),\n        window=window,\n        return_average=False,\n    )\n    # get the event response within the event size\n    idx = (time_lags &gt;= -event_size) &amp; (time_lags &lt;= event_size)\n    event_response = avg_signal[0, idx, :].mean(axis=0)\n\n    # get events that are above threshold\n    valid_events = event_response &gt; spiking_thres\n\n    if show_fig:\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n\n        sorted_idx = np.argsort(event_response)\n\n        fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n        ax[0].imshow(\n            avg_signal[0, :, sorted_idx],\n            aspect=\"auto\",\n            extent=[time_lags[0], time_lags[-1], 0, len(event_response)],\n            vmin=-2,\n            vmax=2,\n            origin=\"lower\",\n            interpolation=\"nearest\",\n        )\n        ax[0].axhline(\n            np.where(event_response[sorted_idx] &gt; spiking_thres)[0][0],\n            color=\"r\",\n            linestyle=\"--\",\n        )\n        ax[1].plot(event_response[sorted_idx], np.arange(len(event_response)))\n        ax[1].axvline(spiking_thres, color=\"r\", linestyle=\"--\")\n        ax[0].set_xlabel(\"Time from event (s)\")\n        ax[0].set_ylabel(\"Event index\")\n        ax[1].set_xlabel(\"Average response\")\n        ax[1].set_ylabel(\"Event index\")\n        sns.despine()\n\n    return valid_events\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.event_triggered_average","title":"<code>event_triggered_average(timestamps, signal, events, sampling_rate=None, window=[-0.5, 0.5], return_average=True, return_pandas=False, irregular_sampling=False)</code>","text":"<p>Calculates the event-triggered averages of signals in a time window relative to the event times of corresponding events for multiple signals.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>A 1D array of timestamps corresponding to the signal samples.</p> required <code>signal</code> <code>ndarray</code> <p>A 2D array of shape (n_samples, n_signals) containing the signal values.</p> required <code>events</code> <code>Union[ndarray, List[ndarray]]</code> <p>One or more 1D arrays of event times.</p> required <code>sampling_rate</code> <code>Union[float, None]</code> <p>The sampling rate of the signal. If not provided, it will be calculated based on the timestamps.</p> <code>None</code> <code>window</code> <code>List[float]</code> <p>A list containing two elements: the start and stop times relative to an event for the time interval of signal averaging. Default is [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>return_average</code> <code>bool</code> <p>Whether to return the average of the event-triggered average. Defaults to True. If False, returns the full event-triggered average matrix (n_samples x n_signals x n_events).</p> <code>True</code> <code>return_pandas</code> <code>bool</code> <p>If True, return the result as a Pandas DataFrame. Default is False.</p> <code>False</code> <code>irregular_sampling</code> <code>bool</code> <p>If True, indicates that the signal is irregularly sampled and interpolation should be used. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, DataFrame]</code> <p>If <code>return_average</code> is True, returns the event-triggered averages of the signals (n_samples, n_signals) or a Pandas DataFrame if <code>return_pandas</code> is True. If <code>return_average</code> is False, returns the full event-triggered average matrix (n_samples, n_signals, n_events).</p> <code>ndarray</code> <p>An array of time lags corresponding to the event-triggered averages.</p> Notes <ul> <li>The function filters out events that do not fit within the valid range of the signal considering the specified window size.</li> <li>If the <code>sampling_rate</code> is not provided, it is calculated based on the timestamps.</li> <li>The function handles both regular and irregular sampling of the signal.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; peth_avg, time_lags = event_triggered_average(\n...    timestamps, signal, events, window=[-0.5, 0.5]\n... )\n&gt;&gt;&gt; # Get individual event responses\n&gt;&gt;&gt; peth_matrix, time_lags = event_triggered_average(\n...    timestamps, signal, events, window=[-0.5, 0.5], return_average=False\n... )\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average(\n    timestamps: np.ndarray,\n    signal: np.ndarray,\n    events: Union[np.ndarray, List[np.ndarray]],\n    sampling_rate: Union[float, None] = None,\n    window: List[float] = [-0.5, 0.5],\n    return_average: bool = True,\n    return_pandas: bool = False,\n    irregular_sampling: bool = False,\n) -&gt; Tuple[Union[np.ndarray, pd.DataFrame], np.ndarray]:\n    \"\"\"\n    Calculates the event-triggered averages of signals in a time window\n    relative to the event times of corresponding events for multiple signals.\n\n    Parameters\n    ----------\n    timestamps : np.ndarray\n        A 1D array of timestamps corresponding to the signal samples.\n    signal : np.ndarray\n        A 2D array of shape (n_samples, n_signals) containing the signal values.\n    events : Union[np.ndarray, List[np.ndarray]]\n        One or more 1D arrays of event times.\n    sampling_rate : Union[float, None], optional\n        The sampling rate of the signal. If not provided, it will be calculated\n        based on the timestamps.\n    window : List[float], optional\n        A list containing two elements: the start and stop times relative to an event\n        for the time interval of signal averaging. Default is [-0.5, 0.5].\n    return_average : bool, optional\n        Whether to return the average of the event-triggered average. Defaults to True.\n        If False, returns the full event-triggered average matrix (n_samples x n_signals x n_events).\n    return_pandas : bool, optional\n        If True, return the result as a Pandas DataFrame. Default is False.\n    irregular_sampling : bool, optional\n        If True, indicates that the signal is irregularly sampled and interpolation should be used. Default is False.\n\n    Returns\n    -------\n    Union[np.ndarray, pd.DataFrame]\n        If `return_average` is True, returns the event-triggered averages of the signals\n        (n_samples, n_signals) or a Pandas DataFrame if `return_pandas` is True.\n        If `return_average` is False, returns the full event-triggered average matrix\n        (n_samples, n_signals, n_events).\n    np.ndarray\n        An array of time lags corresponding to the event-triggered averages.\n\n    Notes\n    -----\n    - The function filters out events that do not fit within the valid range of the signal\n    considering the specified window size.\n    - If the `sampling_rate` is not provided, it is calculated based on the timestamps.\n    - The function handles both regular and irregular sampling of the signal.\n\n    Examples\n    --------\n    &gt;&gt;&gt; peth_avg, time_lags = event_triggered_average(\n    ...    timestamps, signal, events, window=[-0.5, 0.5]\n    ... )\n    &gt;&gt;&gt; # Get individual event responses\n    &gt;&gt;&gt; peth_matrix, time_lags = event_triggered_average(\n    ...    timestamps, signal, events, window=[-0.5, 0.5], return_average=False\n    ... )\n    \"\"\"\n    # Basic input validation\n    if len(window) != 2 or window[0] &gt; window[1]:\n        raise ValueError(\"'window' must be [start, stop] with start &lt; stop\")\n\n    if len(signal.shape) == 1:\n        signal = signal.reshape(-1, 1)\n\n    if sampling_rate is None:\n        sampling_rate = 1 / stats.mode(np.diff(timestamps), keepdims=True)[0][0]\n\n    if isinstance(events, list):\n        events = np.array(events)\n\n    window_starttime, window_stoptime = window\n    window_bins = int(np.ceil(((window_stoptime - window_starttime) * sampling_rate)))\n    time_lags = np.linspace(window_starttime, window_stoptime, window_bins)\n\n    # Filter events that fit within the signal range\n    min_timestamp, max_timestamp = timestamps[0], timestamps[-1]\n    valid_mask = (events + window_starttime &gt;= min_timestamp) &amp; (\n        events + window_stoptime &lt;= max_timestamp\n    )\n\n    if not np.any(valid_mask):\n        warnings.warn(\"No events found within the valid signal range\")\n        empty_shape = (window_bins, signal.shape[1])\n        if return_average:\n            result = np.zeros(empty_shape)\n            return (\n                pd.DataFrame(result, index=time_lags) if return_pandas else result\n            ), time_lags\n        else:\n            return np.full(empty_shape + (len(events),), np.nan), time_lags\n\n    # Initialize result matrix: (window_bins, n_signals, n_events) - keep all events\n    result_matrix = np.full((window_bins, signal.shape[1], len(events)), np.nan)\n\n    # For regular sampling, use fast indexing approach similar to event_triggered_average_fast\n    dt = np.median(np.diff(timestamps))\n    data_is_regular = np.allclose(np.diff(timestamps), dt, rtol=1e-3)\n    use_interpolation = irregular_sampling or not data_is_regular\n\n    if not use_interpolation:\n        # Fast path: regular sampling - use direct indexing like event_triggered_average_fast\n        # Match the exact indexing logic from event_triggered_average_fast\n        start_time = timestamps[0]  # Cache start time for efficiency\n        for i, event in enumerate(events):\n            if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n                continue\n\n            # Convert event time to sample indices, accounting for timestamp start time\n            event_sample = np.round((event - start_time) * sampling_rate)\n            ts_idx = np.arange(\n                event_sample - window_bins / 2,\n                event_sample + window_bins / 2,\n            ).astype(int)\n\n            # Check bounds\n            if np.min(ts_idx) &gt;= 0 and np.max(ts_idx) &lt; len(signal):\n                result_matrix[:, :, i] = signal[ts_idx, :]\n            # If bounds check fails, keep as NaN (already initialized)\n    else:\n        # Slow path: irregular sampling - use interpolation but vectorized\n        target_times_template = np.linspace(\n            window_starttime, window_stoptime, window_bins\n        )\n\n        for i, event in enumerate(events):\n            if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n                continue\n\n            target_times = target_times_template + event\n\n            # Find the range of timestamps that covers our target times\n            start_search = np.searchsorted(\n                timestamps, target_times[0] - dt, side=\"left\"\n            )\n            stop_search = np.searchsorted(\n                timestamps, target_times[-1] + dt, side=\"right\"\n            )\n\n            if start_search &gt;= stop_search:\n                # Keep as NaN (already initialized)\n                continue\n\n            # Extract relevant data for this event\n            event_timestamps = timestamps[start_search:stop_search]\n            event_signal = signal[start_search:stop_search, :]\n\n            # Vectorized interpolation for all channels at once\n            if len(event_timestamps) &gt; 1:\n                for j in range(signal.shape[1]):\n                    result_matrix[:, j, i] = np.interp(\n                        target_times, event_timestamps, event_signal[:, j]\n                    )\n            # If interpolation fails, keep as NaN (already initialized)\n\n    # Return results\n    if return_average:\n        result_avg = bn.nanmean(result_matrix, axis=2)\n        if return_pandas:\n            return pd.DataFrame(\n                result_avg, index=time_lags, columns=np.arange(signal.shape[1])\n            )\n        return result_avg, time_lags\n    else:\n        return result_matrix, time_lags\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.event_triggered_average_fast","title":"<code>event_triggered_average_fast(signal, events, sampling_rate, window=[-0.5, 0.5], return_average=True, return_pandas=False)</code>","text":"<p>Calculate the event-triggered average of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>A 2D array of signal data with shape (channels, timepoints).</p> required <code>events</code> <code>ndarray</code> <p>A 1D array of event times.</p> required <code>sampling_rate</code> <code>int</code> <p>The sampling rate of the signal in Hz.</p> required <code>window</code> <code>Union[list, Tuple[float, float]]</code> <p>A list or tuple specifying the time window (in seconds) to average the signal around each event. Defaults to [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>return_average</code> <code>bool</code> <p>Whether to return the average of the event-triggered average. Defaults to True. If False, returns the full event-triggered average matrix (channels x timepoints x events).</p> <code>True</code> <code>return_pandas</code> <code>bool</code> <p>If True, returns the average as a Pandas DataFrame. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, DataFrame]</code> <p>If <code>return_average</code> is True, returns the event-triggered average of the signal (channels x timepoints) or a Pandas DataFrame if <code>return_pandas</code> is True. If <code>return_average</code> is False, returns the full event-triggered average matrix (channels x timebins x events).</p> <code>ndarray</code> <p>An array of time lags corresponding to the event-triggered averages.</p> Notes <ul> <li>The function filters out events that do not fit within the valid range of the signal considering the specified window size.</li> <li>Assumes the signal starts at time 0.</li> </ul> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average_fast(\n    signal: np.ndarray,\n    events: np.ndarray,\n    sampling_rate: int,\n    window: Union[list, Tuple[float, float]] = [-0.5, 0.5],\n    return_average: bool = True,\n    return_pandas: bool = False,\n) -&gt; Tuple[Union[np.ndarray, pd.DataFrame], np.ndarray]:\n    \"\"\"\n    Calculate the event-triggered average of a signal.\n\n    Parameters\n    ----------\n    signal : np.ndarray\n        A 2D array of signal data with shape (channels, timepoints).\n\n    events : np.ndarray\n        A 1D array of event times.\n\n    sampling_rate : int\n        The sampling rate of the signal in Hz.\n\n    window : Union[list, Tuple[float, float]], optional\n        A list or tuple specifying the time window (in seconds) to average the signal\n        around each event. Defaults to [-0.5, 0.5].\n\n    return_average : bool, optional\n        Whether to return the average of the event-triggered average. Defaults to True.\n        If False, returns the full event-triggered average matrix (channels x timepoints x events).\n\n    return_pandas : bool, optional\n        If True, returns the average as a Pandas DataFrame. Defaults to False.\n\n    Returns\n    -------\n    Union[np.ndarray, pd.DataFrame]\n        If `return_average` is True, returns the event-triggered average of the signal\n        (channels x timepoints) or a Pandas DataFrame if `return_pandas` is True.\n        If `return_average` is False, returns the full event-triggered average matrix (channels x timebins x events).\n\n    np.ndarray\n        An array of time lags corresponding to the event-triggered averages.\n\n    Notes\n    -----\n    - The function filters out events that do not fit within the valid range of the signal\n    considering the specified window size.\n    - Assumes the signal starts at time 0.\n    \"\"\"\n\n    window_starttime, window_stoptime = window\n    window_bins = int(np.ceil(((window_stoptime - window_starttime) * sampling_rate)))\n    time_lags = np.linspace(window_starttime, window_stoptime, window_bins)\n\n    # Create valid mask instead of filtering events\n    valid_mask = (events * sampling_rate &gt; len(time_lags) / 2 + 1) &amp; (\n        events * sampling_rate &lt; signal.shape[1] - len(time_lags) / 2 + 1\n    )\n\n    # Initialize result matrix with all events, filled with NaN\n    avg_signal = np.full(\n        [signal.shape[0], len(time_lags), len(events)], np.nan, dtype=signal.dtype\n    )\n\n    # Process only valid events\n    for i, event in enumerate(events):\n        if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n            continue\n\n        ts_idx = np.arange(\n            np.round(event * sampling_rate) - len(time_lags) / 2,\n            np.round(event * sampling_rate) + len(time_lags) / 2,\n        ).astype(int)\n        avg_signal[:, :, i] = signal[:, ts_idx]\n\n    if return_pandas and return_average:\n        return pd.DataFrame(\n            index=time_lags,\n            columns=np.arange(signal.shape[0]),\n            data=bn.nanmean(avg_signal, axis=2).T,\n        )\n\n    if return_average:\n        return bn.nanmean(avg_signal, axis=2), time_lags\n    else:\n        return avg_signal, time_lags\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.event_triggered_average_irregular_sample","title":"<code>event_triggered_average_irregular_sample(timestamps, data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Compute the average and standard deviation of data values within a window around each reference time, specifically for irregularly sampled data.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>A 1D array of times associated with data.</p> required <code>data</code> <code>ndarray</code> <p>A 1D array of data values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the window, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the window. Default is 100.</p> <code>100</code> <code>window</code> <code>Union[tuple, None]</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <p>Two DataFrames: the first containing the average values, the second the standard deviation of data values within the window around each reference time.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average_irregular_sample(\n    timestamps: np.ndarray,\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Union[tuple, None] = None,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Compute the average and standard deviation of data values within a window around\n    each reference time, specifically for irregularly sampled data.\n\n    Parameters\n    ----------\n    timestamps : np.ndarray\n        A 1D array of times associated with data.\n    data : np.ndarray\n        A 1D array of data values.\n    time_ref : np.ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the window, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the window. Default is 100.\n    window : Union[tuple, None], optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a\n        width of `n_bins * bin_width` seconds.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        Two DataFrames: the first containing the average values, the second the\n        standard deviation of data values within the window around each reference time.\n    \"\"\"\n\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width, bin_width)\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n    x = []\n    y = []\n    for i, r in enumerate(time_ref):\n        idx = (timestamps &gt; r + times.min()) &amp; (timestamps &lt; r + times.max())\n        x.append((timestamps - r)[idx])\n        y.append(data[idx])\n\n    temp_df = pd.DataFrame()\n    if len(x) == 0:\n        return temp_df, temp_df\n    temp_df[\"time\"] = np.hstack(x)\n    temp_df[\"data\"] = np.hstack(y)\n    temp_df = temp_df.sort_values(by=\"time\", ascending=True)\n\n    average_val = np.zeros(len(times) - 1)\n    std_val = np.zeros(len(times) - 1)\n    for i in range(len(times) - 1):\n        average_val[i] = temp_df[\n            temp_df.time.between(times[i], times[i + 1])\n        ].data.mean()\n        std_val[i] = temp_df[temp_df.time.between(times[i], times[i + 1])].data.std()\n\n    avg = pd.DataFrame(index=times[:-1] + bin_width / 2)\n    avg[0] = average_val\n\n    std = pd.DataFrame(index=times[:-1] + bin_width / 2)\n    std[0] = std_val\n\n    return avg, std\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.event_triggered_cross_correlation","title":"<code>event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts, time_lags=None, window=[-0.5, 0.5], bin_width=0.005)</code>","text":"<p>Computes the cross-correlation between two signals at specific event times</p> <p>Parameters:</p> Name Type Description Default <code>event_times</code> <code>ndarray</code> <p>array of event times</p> required <code>signal1_data</code> <code>ndarray</code> <p>data of signal 1</p> required <code>signal1_ts</code> <code>ndarray</code> <p>timestamps of signal 1</p> required <code>signal2_data</code> <code>ndarray</code> <p>data of signal 2</p> required <code>signal2_ts</code> <code>ndarray</code> <p>timestamps of signal 2</p> required <code>time_lags</code> <code>Union[ndarray, None]</code> <p>array of time lags to compute correlation. If None, it will be computed automatically.</p> <code>None</code> <code>window</code> <code>list</code> <p>window to compute correlation. Default is [-0.5, 0.5]</p> <code>[-0.5, 0.5]</code> <code>bin_width</code> <code>float</code> <p>bin width to compute correlation. Ideally this should be the same as the sampling rate. Default is 0.005</p> <code>0.005</code> <p>Returns:</p> Name Type Description <code>correlation_lags</code> <code>ndarray</code> <p>array of time lags in ascending order (negative to positive)</p> <code>avg_correlation</code> <code>ndarray</code> <p>array of correlation values corresponding to each lag</p> Notes <p>The function computes cross-correlation between signal1 and signal2 around event times. The interpretation of lags is as follows:</p> <ul> <li>Negative lags: signal2 leads signal1 (signal2 peaks occur before signal1 peaks)</li> <li>Zero lag: signals are synchronized</li> <li>Positive lags: signal2 lags behind signal1 (signal2 peaks occur after signal1 peaks)</li> </ul> <p>Peak correlation at positive lag indicates signal2 is a delayed version of signal1. Peak correlation at negative lag indicates signal2 precedes or predicts signal1.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lags, corr = event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts)\n&gt;&gt;&gt; peak_lag = lags[np.argmax(np.abs(corr))]  # Find lag with maximum correlation\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def event_triggered_cross_correlation(\n    event_times: np.ndarray,\n    signal1_data: np.ndarray,\n    signal1_ts: np.ndarray,\n    signal2_data: np.ndarray,\n    signal2_ts: np.ndarray,\n    time_lags: Union[np.ndarray, None] = None,\n    window: list = [-0.5, 0.5],\n    bin_width: float = 0.005,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes the cross-correlation between two signals at specific event times\n\n    Parameters\n    ----------\n    event_times : np.ndarray\n        array of event times\n    signal1_data : np.ndarray\n        data of signal 1\n    signal1_ts : np.ndarray\n        timestamps of signal 1\n    signal2_data : np.ndarray\n        data of signal 2\n    signal2_ts : np.ndarray\n        timestamps of signal 2\n    time_lags : Union[np.ndarray, None], optional\n        array of time lags to compute correlation. If None, it will be computed automatically.\n    window : list, optional\n        window to compute correlation. Default is [-0.5, 0.5]\n    bin_width : float, optional\n        bin width to compute correlation. Ideally this should be the same as the sampling rate.\n        Default is 0.005\n\n    Returns\n    -------\n    correlation_lags : np.ndarray\n        array of time lags in ascending order (negative to positive)\n    avg_correlation : np.ndarray\n        array of correlation values corresponding to each lag\n\n    Notes\n    -----\n    The function computes cross-correlation between signal1 and signal2 around event times.\n    The interpretation of lags is as follows:\n\n    - **Negative lags**: signal2 leads signal1 (signal2 peaks occur before signal1 peaks)\n    - **Zero lag**: signals are synchronized\n    - **Positive lags**: signal2 lags behind signal1 (signal2 peaks occur after signal1 peaks)\n\n    Peak correlation at positive lag indicates signal2 is a delayed version of signal1.\n    Peak correlation at negative lag indicates signal2 precedes or predicts signal1.\n\n    Examples\n    --------\n    &gt;&gt;&gt; lags, corr = event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts)\n    &gt;&gt;&gt; peak_lag = lags[np.argmax(np.abs(corr))]  # Find lag with maximum correlation\n    \"\"\"\n\n    if time_lags is None:\n        time_lags = np.arange(window[0], window[1], bin_width)\n\n    # Interpolate both signals at event times + all possible lags\n    n_events = len(event_times)\n    n_lags = len(time_lags)\n\n    # Handle empty event times case\n    if n_events == 0:\n        max_lag_samples = n_lags - 1\n        correlation_lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n            time_lags[1] - time_lags[0]\n        )\n        # Create zero correlation array\n        avg_correlation = np.zeros(2 * n_lags - 1)\n\n        # restrict to window\n        avg_correlation = avg_correlation[\n            (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n        ]\n        correlation_lags = correlation_lags[\n            (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n        ]\n\n        return correlation_lags, avg_correlation\n\n    # Create time matrix: events x lags\n    event_times_matrix = event_times[:, None] + time_lags[None, :]\n\n    # Interpolate both signals\n    signal1_matrix = np.interp(\n        event_times_matrix.flatten(), signal1_ts, signal1_data\n    ).reshape(n_events, n_lags)\n    signal2_matrix = np.interp(\n        event_times_matrix.flatten(), signal2_ts, signal2_data\n    ).reshape(n_events, n_lags)\n\n    # Compute cross-correlation for each event\n    correlations = _jit_event_corr(signal1_matrix, signal2_matrix)\n\n    # Average across events\n    avg_correlation = np.mean(correlations, axis=0)\n\n    # Create lag axis for the correlation result in ascending order\n    max_lag_samples = n_lags - 1\n    correlation_lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n        time_lags[1] - time_lags[0]\n    )\n    # Reverse the correlation array to match the ascending lag order\n    avg_correlation = avg_correlation[::-1]\n\n    # restrict to window\n    avg_correlation = avg_correlation[\n        (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n    ]\n    correlation_lags = correlation_lags[\n        (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n    ]\n\n    return correlation_lags, avg_correlation\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.fast_acf","title":"<code>fast_acf(counts, width, bin_width, cut_peak=True)</code>","text":"<p>Compute the Auto-Correlation Function (ACF) in a fast manner using Numba.</p> <p>This function calculates the ACF of a given variable of interest, such as spike times or spike phases, leveraging the <code>pcorrelate</code> function for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>ndarray</code> <p>1D array of the variable of interest (e.g., spike times or spike phases).</p> required <code>width</code> <code>float</code> <p>Time window for the ACF computation.</p> required <code>bin_width</code> <code>float</code> <p>Width of the bins for the ACF.</p> required <code>cut_peak</code> <code>bool</code> <p>If True, the largest central peak will be replaced for subsequent fitting. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>acf</code> <code>ndarray</code> <p>1D array of counts for the ACF.</p> <code>bins</code> <code>ndarray</code> <p>1D array of lag bins for the ACF.</p> Notes <ul> <li>The ACF is calculated over a specified time window and returns the   counts of the ACF along with the corresponding bins.</li> <li>The <code>cut_peak</code> parameter allows for the adjustment of the ACF peak, which   can be useful for fitting processes.</li> </ul> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def fast_acf(\n    counts: np.ndarray, width: float, bin_width: float, cut_peak: bool = True\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute the Auto-Correlation Function (ACF) in a fast manner using Numba.\n\n    This function calculates the ACF of a given variable of interest, such as\n    spike times or spike phases, leveraging the `pcorrelate` function for efficiency.\n\n    Parameters\n    ----------\n    counts : np.ndarray\n        1D array of the variable of interest (e.g., spike times or spike phases).\n    width : float\n        Time window for the ACF computation.\n    bin_width : float\n        Width of the bins for the ACF.\n    cut_peak : bool, optional\n        If True, the largest central peak will be replaced for subsequent fitting. Default is True.\n\n    Returns\n    -------\n    acf : np.ndarray\n        1D array of counts for the ACF.\n    bins : np.ndarray\n        1D array of lag bins for the ACF.\n\n    Notes\n    -----\n    - The ACF is calculated over a specified time window and returns the\n      counts of the ACF along with the corresponding bins.\n    - The `cut_peak` parameter allows for the adjustment of the ACF peak, which\n      can be useful for fitting processes.\n    \"\"\"\n\n    n_b = int(np.ceil(width / bin_width))  # Num. edges per side\n    # Define the edges of the bins (including rightmost bin)\n    bins = np.linspace(-width, width, 2 * n_b, endpoint=True)\n    temp = pcorrelate(counts, counts, np.split(bins, 2)[1])\n    acf = np.ones(bins.shape[0] - 1)\n    acf[0 : temp.shape[0]] = np.flip(temp)\n    acf[temp.shape[0]] = temp[0]\n    acf[temp.shape[0] + 1 :] = temp\n\n    if cut_peak:\n        acf[np.nanargmax(acf)] = np.sort(acf)[-2]\n\n    return acf, bins\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.find_intersecting_intervals","title":"<code>find_intersecting_intervals(set1, set2, return_indices=True)</code>","text":"<p>Find the amount of time two sets of intervals are intersecting each other for each intersection.</p> <p>Parameters:</p> Name Type Description Default <code>set1</code> <code>nelpy EpochArray</code> <p>The first set of intervals to check for intersections.</p> required <code>set2</code> <code>nelpy EpochArray</code> <p>The second set of intervals to check for intersections.</p> required <code>return_indices</code> <code>bool</code> <p>If True, return the indices of the intervals in set2 that intersect with each interval in set1. If False, return the amount of time each interval in set1 intersects with any interval in set2.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[ndarray, List[bool]]</code> <p>If return_indices is True, returns a boolean array indicating whether each interval in set1 intersects with any interval in set2. If return_indices is False, returns a NumPy array with the amount of time each interval in set1 intersects with any interval in set2.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n&gt;&gt;&gt; set2 = nel.EpochArray([(2, 4), (6, 8)])\n&gt;&gt;&gt; find_intersecting_intervals(set1, set2)\n[True, True, False]\n&gt;&gt;&gt; find_intersecting_intervals(set1, set2, return_indices=False)\n[1, 2, 0]\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def find_intersecting_intervals(\n    set1: nel.EpochArray, set2: nel.EpochArray, return_indices: bool = True\n) -&gt; Union[np.ndarray, List[bool]]:\n    \"\"\"\n    Find the amount of time two sets of intervals are intersecting each other for each intersection.\n\n    Parameters\n    ----------\n    set1 : nelpy EpochArray\n        The first set of intervals to check for intersections.\n    set2 : nelpy EpochArray\n        The second set of intervals to check for intersections.\n    return_indices : bool, optional\n        If True, return the indices of the intervals in set2 that intersect with each interval in set1.\n        If False, return the amount of time each interval in set1 intersects with any interval in set2.\n\n    Returns\n    -------\n    Union[np.ndarray, List[bool]]\n        If return_indices is True, returns a boolean array indicating whether each interval in set1 intersects with any interval in set2.\n        If return_indices is False, returns a NumPy array with the amount of time each interval in set1 intersects with any interval in set2.\n\n    Examples\n    --------\n    &gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n    &gt;&gt;&gt; set2 = nel.EpochArray([(2, 4), (6, 8)])\n    &gt;&gt;&gt; find_intersecting_intervals(set1, set2)\n    [True, True, False]\n    &gt;&gt;&gt; find_intersecting_intervals(set1, set2, return_indices=False)\n    [1, 2, 0]\n    \"\"\"\n    if not isinstance(set1, core.IntervalArray) &amp; isinstance(set2, core.IntervalArray):\n        raise ValueError(\"only EpochArrays are supported\")\n\n    intersection = np.array(_find_intersecting_intervals(set1.data, set2.data))\n    if return_indices:\n        return intersection &gt; 0\n    return intersection\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.find_interval","title":"<code>find_interval(logical)</code>","text":"<p>Find consecutive intervals of True values in a list of boolean values.</p> <p>Parameters:</p> Name Type Description Default <code>logical</code> <code>List[bool]</code> <p>The list of boolean values.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int]]</code> <p>A list of tuples representing the start and end indices of each consecutive interval of True values in the logical list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; find_interval([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])\n[(2, 4), (6, 7), (10, 11)]\n&gt;&gt;&gt; find_interval([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n[(0, 2), (4, 5), (9, 10)]\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def find_interval(logical: List[bool]) -&gt; List[Tuple[int, int]]:\n    \"\"\"\n    Find consecutive intervals of True values in a list of boolean values.\n\n    Parameters\n    ----------\n    logical : List[bool]\n        The list of boolean values.\n\n    Returns\n    -------\n    List[Tuple[int, int]]\n        A list of tuples representing the start and end indices of each consecutive interval of True values in the logical list.\n\n    Examples\n    --------\n    &gt;&gt;&gt; find_interval([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])\n    [(2, 4), (6, 7), (10, 11)]\n    &gt;&gt;&gt; find_interval([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n    [(0, 2), (4, 5), (9, 10)]\n    \"\"\"\n    intervals = []\n    start = None\n    for i, value in enumerate(logical):\n        if value and start is None:\n            start = i\n        elif not value and start is not None:\n            intervals.append((start, i - 1))\n            start = None\n    if start is not None:\n        intervals.append((start, len(logical) - 1))\n    return intervals\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.get_rank_order","title":"<code>get_rank_order(st, epochs, method='peak_fr', ref='cells', padding=0.05, dt=0.001, sigma=0.01, min_units=5)</code>","text":"<p>Calculate the rank order of spike trains within specified epochs.</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>ndarray or array</code> <p>Spike train data. Can be a nelpy array containing spike times.</p> required <code>epochs</code> <code>EpochArray</code> <p>An object containing the epochs (windows) in which to calculate the rank order.</p> required <code>method</code> <code>str</code> <p>Method to calculate rank order. Choices are 'first_spike' or 'peak_fr'. Defaults to 'peak_fr'.</p> <code>'peak_fr'</code> <code>ref</code> <code>str</code> <p>Reference frame for rank order. Choices are 'cells' or 'epoch'. Defaults to 'cells'.</p> <code>'cells'</code> <code>padding</code> <code>float</code> <p>Padding (in seconds) to apply to the epochs. Defaults to 0.05 seconds.</p> <code>0.05</code> <code>dt</code> <code>float</code> <p>Bin width (in seconds) for finding relative time in the epoch reference. Defaults to 0.001 seconds.</p> <code>0.001</code> <code>sigma</code> <code>float</code> <p>Smoothing sigma (in seconds) for the 'peak_fr' method. Defaults to 0.01 seconds.</p> <code>0.01</code> <code>min_units</code> <code>int</code> <p>Minimum number of active units required to compute the rank order. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>median_rank</code> <code>ndarray</code> <p>The median rank order across all epochs, normalized between 0 and 1.</p> <code>rank_order</code> <code>ndarray</code> <p>A 2D array of rank orders, where each column corresponds to an epoch, and each row corresponds to a cell, normalized between 0 and 1.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; st, _ = loading.load_spikes(basepath, putativeCellType='Pyr')\n&gt;&gt;&gt; forward_replay = nel.EpochArray(np.array([starts, stops]).T)\n&gt;&gt;&gt; median_rank, rank_order = get_rank_order(st, forward_replay)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def get_rank_order(\n    st: SpikeTrainArray,  # Assuming 'nelpy.array' is a custom type\n    epochs: EpochArray,\n    method: str = \"peak_fr\",  # 'first_spike' or 'peak_fr'\n    ref: str = \"cells\",  # 'cells' or 'epoch'\n    padding: float = 0.05,\n    dt: float = 0.001,\n    sigma: float = 0.01,\n    min_units: int = 5,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate the rank order of spike trains within specified epochs.\n\n    Parameters\n    ----------\n    st : np.ndarray or nelpy.array\n        Spike train data. Can be a nelpy array containing spike times.\n\n    epochs : nelpy.EpochArray\n        An object containing the epochs (windows) in which to calculate the rank order.\n\n    method : str, optional\n        Method to calculate rank order. Choices are 'first_spike' or 'peak_fr'.\n        Defaults to 'peak_fr'.\n\n    ref : str, optional\n        Reference frame for rank order. Choices are 'cells' or 'epoch'.\n        Defaults to 'cells'.\n\n    padding : float, optional\n        Padding (in seconds) to apply to the epochs. Defaults to 0.05 seconds.\n\n    dt : float, optional\n        Bin width (in seconds) for finding relative time in the epoch reference.\n        Defaults to 0.001 seconds.\n\n    sigma : float, optional\n        Smoothing sigma (in seconds) for the 'peak_fr' method. Defaults to 0.01 seconds.\n\n    min_units : int, optional\n        Minimum number of active units required to compute the rank order. Defaults to 5.\n\n    Returns\n    -------\n    median_rank : np.ndarray\n        The median rank order across all epochs, normalized between 0 and 1.\n\n    rank_order : np.ndarray\n        A 2D array of rank orders, where each column corresponds to an epoch,\n        and each row corresponds to a cell, normalized between 0 and 1.\n\n    Examples\n    --------\n    &gt;&gt;&gt; st, _ = loading.load_spikes(basepath, putativeCellType='Pyr')\n    &gt;&gt;&gt; forward_replay = nel.EpochArray(np.array([starts, stops]).T)\n    &gt;&gt;&gt; median_rank, rank_order = get_rank_order(st, forward_replay)\n    \"\"\"\n    # filter out specific warnings\n    warnings.filterwarnings(\n        \"ignore\", message=\"ignoring events outside of eventarray support\"\n    )\n    warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\")\n\n    if method not in [\"first_spike\", \"peak_fr\"]:\n        raise Exception(\"method \" + method + \" not implemented\")\n    if ref not in [\"cells\", \"epoch\"]:\n        raise Exception(\"ref \" + ref + \" not implemented\")\n\n    def get_min_ts(st_temp):\n        min_ts = []\n        for ts in st_temp.data:\n            # nan if no spikes\n            if len(ts) == 0:\n                min_ts.append(np.nan)\n            else:\n                min_ts.append(np.nanmin(ts))\n        return min_ts\n\n    def rank_order_first_spike(st_epoch, epochs, dt, min_units, ref):\n        # set up empty matrix for rank order\n        rank_order = np.ones([st_epoch.data.shape[0], epochs.n_intervals]) * np.nan\n\n        unit_id = np.arange(st_epoch.data.shape[0])\n        st_epoch._abscissa.support = epochs\n\n        # iter over every event\n        for event_i, st_temp in enumerate(st_epoch):\n            if ref == \"cells\":\n                # get firing order\n                idx = np.array(st_temp.get_event_firing_order()) - 1\n                # reorder unit ids by order and remove non-active\n                units = unit_id[idx][st_temp.n_events[idx] &gt; 0]\n                # how many are left?\n                nUnits = len(units)\n\n                if nUnits &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    # arange 1 to n units in order of units\n                    rank_order[units, event_i] = np.arange(nUnits)\n                    # normalize by n units\n                    rank_order[units, event_i] = rank_order[units, event_i] / nUnits\n            elif ref == \"epoch\":\n                # find first spike time for each cell\n                min_ts = get_min_ts(st_temp)\n                # make time stamps for interpolation\n                epoch_ts = np.arange(epochs[event_i].start, epochs[event_i].stop, dt)\n                # make normalized range 0-1\n                norm_range = np.linspace(0, 1, len(epoch_ts))\n                # get spike order relative to normalized range\n                if len(min_ts) &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    rank_order[:, event_i] = np.interp(min_ts, epoch_ts, norm_range)\n        return rank_order\n\n    def rank_order_fr(st, epochs, dt, sigma, min_units, ref):\n        # set up empty matrix for rank order\n        rank_order = np.zeros([st.data.shape[0], epochs.n_intervals]) * np.nan\n\n        unit_id = np.arange(st.data.shape[0])\n\n        edges = split_epoch_by_width(epochs.data, dt)\n\n        z_t = count_in_interval(st.data, edges[:, 0], edges[:, 1], par_type=\"counts\")\n        _, interval_id = in_intervals(edges[:, 0], epochs.data, return_interval=True)\n\n        # iter over epochs\n        for event_i, epochs_temp in enumerate(epochs):\n            # smooth spike train in order to estimate peak\n            # z_t_temp.smooth(sigma=sigma, inplace=True)\n            z_t_temp = z_t[:, interval_id == event_i]\n            # smooth spike train in order to estimate peak\n            z_t_temp = gaussian_filter1d(z_t_temp, sigma / dt, axis=1)\n            if ref == \"cells\":\n                # find loc of each peak and get sorted idx of active units\n                idx = np.argsort(np.argmax(z_t_temp, axis=1))\n                # reorder unit ids by order and remove non-active\n                units = unit_id[idx][np.sum(z_t_temp[idx, :] &gt; 0, axis=1) &gt; 0]\n\n                nUnits = len(units)\n\n                if nUnits &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    # arange 1 to n units in order of units\n                    rank_order[units, event_i] = np.arange(nUnits)\n                    # normalize by n units\n                    rank_order[units, event_i] = rank_order[units, event_i] / nUnits\n            elif ref == \"epoch\":\n                # iterate over each cell\n                for cell_i, unit in enumerate(z_t_temp):\n                    # if the cell is not active apply nan\n                    if not np.any(unit &gt; 0):\n                        rank_order[cell_i, event_i] = np.nan\n                    else:\n                        # calculate normalized rank order (0-1)\n                        rank_order[cell_i, event_i] = np.argmax(unit) / len(unit)\n        return rank_order\n\n    # expand epochs by padding amount\n    epochs = epochs.expand(padding)\n\n    # check if no active cells\n    if st.n_active == 0:\n        return np.tile(np.nan, st.data.shape), np.tile(\n            np.nan, (st.data.shape[0], epochs.n_intervals)\n        )\n\n    # check if there are any spikes in the epoch\n    st_epoch = count_in_interval(\n        st.data, epochs.starts, epochs.stops, par_type=\"counts\"\n    )\n\n    # if no spikes in epoch, break out\n    if (st_epoch == 0).all():\n        return np.tile(np.nan, st.data.shape), np.tile(\n            np.nan, (st.data.shape[0], epochs.n_intervals)\n        )\n\n    # set up empty matrix for rank order\n    if method == \"peak_fr\":\n        rank_order = rank_order_fr(st, epochs, dt, sigma, min_units, ref)\n    elif method == \"first_spike\":\n        rank_order = rank_order_first_spike(st[epochs], epochs, dt, min_units, ref)\n    else:\n        raise Exception(\"method \" + method + \" not implemented\")\n\n    return np.nanmedian(rank_order, axis=1), rank_order\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.get_raster_points","title":"<code>get_raster_points(data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Generate points for a raster plot centered around each reference time in the <code>time_ref</code> array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A 1D array of time values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the raster plot, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the raster plot. Default is 100.</p> <code>100</code> <code>window</code> <code>tuple</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>x</code> <code>ndarray</code> <p>A 1D array of x values representing the time offsets of each data point relative to the corresponding reference time.</p> <code>y</code> <code>ndarray</code> <p>A 1D array of y values representing the reference times.</p> <code>times</code> <code>ndarray</code> <p>A 1D array of time values corresponding to the bins in the raster plot.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef get_raster_points(\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Optional[Tuple[float, float]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate points for a raster plot centered around each reference time in the `time_ref` array.\n\n    Parameters\n    ----------\n    data : ndarray\n        A 1D array of time values.\n    time_ref : ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the raster plot, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the raster plot. Default is 100.\n    window : tuple, optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a width of `n_bins * bin_width` seconds.\n\n    Returns\n    -------\n    x : ndarray\n        A 1D array of x values representing the time offsets of each data point relative to the corresponding reference time.\n    y : ndarray\n        A 1D array of y values representing the reference times.\n    times : ndarray\n        A 1D array of time values corresponding to the bins in the raster plot.\n    \"\"\"\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    x = np.empty(0)\n    y = np.empty(0)\n    for i, r in enumerate(time_ref):\n        idx = (data &gt; r + times.min()) &amp; (data &lt; r + times.max())\n        cur_data = data[idx]\n        x = np.concatenate((x, cur_data - r))\n        y = np.concatenate((y, np.ones_like(cur_data) * i))\n\n    return x, y, times\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.get_tapers","title":"<code>get_tapers(N, bandwidth, *, fs=1.0, min_lambda=0.95, n_tapers=None)</code>","text":"<p>Compute tapers and associated energy concentrations for the Thomson multitaper method.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Length of taper.</p> required <code>bandwidth</code> <code>float</code> <p>Bandwidth of taper, in Hz.</p> required <code>fs</code> <code>float</code> <p>Sampling rate, in Hz. Default is 1 Hz.</p> <code>1.0</code> <code>min_lambda</code> <code>float</code> <p>Minimum energy concentration that each taper must satisfy. Default is 0.95.</p> <code>0.95</code> <code>n_tapers</code> <code>Optional[int]</code> <p>Number of tapers to compute. Default is to use all tapers that satisfy 'min_lambda'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tapers</code> <code>ndarray</code> <p>Array of tapers with shape (n_tapers, N).</p> <code>lambdas</code> <code>ndarray</code> <p>Energy concentrations for each taper with shape (n_tapers,).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If not enough tapers are available or if none of the tapers satisfy the minimum energy concentration criteria.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def get_tapers(\n    N: int,\n    bandwidth: float,\n    *,\n    fs: float = 1.0,\n    min_lambda: float = 0.95,\n    n_tapers: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute tapers and associated energy concentrations for the Thomson\n    multitaper method.\n\n    Parameters\n    ----------\n    N : int\n        Length of taper.\n    bandwidth : float\n        Bandwidth of taper, in Hz.\n    fs : float, optional\n        Sampling rate, in Hz. Default is 1 Hz.\n    min_lambda : float, optional\n        Minimum energy concentration that each taper must satisfy. Default is 0.95.\n    n_tapers : Optional[int], optional\n        Number of tapers to compute. Default is to use all tapers that satisfy 'min_lambda'.\n\n    Returns\n    -------\n    tapers : np.ndarray\n        Array of tapers with shape (n_tapers, N).\n    lambdas : np.ndarray\n        Energy concentrations for each taper with shape (n_tapers,).\n\n    Raises\n    ------\n    ValueError\n        If not enough tapers are available or if none of the tapers satisfy the\n        minimum energy concentration criteria.\n    \"\"\"\n\n    NW = bandwidth * N / fs\n    K = int(np.ceil(2 * NW)) - 1\n    if n_tapers is not None:\n        K = min(K, n_tapers)\n    if K &lt; 1:\n        raise ValueError(\n            f\"Not enough tapers, with 'NW' of {NW}. Increase the bandwidth or \"\n            \"use more data points\"\n        )\n\n    tapers, lambdas = dpss(N, NW=NW, Kmax=K, sym=False, norm=2, return_ratios=True)\n    mask = lambdas &gt; min_lambda\n    if not np.sum(mask) &gt; 0:\n        raise ValueError(\n            \"None of the tapers satisfied the minimum energy concentration\"\n            f\" criteria of {min_lambda}\"\n        )\n    tapers = tapers[mask]\n    lambdas = lambdas[mask]\n\n    if n_tapers is not None:\n        if n_tapers &gt; tapers.shape[0]:\n            raise ValueError(\n                f\"'n_tapers' of {n_tapers} is greater than the {tapers.shape[0]}\"\n                f\" that satisfied the minimum energy concentration criteria of {min_lambda}\"\n            )\n        tapers = tapers[:n_tapers]\n        lambdas = lambdas[:n_tapers]\n\n    return tapers, lambdas\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.getfgrid","title":"<code>getfgrid(Fs, nfft, fpass)</code>","text":"<p>Get frequency grid for evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>nfft</code> <code>int</code> <p>Number of points for FFT.</p> required <code>fpass</code> <code>List[float]</code> <p>Frequency range to evaluate (as [fmin, fmax]).</p> required <p>Returns:</p> Name Type Description <code>f</code> <code>ndarray</code> <p>Frequency vector within the specified range.</p> <code>findx</code> <code>ndarray</code> <p>Boolean array indicating the indices of the frequency vector that fall within the specified range.</p> Notes <p>The frequency vector is computed based on the sampling frequency and the number of FFT points. Only frequencies within the range defined by <code>fpass</code> are returned.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def getfgrid(Fs: int, nfft: int, fpass: List[float]) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get frequency grid for evaluation.\n\n    Parameters\n    ----------\n    Fs : int\n        Sampling frequency.\n    nfft : int\n        Number of points for FFT.\n    fpass : List[float]\n        Frequency range to evaluate (as [fmin, fmax]).\n\n    Returns\n    -------\n    f : np.ndarray\n        Frequency vector within the specified range.\n    findx : np.ndarray\n        Boolean array indicating the indices of the frequency vector that fall within the specified range.\n\n    Notes\n    -----\n    The frequency vector is computed based on the sampling frequency and the number of FFT points.\n    Only frequencies within the range defined by `fpass` are returned.\n    \"\"\"\n    df = Fs / nfft\n    f = np.arange(0, Fs + df, df)\n    f = f[0:nfft]\n    findx = (f &gt;= fpass[0]) &amp; (f &lt;= fpass[-1])\n    f = f[findx]\n    return f, findx\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.in_intervals","title":"<code>in_intervals(timestamps, intervals, return_interval=False, shift=False)</code>","text":"<p>Find which timestamps fall within the given intervals.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>An array of timestamp values. Assumes sorted.</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <code>return_interval</code> <code>(bool, optional(default=False))</code> <p>If True, return the index of the interval to which each timestamp belongs.</p> <code>False</code> <code>shift</code> <code>(bool, optional(default=False))</code> <p>If True, return the shifted timestamps</p> <code>False</code> <p>Returns:</p> Name Type Description <code>in_interval</code> <code>ndarray</code> <p>A logical index indicating which timestamps fall within the intervals.</p> <code>interval</code> <code>(ndarray, optional)</code> <p>A ndarray indicating for each timestamps which interval it was within.</p> <code>shifted_timestamps</code> <code>(ndarray, optional)</code> <p>The shifted timestamps</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n&gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n&gt;&gt;&gt; in_intervals(timestamps, intervals)\narray([False,  True,  True,  True,  True,  True,  True, False])\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([nan,  0.,  0.,  0.,  1.,  1.,  1., nan]))\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, shift=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([0, 1, 2, 2, 3, 4]))\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True, shift=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([0, 0, 0, 1, 1, 1]),\narray([0, 1, 2, 2, 3, 4]))\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def in_intervals(\n    timestamps: np.ndarray,\n    intervals: np.ndarray,\n    return_interval: bool = False,\n    shift: bool = False,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]]:\n    \"\"\"\n    Find which timestamps fall within the given intervals.\n\n    Parameters\n    ----------\n    timestamps : ndarray\n        An array of timestamp values. Assumes sorted.\n    intervals : ndarray\n        An array of time intervals, represented as pairs of start and end times.\n    return_interval : bool, optional (default=False)\n        If True, return the index of the interval to which each timestamp belongs.\n    shift : bool, optional (default=False)\n        If True, return the shifted timestamps\n\n    Returns\n    -------\n    in_interval : ndarray\n        A logical index indicating which timestamps fall within the intervals.\n    interval : ndarray, optional\n        A ndarray indicating for each timestamps which interval it was within.\n    shifted_timestamps : ndarray, optional\n        The shifted timestamps\n\n    Examples\n    --------\n    &gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n    &gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n    &gt;&gt;&gt; in_intervals(timestamps, intervals)\n    array([False,  True,  True,  True,  True,  True,  True, False])\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1., nan]))\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, shift=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([0, 1, 2, 2, 3, 4]))\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True, shift=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([0, 0, 0, 1, 1, 1]),\n    array([0, 1, 2, 2, 3, 4]))\n    \"\"\"\n    in_interval = np.zeros(timestamps.shape, dtype=np.bool_)\n    interval = np.full(timestamps.shape, np.nan)\n\n    for i, (start, end) in enumerate(intervals):\n        # Find the leftmost index of a timestamp that is &gt;= start\n        left = np.searchsorted(timestamps, start, side=\"left\")\n        if left == len(timestamps):\n            # If start is greater than all timestamps, skip this interval\n            continue\n        # Find the rightmost index of a timestamp that is &lt;= end\n        right = np.searchsorted(timestamps, end, side=\"right\")\n        if right == left:\n            # If there are no timestamps in the interval, skip it\n            continue\n        # Mark the timestamps in the interval\n        in_interval[left:right] = True\n        interval[left:right] = i\n\n    if shift:\n        # Restrict to the timestamps that fall within the intervals\n        interval = interval[in_interval].astype(int)\n\n        # Calculate shifts based on intervals\n        shifts = np.insert(np.cumsum(intervals[1:, 0] - intervals[:-1, 1]), 0, 0)[\n            interval\n        ]\n\n        # Apply shifts to timestamps\n        shifted_timestamps = timestamps[in_interval] - shifts - intervals[0, 0]\n\n    if return_interval and shift:\n        return in_interval, interval, shifted_timestamps\n\n    if return_interval:\n        return in_interval, interval\n\n    if shift:\n        return in_interval, shifted_timestamps\n\n    return in_interval\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.in_intervals_interval","title":"<code>in_intervals_interval(timestamps, intervals)</code>","text":"<p>for each timestamps value, the index of the interval to which it belongs (nan = none)</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>An array of timestamp values. assumes sorted</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <p>A ndarray indicating for each timestamps which interval it was within.</p> <code>Note</code> <code>produces same result as in_intervals with return_interval=True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n&gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n&gt;&gt;&gt; in_intervals_interval(timestamps, intervals)\narray([nan,  0,  0,  0,  1,  1,  1, nan])\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>@jit(nopython=True, parallel=True)\ndef in_intervals_interval(timestamps: np.ndarray, intervals: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    for each timestamps value, the index of the interval to which it belongs (nan = none)\n\n    Parameters\n    ----------\n    timestamps : ndarray\n        An array of timestamp values. assumes sorted\n    intervals : ndarray\n        An array of time intervals, represented as pairs of start and end times.\n\n    Returns\n    -------\n    ndarray\n        A ndarray indicating for each timestamps which interval it was within.\n\n    Note: produces same result as in_intervals with return_interval=True\n\n    Examples\n    --------\n    &gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n    &gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n    &gt;&gt;&gt; in_intervals_interval(timestamps, intervals)\n    array([nan,  0,  0,  0,  1,  1,  1, nan])\n    \"\"\"\n    in_interval = np.full(timestamps.shape, np.nan)\n    for i in numba.prange(intervals.shape[0]):\n        start, end = intervals[i]\n        mask = (timestamps &gt;= start) &amp; (timestamps &lt;= end)\n        in_interval[mask] = i\n\n    return in_interval\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.joint_peth","title":"<code>joint_peth(peth_1, peth_2, smooth_std=2)</code>","text":"<p>Produce a joint histogram for the co-occurrence of two sets of signals around events.</p> <p>This analysis tests for interactions. For example, the interaction of ripples and spindles around the occurrence of delta waves. It is a good way to control whether the relationships between two variables is entirely explained by a third variable (the events serving as basis for the PETHs).</p> <p>Parameters:</p> Name Type Description Default <code>peth_1</code> <code>ndarray</code> <p>The first peri-event time histogram (PETH) signal, shape (n_events, n_time).</p> required <code>peth_2</code> <code>ndarray</code> <p>The second peri-event time histogram (PETH) signal, shape (n_events, n_time).</p> required <code>smooth_std</code> <code>float</code> <p>The standard deviation of the Gaussian smoothing kernel (default is 2).</p> <code>2</code> <p>Returns:</p> Name Type Description <code>joint</code> <code>ndarray</code> <p>The joint histogram of the two PETH signals (n_time, n_time).</p> <code>expected</code> <code>ndarray</code> <p>The expected histogram of the two PETH signals (n_time, n_time).</p> <code>difference</code> <code>ndarray</code> <p>The difference between the joint and expected histograms of the two PETH signals (n_time, n_time).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.peri_event import joint_peth, peth_matrix, joint_peth\n&gt;&gt;&gt; from neuro_py.spikes.spike_tools import get_spindices\n&gt;&gt;&gt; from neuro_py.io import loading\n</code></pre> <pre><code>&gt;&gt;&gt; # load ripples, delta waves, and PFC pyramidal cell spikes from basepath\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\HMC1\\day8\"\n</code></pre> <pre><code>&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; delta_waves = loading.load_events(basepath, epoch_name=\"deltaWaves\")\n&gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"PFC\",putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # flatten spikes (nelpy has .flatten(), but get_spindices is much faster)\n&gt;&gt;&gt; spikes = get_spindices(st.data)\n</code></pre> <pre><code>&gt;&gt;&gt; # create peri-event time histograms (PETHs) for the three signals\n&gt;&gt;&gt; window=[-1,1]\n&gt;&gt;&gt; labels = [\"spikes\", \"ripple\", \"delta\"]\n&gt;&gt;&gt; peth_1,ts = peth_matrix(spikes.spike_times.values, delta_waves.starts, bin_width=0.02, n_bins=101)\n&gt;&gt;&gt; peth_2,ts = peth_matrix(ripples.starts, delta_waves.starts, bin_width=0.02, n_bins=101)\n</code></pre> <pre><code>&gt;&gt;&gt; # calculate the joint, expected, and difference histograms\n&gt;&gt;&gt; joint, expected, difference = joint_peth(peth_1.T, peth_2.T, smooth_std=2)\n</code></pre> Notes <p>Note: sometimes the difference between \"joint\" and \"expected\" may be dominated due to brain state effects (e.g. if both ripples are spindles are more common around delta waves taking place in early SWS and have decreased rates around delta waves in late SWS, then all the values of \"joint\" would be larger than the value of \"expected\". In such a case, to investigate the timing effects in particular and ignore such global changes (correlations across the rows of \"PETH1\" and \"PETH2\"), consider normalizing the rows of the PETHs before calling joint_peth.</p> <p>See Sirota et al. (2003)</p> <p>Adapted from JointPETH.m, Copyright (C) 2018-2022 by Ralitsa Todorova</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def joint_peth(\n    peth_1: np.ndarray, peth_2: np.ndarray, smooth_std: float = 2\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Produce a joint histogram for the co-occurrence of two sets of signals around events.\n\n    This analysis tests for interactions. For example, the interaction of\n    ripples and spindles around the occurrence of delta waves. It is a good way\n    to control whether the relationships between two variables is entirely explained\n    by a third variable (the events serving as basis for the PETHs).\n\n    Parameters\n    ----------\n    peth_1 : np.ndarray\n        The first peri-event time histogram (PETH) signal, shape (n_events, n_time).\n    peth_2 : np.ndarray\n        The second peri-event time histogram (PETH) signal, shape (n_events, n_time).\n    smooth_std : float, optional\n        The standard deviation of the Gaussian smoothing kernel (default is 2).\n\n    Returns\n    -------\n    joint : np.ndarray\n        The joint histogram of the two PETH signals (n_time, n_time).\n    expected : np.ndarray\n        The expected histogram of the two PETH signals (n_time, n_time).\n    difference : np.ndarray\n        The difference between the joint and expected histograms of the two PETH signals (n_time, n_time).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.peri_event import joint_peth, peth_matrix, joint_peth\n    &gt;&gt;&gt; from neuro_py.spikes.spike_tools import get_spindices\n    &gt;&gt;&gt; from neuro_py.io import loading\n\n    &gt;&gt;&gt; # load ripples, delta waves, and PFC pyramidal cell spikes from basepath\n\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\HMC1\\\\day8\"\n\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; delta_waves = loading.load_events(basepath, epoch_name=\"deltaWaves\")\n    &gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"PFC\",putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # flatten spikes (nelpy has .flatten(), but get_spindices is much faster)\n    &gt;&gt;&gt; spikes = get_spindices(st.data)\n\n    &gt;&gt;&gt; # create peri-event time histograms (PETHs) for the three signals\n    &gt;&gt;&gt; window=[-1,1]\n    &gt;&gt;&gt; labels = [\"spikes\", \"ripple\", \"delta\"]\n    &gt;&gt;&gt; peth_1,ts = peth_matrix(spikes.spike_times.values, delta_waves.starts, bin_width=0.02, n_bins=101)\n    &gt;&gt;&gt; peth_2,ts = peth_matrix(ripples.starts, delta_waves.starts, bin_width=0.02, n_bins=101)\n\n    &gt;&gt;&gt; # calculate the joint, expected, and difference histograms\n    &gt;&gt;&gt; joint, expected, difference = joint_peth(peth_1.T, peth_2.T, smooth_std=2)\n\n    Notes\n    -----\n    Note: sometimes the difference between \"joint\" and \"expected\" may be dominated due to\n    brain state effects (e.g. if both ripples are spindles are more common around delta\n    waves taking place in early SWS and have decreased rates around delta waves in late\n    SWS, then all the values of \"joint\" would be larger than the value of \"expected\".\n    In such a case, to investigate the timing effects in particular and ignore such\n    global changes (correlations across the rows of \"PETH1\" and \"PETH2\"), consider\n    normalizing the rows of the PETHs before calling joint_peth.\n\n    See Sirota et al. (2003)\n\n    Adapted from JointPETH.m, Copyright (C) 2018-2022 by Ralitsa Todorova\n    \"\"\"\n    from scipy.ndimage import gaussian_filter\n\n    # make inputs np.ndarrays\n    peth_1 = np.array(peth_1)\n    peth_2 = np.array(peth_2)\n\n    # calculate the joint histogram\n    joint = peth_1.T @ peth_2\n\n    # smooth the 2d joint histogram\n    joint = gaussian_filter(joint, smooth_std)\n\n    # calculate the expected histogram\n    expected = np.tile(np.nanmean(peth_1, axis=0), [peth_1.shape[0], 1]).T @ np.tile(\n        np.nanmean(peth_2, axis=0), [peth_2.shape[0], 1]\n    )\n\n    # smooth the 2d expected histogram\n    expected = gaussian_filter(expected, smooth_std)\n\n    # normalize the joint and expected histograms\n    joint = joint / peth_1.shape[0]\n    expected = expected / peth_1.shape[0]\n\n    # square root the joint and expected histograms so result is Hz\n    joint = np.sqrt(joint)\n    expected = np.sqrt(expected)\n\n    # calculate the difference between the joint and expected histograms\n    difference = joint - expected\n\n    return joint, expected, difference\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.load_results","title":"<code>load_results(save_path, verbose=False, add_save_file_name=False, format_type=None)</code>","text":"<p>Load results from pickled pandas DataFrames or HDF5 files in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str</code> <p>Path to the folder containing pickled results.</p> required <code>verbose</code> <code>bool</code> <p>Whether to print progress for each file. Defaults to False.</p> <code>False</code> <code>add_save_file_name</code> <code>bool</code> <p>Whether to add a column with the name of the save file. Defaults to False.</p> <code>False</code> <code>format_type</code> <code>Optional[Literal['pickle', 'hdf5']]</code> <p>File format to load. If None, will auto-detect based on file extension.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated pandas DataFrame with all results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified folder does not exist or is empty.</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def load_results(\n    save_path: str,\n    verbose: bool = False,\n    add_save_file_name: bool = False,\n    format_type: Optional[Literal[\"pickle\", \"hdf5\"]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Load results from pickled pandas DataFrames or HDF5 files in the specified directory.\n\n    Parameters\n    ----------\n    save_path : str\n        Path to the folder containing pickled results.\n    verbose : bool, optional\n        Whether to print progress for each file. Defaults to False.\n    add_save_file_name : bool, optional\n        Whether to add a column with the name of the save file. Defaults to False.\n    format_type : Optional[Literal[\"pickle\", \"hdf5\"]], optional\n        File format to load. If None, will auto-detect based on file extension.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated pandas DataFrame with all results.\n\n    Raises\n    ------\n    ValueError\n        If the specified folder does not exist or is empty.\n    \"\"\"\n\n    if not os.path.exists(save_path):\n        raise ValueError(f\"folder {save_path} does not exist\")\n\n    # Determine file pattern based on format_type\n    if format_type == \"pickle\":\n        file_pattern = \"*.pkl\"\n    elif format_type == \"hdf5\":\n        file_pattern = \"*.h5\"\n    else:\n        # Auto-detect: look for both formats\n        file_pattern = \"*\"\n\n    sessions = glob.glob(os.path.join(save_path, file_pattern))\n\n    # Filter by supported extensions if auto-detecting\n    if format_type is None:\n        sessions = [s for s in sessions if s.endswith((\".pkl\", \".h5\"))]\n\n    # Sort sessions for consistent ordering\n    sessions.sort()\n\n    results = []\n\n    for session in sessions:\n        if verbose:\n            print(session)\n\n        # Determine format based on file extension\n        if session.endswith(\".h5\"):\n            try:\n                results_ = _load_from_hdf5(session)\n            except Exception as e:\n                print(f\"Error loading HDF5 file {session}: {e}\")\n                continue\n        else:\n            try:\n                with open(session, \"rb\") as f:\n                    results_ = pickle.load(f)\n            except Exception as e:\n                print(f\"Error loading pickle file {session}: {e}\")\n                continue\n\n        if results_ is None:\n            continue\n\n        # Convert to DataFrame if it's a dict containing a single DataFrame\n        if (\n            isinstance(results_, dict)\n            and len(results_) == 1\n            and isinstance(list(results_.values())[0], pd.DataFrame)\n        ):\n            results_ = list(results_.values())[0]\n        elif (\n            isinstance(results_, dict)\n            and \"dataframe\" in results_\n            and isinstance(results_[\"dataframe\"], pd.DataFrame)\n        ):\n            results_ = results_[\"dataframe\"]\n\n        # Ensure we have a DataFrame\n        if not isinstance(results_, pd.DataFrame):\n            if verbose:\n                print(f\"Skipping {session}: not a DataFrame\")\n            continue\n\n        if add_save_file_name:\n            results_[\"save_file_name\"] = os.path.basename(session)\n\n        results.append(results_)\n\n    if not results:\n        raise ValueError(f\"No valid results found in {save_path}\")\n\n    results = pd.concat(results, ignore_index=True, axis=0)\n\n    return results\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtcoherencept","title":"<code>mtcoherencept(data1, data2, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper coherence for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>data1</code> <code>ndarray</code> <p>Array of spike times for the first signal (in seconds).</p> required <code>data2</code> <code>ndarray</code> <p>Array of spike times for the second signal (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product, by default 2.5.</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers, by default 4.</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate, by default None.</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series, by default None.</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Coherence between the two point processes.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtcoherencept(\n    data1: np.ndarray,\n    data2: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper coherence for point processes.\n\n    Parameters\n    ----------\n    data1 : np.ndarray\n        Array of spike times for the first signal (in seconds).\n    data2 : np.ndarray\n        Array of spike times for the second signal (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    NW : Union[int, float], optional\n        Time-bandwidth product, by default 2.5.\n    n_tapers : int, optional\n        Number of tapers, by default 4.\n    time_support : Union[list, None], optional\n        Time range to evaluate, by default None.\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series, by default None.\n    nfft : Optional[int], optional\n        Number of points for FFT, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        Coherence between the two point processes.\n    \"\"\"\n    # Check if data is a single unit and put in array\n    if isinstance(data1, np.ndarray):\n        data1 = np.array([data1])\n    if isinstance(data2, np.ndarray):\n        data2 = np.array([data2])\n\n    # Compute power spectral densities (PSD) for both spike trains\n    psd1 = mtspectrumpt(\n        data1, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n    psd2 = mtspectrumpt(\n        data2, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n\n    # Compute cross-spectral density (CSD) between the two spike trains\n    csd = mtcsdpt(\n        data1, data2, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n\n    # Calculate coherence: |Sxy(f)|^2 / (Sxx(f) * Syy(f))\n    coherence = np.abs(csd[\"CSD\"].values) ** 2 / (psd1.values * psd2.values).flatten()\n\n    # Return coherence as a pandas DataFrame\n    coherence_df = pd.DataFrame(index=csd.index, data=coherence, columns=[\"Coherence\"])\n    return coherence_df\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtcsdpt","title":"<code>mtcsdpt(data1, data2, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper cross-spectral density (CSD) for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>data1</code> <code>ndarray</code> <p>Array of spike times for the first signal (in seconds).</p> required <code>data2</code> <code>ndarray</code> <p>Array of spike times for the second signal (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product, by default 2.5.</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers, by default 4.</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate, by default None.</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series, by default None.</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Cross-spectral density between the two point processes.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtcsdpt(\n    data1: np.ndarray,\n    data2: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper cross-spectral density (CSD) for point processes.\n\n    Parameters\n    ----------\n    data1 : np.ndarray\n        Array of spike times for the first signal (in seconds).\n    data2 : np.ndarray\n        Array of spike times for the second signal (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    NW : Union[int, float], optional\n        Time-bandwidth product, by default 2.5.\n    n_tapers : int, optional\n        Number of tapers, by default 4.\n    time_support : Union[list, None], optional\n        Time range to evaluate, by default None.\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series, by default None.\n    nfft : Optional[int], optional\n        Number of points for FFT, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        Cross-spectral density between the two point processes.\n    \"\"\"\n    if time_support is not None:\n        mintime, maxtime = time_support\n    else:\n        mintime = min(np.min(data1), np.min(data2))\n        maxtime = max(np.max(data1), np.max(data2))\n    dt = 1 / Fs\n\n    # Create tapers if not provided\n    if tapers is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n        N = len(tapers_ts)\n        tapers, eigens = dpss(N, NW, n_tapers, return_ratios=True)\n\n    tapers = tapers.T\n    N = len(tapers_ts)\n\n    # Number of points in FFT\n    if nfft is None:\n        nfft = np.max([int(2 ** np.ceil(np.log2(N))), N])\n    f, findx = getfgrid(Fs, nfft, fpass)\n\n    # Compute the multitaper Fourier transforms of both spike trains\n    J1, Msp1, Nsp1 = mtfftpt(data1, tapers, nfft, tapers_ts, f, findx)\n    J2, Msp2, Nsp2 = mtfftpt(data2, tapers, nfft, tapers_ts, f, findx)\n\n    # Cross-spectral density: Sxy = mean(conjugate(J1) * J2)\n    csd = np.real(np.mean(np.conj(J1) * J2, axis=1))\n\n    csd_df = pd.DataFrame(index=f, data=csd, columns=[\"CSD\"])\n    return csd_df\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtfftc","title":"<code>mtfftc(data, tapers, nfft, Fs)</code>","text":"<p>Multi-taper Fourier Transform - Continuous Data (Single Signal)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of data (samples).</p> required <code>tapers</code> <code>ndarray</code> <p>Precomputed DPSS tapers with shape (samples, tapers).</p> required <code>nfft</code> <code>int</code> <p>Length of padded data for FFT.</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <p>Returns:</p> Name Type Description <code>J</code> <code>ndarray</code> <p>FFT in the form (nfft, K), where K is the number of tapers.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtfftc(data: np.ndarray, tapers: np.ndarray, nfft: int, Fs: int) -&gt; np.ndarray:\n    \"\"\"\n    Multi-taper Fourier Transform - Continuous Data (Single Signal)\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of data (samples).\n    tapers : np.ndarray\n        Precomputed DPSS tapers with shape (samples, tapers).\n    nfft : int\n        Length of padded data for FFT.\n    Fs : int\n        Sampling frequency.\n\n    Returns\n    -------\n    J : np.ndarray\n        FFT in the form (nfft, K), where K is the number of tapers.\n    \"\"\"\n    # Ensure data is 1D\n    if data.ndim != 1:\n        raise ValueError(\"Input data must be a 1D array.\")\n\n    NC = data.shape[0]  # Number of samples in data\n    NK, K = tapers.shape  # Number of samples and tapers\n\n    if NK != NC:\n        raise ValueError(\"Length of tapers is incompatible with length of data.\")\n\n    # Project data onto tapers\n    data_proj = data[:, np.newaxis] * tapers  # Shape: (samples, tapers)\n\n    # Compute FFT for each taper\n    J = np.fft.fft(data_proj, n=nfft, axis=0) / Fs  # Shape: (nfft, K)\n\n    return J\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtfftpt","title":"<code>mtfftpt(data, tapers, nfft, t, f, findx)</code>","text":"<p>Multitaper FFT for point process times.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of spike times (in seconds).</p> required <code>tapers</code> <code>ndarray</code> <p>Tapers from the DPSS method.</p> required <code>nfft</code> <code>int</code> <p>Number of points for FFT.</p> required <code>t</code> <code>ndarray</code> <p>Time vector.</p> required <code>f</code> <code>ndarray</code> <p>Frequency vector.</p> required <code>findx</code> <code>list of bool</code> <p>Frequency index.</p> required <p>Returns:</p> Name Type Description <code>J</code> <code>ndarray</code> <p>FFT of the data.</p> <code>Msp</code> <code>float</code> <p>Mean spikes per time.</p> <code>Nsp</code> <code>float</code> <p>Total number of spikes in data.</p> Notes <p>The function computes the multitaper FFT of spike times using the specified tapers and returns the FFT result, mean spikes, and total spike count.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtfftpt(\n    data: np.ndarray,\n    tapers: np.ndarray,\n    nfft: int,\n    t: np.ndarray,\n    f: np.ndarray,\n    findx: List[bool],\n) -&gt; Tuple[np.ndarray, float, float]:\n    \"\"\"\n    Multitaper FFT for point process times.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of spike times (in seconds).\n    tapers : np.ndarray\n        Tapers from the DPSS method.\n    nfft : int\n        Number of points for FFT.\n    t : np.ndarray\n        Time vector.\n    f : np.ndarray\n        Frequency vector.\n    findx : list of bool\n        Frequency index.\n\n    Returns\n    -------\n    J : np.ndarray\n        FFT of the data.\n    Msp : float\n        Mean spikes per time.\n    Nsp : float\n        Total number of spikes in data.\n\n    Notes\n    -----\n    The function computes the multitaper FFT of spike times using\n    the specified tapers and returns the FFT result, mean spikes,\n    and total spike count.\n    \"\"\"\n    K = tapers.shape[1]\n    nfreq = len(f)\n\n    # get the FFT of the tapers\n    H = np.zeros((nfft, K), dtype=np.complex128)\n    for i in np.arange(K):\n        H[:, i] = np.fft.fft(tapers[:, i], nfft, axis=0)\n\n    H = H[findx, :]\n    w = 2 * np.pi * f\n    dtmp = data\n    indx = np.logical_and(dtmp &gt;= np.min(t), dtmp &lt;= np.max(t))\n    if len(indx):\n        dtmp = dtmp[indx]\n    Nsp = len(dtmp)\n\n    # get the mean spike rate\n    Msp = Nsp / len(t)\n\n    if Msp != 0:\n        # Interpolate spike times for each taper\n        data_proj = np.empty((len(dtmp), K))\n        for i in range(K):\n            data_proj[:, i] = np.interp(dtmp, t, tapers[:, i])\n\n        def compute_J(k):\n            J_k = np.zeros(nfreq, dtype=np.complex128)\n            for i, freq in enumerate(w):\n                phase = -1j * freq * (dtmp - t[0])\n                J_k[i] = np.sum(np.exp(phase) * data_proj[:, k])\n            return J_k\n\n        J = np.array(Parallel(n_jobs=-1)(delayed(compute_J)(k) for k in range(K))).T\n\n        J -= H * Msp\n    else:\n        # No spikes: return zeros\n        J = np.zeros((nfreq, K), dtype=np.complex128)\n\n    return J, Msp, Nsp\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtspectrumc","title":"<code>mtspectrumc(data, Fs, fpass, tapers)</code>","text":"<p>Compute the multitaper power spectrum for continuous data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of continuous data (e.g., LFP).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency in Hz.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>tapers</code> <code>ndarray</code> <p>Tapers array with shape [NW, K] or [tapers, eigenvalues].</p> required <p>Returns:</p> Name Type Description <code>S</code> <code>Series</code> <p>Power spectrum with frequencies as the index.</p> Notes <p>This function utilizes the multitaper method for spectral estimation and returns the power spectrum as a pandas Series.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtspectrumc(\n    data: np.ndarray, Fs: int, fpass: list, tapers: np.ndarray\n) -&gt; pd.Series:\n    \"\"\"\n    Compute the multitaper power spectrum for continuous data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of continuous data (e.g., LFP).\n    Fs : int\n        Sampling frequency in Hz.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    tapers : np.ndarray\n        Tapers array with shape [NW, K] or [tapers, eigenvalues].\n\n    Returns\n    -------\n    S : pd.Series\n        Power spectrum with frequencies as the index.\n\n    Notes\n    -----\n    This function utilizes the multitaper method for spectral estimation\n    and returns the power spectrum as a pandas Series.\n    \"\"\"\n    N = len(data)\n    nfft = np.max(\n        [int(2 ** np.ceil(np.log2(N))), N]\n    )  # number of points in fft of prolates\n    # get the frequency grid\n    f, findx = getfgrid(Fs, nfft, fpass)\n    # get the fft of the tapers\n    tapers = dpsschk(tapers, N, Fs)\n    # get the fft of the data\n    J = mtfftc(data, tapers, nfft, Fs)\n    # restrict fft of tapers to required frequencies\n    J = J[findx, :]\n    # get the power spectrum\n    S = np.real(np.mean(np.conj(J) * J, 1))\n    # return the power spectrum\n    return pd.Series(index=f, data=S)\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.mtspectrumpt","title":"<code>mtspectrumpt(data, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper power spectrum estimation for point process data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of spike times (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list of float</code> <p>Frequency range to evaluate.</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product (default is 2.5).</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers (default is 4).</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate (default is None).</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues] (default is None).</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series (default is None).</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT (default is None).</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the power spectrum.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spec = pychronux.mtspectrumpt(\n&gt;&gt;&gt;    st.data,\n&gt;&gt;&gt;    100,\n&gt;&gt;&gt;    [1, 20],\n&gt;&gt;&gt;    NW=3,\n&gt;&gt;&gt;    n_tapers=5,\n&gt;&gt;&gt;    time_support=[st.support.start, st.support.stop],\n&gt;&gt;&gt;    nfft=500,\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtspectrumpt(\n    data: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper power spectrum estimation for point process data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Array of spike times (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list of float\n        Frequency range to evaluate.\n    NW : Union[int, float], optional\n        Time-bandwidth product (default is 2.5).\n    n_tapers : int, optional\n        Number of tapers (default is 4).\n    time_support : Union[list, None], optional\n        Time range to evaluate (default is None).\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues] (default is None).\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series (default is None).\n    nfft : Optional[int], optional\n        Number of points for FFT (default is None).\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the power spectrum.\n\n\n    Examples\n    -------\n    &gt;&gt;&gt; spec = pychronux.mtspectrumpt(\n    &gt;&gt;&gt;    st.data,\n    &gt;&gt;&gt;    100,\n    &gt;&gt;&gt;    [1, 20],\n    &gt;&gt;&gt;    NW=3,\n    &gt;&gt;&gt;    n_tapers=5,\n    &gt;&gt;&gt;    time_support=[st.support.start, st.support.stop],\n    &gt;&gt;&gt;    nfft=500,\n    &gt;&gt;&gt; )\n    \"\"\"\n\n    # check data\n    if len(data) == 0:\n        return pd.DataFrame()\n\n    # check frequency range\n    if fpass[0] &gt; fpass[1]:\n        raise ValueError(\n            \"Invalid frequency range: fpass[0] should be less than fpass[1].\"\n        )\n\n    if time_support is not None:\n        mintime, maxtime = time_support\n    else:\n        if data.dtype == np.object_:\n            mintime = np.min(np.concatenate(data))\n            maxtime = np.max(np.concatenate(data))\n        else:\n            mintime = np.min(data)\n            maxtime = np.max(data)\n\n    dt = 1 / Fs\n\n    if tapers is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n        N = len(tapers_ts)\n        tapers, eigens = dpss(N, NW, n_tapers, return_ratios=True)\n        tapers = tapers.T\n\n    if tapers_ts is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n\n    N = len(tapers_ts)\n    # number of points in fft of prolates\n    if nfft is None:\n        nfft = np.max([int(2 ** np.ceil(np.log2(N))), N])\n    f, findx = getfgrid(Fs, nfft, fpass)\n\n    spec = np.zeros((len(f), len(data)))\n    for i, d in enumerate(data):\n        J, _, _ = mtfftpt(d, tapers, nfft, tapers_ts, f, findx)\n        spec[:, i] = np.real(np.mean(np.conj(J) * J, 1))\n\n    spectrum_df = pd.DataFrame(index=f, columns=np.arange(len(data)), dtype=np.float64)\n    spectrum_df[:] = spec\n    return spectrum_df\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.nearest_event_delay","title":"<code>nearest_event_delay(ts_1, ts_2)</code>","text":"<p>Return for each timestamp in ts_1 the nearest timestamp in ts_2 and the delay between the two.</p> <p>Parameters:</p> Name Type Description Default <code>ts_1</code> <code>ndarray</code> <p>1D array of timestamps.</p> required <code>ts_2</code> <code>ndarray</code> <p>1D array of timestamps (must be monotonically increasing).</p> required <p>Returns:</p> Name Type Description <code>nearest_ts</code> <code>ndarray</code> <p>Nearest timestamps in ts_2 for each timestamp in ts_1.</p> <code>delays</code> <code>ndarray</code> <p>Delays between ts_1 and nearest_ts.</p> <code>nearest_index</code> <code>ndarray</code> <p>Index of nearest_ts in ts_2.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If ts_1 or ts_2 are empty or not monotonically increasing.</p> Notes <p>Both ts_1 and ts_2 must be monotonically increasing arrays of timestamps.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def nearest_event_delay(\n    ts_1: np.ndarray, ts_2: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Return for each timestamp in ts_1 the nearest timestamp in ts_2 and the delay between the two.\n\n    Parameters\n    ----------\n    ts_1 : np.ndarray\n        1D array of timestamps.\n    ts_2 : np.ndarray\n        1D array of timestamps (must be monotonically increasing).\n\n    Returns\n    -------\n    nearest_ts : np.ndarray\n        Nearest timestamps in ts_2 for each timestamp in ts_1.\n    delays : np.ndarray\n        Delays between ts_1 and nearest_ts.\n    nearest_index : np.ndarray\n        Index of nearest_ts in ts_2.\n\n    Raises\n    ------\n    ValueError\n        If ts_1 or ts_2 are empty or not monotonically increasing.\n\n    Notes\n    -----\n    Both ts_1 and ts_2 must be monotonically increasing arrays of timestamps.\n    \"\"\"\n    ts_1, ts_2 = np.array(ts_1), np.array(ts_2)\n\n    if not np.all(np.diff(ts_2) &gt; 0):\n        raise ValueError(\"ts_2 must be monotonically increasing\")\n\n    if not np.all(np.diff(ts_1) &gt; 0):\n        raise ValueError(\"ts_1 must be monotonically increasing\")\n    # check if empty\n    if len(ts_1) == 0:\n        raise ValueError(\"ts_1 is empty\")\n    if len(ts_2) == 0:\n        raise ValueError(\"ts_2 is empty\")\n\n    # Use searchsorted to find the indices where elements of ts_1 should be inserted\n    nearest_indices = np.searchsorted(ts_2, ts_1, side=\"left\")\n\n    # Calculate indices for the elements before and after the insertion points\n    before = np.maximum(nearest_indices - 1, 0)\n    after = np.minimum(nearest_indices, len(ts_2) - 1)\n\n    # Determine the nearest timestamp for each element in ts_1\n    nearest_ts = np.where(\n        np.abs(ts_1 - ts_2[before]) &lt; np.abs(ts_1 - ts_2[after]),\n        ts_2[before],\n        ts_2[after],\n    )\n\n    # Calculate delays between ts_1 and nearest_ts\n    delays = ts_1 - nearest_ts\n\n    # Find the nearest_index using the absolute difference\n    absolute_diff_before = np.abs(ts_1 - ts_2[before])\n    absolute_diff_after = np.abs(ts_1 - ts_2[after])\n    nearest_index = np.where(absolute_diff_before &lt; absolute_diff_after, before, after)\n\n    return nearest_ts, delays, nearest_index\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.nonspatial_phase_precession","title":"<code>nonspatial_phase_precession(unwrapped_spike_phases, width=4 * 2 * np.pi, bin_width=np.pi / 3, cut_peak=True, norm=True, psd_lims=[0.65, 1.55], upsample=4, smooth_sigma=1)</code>","text":"<p>Compute the nonspatial spike-LFP relationship modulation index.</p> <p>Parameters:</p> Name Type Description Default <code>unwrapped_spike_phases</code> <code>ndarray</code> <p>1D array of spike phases that have been linearly unwrapped.</p> required <code>width</code> <code>float</code> <p>Time window for ACF in cycles (default = 4 cycles).</p> <code>4 * 2 * pi</code> <code>bin_width</code> <code>float</code> <p>Width of bins in radians (default = pi/3 radians).</p> <code>pi / 3</code> <code>cut_peak</code> <code>bool</code> <p>Whether or not the largest central peak should be replaced for subsequent fitting.</p> <code>True</code> <code>norm</code> <code>bool</code> <p>To normalize the ACF or not.</p> <code>True</code> <code>psd_lims</code> <code>List[float]</code> <p>Limits of the PSD to consider for peak finding (default = [0.65, 1.55]).</p> <code>[0.65, 1.55]</code> <code>upsample</code> <code>int</code> <p>Upsampling factor (default = 4).</p> <code>4</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian smoothing of the PSD (default = 1).</p> <code>1</code> <p>Returns:</p> Name Type Description <code>max_freq</code> <code>float</code> <p>Relative spike-LFP frequency of the PSD peak.</p> <code>MI</code> <code>float</code> <p>Modulation index of non-spatial phase relationship.</p> <code>psd</code> <code>ndarray</code> <p>Power spectral density of interest.</p> <code>frequencies</code> <code>ndarray</code> <p>Frequencies corresponding to the PSD.</p> <code>acf</code> <code>ndarray</code> <p>Autocorrelation function.</p> Notes <p>The modulation index (MI) is computed based on the maximum peak of the power spectral density (PSD) within specified frequency limits.</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def nonspatial_phase_precession(\n    unwrapped_spike_phases: np.ndarray,\n    width: float = 4 * 2 * np.pi,\n    bin_width: float = np.pi / 3,\n    cut_peak: bool = True,\n    norm: bool = True,\n    psd_lims: List[float] = [0.65, 1.55],\n    upsample: int = 4,\n    smooth_sigma: float = 1,\n) -&gt; Tuple[float, float, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute the nonspatial spike-LFP relationship modulation index.\n\n    Parameters\n    ----------\n    unwrapped_spike_phases : np.ndarray\n        1D array of spike phases that have been linearly unwrapped.\n    width : float\n        Time window for ACF in cycles (default = 4 cycles).\n    bin_width : float\n        Width of bins in radians (default = pi/3 radians).\n    cut_peak : bool\n        Whether or not the largest central peak should be replaced for subsequent fitting.\n    norm : bool\n        To normalize the ACF or not.\n    psd_lims : List[float]\n        Limits of the PSD to consider for peak finding (default = [0.65, 1.55]).\n    upsample : int\n        Upsampling factor (default = 4).\n    smooth_sigma : float\n        Standard deviation for Gaussian smoothing of the PSD (default = 1).\n\n    Returns\n    -------\n    max_freq : float\n        Relative spike-LFP frequency of the PSD peak.\n    MI : float\n        Modulation index of non-spatial phase relationship.\n    psd : np.ndarray\n        Power spectral density of interest.\n    frequencies : np.ndarray\n        Frequencies corresponding to the PSD.\n    acf : np.ndarray\n        Autocorrelation function.\n\n    Notes\n    -----\n    The modulation index (MI) is computed based on the maximum peak of the power\n    spectral density (PSD) within specified frequency limits.\n    \"\"\"\n\n    frequencies = (\n        (np.arange(2 * (width // bin_width) - 1))\n        * (2 * np.pi)\n        / (2 * width - bin_width)\n    )\n\n    frequencies = np.interp(\n        np.arange(0, len(frequencies), 1 / upsample),\n        np.arange(0, len(frequencies)),\n        frequencies,\n    )\n\n    freqs_of_interest = np.intersect1d(\n        np.where(frequencies &gt; psd_lims[0]), np.where(frequencies &lt; psd_lims[1])\n    )\n\n    acf, _ = fast_acf(unwrapped_spike_phases, width, bin_width, cut_peak=cut_peak)\n    psd = acf_power(acf, norm=norm)\n\n    # upsample 2x psd\n    psd = np.interp(np.arange(0, len(psd), 1 / upsample), np.arange(0, len(psd)), psd)\n    # smooth psd with gaussian filter\n    psd = gaussian_filter1d(psd, smooth_sigma)\n\n    # FIND ALL LOCAL MAXIMA IN WINDOW OF INTEREST\n    all_peaks = find_peaks(psd[freqs_of_interest], None)[0]\n\n    # make sure there is a peak\n    if ~np.any(all_peaks):\n        return (\n            np.nan,\n            np.nan,\n            psd[freqs_of_interest],\n            frequencies[freqs_of_interest],\n            acf,\n        )\n\n    max_peak = np.max(psd[freqs_of_interest][all_peaks])\n    max_idx = [all_peaks[np.argmax(psd[freqs_of_interest][all_peaks])]]\n    max_freq = frequencies[freqs_of_interest][max_idx]\n    MI = max_peak / np.trapezoid(psd[freqs_of_interest])\n\n    return max_freq, MI, psd[freqs_of_interest], frequencies[freqs_of_interest], acf\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.overlap_intersect","title":"<code>overlap_intersect(epoch, interval, return_indices=True)</code>","text":"<p>Returns the epochs with overlap with the given interval.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epochs to check.</p> required <code>interval</code> <code>IntervalArray</code> <p>The interval to check for overlap.</p> required <code>return_indices</code> <code>bool</code> <p>If True, returns the indices of the overlapping epochs. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>The epochs with overlap with the interval.</p> <code>(Tuple[EpochArray, ndarray], optional)</code> <p>If <code>return_indices</code> is True, also returns the indices of the overlapping epochs.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def overlap_intersect(\n    epoch: nel.EpochArray, interval: nel.IntervalArray, return_indices: bool = True\n) -&gt; Union[nel.EpochArray, Tuple[nel.EpochArray, np.ndarray]]:\n    \"\"\"\n    Returns the epochs with overlap with the given interval.\n\n    Parameters\n    ----------\n    epoch : nelpy.EpochArray\n        The epochs to check.\n    interval : nelpy.IntervalArray\n        The interval to check for overlap.\n    return_indices : bool, optional\n        If True, returns the indices of the overlapping epochs. Default is True.\n\n    Returns\n    -------\n    nelpy.EpochArray\n        The epochs with overlap with the interval.\n    Tuple[nelpy.EpochArray, np.ndarray], optional\n        If `return_indices` is True, also returns the indices of the overlapping epochs.\n    \"\"\"\n    new_intervals = []\n    indices = []\n    for epa in epoch:\n        if any((interval.starts &lt; epa.stop) &amp; (interval.stops &gt; epa.start)):\n            new_intervals.append([epa.start, epa.stop])\n            cand_ep_idx = np.where(\n                (interval.starts &lt; epa.stop) &amp; (interval.stops &gt; epa.start)\n            )\n            indices.append(cand_ep_idx[0][0])\n    out = type(epoch)(new_intervals)\n    out._domain = epoch.domain\n    if return_indices:\n        return out, indices\n    return out\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.pairwise_corr","title":"<code>pairwise_corr(X, method='pearson', pairs=None)</code>","text":"<p>Compute pairwise correlations between all rows of a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>2D numpy array of shape (n, p), where n is the number of rows (variables) and p is the number of columns (features).</p> required <code>method</code> <code>str</code> <p>Correlation method to use ('pearson', 'spearman', or 'kendall'), by default \"pearson\".</p> <code>'pearson'</code> <code>pairs</code> <code>ndarray</code> <p>Array of shape (m, 2) specifying the pairs of rows to compute correlations between. If None, computes correlations for all unique row pairs.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>ndarray</code> <p>Array of correlation coefficients.</p> <code>pval</code> <code>ndarray</code> <p>Array of p-values for the correlation tests.</p> <code>pairs</code> <code>ndarray</code> <p>Array of pairs (indices) for which correlations were computed.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is not 'pearson', 'spearman', or 'kendall'.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 5)\n&gt;&gt;&gt; rho, pval, pairs = pairwise_corr(X, method=\"spearman\")\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_corr(\n    X: np.ndarray, method: str = \"pearson\", pairs: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute pairwise correlations between all rows of a matrix.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        2D numpy array of shape (n, p), where n is the number of rows (variables) and p is the number of columns (features).\n    method : str, optional\n        Correlation method to use ('pearson', 'spearman', or 'kendall'), by default \"pearson\".\n    pairs : np.ndarray, optional\n        Array of shape (m, 2) specifying the pairs of rows to compute correlations between.\n        If None, computes correlations for all unique row pairs.\n\n    Returns\n    -------\n    rho : np.ndarray\n        Array of correlation coefficients.\n    pval : np.ndarray\n        Array of p-values for the correlation tests.\n    pairs : np.ndarray\n        Array of pairs (indices) for which correlations were computed.\n\n    Raises\n    ------\n    ValueError\n        If the method is not 'pearson', 'spearman', or 'kendall'.\n\n    Examples\n    -------\n    &gt;&gt;&gt; X = np.random.rand(10, 5)\n    &gt;&gt;&gt; rho, pval, pairs = pairwise_corr(X, method=\"spearman\")\n    \"\"\"\n    if pairs is None:\n        x = np.arange(0, X.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    rho = []\n    pval = []\n    for i, s in enumerate(pairs):\n        if method == \"pearson\":\n            rho_, pval_ = stats.pearsonr(X[s[0], :], X[s[1], :])\n        elif method == \"spearman\":\n            rho_, pval_ = stats.spearmanr(X[s[0], :], X[s[1], :])\n        elif method == \"kendall\":\n            rho_, pval_ = stats.kendalltau(X[s[0], :], X[s[1], :])\n        else:\n            raise ValueError(\"method must be pearson, spearman or kendall\")\n        rho.append(rho_)\n        pval.append(pval_)\n    return rho, pval, pairs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.pairwise_cross_corr","title":"<code>pairwise_cross_corr(spks, binsize=0.001, nbins=100, return_index=False, pairs=None, deconvolve=False)</code>","text":"<p>Compute pairwise time-lagged cross-correlations between spike trains of different cells.</p> <p>Parameters:</p> Name Type Description Default <code>spks</code> <code>ndarray</code> <p>Nested numpy arrays, where each array contains the spike times for a cell.</p> required <code>binsize</code> <code>float</code> <p>The size of time bins in seconds. Default is 0.001 (1 ms).</p> <code>0.001</code> <code>nbins</code> <code>int</code> <p>Number of bins to use for the correlation window. Default is 100.</p> <code>100</code> <code>return_index</code> <code>bool</code> <p>Whether to return the index (pairs) of cells used for the correlation. Default is False.</p> <code>False</code> <code>pairs</code> <code>ndarray</code> <p>Precomputed list of pairs of cells (indices) to compute the cross-correlation for. If None, all unique pairs will be computed. Default is None.</p> <code>None</code> <code>deconvolve</code> <code>bool</code> <p>Whether to apply deconvolution when computing the cross-correlation. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>crosscorrs</code> <code>DataFrame</code> <p>A pandas DataFrame of shape (t, n_pairs), where t is the time axis and n_pairs are the pairs of cells.</p> <code>pairs</code> <code>(ndarray, optional)</code> <p>The pairs of cells for which cross-correlations were computed. Returned only if <code>return_index</code> is True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spks = np.array([np.random.rand(100), np.random.rand(100)])\n&gt;&gt;&gt; crosscorrs, pairs = pairwise_cross_corr(spks, binsize=0.01, nbins=50, return_index=True)\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_cross_corr(\n    spks: np.ndarray,\n    binsize: float = 0.001,\n    nbins: int = 100,\n    return_index: bool = False,\n    pairs: Optional[np.ndarray] = None,\n    deconvolve: bool = False,\n) -&gt; Tuple[pd.DataFrame, Optional[np.ndarray]]:\n    \"\"\"\n    Compute pairwise time-lagged cross-correlations between spike trains of different cells.\n\n    Parameters\n    ----------\n    spks : np.ndarray\n        Nested numpy arrays, where each array contains the spike times for a cell.\n    binsize : float, optional\n        The size of time bins in seconds. Default is 0.001 (1 ms).\n    nbins : int, optional\n        Number of bins to use for the correlation window. Default is 100.\n    return_index : bool, optional\n        Whether to return the index (pairs) of cells used for the correlation. Default is False.\n    pairs : np.ndarray, optional\n        Precomputed list of pairs of cells (indices) to compute the cross-correlation for.\n        If None, all unique pairs will be computed. Default is None.\n    deconvolve : bool, optional\n        Whether to apply deconvolution when computing the cross-correlation. Default is False.\n\n    Returns\n    -------\n    crosscorrs : pd.DataFrame\n        A pandas DataFrame of shape (t, n_pairs), where t is the time axis and n_pairs are the pairs of cells.\n    pairs : np.ndarray, optional\n        The pairs of cells for which cross-correlations were computed. Returned only if `return_index` is True.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spks = np.array([np.random.rand(100), np.random.rand(100)])\n    &gt;&gt;&gt; crosscorrs, pairs = pairwise_cross_corr(spks, binsize=0.01, nbins=50, return_index=True)\n    \"\"\"\n    # Get unique combo without repeats\n    if pairs is None:\n        x = np.arange(0, spks.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    # prepare a pandas dataframe to receive the data\n    times = np.linspace(-(nbins * binsize) / 2, (nbins * binsize) / 2, nbins + 1)\n\n    def compute_crosscorr(pair):\n        i, j = pair\n        # Explicitly convert to float64 arrays to ensure proper typing for numba jit\n        spk_i = np.asarray(spks[i], dtype=np.float64)\n        spk_j = np.asarray(spks[j], dtype=np.float64)\n        crosscorr = crossCorr(spk_i, spk_j, binsize, nbins)\n        return crosscorr\n\n    def compute_crosscorr_deconvolve(pair):\n        i, j = pair\n        # Explicitly convert to float64 arrays to ensure proper typing for numba jit\n        spk_i = np.asarray(spks[i], dtype=np.float64)\n        spk_j = np.asarray(spks[j], dtype=np.float64)\n        crosscorr, _ = deconvolve_peth(spk_i, spk_j, binsize, nbins)\n        return crosscorr\n\n    if deconvolve:\n        crosscorrs = [compute_crosscorr_deconvolve(pair) for pair in pairs]\n    else:\n        crosscorrs = [compute_crosscorr(pair) for pair in pairs]\n\n    crosscorrs = pd.DataFrame(\n        index=times,\n        data=np.array(crosscorrs).T,\n        columns=np.arange(len(pairs)),\n    )\n\n    if return_index:\n        return crosscorrs, pairs\n    else:\n        return crosscorrs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.pairwise_event_triggered_cross_correlation","title":"<code>pairwise_event_triggered_cross_correlation(event_times, signals_data, signals_ts, time_lags=None, window=[-0.5, 0.5], bin_width=0.005, pairs=None, n_jobs=-1)</code>","text":"<p>Computes event-triggered cross-correlation for all unique signal pairs.</p> <p>Parameters:</p> Name Type Description Default <code>event_times</code> <code>ndarray</code> <p>Array of event times.</p> required <code>signals_data</code> <code>ndarray</code> <p>2D array (n_signals, n_samples) of signal data.</p> required <code>signals_ts</code> <code>ndarray</code> <p>Array of timestamps for each signal.</p> required <code>time_lags</code> <code>Union[ndarray, None]</code> <p>Array of time lags to compute correlation. If None, computed automatically.</p> <code>None</code> <code>window</code> <code>list</code> <p>Window to compute correlation. Default is [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>bin_width</code> <code>float</code> <p>Bin width to compute correlation. Default is 0.005.</p> <code>0.005</code> <code>pairs</code> <code>Optional[ndarray]</code> <p>Array of shape (n_pairs, 2) specifying pairs of signals to compute correlations for. If None, computes correlations for all unique signal pairs.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>correlation_lags</code> <code>ndarray</code> <p>Array of time lags.</p> <code>avg_correlation</code> <code>ndarray</code> <p>Array of shape (n_pairs, n_lags) with average correlation for each pair.</p> <code>pairs</code> <code>ndarray</code> <p>Array of shape (n_pairs, 2) with indices of signal pairs.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_event_triggered_cross_correlation(\n    event_times: np.ndarray,\n    signals_data: np.ndarray,\n    signals_ts: np.ndarray,\n    time_lags: Union[np.ndarray, None] = None,\n    window: list = [-0.5, 0.5],\n    bin_width: float = 0.005,\n    pairs: Optional[np.ndarray] = None,\n    n_jobs: int = -1,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes event-triggered cross-correlation for all unique signal pairs.\n\n    Parameters\n    ----------\n    event_times : np.ndarray\n        Array of event times.\n    signals_data : np.ndarray\n        2D array (n_signals, n_samples) of signal data.\n    signals_ts : np.ndarray\n        Array of timestamps for each signal.\n    time_lags : Union[np.ndarray, None], optional\n        Array of time lags to compute correlation. If None, computed automatically.\n    window : list, optional\n        Window to compute correlation. Default is [-0.5, 0.5].\n    bin_width : float, optional\n        Bin width to compute correlation. Default is 0.005.\n    pairs : Optional[np.ndarray], optional\n        Array of shape (n_pairs, 2) specifying pairs of signals to compute correlations for.\n        If None, computes correlations for all unique signal pairs.\n\n    Returns\n    -------\n    correlation_lags : np.ndarray\n        Array of time lags.\n    avg_correlation : np.ndarray\n        Array of shape (n_pairs, n_lags) with average correlation for each pair.\n    pairs : np.ndarray\n        Array of shape (n_pairs, 2) with indices of signal pairs.\n    \"\"\"\n\n    if pairs is None:\n        n_signals = signals_data.shape[0]\n        pairs = np.array(list(itertools.combinations(np.arange(n_signals), 2)))\n\n    def compute_pair(i, j):\n        lags, corr = event_triggered_cross_correlation(\n            event_times,\n            signals_data[i, :],\n            signals_ts,\n            signals_data[j, :],\n            signals_ts,\n            time_lags=time_lags,\n            window=window,\n            bin_width=bin_width,\n        )\n        return corr\n\n    results = Parallel(n_jobs=n_jobs, prefer=\"processes\")(\n        delayed(compute_pair)(i, j) for i, j in pairs\n    )\n    avg_correlation = np.vstack(results)\n\n    # Calculate lags directly (avoid extra function call)\n    if time_lags is None:\n        time_lags_arr = np.arange(window[0], window[1], bin_width)\n    else:\n        time_lags_arr = time_lags\n    n_lags = len(time_lags_arr)\n    max_lag_samples = n_lags - 1\n    lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n        time_lags_arr[1] - time_lags_arr[0]\n    )\n    lags = lags[(lags &gt;= window[0]) &amp; (lags &lt;= window[1])]\n\n    return lags, avg_correlation, pairs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.pairwise_spatial_corr","title":"<code>pairwise_spatial_corr(X, return_index=False, pairs=None)</code>","text":"<p>Compute pairwise spatial correlations between cells' spatial maps.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A 3D numpy array of shape (n_cells, n_space, n_space) representing the spatial maps of cells.</p> required <code>return_index</code> <code>bool</code> <p>If True, returns the indices of the cell pairs used for the correlation.</p> <code>False</code> <code>pairs</code> <code>ndarray</code> <p>Array of cell pairs for which to compute the correlation. If not provided, all unique pairs are used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>spatial_corr</code> <code>ndarray</code> <p>Array containing the Pearson correlation coefficients for each pair of cells.</p> <code>pairs</code> <code>(ndarray, optional)</code> <p>Array of cell pairs used for the correlation (if return_index is True).</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_spatial_corr(\n    X: np.ndarray, return_index: bool = False, pairs: np.ndarray = None\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Compute pairwise spatial correlations between cells' spatial maps.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A 3D numpy array of shape (n_cells, n_space, n_space) representing the spatial maps of cells.\n    return_index : bool, optional\n        If True, returns the indices of the cell pairs used for the correlation.\n    pairs : np.ndarray, optional\n        Array of cell pairs for which to compute the correlation. If not provided, all unique pairs are used.\n\n    Returns\n    -------\n    spatial_corr : np.ndarray\n        Array containing the Pearson correlation coefficients for each pair of cells.\n    pairs : np.ndarray, optional\n        Array of cell pairs used for the correlation (if return_index is True).\n    \"\"\"\n    # Get unique combo without repeats\n    if pairs is None:\n        x = np.arange(0, X.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    spatial_corr = []\n    # Now we can iterate over spikes\n    for i, s in enumerate(pairs):\n        # Calling the crossCorr function\n        x1 = X[s[0], :, :].flatten()\n        x2 = X[s[1], :, :].flatten()\n        bad_idx = np.isnan(x1) | np.isnan(x2)\n        spatial_corr.append(np.corrcoef(x1[~bad_idx], x2[~bad_idx])[0, 1])\n\n    if return_index:\n        return np.array(spatial_corr), pairs\n    else:\n        return np.array(spatial_corr)\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.peth","title":"<code>peth(data, events, window=None, bin_width=0.002, n_bins=100, average=True)</code>","text":"<p>Compute peri-event time histogram (PETH) for nelpy data objects or numpy arrays.</p> <p>This is a high-level function that handles multiple data types and automatically computes the appropriate PETH based on the input data type. For point process data (spikes/events), it computes firing rates (Hz). For continuous data (analog signals), it computes event-triggered averages.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>nelpy object or np.ndarray</code> <p>Data can be: - AnalogSignalArray: continuous signals - PositionArray: 2D/3D position data (x, y, [z] coordinates) - SpikeTrainArray: spike trains - BinnedSpikeTrainArray: binned spike trains - EventArray: event times - BinnedEventArray: binned events - np.ndarray: array of spike times (object array) or continuous signal</p> required <code>events</code> <code>ndarray</code> <p>1D array of event times to align data to.</p> required <code>window</code> <code>list</code> <p>Time window around events [start, end] in seconds. If None, uses symmetric window based on n_bins and bin_width.</p> <code>None</code> <code>bin_width</code> <code>float</code> <p>Width of time bins in seconds (default 0.002).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>Number of bins (default 100). Ignored if window is specified.</p> <code>100</code> <code>average</code> <code>bool</code> <p>If True (default), returns averaged PETH across all events as DataFrame. If False, returns event-wise PETH matrix and time bins array.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame or Tuple[ndarray, ndarray]</code> <p>If average=True:     DataFrame with time bins as index and each series/signal as columns.     Values are rates (Hz) for point process data or averaged     signal values for continuous data. If average=False:     Tuple of (peth_matrix, time_bins) where:     - peth_matrix: 3D array with shape (n_time_bins, n_signals, n_events)     - time_bins: 1D array of time bin centers</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # With SpikeTrainArray - averaged across events\n&gt;&gt;&gt; st, _ = loading.load_spikes(basepath)\n&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; peth_df = peth(st, ripples.starts, window=[-0.5, 0.5], bin_width=0.01)\n</code></pre> <pre><code>&gt;&gt;&gt; # Get event-wise matrix for detailed analysis\n&gt;&gt;&gt; peth_matrix, time_bins = peth(st, ripples.starts, window=[-0.5, 0.5],\n...                               bin_width=0.01, average=False)\n&gt;&gt;&gt; # peth_matrix.shape: (n_time_bins, n_units, n_events)\n&gt;&gt;&gt; # Can now analyze individual events\n&gt;&gt;&gt; strong_events = peth_matrix.sum(axis=(0,1)) &gt; threshold\n</code></pre> <pre><code>&gt;&gt;&gt; # With AnalogSignalArray\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from nelpy import AnalogSignalArray\n&gt;&gt;&gt; timestamps = np.linspace(0, 5, 100)\n&gt;&gt;&gt; signal = np.vstack([\n...     np.sin(2 * np.pi * timestamps),\n...     np.cos(2 * np.pi * timestamps),\n... ])\n&gt;&gt;&gt; lfp = AnalogSignalArray(timestamps=timestamps, data=signal)\n&gt;&gt;&gt; events = np.array([1.0, 2.0, 3.0])\n&gt;&gt;&gt; peth_df = peth(lfp, events, window=[-0.2, 0.2])\n</code></pre> <pre><code>&gt;&gt;&gt; # Get event-wise continuous data\n&gt;&gt;&gt; lfp_matrix, time_lags = peth(lfp, events, window=[-0.2, 0.2], average=False)\n</code></pre> <pre><code>&gt;&gt;&gt; # With PositionArray\n&gt;&gt;&gt; from nelpy import PositionArray\n&gt;&gt;&gt; x_pos = np.sin(2 * np.pi * timestamps)\n&gt;&gt;&gt; y_pos = np.cos(2 * np.pi * timestamps)\n&gt;&gt;&gt; position = PositionArray(timestamps=timestamps, data=np.vstack([x_pos, y_pos]))\n&gt;&gt;&gt; peth_df = peth(position, events, window=[-0.5, 0.5])\n</code></pre> <pre><code>&gt;&gt;&gt; # With numpy array\n&gt;&gt;&gt; spikes = np.array([spike_train_1, spike_train_2], dtype=object)\n&gt;&gt;&gt; peth_df = peth(spikes, events, window=[-0.5, 0.5])\n</code></pre> Notes <ul> <li>For point process data (spikes/events), uses crossCorr to compute firing rates</li> <li>For continuous data (analog signals), uses event_triggered_average<ul> <li>For continuous data, output resolution follows the signal sampling rate;     <code>bin_width</code> is ignored unless you resample beforehand</li> <li>For numpy/object arrays of spike times, each spike train must be sorted in     ascending order (crossCorr assumes sorted targets)</li> </ul> </li> <li>Returns rates in Hz for point process data</li> <li>Handles both regular and irregularly sampled continuous data</li> </ul> See Also <p>compute_psth : Lower-level PSTH computation for numpy arrays event_triggered_average : Event-triggered averaging for continuous signals crossCorr : Cross-correlogram computation</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def peth(\n    data,\n    events: np.ndarray,\n    window: Union[list, None] = None,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    average: bool = True,\n) -&gt; Union[pd.DataFrame, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Compute peri-event time histogram (PETH) for nelpy data objects or numpy arrays.\n\n    This is a high-level function that handles multiple data types and automatically\n    computes the appropriate PETH based on the input data type. For point process data\n    (spikes/events), it computes firing rates (Hz). For continuous data (analog signals),\n    it computes event-triggered averages.\n\n    Parameters\n    ----------\n    data : nelpy object or np.ndarray\n        Data can be:\n        - AnalogSignalArray: continuous signals\n        - PositionArray: 2D/3D position data (x, y, [z] coordinates)\n        - SpikeTrainArray: spike trains\n        - BinnedSpikeTrainArray: binned spike trains\n        - EventArray: event times\n        - BinnedEventArray: binned events\n        - np.ndarray: array of spike times (object array) or continuous signal\n    events : np.ndarray\n        1D array of event times to align data to.\n    window : list, optional\n        Time window around events [start, end] in seconds.\n        If None, uses symmetric window based on n_bins and bin_width.\n    bin_width : float, optional\n        Width of time bins in seconds (default 0.002).\n    n_bins : int, optional\n        Number of bins (default 100). Ignored if window is specified.\n    average : bool, optional\n        If True (default), returns averaged PETH across all events as DataFrame.\n        If False, returns event-wise PETH matrix and time bins array.\n\n    Returns\n    -------\n    pd.DataFrame or Tuple[np.ndarray, np.ndarray]\n        If average=True:\n            DataFrame with time bins as index and each series/signal as columns.\n            Values are rates (Hz) for point process data or averaged\n            signal values for continuous data.\n        If average=False:\n            Tuple of (peth_matrix, time_bins) where:\n            - peth_matrix: 3D array with shape (n_time_bins, n_signals, n_events)\n            - time_bins: 1D array of time bin centers\n\n    Examples\n    --------\n    &gt;&gt;&gt; # With SpikeTrainArray - averaged across events\n    &gt;&gt;&gt; st, _ = loading.load_spikes(basepath)\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; peth_df = peth(st, ripples.starts, window=[-0.5, 0.5], bin_width=0.01)\n\n    &gt;&gt;&gt; # Get event-wise matrix for detailed analysis\n    &gt;&gt;&gt; peth_matrix, time_bins = peth(st, ripples.starts, window=[-0.5, 0.5],\n    ...                               bin_width=0.01, average=False)\n    &gt;&gt;&gt; # peth_matrix.shape: (n_time_bins, n_units, n_events)\n    &gt;&gt;&gt; # Can now analyze individual events\n    &gt;&gt;&gt; strong_events = peth_matrix.sum(axis=(0,1)) &gt; threshold\n\n    &gt;&gt;&gt; # With AnalogSignalArray\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from nelpy import AnalogSignalArray\n    &gt;&gt;&gt; timestamps = np.linspace(0, 5, 100)\n    &gt;&gt;&gt; signal = np.vstack([\n    ...     np.sin(2 * np.pi * timestamps),\n    ...     np.cos(2 * np.pi * timestamps),\n    ... ])\n    &gt;&gt;&gt; lfp = AnalogSignalArray(timestamps=timestamps, data=signal)\n    &gt;&gt;&gt; events = np.array([1.0, 2.0, 3.0])\n    &gt;&gt;&gt; peth_df = peth(lfp, events, window=[-0.2, 0.2])\n\n    &gt;&gt;&gt; # Get event-wise continuous data\n    &gt;&gt;&gt; lfp_matrix, time_lags = peth(lfp, events, window=[-0.2, 0.2], average=False)\n\n    &gt;&gt;&gt; # With PositionArray\n    &gt;&gt;&gt; from nelpy import PositionArray\n    &gt;&gt;&gt; x_pos = np.sin(2 * np.pi * timestamps)\n    &gt;&gt;&gt; y_pos = np.cos(2 * np.pi * timestamps)\n    &gt;&gt;&gt; position = PositionArray(timestamps=timestamps, data=np.vstack([x_pos, y_pos]))\n    &gt;&gt;&gt; peth_df = peth(position, events, window=[-0.5, 0.5])\n\n    &gt;&gt;&gt; # With numpy array\n    &gt;&gt;&gt; spikes = np.array([spike_train_1, spike_train_2], dtype=object)\n    &gt;&gt;&gt; peth_df = peth(spikes, events, window=[-0.5, 0.5])\n\n    Notes\n    -----\n    - For point process data (spikes/events), uses crossCorr to compute firing rates\n    - For continuous data (analog signals), uses event_triggered_average\n        - For continuous data, output resolution follows the signal sampling rate;\n            `bin_width` is ignored unless you resample beforehand\n        - For numpy/object arrays of spike times, each spike train must be sorted in\n            ascending order (crossCorr assumes sorted targets)\n    - Returns rates in Hz for point process data\n    - Handles both regular and irregularly sampled continuous data\n\n    See Also\n    --------\n    compute_psth : Lower-level PSTH computation for numpy arrays\n    event_triggered_average : Event-triggered averaging for continuous signals\n    crossCorr : Cross-correlogram computation\n    \"\"\"\n\n    # Determine data type and extract spike/signal data\n    is_continuous = False\n\n    if isinstance(\n        data,\n        (AnalogSignalArray, PositionArray, BinnedSpikeTrainArray, BinnedEventArray),\n    ):\n        # Continuous signal data (includes position and binned spike/event data)\n        is_continuous = True\n\n        # Use bin_centers for binned data, abscissa_vals for others\n        if isinstance(data, (BinnedSpikeTrainArray, BinnedEventArray)):\n            timestamps = data.bin_centers\n        else:\n            timestamps = data.abscissa_vals\n\n        signal = data.data.T  # transpose to (n_samples, n_signals)\n        # Use n_signals if available (AnalogSignalArray/PositionArray), otherwise n_series (BinnedSpikeTrainArray)\n        n_series = getattr(\n            data, \"n_series\", getattr(data, \"n_signals\", data.data.shape[0])\n        )\n\n    elif isinstance(data, (SpikeTrainArray, EventArray)):\n        # Point process data - extract spike times\n        is_continuous = False\n        spike_data = data.data\n        n_series = len(spike_data)\n\n    elif isinstance(data, np.ndarray):\n        # Numpy array - determine if continuous or point process\n        if data.dtype == object:\n            # Object array - assume point process\n            is_continuous = False\n            spike_data = data\n            n_series = len(spike_data)\n        else:\n            # Regular array - could be continuous or point process\n            # If 2D, assume continuous; if 1D, assume point process\n            if data.ndim == 2:\n                # Continuous data\n                is_continuous = True\n                # Need timestamps - if not provided, we can't use event_triggered_average\n                # Fall back to treating as point process\n                raise ValueError(\n                    \"For continuous numpy arrays, please use AnalogSignalArray or provide \"\n                    \"timestamps separately via event_triggered_average function.\"\n                )\n            else:\n                # 1D array - single point process\n                is_continuous = False\n                spike_data = np.array([data], dtype=object)\n                n_series = 1\n    else:\n        raise TypeError(\n            f\"Unsupported data type: {type(data)}. \"\n            \"Must be AnalogSignalArray, PositionArray, SpikeTrainArray, BinnedSpikeTrainArray, \"\n            \"EventArray, BinnedEventArray, or np.ndarray\"\n        )\n\n    # Calculate time bins\n    window_original = None\n    if window is not None:\n        # Check if window is symmetric around 0, if not make it so\n        if ((window[1] - window[0]) / 2 != window[1]) | (\n            (window[1] - window[0]) / -2 != window[0]\n        ):\n            window_original = np.array(window)\n            window = [-np.max(np.abs(window)), np.max(np.abs(window))]\n\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        n_bins = len(times) - 1\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    # Compute PETH based on data type\n    if is_continuous:\n        # Continuous data - use event_triggered_average\n        if window is None:\n            window = [times[0], times[-1]]\n\n        # Calculate sampling rate\n        sampling_rate = 1 / np.median(np.diff(timestamps))\n\n        # Compute event-triggered average\n        result, time_lags = event_triggered_average(\n            timestamps,\n            signal,\n            events,\n            sampling_rate=sampling_rate,\n            window=window,\n            return_average=average,\n            return_pandas=False,\n        )\n\n        if average:\n            # Create DataFrame from averaged result\n            peth_df = pd.DataFrame(result, index=time_lags, columns=np.arange(n_series))\n        else:\n            # Return matrix directly: (n_time_bins, n_signals, n_events)\n            # event_triggered_average already returns in the correct shape\n            return result, time_lags\n\n    else:\n        # Point process data\n        if average:\n            # Use crossCorr for averaged PETH\n            peth_df = pd.DataFrame(index=times, columns=np.arange(n_series))\n\n            for i, s in enumerate(spike_data):\n                # Ensure spike times are float64\n                if len(s) &gt; 0:\n                    s = np.asarray(s, dtype=np.float64)\n                else:\n                    s = np.array([], dtype=np.float64)\n                peth_df[i] = crossCorr(events, s, bin_width, n_bins)\n        else:\n            # Use peth_matrix for event-wise PETH\n            # Build matrix for each spike train: (n_time_bins, n_signals, n_events)\n            matrices_list = []\n            window_arg = None if window is None else (window[0], window[1])\n\n            for i, s in enumerate(spike_data):\n                # Ensure spike times are float64\n                if len(s) &gt; 0:\n                    s = np.asarray(s, dtype=np.float64)\n                else:\n                    s = np.array([], dtype=np.float64)\n\n                # peth_matrix returns (n_time_bins, n_events)\n                H, t = peth_matrix(\n                    s, events, bin_width=bin_width, n_bins=n_bins, window=window_arg\n                )\n                matrices_list.append(H)\n\n            # Stack into (n_time_bins, n_signals, n_events)\n            result_matrix = np.stack(matrices_list, axis=1)\n\n            # If window was not symmetric, trim the time dimension\n            if window is not None and window_original is not None:\n                mask = (t &gt;= window_original[0]) &amp; (t &lt;= window_original[1])\n                result_matrix = result_matrix[mask, :, :]\n                t = t[mask]\n\n            return result_matrix, t\n\n    # If window was not symmetric, remove the extra bins (only for averaged DataFrame)\n    if average and window is not None and window_original is not None:\n        peth_df = peth_df.loc[window_original[0] : window_original[1], :]\n\n    return peth_df\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.peth_matrix","title":"<code>peth_matrix(data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Generate a peri-event time histogram (PETH) matrix.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A 1D array of time values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the PETH matrix, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the PETH matrix. Default is 100.</p> <code>100</code> <code>window</code> <code>tuple</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds. Use a tuple to avoid numba reflected-list warnings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>A 2D array representing the PETH matrix with rates in Hz. Shape is (n_time_bins, n_events).</p> <code>t</code> <code>ndarray</code> <p>A 1D array of time values corresponding to the bins in the PETH matrix.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True, parallel=True)\ndef peth_matrix(\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Union[Tuple[float, float], None] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate a peri-event time histogram (PETH) matrix.\n\n    Parameters\n    ----------\n    data : ndarray\n        A 1D array of time values.\n    time_ref : ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the PETH matrix, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the PETH matrix. Default is 100.\n    window : tuple, optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a width of `n_bins * bin_width` seconds.\n        Use a tuple to avoid numba reflected-list warnings.\n\n    Returns\n    -------\n    H : ndarray\n        A 2D array representing the PETH matrix with rates in Hz.\n        Shape is (n_time_bins, n_events).\n    t : ndarray\n        A 1D array of time values corresponding to the bins in the PETH matrix.\n\n    \"\"\"\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        # Compute n_bins from window-based times\n        n_bins = len(times) - 1\n        # Ensure n_bins is odd, same way crossCorr does it\n        if np.floor(n_bins / 2) * 2 == n_bins:\n            n_bins = n_bins + 1\n    else:\n        # Ensure n_bins is odd before computing times (crossCorr expects odd)\n        n_bins = int(n_bins)\n        if np.floor(n_bins / 2) * 2 == n_bins:\n            n_bins = n_bins + 1\n\n        times = (\n            np.arange(0, bin_width * n_bins, bin_width)\n            - (bin_width * n_bins) / 2\n            + bin_width / 2\n        )\n\n    H = np.zeros((len(times), len(time_ref)))\n\n    for event_i in prange(len(time_ref)):\n        H[:, event_i] = crossCorr([time_ref[event_i]], data, bin_width, n_bins)\n\n    return H, times\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.point_spectra","title":"<code>point_spectra(times, Fs=1250, freq_range=[1, 20], tapers0=[3, 5], pad=0, nfft=None)</code>","text":"<p>Compute multitaper power spectrum for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>times</code> <code>ndarray</code> <p>Array of spike times (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency (default is 1250 Hz).</p> <code>1250</code> <code>freq_range</code> <code>List[float]</code> <p>Frequency range to evaluate (default is [1, 20] Hz).</p> <code>[1, 20]</code> <code>tapers0</code> <code>List[int]</code> <p>Time-bandwidth product and number of tapers (default is [3, 5]). The time-bandwidth product is used to compute the tapers.</p> <code>[3, 5]</code> <code>pad</code> <code>int</code> <p>Padding for the FFT (default is 0).</p> <code>0</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>spectra</code> <code>ndarray</code> <p>Power spectrum.</p> <code>f</code> <code>ndarray</code> <p>Frequency vector.</p> Notes <p>Alternative function to <code>mtspectrumpt</code> for computing the power spectrum</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def point_spectra(\n    times: np.ndarray,\n    Fs: int = 1250,\n    freq_range: List[float] = [1, 20],\n    tapers0: List[int] = [3, 5],\n    pad: int = 0,\n    nfft: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute multitaper power spectrum for point processes.\n\n    Parameters\n    ----------\n    times : np.ndarray\n        Array of spike times (in seconds).\n    Fs : int, optional\n        Sampling frequency (default is 1250 Hz).\n    freq_range : List[float], optional\n        Frequency range to evaluate (default is [1, 20] Hz).\n    tapers0 : List[int], optional\n        Time-bandwidth product and number of tapers (default is [3, 5]).\n        The time-bandwidth product is used to compute the tapers.\n    pad : int, optional\n        Padding for the FFT (default is 0).\n    nfft : Optional[int], optional\n        Number of points for FFT (default is None).\n\n    Returns\n    -------\n    spectra : np.ndarray\n        Power spectrum.\n    f : np.ndarray\n        Frequency vector.\n\n    Notes\n    -----\n    Alternative function to `mtspectrumpt` for computing the power spectrum\n    \"\"\"\n\n    # generate frequency grid\n    timesRange = [min(times), max(times)]\n    window = np.floor(np.diff(timesRange))\n    nSamplesPerWindow = int(np.round(Fs * window[0]))\n    if nfft is None:\n        nfft = np.max(\n            [(int(2 ** np.ceil(np.log2(nSamplesPerWindow))) + pad), nSamplesPerWindow]\n        )\n    fAll = np.linspace(0, Fs, int(nfft))\n    frequency_ind = (fAll &gt;= freq_range[0]) &amp; (fAll &lt;= freq_range[1])\n\n    # Generate tapers\n    tapers, _ = dpss(nSamplesPerWindow, tapers0[0], tapers0[1], return_ratios=True)\n    tapers = tapers * np.sqrt(Fs)\n\n    # Compute FFT of tapers and restrict to required frequencies\n    H = np.fft.fft(tapers, n=nfft, axis=1)  # Shape: (K, nfft)\n    H = H[:, frequency_ind]  # Shape: (K, Nf)\n\n    # Angular frequencies\n    f = fAll[frequency_ind]\n    w = 2 * np.pi * f\n\n    # Time grid\n    timegrid = np.linspace(timesRange[0], timesRange[1], nSamplesPerWindow)\n\n    # Ensure times are within range\n    data = times[(times &gt;= timegrid[0]) &amp; (times &lt;= timegrid[-1])]\n\n    # Project spike times onto tapers\n    data_proj = [np.interp(data, timegrid, taper) for taper in tapers]\n    data_proj = np.vstack(data_proj)  # Shape: (K, len(data))\n\n    # Compute multitaper spectrum\n    exponential = np.exp(\n        np.outer(-1j * w, (data - timegrid[0]))\n    )  # Shape: (Nf, len(data))\n    J = exponential @ data_proj.T - H.T * len(data) / len(timegrid)  # Shape: (Nf, K)\n    spectra = np.squeeze(np.mean(np.real(np.conj(J) * J), axis=1))  # Mean across tapers\n\n    return spectra, f\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.randomize_epochs","title":"<code>randomize_epochs(epoch, randomize_each=True, start_stop=None)</code>","text":"<p>Randomly shifts the epochs of a EpochArray object and wraps them around the original time boundaries.</p> <p>This method takes a EpochArray object as input, and can either randomly shift each epoch by a different amount (if <code>randomize_each</code> is True) or shift all the epochs by the same amount (if <code>randomize_each</code> is False). In either case, the method wraps the shifted epochs around the original time boundaries to make sure they remain within the original time range. It then returns the modified EpochArray object.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The EpochArray object whose epochs should be shifted and wrapped.</p> required <code>randomize_each</code> <code>bool</code> <p>If True, each epoch will be shifted by a different random amount. If False, all the epochs will be shifted by the same random amount. Defaults to True.</p> <code>True</code> <code>start_stop</code> <code>array</code> <p>If not None, time support will be taken from start_stop</p> <code>None</code> <p>Returns:</p> Name Type Description <code>new_epochs</code> <code>EpochArray</code> <p>The modified EpochArray object with the shifted and wrapped epochs.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def randomize_epochs(\n    epoch: EpochArray,\n    randomize_each: bool = True,\n    start_stop: Optional[np.ndarray] = None,\n) -&gt; EpochArray:\n    \"\"\"\n    Randomly shifts the epochs of a EpochArray object and wraps them around the original time boundaries.\n\n    This method takes a EpochArray object as input, and can either randomly shift each epoch by a different amount\n    (if `randomize_each` is True) or shift all the epochs by the same amount (if `randomize_each` is False).\n    In either case, the method wraps the shifted epochs around the original time boundaries to make sure they remain\n    within the original time range. It then returns the modified EpochArray object.\n\n    Parameters\n    ----------\n    epoch : EpochArray\n        The EpochArray object whose epochs should be shifted and wrapped.\n    randomize_each : bool, optional\n        If True, each epoch will be shifted by a different random amount.\n        If False, all the epochs will be shifted by the same random amount. Defaults to True.\n    start_stop : array, optional\n        If not None, time support will be taken from start_stop\n\n    Returns\n    -------\n    new_epochs : EpochArray\n        The modified EpochArray object with the shifted and wrapped epochs.\n    \"\"\"\n\n    def wrap_intervals(intervals, start, stop):\n        idx = np.any(intervals &gt; stop, axis=1)\n        intervals[idx] = intervals[idx] - stop + start\n\n        idx = np.any(intervals &lt; start, axis=1)\n        intervals[idx] = intervals[idx] - start + stop\n        return intervals\n\n    new_epochs = epoch.copy()\n\n    if start_stop is None:\n        start = new_epochs.start\n        stop = new_epochs.stop\n    else:\n        start, stop = start_stop\n\n    if randomize_each:\n        # Randomly shift each epoch while keeping intervals within bounds\n        min_shifts = start - new_epochs.data[:, 0]\n        max_shifts = stop - new_epochs.data[:, 1]\n        if np.any(min_shifts &gt; max_shifts):\n            raise ValueError(\"start_stop must fully cover epoch intervals\")\n\n        random_order = np.random.uniform(min_shifts, max_shifts)\n        new_intervals = new_epochs.data + np.expand_dims(random_order, axis=1)\n        new_epochs._data = wrap_intervals(new_intervals, start, stop)\n    else:\n        # Shift all the epochs by the same amount while keeping within bounds\n        min_shifts = start - new_epochs.data[:, 0]\n        max_shifts = stop - new_epochs.data[:, 1]\n        min_shift = np.max(min_shifts)\n        max_shift = np.min(max_shifts)\n        if min_shift &gt; max_shift:\n            raise ValueError(\"start_stop must fully cover epoch intervals\")\n\n        random_shift = np.random.uniform(min_shift, max_shift)\n        new_epochs._data = wrap_intervals((new_epochs.data + random_shift), start, stop)\n\n    if not new_epochs.isempty:\n        if np.any(new_epochs.data[:, 1] - new_epochs.data[:, 0] &lt; 0):\n            raise ValueError(\"start must be less than or equal to stop\")\n\n    new_epochs._sort()\n\n    return new_epochs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.relative_times","title":"<code>relative_times(t, intervals, values=np.array([0, 1]))</code>","text":"<p>Calculate relative times and interval IDs for a set of time points.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>An array of time points.</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <code>values</code> <code>ndarray</code> <p>An array of values to assign to interval bounds. The default is [0,1].</p> <code>array([0, 1])</code> <p>Returns:</p> Name Type Description <code>rt</code> <code>ndarray</code> <p>An array of relative times, one for each time point (same len as t).</p> <code>intervalID</code> <code>ndarray</code> <p>An array of interval IDs, one for each time point (same len as t).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n&gt;&gt;&gt; relative_times(t, intervals)\n    (array([nan, 0. , 0.5, 1. , 0. , 0.5, 1. , 0. , 0.5, 1. ]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n</code></pre> <pre><code>&gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n&gt;&gt;&gt; values = np.array([0, 2*np.pi])\n&gt;&gt;&gt; relative_times(t, intervals, values)\n    (array([       nan, 0.        , 3.14159265, 6.28318531, 0.        ,\n            3.14159265, 6.28318531, 0.        , 3.14159265, 6.28318531]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n</code></pre> Notes <p>Intervals are defined as pairs of start and end times. The relative time is the time within the interval, normalized to the interval duration. The interval ID is the index of the interval in the intervals array. The values array can be used to assign a value to each interval.</p> <p>By Ryan H, based on RelativeTimes.m by Ralitsa Todorova</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef relative_times(\n    t: np.ndarray, intervals: np.ndarray, values: np.ndarray = np.array([0, 1])\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate relative times and interval IDs for a set of time points.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        An array of time points.\n    intervals : np.ndarray\n        An array of time intervals, represented as pairs of start and end times.\n    values : np.ndarray, optional\n        An array of values to assign to interval bounds. The default is [0,1].\n\n    Returns\n    -------\n    rt : np.ndarray\n        An array of relative times, one for each time point (same len as t).\n    intervalID : np.ndarray\n        An array of interval IDs, one for each time point (same len as t).\n\n    Examples\n    --------\n    &gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    &gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n    &gt;&gt;&gt; relative_times(t, intervals)\n        (array([nan, 0. , 0.5, 1. , 0. , 0.5, 1. , 0. , 0.5, 1. ]),\n        array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n\n    &gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    &gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n    &gt;&gt;&gt; values = np.array([0, 2*np.pi])\n    &gt;&gt;&gt; relative_times(t, intervals, values)\n        (array([       nan, 0.        , 3.14159265, 6.28318531, 0.        ,\n                3.14159265, 6.28318531, 0.        , 3.14159265, 6.28318531]),\n        array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n\n    Notes\n    -----\n    Intervals are defined as pairs of start and end times. The relative time is the time\n    within the interval, normalized to the interval duration. The interval ID is the index\n    of the interval in the intervals array. The values array can be used to assign a value\n    to each interval.\n\n    By Ryan H, based on RelativeTimes.m by Ralitsa Todorova\n\n    \"\"\"\n\n    rt = np.zeros(len(t), dtype=np.float64) * np.nan\n    intervalID = np.zeros(len(t), dtype=np.float64) * np.nan\n\n    start_times = intervals[:, 0]\n    end_times = intervals[:, 1]\n    values_diff = values[1] - values[0]\n    intervals_diff = end_times - start_times\n    intervals_scale = values_diff / intervals_diff\n\n    for i in range(len(t)):\n        idx = np.searchsorted(start_times, t[i])\n        if idx &gt; 0 and t[i] &lt;= end_times[idx - 1]:\n            interval_i = idx - 1\n        elif idx &lt; len(start_times) and t[i] == start_times[idx]:\n            interval_i = idx\n        else:\n            continue\n\n        scale = intervals_scale[interval_i]\n        rt[i] = ((t[i] - start_times[interval_i]) * scale) + values[0]\n        intervalID[i] = interval_i\n\n    return rt, intervalID\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.remove_inactive_cells","title":"<code>remove_inactive_cells(st, cell_metrics=None, epochs=None, min_spikes=100)</code>","text":"<p>remove_inactive_cells: Remove cells with fewer than min_spikes spikes per sub-epoch</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>SpikeTrainArray object containing spike times for multiple cells.</p> required <code>cell_metrics</code> <code>DataFrame</code> <p>DataFrame containing metrics for each cell (e.g., quality metrics).</p> <code>None</code> <code>epochs</code> <code>EpochArray or list of EpochArray</code> <p>If a list of EpochArray objects is provided, each EpochArray object is treated as a sub-epoch. If a single EpochArray object is provided, each interval in the EpochArray object is treated as a sub-epoch.</p> <code>None</code> <code>min_spikes</code> <code>int</code> <p>Minimum number of spikes required per sub-epoch to retain a cell. Default is 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>Tuple[SpikeTrainArray, Union[DataFrame, None]]</code> <p>A tuple containing: - SpikeTrainArray object with inactive cells removed. - DataFrame containing cell metrics with inactive cells removed (if provided).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.intervals import truncate_epoch\n&gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n&gt;&gt;&gt;     find_multitask_pre_post,\n&gt;&gt;&gt;     compress_repeated_epochs,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; import nelpy as nel\n&gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells\n</code></pre> <pre><code>&gt;&gt;&gt; # load data from session\n&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load spikes and cell metrics (cm)\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n&gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n&gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; beh_epochs = nel.EpochArray(\n&gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n&gt;&gt;&gt; )\n&gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"NREMstate\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; theta_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"THETA\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; # create list of restricted epochs\n&gt;&gt;&gt; restict_epochs = []\n&gt;&gt;&gt; for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n&gt;&gt;&gt;     if epoch_label in \"pre\":\n&gt;&gt;&gt;         # get cumulative hours of sleep\n&gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n&gt;&gt;&gt;     elif epoch_label in \"post\":\n&gt;&gt;&gt;         # get cumulative hours of sleep\n&gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n&gt;&gt;&gt;     else:\n&gt;&gt;&gt;         # get theta during task\n&gt;&gt;&gt;         epoch_restrict = epoch &amp; theta_epochs\n&gt;&gt;&gt;     restict_epochs.append(epoch_restrict)\n</code></pre> <pre><code>&gt;&gt;&gt; # remove inactive cells\n&gt;&gt;&gt; st, cm = remove_inactive_cells(st, cm, restict_epochs)\n</code></pre> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def remove_inactive_cells(\n    st: nel.core._eventarray.SpikeTrainArray,\n    cell_metrics: Union[pd.DataFrame, None] = None,\n    epochs: Union[\n        List[nel.core._intervalarray.EpochArray],\n        nel.core._intervalarray.EpochArray,\n        None,\n    ] = None,\n    min_spikes: int = 100,\n) -&gt; Tuple[nel.core._eventarray.SpikeTrainArray, Union[pd.DataFrame, None]]:\n    \"\"\"\n    remove_inactive_cells: Remove cells with fewer than min_spikes spikes per sub-epoch\n\n    Parameters\n    ----------\n    st : SpikeTrainArray\n        SpikeTrainArray object containing spike times for multiple cells.\n\n    cell_metrics : pd.DataFrame, optional\n        DataFrame containing metrics for each cell (e.g., quality metrics).\n\n    epochs : EpochArray or list of EpochArray, optional\n        If a list of EpochArray objects is provided, each EpochArray object\n        is treated as a sub-epoch. If a single EpochArray object is provided,\n        each interval in the EpochArray object is treated as a sub-epoch.\n\n    min_spikes : int, optional\n        Minimum number of spikes required per sub-epoch to retain a cell.\n        Default is 100.\n\n    Returns\n    -------\n    Tuple[SpikeTrainArray, Union[pd.DataFrame, None]]\n        A tuple containing:\n        - SpikeTrainArray object with inactive cells removed.\n        - DataFrame containing cell metrics with inactive cells removed (if provided).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.intervals import truncate_epoch\n    &gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n    &gt;&gt;&gt;     find_multitask_pre_post,\n    &gt;&gt;&gt;     compress_repeated_epochs,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; import nelpy as nel\n    &gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells\n\n    &gt;&gt;&gt; # load data from session\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n\n    &gt;&gt;&gt; # load spikes and cell metrics (cm)\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n    &gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n    &gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"NREMstate\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; theta_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"THETA\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; # create list of restricted epochs\n    &gt;&gt;&gt; restict_epochs = []\n    &gt;&gt;&gt; for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n    &gt;&gt;&gt;     if epoch_label in \"pre\":\n    &gt;&gt;&gt;         # get cumulative hours of sleep\n    &gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n    &gt;&gt;&gt;     elif epoch_label in \"post\":\n    &gt;&gt;&gt;         # get cumulative hours of sleep\n    &gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n    &gt;&gt;&gt;     else:\n    &gt;&gt;&gt;         # get theta during task\n    &gt;&gt;&gt;         epoch_restrict = epoch &amp; theta_epochs\n    &gt;&gt;&gt;     restict_epochs.append(epoch_restrict)\n\n    &gt;&gt;&gt; # remove inactive cells\n    &gt;&gt;&gt; st, cm = remove_inactive_cells(st, cm, restict_epochs)\n    \"\"\"\n\n    def return_results(st, cell_metrics):\n        if cell_metrics is None:\n            return st\n        else:\n            return st, cell_metrics\n\n    # check data types\n    if not isinstance(st, nel.core._eventarray.SpikeTrainArray):\n        raise ValueError(\"st must be a SpikeTrainArray object\")\n\n    if not isinstance(cell_metrics, (pd.core.frame.DataFrame, type(None))):\n        raise ValueError(\"cell_metrics must be a DataFrame object\")\n\n    if not isinstance(epochs, (nel.core._intervalarray.EpochArray, list)):\n        raise ValueError(\n            \"epochs must be an EpochArray object or a list of EpochArray objects\"\n        )\n\n    if isinstance(epochs, list):\n        for epoch in epochs:\n            if not isinstance(epoch, nel.core._intervalarray.EpochArray):\n                raise ValueError(\"list of epochs must contain EpochArray objects\")\n\n    # check if st is empty\n    if st.isempty:\n        return return_results(st, cell_metrics)\n\n    # check if epochs is empty\n    if isinstance(epochs, nel.core._intervalarray.EpochArray):\n        if epochs.isempty:\n            return return_results(st, cell_metrics)\n\n    # check if cell_metrics is empty\n    if cell_metrics is not None and cell_metrics.empty:\n        return return_results(st, cell_metrics)\n\n    # check if min_spikes is less than 1\n    if min_spikes &lt; 1:\n        return return_results(st, cell_metrics)\n\n    # check if st and cell_metrics have the same number of units\n    if cell_metrics is not None and st.n_units != cell_metrics.shape[0]:\n        # assert error message\n        raise ValueError(\"st and cell_metrics must have the same number of units\")\n\n    spk_thres_met = []\n    # check if each cell has at least min_spikes spikes in each epoch\n    for epoch_restrict in epochs:\n        if st[epoch_restrict].isempty:\n            spk_thres_met.append([False] * st.n_units)\n            continue\n        spk_thres_met.append(st[epoch_restrict].n_events &gt;= min_spikes)\n\n    good_idx = np.vstack(spk_thres_met).all(axis=0)\n\n    # remove inactive cells\n    st = st.iloc[:, good_idx]\n    if cell_metrics is not None:\n        cell_metrics = cell_metrics[good_idx]\n\n    return return_results(st, cell_metrics)\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.remove_inactive_cells_pre_task_post","title":"<code>remove_inactive_cells_pre_task_post(st, cell_metrics=None, beh_epochs=None, nrem_epochs=None, theta_epochs=None, min_spikes=100, nrem_time=3600)</code>","text":"<p>remove_inactive_cells_pre_task_post: Remove cells with fewer than min_spikes spikes per pre/task/post</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>SpikeTrainArray object containing spike times for multiple cells.</p> required <code>cell_metrics</code> <code>DataFrame</code> <p>DataFrame containing metrics for each cell (e.g., quality metrics).</p> <code>None</code> <code>beh_epochs</code> <code>EpochArray</code> <p>EpochArray object containing pre/task/post epochs.</p> <code>None</code> <code>nrem_epochs</code> <code>EpochArray</code> <p>EpochArray object containing NREM epochs.</p> <code>None</code> <code>theta_epochs</code> <code>EpochArray</code> <p>EpochArray object containing theta epochs.</p> <code>None</code> <code>min_spikes</code> <code>int</code> <p>Minimum number of spikes required per pre/task/post. Default is 100.</p> <code>100</code> <code>nrem_time</code> <code>int or float</code> <p>Time in seconds to truncate NREM epochs. Default is 3600 seconds.</p> <code>3600</code> <p>Returns:</p> Type Description <code>Tuple[SpikeTrainArray, Union[DataFrame, None]]</code> <p>A tuple containing: - SpikeTrainArray object with inactive cells removed. - DataFrame containing cell metrics with inactive cells removed (if provided).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells_pre_task_post\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n&gt;&gt;&gt;     find_multitask_pre_post,\n&gt;&gt;&gt;     compress_repeated_epochs,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; mport nelpy as nel\n</code></pre> <pre><code>&gt;&gt;&gt; # load data from session\n&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load spikes and cell metrics (cm)\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n&gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n&gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; beh_epochs = nel.EpochArray(\n&gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"NREMstate\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; theta_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"THETA\"],\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; st,cm = remove_inactive_cells_pre_task_post(st,cm,beh_epochs,nrem_epochs,theta_epochs)\n</code></pre> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def remove_inactive_cells_pre_task_post(\n    st: nel.core._eventarray.SpikeTrainArray,\n    cell_metrics: Union[pd.core.frame.DataFrame, None] = None,\n    beh_epochs: nel.core._intervalarray.EpochArray = None,\n    nrem_epochs: nel.core._intervalarray.EpochArray = None,\n    theta_epochs: nel.core._intervalarray.EpochArray = None,\n    min_spikes: int = 100,\n    nrem_time: Union[int, float] = 3600,\n) -&gt; tuple:\n    \"\"\"\n    remove_inactive_cells_pre_task_post: Remove cells with fewer than min_spikes spikes per pre/task/post\n\n    Parameters\n    ----------\n    st : SpikeTrainArray\n        SpikeTrainArray object containing spike times for multiple cells.\n\n    cell_metrics : pd.DataFrame, optional\n        DataFrame containing metrics for each cell (e.g., quality metrics).\n\n    beh_epochs : EpochArray\n        EpochArray object containing pre/task/post epochs.\n\n    nrem_epochs : EpochArray\n        EpochArray object containing NREM epochs.\n\n    theta_epochs : EpochArray\n        EpochArray object containing theta epochs.\n\n    min_spikes : int, optional\n        Minimum number of spikes required per pre/task/post. Default is 100.\n\n    nrem_time : int or float, optional\n        Time in seconds to truncate NREM epochs. Default is 3600 seconds.\n\n    Returns\n    -------\n    Tuple[nel.core._eventarray.SpikeTrainArray, Union[pd.DataFrame, None]]\n        A tuple containing:\n        - SpikeTrainArray object with inactive cells removed.\n        - DataFrame containing cell metrics with inactive cells removed (if provided).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells_pre_task_post\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n    &gt;&gt;&gt;     find_multitask_pre_post,\n    &gt;&gt;&gt;     compress_repeated_epochs,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; mport nelpy as nel\n\n    &gt;&gt;&gt; # load data from session\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n\n    &gt;&gt;&gt; # load spikes and cell metrics (cm)\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n    &gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n    &gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"NREMstate\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; theta_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"THETA\"],\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; st,cm = remove_inactive_cells_pre_task_post(st,cm,beh_epochs,nrem_epochs,theta_epochs)\n    \"\"\"\n\n    # check data types (further checks are done in remove_inactive_cells)\n    if not isinstance(beh_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"beh_epochs must be an EpochArray object\")\n\n    if not isinstance(nrem_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"nrem_epochs must be an EpochArray object\")\n\n    if not isinstance(theta_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"theta_epochs must be an EpochArray object\")\n\n    # create list of restricted epochs\n    restict_epochs = []\n    for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n        if epoch_label in \"pre\":\n            # get cumulative hours of sleep\n            epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=nrem_time)\n        elif epoch_label in \"post\":\n            # get cumulative hours of sleep\n            epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=nrem_time)\n        else:\n            # get theta during task\n            epoch_restrict = epoch &amp; theta_epochs\n        restict_epochs.append(epoch_restrict)\n\n    return remove_inactive_cells(\n        st, cell_metrics, restict_epochs, min_spikes=min_spikes\n    )\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.shift_epoch_array","title":"<code>shift_epoch_array(epoch, epoch_shift)</code>","text":"<p>Shift an EpochArray by another EpochArray.</p> <p>Shifting means that intervals in 'epoch' will be relative to intervals in 'epoch_shift' as if 'epoch_shift' intervals were without gaps.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The intervals to shift.</p> required <code>epoch_shift</code> <code>EpochArray</code> <p>The intervals to shift by.</p> required <p>Returns:</p> Type Description <code>EpochArray</code> <p>The shifted EpochArray.</p> Notes <p>This function restricts 'epoch' to those within 'epoch_shift' as epochs between 'epoch_shift' intervals would result in a duration of 0.</p> <p>Visual representation: inputs:     epoch       =   [  ]   [  ][]  []     epoch_shift =   [    ][]   [    ] becomes:     epoch       =   [  ]  [  ]    []     epoch_shift =   [    ][][    ]</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def shift_epoch_array(\n    epoch: nel.EpochArray, epoch_shift: nel.EpochArray\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Shift an EpochArray by another EpochArray.\n\n    Shifting means that intervals in 'epoch' will be relative to\n    intervals in 'epoch_shift' as if 'epoch_shift' intervals were without gaps.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The intervals to shift.\n    epoch_shift : nel.EpochArray\n        The intervals to shift by.\n\n    Returns\n    -------\n    nel.EpochArray\n        The shifted EpochArray.\n\n    Notes\n    -----\n    This function restricts 'epoch' to those within 'epoch_shift' as\n    epochs between 'epoch_shift' intervals would result in a duration of 0.\n\n    Visual representation:\n    inputs:\n        epoch       =   [  ]   [  ] [  ]  []\n        epoch_shift =   [    ] [    ]   [    ]\n    becomes:\n        epoch       =   [  ]  [  ]    []\n        epoch_shift =   [    ][    ][    ]\n    \"\"\"\n    # input validation\n    if not isinstance(epoch, nel.EpochArray):\n        raise TypeError(\"epoch must be a nelpy EpochArray\")\n    if not isinstance(epoch_shift, nel.EpochArray):\n        raise TypeError(\"epoch_shift must be a nelpy EpochArray\")\n\n    # restrict epoch to epoch_shift and extract starts and stops\n    epoch_starts, epoch_stops = epoch[epoch_shift].data.T\n\n    # shift starts and stops by epoch_shift\n    _, epoch_starts_shifted = in_intervals(epoch_starts, epoch_shift.data, shift=True)\n    _, epoch_stops_shifted = in_intervals(epoch_stops, epoch_shift.data, shift=True)\n\n    # shift time support as well, if one exists\n    support_starts_shifted, support_stops_shifted = -np.inf, np.inf\n    if epoch.domain.start != -np.inf:\n        _, support_starts_shifted = in_intervals(\n            epoch.domain.start, epoch_shift.data, shift=True\n        )\n    if epoch.domain.stop != np.inf:\n        _, support_stops_shifted = in_intervals(\n            epoch.domain.stop, epoch_shift.data, shift=True\n        )\n\n    session_domain = nel.EpochArray([support_starts_shifted, support_stops_shifted])\n\n    # package shifted intervals into epoch array with shifted time support\n    return nel.EpochArray(\n        np.array([epoch_starts_shifted, epoch_stops_shifted]).T, domain=session_domain\n    )\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.spatial_phase_precession","title":"<code>spatial_phase_precession(circ, lin, slope_bounds=[-3 * np.pi, 3 * np.pi])</code>","text":"<p>Compute the circular-linear correlation as described in https://pubmed.ncbi.nlm.nih.gov/22487609/.</p> <p>Parameters:</p> Name Type Description Default <code>circ</code> <code>ndarray</code> <p>Circular data in radians (e.g., spike phases).</p> required <code>lin</code> <code>ndarray</code> <p>Linear data (e.g., spike positions).</p> required <code>slope_bounds</code> <code>Union[List[float], Tuple[float, float]]</code> <p>The slope range for optimization (default is [-3 * np.pi, 3 * np.pi]).</p> <code>[-3 * pi, 3 * pi]</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-linear correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> <code>sl</code> <code>float</code> <p>Slope of the circular-linear correlation.</p> <code>offs</code> <code>float</code> <p>Offset of the circular-linear correlation.</p> Notes <p>This method computes a circular-linear correlation and can handle cases where one or both variables may follow a uniform distribution. It differs from the linear-circular correlation used in other studies (e.g., https://science.sciencemag.org/content/340/6138/1342).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; circ = np.random.uniform(0, 2 * np.pi, 100)\n&gt;&gt;&gt; lin = np.random.uniform(0, 1, 100)\n&gt;&gt;&gt; rho, pval, sl, offs = spatial_phase_precession(circ, lin)\n&gt;&gt;&gt; print(f\"Correlation: {rho}, p-value: {pval}, slope: {sl}, offset: {offs}\")\n</code></pre> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def spatial_phase_precession(\n    circ: np.ndarray,\n    lin: np.ndarray,\n    slope_bounds: Union[List[float], Tuple[float, float]] = [-3 * np.pi, 3 * np.pi],\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"\n    Compute the circular-linear correlation as described in https://pubmed.ncbi.nlm.nih.gov/22487609/.\n\n    Parameters\n    ----------\n    circ : np.ndarray\n        Circular data in radians (e.g., spike phases).\n    lin : np.ndarray\n        Linear data (e.g., spike positions).\n    slope_bounds : Union[List[float], Tuple[float, float]], optional\n        The slope range for optimization (default is [-3 * np.pi, 3 * np.pi]).\n\n    Returns\n    -------\n    rho : float\n        Circular-linear correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n    sl : float\n        Slope of the circular-linear correlation.\n    offs : float\n        Offset of the circular-linear correlation.\n\n    Notes\n    -----\n    This method computes a circular-linear correlation and can handle cases\n    where one or both variables may follow a uniform distribution. It differs from\n    the linear-circular correlation used in other studies (e.g., https://science.sciencemag.org/content/340/6138/1342).\n\n    Examples\n    -------\n    &gt;&gt;&gt; circ = np.random.uniform(0, 2 * np.pi, 100)\n    &gt;&gt;&gt; lin = np.random.uniform(0, 1, 100)\n    &gt;&gt;&gt; rho, pval, sl, offs = spatial_phase_precession(circ, lin)\n    &gt;&gt;&gt; print(f\"Correlation: {rho}, p-value: {pval}, slope: {sl}, offset: {offs}\")\n    \"\"\"\n\n    # Get rid of all the nans in this data\n    nan_index = np.logical_or(np.isnan(circ), np.isnan(lin))\n    circ = circ[~nan_index]\n    lin = lin[~nan_index]\n\n    # Make sure there are still valid data\n    if np.size(lin) == 0:\n        return np.nan, np.nan, np.nan, np.nan\n\n    def myfun1(p):\n        return -np.sqrt(\n            (np.sum(np.cos(circ - (p * lin))) / len(circ)) ** 2\n            + (np.sum(np.sin(circ - (p * lin))) / len(circ)) ** 2\n        )\n\n    # finding the optimal slope, note that we have to restrict the range of slopes\n\n    sl = sp.optimize.fminbound(\n        myfun1,\n        slope_bounds[0] / (np.max(lin) - np.min(lin)),\n        slope_bounds[1] / (np.max(lin) - np.min(lin)),\n    )\n\n    # calculate offset\n    offs = np.arctan2(\n        np.sum(np.sin(circ - (sl * lin))), np.sum(np.cos(circ - (sl * lin)))\n    )\n    # offs = (offs + np.pi) % (2 * np.pi) - np.pi\n    offs = np.arctan2(np.sin(offs), np.cos(offs))\n\n    # circular variable derived from the linearization\n    linear_circ = np.mod(abs(sl) * lin, 2 * np.pi)\n\n    # # marginal distributions:\n    p1, z1 = pcs.rayleigh(circ)\n    p2, z2 = pcs.rayleigh(linear_circ)\n\n    # circular-linear correlation:\n    if (p1 &gt; 0.5) | (p2 &gt; 0.5):\n        # This means at least one of our variables may be a uniform distribution\n        rho, pval = corrcc_uniform(circ, linear_circ)\n    else:\n        rho, pval = corrcc(circ, linear_circ)\n\n    # Assign the correct sign to rho\n    if sl &lt; 0:\n        rho = -np.abs(rho)\n    else:\n        rho = np.abs(rho)\n\n    # if offs &lt; 0:\n    #     offs = offs + 2 * np.pi\n    # if offs &gt; np.pi:\n    #     offs = offs - 2 * np.pi\n\n    return rho, pval, sl, offs\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.split_epoch_by_width","title":"<code>split_epoch_by_width(intervals, bin_width=0.001)</code>","text":"<p>Generate combined intervals (start, stop) at a specified width within given intervals.</p> <p>Parameters:</p> Name Type Description Default <code>intervals</code> <code>List[Tuple[float, float]]</code> <p>A list of (start, end) tuples representing intervals.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in seconds. Default is 0.001 (1 ms).</p> <code>0.001</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array containing (start, stop) pairs for all bins across intervals.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def split_epoch_by_width(\n    intervals: List[Tuple[float, float]], bin_width: float = 0.001\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate combined intervals (start, stop) at a specified width within given intervals.\n\n    Parameters\n    ----------\n    intervals : List[Tuple[float, float]]\n        A list of (start, end) tuples representing intervals.\n    bin_width : float\n        The width of each bin in seconds. Default is 0.001 (1 ms).\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array containing (start, stop) pairs for all bins across intervals.\n    \"\"\"\n    bin_intervals = []\n    for start, end in intervals:\n        # Generate bin edges\n        edges = np.arange(start, end, bin_width)\n        edges = np.append(edges, end)  # Ensure the final end is included\n        # Generate intervals (start, stop) for each bin\n        intervals = np.stack((edges[:-1], edges[1:]), axis=1)\n        bin_intervals.append(intervals)\n    return np.vstack(bin_intervals)\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.split_epoch_equal_parts","title":"<code>split_epoch_equal_parts(intervals, n_parts, return_epoch_array=True)</code>","text":"<p>Split multiple intervals into equal parts.</p> <p>Parameters:</p> Name Type Description Default <code>intervals</code> <code>(array - like, shape(n_intervals, 2))</code> <p>The intervals to split.</p> required <code>n_parts</code> <code>int</code> <p>The number of parts to split each interval into.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, returns the intervals as a nelpy.EpochArray object. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>split_intervals</code> <code>(array - like, shape(n_intervals * n_parts, 2) or EpochArray)</code> <p>The split intervals.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def split_epoch_equal_parts(\n    intervals: np.ndarray, n_parts: int, return_epoch_array: bool = True\n) -&gt; Union[np.ndarray, nel.EpochArray]:\n    \"\"\"\n    Split multiple intervals into equal parts.\n\n    Parameters\n    ----------\n    intervals : array-like, shape (n_intervals, 2)\n        The intervals to split.\n    n_parts : int\n        The number of parts to split each interval into.\n    return_epoch_array : bool, optional\n        If True, returns the intervals as a nelpy.EpochArray object. Defaults to True.\n\n    Returns\n    -------\n    split_intervals : array-like, shape (n_intervals * n_parts, 2) or nelpy.EpochArray\n        The split intervals.\n    \"\"\"\n    # Ensure intervals is a numpy array\n    intervals = np.asarray(intervals)\n\n    # Number of intervals\n    n_intervals = intervals.shape[0]\n\n    # Preallocate the output array\n    split_intervals = np.zeros((n_intervals * n_parts, 2))\n\n    for i, interval in enumerate(intervals):\n        start, end = interval\n        epoch_parts = np.linspace(start, end, n_parts + 1)\n        epoch_parts = np.vstack((epoch_parts[:-1], epoch_parts[1:])).T\n        split_intervals[i * n_parts : (i + 1) * n_parts] = epoch_parts\n\n    if return_epoch_array:\n        return nel.EpochArray(split_intervals)\n    return split_intervals\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.sync","title":"<code>sync(samples, sync_times, durations=(-0.5, 0.5), fast=True)</code>","text":"<p>Synchronize sample timestamps to reference events.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>ndarray</code> <p>Sample array with timestamps in the first column. Can be shape (n_samples,) or (n_samples, n_features). Assumed to be sorted by default.</p> required <code>sync_times</code> <code>ndarray</code> <p>1D array of synchronizing event times. Assumed to be sorted by default.</p> required <code>durations</code> <code>tuple of float</code> <p>Time window around each event as (start, stop), in seconds. Defaults to (-0.5, 0.5).</p> <code>(-0.5, 0.5)</code> <code>fast</code> <code>bool</code> <p>If True, assumes <code>samples</code> and <code>sync_times</code> are already sorted and skips sorting. If False, sorts the inputs (slower but handles unsorted data). Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>synchronized</code> <code>ndarray</code> <p>Samples that fall within event windows, with first column replaced by time relative to event.</p> <code>Ie</code> <code>ndarray</code> <p>Event indices for each synchronized sample, referencing the original <code>sync_times</code> order (0-based indices).</p> <code>Is</code> <code>ndarray</code> <p>Sample indices for each synchronized sample, referencing the original <code>samples</code> order (0-based indices).</p> Notes <p>By default, this function assumes both <code>samples</code> and <code>sync_times</code> are sorted in ascending order for maximum performance. If your data is unsorted, set <code>fast=False</code> to enable automatic sorting (with index remapping).</p> <p>Similar to get_raster_points but returns the synchronized samples in a single array and also returns the indices of the events and samples that correspond to each synchronized sample. Also is much faster than get_raster_points.</p> References <ul> <li>Original MATLAB implementation: Sync.m from FMAToolbox</li> </ul> <p>Examples:</p> <p>Basic usage with 1D timestamps:</p> <pre><code>&gt;&gt;&gt; samples = np.array([0.9, 1.1, 2.0, 2.1, 3.0])\n&gt;&gt;&gt; sync_times = np.array([1.0, 2.0])\n&gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15))\n&gt;&gt;&gt; synchronized[:, 0]\narray([-0.1,  0.1,  0. ,  0.1])\n&gt;&gt;&gt; Ie\narray([0, 0, 1, 1])\n&gt;&gt;&gt; Is\narray([0, 1, 2, 3])\n</code></pre> <p>Usage with unsorted samples and extra columns:</p> <pre><code>&gt;&gt;&gt; samples = np.array([[2.0, 20.0], [0.9, 9.0], [1.1, 11.0], [2.1, 21.0]])\n&gt;&gt;&gt; sync_times = np.array([2.0, 1.0])\n&gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15), fast=False)\n&gt;&gt;&gt; synchronized[:, 0]\narray([-0.1,  0.1,  0. ,  0.1])\n&gt;&gt;&gt; Ie  # indices into original sync_times\narray([1, 1, 0, 0])\n&gt;&gt;&gt; Is  # indices into original samples\narray([1, 2, 0, 3])\n</code></pre> <p>Real-world example with spike times and ripple events:</p> <pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP17\\hp17_day48_20250603\"\n&gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n&gt;&gt;&gt; ripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; sleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)\n&gt;&gt;&gt; nrem = sleep_states.get(\"NREMstate\")\n&gt;&gt;&gt; synchronized, Ie, Is = npy.process.sync(\n...     st.data[1], ripples[nrem].starts, durations=(-0.5, 0.5)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; plt.figure(figsize=(6, 4))\n&gt;&gt;&gt; plt.scatter(synchronized[:, 0], Ie, s=4, alpha=0.2, marker=\"|\", color=\"k\")\n&gt;&gt;&gt; plt.axvline(0, color=\"r\", ls=\"--\", lw=2)\n&gt;&gt;&gt; plt.xlabel(\"Time from event (s)\")\n&gt;&gt;&gt; plt.ylabel(\"Event #\")\n&gt;&gt;&gt; plt.title(\"Event-aligned raster\")\n&gt;&gt;&gt; plt.xlim(-0.5, 0.5)\n&gt;&gt;&gt; plt.ylim(0, np.max(Ie) + 1)\n&gt;&gt;&gt; plt.show()\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def sync(\n    samples: np.ndarray,\n    sync_times: np.ndarray,\n    durations: Tuple[float, float] = (-0.5, 0.5),\n    fast: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Synchronize sample timestamps to reference events.\n\n    Parameters\n    ----------\n    samples : np.ndarray\n        Sample array with timestamps in the first column. Can be shape (n_samples,)\n        or (n_samples, n_features). Assumed to be sorted by default.\n    sync_times : np.ndarray\n        1D array of synchronizing event times. Assumed to be sorted by default.\n    durations : tuple of float, optional\n        Time window around each event as (start, stop), in seconds.\n        Defaults to (-0.5, 0.5).\n    fast : bool, optional\n        If True, assumes `samples` and `sync_times` are already sorted and skips sorting.\n        If False, sorts the inputs (slower but handles unsorted data).\n        Defaults to True.\n\n    Returns\n    -------\n    synchronized : np.ndarray\n        Samples that fall within event windows, with first column replaced by\n        time relative to event.\n    Ie : np.ndarray\n        Event indices for each synchronized sample, referencing the original\n        `sync_times` order (0-based indices).\n    Is : np.ndarray\n        Sample indices for each synchronized sample, referencing the original\n        `samples` order (0-based indices).\n\n    Notes\n    -----\n    By default, this function assumes both `samples` and `sync_times` are sorted\n    in ascending order for maximum performance. If your data is unsorted, set\n    `fast=False` to enable automatic sorting (with index remapping).\n\n    Similar to get_raster_points but returns the synchronized samples in a\n    single array and also returns the indices of the events and samples that\n    correspond to each synchronized sample. Also is much faster than get_raster_points.\n\n\n    References\n    ----------\n    - Original MATLAB implementation: Sync.m from FMAToolbox\n\n    Examples\n    --------\n    Basic usage with 1D timestamps:\n\n    &gt;&gt;&gt; samples = np.array([0.9, 1.1, 2.0, 2.1, 3.0])\n    &gt;&gt;&gt; sync_times = np.array([1.0, 2.0])\n    &gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15))\n    &gt;&gt;&gt; synchronized[:, 0]\n    array([-0.1,  0.1,  0. ,  0.1])\n    &gt;&gt;&gt; Ie\n    array([0, 0, 1, 1])\n    &gt;&gt;&gt; Is\n    array([0, 1, 2, 3])\n\n    Usage with unsorted samples and extra columns:\n\n    &gt;&gt;&gt; samples = np.array([[2.0, 20.0], [0.9, 9.0], [1.1, 11.0], [2.1, 21.0]])\n    &gt;&gt;&gt; sync_times = np.array([2.0, 1.0])\n    &gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15), fast=False)\n    &gt;&gt;&gt; synchronized[:, 0]\n    array([-0.1,  0.1,  0. ,  0.1])\n    &gt;&gt;&gt; Ie  # indices into original sync_times\n    array([1, 1, 0, 0])\n    &gt;&gt;&gt; Is  # indices into original samples\n    array([1, 2, 0, 3])\n\n    Real-world example with spike times and ripple events:\n\n    &gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP17\\hp17_day48_20250603\"\n    &gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n    &gt;&gt;&gt; ripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; sleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; nrem = sleep_states.get(\"NREMstate\")\n    &gt;&gt;&gt; synchronized, Ie, Is = npy.process.sync(\n    ...     st.data[1], ripples[nrem].starts, durations=(-0.5, 0.5)\n    ... )\n\n    &gt;&gt;&gt; plt.figure(figsize=(6, 4))\n    &gt;&gt;&gt; plt.scatter(synchronized[:, 0], Ie, s=4, alpha=0.2, marker=\"|\", color=\"k\")\n    &gt;&gt;&gt; plt.axvline(0, color=\"r\", ls=\"--\", lw=2)\n    &gt;&gt;&gt; plt.xlabel(\"Time from event (s)\")\n    &gt;&gt;&gt; plt.ylabel(\"Event #\")\n    &gt;&gt;&gt; plt.title(\"Event-aligned raster\")\n    &gt;&gt;&gt; plt.xlim(-0.5, 0.5)\n    &gt;&gt;&gt; plt.ylim(0, np.max(Ie) + 1)\n    &gt;&gt;&gt; plt.show()\n    \"\"\"\n    samples = np.asarray(samples)\n    sync_times = np.asarray(sync_times)\n\n    if samples.ndim == 1:\n        samples = samples.reshape(-1, 1)\n    if samples.ndim != 2 or samples.shape[1] &lt; 1:\n        raise ValueError(\n            \"'samples' must be a 1D array or a 2D array with timestamps in column 0\"\n        )\n    if sync_times.ndim == 2 and sync_times.shape[1] == 1:\n        sync_times = sync_times[:, 0]\n    elif sync_times.ndim != 1:\n        raise ValueError(\"'sync_times' must be a 1D array or a 2D column vector\")\n    if len(durations) != 2 or durations[0] &gt; durations[1]:\n        raise ValueError(\"'durations' must be (start, stop) with start &lt;= stop\")\n\n    if len(sync_times) == 0 or samples.shape[0] == 0:\n        return (\n            np.empty((0, samples.shape[1])),\n            np.array([], dtype=int),\n            np.array([], dtype=int),\n        )\n\n    sort_samples = None\n    sort_sync = None\n\n    work_samples = samples\n    work_sync = sync_times\n\n    if not fast:\n        sort_samples = np.argsort(samples[:, 0], kind=\"mergesort\")\n        work_samples = samples[sort_samples]\n\n        sort_sync = np.argsort(sync_times, kind=\"mergesort\")\n        work_sync = sync_times[sort_sync]\n\n    sample_times = work_samples[:, 0]\n\n    # Use numba-compiled functions for the core sweep and index filling\n    starts, stops, events_with_hits, total_hits = _sync_find_windows(\n        sample_times, work_sync, durations[0], durations[1]\n    )\n\n    if len(starts) == 0:\n        return (\n            np.empty((0, samples.shape[1])),\n            np.array([], dtype=int),\n            np.array([], dtype=int),\n        )\n\n    Is, Ie = _sync_fill_indices(starts, stops, events_with_hits, total_hits)\n\n    # Ensure synchronized has floating dtype so relative times are preserved\n    # If samples were integer, subtraction would silently truncate to integers\n    synchronized = work_samples[Is].astype(np.float64, copy=True)\n    synchronized[:, 0] = synchronized[:, 0] - work_sync[Ie]\n\n    if sort_samples is not None:\n        Is = sort_samples[Is]\n    if sort_sync is not None:\n        Ie = sort_sync[Ie]\n\n    return synchronized, Ie, Is\n</code></pre>"},{"location":"reference/neuro_py/process/#neuro_py.process.truncate_epoch","title":"<code>truncate_epoch(epoch, time=3600)</code>","text":"<p>Truncates an EpochArray to achieve a specified cumulative time duration.</p> <p>This function takes an input EpochArray 'epoch' and a 'time' value representing the desired cumulative time duration in seconds. It returns a new EpochArray containing intervals that cumulatively match the specified time.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The input EpochArray containing intervals to be truncated.</p> required <code>time</code> <code>Union[int, float]</code> <p>The desired cumulative time in seconds (default is 3600).</p> <code>3600</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>A new EpochArray containing intervals that cumulatively match the specified time.</p> Algorithm <ol> <li>Calculate the cumulative lengths of intervals in the 'epoch'.</li> <li>If the cumulative time of the 'epoch' is already less than or equal to 'time',     return the original 'epoch'.</li> <li>Find the last interval that fits within the specified 'time' and create a new EpochArray     'truncated_intervals' with intervals up to that point.</li> <li>To achieve the desired cumulative time, calculate the remaining time needed to reach 'time'.</li> <li>Add portions of the next interval to 'truncated_intervals' until the desired 'time' is reached     or all intervals are used.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_data = [(0, 2), (3, 6), (8, 10)]\n&gt;&gt;&gt; epoch = nel.EpochArray(epoch_data)\n&gt;&gt;&gt; truncated_epoch = truncate_epoch(epoch, time=7)\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def truncate_epoch(\n    epoch: nel.EpochArray, time: Union[int, float] = 3600\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Truncates an EpochArray to achieve a specified cumulative time duration.\n\n    This function takes an input EpochArray 'epoch' and a 'time' value representing\n    the desired cumulative time duration in seconds. It returns a new EpochArray\n    containing intervals that cumulatively match the specified time.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The input EpochArray containing intervals to be truncated.\n    time : Union[int, float], optional\n        The desired cumulative time in seconds (default is 3600).\n\n    Returns\n    -------\n    nel.EpochArray\n        A new EpochArray containing intervals that cumulatively match\n        the specified time.\n\n    Algorithm\n    ---------\n    1. Calculate the cumulative lengths of intervals in the 'epoch'.\n    2. If the cumulative time of the 'epoch' is already less than or equal to 'time',\n        return the original 'epoch'.\n    3. Find the last interval that fits within the specified 'time' and create a new EpochArray\n        'truncated_intervals' with intervals up to that point.\n    4. To achieve the desired cumulative time, calculate the remaining time needed to reach 'time'.\n    5. Add portions of the next interval to 'truncated_intervals' until the desired 'time' is reached\n        or all intervals are used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; epoch_data = [(0, 2), (3, 6), (8, 10)]\n    &gt;&gt;&gt; epoch = nel.EpochArray(epoch_data)\n    &gt;&gt;&gt; truncated_epoch = truncate_epoch(epoch, time=7)\n    \"\"\"\n\n    if epoch.isempty:\n        return epoch\n\n    # calcuate cumulative lengths\n    cumulative_lengths = epoch.lengths.cumsum()\n\n    # No truncation needed\n    if cumulative_lengths[-1] &lt;= time:\n        return epoch\n\n    # Find the last interval that fits within the time and make new epoch\n    idx = cumulative_lengths &lt;= time\n    truncated_intervals = nel.EpochArray(epoch.data[idx])\n\n    # It's unlikely that the last interval will fit perfectly, so add the remainder from the next interval\n    #   until the epoch is the desired length\n    interval_i = 0\n    while (time - truncated_intervals.duration) &gt; 1e-10 or interval_i &gt; len(epoch):\n        # Add the last interval\n        next_interval = int(np.where(cumulative_lengths &gt;= time)[0][interval_i])\n\n        remainder = (\n            nel.EpochArray(\n                [\n                    epoch[next_interval].start,\n                    epoch[next_interval].start + (time - truncated_intervals.duration),\n                ]\n            )\n            &amp; epoch[next_interval]\n        )\n        truncated_intervals = truncated_intervals | remainder\n        interval_i += 1\n\n    return truncated_intervals\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/","title":"neuro_py.process.batch_analysis","text":""},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._is_homogeneous_array_compatible","title":"<code>_is_homogeneous_array_compatible(value)</code>","text":"<p>Check if a nested list/array structure can be converted to a homogeneous numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>any</code> <p>The value to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the value can be converted to a homogeneous numpy array</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _is_homogeneous_array_compatible(value: object) -&gt; bool:\n    \"\"\"\n    Check if a nested list/array structure can be converted to a homogeneous numpy array.\n\n    Parameters\n    ----------\n    value : any\n        The value to check\n\n    Returns\n    -------\n    bool\n        True if the value can be converted to a homogeneous numpy array\n    \"\"\"\n    try:\n        # Try to create a numpy array - if it fails, it's inhomogeneous\n        np.array(value)\n        return True\n    except (ValueError, TypeError):\n        return False\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._load_dataframe_from_hdf5","title":"<code>_load_dataframe_from_hdf5(h5_group)</code>","text":"<p>Load a pandas DataFrame from an HDF5 group.</p> <p>Parameters:</p> Name Type Description Default <code>h5_group</code> <code>Group</code> <p>HDF5 group containing the DataFrame data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Loaded DataFrame.</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _load_dataframe_from_hdf5(h5_group: h5py.Group) -&gt; pd.DataFrame:\n    \"\"\"\n    Load a pandas DataFrame from an HDF5 group.\n\n    Parameters\n    ----------\n    h5_group : h5py.Group\n        HDF5 group containing the DataFrame data.\n\n    Returns\n    -------\n    pd.DataFrame\n        Loaded DataFrame.\n    \"\"\"\n    data = {}\n\n    # Get column names\n    if \"columns\" in h5_group.attrs:\n        string_columns = h5_group.attrs[\"columns\"]\n        # Handle empty columns case\n        if len(string_columns) == 0:\n            string_columns = []\n        # Handle both bytes and str column names\n        elif isinstance(string_columns[0], bytes):\n            string_columns = [col.decode(\"utf-8\") for col in string_columns]\n        elif isinstance(string_columns[0], str):\n            string_columns = list(string_columns)  # already strings\n        else:\n            # Handle case where columns might be numeric types already\n            string_columns = [str(col) for col in string_columns]\n\n        # Try to load original column names if stored as numeric array\n        if \"_original_columns\" in h5_group:\n            columns = h5_group[\"_original_columns\"][:].tolist()\n        elif \"original_columns\" in h5_group.attrs and \"column_types\" in h5_group.attrs:\n            # Legacy approach: reconstruct from string representation and type info\n            original_columns = h5_group.attrs[\"original_columns\"]\n            column_types = h5_group.attrs[\"column_types\"]\n\n            # Convert string representations back to original types\n            reconstructed_columns = []\n            for orig_col, col_type in zip(original_columns, column_types):\n                if col_type == \"int64\" or col_type == \"int\":\n                    reconstructed_columns.append(int(orig_col))\n                elif col_type == \"float64\" or col_type == \"float\":\n                    reconstructed_columns.append(float(orig_col))\n                elif col_type == \"bool\":\n                    reconstructed_columns.append(orig_col.lower() == \"true\")\n                else:\n                    reconstructed_columns.append(orig_col)  # Keep as string\n\n            columns = reconstructed_columns\n        elif len(string_columns) &gt; 0:\n            # Fallback: try to convert numeric strings back to numbers\n            columns = []\n            for col in string_columns:\n                try:\n                    # Convert to string first if it's not already\n                    col_str = str(col)\n\n                    # Try to convert to float first (to handle both int and float)\n                    float_val = float(col_str)\n\n                    # If it's a whole number, convert to int\n                    if float_val.is_integer():\n                        columns.append(int(float_val))\n                    else:\n                        columns.append(float_val)\n\n                except (ValueError, TypeError):\n                    # Keep as string if conversion fails\n                    columns.append(col)\n        else:\n            # Empty columns case\n            columns = []\n    else:\n        # Fallback: get all keys except index\n        string_columns = [key for key in h5_group.keys() if key != \"_index\"]\n        columns = string_columns\n\n    # Load each column using string keys\n    for str_col, final_col in zip(string_columns, columns):\n        if str_col in h5_group:\n            dset = h5_group[str_col]\n            col_data = dset[:]\n            # Handle fixed-length bytes strings\n            if isinstance(col_data, np.ndarray) and col_data.dtype.kind == \"S\":\n                col_data = col_data.astype(str)\n            # Handle variable-length bytes arrays (object of bytes)\n            elif isinstance(col_data, np.ndarray) and col_data.dtype.kind == \"O\":\n                if len(col_data) and isinstance(col_data[0], (bytes, np.bytes_)):\n                    col_data = np.array([x.decode(\"utf-8\") for x in col_data])\n\n            # Restore original dtype based on metadata\n            if \"pandas_dtype\" in dset.attrs:\n                dtype_marker = dset.attrs[\"pandas_dtype\"]\n                if dtype_marker == \"string\":\n                    # StringDtype: restore as pandas StringDtype with original na_value.\n                    # Note: pandas StringDtype only supports np.nan or pd.NA as na_value.\n                    na_value_str = dset.attrs.get(\"string_na_value\", \"&lt;NA&gt;\")\n                    if na_value_str == \"&lt;NA&gt;\":\n                        na_value = pd.NA\n                    elif na_value_str == \"nan\":\n                        na_value = np.nan\n                    else:\n                        # Fallback for unexpected values (should not occur with standard StringDtype)\n                        na_value = pd.NA\n                    string_dtype = pd.StringDtype(na_value=na_value)\n                    data[final_col] = pd.Series(col_data, dtype=string_dtype)\n                elif dtype_marker == \"object\":\n                    # Object dtype: keep as object (for mixed-type columns)\n                    data[final_col] = col_data\n                else:\n                    # Try to convert back to original dtype (e.g., int64, float32, etc.)\n                    try:\n                        data[final_col] = col_data.astype(dtype_marker)\n                    except (ValueError, TypeError):\n                        # If conversion fails, keep as-is\n                        data[final_col] = col_data\n            else:\n                data[final_col] = col_data\n\n    # Load index\n    if \"_index\" in h5_group:\n        index = h5_group[\"_index\"][:]\n        # Handle string index\n        if index.dtype.kind == \"S\":\n            index = index.astype(str)\n    else:\n        index = None\n\n    return pd.DataFrame(data, index=index, columns=columns)\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._load_from_hdf5","title":"<code>_load_from_hdf5(filepath)</code>","text":"<p>Load data from HDF5 format with support for inhomogeneous arrays.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the HDF5 file.</p> required <p>Returns:</p> Type Description <code>Union[DataFrame, dict]</code> <p>Loaded data.</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _load_from_hdf5(filepath: str) -&gt; Union[pd.DataFrame, dict]:\n    \"\"\"\n    Load data from HDF5 format with support for inhomogeneous arrays.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the HDF5 file.\n\n    Returns\n    -------\n    Union[pd.DataFrame, dict]\n        Loaded data.\n    \"\"\"\n    with h5py.File(filepath, \"r\") as f:\n        if \"dataframe\" in f and len(f.keys()) == 1:\n            # Single DataFrame case\n            return _load_dataframe_from_hdf5(f[\"dataframe\"])\n        else:\n            # Multiple items case\n            result = {}\n\n            # First, identify which keys are inhomogeneous data\n            inhom_keys = set()\n            for key in f.keys():\n                if key.endswith(\"_inhomogeneous\"):\n                    original_key = key.replace(\"_inhomogeneous\", \"\")\n                    inhom_keys.add(original_key)\n                elif key.endswith(\"_pickled\"):\n                    original_key = key.replace(\"_pickled\", \"\")\n                    if f\"{key}_type\" in f.attrs:\n                        inhom_keys.add(original_key)\n\n            # Load datasets and groups\n            for key in f.keys():\n                if isinstance(f[key], h5py.Group):\n                    # Check if this is an inhomogeneous array group\n                    if key.endswith(\"_inhomogeneous\") or key.endswith(\"_pickled\"):\n                        # This will be handled later by the inhomogeneous data loader\n                        continue\n                    else:\n                        # This is a regular DataFrame group\n                        result[key] = _load_dataframe_from_hdf5(f[key])\n                else:\n                    # Skip internal keys that will be handled by inhomogeneous data loader\n                    if key.endswith(\"_inhomogeneous\") or key.endswith(\"_pickled\"):\n                        continue\n\n                    # Handle datasets - check if it's a scalar dataset\n                    dataset = f[key]\n                    if dataset.shape == ():  # Scalar dataset\n                        result[key] = dataset[()]  # Use [()] for scalar datasets\n                    else:\n                        result[key] = dataset[:]  # Use [:] for array datasets\n\n            # Load attributes (including scalar values)\n            for key, value in f.attrs.items():\n                if key.endswith(\"_pickled_type\"):\n                    continue  # Skip metadata attributes\n                elif isinstance(value, (int, float, bool)):\n                    result[key] = value\n                elif isinstance(value, (np.bytes_, bytes)):\n                    result[key] = value.decode(\"utf-8\")  # Convert bytes back to string\n                else:\n                    result[key] = value\n\n            # Load inhomogeneous data\n            for key in inhom_keys:\n                try:\n                    result[key] = _load_inhomogeneous_data_hdf5(f, key)\n                except Exception as e:\n                    print(\n                        f\"Warning: Could not load inhomogeneous data for key {key}: {e}\"\n                    )\n\n            return result\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._load_inhomogeneous_data_hdf5","title":"<code>_load_inhomogeneous_data_hdf5(group, key)</code>","text":"<p>Load inhomogeneous data from HDF5.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>Group</code> <p>HDF5 group to load from</p> required <code>key</code> <code>str</code> <p>Key name for the data</p> required <p>Returns:</p> Type Description <code>any</code> <p>The loaded inhomogeneous data</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _load_inhomogeneous_data_hdf5(group: h5py.Group, key: str) -&gt; object:\n    \"\"\"\n    Load inhomogeneous data from HDF5.\n\n    Parameters\n    ----------\n    group : h5py.Group\n        HDF5 group to load from\n    key : str\n        Key name for the data\n\n    Returns\n    -------\n    any\n        The loaded inhomogeneous data\n    \"\"\"\n    # Check for inhomogeneous array collection\n    if f\"{key}_inhomogeneous\" in group:\n        inhom_group = group[f\"{key}_inhomogeneous\"]\n        data_type = inhom_group.attrs.get(\"type\", \"\")\n\n        if data_type == \"inhomogeneous_array_list\":\n            # Load list of arrays\n            length = inhom_group.attrs[\"length\"]\n            arrays = []\n            for i in range(length):\n                arrays.append(inhom_group[f\"array_{i}\"][:])\n            return arrays\n\n        elif data_type == \"nested_inhomogeneous_array_list\":\n            # Load nested list of arrays\n            length = inhom_group.attrs[\"length\"]\n            result = []\n            for i in range(length):\n                subgroup = inhom_group[f\"sublist_{i}\"]\n                sublength = subgroup.attrs[\"length\"]\n                sublist = []\n                for j in range(sublength):\n                    sublist.append(subgroup[f\"array_{j}\"][:])\n                result.append(sublist)\n            return result\n\n    # Check for pickled object\n    elif f\"{key}_pickled\" in group:\n        pickled_data = group[f\"{key}_pickled\"][()]\n        return pickle.loads(pickled_data.tobytes())\n\n    else:\n        raise KeyError(f\"Inhomogeneous data with key '{key}' not found\")\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._save_dataframe_to_hdf5","title":"<code>_save_dataframe_to_hdf5(df, h5_group, group_name)</code>","text":"<p>Save a pandas DataFrame to an HDF5 group.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to save.</p> required <code>h5_group</code> <code>Group</code> <p>HDF5 group or file to save to.</p> required <code>group_name</code> <code>str</code> <p>Name of the group to create.</p> required Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _save_dataframe_to_hdf5(\n    df: pd.DataFrame, h5_group: h5py.Group, group_name: str\n) -&gt; None:\n    \"\"\"\n    Save a pandas DataFrame to an HDF5 group.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame to save.\n    h5_group : h5py.Group\n        HDF5 group or file to save to.\n    group_name : str\n        Name of the group to create.\n    \"\"\"\n    group = h5_group.create_group(group_name)\n\n    # Convert column names to strings for HDF5 compatibility\n    string_columns = [str(col) for col in df.columns]\n\n    # Save each column\n    for orig_col, str_col in zip(df.columns, string_columns):\n        try:\n            series = df[orig_col]\n\n            # Preserve pandas StringDtype explicitly\n            if isinstance(series.dtype, pd.StringDtype):\n                string_data = series.astype(\"string\").fillna(\"\").astype(str).values\n                dset = group.create_dataset(str_col, data=string_data.astype(\"S\"))\n                dset.attrs[\"pandas_dtype\"] = \"string\"\n                # Store na_value setting (only np.nan or pd.NA are valid for StringDtype)\n                dset.attrs[\"string_na_value\"] = str(series.dtype.na_value)\n\n            elif series.dtype == \"object\":\n                # Check if object column contains strings\n                string_data = series.astype(str).values\n                dset = group.create_dataset(str_col, data=string_data.astype(\"S\"))\n                # Mark as object so we can detect it on load\n                dset.attrs[\"pandas_dtype\"] = \"object\"\n\n            else:\n                # For numeric and other types, save with dtype info\n                dset = group.create_dataset(str_col, data=series.values)\n                dset.attrs[\"pandas_dtype\"] = str(series.dtype)\n        except Exception as e:\n            print(f\"Warning: Could not save column {orig_col}: {e}\")\n\n    # Save index\n    try:\n        if hasattr(df.index, \"values\"):\n            index_values = np.array(df.index)\n            # Convert string-like index to bytes\n            if index_values.dtype.kind in (\"O\", \"U\", \"S\") and len(index_values) &gt; 0:\n                encoded = np.array([str(x).encode(\"utf-8\") for x in index_values])\n                group.create_dataset(\"_index\", data=encoded)\n            else:\n                group.create_dataset(\"_index\", data=index_values)\n        else:\n            group.create_dataset(\"_index\", data=np.array(df.index))\n    except Exception as e:\n        print(f\"Warning: Could not save index: {e}\")\n\n    # Save original column names and their types for proper reconstruction\n    group.attrs[\"columns\"] = string_columns\n    group.attrs[\"original_columns\"] = [\n        str(col) for col in df.columns\n    ]  # String representation\n    group.attrs[\"column_types\"] = [\n        str(type(col).__name__) for col in df.columns\n    ]  # Type info\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._save_inhomogeneous_data_hdf5","title":"<code>_save_inhomogeneous_data_hdf5(group, key, value)</code>","text":"<p>Save inhomogeneous data to HDF5 using different strategies.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>Group</code> <p>HDF5 group to save to</p> required <code>key</code> <code>str</code> <p>Key name for the data</p> required <code>value</code> <code>any</code> <p>The inhomogeneous data to save</p> required Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _save_inhomogeneous_data_hdf5(group: h5py.Group, key: str, value: object) -&gt; None:\n    \"\"\"\n    Save inhomogeneous data to HDF5 using different strategies.\n\n    Parameters\n    ----------\n    group : h5py.Group\n        HDF5 group to save to\n    key : str\n        Key name for the data\n    value : any\n        The inhomogeneous data to save\n    \"\"\"\n    # Strategy 1: Try to save as individual arrays if it's a list of arrays\n    if isinstance(value, (list, tuple)) and len(value) &gt; 0:\n        # Check if all elements are numpy arrays\n        if all(isinstance(item, np.ndarray) for item in value):\n            # Create a group for this inhomogeneous array collection\n            inhom_group = group.create_group(f\"{key}_inhomogeneous\")\n\n            # Save each array separately with its index\n            for i, arr in enumerate(value):\n                inhom_group.create_dataset(f\"array_{i}\", data=arr)\n\n            # Save metadata about the structure\n            inhom_group.attrs[\"type\"] = \"inhomogeneous_array_list\"\n            inhom_group.attrs[\"length\"] = len(value)\n            return\n\n        # Check if it's a nested list where each element is a list of arrays\n        elif (\n            len(value) &gt; 0\n            and isinstance(value[0], (list, tuple))\n            and len(value[0]) &gt; 0\n            and isinstance(value[0][0], np.ndarray)\n        ):\n            # Handle nested structure like [[array1, array2, ...], [array3, array4, ...]]\n            inhom_group = group.create_group(f\"{key}_inhomogeneous\")\n\n            for i, sublist in enumerate(value):\n                subgroup = inhom_group.create_group(f\"sublist_{i}\")\n                for j, arr in enumerate(sublist):\n                    subgroup.create_dataset(f\"array_{j}\", data=arr)\n                subgroup.attrs[\"length\"] = len(sublist)\n\n            inhom_group.attrs[\"type\"] = \"nested_inhomogeneous_array_list\"\n            inhom_group.attrs[\"length\"] = len(value)\n            return\n\n    # Strategy 2: Fall back to pickle serialization for complex structures\n    pickled_data = pickle.dumps(value)\n    # Store as bytes dataset\n    group.create_dataset(f\"{key}_pickled\", data=np.void(pickled_data))\n    group.attrs[f\"{key}_pickled_type\"] = \"pickled_object\"\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis._save_to_hdf5","title":"<code>_save_to_hdf5(data, filepath)</code>","text":"<p>Save data to HDF5 format with support for inhomogeneous arrays.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, dict]</code> <p>Data to save. Can be a DataFrame or dict containing DataFrames/arrays.</p> required <code>filepath</code> <code>str</code> <p>Path to save the HDF5 file.</p> required Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def _save_to_hdf5(data: Union[pd.DataFrame, dict], filepath: str) -&gt; None:\n    \"\"\"\n    Save data to HDF5 format with support for inhomogeneous arrays.\n\n    Parameters\n    ----------\n    data : Union[pd.DataFrame, dict]\n        Data to save. Can be a DataFrame or dict containing DataFrames/arrays.\n    filepath : str\n        Path to save the HDF5 file.\n    \"\"\"\n    with h5py.File(filepath, \"w\") as f:\n        if isinstance(data, pd.DataFrame):\n            # Save DataFrame directly\n            _save_dataframe_to_hdf5(data, f, \"dataframe\")\n        elif isinstance(data, dict):\n            # Save each item in the dictionary\n            for key, value in data.items():\n                if value is None:\n                    # Handle None values by storing as pickled data\n                    _save_inhomogeneous_data_hdf5(f, key, value)\n                elif isinstance(value, pd.DataFrame):\n                    _save_dataframe_to_hdf5(value, f, key)\n                elif isinstance(value, np.ndarray):\n                    f.create_dataset(key, data=value)\n                elif isinstance(value, (int, float, bool)):\n                    f.attrs[key] = value\n                elif isinstance(value, str):\n                    f.attrs[key] = np.bytes_(\n                        value.encode(\"utf-8\")\n                    )  # Store string as bytes\n                elif isinstance(value, (list, tuple)):\n                    # Check if it can be converted to homogeneous array\n                    if _is_homogeneous_array_compatible(value):\n                        # Convert to numpy array for storage\n                        f.create_dataset(key, data=np.array(value))\n                    else:\n                        # Handle inhomogeneous data\n                        _save_inhomogeneous_data_hdf5(f, key, value)\n                else:\n                    # For other types, try to pickle them\n                    try:\n                        _save_inhomogeneous_data_hdf5(f, key, value)\n                    except Exception as e:\n                        # Final fallback: store as string representation\n                        f.attrs[f\"{key}_str\"] = np.bytes_(str(value).encode(\"utf-8\"))\n                        print(\n                            f\"Warning: Saved {key} as string representation due to: {e}\"\n                        )\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.decode_file_path","title":"<code>decode_file_path(save_file)</code>","text":"<p>Decode an encoded file path to retrieve the original session path.</p> <p>Parameters:</p> Name Type Description Default <code>save_file</code> <code>str</code> <p>Encoded file path that includes the original session path.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Original session path before encoding.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; save_file = r\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n&gt;&gt;&gt; decode_file_path(save_file)\n\"Z:\\Data\\AYAold\\AB3\\AB3_38_41\"\n</code></pre> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def decode_file_path(save_file: str) -&gt; str:\n    \"\"\"\n    Decode an encoded file path to retrieve the original session path.\n\n    Parameters\n    ----------\n    save_file : str\n        Encoded file path that includes the original session path.\n\n    Returns\n    -------\n    str\n        Original session path before encoding.\n\n    Examples\n    -------\n    &gt;&gt;&gt; save_file = r\"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\\\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n    &gt;&gt;&gt; decode_file_path(save_file)\n    \"Z:\\\\Data\\\\AYAold\\\\AB3\\\\AB3_38_41\"\n    \"\"\"\n\n    # get basepath from save_file\n    basepath = os.path.basename(save_file).replace(\"___\", \"/\").replace(\"---\", \":\")\n    # also remove file extension\n    basepath = os.path.splitext(basepath)[0]\n\n    # Convert to OS-appropriate path separators\n    basepath = basepath.replace(\"/\", os.sep)\n\n    return basepath\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.encode_file_path","title":"<code>encode_file_path(basepath, save_path, format_type='pickle')</code>","text":"<p>Encode file path to be used as a filename.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the session to be encoded.</p> required <code>save_path</code> <code>str</code> <p>Directory where the encoded file will be saved.</p> required <code>format_type</code> <code>str</code> <p>File format type (\"pickle\" or \"hdf5\"). Defaults to \"pickle\".</p> <code>'pickle'</code> <p>Returns:</p> Type Description <code>str</code> <p>Encoded file path suitable for use as a filename.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\AYAold\\AB3\\AB3_38_41\"\n&gt;&gt;&gt; save_path = r\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\"\n&gt;&gt;&gt; encode_file_path(basepath, save_path)\n\"Z:\\home\\ryanh\\projects\\ripple_heterogeneity\\replay_02_17_23\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n</code></pre> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def encode_file_path(basepath: str, save_path: str, format_type: str = \"pickle\") -&gt; str:\n    \"\"\"\n    Encode file path to be used as a filename.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the session to be encoded.\n    save_path : str\n        Directory where the encoded file will be saved.\n    format_type : str, optional\n        File format type (\"pickle\" or \"hdf5\"). Defaults to \"pickle\".\n\n    Returns\n    -------\n    str\n        Encoded file path suitable for use as a filename.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\AYAold\\\\AB3\\\\AB3_38_41\"\n    &gt;&gt;&gt; save_path = r\"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\"\n    &gt;&gt;&gt; encode_file_path(basepath, save_path)\n    \"Z:\\\\home\\\\ryanh\\\\projects\\\\ripple_heterogeneity\\\\replay_02_17_23\\\\Z---___Data___AYAold___AB3___AB3_38_41.pkl\"\n    \"\"\"\n    # Normalize path separators to forward slashes for consistent encoding\n    basepath = basepath.replace(\"\\\\\", \"/\")\n    save_path = os.path.normpath(save_path)\n\n    # Encode with consistent separators\n    encoded_name = basepath.replace(\"/\", \"___\").replace(\":\", \"---\")\n\n    # Add extension\n    extension = \".h5\" if format_type == \"hdf5\" else \".pkl\"\n    encoded_name += extension\n\n    # Join using os.path.join for proper OS-specific path joining\n    return os.path.join(save_path, encoded_name)\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.load_results","title":"<code>load_results(save_path, verbose=False, add_save_file_name=False, format_type=None)</code>","text":"<p>Load results from pickled pandas DataFrames or HDF5 files in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str</code> <p>Path to the folder containing pickled results.</p> required <code>verbose</code> <code>bool</code> <p>Whether to print progress for each file. Defaults to False.</p> <code>False</code> <code>add_save_file_name</code> <code>bool</code> <p>Whether to add a column with the name of the save file. Defaults to False.</p> <code>False</code> <code>format_type</code> <code>Optional[Literal['pickle', 'hdf5']]</code> <p>File format to load. If None, will auto-detect based on file extension.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated pandas DataFrame with all results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified folder does not exist or is empty.</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def load_results(\n    save_path: str,\n    verbose: bool = False,\n    add_save_file_name: bool = False,\n    format_type: Optional[Literal[\"pickle\", \"hdf5\"]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Load results from pickled pandas DataFrames or HDF5 files in the specified directory.\n\n    Parameters\n    ----------\n    save_path : str\n        Path to the folder containing pickled results.\n    verbose : bool, optional\n        Whether to print progress for each file. Defaults to False.\n    add_save_file_name : bool, optional\n        Whether to add a column with the name of the save file. Defaults to False.\n    format_type : Optional[Literal[\"pickle\", \"hdf5\"]], optional\n        File format to load. If None, will auto-detect based on file extension.\n\n    Returns\n    -------\n    pd.DataFrame\n        Concatenated pandas DataFrame with all results.\n\n    Raises\n    ------\n    ValueError\n        If the specified folder does not exist or is empty.\n    \"\"\"\n\n    if not os.path.exists(save_path):\n        raise ValueError(f\"folder {save_path} does not exist\")\n\n    # Determine file pattern based on format_type\n    if format_type == \"pickle\":\n        file_pattern = \"*.pkl\"\n    elif format_type == \"hdf5\":\n        file_pattern = \"*.h5\"\n    else:\n        # Auto-detect: look for both formats\n        file_pattern = \"*\"\n\n    sessions = glob.glob(os.path.join(save_path, file_pattern))\n\n    # Filter by supported extensions if auto-detecting\n    if format_type is None:\n        sessions = [s for s in sessions if s.endswith((\".pkl\", \".h5\"))]\n\n    # Sort sessions for consistent ordering\n    sessions.sort()\n\n    results = []\n\n    for session in sessions:\n        if verbose:\n            print(session)\n\n        # Determine format based on file extension\n        if session.endswith(\".h5\"):\n            try:\n                results_ = _load_from_hdf5(session)\n            except Exception as e:\n                print(f\"Error loading HDF5 file {session}: {e}\")\n                continue\n        else:\n            try:\n                with open(session, \"rb\") as f:\n                    results_ = pickle.load(f)\n            except Exception as e:\n                print(f\"Error loading pickle file {session}: {e}\")\n                continue\n\n        if results_ is None:\n            continue\n\n        # Convert to DataFrame if it's a dict containing a single DataFrame\n        if (\n            isinstance(results_, dict)\n            and len(results_) == 1\n            and isinstance(list(results_.values())[0], pd.DataFrame)\n        ):\n            results_ = list(results_.values())[0]\n        elif (\n            isinstance(results_, dict)\n            and \"dataframe\" in results_\n            and isinstance(results_[\"dataframe\"], pd.DataFrame)\n        ):\n            results_ = results_[\"dataframe\"]\n\n        # Ensure we have a DataFrame\n        if not isinstance(results_, pd.DataFrame):\n            if verbose:\n                print(f\"Skipping {session}: not a DataFrame\")\n            continue\n\n        if add_save_file_name:\n            results_[\"save_file_name\"] = os.path.basename(session)\n\n        results.append(results_)\n\n    if not results:\n        raise ValueError(f\"No valid results found in {save_path}\")\n\n    results = pd.concat(results, ignore_index=True, axis=0)\n\n    return results\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.load_specific_data","title":"<code>load_specific_data(filepath, key=None)</code>","text":"<p>Load specific data from a file (supports selective loading for HDF5).</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, PathLike]</code> <p>Path to the file to load. Can be string or path-like object.</p> required <code>key</code> <code>Optional[str]</code> <p>Specific key/dataset to load (only for HDF5). If None, loads all data.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[DataFrame, dict, ndarray, None]</code> <p>Loaded data, or None if key not found in file.</p> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def load_specific_data(\n    filepath: Union[str, os.PathLike], key: Optional[str] = None\n) -&gt; Union[pd.DataFrame, dict, np.ndarray, None]:\n    \"\"\"\n    Load specific data from a file (supports selective loading for HDF5).\n\n    Parameters\n    ----------\n    filepath : Union[str, os.PathLike]\n        Path to the file to load. Can be string or path-like object.\n    key : Optional[str], optional\n        Specific key/dataset to load (only for HDF5). If None, loads all data.\n\n    Returns\n    -------\n    Union[pd.DataFrame, dict, np.ndarray, None]\n        Loaded data, or None if key not found in file.\n    \"\"\"\n    filepath_str = str(filepath)\n\n    if filepath_str.endswith(\".h5\"):\n        if key is None:\n            return _load_from_hdf5(filepath_str)\n        else:\n            with h5py.File(filepath_str, \"r\") as f:\n                if key in f:\n                    if isinstance(f[key], h5py.Group):\n                        return _load_dataframe_from_hdf5(f[key])\n                    else:\n                        return f[key][:]\n                elif f\"{key}_inhomogeneous\" in f or f\"{key}_pickled\" in f:\n                    return _load_inhomogeneous_data_hdf5(f, key)\n                else:\n                    # Silent return - empty files are expected\n                    return None\n    else:\n        with open(filepath_str, \"rb\") as f:\n            data = pickle.load(f)\n\n        if key is not None:\n            if isinstance(data, dict):\n                return data.get(key)  # Returns None if key not found\n            else:\n                return None  # Return None if key is requested but data is not a dict\n        else:\n            return data\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.main_loop","title":"<code>main_loop(basepath, save_path, func, overwrite=False, skip_if_error=False, format_type='pickle', **kwargs)</code>","text":"<p>main_loop: file management &amp; run function</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to session.</p> required <code>save_path</code> <code>str</code> <p>Path to save results to (will be created if it doesn't exist).</p> required <code>func</code> <code>Callable</code> <p>Function to run on each basepath in df (see run).</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing files in save_path. Defaults to False.</p> <code>False</code> <code>skip_if_error</code> <code>bool</code> <p>Whether to skip if an error occurs. Defaults to False.</p> <code>False</code> <code>format_type</code> <code>Literal['pickle', 'hdf5']</code> <p>File format to use for saving. Defaults to \"pickle\".</p> <code>'pickle'</code> <code>kwargs</code> <code>dict</code> <p>Keyword arguments to pass to func (see run).</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def main_loop(\n    basepath: str,\n    save_path: str,\n    func: Callable,\n    overwrite: bool = False,\n    skip_if_error: bool = False,\n    format_type: Literal[\"pickle\", \"hdf5\"] = \"pickle\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    main_loop: file management &amp; run function\n\n    Parameters\n    ----------\n    basepath : str\n        Path to session.\n    save_path : str\n        Path to save results to (will be created if it doesn't exist).\n    func : Callable\n        Function to run on each basepath in df (see run).\n    overwrite : bool, optional\n        Whether to overwrite existing files in save_path. Defaults to False.\n    skip_if_error : bool, optional\n        Whether to skip if an error occurs. Defaults to False.\n    format_type : Literal[\"pickle\", \"hdf5\"], optional\n        File format to use for saving. Defaults to \"pickle\".\n    kwargs : dict\n        Keyword arguments to pass to func (see run).\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # get file name from basepath\n    save_file = encode_file_path(basepath, save_path, format_type)\n\n    # if file exists and overwrite is False, skip\n    if os.path.exists(save_file) and not overwrite:\n        return\n\n    # calc some features\n    if skip_if_error:\n        try:\n            results = func(basepath, **kwargs)\n        except Exception:\n            traceback.print_exc()\n            print(f\"Error in {basepath}\")\n            return\n    else:\n        results = func(basepath, **kwargs)\n\n    # save file\n    if format_type == \"hdf5\":\n        _save_to_hdf5(results, save_file)\n    else:\n        with open(save_file, \"wb\") as f:\n            pickle.dump(results, f)\n</code></pre>"},{"location":"reference/neuro_py/process/batch_analysis/#neuro_py.process.batch_analysis.run","title":"<code>run(df, save_path, func, parallel=True, verbose=False, overwrite=False, skip_if_error=False, num_cores=None, format_type='pickle', **kwargs)</code>","text":"<p>Run a function on each basepath in the DataFrame and save results.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing a 'basepath' column.</p> required <code>save_path</code> <code>str</code> <p>Path to save results to (will be created if it doesn't exist).</p> required <code>func</code> <code>Callable</code> <p>Function to run on each basepath (see main_loop).</p> required <code>parallel</code> <code>bool</code> <p>Whether to run in parallel. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Whether to print progress. Defaults to False.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing files in save_path. Defaults to False.</p> <code>False</code> <code>skip_if_error</code> <code>bool</code> <p>Whether to skip processing if an error occurs. Defaults to False.</p> <code>False</code> <code>num_cores</code> <code>int</code> <p>Number of CPU cores to use (if None, will use all available cores). Defaults to None.</p> <code>None</code> <code>format_type</code> <code>Literal['pickle', 'hdf5']</code> <p>File format to use for saving. Defaults to \"pickle\".</p> <code>'pickle'</code> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to func.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/process/batch_analysis.py</code> <pre><code>def run(\n    df: pd.DataFrame,\n    save_path: str,\n    func: Callable,\n    parallel: bool = True,\n    verbose: bool = False,\n    overwrite: bool = False,\n    skip_if_error: bool = False,\n    num_cores: int = None,\n    format_type: Literal[\"pickle\", \"hdf5\"] = \"pickle\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run a function on each basepath in the DataFrame and save results.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame containing a 'basepath' column.\n    save_path : str\n        Path to save results to (will be created if it doesn't exist).\n    func : Callable\n        Function to run on each basepath (see main_loop).\n    parallel : bool, optional\n        Whether to run in parallel. Defaults to True.\n    verbose : bool, optional\n        Whether to print progress. Defaults to False.\n    overwrite : bool, optional\n        Whether to overwrite existing files in save_path. Defaults to False.\n    skip_if_error : bool, optional\n        Whether to skip processing if an error occurs. Defaults to False.\n    num_cores : int, optional\n        Number of CPU cores to use (if None, will use all available cores). Defaults to None.\n    format_type : Literal[\"pickle\", \"hdf5\"], optional\n        File format to use for saving. Defaults to \"pickle\".\n    kwargs : dict\n        Additional keyword arguments to pass to func.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # find sessions to run\n    basepaths = pd.unique(df.basepath)\n    # create save_path if it doesn't exist\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n    # run in parallel if parallel is True\n    if parallel:\n        # get number of cores\n        if num_cores is None:\n            num_cores = multiprocessing.cpu_count()\n        # run in parallel\n        Parallel(n_jobs=num_cores)(\n            delayed(main_loop)(\n                basepath,\n                save_path,\n                func,\n                overwrite,\n                skip_if_error,\n                format_type,\n                **kwargs,\n            )\n            for basepath in tqdm(basepaths)\n        )\n    else:\n        # run in serial\n        for basepath in tqdm(basepaths):\n            if verbose:\n                print(basepath)\n            # run main_loop on each basepath in df\n            main_loop(\n                basepath,\n                save_path,\n                func,\n                overwrite,\n                skip_if_error,\n                format_type,\n                **kwargs,\n            )\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/","title":"neuro_py.process.correlations","text":""},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.cch_conv","title":"<code>cch_conv(cch, W=30, HF=0.6)</code>","text":"<p>Convolve the cross-correlogram with a Gaussian window and calculate p-values.</p> <p>Parameters:</p> Name Type Description Default <code>cch</code> <code>ndarray</code> <p>The cross-correlogram data (1D array).</p> required <code>W</code> <code>int</code> <p>The width of the Gaussian window (default is 30).</p> <code>30</code> <code>HF</code> <code>float</code> <p>The height factor to modify the Gaussian peak (default is 0.6).</p> <code>0.6</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <ul> <li>pvals : array of p-values.</li> <li>pred : predicted values after convolution.</li> <li>qvals : q-values (1 - pvals).</li> </ul> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def cch_conv(\n    cch: np.ndarray, W: int = 30, HF: float = 0.6\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Convolve the cross-correlogram with a Gaussian window and calculate p-values.\n\n    Parameters\n    ----------\n    cch : np.ndarray\n        The cross-correlogram data (1D array).\n    W : int, optional\n        The width of the Gaussian window (default is 30).\n    HF : float, optional\n        The height factor to modify the Gaussian peak (default is 0.6).\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        - pvals : array of p-values.\n        - pred : predicted values after convolution.\n        - qvals : q-values (1 - pvals).\n    \"\"\"\n\n    SDG = W / 2\n    if round(SDG) == SDG:  # even W\n        win = local_gausskernel(SDG, 6 * SDG + 1)\n        cidx = int(SDG * 3 + 1)\n    else:\n        win = local_gausskernel(SDG, 6 * SDG + 2)\n        cidx = int(SDG * 3 + 1.5)\n    win[cidx - 1] = win[cidx - 1] * (1 - HF)\n    win = win / sum(win)\n    pred = local_firfilt(cch, win)\n    pvals = 1 - poisson.cdf(cch - 1, pred) - poisson.pmf(cch, pred) * 0.5\n    qvals = 1 - pvals\n    return pvals, pred, qvals\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.compute_AutoCorrs","title":"<code>compute_AutoCorrs(spks, binsize=0.001, nbins=100)</code>","text":"<p>Compute autocorrelations for spike trains.</p> <p>Parameters:</p> Name Type Description Default <code>spks</code> <code>ndarray</code> <p>Nested ndarrays where each array contains the spike times for one neuron.</p> required <code>binsize</code> <code>float</code> <p>The size of each bin in seconds, by default 0.001 (1 ms).</p> <code>0.001</code> <code>nbins</code> <code>int</code> <p>The number of bins for the autocorrelation, by default 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame where each column represents the autocorrelation of the corresponding neuron. The index is the time lag, and the values are the autocorrelations.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def compute_AutoCorrs(\n    spks: np.ndarray, binsize: float = 0.001, nbins: int = 100\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute autocorrelations for spike trains.\n\n    Parameters\n    ----------\n    spks : np.ndarray\n        Nested ndarrays where each array contains the spike times for one neuron.\n    binsize : float, optional\n        The size of each bin in seconds, by default 0.001 (1 ms).\n    nbins : int, optional\n        The number of bins for the autocorrelation, by default 100.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame where each column represents the autocorrelation of the corresponding neuron.\n        The index is the time lag, and the values are the autocorrelations.\n    \"\"\"\n    # First let's prepare a pandas dataframe to receive the data\n    times = np.arange(0, binsize * (nbins + 1), binsize) - (nbins * binsize) / 2\n    autocorrs = pd.DataFrame(index=times, columns=np.arange(len(spks)))\n\n    # Now we can iterate over the dictionnary of spikes\n    for i, s in enumerate(spks):\n        if len(s) == 0:\n            continue\n        # Explicitly convert to float64 array to ensure proper typing for numba jit\n        s_arr = np.asarray(s, dtype=np.float64)\n        # Calling the crossCorr function\n        autocorrs[i] = crossCorr(s_arr, s_arr, binsize, nbins)\n\n    # And don't forget to replace the 0 ms for 0\n    autocorrs.loc[0] = 0.0\n    return autocorrs\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.compute_cross_correlogram","title":"<code>compute_cross_correlogram(X, dt=1.0, window=0.5)</code>","text":"<p>Compute pairwise cross-correlograms between signals in an array.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>N-dimensional array of shape (n_signals, n_timepoints) representing the signals.</p> required <code>dt</code> <code>float</code> <p>Time step between samples in seconds, default is 1.0.</p> <code>1.0</code> <code>window</code> <code>float</code> <p>Window size in seconds for the cross-correlogram. The output will include values within +/- window from the center. If None, returns the full correlogram.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Pairwise cross-correlogram with time lags as the index and signal pairs as columns.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def compute_cross_correlogram(\n    X: np.ndarray, dt: float = 1.0, window: float = 0.5\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute pairwise cross-correlograms between signals in an array.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        N-dimensional array of shape (n_signals, n_timepoints) representing the signals.\n    dt : float, optional\n        Time step between samples in seconds, default is 1.0.\n    window : float, optional\n        Window size in seconds for the cross-correlogram. The output will include values\n        within +/- window from the center. If None, returns the full correlogram.\n\n    Returns\n    -------\n    pd.DataFrame\n        Pairwise cross-correlogram with time lags as the index and signal pairs as columns.\n    \"\"\"\n\n    crosscorrs = {}\n    pairs = list(itertools.combinations(np.arange(X.shape[0]), 2))\n    for i, j in pairs:\n        auc = signal.correlate(X[i], X[j])\n        times = signal.correlation_lags(len(X[i]), len(X[j])) * dt\n        # normalize by coeff\n        normalizer = np.sqrt((X[i] ** 2).sum(axis=0) * (X[j] ** 2).sum(axis=0))\n        auc /= normalizer\n\n        crosscorrs[(i, j)] = pd.Series(index=times, data=auc, dtype=\"float32\")\n    crosscorrs = pd.DataFrame.from_dict(crosscorrs)\n\n    if window is None:\n        return crosscorrs\n    else:\n        return crosscorrs[(crosscorrs.index &gt;= -window) &amp; (crosscorrs.index &lt;= window)]\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.event_triggered_cross_correlation","title":"<code>event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts, time_lags=None, window=[-0.5, 0.5], bin_width=0.005)</code>","text":"<p>Computes the cross-correlation between two signals at specific event times</p> <p>Parameters:</p> Name Type Description Default <code>event_times</code> <code>ndarray</code> <p>array of event times</p> required <code>signal1_data</code> <code>ndarray</code> <p>data of signal 1</p> required <code>signal1_ts</code> <code>ndarray</code> <p>timestamps of signal 1</p> required <code>signal2_data</code> <code>ndarray</code> <p>data of signal 2</p> required <code>signal2_ts</code> <code>ndarray</code> <p>timestamps of signal 2</p> required <code>time_lags</code> <code>Union[ndarray, None]</code> <p>array of time lags to compute correlation. If None, it will be computed automatically.</p> <code>None</code> <code>window</code> <code>list</code> <p>window to compute correlation. Default is [-0.5, 0.5]</p> <code>[-0.5, 0.5]</code> <code>bin_width</code> <code>float</code> <p>bin width to compute correlation. Ideally this should be the same as the sampling rate. Default is 0.005</p> <code>0.005</code> <p>Returns:</p> Name Type Description <code>correlation_lags</code> <code>ndarray</code> <p>array of time lags in ascending order (negative to positive)</p> <code>avg_correlation</code> <code>ndarray</code> <p>array of correlation values corresponding to each lag</p> Notes <p>The function computes cross-correlation between signal1 and signal2 around event times. The interpretation of lags is as follows:</p> <ul> <li>Negative lags: signal2 leads signal1 (signal2 peaks occur before signal1 peaks)</li> <li>Zero lag: signals are synchronized</li> <li>Positive lags: signal2 lags behind signal1 (signal2 peaks occur after signal1 peaks)</li> </ul> <p>Peak correlation at positive lag indicates signal2 is a delayed version of signal1. Peak correlation at negative lag indicates signal2 precedes or predicts signal1.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lags, corr = event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts)\n&gt;&gt;&gt; peak_lag = lags[np.argmax(np.abs(corr))]  # Find lag with maximum correlation\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def event_triggered_cross_correlation(\n    event_times: np.ndarray,\n    signal1_data: np.ndarray,\n    signal1_ts: np.ndarray,\n    signal2_data: np.ndarray,\n    signal2_ts: np.ndarray,\n    time_lags: Union[np.ndarray, None] = None,\n    window: list = [-0.5, 0.5],\n    bin_width: float = 0.005,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes the cross-correlation between two signals at specific event times\n\n    Parameters\n    ----------\n    event_times : np.ndarray\n        array of event times\n    signal1_data : np.ndarray\n        data of signal 1\n    signal1_ts : np.ndarray\n        timestamps of signal 1\n    signal2_data : np.ndarray\n        data of signal 2\n    signal2_ts : np.ndarray\n        timestamps of signal 2\n    time_lags : Union[np.ndarray, None], optional\n        array of time lags to compute correlation. If None, it will be computed automatically.\n    window : list, optional\n        window to compute correlation. Default is [-0.5, 0.5]\n    bin_width : float, optional\n        bin width to compute correlation. Ideally this should be the same as the sampling rate.\n        Default is 0.005\n\n    Returns\n    -------\n    correlation_lags : np.ndarray\n        array of time lags in ascending order (negative to positive)\n    avg_correlation : np.ndarray\n        array of correlation values corresponding to each lag\n\n    Notes\n    -----\n    The function computes cross-correlation between signal1 and signal2 around event times.\n    The interpretation of lags is as follows:\n\n    - **Negative lags**: signal2 leads signal1 (signal2 peaks occur before signal1 peaks)\n    - **Zero lag**: signals are synchronized\n    - **Positive lags**: signal2 lags behind signal1 (signal2 peaks occur after signal1 peaks)\n\n    Peak correlation at positive lag indicates signal2 is a delayed version of signal1.\n    Peak correlation at negative lag indicates signal2 precedes or predicts signal1.\n\n    Examples\n    --------\n    &gt;&gt;&gt; lags, corr = event_triggered_cross_correlation(event_times, signal1_data, signal1_ts, signal2_data, signal2_ts)\n    &gt;&gt;&gt; peak_lag = lags[np.argmax(np.abs(corr))]  # Find lag with maximum correlation\n    \"\"\"\n\n    if time_lags is None:\n        time_lags = np.arange(window[0], window[1], bin_width)\n\n    # Interpolate both signals at event times + all possible lags\n    n_events = len(event_times)\n    n_lags = len(time_lags)\n\n    # Handle empty event times case\n    if n_events == 0:\n        max_lag_samples = n_lags - 1\n        correlation_lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n            time_lags[1] - time_lags[0]\n        )\n        # Create zero correlation array\n        avg_correlation = np.zeros(2 * n_lags - 1)\n\n        # restrict to window\n        avg_correlation = avg_correlation[\n            (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n        ]\n        correlation_lags = correlation_lags[\n            (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n        ]\n\n        return correlation_lags, avg_correlation\n\n    # Create time matrix: events x lags\n    event_times_matrix = event_times[:, None] + time_lags[None, :]\n\n    # Interpolate both signals\n    signal1_matrix = np.interp(\n        event_times_matrix.flatten(), signal1_ts, signal1_data\n    ).reshape(n_events, n_lags)\n    signal2_matrix = np.interp(\n        event_times_matrix.flatten(), signal2_ts, signal2_data\n    ).reshape(n_events, n_lags)\n\n    # Compute cross-correlation for each event\n    correlations = _jit_event_corr(signal1_matrix, signal2_matrix)\n\n    # Average across events\n    avg_correlation = np.mean(correlations, axis=0)\n\n    # Create lag axis for the correlation result in ascending order\n    max_lag_samples = n_lags - 1\n    correlation_lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n        time_lags[1] - time_lags[0]\n    )\n    # Reverse the correlation array to match the ascending lag order\n    avg_correlation = avg_correlation[::-1]\n\n    # restrict to window\n    avg_correlation = avg_correlation[\n        (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n    ]\n    correlation_lags = correlation_lags[\n        (correlation_lags &gt;= window[0]) &amp; (correlation_lags &lt;= window[1])\n    ]\n\n    return correlation_lags, avg_correlation\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.local_firfilt","title":"<code>local_firfilt(x, W)</code>","text":"<p>Apply a FIR filter to the input signal x using the provided filter coefficients W.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The input signal to be filtered.</p> required <code>W</code> <code>ndarray</code> <p>The FIR filter coefficients.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The filtered signal.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def local_firfilt(x: np.ndarray, W: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply a FIR filter to the input signal x using the provided filter coefficients W.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        The input signal to be filtered.\n    W : np.ndarray\n        The FIR filter coefficients.\n\n    Returns\n    -------\n    np.ndarray\n        The filtered signal.\n    \"\"\"\n    C = int(len(W))\n    D = int(np.ceil(C / 2) - 1)\n    xx = [np.flipud(x[:C]), x, np.flipud(x[-C:])]\n    xx = list(itertools.chain(*xx))\n    Y = signal.lfilter(W, 1, xx)\n    Y = Y[C + D : len(Y) - C + D]\n    return Y\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.local_gausskernel","title":"<code>local_gausskernel(sigma, N)</code>","text":"<p>Generate a Gaussian kernel with the given standard deviation and size.</p> <p>Parameters:</p> Name Type Description Default <code>sigma</code> <code>float</code> <p>The standard deviation of the Gaussian.</p> required <code>N</code> <code>int</code> <p>The size of the kernel (number of points). Must be an odd number.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A 1D Gaussian kernel.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def local_gausskernel(sigma: float, N: int) -&gt; np.ndarray:\n    \"\"\"\n    Generate a Gaussian kernel with the given standard deviation and size.\n\n    Parameters\n    ----------\n    sigma : float\n        The standard deviation of the Gaussian.\n    N : int\n        The size of the kernel (number of points). Must be an odd number.\n\n    Returns\n    -------\n    np.ndarray\n        A 1D Gaussian kernel.\n    \"\"\"\n    x = np.arange(-(N - 1) / 2, ((N - 1) / 2) + 1)\n    k = 1 / (2 * np.pi * sigma) * np.exp(-(x**2 / 2 / sigma**2))\n    return k\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.pairwise_corr","title":"<code>pairwise_corr(X, method='pearson', pairs=None)</code>","text":"<p>Compute pairwise correlations between all rows of a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>2D numpy array of shape (n, p), where n is the number of rows (variables) and p is the number of columns (features).</p> required <code>method</code> <code>str</code> <p>Correlation method to use ('pearson', 'spearman', or 'kendall'), by default \"pearson\".</p> <code>'pearson'</code> <code>pairs</code> <code>ndarray</code> <p>Array of shape (m, 2) specifying the pairs of rows to compute correlations between. If None, computes correlations for all unique row pairs.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>ndarray</code> <p>Array of correlation coefficients.</p> <code>pval</code> <code>ndarray</code> <p>Array of p-values for the correlation tests.</p> <code>pairs</code> <code>ndarray</code> <p>Array of pairs (indices) for which correlations were computed.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is not 'pearson', 'spearman', or 'kendall'.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.random.rand(10, 5)\n&gt;&gt;&gt; rho, pval, pairs = pairwise_corr(X, method=\"spearman\")\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_corr(\n    X: np.ndarray, method: str = \"pearson\", pairs: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute pairwise correlations between all rows of a matrix.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        2D numpy array of shape (n, p), where n is the number of rows (variables) and p is the number of columns (features).\n    method : str, optional\n        Correlation method to use ('pearson', 'spearman', or 'kendall'), by default \"pearson\".\n    pairs : np.ndarray, optional\n        Array of shape (m, 2) specifying the pairs of rows to compute correlations between.\n        If None, computes correlations for all unique row pairs.\n\n    Returns\n    -------\n    rho : np.ndarray\n        Array of correlation coefficients.\n    pval : np.ndarray\n        Array of p-values for the correlation tests.\n    pairs : np.ndarray\n        Array of pairs (indices) for which correlations were computed.\n\n    Raises\n    ------\n    ValueError\n        If the method is not 'pearson', 'spearman', or 'kendall'.\n\n    Examples\n    -------\n    &gt;&gt;&gt; X = np.random.rand(10, 5)\n    &gt;&gt;&gt; rho, pval, pairs = pairwise_corr(X, method=\"spearman\")\n    \"\"\"\n    if pairs is None:\n        x = np.arange(0, X.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    rho = []\n    pval = []\n    for i, s in enumerate(pairs):\n        if method == \"pearson\":\n            rho_, pval_ = stats.pearsonr(X[s[0], :], X[s[1], :])\n        elif method == \"spearman\":\n            rho_, pval_ = stats.spearmanr(X[s[0], :], X[s[1], :])\n        elif method == \"kendall\":\n            rho_, pval_ = stats.kendalltau(X[s[0], :], X[s[1], :])\n        else:\n            raise ValueError(\"method must be pearson, spearman or kendall\")\n        rho.append(rho_)\n        pval.append(pval_)\n    return rho, pval, pairs\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.pairwise_cross_corr","title":"<code>pairwise_cross_corr(spks, binsize=0.001, nbins=100, return_index=False, pairs=None, deconvolve=False)</code>","text":"<p>Compute pairwise time-lagged cross-correlations between spike trains of different cells.</p> <p>Parameters:</p> Name Type Description Default <code>spks</code> <code>ndarray</code> <p>Nested numpy arrays, where each array contains the spike times for a cell.</p> required <code>binsize</code> <code>float</code> <p>The size of time bins in seconds. Default is 0.001 (1 ms).</p> <code>0.001</code> <code>nbins</code> <code>int</code> <p>Number of bins to use for the correlation window. Default is 100.</p> <code>100</code> <code>return_index</code> <code>bool</code> <p>Whether to return the index (pairs) of cells used for the correlation. Default is False.</p> <code>False</code> <code>pairs</code> <code>ndarray</code> <p>Precomputed list of pairs of cells (indices) to compute the cross-correlation for. If None, all unique pairs will be computed. Default is None.</p> <code>None</code> <code>deconvolve</code> <code>bool</code> <p>Whether to apply deconvolution when computing the cross-correlation. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>crosscorrs</code> <code>DataFrame</code> <p>A pandas DataFrame of shape (t, n_pairs), where t is the time axis and n_pairs are the pairs of cells.</p> <code>pairs</code> <code>(ndarray, optional)</code> <p>The pairs of cells for which cross-correlations were computed. Returned only if <code>return_index</code> is True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spks = np.array([np.random.rand(100), np.random.rand(100)])\n&gt;&gt;&gt; crosscorrs, pairs = pairwise_cross_corr(spks, binsize=0.01, nbins=50, return_index=True)\n</code></pre> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_cross_corr(\n    spks: np.ndarray,\n    binsize: float = 0.001,\n    nbins: int = 100,\n    return_index: bool = False,\n    pairs: Optional[np.ndarray] = None,\n    deconvolve: bool = False,\n) -&gt; Tuple[pd.DataFrame, Optional[np.ndarray]]:\n    \"\"\"\n    Compute pairwise time-lagged cross-correlations between spike trains of different cells.\n\n    Parameters\n    ----------\n    spks : np.ndarray\n        Nested numpy arrays, where each array contains the spike times for a cell.\n    binsize : float, optional\n        The size of time bins in seconds. Default is 0.001 (1 ms).\n    nbins : int, optional\n        Number of bins to use for the correlation window. Default is 100.\n    return_index : bool, optional\n        Whether to return the index (pairs) of cells used for the correlation. Default is False.\n    pairs : np.ndarray, optional\n        Precomputed list of pairs of cells (indices) to compute the cross-correlation for.\n        If None, all unique pairs will be computed. Default is None.\n    deconvolve : bool, optional\n        Whether to apply deconvolution when computing the cross-correlation. Default is False.\n\n    Returns\n    -------\n    crosscorrs : pd.DataFrame\n        A pandas DataFrame of shape (t, n_pairs), where t is the time axis and n_pairs are the pairs of cells.\n    pairs : np.ndarray, optional\n        The pairs of cells for which cross-correlations were computed. Returned only if `return_index` is True.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spks = np.array([np.random.rand(100), np.random.rand(100)])\n    &gt;&gt;&gt; crosscorrs, pairs = pairwise_cross_corr(spks, binsize=0.01, nbins=50, return_index=True)\n    \"\"\"\n    # Get unique combo without repeats\n    if pairs is None:\n        x = np.arange(0, spks.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    # prepare a pandas dataframe to receive the data\n    times = np.linspace(-(nbins * binsize) / 2, (nbins * binsize) / 2, nbins + 1)\n\n    def compute_crosscorr(pair):\n        i, j = pair\n        # Explicitly convert to float64 arrays to ensure proper typing for numba jit\n        spk_i = np.asarray(spks[i], dtype=np.float64)\n        spk_j = np.asarray(spks[j], dtype=np.float64)\n        crosscorr = crossCorr(spk_i, spk_j, binsize, nbins)\n        return crosscorr\n\n    def compute_crosscorr_deconvolve(pair):\n        i, j = pair\n        # Explicitly convert to float64 arrays to ensure proper typing for numba jit\n        spk_i = np.asarray(spks[i], dtype=np.float64)\n        spk_j = np.asarray(spks[j], dtype=np.float64)\n        crosscorr, _ = deconvolve_peth(spk_i, spk_j, binsize, nbins)\n        return crosscorr\n\n    if deconvolve:\n        crosscorrs = [compute_crosscorr_deconvolve(pair) for pair in pairs]\n    else:\n        crosscorrs = [compute_crosscorr(pair) for pair in pairs]\n\n    crosscorrs = pd.DataFrame(\n        index=times,\n        data=np.array(crosscorrs).T,\n        columns=np.arange(len(pairs)),\n    )\n\n    if return_index:\n        return crosscorrs, pairs\n    else:\n        return crosscorrs\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.pairwise_event_triggered_cross_correlation","title":"<code>pairwise_event_triggered_cross_correlation(event_times, signals_data, signals_ts, time_lags=None, window=[-0.5, 0.5], bin_width=0.005, pairs=None, n_jobs=-1)</code>","text":"<p>Computes event-triggered cross-correlation for all unique signal pairs.</p> <p>Parameters:</p> Name Type Description Default <code>event_times</code> <code>ndarray</code> <p>Array of event times.</p> required <code>signals_data</code> <code>ndarray</code> <p>2D array (n_signals, n_samples) of signal data.</p> required <code>signals_ts</code> <code>ndarray</code> <p>Array of timestamps for each signal.</p> required <code>time_lags</code> <code>Union[ndarray, None]</code> <p>Array of time lags to compute correlation. If None, computed automatically.</p> <code>None</code> <code>window</code> <code>list</code> <p>Window to compute correlation. Default is [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>bin_width</code> <code>float</code> <p>Bin width to compute correlation. Default is 0.005.</p> <code>0.005</code> <code>pairs</code> <code>Optional[ndarray]</code> <p>Array of shape (n_pairs, 2) specifying pairs of signals to compute correlations for. If None, computes correlations for all unique signal pairs.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>correlation_lags</code> <code>ndarray</code> <p>Array of time lags.</p> <code>avg_correlation</code> <code>ndarray</code> <p>Array of shape (n_pairs, n_lags) with average correlation for each pair.</p> <code>pairs</code> <code>ndarray</code> <p>Array of shape (n_pairs, 2) with indices of signal pairs.</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_event_triggered_cross_correlation(\n    event_times: np.ndarray,\n    signals_data: np.ndarray,\n    signals_ts: np.ndarray,\n    time_lags: Union[np.ndarray, None] = None,\n    window: list = [-0.5, 0.5],\n    bin_width: float = 0.005,\n    pairs: Optional[np.ndarray] = None,\n    n_jobs: int = -1,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes event-triggered cross-correlation for all unique signal pairs.\n\n    Parameters\n    ----------\n    event_times : np.ndarray\n        Array of event times.\n    signals_data : np.ndarray\n        2D array (n_signals, n_samples) of signal data.\n    signals_ts : np.ndarray\n        Array of timestamps for each signal.\n    time_lags : Union[np.ndarray, None], optional\n        Array of time lags to compute correlation. If None, computed automatically.\n    window : list, optional\n        Window to compute correlation. Default is [-0.5, 0.5].\n    bin_width : float, optional\n        Bin width to compute correlation. Default is 0.005.\n    pairs : Optional[np.ndarray], optional\n        Array of shape (n_pairs, 2) specifying pairs of signals to compute correlations for.\n        If None, computes correlations for all unique signal pairs.\n\n    Returns\n    -------\n    correlation_lags : np.ndarray\n        Array of time lags.\n    avg_correlation : np.ndarray\n        Array of shape (n_pairs, n_lags) with average correlation for each pair.\n    pairs : np.ndarray\n        Array of shape (n_pairs, 2) with indices of signal pairs.\n    \"\"\"\n\n    if pairs is None:\n        n_signals = signals_data.shape[0]\n        pairs = np.array(list(itertools.combinations(np.arange(n_signals), 2)))\n\n    def compute_pair(i, j):\n        lags, corr = event_triggered_cross_correlation(\n            event_times,\n            signals_data[i, :],\n            signals_ts,\n            signals_data[j, :],\n            signals_ts,\n            time_lags=time_lags,\n            window=window,\n            bin_width=bin_width,\n        )\n        return corr\n\n    results = Parallel(n_jobs=n_jobs, prefer=\"processes\")(\n        delayed(compute_pair)(i, j) for i, j in pairs\n    )\n    avg_correlation = np.vstack(results)\n\n    # Calculate lags directly (avoid extra function call)\n    if time_lags is None:\n        time_lags_arr = np.arange(window[0], window[1], bin_width)\n    else:\n        time_lags_arr = time_lags\n    n_lags = len(time_lags_arr)\n    max_lag_samples = n_lags - 1\n    lags = np.arange(-max_lag_samples, max_lag_samples + 1) * (\n        time_lags_arr[1] - time_lags_arr[0]\n    )\n    lags = lags[(lags &gt;= window[0]) &amp; (lags &lt;= window[1])]\n\n    return lags, avg_correlation, pairs\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.pairwise_spatial_corr","title":"<code>pairwise_spatial_corr(X, return_index=False, pairs=None)</code>","text":"<p>Compute pairwise spatial correlations between cells' spatial maps.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A 3D numpy array of shape (n_cells, n_space, n_space) representing the spatial maps of cells.</p> required <code>return_index</code> <code>bool</code> <p>If True, returns the indices of the cell pairs used for the correlation.</p> <code>False</code> <code>pairs</code> <code>ndarray</code> <p>Array of cell pairs for which to compute the correlation. If not provided, all unique pairs are used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>spatial_corr</code> <code>ndarray</code> <p>Array containing the Pearson correlation coefficients for each pair of cells.</p> <code>pairs</code> <code>(ndarray, optional)</code> <p>Array of cell pairs used for the correlation (if return_index is True).</p> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def pairwise_spatial_corr(\n    X: np.ndarray, return_index: bool = False, pairs: np.ndarray = None\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Compute pairwise spatial correlations between cells' spatial maps.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A 3D numpy array of shape (n_cells, n_space, n_space) representing the spatial maps of cells.\n    return_index : bool, optional\n        If True, returns the indices of the cell pairs used for the correlation.\n    pairs : np.ndarray, optional\n        Array of cell pairs for which to compute the correlation. If not provided, all unique pairs are used.\n\n    Returns\n    -------\n    spatial_corr : np.ndarray\n        Array containing the Pearson correlation coefficients for each pair of cells.\n    pairs : np.ndarray, optional\n        Array of cell pairs used for the correlation (if return_index is True).\n    \"\"\"\n    # Get unique combo without repeats\n    if pairs is None:\n        x = np.arange(0, X.shape[0])\n        pairs = np.array(list(itertools.combinations(x, 2)))\n\n    spatial_corr = []\n    # Now we can iterate over spikes\n    for i, s in enumerate(pairs):\n        # Calling the crossCorr function\n        x1 = X[s[0], :, :].flatten()\n        x2 = X[s[1], :, :].flatten()\n        bad_idx = np.isnan(x1) | np.isnan(x2)\n        spatial_corr.append(np.corrcoef(x1[~bad_idx], x2[~bad_idx])[0, 1])\n\n    if return_index:\n        return np.array(spatial_corr), pairs\n    else:\n        return np.array(spatial_corr)\n</code></pre>"},{"location":"reference/neuro_py/process/correlations/#neuro_py.process.correlations.sig_mod","title":"<code>sig_mod(cch, binsize=0.005, sig_window=0.2, alpha=0.001, W=30)</code>","text":"<p>Assess the significance of cross-correlogram values using Poisson statistics.</p> <p>Parameters:</p> Name Type Description Default <code>cch</code> <code>ndarray</code> <p>The cross-correlogram data (1D array).</p> required <code>binsize</code> <code>float</code> <p>The size of each bin in seconds (default is 0.005).</p> <code>0.005</code> <code>sig_window</code> <code>float</code> <p>The window size to consider for significance (default is 0.2).</p> <code>0.2</code> <code>alpha</code> <code>float</code> <p>The significance level (default is 0.001).</p> <code>0.001</code> <code>W</code> <code>int</code> <p>The width of the Gaussian window for convolution (default is 30).</p> <code>30</code> <p>Returns:</p> Type Description <code>tuple[bool, ndarray, ndarray, ndarray, ndarray]</code> <ul> <li>sig : boolean indicating whether the cross-correlogram is significant.</li> <li>hiBound : upper bound for significance.</li> <li>loBound : lower bound for significance.</li> <li>pvals : array of p-values.</li> <li>pred : predicted values after convolution.</li> </ul> Source code in <code>neuro_py/process/correlations.py</code> <pre><code>def sig_mod(\n    cch: np.ndarray,\n    binsize: float = 0.005,\n    sig_window: float = 0.2,\n    alpha: float = 0.001,\n    W: int = 30,\n) -&gt; Tuple[bool, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Assess the significance of cross-correlogram values using Poisson statistics.\n\n    Parameters\n    ----------\n    cch : np.ndarray\n        The cross-correlogram data (1D array).\n    binsize : float, optional\n        The size of each bin in seconds (default is 0.005).\n    sig_window : float, optional\n        The window size to consider for significance (default is 0.2).\n    alpha : float, optional\n        The significance level (default is 0.001).\n    W : int, optional\n        The width of the Gaussian window for convolution (default is 30).\n\n    Returns\n    -------\n    tuple[bool, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n        - sig : boolean indicating whether the cross-correlogram is significant.\n        - hiBound : upper bound for significance.\n        - loBound : lower bound for significance.\n        - pvals : array of p-values.\n        - pred : predicted values after convolution.\n    \"\"\"\n    # check and correct for negative values\n    if np.any(cch &lt; 0):\n        cch = cch + np.abs(min(cch))\n\n    pvals, pred, qvals = cch_conv(cch, W)\n\n    nBonf = int(sig_window / binsize) * 2\n    hiBound = poisson.ppf(1 - alpha / nBonf, pred)\n    loBound = poisson.ppf(alpha / nBonf, pred)\n\n    center_bins = np.arange(\n        int(len(cch) / 2 - 0.1 / binsize), int(len(cch) / 2 + 0.1 / binsize)\n    )\n    # at least 2 bins more extreme than bound to be sig\n    sig = (sum(cch[center_bins] &gt; max(hiBound)) &gt; 2) | (\n        sum(cch[center_bins] &lt; min(loBound)) &gt; 2\n    )\n    return sig, hiBound, loBound, pvals, pred\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/","title":"neuro_py.process.intervals","text":""},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals._find_intersecting_intervals","title":"<code>_find_intersecting_intervals(set1, set2)</code>","text":"<p>Find the amount of time two sets of intervals are intersecting each other for each interval in set1.</p> <p>Parameters:</p> Name Type Description Default <code>set1</code> <code>ndarray</code> <p>An array of intervals represented as pairs of start and end times.</p> required <code>set2</code> <code>ndarray</code> <p>An array of intervals represented as pairs of start and end times.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>A list of floats, where each float represents the amount of time the corresponding interval in set1 intersects with any interval in set2.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>@jit(nopython=True)\ndef _find_intersecting_intervals(set1: np.ndarray, set2: np.ndarray) -&gt; List[float]:\n    \"\"\"\n    Find the amount of time two sets of intervals are intersecting each other for each interval in set1.\n\n    Parameters\n    ----------\n    set1 : ndarray\n        An array of intervals represented as pairs of start and end times.\n    set2 : ndarray\n        An array of intervals represented as pairs of start and end times.\n\n    Returns\n    -------\n    list of float\n        A list of floats, where each float represents the amount of time the\n        corresponding interval in set1 intersects with any interval in set2.\n    \"\"\"\n    intersecting_intervals = []\n    for i, (start1, end1) in enumerate(set1):\n        # Check if any of the intervals in set2 intersect with the current interval in set1\n        for start2, end2 in set2:\n            if start2 &lt;= end1 and end2 &gt;= start1:\n                # Calculate the amount of intersection between the two intervals\n                intersection = min(end1, end2) - max(start1, start2)\n                intersecting_intervals.append(intersection)\n                break\n        else:\n            intersecting_intervals.append(0)  # No intersection found\n\n    return intersecting_intervals\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.find_intersecting_intervals","title":"<code>find_intersecting_intervals(set1, set2, return_indices=True)</code>","text":"<p>Find the amount of time two sets of intervals are intersecting each other for each intersection.</p> <p>Parameters:</p> Name Type Description Default <code>set1</code> <code>nelpy EpochArray</code> <p>The first set of intervals to check for intersections.</p> required <code>set2</code> <code>nelpy EpochArray</code> <p>The second set of intervals to check for intersections.</p> required <code>return_indices</code> <code>bool</code> <p>If True, return the indices of the intervals in set2 that intersect with each interval in set1. If False, return the amount of time each interval in set1 intersects with any interval in set2.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[ndarray, List[bool]]</code> <p>If return_indices is True, returns a boolean array indicating whether each interval in set1 intersects with any interval in set2. If return_indices is False, returns a NumPy array with the amount of time each interval in set1 intersects with any interval in set2.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n&gt;&gt;&gt; set2 = nel.EpochArray([(2, 4), (6, 8)])\n&gt;&gt;&gt; find_intersecting_intervals(set1, set2)\n[True, True, False]\n&gt;&gt;&gt; find_intersecting_intervals(set1, set2, return_indices=False)\n[1, 2, 0]\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def find_intersecting_intervals(\n    set1: nel.EpochArray, set2: nel.EpochArray, return_indices: bool = True\n) -&gt; Union[np.ndarray, List[bool]]:\n    \"\"\"\n    Find the amount of time two sets of intervals are intersecting each other for each intersection.\n\n    Parameters\n    ----------\n    set1 : nelpy EpochArray\n        The first set of intervals to check for intersections.\n    set2 : nelpy EpochArray\n        The second set of intervals to check for intersections.\n    return_indices : bool, optional\n        If True, return the indices of the intervals in set2 that intersect with each interval in set1.\n        If False, return the amount of time each interval in set1 intersects with any interval in set2.\n\n    Returns\n    -------\n    Union[np.ndarray, List[bool]]\n        If return_indices is True, returns a boolean array indicating whether each interval in set1 intersects with any interval in set2.\n        If return_indices is False, returns a NumPy array with the amount of time each interval in set1 intersects with any interval in set2.\n\n    Examples\n    --------\n    &gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n    &gt;&gt;&gt; set2 = nel.EpochArray([(2, 4), (6, 8)])\n    &gt;&gt;&gt; find_intersecting_intervals(set1, set2)\n    [True, True, False]\n    &gt;&gt;&gt; find_intersecting_intervals(set1, set2, return_indices=False)\n    [1, 2, 0]\n    \"\"\"\n    if not isinstance(set1, core.IntervalArray) &amp; isinstance(set2, core.IntervalArray):\n        raise ValueError(\"only EpochArrays are supported\")\n\n    intersection = np.array(_find_intersecting_intervals(set1.data, set2.data))\n    if return_indices:\n        return intersection &gt; 0\n    return intersection\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.find_intersection_intervals_strict","title":"<code>find_intersection_intervals_strict(set1, set2)</code>","text":"<p>Find the intervals in set1 that are completely contained within set2.</p> <p>Parameters:</p> Name Type Description Default <code>set1</code> <code>nelpy EpochArray</code> <p>The first set of intervals to check for intersections.</p> required <code>set2</code> <code>nelpy EpochArray</code> <p>The second set of intervals to check for intersections.</p> required <p>Returns:</p> Type Description <code>nelpy EpochArray</code> <p>An EpochArray containing the intervals in set1 which are completely contained within set2.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n&gt;&gt;&gt; set2 = nel.EpochArray([(0, 4), (6, 8)])\n&gt;&gt;&gt; find_intersection_intervals_strict(set1, set2)\nEpochArray([[1, 3]])\n</code></pre> Notes <p>Common use cases: - Finding theta cycles (set1) that are completely within running periods (set2) - Finding SWRs (set1) that are completely within NREM periods (set2) - Generally useful when you don't want partial overlaps created by intersection of set1 &amp; set2</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def find_intersection_intervals_strict(\n    set1: nel.EpochArray, set2: nel.EpochArray\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Find the intervals in set1 that are completely contained within set2.\n\n    Parameters\n    ----------\n    set1 : nelpy EpochArray\n        The first set of intervals to check for intersections.\n    set2 : nelpy EpochArray\n        The second set of intervals to check for intersections.\n    Returns\n    -------\n    nelpy EpochArray\n        An EpochArray containing the intervals in set1 which are completely contained within set2.\n\n    Examples\n    --------\n    &gt;&gt;&gt; set1 = nel.EpochArray([(1, 3), (5, 7), (9, 10)])\n    &gt;&gt;&gt; set2 = nel.EpochArray([(0, 4), (6, 8)])\n    &gt;&gt;&gt; find_intersection_intervals_strict(set1, set2)\n    EpochArray([[1, 3]])\n\n    Notes\n    -----\n    Common use cases:\n    - Finding theta cycles (set1) that are completely within running periods (set2)\n    - Finding SWRs (set1) that are completely within NREM periods (set2)\n    - Generally useful when you don't want partial overlaps created by intersection of set1 &amp; set2\n    \"\"\"\n    overlap = find_intersecting_intervals(set1, set2, return_indices=False)\n    out = nel.EpochArray(set1.data[set1.lengths == overlap])\n    out._domain = set1.domain\n    return out\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.find_interval","title":"<code>find_interval(logical)</code>","text":"<p>Find consecutive intervals of True values in a list of boolean values.</p> <p>Parameters:</p> Name Type Description Default <code>logical</code> <code>List[bool]</code> <p>The list of boolean values.</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int]]</code> <p>A list of tuples representing the start and end indices of each consecutive interval of True values in the logical list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; find_interval([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])\n[(2, 4), (6, 7), (10, 11)]\n&gt;&gt;&gt; find_interval([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n[(0, 2), (4, 5), (9, 10)]\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def find_interval(logical: List[bool]) -&gt; List[Tuple[int, int]]:\n    \"\"\"\n    Find consecutive intervals of True values in a list of boolean values.\n\n    Parameters\n    ----------\n    logical : List[bool]\n        The list of boolean values.\n\n    Returns\n    -------\n    List[Tuple[int, int]]\n        A list of tuples representing the start and end indices of each consecutive interval of True values in the logical list.\n\n    Examples\n    --------\n    &gt;&gt;&gt; find_interval([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])\n    [(2, 4), (6, 7), (10, 11)]\n    &gt;&gt;&gt; find_interval([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n    [(0, 2), (4, 5), (9, 10)]\n    \"\"\"\n    intervals = []\n    start = None\n    for i, value in enumerate(logical):\n        if value and start is None:\n            start = i\n        elif not value and start is not None:\n            intervals.append((start, i - 1))\n            start = None\n    if start is not None:\n        intervals.append((start, len(logical) - 1))\n    return intervals\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.get_overlapping_intervals","title":"<code>get_overlapping_intervals(start, stop, interval_width, slideby)</code>","text":"<p>Generate overlapping intervals within a specified time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float</code> <p>The start time of the time range.</p> required <code>stop</code> <code>float</code> <p>The stop time of the time range.</p> required <code>interval_width</code> <code>float</code> <p>The width of each interval in seconds.</p> required <code>slideby</code> <code>float</code> <p>The amount to slide the interval by in seconds.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array containing (start, stop) pairs for all overlapping intervals.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_overlapping_intervals(0, 10, 2, 1)\narray([[0, 2],\n    [1, 3],\n    [2, 4],\n    [3, 5],\n    [4, 6],\n    [5, 7],\n    [6, 8],\n    [7, 9]])\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def get_overlapping_intervals(\n    start: float, stop: float, interval_width: float, slideby: float\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate overlapping intervals within a specified time range.\n\n    Parameters\n    ----------\n    start : float\n        The start time of the time range.\n    stop : float\n        The stop time of the time range.\n    interval_width : float\n        The width of each interval in seconds.\n    slideby : float\n        The amount to slide the interval by in seconds.\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array containing (start, stop) pairs for all overlapping intervals.\n\n    Examples\n    --------\n    &gt;&gt;&gt; get_overlapping_intervals(0, 10, 2, 1)\n    array([[0, 2],\n        [1, 3],\n        [2, 4],\n        [3, 5],\n        [4, 6],\n        [5, 7],\n        [6, 8],\n        [7, 9]])\n    \"\"\"\n    starts = np.arange(start, stop - interval_width, slideby)\n    stops = starts + interval_width\n    return np.column_stack((starts, stops))\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.in_intervals","title":"<code>in_intervals(timestamps, intervals, return_interval=False, shift=False)</code>","text":"<p>Find which timestamps fall within the given intervals.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>An array of timestamp values. Assumes sorted.</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <code>return_interval</code> <code>(bool, optional(default=False))</code> <p>If True, return the index of the interval to which each timestamp belongs.</p> <code>False</code> <code>shift</code> <code>(bool, optional(default=False))</code> <p>If True, return the shifted timestamps</p> <code>False</code> <p>Returns:</p> Name Type Description <code>in_interval</code> <code>ndarray</code> <p>A logical index indicating which timestamps fall within the intervals.</p> <code>interval</code> <code>(ndarray, optional)</code> <p>A ndarray indicating for each timestamps which interval it was within.</p> <code>shifted_timestamps</code> <code>(ndarray, optional)</code> <p>The shifted timestamps</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n&gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n&gt;&gt;&gt; in_intervals(timestamps, intervals)\narray([False,  True,  True,  True,  True,  True,  True, False])\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([nan,  0.,  0.,  0.,  1.,  1.,  1., nan]))\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, shift=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([0, 1, 2, 2, 3, 4]))\n</code></pre> <pre><code>&gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True, shift=True)\n(array([False,  True,  True,  True,  True,  True,  True, False]),\narray([0, 0, 0, 1, 1, 1]),\narray([0, 1, 2, 2, 3, 4]))\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def in_intervals(\n    timestamps: np.ndarray,\n    intervals: np.ndarray,\n    return_interval: bool = False,\n    shift: bool = False,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]]:\n    \"\"\"\n    Find which timestamps fall within the given intervals.\n\n    Parameters\n    ----------\n    timestamps : ndarray\n        An array of timestamp values. Assumes sorted.\n    intervals : ndarray\n        An array of time intervals, represented as pairs of start and end times.\n    return_interval : bool, optional (default=False)\n        If True, return the index of the interval to which each timestamp belongs.\n    shift : bool, optional (default=False)\n        If True, return the shifted timestamps\n\n    Returns\n    -------\n    in_interval : ndarray\n        A logical index indicating which timestamps fall within the intervals.\n    interval : ndarray, optional\n        A ndarray indicating for each timestamps which interval it was within.\n    shifted_timestamps : ndarray, optional\n        The shifted timestamps\n\n    Examples\n    --------\n    &gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n    &gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n    &gt;&gt;&gt; in_intervals(timestamps, intervals)\n    array([False,  True,  True,  True,  True,  True,  True, False])\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1., nan]))\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, shift=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([0, 1, 2, 2, 3, 4]))\n\n    &gt;&gt;&gt; in_intervals(timestamps, intervals, return_interval=True, shift=True)\n    (array([False,  True,  True,  True,  True,  True,  True, False]),\n    array([0, 0, 0, 1, 1, 1]),\n    array([0, 1, 2, 2, 3, 4]))\n    \"\"\"\n    in_interval = np.zeros(timestamps.shape, dtype=np.bool_)\n    interval = np.full(timestamps.shape, np.nan)\n\n    for i, (start, end) in enumerate(intervals):\n        # Find the leftmost index of a timestamp that is &gt;= start\n        left = np.searchsorted(timestamps, start, side=\"left\")\n        if left == len(timestamps):\n            # If start is greater than all timestamps, skip this interval\n            continue\n        # Find the rightmost index of a timestamp that is &lt;= end\n        right = np.searchsorted(timestamps, end, side=\"right\")\n        if right == left:\n            # If there are no timestamps in the interval, skip it\n            continue\n        # Mark the timestamps in the interval\n        in_interval[left:right] = True\n        interval[left:right] = i\n\n    if shift:\n        # Restrict to the timestamps that fall within the intervals\n        interval = interval[in_interval].astype(int)\n\n        # Calculate shifts based on intervals\n        shifts = np.insert(np.cumsum(intervals[1:, 0] - intervals[:-1, 1]), 0, 0)[\n            interval\n        ]\n\n        # Apply shifts to timestamps\n        shifted_timestamps = timestamps[in_interval] - shifts - intervals[0, 0]\n\n    if return_interval and shift:\n        return in_interval, interval, shifted_timestamps\n\n    if return_interval:\n        return in_interval, interval\n\n    if shift:\n        return in_interval, shifted_timestamps\n\n    return in_interval\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.in_intervals_interval","title":"<code>in_intervals_interval(timestamps, intervals)</code>","text":"<p>for each timestamps value, the index of the interval to which it belongs (nan = none)</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>An array of timestamp values. assumes sorted</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <p>A ndarray indicating for each timestamps which interval it was within.</p> <code>Note</code> <code>produces same result as in_intervals with return_interval=True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n&gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n&gt;&gt;&gt; in_intervals_interval(timestamps, intervals)\narray([nan,  0,  0,  0,  1,  1,  1, nan])\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>@jit(nopython=True, parallel=True)\ndef in_intervals_interval(timestamps: np.ndarray, intervals: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    for each timestamps value, the index of the interval to which it belongs (nan = none)\n\n    Parameters\n    ----------\n    timestamps : ndarray\n        An array of timestamp values. assumes sorted\n    intervals : ndarray\n        An array of time intervals, represented as pairs of start and end times.\n\n    Returns\n    -------\n    ndarray\n        A ndarray indicating for each timestamps which interval it was within.\n\n    Note: produces same result as in_intervals with return_interval=True\n\n    Examples\n    --------\n    &gt;&gt;&gt; timestamps = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n    &gt;&gt;&gt; intervals = np.array([[2, 4], [5, 7]])\n    &gt;&gt;&gt; in_intervals_interval(timestamps, intervals)\n    array([nan,  0,  0,  0,  1,  1,  1, nan])\n    \"\"\"\n    in_interval = np.full(timestamps.shape, np.nan)\n    for i in numba.prange(intervals.shape[0]):\n        start, end = intervals[i]\n        mask = (timestamps &gt;= start) &amp; (timestamps &lt;= end)\n        in_interval[mask] = i\n\n    return in_interval\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.overlap_intersect","title":"<code>overlap_intersect(epoch, interval, return_indices=True)</code>","text":"<p>Returns the epochs with overlap with the given interval.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The epochs to check.</p> required <code>interval</code> <code>IntervalArray</code> <p>The interval to check for overlap.</p> required <code>return_indices</code> <code>bool</code> <p>If True, returns the indices of the overlapping epochs. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>The epochs with overlap with the interval.</p> <code>(Tuple[EpochArray, ndarray], optional)</code> <p>If <code>return_indices</code> is True, also returns the indices of the overlapping epochs.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def overlap_intersect(\n    epoch: nel.EpochArray, interval: nel.IntervalArray, return_indices: bool = True\n) -&gt; Union[nel.EpochArray, Tuple[nel.EpochArray, np.ndarray]]:\n    \"\"\"\n    Returns the epochs with overlap with the given interval.\n\n    Parameters\n    ----------\n    epoch : nelpy.EpochArray\n        The epochs to check.\n    interval : nelpy.IntervalArray\n        The interval to check for overlap.\n    return_indices : bool, optional\n        If True, returns the indices of the overlapping epochs. Default is True.\n\n    Returns\n    -------\n    nelpy.EpochArray\n        The epochs with overlap with the interval.\n    Tuple[nelpy.EpochArray, np.ndarray], optional\n        If `return_indices` is True, also returns the indices of the overlapping epochs.\n    \"\"\"\n    new_intervals = []\n    indices = []\n    for epa in epoch:\n        if any((interval.starts &lt; epa.stop) &amp; (interval.stops &gt; epa.start)):\n            new_intervals.append([epa.start, epa.stop])\n            cand_ep_idx = np.where(\n                (interval.starts &lt; epa.stop) &amp; (interval.stops &gt; epa.start)\n            )\n            indices.append(cand_ep_idx[0][0])\n    out = type(epoch)(new_intervals)\n    out._domain = epoch.domain\n    if return_indices:\n        return out, indices\n    return out\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.randomize_epochs","title":"<code>randomize_epochs(epoch, randomize_each=True, start_stop=None)</code>","text":"<p>Randomly shifts the epochs of a EpochArray object and wraps them around the original time boundaries.</p> <p>This method takes a EpochArray object as input, and can either randomly shift each epoch by a different amount (if <code>randomize_each</code> is True) or shift all the epochs by the same amount (if <code>randomize_each</code> is False). In either case, the method wraps the shifted epochs around the original time boundaries to make sure they remain within the original time range. It then returns the modified EpochArray object.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The EpochArray object whose epochs should be shifted and wrapped.</p> required <code>randomize_each</code> <code>bool</code> <p>If True, each epoch will be shifted by a different random amount. If False, all the epochs will be shifted by the same random amount. Defaults to True.</p> <code>True</code> <code>start_stop</code> <code>array</code> <p>If not None, time support will be taken from start_stop</p> <code>None</code> <p>Returns:</p> Name Type Description <code>new_epochs</code> <code>EpochArray</code> <p>The modified EpochArray object with the shifted and wrapped epochs.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def randomize_epochs(\n    epoch: EpochArray,\n    randomize_each: bool = True,\n    start_stop: Optional[np.ndarray] = None,\n) -&gt; EpochArray:\n    \"\"\"\n    Randomly shifts the epochs of a EpochArray object and wraps them around the original time boundaries.\n\n    This method takes a EpochArray object as input, and can either randomly shift each epoch by a different amount\n    (if `randomize_each` is True) or shift all the epochs by the same amount (if `randomize_each` is False).\n    In either case, the method wraps the shifted epochs around the original time boundaries to make sure they remain\n    within the original time range. It then returns the modified EpochArray object.\n\n    Parameters\n    ----------\n    epoch : EpochArray\n        The EpochArray object whose epochs should be shifted and wrapped.\n    randomize_each : bool, optional\n        If True, each epoch will be shifted by a different random amount.\n        If False, all the epochs will be shifted by the same random amount. Defaults to True.\n    start_stop : array, optional\n        If not None, time support will be taken from start_stop\n\n    Returns\n    -------\n    new_epochs : EpochArray\n        The modified EpochArray object with the shifted and wrapped epochs.\n    \"\"\"\n\n    def wrap_intervals(intervals, start, stop):\n        idx = np.any(intervals &gt; stop, axis=1)\n        intervals[idx] = intervals[idx] - stop + start\n\n        idx = np.any(intervals &lt; start, axis=1)\n        intervals[idx] = intervals[idx] - start + stop\n        return intervals\n\n    new_epochs = epoch.copy()\n\n    if start_stop is None:\n        start = new_epochs.start\n        stop = new_epochs.stop\n    else:\n        start, stop = start_stop\n\n    if randomize_each:\n        # Randomly shift each epoch while keeping intervals within bounds\n        min_shifts = start - new_epochs.data[:, 0]\n        max_shifts = stop - new_epochs.data[:, 1]\n        if np.any(min_shifts &gt; max_shifts):\n            raise ValueError(\"start_stop must fully cover epoch intervals\")\n\n        random_order = np.random.uniform(min_shifts, max_shifts)\n        new_intervals = new_epochs.data + np.expand_dims(random_order, axis=1)\n        new_epochs._data = wrap_intervals(new_intervals, start, stop)\n    else:\n        # Shift all the epochs by the same amount while keeping within bounds\n        min_shifts = start - new_epochs.data[:, 0]\n        max_shifts = stop - new_epochs.data[:, 1]\n        min_shift = np.max(min_shifts)\n        max_shift = np.min(max_shifts)\n        if min_shift &gt; max_shift:\n            raise ValueError(\"start_stop must fully cover epoch intervals\")\n\n        random_shift = np.random.uniform(min_shift, max_shift)\n        new_epochs._data = wrap_intervals((new_epochs.data + random_shift), start, stop)\n\n    if not new_epochs.isempty:\n        if np.any(new_epochs.data[:, 1] - new_epochs.data[:, 0] &lt; 0):\n            raise ValueError(\"start must be less than or equal to stop\")\n\n    new_epochs._sort()\n\n    return new_epochs\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.shift_epoch_array","title":"<code>shift_epoch_array(epoch, epoch_shift)</code>","text":"<p>Shift an EpochArray by another EpochArray.</p> <p>Shifting means that intervals in 'epoch' will be relative to intervals in 'epoch_shift' as if 'epoch_shift' intervals were without gaps.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The intervals to shift.</p> required <code>epoch_shift</code> <code>EpochArray</code> <p>The intervals to shift by.</p> required <p>Returns:</p> Type Description <code>EpochArray</code> <p>The shifted EpochArray.</p> Notes <p>This function restricts 'epoch' to those within 'epoch_shift' as epochs between 'epoch_shift' intervals would result in a duration of 0.</p> <p>Visual representation: inputs:     epoch       =   [  ]   [  ][]  []     epoch_shift =   [    ][]   [    ] becomes:     epoch       =   [  ]  [  ]    []     epoch_shift =   [    ][][    ]</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def shift_epoch_array(\n    epoch: nel.EpochArray, epoch_shift: nel.EpochArray\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Shift an EpochArray by another EpochArray.\n\n    Shifting means that intervals in 'epoch' will be relative to\n    intervals in 'epoch_shift' as if 'epoch_shift' intervals were without gaps.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The intervals to shift.\n    epoch_shift : nel.EpochArray\n        The intervals to shift by.\n\n    Returns\n    -------\n    nel.EpochArray\n        The shifted EpochArray.\n\n    Notes\n    -----\n    This function restricts 'epoch' to those within 'epoch_shift' as\n    epochs between 'epoch_shift' intervals would result in a duration of 0.\n\n    Visual representation:\n    inputs:\n        epoch       =   [  ]   [  ] [  ]  []\n        epoch_shift =   [    ] [    ]   [    ]\n    becomes:\n        epoch       =   [  ]  [  ]    []\n        epoch_shift =   [    ][    ][    ]\n    \"\"\"\n    # input validation\n    if not isinstance(epoch, nel.EpochArray):\n        raise TypeError(\"epoch must be a nelpy EpochArray\")\n    if not isinstance(epoch_shift, nel.EpochArray):\n        raise TypeError(\"epoch_shift must be a nelpy EpochArray\")\n\n    # restrict epoch to epoch_shift and extract starts and stops\n    epoch_starts, epoch_stops = epoch[epoch_shift].data.T\n\n    # shift starts and stops by epoch_shift\n    _, epoch_starts_shifted = in_intervals(epoch_starts, epoch_shift.data, shift=True)\n    _, epoch_stops_shifted = in_intervals(epoch_stops, epoch_shift.data, shift=True)\n\n    # shift time support as well, if one exists\n    support_starts_shifted, support_stops_shifted = -np.inf, np.inf\n    if epoch.domain.start != -np.inf:\n        _, support_starts_shifted = in_intervals(\n            epoch.domain.start, epoch_shift.data, shift=True\n        )\n    if epoch.domain.stop != np.inf:\n        _, support_stops_shifted = in_intervals(\n            epoch.domain.stop, epoch_shift.data, shift=True\n        )\n\n    session_domain = nel.EpochArray([support_starts_shifted, support_stops_shifted])\n\n    # package shifted intervals into epoch array with shifted time support\n    return nel.EpochArray(\n        np.array([epoch_starts_shifted, epoch_stops_shifted]).T, domain=session_domain\n    )\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.split_epoch_by_width","title":"<code>split_epoch_by_width(intervals, bin_width=0.001)</code>","text":"<p>Generate combined intervals (start, stop) at a specified width within given intervals.</p> <p>Parameters:</p> Name Type Description Default <code>intervals</code> <code>List[Tuple[float, float]]</code> <p>A list of (start, end) tuples representing intervals.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in seconds. Default is 0.001 (1 ms).</p> <code>0.001</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array containing (start, stop) pairs for all bins across intervals.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def split_epoch_by_width(\n    intervals: List[Tuple[float, float]], bin_width: float = 0.001\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate combined intervals (start, stop) at a specified width within given intervals.\n\n    Parameters\n    ----------\n    intervals : List[Tuple[float, float]]\n        A list of (start, end) tuples representing intervals.\n    bin_width : float\n        The width of each bin in seconds. Default is 0.001 (1 ms).\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array containing (start, stop) pairs for all bins across intervals.\n    \"\"\"\n    bin_intervals = []\n    for start, end in intervals:\n        # Generate bin edges\n        edges = np.arange(start, end, bin_width)\n        edges = np.append(edges, end)  # Ensure the final end is included\n        # Generate intervals (start, stop) for each bin\n        intervals = np.stack((edges[:-1], edges[1:]), axis=1)\n        bin_intervals.append(intervals)\n    return np.vstack(bin_intervals)\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.split_epoch_equal_parts","title":"<code>split_epoch_equal_parts(intervals, n_parts, return_epoch_array=True)</code>","text":"<p>Split multiple intervals into equal parts.</p> <p>Parameters:</p> Name Type Description Default <code>intervals</code> <code>(array - like, shape(n_intervals, 2))</code> <p>The intervals to split.</p> required <code>n_parts</code> <code>int</code> <p>The number of parts to split each interval into.</p> required <code>return_epoch_array</code> <code>bool</code> <p>If True, returns the intervals as a nelpy.EpochArray object. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>split_intervals</code> <code>(array - like, shape(n_intervals * n_parts, 2) or EpochArray)</code> <p>The split intervals.</p> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def split_epoch_equal_parts(\n    intervals: np.ndarray, n_parts: int, return_epoch_array: bool = True\n) -&gt; Union[np.ndarray, nel.EpochArray]:\n    \"\"\"\n    Split multiple intervals into equal parts.\n\n    Parameters\n    ----------\n    intervals : array-like, shape (n_intervals, 2)\n        The intervals to split.\n    n_parts : int\n        The number of parts to split each interval into.\n    return_epoch_array : bool, optional\n        If True, returns the intervals as a nelpy.EpochArray object. Defaults to True.\n\n    Returns\n    -------\n    split_intervals : array-like, shape (n_intervals * n_parts, 2) or nelpy.EpochArray\n        The split intervals.\n    \"\"\"\n    # Ensure intervals is a numpy array\n    intervals = np.asarray(intervals)\n\n    # Number of intervals\n    n_intervals = intervals.shape[0]\n\n    # Preallocate the output array\n    split_intervals = np.zeros((n_intervals * n_parts, 2))\n\n    for i, interval in enumerate(intervals):\n        start, end = interval\n        epoch_parts = np.linspace(start, end, n_parts + 1)\n        epoch_parts = np.vstack((epoch_parts[:-1], epoch_parts[1:])).T\n        split_intervals[i * n_parts : (i + 1) * n_parts] = epoch_parts\n\n    if return_epoch_array:\n        return nel.EpochArray(split_intervals)\n    return split_intervals\n</code></pre>"},{"location":"reference/neuro_py/process/intervals/#neuro_py.process.intervals.truncate_epoch","title":"<code>truncate_epoch(epoch, time=3600)</code>","text":"<p>Truncates an EpochArray to achieve a specified cumulative time duration.</p> <p>This function takes an input EpochArray 'epoch' and a 'time' value representing the desired cumulative time duration in seconds. It returns a new EpochArray containing intervals that cumulatively match the specified time.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <code>EpochArray</code> <p>The input EpochArray containing intervals to be truncated.</p> required <code>time</code> <code>Union[int, float]</code> <p>The desired cumulative time in seconds (default is 3600).</p> <code>3600</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>A new EpochArray containing intervals that cumulatively match the specified time.</p> Algorithm <ol> <li>Calculate the cumulative lengths of intervals in the 'epoch'.</li> <li>If the cumulative time of the 'epoch' is already less than or equal to 'time',     return the original 'epoch'.</li> <li>Find the last interval that fits within the specified 'time' and create a new EpochArray     'truncated_intervals' with intervals up to that point.</li> <li>To achieve the desired cumulative time, calculate the remaining time needed to reach 'time'.</li> <li>Add portions of the next interval to 'truncated_intervals' until the desired 'time' is reached     or all intervals are used.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_data = [(0, 2), (3, 6), (8, 10)]\n&gt;&gt;&gt; epoch = nel.EpochArray(epoch_data)\n&gt;&gt;&gt; truncated_epoch = truncate_epoch(epoch, time=7)\n</code></pre> Source code in <code>neuro_py/process/intervals.py</code> <pre><code>def truncate_epoch(\n    epoch: nel.EpochArray, time: Union[int, float] = 3600\n) -&gt; nel.EpochArray:\n    \"\"\"\n    Truncates an EpochArray to achieve a specified cumulative time duration.\n\n    This function takes an input EpochArray 'epoch' and a 'time' value representing\n    the desired cumulative time duration in seconds. It returns a new EpochArray\n    containing intervals that cumulatively match the specified time.\n\n    Parameters\n    ----------\n    epoch : nel.EpochArray\n        The input EpochArray containing intervals to be truncated.\n    time : Union[int, float], optional\n        The desired cumulative time in seconds (default is 3600).\n\n    Returns\n    -------\n    nel.EpochArray\n        A new EpochArray containing intervals that cumulatively match\n        the specified time.\n\n    Algorithm\n    ---------\n    1. Calculate the cumulative lengths of intervals in the 'epoch'.\n    2. If the cumulative time of the 'epoch' is already less than or equal to 'time',\n        return the original 'epoch'.\n    3. Find the last interval that fits within the specified 'time' and create a new EpochArray\n        'truncated_intervals' with intervals up to that point.\n    4. To achieve the desired cumulative time, calculate the remaining time needed to reach 'time'.\n    5. Add portions of the next interval to 'truncated_intervals' until the desired 'time' is reached\n        or all intervals are used.\n\n    Examples\n    --------\n    &gt;&gt;&gt; epoch_data = [(0, 2), (3, 6), (8, 10)]\n    &gt;&gt;&gt; epoch = nel.EpochArray(epoch_data)\n    &gt;&gt;&gt; truncated_epoch = truncate_epoch(epoch, time=7)\n    \"\"\"\n\n    if epoch.isempty:\n        return epoch\n\n    # calcuate cumulative lengths\n    cumulative_lengths = epoch.lengths.cumsum()\n\n    # No truncation needed\n    if cumulative_lengths[-1] &lt;= time:\n        return epoch\n\n    # Find the last interval that fits within the time and make new epoch\n    idx = cumulative_lengths &lt;= time\n    truncated_intervals = nel.EpochArray(epoch.data[idx])\n\n    # It's unlikely that the last interval will fit perfectly, so add the remainder from the next interval\n    #   until the epoch is the desired length\n    interval_i = 0\n    while (time - truncated_intervals.duration) &gt; 1e-10 or interval_i &gt; len(epoch):\n        # Add the last interval\n        next_interval = int(np.where(cumulative_lengths &gt;= time)[0][interval_i])\n\n        remainder = (\n            nel.EpochArray(\n                [\n                    epoch[next_interval].start,\n                    epoch[next_interval].start + (time - truncated_intervals.duration),\n                ]\n            )\n            &amp; epoch[next_interval]\n        )\n        truncated_intervals = truncated_intervals | remainder\n        interval_i += 1\n\n    return truncated_intervals\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/","title":"neuro_py.process.peri_event","text":""},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event._sync_fill_indices","title":"<code>_sync_fill_indices(starts, stops, events_with_hits, total_hits)</code>","text":"<p>Numba-compiled function to fill Is and Ie index arrays.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef _sync_fill_indices(\n    starts: np.ndarray,\n    stops: np.ndarray,\n    events_with_hits: np.ndarray,\n    total_hits: int,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Numba-compiled function to fill Is and Ie index arrays.\n    \"\"\"\n    Is = np.empty(total_hits, dtype=np.int64)\n    Ie = np.empty(total_hits, dtype=np.int64)\n\n    write_pos = 0\n    for i in range(len(starts)):\n        start_idx = starts[i]\n        stop_idx = stops[i]\n        event_i = events_with_hits[i]\n        run_len = stop_idx - start_idx\n\n        # Fill this segment\n        for j in range(run_len):\n            Is[write_pos + j] = start_idx + j\n            Ie[write_pos + j] = event_i\n\n        write_pos += run_len\n\n    return Is, Ie\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event._sync_find_windows","title":"<code>_sync_find_windows(sample_times, event_times, start_offset, stop_offset)</code>","text":"<p>Numba-compiled function to find time windows for each event.</p> <p>Returns arrays of starts, stops, events_with_hits, and total_hits count.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef _sync_find_windows(\n    sample_times: np.ndarray,\n    event_times: np.ndarray,\n    start_offset: float,\n    stop_offset: float,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, int]:\n    \"\"\"\n    Numba-compiled function to find time windows for each event.\n\n    Returns arrays of starts, stops, events_with_hits, and total_hits count.\n    \"\"\"\n    n_samples = len(sample_times)\n    n_events = len(event_times)\n\n    # Pre-allocate maximum possible size\n    starts = np.empty(n_events, dtype=np.int64)\n    stops = np.empty(n_events, dtype=np.int64)\n    events_with_hits = np.empty(n_events, dtype=np.int64)\n\n    n_hits = 0\n    total_hits = 0\n    left_idx = 0\n    right_idx = 0\n\n    for event_i in range(n_events):\n        event_t = event_times[event_i]\n        start_t = event_t + start_offset\n        stop_t = event_t + stop_offset\n\n        # Advance left pointer\n        while left_idx &lt; n_samples and sample_times[left_idx] &lt; start_t:\n            left_idx += 1\n\n        # Ensure right_idx is at least left_idx\n        if right_idx &lt; left_idx:\n            right_idx = left_idx\n\n        # Advance right pointer\n        while right_idx &lt; n_samples and sample_times[right_idx] &lt;= stop_t:\n            right_idx += 1\n\n        # Record if we found any samples in this window\n        if right_idx &gt; left_idx:\n            starts[n_hits] = left_idx\n            stops[n_hits] = right_idx\n            events_with_hits[n_hits] = event_i\n            total_hits += right_idx - left_idx\n            n_hits += 1\n\n    # Trim arrays to actual size\n    starts = starts[:n_hits]\n    stops = stops[:n_hits]\n    events_with_hits = events_with_hits[:n_hits]\n\n    return starts, stops, events_with_hits, total_hits\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.compute_psth","title":"<code>compute_psth(data, event, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Compute the Peri-Stimulus Time Histogram (PSTH) for discrete-time events.</p> <p>This function calculates the PSTH for a given set of discrete-time events (e.g. spike times) aligned to specific reference events. The PSTH provides time-resolved rates (Hz) in response to the events over a defined time window.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>An array of discrete-time events (e.g. spike times) for multiple trials, with each trial in a separate row.</p> required <code>event</code> <code>ndarray</code> <p>An array of reference event times to which the data are aligned.</p> required <code>bin_width</code> <code>float</code> <p>Width of each time bin in seconds (default is 0.002 seconds).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>Number of bins to create for the histogram (default is 100).</p> <code>100</code> <code>window</code> <code>list</code> <p>Time window around each event to consider for the PSTH. If None, a symmetric window is created based on <code>n_bins</code> and <code>bin_width</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the PSTH, indexed by time bins and columns representing each trial's PSTH.</p> Notes <p>If the specified window is not symmetric around 0, it is adjusted to be symmetric. Each trial's times must be sorted in ascending order. This function relies on <code>crossCorr</code>, which uses binary search and assumes sorted input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spikes = np.array([[0.1, 0.15, 0.2], [0.1, 0.12, 0.13]])\n&gt;&gt;&gt; event = np.array([0.1, 0.3])\n&gt;&gt;&gt; psth = compute_psth(spikes, event)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def compute_psth(\n    data: np.ndarray,\n    event: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: list = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute the Peri-Stimulus Time Histogram (PSTH) for discrete-time events.\n\n    This function calculates the PSTH for a given set of discrete-time events\n    (e.g. spike times) aligned to specific reference events. The PSTH provides\n    time-resolved **rates (Hz)** in response to the events over a defined time window.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        An array of discrete-time events (e.g. spike times) for multiple trials,\n        with each trial in a separate row.\n    event : np.ndarray\n        An array of reference event times to which the data are aligned.\n    bin_width : float, optional\n        Width of each time bin in seconds (default is 0.002 seconds).\n    n_bins : int, optional\n        Number of bins to create for the histogram (default is 100).\n    window : list, optional\n        Time window around each event to consider for the PSTH. If None, a\n        symmetric window is created based on `n_bins` and `bin_width`.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the PSTH, indexed by time bins and columns\n        representing each trial's PSTH.\n\n    Notes\n    -----\n    If the specified window is not symmetric around 0, it is adjusted to be symmetric.\n    Each trial's times must be sorted in ascending order. This function\n    relies on `crossCorr`, which uses binary search and assumes sorted input.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spikes = np.array([[0.1, 0.15, 0.2], [0.1, 0.12, 0.13]])\n    &gt;&gt;&gt; event = np.array([0.1, 0.3])\n    &gt;&gt;&gt; psth = compute_psth(spikes, event)\n    \"\"\"\n    if window is not None:\n        window_original = None\n        # check if window is symmetric around 0, if not make it so\n        mid = (window[1] - window[0]) / 2.0\n        is_symmetric = np.isclose(mid, window[1]) and np.isclose(-mid, window[0])\n        if not is_symmetric:\n            window_original = np.array(window)\n            window = [-np.max(np.abs(window)), np.max(np.abs(window))]\n\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        n_bins = len(times) - 1\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    ccg = pd.DataFrame(index=times, columns=np.arange(len(data)))\n    # Now we can iterate over trials\n    for i, s in enumerate(data):\n        # Ensure spike times are float64 for numba compatibility\n        s = np.asarray(s, dtype=np.float64)\n        ccg[i] = crossCorr(event, s, bin_width, n_bins)\n\n    # if window was not symmetric, remove the extra bins\n    if window is not None:\n        if window_original is not None:\n            ccg = ccg.loc[window_original[0] : window_original[1], :]\n    return ccg\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.count_events","title":"<code>count_events(events, time_ref, time_range)</code>","text":"<p>Count the number of events that occur within a given time range after each reference event.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>ndarray</code> <p>A 1D array of event times.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>time_range</code> <code>tuple of (float, float)</code> <p>A tuple containing the start and end times of the time range.</p> required <p>Returns:</p> Name Type Description <code>counts</code> <code>ndarray</code> <p>A 1D array of event counts, one for each reference time (same length as time_ref).</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def count_events(\n    events: np.ndarray, time_ref: np.ndarray, time_range: Tuple[float, float]\n) -&gt; np.ndarray:\n    \"\"\"\n    Count the number of events that occur within a given time range after each reference event.\n\n    Parameters\n    ----------\n    events : np.ndarray\n        A 1D array of event times.\n    time_ref : np.ndarray\n        A 1D array of reference times.\n    time_range : tuple of (float, float)\n        A tuple containing the start and end times of the time range.\n\n    Returns\n    -------\n    counts : np.ndarray\n        A 1D array of event counts, one for each reference time (same length as time_ref).\n    \"\"\"\n    # Initialize an array to store the event counts\n    counts = np.zeros_like(time_ref)\n\n    # Iterate over the reference times\n    for i, r in enumerate(time_ref):\n        # Check if any events occur within the time range\n        idx = (events &gt; r + time_range[0]) &amp; (events &lt; r + time_range[1])\n        # Increment the event count if any events are found\n        counts[i] = len(events[idx])\n\n    return counts\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.count_in_interval","title":"<code>count_in_interval(data, event_starts, event_stops, par_type='counts')</code>","text":"<p>Count discrete-time events in specified intervals and return a matrix where each column represents counts for each discrete-time event series over given epochs.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A jagged array where each element contains discrete-time events times for a series (e.g. spike times for a neuron). (n series x variable length event times).</p> required <code>event_starts</code> <code>ndarray</code> <p>A 1D array containing the start times of events.</p> required <code>event_stops</code> <code>ndarray</code> <p>A 1D array containing the stop times of events.</p> required <code>par_type</code> <code>str</code> <p>The type of count calculation to perform: - 'counts': returns raw counts of spikes in the intervals. - 'binary': returns a binary matrix indicating presence (1) or absence (0) of spikes. - 'rate': returns the firing rate calculated as counts divided by the interval duration. Defaults to 'binary'.</p> <code>'counts'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D array (n series x n epochs) where each column shows the counts (or binary values or rates) per series for each epoch.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Create spike trains for 3 units with different spike times\n&gt;&gt;&gt; unit_1_spikes = np.array([0.1, 0.3, 0.5, 1.2, 1.8])\n&gt;&gt;&gt; unit_2_spikes = np.array([0.2, 0.8, 1.5])\n&gt;&gt;&gt; unit_3_spikes = np.array([0.05, 0.4, 0.9, 1.1])\n&gt;&gt;&gt; st = np.array([unit_1_spikes, unit_2_spikes, unit_3_spikes], dtype=object)\n&gt;&gt;&gt; # Define two events with their start and stop times\n&gt;&gt;&gt; event_starts = np.array([0.0, 1.0])\n&gt;&gt;&gt; event_stops = np.array([0.7, 2.0])\n&gt;&gt;&gt; # Count spikes in each interval\n&gt;&gt;&gt; counts = count_in_interval(st, event_starts, event_stops, par_type='counts')\n&gt;&gt;&gt; print(counts)\n[[3. 2.]\n [1. 1.]\n [2. 1.]]\n&gt;&gt;&gt; # Get binary presence/absence\n&gt;&gt;&gt; binary = count_in_interval(st, event_starts, event_stops, par_type='binary')\n&gt;&gt;&gt; print(binary)\n[[1. 1.]\n [1. 1.]\n [1. 1.]]\n&gt;&gt;&gt; # Calculate firing rates\n&gt;&gt;&gt; rates = count_in_interval(st, event_starts, event_stops, par_type='firing_rate')\n&gt;&gt;&gt; print(rates)\n[[4.28571429 2.   ]\n [1.42857143 1.   ]\n [2.85714286 1.   ]]\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def count_in_interval(\n    data: np.ndarray,\n    event_starts: np.ndarray,\n    event_stops: np.ndarray,\n    par_type: str = \"counts\",\n) -&gt; np.ndarray:\n    \"\"\"\n    Count discrete-time events in specified intervals and return a matrix where each\n    column represents counts for each discrete-time event series over given epochs.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A jagged array where each element contains discrete-time events times for\n        a series (e.g. spike times for a neuron). (n series x variable length event times).\n\n    event_starts : np.ndarray\n        A 1D array containing the start times of events.\n\n    event_stops : np.ndarray\n        A 1D array containing the stop times of events.\n\n    par_type : str, optional\n        The type of count calculation to perform:\n        - 'counts': returns raw counts of spikes in the intervals.\n        - 'binary': returns a binary matrix indicating presence (1) or absence (0) of spikes.\n        - 'rate': returns the firing rate calculated as counts divided by the interval duration.\n        Defaults to 'binary'.\n\n    Returns\n    -------\n    np.ndarray\n        A 2D array (n series x n epochs) where each column shows the counts\n        (or binary values or rates) per series for each epoch.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; # Create spike trains for 3 units with different spike times\n    &gt;&gt;&gt; unit_1_spikes = np.array([0.1, 0.3, 0.5, 1.2, 1.8])\n    &gt;&gt;&gt; unit_2_spikes = np.array([0.2, 0.8, 1.5])\n    &gt;&gt;&gt; unit_3_spikes = np.array([0.05, 0.4, 0.9, 1.1])\n    &gt;&gt;&gt; st = np.array([unit_1_spikes, unit_2_spikes, unit_3_spikes], dtype=object)\n    &gt;&gt;&gt; # Define two events with their start and stop times\n    &gt;&gt;&gt; event_starts = np.array([0.0, 1.0])\n    &gt;&gt;&gt; event_stops = np.array([0.7, 2.0])\n    &gt;&gt;&gt; # Count spikes in each interval\n    &gt;&gt;&gt; counts = count_in_interval(st, event_starts, event_stops, par_type='counts')\n    &gt;&gt;&gt; print(counts)\n    [[3. 2.]\n     [1. 1.]\n     [2. 1.]]\n    &gt;&gt;&gt; # Get binary presence/absence\n    &gt;&gt;&gt; binary = count_in_interval(st, event_starts, event_stops, par_type='binary')\n    &gt;&gt;&gt; print(binary)\n    [[1. 1.]\n     [1. 1.]\n     [1. 1.]]\n    &gt;&gt;&gt; # Calculate firing rates\n    &gt;&gt;&gt; rates = count_in_interval(st, event_starts, event_stops, par_type='firing_rate')\n    &gt;&gt;&gt; print(rates)\n    [[4.28571429 2.   ]\n     [1.42857143 1.   ]\n     [2.85714286 1.   ]]\n    \"\"\"\n    # convert to numpy array\n    event_starts, event_stops = np.array(event_starts), np.array(event_stops)\n\n    # initialize matrix\n    unit_mat = np.zeros((len(data), (len(event_starts))))\n\n    # loop over units and bin spikes into epochs\n    for i, s in enumerate(data):\n        idx1 = np.searchsorted(s, event_starts, \"right\")\n        idx2 = np.searchsorted(s, event_stops, \"left\")\n        unit_mat[i, :] = idx2 - idx1\n\n    par_type_funcs = {\n        \"counts\": lambda x: x,\n        \"binary\": lambda x: (x &gt; 0) * 1,\n        \"firing_rate\": lambda x: x / (event_stops - event_starts),\n    }\n    calc_func = par_type_funcs[par_type]\n    unit_mat = calc_func(unit_mat)\n\n    return unit_mat\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.crossCorr","title":"<code>crossCorr(t1, t2, binsize, nbins)</code>","text":"<p>Compute a cross-correlogram using independent event-wise histograms.</p> <p>This is the standard definition of a cross-correlogram: each reference event (t1) independently computes a histogram of all target timestamps (t2) relative to it. Each t2 sample can contribute to every t1 event (no \"consumption\").</p> <p>Efficient O(nt1 * (log(nt2) + nt2)) implementation using binary search for initial positioning, then single-pass binning per event.</p> <p>Parameters:</p> Name Type Description Default <code>t1</code> <code>ndarray</code> <p>Reference events (can be unsorted, any order).</p> required <code>t2</code> <code>ndarray</code> <p>Target timestamps (must be sorted in ascending order).</p> required <code>binsize</code> <code>float</code> <p>Bin width in seconds.</p> required <code>nbins</code> <code>int</code> <p>Number of bins (will be adjusted to be odd).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized cross-correlogram (rate in Hz). Shape (nbins,) where nbins is adjusted to be odd.</p> Notes <p>True cross-correlogram: each t2 sample contributes to every t1 event. Order of t1 does not affect the result. Suitable for spike-to-event analysis (e.g., spikes relative to ripples).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t1 = np.array([1.0, 2.0])\n&gt;&gt;&gt; t2 = np.sort(np.array([1.1, 1.3, 2.1, 2.3]))\n&gt;&gt;&gt; result = crossCorr(t1, t2, binsize=0.2, nbins=4)\n&gt;&gt;&gt; result.shape\n(5,)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef crossCorr(\n    t1: np.ndarray,\n    t2: np.ndarray,\n    binsize: float,\n    nbins: int,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute a cross-correlogram using independent event-wise histograms.\n\n    This is the standard definition of a cross-correlogram: each reference event (t1)\n    independently computes a histogram of all target timestamps (t2) relative to it.\n    Each t2 sample can contribute to every t1 event (no \"consumption\").\n\n    Efficient O(nt1 * (log(nt2) + nt2)) implementation using binary search for\n    initial positioning, then single-pass binning per event.\n\n    Parameters\n    ----------\n    t1 : np.ndarray\n        Reference events (can be unsorted, any order).\n    t2 : np.ndarray\n        Target timestamps (must be sorted in ascending order).\n    binsize : float\n        Bin width in seconds.\n    nbins : int\n        Number of bins (will be adjusted to be odd).\n\n    Returns\n    -------\n    np.ndarray\n        Normalized cross-correlogram (rate in Hz).\n        Shape (nbins,) where nbins is adjusted to be odd.\n\n    Notes\n    -----\n    True cross-correlogram: each t2 sample contributes to every t1 event.\n    Order of t1 does not affect the result.\n    Suitable for spike-to-event analysis (e.g., spikes relative to ripples).\n\n    Examples\n    --------\n    &gt;&gt;&gt; t1 = np.array([1.0, 2.0])\n    &gt;&gt;&gt; t2 = np.sort(np.array([1.1, 1.3, 2.1, 2.3]))\n    &gt;&gt;&gt; result = crossCorr(t1, t2, binsize=0.2, nbins=4)\n    &gt;&gt;&gt; result.shape\n    (5,)\n    \"\"\"\n    # Ensure nbins is odd\n    nbins = int(nbins)\n    if np.floor(nbins / 2) * 2 == nbins:\n        nbins = nbins + 1\n\n    nt1 = len(t1)\n    nt2 = len(t2)\n\n    w = (nbins / 2) * binsize\n    C = np.zeros(nbins)\n\n    # For each reference event, independently compute histogram\n    for i1 in range(nt1):\n        lbound = t1[i1] - w\n        ubound = lbound + nbins * binsize\n\n        # Binary search to find first t2 sample in window\n        left = 0\n        right = nt2\n        while left &lt; right:\n            mid = (left + right) // 2\n            if t2[mid] &lt; lbound:\n                left = mid + 1\n            else:\n                right = mid\n\n        # Single pass through t2 samples in this event's window\n        # Bin each sample directly using its offset from lbound\n        k = left\n        while k &lt; nt2 and t2[k] &lt; ubound:\n            bin_j = int((t2[k] - lbound) / binsize)\n            if 0 &lt;= bin_j &lt; nbins:\n                C[bin_j] += 1\n            k += 1\n\n    # Normalize by number of events and bin width\n    C = C / (nt1 * binsize)\n\n    return C\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.deconvolve_peth","title":"<code>deconvolve_peth(signal, events, bin_width=0.002, n_bins=100)</code>","text":"<p>Perform deconvolution of a peri-event time histogram (PETH) signal.</p> <p>This function calculates the deconvolved signal based on the input signal and events.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>An array representing the discrete events.</p> required <code>events</code> <code>ndarray</code> <p>An array representing the discrete events.</p> required <code>bin_width</code> <code>float</code> <p>The width of a time bin in seconds (default is 0.002 seconds).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins to use in the PETH (default is 100 bins).</p> <code>100</code> <p>Returns:</p> Name Type Description <code>deconvolved</code> <code>ndarray</code> <p>An array representing the deconvolved signal.</p> <code>times</code> <code>ndarray</code> <p>An array representing the time points corresponding to the bins.</p> Notes <p>Based on DeconvolvePETH.m from https://github.com/ayalab1/neurocode/blob/master/spikes/DeconvolvePETH.m</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def deconvolve_peth(\n    signal: np.ndarray, events: np.ndarray, bin_width: float = 0.002, n_bins: int = 100\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Perform deconvolution of a peri-event time histogram (PETH) signal.\n\n    This function calculates the deconvolved signal based on the input signal and events.\n\n    Parameters\n    ----------\n    signal : np.ndarray\n        An array representing the discrete events.\n    events : np.ndarray\n        An array representing the discrete events.\n    bin_width : float, optional\n        The width of a time bin in seconds (default is 0.002 seconds).\n    n_bins : int, optional\n        The number of bins to use in the PETH (default is 100 bins).\n\n    Returns\n    -------\n    deconvolved : np.ndarray\n        An array representing the deconvolved signal.\n    times : np.ndarray\n        An array representing the time points corresponding to the bins.\n\n    Notes\n    -----\n    Based on DeconvolvePETH.m from https://github.com/ayalab1/neurocode/blob/master/spikes/DeconvolvePETH.m\n    \"\"\"\n\n    # calculate time lags for peth\n    times = np.linspace(-(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1)\n\n    # Calculate the autocorrelogram of the signal and the PETH of the events and the signal\n    autocorrelogram = crossCorr(signal, signal, bin_width, n_bins * 2)\n    raw_peth = crossCorr(events, signal, bin_width, n_bins * 2)\n\n    # If raw_peth all zeros, return zeros\n    if not raw_peth.any():\n        return np.zeros(len(times)), times\n\n    # Subtract the mean value from the raw_peth\n    const = np.mean(raw_peth)\n    raw_peth = raw_peth - const\n\n    # Calculate the Toeplitz matrix using the autocorrelogram and\n    #   the cross-correlation of the autocorrelogram\n    T0 = toeplitz(\n        autocorrelogram,\n        np.hstack([autocorrelogram[0], np.zeros(len(autocorrelogram) - 1)]),\n    )\n    T = T0[n_bins:, : n_bins + 1]\n\n    # Calculate the deconvolved signal by solving a linear equation\n    deconvolved = np.linalg.solve(\n        T, raw_peth[int(n_bins / 2) : int(n_bins / 2 * 3 + 1)].T + const / len(events)\n    )\n\n    return deconvolved, times\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.event_spiking_threshold","title":"<code>event_spiking_threshold(spikes, events, window=[-0.5, 0.5], event_size=0.1, spiking_thres=0, binsize=0.01, sigma=0.02, min_units=6, show_fig=False)</code>","text":"<p>event_spiking_threshold: filter events based on spiking threshold</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>SpikeTrainArray</code> <p>Spike train array of neurons.</p> required <code>events</code> <code>ndarray</code> <p>Event times in seconds.</p> required <code>window</code> <code>list of float</code> <p>Time window (in seconds) to compute event-triggered average, by default [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>event_size</code> <code>float</code> <p>Time window (in seconds) around event to measure firing response, by default 0.1.</p> <code>0.1</code> <code>spiking_thres</code> <code>float</code> <p>Spiking threshold in z-score units, by default 0.</p> <code>0</code> <code>binsize</code> <code>float</code> <p>Bin size (in seconds) for time-binning the spike trains, by default 0.01.</p> <code>0.01</code> <code>sigma</code> <code>float</code> <p>Standard deviation (in seconds) for Gaussian smoothing of spike counts, by default 0.02.</p> <code>0.02</code> <code>min_units</code> <code>int</code> <p>Minimum number of units required to compute event-triggered average, by default 6.</p> <code>6</code> <code>show_fig</code> <code>bool</code> <p>If True, plots the figure of event-triggered spiking activity, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean array indicating valid events that meet the spiking threshold.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP04\\day_32_20240430\"\n&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=False)\n&gt;&gt;&gt; st, cell_metrics = loading.load_spikes(\n        basepath,\n        brainRegion=\"CA1\",\n        support=nel.EpochArray([0, loading.load_epoch(basepath).iloc[-1].stopTime])\n    )\n&gt;&gt;&gt; idx = event_spiking_threshold(st, ripples.peaks.values, show_fig=True)\n&gt;&gt;&gt; print(f\"Number of valid ripples: {idx.sum()} out of {len(ripples)}\")\nNumber of valid ripples: 9244 out of 12655\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_spiking_threshold(\n    spikes: SpikeTrainArray,\n    events: np.ndarray,\n    window: list = [-0.5, 0.5],\n    event_size: float = 0.1,\n    spiking_thres: float = 0,\n    binsize: float = 0.01,\n    sigma: float = 0.02,\n    min_units: int = 6,\n    show_fig: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"\n    event_spiking_threshold: filter events based on spiking threshold\n\n    Parameters\n    ----------\n    spikes : nel.SpikeTrainArray\n        Spike train array of neurons.\n    events : np.ndarray\n        Event times in seconds.\n    window : list of float, optional\n        Time window (in seconds) to compute event-triggered average, by default [-0.5, 0.5].\n    event_size : float, optional\n        Time window (in seconds) around event to measure firing response, by default 0.1.\n    spiking_thres : float, optional\n        Spiking threshold in z-score units, by default 0.\n    binsize : float, optional\n        Bin size (in seconds) for time-binning the spike trains, by default 0.01.\n    sigma : float, optional\n        Standard deviation (in seconds) for Gaussian smoothing of spike counts, by default 0.02.\n    min_units : int, optional\n        Minimum number of units required to compute event-triggered average, by default 6.\n    show_fig : bool, optional\n        If True, plots the figure of event-triggered spiking activity, by default False.\n\n    Returns\n    -------\n    np.ndarray\n        Boolean array indicating valid events that meet the spiking threshold.\n\n    Examples\n    -------\n    &gt;&gt;&gt; basepath = r\"U:\\\\data\\\\hpc_ctx_project\\\\HP04\\\\day_32_20240430\"\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=False)\n    &gt;&gt;&gt; st, cell_metrics = loading.load_spikes(\n            basepath,\n            brainRegion=\"CA1\",\n            support=nel.EpochArray([0, loading.load_epoch(basepath).iloc[-1].stopTime])\n        )\n    &gt;&gt;&gt; idx = event_spiking_threshold(st, ripples.peaks.values, show_fig=True)\n    &gt;&gt;&gt; print(f\"Number of valid ripples: {idx.sum()} out of {len(ripples)}\")\n    Number of valid ripples: 9244 out of 12655\n\n    \"\"\"\n\n    # check if there are enough units to compute a confident event triggered average\n    if spikes.n_active &lt; min_units:\n        return np.ones(len(events), dtype=bool)\n\n    # bin spikes\n    bst = spikes.bin(ds=binsize).smooth(sigma=sigma)\n    # sum over all neurons and zscore\n    bst = bst.data.sum(axis=0)\n    bst = (bst - bst.mean()) / bst.std()\n    # get event triggered average\n    avg_signal, time_lags = event_triggered_average_fast(\n        bst[np.newaxis, :],\n        events,\n        sampling_rate=int(1 / binsize),\n        window=window,\n        return_average=False,\n    )\n    # get the event response within the event size\n    idx = (time_lags &gt;= -event_size) &amp; (time_lags &lt;= event_size)\n    event_response = avg_signal[0, idx, :].mean(axis=0)\n\n    # get events that are above threshold\n    valid_events = event_response &gt; spiking_thres\n\n    if show_fig:\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n\n        sorted_idx = np.argsort(event_response)\n\n        fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n        ax[0].imshow(\n            avg_signal[0, :, sorted_idx],\n            aspect=\"auto\",\n            extent=[time_lags[0], time_lags[-1], 0, len(event_response)],\n            vmin=-2,\n            vmax=2,\n            origin=\"lower\",\n            interpolation=\"nearest\",\n        )\n        ax[0].axhline(\n            np.where(event_response[sorted_idx] &gt; spiking_thres)[0][0],\n            color=\"r\",\n            linestyle=\"--\",\n        )\n        ax[1].plot(event_response[sorted_idx], np.arange(len(event_response)))\n        ax[1].axvline(spiking_thres, color=\"r\", linestyle=\"--\")\n        ax[0].set_xlabel(\"Time from event (s)\")\n        ax[0].set_ylabel(\"Event index\")\n        ax[1].set_xlabel(\"Average response\")\n        ax[1].set_ylabel(\"Event index\")\n        sns.despine()\n\n    return valid_events\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.event_triggered_average","title":"<code>event_triggered_average(timestamps, signal, events, sampling_rate=None, window=[-0.5, 0.5], return_average=True, return_pandas=False, irregular_sampling=False)</code>","text":"<p>Calculates the event-triggered averages of signals in a time window relative to the event times of corresponding events for multiple signals.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>A 1D array of timestamps corresponding to the signal samples.</p> required <code>signal</code> <code>ndarray</code> <p>A 2D array of shape (n_samples, n_signals) containing the signal values.</p> required <code>events</code> <code>Union[ndarray, List[ndarray]]</code> <p>One or more 1D arrays of event times.</p> required <code>sampling_rate</code> <code>Union[float, None]</code> <p>The sampling rate of the signal. If not provided, it will be calculated based on the timestamps.</p> <code>None</code> <code>window</code> <code>List[float]</code> <p>A list containing two elements: the start and stop times relative to an event for the time interval of signal averaging. Default is [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>return_average</code> <code>bool</code> <p>Whether to return the average of the event-triggered average. Defaults to True. If False, returns the full event-triggered average matrix (n_samples x n_signals x n_events).</p> <code>True</code> <code>return_pandas</code> <code>bool</code> <p>If True, return the result as a Pandas DataFrame. Default is False.</p> <code>False</code> <code>irregular_sampling</code> <code>bool</code> <p>If True, indicates that the signal is irregularly sampled and interpolation should be used. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, DataFrame]</code> <p>If <code>return_average</code> is True, returns the event-triggered averages of the signals (n_samples, n_signals) or a Pandas DataFrame if <code>return_pandas</code> is True. If <code>return_average</code> is False, returns the full event-triggered average matrix (n_samples, n_signals, n_events).</p> <code>ndarray</code> <p>An array of time lags corresponding to the event-triggered averages.</p> Notes <ul> <li>The function filters out events that do not fit within the valid range of the signal considering the specified window size.</li> <li>If the <code>sampling_rate</code> is not provided, it is calculated based on the timestamps.</li> <li>The function handles both regular and irregular sampling of the signal.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; peth_avg, time_lags = event_triggered_average(\n...    timestamps, signal, events, window=[-0.5, 0.5]\n... )\n&gt;&gt;&gt; # Get individual event responses\n&gt;&gt;&gt; peth_matrix, time_lags = event_triggered_average(\n...    timestamps, signal, events, window=[-0.5, 0.5], return_average=False\n... )\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average(\n    timestamps: np.ndarray,\n    signal: np.ndarray,\n    events: Union[np.ndarray, List[np.ndarray]],\n    sampling_rate: Union[float, None] = None,\n    window: List[float] = [-0.5, 0.5],\n    return_average: bool = True,\n    return_pandas: bool = False,\n    irregular_sampling: bool = False,\n) -&gt; Tuple[Union[np.ndarray, pd.DataFrame], np.ndarray]:\n    \"\"\"\n    Calculates the event-triggered averages of signals in a time window\n    relative to the event times of corresponding events for multiple signals.\n\n    Parameters\n    ----------\n    timestamps : np.ndarray\n        A 1D array of timestamps corresponding to the signal samples.\n    signal : np.ndarray\n        A 2D array of shape (n_samples, n_signals) containing the signal values.\n    events : Union[np.ndarray, List[np.ndarray]]\n        One or more 1D arrays of event times.\n    sampling_rate : Union[float, None], optional\n        The sampling rate of the signal. If not provided, it will be calculated\n        based on the timestamps.\n    window : List[float], optional\n        A list containing two elements: the start and stop times relative to an event\n        for the time interval of signal averaging. Default is [-0.5, 0.5].\n    return_average : bool, optional\n        Whether to return the average of the event-triggered average. Defaults to True.\n        If False, returns the full event-triggered average matrix (n_samples x n_signals x n_events).\n    return_pandas : bool, optional\n        If True, return the result as a Pandas DataFrame. Default is False.\n    irregular_sampling : bool, optional\n        If True, indicates that the signal is irregularly sampled and interpolation should be used. Default is False.\n\n    Returns\n    -------\n    Union[np.ndarray, pd.DataFrame]\n        If `return_average` is True, returns the event-triggered averages of the signals\n        (n_samples, n_signals) or a Pandas DataFrame if `return_pandas` is True.\n        If `return_average` is False, returns the full event-triggered average matrix\n        (n_samples, n_signals, n_events).\n    np.ndarray\n        An array of time lags corresponding to the event-triggered averages.\n\n    Notes\n    -----\n    - The function filters out events that do not fit within the valid range of the signal\n    considering the specified window size.\n    - If the `sampling_rate` is not provided, it is calculated based on the timestamps.\n    - The function handles both regular and irregular sampling of the signal.\n\n    Examples\n    --------\n    &gt;&gt;&gt; peth_avg, time_lags = event_triggered_average(\n    ...    timestamps, signal, events, window=[-0.5, 0.5]\n    ... )\n    &gt;&gt;&gt; # Get individual event responses\n    &gt;&gt;&gt; peth_matrix, time_lags = event_triggered_average(\n    ...    timestamps, signal, events, window=[-0.5, 0.5], return_average=False\n    ... )\n    \"\"\"\n    # Basic input validation\n    if len(window) != 2 or window[0] &gt; window[1]:\n        raise ValueError(\"'window' must be [start, stop] with start &lt; stop\")\n\n    if len(signal.shape) == 1:\n        signal = signal.reshape(-1, 1)\n\n    if sampling_rate is None:\n        sampling_rate = 1 / stats.mode(np.diff(timestamps), keepdims=True)[0][0]\n\n    if isinstance(events, list):\n        events = np.array(events)\n\n    window_starttime, window_stoptime = window\n    window_bins = int(np.ceil(((window_stoptime - window_starttime) * sampling_rate)))\n    time_lags = np.linspace(window_starttime, window_stoptime, window_bins)\n\n    # Filter events that fit within the signal range\n    min_timestamp, max_timestamp = timestamps[0], timestamps[-1]\n    valid_mask = (events + window_starttime &gt;= min_timestamp) &amp; (\n        events + window_stoptime &lt;= max_timestamp\n    )\n\n    if not np.any(valid_mask):\n        warnings.warn(\"No events found within the valid signal range\")\n        empty_shape = (window_bins, signal.shape[1])\n        if return_average:\n            result = np.zeros(empty_shape)\n            return (\n                pd.DataFrame(result, index=time_lags) if return_pandas else result\n            ), time_lags\n        else:\n            return np.full(empty_shape + (len(events),), np.nan), time_lags\n\n    # Initialize result matrix: (window_bins, n_signals, n_events) - keep all events\n    result_matrix = np.full((window_bins, signal.shape[1], len(events)), np.nan)\n\n    # For regular sampling, use fast indexing approach similar to event_triggered_average_fast\n    dt = np.median(np.diff(timestamps))\n    data_is_regular = np.allclose(np.diff(timestamps), dt, rtol=1e-3)\n    use_interpolation = irregular_sampling or not data_is_regular\n\n    if not use_interpolation:\n        # Fast path: regular sampling - use direct indexing like event_triggered_average_fast\n        # Match the exact indexing logic from event_triggered_average_fast\n        start_time = timestamps[0]  # Cache start time for efficiency\n        for i, event in enumerate(events):\n            if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n                continue\n\n            # Convert event time to sample indices, accounting for timestamp start time\n            event_sample = np.round((event - start_time) * sampling_rate)\n            ts_idx = np.arange(\n                event_sample - window_bins / 2,\n                event_sample + window_bins / 2,\n            ).astype(int)\n\n            # Check bounds\n            if np.min(ts_idx) &gt;= 0 and np.max(ts_idx) &lt; len(signal):\n                result_matrix[:, :, i] = signal[ts_idx, :]\n            # If bounds check fails, keep as NaN (already initialized)\n    else:\n        # Slow path: irregular sampling - use interpolation but vectorized\n        target_times_template = np.linspace(\n            window_starttime, window_stoptime, window_bins\n        )\n\n        for i, event in enumerate(events):\n            if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n                continue\n\n            target_times = target_times_template + event\n\n            # Find the range of timestamps that covers our target times\n            start_search = np.searchsorted(\n                timestamps, target_times[0] - dt, side=\"left\"\n            )\n            stop_search = np.searchsorted(\n                timestamps, target_times[-1] + dt, side=\"right\"\n            )\n\n            if start_search &gt;= stop_search:\n                # Keep as NaN (already initialized)\n                continue\n\n            # Extract relevant data for this event\n            event_timestamps = timestamps[start_search:stop_search]\n            event_signal = signal[start_search:stop_search, :]\n\n            # Vectorized interpolation for all channels at once\n            if len(event_timestamps) &gt; 1:\n                for j in range(signal.shape[1]):\n                    result_matrix[:, j, i] = np.interp(\n                        target_times, event_timestamps, event_signal[:, j]\n                    )\n            # If interpolation fails, keep as NaN (already initialized)\n\n    # Return results\n    if return_average:\n        result_avg = bn.nanmean(result_matrix, axis=2)\n        if return_pandas:\n            return pd.DataFrame(\n                result_avg, index=time_lags, columns=np.arange(signal.shape[1])\n            )\n        return result_avg, time_lags\n    else:\n        return result_matrix, time_lags\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.event_triggered_average_fast","title":"<code>event_triggered_average_fast(signal, events, sampling_rate, window=[-0.5, 0.5], return_average=True, return_pandas=False)</code>","text":"<p>Calculate the event-triggered average of a signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>A 2D array of signal data with shape (channels, timepoints).</p> required <code>events</code> <code>ndarray</code> <p>A 1D array of event times.</p> required <code>sampling_rate</code> <code>int</code> <p>The sampling rate of the signal in Hz.</p> required <code>window</code> <code>Union[list, Tuple[float, float]]</code> <p>A list or tuple specifying the time window (in seconds) to average the signal around each event. Defaults to [-0.5, 0.5].</p> <code>[-0.5, 0.5]</code> <code>return_average</code> <code>bool</code> <p>Whether to return the average of the event-triggered average. Defaults to True. If False, returns the full event-triggered average matrix (channels x timepoints x events).</p> <code>True</code> <code>return_pandas</code> <code>bool</code> <p>If True, returns the average as a Pandas DataFrame. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, DataFrame]</code> <p>If <code>return_average</code> is True, returns the event-triggered average of the signal (channels x timepoints) or a Pandas DataFrame if <code>return_pandas</code> is True. If <code>return_average</code> is False, returns the full event-triggered average matrix (channels x timebins x events).</p> <code>ndarray</code> <p>An array of time lags corresponding to the event-triggered averages.</p> Notes <ul> <li>The function filters out events that do not fit within the valid range of the signal considering the specified window size.</li> <li>Assumes the signal starts at time 0.</li> </ul> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average_fast(\n    signal: np.ndarray,\n    events: np.ndarray,\n    sampling_rate: int,\n    window: Union[list, Tuple[float, float]] = [-0.5, 0.5],\n    return_average: bool = True,\n    return_pandas: bool = False,\n) -&gt; Tuple[Union[np.ndarray, pd.DataFrame], np.ndarray]:\n    \"\"\"\n    Calculate the event-triggered average of a signal.\n\n    Parameters\n    ----------\n    signal : np.ndarray\n        A 2D array of signal data with shape (channels, timepoints).\n\n    events : np.ndarray\n        A 1D array of event times.\n\n    sampling_rate : int\n        The sampling rate of the signal in Hz.\n\n    window : Union[list, Tuple[float, float]], optional\n        A list or tuple specifying the time window (in seconds) to average the signal\n        around each event. Defaults to [-0.5, 0.5].\n\n    return_average : bool, optional\n        Whether to return the average of the event-triggered average. Defaults to True.\n        If False, returns the full event-triggered average matrix (channels x timepoints x events).\n\n    return_pandas : bool, optional\n        If True, returns the average as a Pandas DataFrame. Defaults to False.\n\n    Returns\n    -------\n    Union[np.ndarray, pd.DataFrame]\n        If `return_average` is True, returns the event-triggered average of the signal\n        (channels x timepoints) or a Pandas DataFrame if `return_pandas` is True.\n        If `return_average` is False, returns the full event-triggered average matrix (channels x timebins x events).\n\n    np.ndarray\n        An array of time lags corresponding to the event-triggered averages.\n\n    Notes\n    -----\n    - The function filters out events that do not fit within the valid range of the signal\n    considering the specified window size.\n    - Assumes the signal starts at time 0.\n    \"\"\"\n\n    window_starttime, window_stoptime = window\n    window_bins = int(np.ceil(((window_stoptime - window_starttime) * sampling_rate)))\n    time_lags = np.linspace(window_starttime, window_stoptime, window_bins)\n\n    # Create valid mask instead of filtering events\n    valid_mask = (events * sampling_rate &gt; len(time_lags) / 2 + 1) &amp; (\n        events * sampling_rate &lt; signal.shape[1] - len(time_lags) / 2 + 1\n    )\n\n    # Initialize result matrix with all events, filled with NaN\n    avg_signal = np.full(\n        [signal.shape[0], len(time_lags), len(events)], np.nan, dtype=signal.dtype\n    )\n\n    # Process only valid events\n    for i, event in enumerate(events):\n        if not valid_mask[i]:  # Skip invalid events (already filled with NaN)\n            continue\n\n        ts_idx = np.arange(\n            np.round(event * sampling_rate) - len(time_lags) / 2,\n            np.round(event * sampling_rate) + len(time_lags) / 2,\n        ).astype(int)\n        avg_signal[:, :, i] = signal[:, ts_idx]\n\n    if return_pandas and return_average:\n        return pd.DataFrame(\n            index=time_lags,\n            columns=np.arange(signal.shape[0]),\n            data=bn.nanmean(avg_signal, axis=2).T,\n        )\n\n    if return_average:\n        return bn.nanmean(avg_signal, axis=2), time_lags\n    else:\n        return avg_signal, time_lags\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.event_triggered_average_irregular_sample","title":"<code>event_triggered_average_irregular_sample(timestamps, data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Compute the average and standard deviation of data values within a window around each reference time, specifically for irregularly sampled data.</p> <p>Parameters:</p> Name Type Description Default <code>timestamps</code> <code>ndarray</code> <p>A 1D array of times associated with data.</p> required <code>data</code> <code>ndarray</code> <p>A 1D array of data values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the window, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the window. Default is 100.</p> <code>100</code> <code>window</code> <code>Union[tuple, None]</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <p>Two DataFrames: the first containing the average values, the second the standard deviation of data values within the window around each reference time.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def event_triggered_average_irregular_sample(\n    timestamps: np.ndarray,\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Union[tuple, None] = None,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Compute the average and standard deviation of data values within a window around\n    each reference time, specifically for irregularly sampled data.\n\n    Parameters\n    ----------\n    timestamps : np.ndarray\n        A 1D array of times associated with data.\n    data : np.ndarray\n        A 1D array of data values.\n    time_ref : np.ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the window, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the window. Default is 100.\n    window : Union[tuple, None], optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a\n        width of `n_bins * bin_width` seconds.\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        Two DataFrames: the first containing the average values, the second the\n        standard deviation of data values within the window around each reference time.\n    \"\"\"\n\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width, bin_width)\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n    x = []\n    y = []\n    for i, r in enumerate(time_ref):\n        idx = (timestamps &gt; r + times.min()) &amp; (timestamps &lt; r + times.max())\n        x.append((timestamps - r)[idx])\n        y.append(data[idx])\n\n    temp_df = pd.DataFrame()\n    if len(x) == 0:\n        return temp_df, temp_df\n    temp_df[\"time\"] = np.hstack(x)\n    temp_df[\"data\"] = np.hstack(y)\n    temp_df = temp_df.sort_values(by=\"time\", ascending=True)\n\n    average_val = np.zeros(len(times) - 1)\n    std_val = np.zeros(len(times) - 1)\n    for i in range(len(times) - 1):\n        average_val[i] = temp_df[\n            temp_df.time.between(times[i], times[i + 1])\n        ].data.mean()\n        std_val[i] = temp_df[temp_df.time.between(times[i], times[i + 1])].data.std()\n\n    avg = pd.DataFrame(index=times[:-1] + bin_width / 2)\n    avg[0] = average_val\n\n    std = pd.DataFrame(index=times[:-1] + bin_width / 2)\n    std[0] = std_val\n\n    return avg, std\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.get_rank_order","title":"<code>get_rank_order(st, epochs, method='peak_fr', ref='cells', padding=0.05, dt=0.001, sigma=0.01, min_units=5)</code>","text":"<p>Calculate the rank order of spike trains within specified epochs.</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>ndarray or array</code> <p>Spike train data. Can be a nelpy array containing spike times.</p> required <code>epochs</code> <code>EpochArray</code> <p>An object containing the epochs (windows) in which to calculate the rank order.</p> required <code>method</code> <code>str</code> <p>Method to calculate rank order. Choices are 'first_spike' or 'peak_fr'. Defaults to 'peak_fr'.</p> <code>'peak_fr'</code> <code>ref</code> <code>str</code> <p>Reference frame for rank order. Choices are 'cells' or 'epoch'. Defaults to 'cells'.</p> <code>'cells'</code> <code>padding</code> <code>float</code> <p>Padding (in seconds) to apply to the epochs. Defaults to 0.05 seconds.</p> <code>0.05</code> <code>dt</code> <code>float</code> <p>Bin width (in seconds) for finding relative time in the epoch reference. Defaults to 0.001 seconds.</p> <code>0.001</code> <code>sigma</code> <code>float</code> <p>Smoothing sigma (in seconds) for the 'peak_fr' method. Defaults to 0.01 seconds.</p> <code>0.01</code> <code>min_units</code> <code>int</code> <p>Minimum number of active units required to compute the rank order. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>median_rank</code> <code>ndarray</code> <p>The median rank order across all epochs, normalized between 0 and 1.</p> <code>rank_order</code> <code>ndarray</code> <p>A 2D array of rank orders, where each column corresponds to an epoch, and each row corresponds to a cell, normalized between 0 and 1.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; st, _ = loading.load_spikes(basepath, putativeCellType='Pyr')\n&gt;&gt;&gt; forward_replay = nel.EpochArray(np.array([starts, stops]).T)\n&gt;&gt;&gt; median_rank, rank_order = get_rank_order(st, forward_replay)\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def get_rank_order(\n    st: SpikeTrainArray,  # Assuming 'nelpy.array' is a custom type\n    epochs: EpochArray,\n    method: str = \"peak_fr\",  # 'first_spike' or 'peak_fr'\n    ref: str = \"cells\",  # 'cells' or 'epoch'\n    padding: float = 0.05,\n    dt: float = 0.001,\n    sigma: float = 0.01,\n    min_units: int = 5,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate the rank order of spike trains within specified epochs.\n\n    Parameters\n    ----------\n    st : np.ndarray or nelpy.array\n        Spike train data. Can be a nelpy array containing spike times.\n\n    epochs : nelpy.EpochArray\n        An object containing the epochs (windows) in which to calculate the rank order.\n\n    method : str, optional\n        Method to calculate rank order. Choices are 'first_spike' or 'peak_fr'.\n        Defaults to 'peak_fr'.\n\n    ref : str, optional\n        Reference frame for rank order. Choices are 'cells' or 'epoch'.\n        Defaults to 'cells'.\n\n    padding : float, optional\n        Padding (in seconds) to apply to the epochs. Defaults to 0.05 seconds.\n\n    dt : float, optional\n        Bin width (in seconds) for finding relative time in the epoch reference.\n        Defaults to 0.001 seconds.\n\n    sigma : float, optional\n        Smoothing sigma (in seconds) for the 'peak_fr' method. Defaults to 0.01 seconds.\n\n    min_units : int, optional\n        Minimum number of active units required to compute the rank order. Defaults to 5.\n\n    Returns\n    -------\n    median_rank : np.ndarray\n        The median rank order across all epochs, normalized between 0 and 1.\n\n    rank_order : np.ndarray\n        A 2D array of rank orders, where each column corresponds to an epoch,\n        and each row corresponds to a cell, normalized between 0 and 1.\n\n    Examples\n    --------\n    &gt;&gt;&gt; st, _ = loading.load_spikes(basepath, putativeCellType='Pyr')\n    &gt;&gt;&gt; forward_replay = nel.EpochArray(np.array([starts, stops]).T)\n    &gt;&gt;&gt; median_rank, rank_order = get_rank_order(st, forward_replay)\n    \"\"\"\n    # filter out specific warnings\n    warnings.filterwarnings(\n        \"ignore\", message=\"ignoring events outside of eventarray support\"\n    )\n    warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\")\n\n    if method not in [\"first_spike\", \"peak_fr\"]:\n        raise Exception(\"method \" + method + \" not implemented\")\n    if ref not in [\"cells\", \"epoch\"]:\n        raise Exception(\"ref \" + ref + \" not implemented\")\n\n    def get_min_ts(st_temp):\n        min_ts = []\n        for ts in st_temp.data:\n            # nan if no spikes\n            if len(ts) == 0:\n                min_ts.append(np.nan)\n            else:\n                min_ts.append(np.nanmin(ts))\n        return min_ts\n\n    def rank_order_first_spike(st_epoch, epochs, dt, min_units, ref):\n        # set up empty matrix for rank order\n        rank_order = np.ones([st_epoch.data.shape[0], epochs.n_intervals]) * np.nan\n\n        unit_id = np.arange(st_epoch.data.shape[0])\n        st_epoch._abscissa.support = epochs\n\n        # iter over every event\n        for event_i, st_temp in enumerate(st_epoch):\n            if ref == \"cells\":\n                # get firing order\n                idx = np.array(st_temp.get_event_firing_order()) - 1\n                # reorder unit ids by order and remove non-active\n                units = unit_id[idx][st_temp.n_events[idx] &gt; 0]\n                # how many are left?\n                nUnits = len(units)\n\n                if nUnits &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    # arange 1 to n units in order of units\n                    rank_order[units, event_i] = np.arange(nUnits)\n                    # normalize by n units\n                    rank_order[units, event_i] = rank_order[units, event_i] / nUnits\n            elif ref == \"epoch\":\n                # find first spike time for each cell\n                min_ts = get_min_ts(st_temp)\n                # make time stamps for interpolation\n                epoch_ts = np.arange(epochs[event_i].start, epochs[event_i].stop, dt)\n                # make normalized range 0-1\n                norm_range = np.linspace(0, 1, len(epoch_ts))\n                # get spike order relative to normalized range\n                if len(min_ts) &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    rank_order[:, event_i] = np.interp(min_ts, epoch_ts, norm_range)\n        return rank_order\n\n    def rank_order_fr(st, epochs, dt, sigma, min_units, ref):\n        # set up empty matrix for rank order\n        rank_order = np.zeros([st.data.shape[0], epochs.n_intervals]) * np.nan\n\n        unit_id = np.arange(st.data.shape[0])\n\n        edges = split_epoch_by_width(epochs.data, dt)\n\n        z_t = count_in_interval(st.data, edges[:, 0], edges[:, 1], par_type=\"counts\")\n        _, interval_id = in_intervals(edges[:, 0], epochs.data, return_interval=True)\n\n        # iter over epochs\n        for event_i, epochs_temp in enumerate(epochs):\n            # smooth spike train in order to estimate peak\n            # z_t_temp.smooth(sigma=sigma, inplace=True)\n            z_t_temp = z_t[:, interval_id == event_i]\n            # smooth spike train in order to estimate peak\n            z_t_temp = gaussian_filter1d(z_t_temp, sigma / dt, axis=1)\n            if ref == \"cells\":\n                # find loc of each peak and get sorted idx of active units\n                idx = np.argsort(np.argmax(z_t_temp, axis=1))\n                # reorder unit ids by order and remove non-active\n                units = unit_id[idx][np.sum(z_t_temp[idx, :] &gt; 0, axis=1) &gt; 0]\n\n                nUnits = len(units)\n\n                if nUnits &lt; min_units:\n                    rank_order[:, event_i] = np.nan\n                else:\n                    # arange 1 to n units in order of units\n                    rank_order[units, event_i] = np.arange(nUnits)\n                    # normalize by n units\n                    rank_order[units, event_i] = rank_order[units, event_i] / nUnits\n            elif ref == \"epoch\":\n                # iterate over each cell\n                for cell_i, unit in enumerate(z_t_temp):\n                    # if the cell is not active apply nan\n                    if not np.any(unit &gt; 0):\n                        rank_order[cell_i, event_i] = np.nan\n                    else:\n                        # calculate normalized rank order (0-1)\n                        rank_order[cell_i, event_i] = np.argmax(unit) / len(unit)\n        return rank_order\n\n    # expand epochs by padding amount\n    epochs = epochs.expand(padding)\n\n    # check if no active cells\n    if st.n_active == 0:\n        return np.tile(np.nan, st.data.shape), np.tile(\n            np.nan, (st.data.shape[0], epochs.n_intervals)\n        )\n\n    # check if there are any spikes in the epoch\n    st_epoch = count_in_interval(\n        st.data, epochs.starts, epochs.stops, par_type=\"counts\"\n    )\n\n    # if no spikes in epoch, break out\n    if (st_epoch == 0).all():\n        return np.tile(np.nan, st.data.shape), np.tile(\n            np.nan, (st.data.shape[0], epochs.n_intervals)\n        )\n\n    # set up empty matrix for rank order\n    if method == \"peak_fr\":\n        rank_order = rank_order_fr(st, epochs, dt, sigma, min_units, ref)\n    elif method == \"first_spike\":\n        rank_order = rank_order_first_spike(st[epochs], epochs, dt, min_units, ref)\n    else:\n        raise Exception(\"method \" + method + \" not implemented\")\n\n    return np.nanmedian(rank_order, axis=1), rank_order\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.get_raster_points","title":"<code>get_raster_points(data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Generate points for a raster plot centered around each reference time in the <code>time_ref</code> array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A 1D array of time values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the raster plot, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the raster plot. Default is 100.</p> <code>100</code> <code>window</code> <code>tuple</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>x</code> <code>ndarray</code> <p>A 1D array of x values representing the time offsets of each data point relative to the corresponding reference time.</p> <code>y</code> <code>ndarray</code> <p>A 1D array of y values representing the reference times.</p> <code>times</code> <code>ndarray</code> <p>A 1D array of time values corresponding to the bins in the raster plot.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef get_raster_points(\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Optional[Tuple[float, float]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate points for a raster plot centered around each reference time in the `time_ref` array.\n\n    Parameters\n    ----------\n    data : ndarray\n        A 1D array of time values.\n    time_ref : ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the raster plot, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the raster plot. Default is 100.\n    window : tuple, optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a width of `n_bins * bin_width` seconds.\n\n    Returns\n    -------\n    x : ndarray\n        A 1D array of x values representing the time offsets of each data point relative to the corresponding reference time.\n    y : ndarray\n        A 1D array of y values representing the reference times.\n    times : ndarray\n        A 1D array of time values corresponding to the bins in the raster plot.\n    \"\"\"\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    x = np.empty(0)\n    y = np.empty(0)\n    for i, r in enumerate(time_ref):\n        idx = (data &gt; r + times.min()) &amp; (data &lt; r + times.max())\n        cur_data = data[idx]\n        x = np.concatenate((x, cur_data - r))\n        y = np.concatenate((y, np.ones_like(cur_data) * i))\n\n    return x, y, times\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.joint_peth","title":"<code>joint_peth(peth_1, peth_2, smooth_std=2)</code>","text":"<p>Produce a joint histogram for the co-occurrence of two sets of signals around events.</p> <p>This analysis tests for interactions. For example, the interaction of ripples and spindles around the occurrence of delta waves. It is a good way to control whether the relationships between two variables is entirely explained by a third variable (the events serving as basis for the PETHs).</p> <p>Parameters:</p> Name Type Description Default <code>peth_1</code> <code>ndarray</code> <p>The first peri-event time histogram (PETH) signal, shape (n_events, n_time).</p> required <code>peth_2</code> <code>ndarray</code> <p>The second peri-event time histogram (PETH) signal, shape (n_events, n_time).</p> required <code>smooth_std</code> <code>float</code> <p>The standard deviation of the Gaussian smoothing kernel (default is 2).</p> <code>2</code> <p>Returns:</p> Name Type Description <code>joint</code> <code>ndarray</code> <p>The joint histogram of the two PETH signals (n_time, n_time).</p> <code>expected</code> <code>ndarray</code> <p>The expected histogram of the two PETH signals (n_time, n_time).</p> <code>difference</code> <code>ndarray</code> <p>The difference between the joint and expected histograms of the two PETH signals (n_time, n_time).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.peri_event import joint_peth, peth_matrix, joint_peth\n&gt;&gt;&gt; from neuro_py.spikes.spike_tools import get_spindices\n&gt;&gt;&gt; from neuro_py.io import loading\n</code></pre> <pre><code>&gt;&gt;&gt; # load ripples, delta waves, and PFC pyramidal cell spikes from basepath\n</code></pre> <pre><code>&gt;&gt;&gt; basepath = r\"Z:\\Data\\HMC1\\day8\"\n</code></pre> <pre><code>&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; delta_waves = loading.load_events(basepath, epoch_name=\"deltaWaves\")\n&gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"PFC\",putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # flatten spikes (nelpy has .flatten(), but get_spindices is much faster)\n&gt;&gt;&gt; spikes = get_spindices(st.data)\n</code></pre> <pre><code>&gt;&gt;&gt; # create peri-event time histograms (PETHs) for the three signals\n&gt;&gt;&gt; window=[-1,1]\n&gt;&gt;&gt; labels = [\"spikes\", \"ripple\", \"delta\"]\n&gt;&gt;&gt; peth_1,ts = peth_matrix(spikes.spike_times.values, delta_waves.starts, bin_width=0.02, n_bins=101)\n&gt;&gt;&gt; peth_2,ts = peth_matrix(ripples.starts, delta_waves.starts, bin_width=0.02, n_bins=101)\n</code></pre> <pre><code>&gt;&gt;&gt; # calculate the joint, expected, and difference histograms\n&gt;&gt;&gt; joint, expected, difference = joint_peth(peth_1.T, peth_2.T, smooth_std=2)\n</code></pre> Notes <p>Note: sometimes the difference between \"joint\" and \"expected\" may be dominated due to brain state effects (e.g. if both ripples are spindles are more common around delta waves taking place in early SWS and have decreased rates around delta waves in late SWS, then all the values of \"joint\" would be larger than the value of \"expected\". In such a case, to investigate the timing effects in particular and ignore such global changes (correlations across the rows of \"PETH1\" and \"PETH2\"), consider normalizing the rows of the PETHs before calling joint_peth.</p> <p>See Sirota et al. (2003)</p> <p>Adapted from JointPETH.m, Copyright (C) 2018-2022 by Ralitsa Todorova</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def joint_peth(\n    peth_1: np.ndarray, peth_2: np.ndarray, smooth_std: float = 2\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Produce a joint histogram for the co-occurrence of two sets of signals around events.\n\n    This analysis tests for interactions. For example, the interaction of\n    ripples and spindles around the occurrence of delta waves. It is a good way\n    to control whether the relationships between two variables is entirely explained\n    by a third variable (the events serving as basis for the PETHs).\n\n    Parameters\n    ----------\n    peth_1 : np.ndarray\n        The first peri-event time histogram (PETH) signal, shape (n_events, n_time).\n    peth_2 : np.ndarray\n        The second peri-event time histogram (PETH) signal, shape (n_events, n_time).\n    smooth_std : float, optional\n        The standard deviation of the Gaussian smoothing kernel (default is 2).\n\n    Returns\n    -------\n    joint : np.ndarray\n        The joint histogram of the two PETH signals (n_time, n_time).\n    expected : np.ndarray\n        The expected histogram of the two PETH signals (n_time, n_time).\n    difference : np.ndarray\n        The difference between the joint and expected histograms of the two PETH signals (n_time, n_time).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.peri_event import joint_peth, peth_matrix, joint_peth\n    &gt;&gt;&gt; from neuro_py.spikes.spike_tools import get_spindices\n    &gt;&gt;&gt; from neuro_py.io import loading\n\n    &gt;&gt;&gt; # load ripples, delta waves, and PFC pyramidal cell spikes from basepath\n\n    &gt;&gt;&gt; basepath = r\"Z:\\\\Data\\\\HMC1\\\\day8\"\n\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; delta_waves = loading.load_events(basepath, epoch_name=\"deltaWaves\")\n    &gt;&gt;&gt; st,cm = loading.load_spikes(basepath,brainRegion=\"PFC\",putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # flatten spikes (nelpy has .flatten(), but get_spindices is much faster)\n    &gt;&gt;&gt; spikes = get_spindices(st.data)\n\n    &gt;&gt;&gt; # create peri-event time histograms (PETHs) for the three signals\n    &gt;&gt;&gt; window=[-1,1]\n    &gt;&gt;&gt; labels = [\"spikes\", \"ripple\", \"delta\"]\n    &gt;&gt;&gt; peth_1,ts = peth_matrix(spikes.spike_times.values, delta_waves.starts, bin_width=0.02, n_bins=101)\n    &gt;&gt;&gt; peth_2,ts = peth_matrix(ripples.starts, delta_waves.starts, bin_width=0.02, n_bins=101)\n\n    &gt;&gt;&gt; # calculate the joint, expected, and difference histograms\n    &gt;&gt;&gt; joint, expected, difference = joint_peth(peth_1.T, peth_2.T, smooth_std=2)\n\n    Notes\n    -----\n    Note: sometimes the difference between \"joint\" and \"expected\" may be dominated due to\n    brain state effects (e.g. if both ripples are spindles are more common around delta\n    waves taking place in early SWS and have decreased rates around delta waves in late\n    SWS, then all the values of \"joint\" would be larger than the value of \"expected\".\n    In such a case, to investigate the timing effects in particular and ignore such\n    global changes (correlations across the rows of \"PETH1\" and \"PETH2\"), consider\n    normalizing the rows of the PETHs before calling joint_peth.\n\n    See Sirota et al. (2003)\n\n    Adapted from JointPETH.m, Copyright (C) 2018-2022 by Ralitsa Todorova\n    \"\"\"\n    from scipy.ndimage import gaussian_filter\n\n    # make inputs np.ndarrays\n    peth_1 = np.array(peth_1)\n    peth_2 = np.array(peth_2)\n\n    # calculate the joint histogram\n    joint = peth_1.T @ peth_2\n\n    # smooth the 2d joint histogram\n    joint = gaussian_filter(joint, smooth_std)\n\n    # calculate the expected histogram\n    expected = np.tile(np.nanmean(peth_1, axis=0), [peth_1.shape[0], 1]).T @ np.tile(\n        np.nanmean(peth_2, axis=0), [peth_2.shape[0], 1]\n    )\n\n    # smooth the 2d expected histogram\n    expected = gaussian_filter(expected, smooth_std)\n\n    # normalize the joint and expected histograms\n    joint = joint / peth_1.shape[0]\n    expected = expected / peth_1.shape[0]\n\n    # square root the joint and expected histograms so result is Hz\n    joint = np.sqrt(joint)\n    expected = np.sqrt(expected)\n\n    # calculate the difference between the joint and expected histograms\n    difference = joint - expected\n\n    return joint, expected, difference\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.nearest_event_delay","title":"<code>nearest_event_delay(ts_1, ts_2)</code>","text":"<p>Return for each timestamp in ts_1 the nearest timestamp in ts_2 and the delay between the two.</p> <p>Parameters:</p> Name Type Description Default <code>ts_1</code> <code>ndarray</code> <p>1D array of timestamps.</p> required <code>ts_2</code> <code>ndarray</code> <p>1D array of timestamps (must be monotonically increasing).</p> required <p>Returns:</p> Name Type Description <code>nearest_ts</code> <code>ndarray</code> <p>Nearest timestamps in ts_2 for each timestamp in ts_1.</p> <code>delays</code> <code>ndarray</code> <p>Delays between ts_1 and nearest_ts.</p> <code>nearest_index</code> <code>ndarray</code> <p>Index of nearest_ts in ts_2.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If ts_1 or ts_2 are empty or not monotonically increasing.</p> Notes <p>Both ts_1 and ts_2 must be monotonically increasing arrays of timestamps.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def nearest_event_delay(\n    ts_1: np.ndarray, ts_2: np.ndarray\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Return for each timestamp in ts_1 the nearest timestamp in ts_2 and the delay between the two.\n\n    Parameters\n    ----------\n    ts_1 : np.ndarray\n        1D array of timestamps.\n    ts_2 : np.ndarray\n        1D array of timestamps (must be monotonically increasing).\n\n    Returns\n    -------\n    nearest_ts : np.ndarray\n        Nearest timestamps in ts_2 for each timestamp in ts_1.\n    delays : np.ndarray\n        Delays between ts_1 and nearest_ts.\n    nearest_index : np.ndarray\n        Index of nearest_ts in ts_2.\n\n    Raises\n    ------\n    ValueError\n        If ts_1 or ts_2 are empty or not monotonically increasing.\n\n    Notes\n    -----\n    Both ts_1 and ts_2 must be monotonically increasing arrays of timestamps.\n    \"\"\"\n    ts_1, ts_2 = np.array(ts_1), np.array(ts_2)\n\n    if not np.all(np.diff(ts_2) &gt; 0):\n        raise ValueError(\"ts_2 must be monotonically increasing\")\n\n    if not np.all(np.diff(ts_1) &gt; 0):\n        raise ValueError(\"ts_1 must be monotonically increasing\")\n    # check if empty\n    if len(ts_1) == 0:\n        raise ValueError(\"ts_1 is empty\")\n    if len(ts_2) == 0:\n        raise ValueError(\"ts_2 is empty\")\n\n    # Use searchsorted to find the indices where elements of ts_1 should be inserted\n    nearest_indices = np.searchsorted(ts_2, ts_1, side=\"left\")\n\n    # Calculate indices for the elements before and after the insertion points\n    before = np.maximum(nearest_indices - 1, 0)\n    after = np.minimum(nearest_indices, len(ts_2) - 1)\n\n    # Determine the nearest timestamp for each element in ts_1\n    nearest_ts = np.where(\n        np.abs(ts_1 - ts_2[before]) &lt; np.abs(ts_1 - ts_2[after]),\n        ts_2[before],\n        ts_2[after],\n    )\n\n    # Calculate delays between ts_1 and nearest_ts\n    delays = ts_1 - nearest_ts\n\n    # Find the nearest_index using the absolute difference\n    absolute_diff_before = np.abs(ts_1 - ts_2[before])\n    absolute_diff_after = np.abs(ts_1 - ts_2[after])\n    nearest_index = np.where(absolute_diff_before &lt; absolute_diff_after, before, after)\n\n    return nearest_ts, delays, nearest_index\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.peth","title":"<code>peth(data, events, window=None, bin_width=0.002, n_bins=100, average=True)</code>","text":"<p>Compute peri-event time histogram (PETH) for nelpy data objects or numpy arrays.</p> <p>This is a high-level function that handles multiple data types and automatically computes the appropriate PETH based on the input data type. For point process data (spikes/events), it computes firing rates (Hz). For continuous data (analog signals), it computes event-triggered averages.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>nelpy object or np.ndarray</code> <p>Data can be: - AnalogSignalArray: continuous signals - PositionArray: 2D/3D position data (x, y, [z] coordinates) - SpikeTrainArray: spike trains - BinnedSpikeTrainArray: binned spike trains - EventArray: event times - BinnedEventArray: binned events - np.ndarray: array of spike times (object array) or continuous signal</p> required <code>events</code> <code>ndarray</code> <p>1D array of event times to align data to.</p> required <code>window</code> <code>list</code> <p>Time window around events [start, end] in seconds. If None, uses symmetric window based on n_bins and bin_width.</p> <code>None</code> <code>bin_width</code> <code>float</code> <p>Width of time bins in seconds (default 0.002).</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>Number of bins (default 100). Ignored if window is specified.</p> <code>100</code> <code>average</code> <code>bool</code> <p>If True (default), returns averaged PETH across all events as DataFrame. If False, returns event-wise PETH matrix and time bins array.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame or Tuple[ndarray, ndarray]</code> <p>If average=True:     DataFrame with time bins as index and each series/signal as columns.     Values are rates (Hz) for point process data or averaged     signal values for continuous data. If average=False:     Tuple of (peth_matrix, time_bins) where:     - peth_matrix: 3D array with shape (n_time_bins, n_signals, n_events)     - time_bins: 1D array of time bin centers</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # With SpikeTrainArray - averaged across events\n&gt;&gt;&gt; st, _ = loading.load_spikes(basepath)\n&gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; peth_df = peth(st, ripples.starts, window=[-0.5, 0.5], bin_width=0.01)\n</code></pre> <pre><code>&gt;&gt;&gt; # Get event-wise matrix for detailed analysis\n&gt;&gt;&gt; peth_matrix, time_bins = peth(st, ripples.starts, window=[-0.5, 0.5],\n...                               bin_width=0.01, average=False)\n&gt;&gt;&gt; # peth_matrix.shape: (n_time_bins, n_units, n_events)\n&gt;&gt;&gt; # Can now analyze individual events\n&gt;&gt;&gt; strong_events = peth_matrix.sum(axis=(0,1)) &gt; threshold\n</code></pre> <pre><code>&gt;&gt;&gt; # With AnalogSignalArray\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from nelpy import AnalogSignalArray\n&gt;&gt;&gt; timestamps = np.linspace(0, 5, 100)\n&gt;&gt;&gt; signal = np.vstack([\n...     np.sin(2 * np.pi * timestamps),\n...     np.cos(2 * np.pi * timestamps),\n... ])\n&gt;&gt;&gt; lfp = AnalogSignalArray(timestamps=timestamps, data=signal)\n&gt;&gt;&gt; events = np.array([1.0, 2.0, 3.0])\n&gt;&gt;&gt; peth_df = peth(lfp, events, window=[-0.2, 0.2])\n</code></pre> <pre><code>&gt;&gt;&gt; # Get event-wise continuous data\n&gt;&gt;&gt; lfp_matrix, time_lags = peth(lfp, events, window=[-0.2, 0.2], average=False)\n</code></pre> <pre><code>&gt;&gt;&gt; # With PositionArray\n&gt;&gt;&gt; from nelpy import PositionArray\n&gt;&gt;&gt; x_pos = np.sin(2 * np.pi * timestamps)\n&gt;&gt;&gt; y_pos = np.cos(2 * np.pi * timestamps)\n&gt;&gt;&gt; position = PositionArray(timestamps=timestamps, data=np.vstack([x_pos, y_pos]))\n&gt;&gt;&gt; peth_df = peth(position, events, window=[-0.5, 0.5])\n</code></pre> <pre><code>&gt;&gt;&gt; # With numpy array\n&gt;&gt;&gt; spikes = np.array([spike_train_1, spike_train_2], dtype=object)\n&gt;&gt;&gt; peth_df = peth(spikes, events, window=[-0.5, 0.5])\n</code></pre> Notes <ul> <li>For point process data (spikes/events), uses crossCorr to compute firing rates</li> <li>For continuous data (analog signals), uses event_triggered_average<ul> <li>For continuous data, output resolution follows the signal sampling rate;     <code>bin_width</code> is ignored unless you resample beforehand</li> <li>For numpy/object arrays of spike times, each spike train must be sorted in     ascending order (crossCorr assumes sorted targets)</li> </ul> </li> <li>Returns rates in Hz for point process data</li> <li>Handles both regular and irregularly sampled continuous data</li> </ul> See Also <p>compute_psth : Lower-level PSTH computation for numpy arrays event_triggered_average : Event-triggered averaging for continuous signals crossCorr : Cross-correlogram computation</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def peth(\n    data,\n    events: np.ndarray,\n    window: Union[list, None] = None,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    average: bool = True,\n) -&gt; Union[pd.DataFrame, Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Compute peri-event time histogram (PETH) for nelpy data objects or numpy arrays.\n\n    This is a high-level function that handles multiple data types and automatically\n    computes the appropriate PETH based on the input data type. For point process data\n    (spikes/events), it computes firing rates (Hz). For continuous data (analog signals),\n    it computes event-triggered averages.\n\n    Parameters\n    ----------\n    data : nelpy object or np.ndarray\n        Data can be:\n        - AnalogSignalArray: continuous signals\n        - PositionArray: 2D/3D position data (x, y, [z] coordinates)\n        - SpikeTrainArray: spike trains\n        - BinnedSpikeTrainArray: binned spike trains\n        - EventArray: event times\n        - BinnedEventArray: binned events\n        - np.ndarray: array of spike times (object array) or continuous signal\n    events : np.ndarray\n        1D array of event times to align data to.\n    window : list, optional\n        Time window around events [start, end] in seconds.\n        If None, uses symmetric window based on n_bins and bin_width.\n    bin_width : float, optional\n        Width of time bins in seconds (default 0.002).\n    n_bins : int, optional\n        Number of bins (default 100). Ignored if window is specified.\n    average : bool, optional\n        If True (default), returns averaged PETH across all events as DataFrame.\n        If False, returns event-wise PETH matrix and time bins array.\n\n    Returns\n    -------\n    pd.DataFrame or Tuple[np.ndarray, np.ndarray]\n        If average=True:\n            DataFrame with time bins as index and each series/signal as columns.\n            Values are rates (Hz) for point process data or averaged\n            signal values for continuous data.\n        If average=False:\n            Tuple of (peth_matrix, time_bins) where:\n            - peth_matrix: 3D array with shape (n_time_bins, n_signals, n_events)\n            - time_bins: 1D array of time bin centers\n\n    Examples\n    --------\n    &gt;&gt;&gt; # With SpikeTrainArray - averaged across events\n    &gt;&gt;&gt; st, _ = loading.load_spikes(basepath)\n    &gt;&gt;&gt; ripples = loading.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; peth_df = peth(st, ripples.starts, window=[-0.5, 0.5], bin_width=0.01)\n\n    &gt;&gt;&gt; # Get event-wise matrix for detailed analysis\n    &gt;&gt;&gt; peth_matrix, time_bins = peth(st, ripples.starts, window=[-0.5, 0.5],\n    ...                               bin_width=0.01, average=False)\n    &gt;&gt;&gt; # peth_matrix.shape: (n_time_bins, n_units, n_events)\n    &gt;&gt;&gt; # Can now analyze individual events\n    &gt;&gt;&gt; strong_events = peth_matrix.sum(axis=(0,1)) &gt; threshold\n\n    &gt;&gt;&gt; # With AnalogSignalArray\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from nelpy import AnalogSignalArray\n    &gt;&gt;&gt; timestamps = np.linspace(0, 5, 100)\n    &gt;&gt;&gt; signal = np.vstack([\n    ...     np.sin(2 * np.pi * timestamps),\n    ...     np.cos(2 * np.pi * timestamps),\n    ... ])\n    &gt;&gt;&gt; lfp = AnalogSignalArray(timestamps=timestamps, data=signal)\n    &gt;&gt;&gt; events = np.array([1.0, 2.0, 3.0])\n    &gt;&gt;&gt; peth_df = peth(lfp, events, window=[-0.2, 0.2])\n\n    &gt;&gt;&gt; # Get event-wise continuous data\n    &gt;&gt;&gt; lfp_matrix, time_lags = peth(lfp, events, window=[-0.2, 0.2], average=False)\n\n    &gt;&gt;&gt; # With PositionArray\n    &gt;&gt;&gt; from nelpy import PositionArray\n    &gt;&gt;&gt; x_pos = np.sin(2 * np.pi * timestamps)\n    &gt;&gt;&gt; y_pos = np.cos(2 * np.pi * timestamps)\n    &gt;&gt;&gt; position = PositionArray(timestamps=timestamps, data=np.vstack([x_pos, y_pos]))\n    &gt;&gt;&gt; peth_df = peth(position, events, window=[-0.5, 0.5])\n\n    &gt;&gt;&gt; # With numpy array\n    &gt;&gt;&gt; spikes = np.array([spike_train_1, spike_train_2], dtype=object)\n    &gt;&gt;&gt; peth_df = peth(spikes, events, window=[-0.5, 0.5])\n\n    Notes\n    -----\n    - For point process data (spikes/events), uses crossCorr to compute firing rates\n    - For continuous data (analog signals), uses event_triggered_average\n        - For continuous data, output resolution follows the signal sampling rate;\n            `bin_width` is ignored unless you resample beforehand\n        - For numpy/object arrays of spike times, each spike train must be sorted in\n            ascending order (crossCorr assumes sorted targets)\n    - Returns rates in Hz for point process data\n    - Handles both regular and irregularly sampled continuous data\n\n    See Also\n    --------\n    compute_psth : Lower-level PSTH computation for numpy arrays\n    event_triggered_average : Event-triggered averaging for continuous signals\n    crossCorr : Cross-correlogram computation\n    \"\"\"\n\n    # Determine data type and extract spike/signal data\n    is_continuous = False\n\n    if isinstance(\n        data,\n        (AnalogSignalArray, PositionArray, BinnedSpikeTrainArray, BinnedEventArray),\n    ):\n        # Continuous signal data (includes position and binned spike/event data)\n        is_continuous = True\n\n        # Use bin_centers for binned data, abscissa_vals for others\n        if isinstance(data, (BinnedSpikeTrainArray, BinnedEventArray)):\n            timestamps = data.bin_centers\n        else:\n            timestamps = data.abscissa_vals\n\n        signal = data.data.T  # transpose to (n_samples, n_signals)\n        # Use n_signals if available (AnalogSignalArray/PositionArray), otherwise n_series (BinnedSpikeTrainArray)\n        n_series = getattr(\n            data, \"n_series\", getattr(data, \"n_signals\", data.data.shape[0])\n        )\n\n    elif isinstance(data, (SpikeTrainArray, EventArray)):\n        # Point process data - extract spike times\n        is_continuous = False\n        spike_data = data.data\n        n_series = len(spike_data)\n\n    elif isinstance(data, np.ndarray):\n        # Numpy array - determine if continuous or point process\n        if data.dtype == object:\n            # Object array - assume point process\n            is_continuous = False\n            spike_data = data\n            n_series = len(spike_data)\n        else:\n            # Regular array - could be continuous or point process\n            # If 2D, assume continuous; if 1D, assume point process\n            if data.ndim == 2:\n                # Continuous data\n                is_continuous = True\n                # Need timestamps - if not provided, we can't use event_triggered_average\n                # Fall back to treating as point process\n                raise ValueError(\n                    \"For continuous numpy arrays, please use AnalogSignalArray or provide \"\n                    \"timestamps separately via event_triggered_average function.\"\n                )\n            else:\n                # 1D array - single point process\n                is_continuous = False\n                spike_data = np.array([data], dtype=object)\n                n_series = 1\n    else:\n        raise TypeError(\n            f\"Unsupported data type: {type(data)}. \"\n            \"Must be AnalogSignalArray, PositionArray, SpikeTrainArray, BinnedSpikeTrainArray, \"\n            \"EventArray, BinnedEventArray, or np.ndarray\"\n        )\n\n    # Calculate time bins\n    window_original = None\n    if window is not None:\n        # Check if window is symmetric around 0, if not make it so\n        if ((window[1] - window[0]) / 2 != window[1]) | (\n            (window[1] - window[0]) / -2 != window[0]\n        ):\n            window_original = np.array(window)\n            window = [-np.max(np.abs(window)), np.max(np.abs(window))]\n\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        n_bins = len(times) - 1\n    else:\n        times = np.linspace(\n            -(n_bins * bin_width) / 2, (n_bins * bin_width) / 2, n_bins + 1\n        )\n\n    # Compute PETH based on data type\n    if is_continuous:\n        # Continuous data - use event_triggered_average\n        if window is None:\n            window = [times[0], times[-1]]\n\n        # Calculate sampling rate\n        sampling_rate = 1 / np.median(np.diff(timestamps))\n\n        # Compute event-triggered average\n        result, time_lags = event_triggered_average(\n            timestamps,\n            signal,\n            events,\n            sampling_rate=sampling_rate,\n            window=window,\n            return_average=average,\n            return_pandas=False,\n        )\n\n        if average:\n            # Create DataFrame from averaged result\n            peth_df = pd.DataFrame(result, index=time_lags, columns=np.arange(n_series))\n        else:\n            # Return matrix directly: (n_time_bins, n_signals, n_events)\n            # event_triggered_average already returns in the correct shape\n            return result, time_lags\n\n    else:\n        # Point process data\n        if average:\n            # Use crossCorr for averaged PETH\n            peth_df = pd.DataFrame(index=times, columns=np.arange(n_series))\n\n            for i, s in enumerate(spike_data):\n                # Ensure spike times are float64\n                if len(s) &gt; 0:\n                    s = np.asarray(s, dtype=np.float64)\n                else:\n                    s = np.array([], dtype=np.float64)\n                peth_df[i] = crossCorr(events, s, bin_width, n_bins)\n        else:\n            # Use peth_matrix for event-wise PETH\n            # Build matrix for each spike train: (n_time_bins, n_signals, n_events)\n            matrices_list = []\n            window_arg = None if window is None else (window[0], window[1])\n\n            for i, s in enumerate(spike_data):\n                # Ensure spike times are float64\n                if len(s) &gt; 0:\n                    s = np.asarray(s, dtype=np.float64)\n                else:\n                    s = np.array([], dtype=np.float64)\n\n                # peth_matrix returns (n_time_bins, n_events)\n                H, t = peth_matrix(\n                    s, events, bin_width=bin_width, n_bins=n_bins, window=window_arg\n                )\n                matrices_list.append(H)\n\n            # Stack into (n_time_bins, n_signals, n_events)\n            result_matrix = np.stack(matrices_list, axis=1)\n\n            # If window was not symmetric, trim the time dimension\n            if window is not None and window_original is not None:\n                mask = (t &gt;= window_original[0]) &amp; (t &lt;= window_original[1])\n                result_matrix = result_matrix[mask, :, :]\n                t = t[mask]\n\n            return result_matrix, t\n\n    # If window was not symmetric, remove the extra bins (only for averaged DataFrame)\n    if average and window is not None and window_original is not None:\n        peth_df = peth_df.loc[window_original[0] : window_original[1], :]\n\n    return peth_df\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.peth_matrix","title":"<code>peth_matrix(data, time_ref, bin_width=0.002, n_bins=100, window=None)</code>","text":"<p>Generate a peri-event time histogram (PETH) matrix.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>A 1D array of time values.</p> required <code>time_ref</code> <code>ndarray</code> <p>A 1D array of reference times.</p> required <code>bin_width</code> <code>float</code> <p>The width of each bin in the PETH matrix, in seconds. Default is 0.002 seconds.</p> <code>0.002</code> <code>n_bins</code> <code>int</code> <p>The number of bins in the PETH matrix. Default is 100.</p> <code>100</code> <code>window</code> <code>tuple</code> <p>A tuple containing the start and end times of the window to be plotted around each reference time. If not provided, the window will be centered around each reference time and have a width of <code>n_bins * bin_width</code> seconds. Use a tuple to avoid numba reflected-list warnings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>H</code> <code>ndarray</code> <p>A 2D array representing the PETH matrix with rates in Hz. Shape is (n_time_bins, n_events).</p> <code>t</code> <code>ndarray</code> <p>A 1D array of time values corresponding to the bins in the PETH matrix.</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True, parallel=True)\ndef peth_matrix(\n    data: np.ndarray,\n    time_ref: np.ndarray,\n    bin_width: float = 0.002,\n    n_bins: int = 100,\n    window: Union[Tuple[float, float], None] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate a peri-event time histogram (PETH) matrix.\n\n    Parameters\n    ----------\n    data : ndarray\n        A 1D array of time values.\n    time_ref : ndarray\n        A 1D array of reference times.\n    bin_width : float, optional\n        The width of each bin in the PETH matrix, in seconds. Default is 0.002 seconds.\n    n_bins : int, optional\n        The number of bins in the PETH matrix. Default is 100.\n    window : tuple, optional\n        A tuple containing the start and end times of the window to be plotted around each reference time.\n        If not provided, the window will be centered around each reference time and have a width of `n_bins * bin_width` seconds.\n        Use a tuple to avoid numba reflected-list warnings.\n\n    Returns\n    -------\n    H : ndarray\n        A 2D array representing the PETH matrix with rates in Hz.\n        Shape is (n_time_bins, n_events).\n    t : ndarray\n        A 1D array of time values corresponding to the bins in the PETH matrix.\n\n    \"\"\"\n    if window is not None:\n        times = np.arange(window[0], window[1] + bin_width / 2, bin_width)\n        # Compute n_bins from window-based times\n        n_bins = len(times) - 1\n        # Ensure n_bins is odd, same way crossCorr does it\n        if np.floor(n_bins / 2) * 2 == n_bins:\n            n_bins = n_bins + 1\n    else:\n        # Ensure n_bins is odd before computing times (crossCorr expects odd)\n        n_bins = int(n_bins)\n        if np.floor(n_bins / 2) * 2 == n_bins:\n            n_bins = n_bins + 1\n\n        times = (\n            np.arange(0, bin_width * n_bins, bin_width)\n            - (bin_width * n_bins) / 2\n            + bin_width / 2\n        )\n\n    H = np.zeros((len(times), len(time_ref)))\n\n    for event_i in prange(len(time_ref)):\n        H[:, event_i] = crossCorr([time_ref[event_i]], data, bin_width, n_bins)\n\n    return H, times\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.relative_times","title":"<code>relative_times(t, intervals, values=np.array([0, 1]))</code>","text":"<p>Calculate relative times and interval IDs for a set of time points.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>An array of time points.</p> required <code>intervals</code> <code>ndarray</code> <p>An array of time intervals, represented as pairs of start and end times.</p> required <code>values</code> <code>ndarray</code> <p>An array of values to assign to interval bounds. The default is [0,1].</p> <code>array([0, 1])</code> <p>Returns:</p> Name Type Description <code>rt</code> <code>ndarray</code> <p>An array of relative times, one for each time point (same len as t).</p> <code>intervalID</code> <code>ndarray</code> <p>An array of interval IDs, one for each time point (same len as t).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n&gt;&gt;&gt; relative_times(t, intervals)\n    (array([nan, 0. , 0.5, 1. , 0. , 0.5, 1. , 0. , 0.5, 1. ]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n</code></pre> <pre><code>&gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n&gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n&gt;&gt;&gt; values = np.array([0, 2*np.pi])\n&gt;&gt;&gt; relative_times(t, intervals, values)\n    (array([       nan, 0.        , 3.14159265, 6.28318531, 0.        ,\n            3.14159265, 6.28318531, 0.        , 3.14159265, 6.28318531]),\n    array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n</code></pre> Notes <p>Intervals are defined as pairs of start and end times. The relative time is the time within the interval, normalized to the interval duration. The interval ID is the index of the interval in the intervals array. The values array can be used to assign a value to each interval.</p> <p>By Ryan H, based on RelativeTimes.m by Ralitsa Todorova</p> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>@jit(nopython=True)\ndef relative_times(\n    t: np.ndarray, intervals: np.ndarray, values: np.ndarray = np.array([0, 1])\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate relative times and interval IDs for a set of time points.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        An array of time points.\n    intervals : np.ndarray\n        An array of time intervals, represented as pairs of start and end times.\n    values : np.ndarray, optional\n        An array of values to assign to interval bounds. The default is [0,1].\n\n    Returns\n    -------\n    rt : np.ndarray\n        An array of relative times, one for each time point (same len as t).\n    intervalID : np.ndarray\n        An array of interval IDs, one for each time point (same len as t).\n\n    Examples\n    --------\n    &gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    &gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n    &gt;&gt;&gt; relative_times(t, intervals)\n        (array([nan, 0. , 0.5, 1. , 0. , 0.5, 1. , 0. , 0.5, 1. ]),\n        array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n\n    &gt;&gt;&gt; t = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    &gt;&gt;&gt; intervals = np.array([[1, 3], [4, 6], [7, 9]])\n    &gt;&gt;&gt; values = np.array([0, 2*np.pi])\n    &gt;&gt;&gt; relative_times(t, intervals, values)\n        (array([       nan, 0.        , 3.14159265, 6.28318531, 0.        ,\n                3.14159265, 6.28318531, 0.        , 3.14159265, 6.28318531]),\n        array([nan,  0.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  2.]))\n\n    Notes\n    -----\n    Intervals are defined as pairs of start and end times. The relative time is the time\n    within the interval, normalized to the interval duration. The interval ID is the index\n    of the interval in the intervals array. The values array can be used to assign a value\n    to each interval.\n\n    By Ryan H, based on RelativeTimes.m by Ralitsa Todorova\n\n    \"\"\"\n\n    rt = np.zeros(len(t), dtype=np.float64) * np.nan\n    intervalID = np.zeros(len(t), dtype=np.float64) * np.nan\n\n    start_times = intervals[:, 0]\n    end_times = intervals[:, 1]\n    values_diff = values[1] - values[0]\n    intervals_diff = end_times - start_times\n    intervals_scale = values_diff / intervals_diff\n\n    for i in range(len(t)):\n        idx = np.searchsorted(start_times, t[i])\n        if idx &gt; 0 and t[i] &lt;= end_times[idx - 1]:\n            interval_i = idx - 1\n        elif idx &lt; len(start_times) and t[i] == start_times[idx]:\n            interval_i = idx\n        else:\n            continue\n\n        scale = intervals_scale[interval_i]\n        rt[i] = ((t[i] - start_times[interval_i]) * scale) + values[0]\n        intervalID[i] = interval_i\n\n    return rt, intervalID\n</code></pre>"},{"location":"reference/neuro_py/process/peri_event/#neuro_py.process.peri_event.sync","title":"<code>sync(samples, sync_times, durations=(-0.5, 0.5), fast=True)</code>","text":"<p>Synchronize sample timestamps to reference events.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>ndarray</code> <p>Sample array with timestamps in the first column. Can be shape (n_samples,) or (n_samples, n_features). Assumed to be sorted by default.</p> required <code>sync_times</code> <code>ndarray</code> <p>1D array of synchronizing event times. Assumed to be sorted by default.</p> required <code>durations</code> <code>tuple of float</code> <p>Time window around each event as (start, stop), in seconds. Defaults to (-0.5, 0.5).</p> <code>(-0.5, 0.5)</code> <code>fast</code> <code>bool</code> <p>If True, assumes <code>samples</code> and <code>sync_times</code> are already sorted and skips sorting. If False, sorts the inputs (slower but handles unsorted data). Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>synchronized</code> <code>ndarray</code> <p>Samples that fall within event windows, with first column replaced by time relative to event.</p> <code>Ie</code> <code>ndarray</code> <p>Event indices for each synchronized sample, referencing the original <code>sync_times</code> order (0-based indices).</p> <code>Is</code> <code>ndarray</code> <p>Sample indices for each synchronized sample, referencing the original <code>samples</code> order (0-based indices).</p> Notes <p>By default, this function assumes both <code>samples</code> and <code>sync_times</code> are sorted in ascending order for maximum performance. If your data is unsorted, set <code>fast=False</code> to enable automatic sorting (with index remapping).</p> <p>Similar to get_raster_points but returns the synchronized samples in a single array and also returns the indices of the events and samples that correspond to each synchronized sample. Also is much faster than get_raster_points.</p> References <ul> <li>Original MATLAB implementation: Sync.m from FMAToolbox</li> </ul> <p>Examples:</p> <p>Basic usage with 1D timestamps:</p> <pre><code>&gt;&gt;&gt; samples = np.array([0.9, 1.1, 2.0, 2.1, 3.0])\n&gt;&gt;&gt; sync_times = np.array([1.0, 2.0])\n&gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15))\n&gt;&gt;&gt; synchronized[:, 0]\narray([-0.1,  0.1,  0. ,  0.1])\n&gt;&gt;&gt; Ie\narray([0, 0, 1, 1])\n&gt;&gt;&gt; Is\narray([0, 1, 2, 3])\n</code></pre> <p>Usage with unsorted samples and extra columns:</p> <pre><code>&gt;&gt;&gt; samples = np.array([[2.0, 20.0], [0.9, 9.0], [1.1, 11.0], [2.1, 21.0]])\n&gt;&gt;&gt; sync_times = np.array([2.0, 1.0])\n&gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15), fast=False)\n&gt;&gt;&gt; synchronized[:, 0]\narray([-0.1,  0.1,  0. ,  0.1])\n&gt;&gt;&gt; Ie  # indices into original sync_times\narray([1, 1, 0, 0])\n&gt;&gt;&gt; Is  # indices into original samples\narray([1, 2, 0, 3])\n</code></pre> <p>Real-world example with spike times and ripple events:</p> <pre><code>&gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP17\\hp17_day48_20250603\"\n&gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n&gt;&gt;&gt; ripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n&gt;&gt;&gt; sleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)\n&gt;&gt;&gt; nrem = sleep_states.get(\"NREMstate\")\n&gt;&gt;&gt; synchronized, Ie, Is = npy.process.sync(\n...     st.data[1], ripples[nrem].starts, durations=(-0.5, 0.5)\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; plt.figure(figsize=(6, 4))\n&gt;&gt;&gt; plt.scatter(synchronized[:, 0], Ie, s=4, alpha=0.2, marker=\"|\", color=\"k\")\n&gt;&gt;&gt; plt.axvline(0, color=\"r\", ls=\"--\", lw=2)\n&gt;&gt;&gt; plt.xlabel(\"Time from event (s)\")\n&gt;&gt;&gt; plt.ylabel(\"Event #\")\n&gt;&gt;&gt; plt.title(\"Event-aligned raster\")\n&gt;&gt;&gt; plt.xlim(-0.5, 0.5)\n&gt;&gt;&gt; plt.ylim(0, np.max(Ie) + 1)\n&gt;&gt;&gt; plt.show()\n</code></pre> Source code in <code>neuro_py/process/peri_event.py</code> <pre><code>def sync(\n    samples: np.ndarray,\n    sync_times: np.ndarray,\n    durations: Tuple[float, float] = (-0.5, 0.5),\n    fast: bool = True,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Synchronize sample timestamps to reference events.\n\n    Parameters\n    ----------\n    samples : np.ndarray\n        Sample array with timestamps in the first column. Can be shape (n_samples,)\n        or (n_samples, n_features). Assumed to be sorted by default.\n    sync_times : np.ndarray\n        1D array of synchronizing event times. Assumed to be sorted by default.\n    durations : tuple of float, optional\n        Time window around each event as (start, stop), in seconds.\n        Defaults to (-0.5, 0.5).\n    fast : bool, optional\n        If True, assumes `samples` and `sync_times` are already sorted and skips sorting.\n        If False, sorts the inputs (slower but handles unsorted data).\n        Defaults to True.\n\n    Returns\n    -------\n    synchronized : np.ndarray\n        Samples that fall within event windows, with first column replaced by\n        time relative to event.\n    Ie : np.ndarray\n        Event indices for each synchronized sample, referencing the original\n        `sync_times` order (0-based indices).\n    Is : np.ndarray\n        Sample indices for each synchronized sample, referencing the original\n        `samples` order (0-based indices).\n\n    Notes\n    -----\n    By default, this function assumes both `samples` and `sync_times` are sorted\n    in ascending order for maximum performance. If your data is unsorted, set\n    `fast=False` to enable automatic sorting (with index remapping).\n\n    Similar to get_raster_points but returns the synchronized samples in a\n    single array and also returns the indices of the events and samples that\n    correspond to each synchronized sample. Also is much faster than get_raster_points.\n\n\n    References\n    ----------\n    - Original MATLAB implementation: Sync.m from FMAToolbox\n\n    Examples\n    --------\n    Basic usage with 1D timestamps:\n\n    &gt;&gt;&gt; samples = np.array([0.9, 1.1, 2.0, 2.1, 3.0])\n    &gt;&gt;&gt; sync_times = np.array([1.0, 2.0])\n    &gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15))\n    &gt;&gt;&gt; synchronized[:, 0]\n    array([-0.1,  0.1,  0. ,  0.1])\n    &gt;&gt;&gt; Ie\n    array([0, 0, 1, 1])\n    &gt;&gt;&gt; Is\n    array([0, 1, 2, 3])\n\n    Usage with unsorted samples and extra columns:\n\n    &gt;&gt;&gt; samples = np.array([[2.0, 20.0], [0.9, 9.0], [1.1, 11.0], [2.1, 21.0]])\n    &gt;&gt;&gt; sync_times = np.array([2.0, 1.0])\n    &gt;&gt;&gt; synchronized, Ie, Is = sync(samples, sync_times, durations=(-0.15, 0.15), fast=False)\n    &gt;&gt;&gt; synchronized[:, 0]\n    array([-0.1,  0.1,  0. ,  0.1])\n    &gt;&gt;&gt; Ie  # indices into original sync_times\n    array([1, 1, 0, 0])\n    &gt;&gt;&gt; Is  # indices into original samples\n    array([1, 2, 0, 3])\n\n    Real-world example with spike times and ripple events:\n\n    &gt;&gt;&gt; basepath = r\"U:\\data\\hpc_ctx_project\\HP17\\hp17_day48_20250603\"\n    &gt;&gt;&gt; st, cm = npy.io.load_spikes(basepath, brainRegion=\"CA1\")\n    &gt;&gt;&gt; ripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; sleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)\n    &gt;&gt;&gt; nrem = sleep_states.get(\"NREMstate\")\n    &gt;&gt;&gt; synchronized, Ie, Is = npy.process.sync(\n    ...     st.data[1], ripples[nrem].starts, durations=(-0.5, 0.5)\n    ... )\n\n    &gt;&gt;&gt; plt.figure(figsize=(6, 4))\n    &gt;&gt;&gt; plt.scatter(synchronized[:, 0], Ie, s=4, alpha=0.2, marker=\"|\", color=\"k\")\n    &gt;&gt;&gt; plt.axvline(0, color=\"r\", ls=\"--\", lw=2)\n    &gt;&gt;&gt; plt.xlabel(\"Time from event (s)\")\n    &gt;&gt;&gt; plt.ylabel(\"Event #\")\n    &gt;&gt;&gt; plt.title(\"Event-aligned raster\")\n    &gt;&gt;&gt; plt.xlim(-0.5, 0.5)\n    &gt;&gt;&gt; plt.ylim(0, np.max(Ie) + 1)\n    &gt;&gt;&gt; plt.show()\n    \"\"\"\n    samples = np.asarray(samples)\n    sync_times = np.asarray(sync_times)\n\n    if samples.ndim == 1:\n        samples = samples.reshape(-1, 1)\n    if samples.ndim != 2 or samples.shape[1] &lt; 1:\n        raise ValueError(\n            \"'samples' must be a 1D array or a 2D array with timestamps in column 0\"\n        )\n    if sync_times.ndim == 2 and sync_times.shape[1] == 1:\n        sync_times = sync_times[:, 0]\n    elif sync_times.ndim != 1:\n        raise ValueError(\"'sync_times' must be a 1D array or a 2D column vector\")\n    if len(durations) != 2 or durations[0] &gt; durations[1]:\n        raise ValueError(\"'durations' must be (start, stop) with start &lt;= stop\")\n\n    if len(sync_times) == 0 or samples.shape[0] == 0:\n        return (\n            np.empty((0, samples.shape[1])),\n            np.array([], dtype=int),\n            np.array([], dtype=int),\n        )\n\n    sort_samples = None\n    sort_sync = None\n\n    work_samples = samples\n    work_sync = sync_times\n\n    if not fast:\n        sort_samples = np.argsort(samples[:, 0], kind=\"mergesort\")\n        work_samples = samples[sort_samples]\n\n        sort_sync = np.argsort(sync_times, kind=\"mergesort\")\n        work_sync = sync_times[sort_sync]\n\n    sample_times = work_samples[:, 0]\n\n    # Use numba-compiled functions for the core sweep and index filling\n    starts, stops, events_with_hits, total_hits = _sync_find_windows(\n        sample_times, work_sync, durations[0], durations[1]\n    )\n\n    if len(starts) == 0:\n        return (\n            np.empty((0, samples.shape[1])),\n            np.array([], dtype=int),\n            np.array([], dtype=int),\n        )\n\n    Is, Ie = _sync_fill_indices(starts, stops, events_with_hits, total_hits)\n\n    # Ensure synchronized has floating dtype so relative times are preserved\n    # If samples were integer, subtraction would silently truncate to integers\n    synchronized = work_samples[Is].astype(np.float64, copy=True)\n    synchronized[:, 0] = synchronized[:, 0] - work_sync[Ie]\n\n    if sort_samples is not None:\n        Is = sort_samples[Is]\n    if sort_sync is not None:\n        Ie = sort_sync[Ie]\n\n    return synchronized, Ie, Is\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/","title":"neuro_py.process.precession_utils","text":""},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.acf_power","title":"<code>acf_power(acf, norm=True)</code>","text":"<p>Compute the power spectrum of the signal by calculating the FFT of the autocorrelation function (ACF).</p> <p>Parameters:</p> Name Type Description Default <code>acf</code> <code>ndarray</code> <p>1D array of counts for the ACF.</p> required <code>norm</code> <code>bool</code> <p>If True, normalize the power spectrum. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>psd</code> <code>ndarray</code> <p>1D array representing the power spectrum of the signal.</p> Notes <p>The power spectrum is computed by taking the Fourier Transform of the ACF, then squaring the absolute values of the FFT result. The Nyquist frequency is accounted for by returning only the first half of the spectrum.</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def acf_power(acf: np.ndarray, norm: Optional[bool] = True) -&gt; np.ndarray:\n    \"\"\"\n    Compute the power spectrum of the signal by calculating the FFT of the autocorrelation function (ACF).\n\n    Parameters\n    ----------\n    acf : np.ndarray\n        1D array of counts for the ACF.\n    norm : bool, optional\n        If True, normalize the power spectrum. Default is True.\n\n    Returns\n    -------\n    psd : np.ndarray\n        1D array representing the power spectrum of the signal.\n\n    Notes\n    -----\n    The power spectrum is computed by taking the Fourier Transform of the ACF,\n    then squaring the absolute values of the FFT result.\n    The Nyquist frequency is accounted for by returning only the first half of the spectrum.\n    \"\"\"\n\n    # Take the FFT\n    fft = np.fft.fft(acf)\n\n    # Compute the power spectrum\n    pow = np.abs(fft) ** 2\n\n    # Account for Nyquist frequency\n    psd = pow[: pow.shape[0] // 2]\n\n    # Normalize if required\n    if norm:\n        psd = psd / np.trapezoid(psd)\n\n    return psd\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.corrcc","title":"<code>corrcc(alpha1, alpha2, axis=None)</code>","text":"<p>Circular correlation coefficient for two circular random variables.</p> <p>Parameters:</p> Name Type Description Default <code>alpha1</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>alpha2</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>axis</code> <code>Optional[int]</code> <p>The axis along which to compute the correlation coefficient. If None, compute over the entire array (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-circular correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n&gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n&gt;&gt;&gt; rho, pval = corrcc(alpha1, alpha2)\n&gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n</code></pre> Notes <p>The function computes the correlation between two sets of angles using a method that adjusts for circular data. The significance of the correlation coefficient is tested using the fact that the test statistic is approximately normally distributed.</p> References <p>Jammalamadaka et al (2001)</p> <p>Original code: https://github.com/circstat/pycircstat Modified by: Salman Qasim, 11/12/2018</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def corrcc(\n    alpha1: np.ndarray, alpha2: np.ndarray, axis: Optional[int] = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Circular correlation coefficient for two circular random variables.\n\n    Parameters\n    ----------\n    alpha1 : np.ndarray\n        Sample of angles in radians.\n    alpha2 : np.ndarray\n        Sample of angles in radians.\n    axis : Optional[int], optional\n        The axis along which to compute the correlation coefficient.\n        If None, compute over the entire array (default is None).\n\n    Returns\n    -------\n    rho : float\n        Circular-circular correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n\n    Examples\n    --------\n    &gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n    &gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n    &gt;&gt;&gt; rho, pval = corrcc(alpha1, alpha2)\n    &gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n\n    Notes\n    -----\n    The function computes the correlation between two sets of angles using a\n    method that adjusts for circular data. The significance of the correlation\n    coefficient is tested using the fact that the test statistic is approximately\n    normally distributed.\n\n    References\n    ----------\n    Jammalamadaka et al (2001)\n\n    Original code: https://github.com/circstat/pycircstat\n    Modified by: Salman Qasim, 11/12/2018\n    \"\"\"\n    assert alpha1.shape == alpha2.shape, \"Input dimensions do not match.\"\n\n    n = len(alpha1)\n\n    # center data on circular mean\n    alpha1_centered, alpha2_centered = pcs.center(alpha1, alpha2, axis=axis)\n\n    num = np.sum(np.sin(alpha1_centered) * np.sin(alpha2_centered), axis=axis)\n    den = np.sqrt(\n        np.sum(np.sin(alpha1_centered) ** 2, axis=axis)\n        * np.sum(np.sin(alpha2_centered) ** 2, axis=axis)\n    )\n    # compute correlation coefficient from p. 176\n    rho = num / den\n\n    # Modification:\n    # significance of this correlation coefficient can be tested using the fact that Z is approx. normal\n\n    l20 = np.mean(np.sin(alpha1_centered) ** 2)\n    l02 = np.mean(np.sin(alpha2_centered) ** 2)\n    l22 = np.mean((np.sin(alpha1_centered) ** 2) * (np.sin(alpha2_centered) ** 2))\n    z = np.sqrt((n * l20 * l02) / l22) * rho\n    pval = 2 * (1 - sp.stats.norm.cdf(np.abs(z)))  # two-sided test\n\n    return rho, pval\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.corrcc_uniform","title":"<code>corrcc_uniform(alpha1, alpha2, axis=None)</code>","text":"<p>Circular correlation coefficient for two circular random variables. Use this function if at least one of the variables may follow a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>alpha1</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>alpha2</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>axis</code> <code>Optional[int]</code> <p>The axis along which to compute the correlation coefficient. If None, compute over the entire array (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-circular correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> Notes <p>This method accounts for cases where one or both of the circular variables may follow a uniform distribution. The significance of the correlation coefficient is tested using a normal approximation of the Z statistic.</p> References <p>Jammalamadaka, et al (2001).</p> <p>Original code: https://github.com/circstat/pycircstat Modified by: Salman Qasim, 11/12/2018 https://github.com/HoniSanders/measure_phaseprec/blob/master/cl_corr.m</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n&gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n&gt;&gt;&gt; rho, pval = corrcc_uniform(alpha1, alpha2)\n&gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n</code></pre> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def corrcc_uniform(\n    alpha1: np.ndarray, alpha2: np.ndarray, axis: Optional[int] = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Circular correlation coefficient for two circular random variables.\n    Use this function if at least one of the variables may follow a uniform distribution.\n\n    Parameters\n    ----------\n    alpha1 : np.ndarray\n        Sample of angles in radians.\n    alpha2 : np.ndarray\n        Sample of angles in radians.\n    axis : Optional[int], optional\n        The axis along which to compute the correlation coefficient.\n        If None, compute over the entire array (default is None).\n\n    Returns\n    -------\n    rho : float\n        Circular-circular correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n\n    Notes\n    -----\n    This method accounts for cases where one or both of the circular variables\n    may follow a uniform distribution. The significance of the correlation coefficient\n    is tested using a normal approximation of the Z statistic.\n\n    References\n    ----------\n    Jammalamadaka, et al (2001).\n\n    Original code: https://github.com/circstat/pycircstat\n    Modified by: Salman Qasim, 11/12/2018\n    https://github.com/HoniSanders/measure_phaseprec/blob/master/cl_corr.m\n\n    Examples\n    --------\n    &gt;&gt;&gt; alpha1 = np.array([0.1, 0.2, 0.4, 0.5])\n    &gt;&gt;&gt; alpha2 = np.array([0.3, 0.6, 0.2, 0.8])\n    &gt;&gt;&gt; rho, pval = corrcc_uniform(alpha1, alpha2)\n    &gt;&gt;&gt; print(f\"Circular correlation: {rho}, p-value: {pval}\")\n    \"\"\"\n\n    assert alpha1.shape == alpha2.shape, \"Input dimensions do not match.\"\n\n    n = len(alpha1)\n\n    # center data on circular mean\n    alpha1_centered, alpha2_centered = pcs.center(alpha1, alpha2, axis=axis)\n\n    # One of the sample means is not well defined due to uniform distribution of data\n    # so take the difference of the resultant vector length for the sum and difference\n    # of the alphas\n    num = pcs.resultant_vector_length(alpha1 - alpha2) - pcs.resultant_vector_length(\n        alpha1 + alpha2\n    )\n    den = 2 * np.sqrt(\n        np.sum(np.sin(alpha1_centered) ** 2, axis=axis)\n        * np.sum(np.sin(alpha2_centered) ** 2, axis=axis)\n    )\n    rho = n * num / den\n    # significance of this correlation coefficient can be tested using the fact that Z\n    # is approx. normal\n\n    l20 = np.mean(np.sin(alpha1_centered) ** 2)\n    l02 = np.mean(np.sin(alpha2_centered) ** 2)\n    l22 = np.mean((np.sin(alpha1_centered) ** 2) * (np.sin(alpha2_centered) ** 2))\n    z = np.sqrt((n * l20 * l02) / l22) * rho\n    pval = 2 * (1 - sp.stats.norm.cdf(np.abs(z)))  # two-sided test\n\n    return rho, pval\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.fast_acf","title":"<code>fast_acf(counts, width, bin_width, cut_peak=True)</code>","text":"<p>Compute the Auto-Correlation Function (ACF) in a fast manner using Numba.</p> <p>This function calculates the ACF of a given variable of interest, such as spike times or spike phases, leveraging the <code>pcorrelate</code> function for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>ndarray</code> <p>1D array of the variable of interest (e.g., spike times or spike phases).</p> required <code>width</code> <code>float</code> <p>Time window for the ACF computation.</p> required <code>bin_width</code> <code>float</code> <p>Width of the bins for the ACF.</p> required <code>cut_peak</code> <code>bool</code> <p>If True, the largest central peak will be replaced for subsequent fitting. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>acf</code> <code>ndarray</code> <p>1D array of counts for the ACF.</p> <code>bins</code> <code>ndarray</code> <p>1D array of lag bins for the ACF.</p> Notes <ul> <li>The ACF is calculated over a specified time window and returns the   counts of the ACF along with the corresponding bins.</li> <li>The <code>cut_peak</code> parameter allows for the adjustment of the ACF peak, which   can be useful for fitting processes.</li> </ul> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def fast_acf(\n    counts: np.ndarray, width: float, bin_width: float, cut_peak: bool = True\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute the Auto-Correlation Function (ACF) in a fast manner using Numba.\n\n    This function calculates the ACF of a given variable of interest, such as\n    spike times or spike phases, leveraging the `pcorrelate` function for efficiency.\n\n    Parameters\n    ----------\n    counts : np.ndarray\n        1D array of the variable of interest (e.g., spike times or spike phases).\n    width : float\n        Time window for the ACF computation.\n    bin_width : float\n        Width of the bins for the ACF.\n    cut_peak : bool, optional\n        If True, the largest central peak will be replaced for subsequent fitting. Default is True.\n\n    Returns\n    -------\n    acf : np.ndarray\n        1D array of counts for the ACF.\n    bins : np.ndarray\n        1D array of lag bins for the ACF.\n\n    Notes\n    -----\n    - The ACF is calculated over a specified time window and returns the\n      counts of the ACF along with the corresponding bins.\n    - The `cut_peak` parameter allows for the adjustment of the ACF peak, which\n      can be useful for fitting processes.\n    \"\"\"\n\n    n_b = int(np.ceil(width / bin_width))  # Num. edges per side\n    # Define the edges of the bins (including rightmost bin)\n    bins = np.linspace(-width, width, 2 * n_b, endpoint=True)\n    temp = pcorrelate(counts, counts, np.split(bins, 2)[1])\n    acf = np.ones(bins.shape[0] - 1)\n    acf[0 : temp.shape[0]] = np.flip(temp)\n    acf[temp.shape[0]] = temp[0]\n    acf[temp.shape[0] + 1 :] = temp\n\n    if cut_peak:\n        acf[np.nanargmax(acf)] = np.sort(acf)[-2]\n\n    return acf, bins\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.nonspatial_phase_precession","title":"<code>nonspatial_phase_precession(unwrapped_spike_phases, width=4 * 2 * np.pi, bin_width=np.pi / 3, cut_peak=True, norm=True, psd_lims=[0.65, 1.55], upsample=4, smooth_sigma=1)</code>","text":"<p>Compute the nonspatial spike-LFP relationship modulation index.</p> <p>Parameters:</p> Name Type Description Default <code>unwrapped_spike_phases</code> <code>ndarray</code> <p>1D array of spike phases that have been linearly unwrapped.</p> required <code>width</code> <code>float</code> <p>Time window for ACF in cycles (default = 4 cycles).</p> <code>4 * 2 * pi</code> <code>bin_width</code> <code>float</code> <p>Width of bins in radians (default = pi/3 radians).</p> <code>pi / 3</code> <code>cut_peak</code> <code>bool</code> <p>Whether or not the largest central peak should be replaced for subsequent fitting.</p> <code>True</code> <code>norm</code> <code>bool</code> <p>To normalize the ACF or not.</p> <code>True</code> <code>psd_lims</code> <code>List[float]</code> <p>Limits of the PSD to consider for peak finding (default = [0.65, 1.55]).</p> <code>[0.65, 1.55]</code> <code>upsample</code> <code>int</code> <p>Upsampling factor (default = 4).</p> <code>4</code> <code>smooth_sigma</code> <code>float</code> <p>Standard deviation for Gaussian smoothing of the PSD (default = 1).</p> <code>1</code> <p>Returns:</p> Name Type Description <code>max_freq</code> <code>float</code> <p>Relative spike-LFP frequency of the PSD peak.</p> <code>MI</code> <code>float</code> <p>Modulation index of non-spatial phase relationship.</p> <code>psd</code> <code>ndarray</code> <p>Power spectral density of interest.</p> <code>frequencies</code> <code>ndarray</code> <p>Frequencies corresponding to the PSD.</p> <code>acf</code> <code>ndarray</code> <p>Autocorrelation function.</p> Notes <p>The modulation index (MI) is computed based on the maximum peak of the power spectral density (PSD) within specified frequency limits.</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def nonspatial_phase_precession(\n    unwrapped_spike_phases: np.ndarray,\n    width: float = 4 * 2 * np.pi,\n    bin_width: float = np.pi / 3,\n    cut_peak: bool = True,\n    norm: bool = True,\n    psd_lims: List[float] = [0.65, 1.55],\n    upsample: int = 4,\n    smooth_sigma: float = 1,\n) -&gt; Tuple[float, float, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute the nonspatial spike-LFP relationship modulation index.\n\n    Parameters\n    ----------\n    unwrapped_spike_phases : np.ndarray\n        1D array of spike phases that have been linearly unwrapped.\n    width : float\n        Time window for ACF in cycles (default = 4 cycles).\n    bin_width : float\n        Width of bins in radians (default = pi/3 radians).\n    cut_peak : bool\n        Whether or not the largest central peak should be replaced for subsequent fitting.\n    norm : bool\n        To normalize the ACF or not.\n    psd_lims : List[float]\n        Limits of the PSD to consider for peak finding (default = [0.65, 1.55]).\n    upsample : int\n        Upsampling factor (default = 4).\n    smooth_sigma : float\n        Standard deviation for Gaussian smoothing of the PSD (default = 1).\n\n    Returns\n    -------\n    max_freq : float\n        Relative spike-LFP frequency of the PSD peak.\n    MI : float\n        Modulation index of non-spatial phase relationship.\n    psd : np.ndarray\n        Power spectral density of interest.\n    frequencies : np.ndarray\n        Frequencies corresponding to the PSD.\n    acf : np.ndarray\n        Autocorrelation function.\n\n    Notes\n    -----\n    The modulation index (MI) is computed based on the maximum peak of the power\n    spectral density (PSD) within specified frequency limits.\n    \"\"\"\n\n    frequencies = (\n        (np.arange(2 * (width // bin_width) - 1))\n        * (2 * np.pi)\n        / (2 * width - bin_width)\n    )\n\n    frequencies = np.interp(\n        np.arange(0, len(frequencies), 1 / upsample),\n        np.arange(0, len(frequencies)),\n        frequencies,\n    )\n\n    freqs_of_interest = np.intersect1d(\n        np.where(frequencies &gt; psd_lims[0]), np.where(frequencies &lt; psd_lims[1])\n    )\n\n    acf, _ = fast_acf(unwrapped_spike_phases, width, bin_width, cut_peak=cut_peak)\n    psd = acf_power(acf, norm=norm)\n\n    # upsample 2x psd\n    psd = np.interp(np.arange(0, len(psd), 1 / upsample), np.arange(0, len(psd)), psd)\n    # smooth psd with gaussian filter\n    psd = gaussian_filter1d(psd, smooth_sigma)\n\n    # FIND ALL LOCAL MAXIMA IN WINDOW OF INTEREST\n    all_peaks = find_peaks(psd[freqs_of_interest], None)[0]\n\n    # make sure there is a peak\n    if ~np.any(all_peaks):\n        return (\n            np.nan,\n            np.nan,\n            psd[freqs_of_interest],\n            frequencies[freqs_of_interest],\n            acf,\n        )\n\n    max_peak = np.max(psd[freqs_of_interest][all_peaks])\n    max_idx = [all_peaks[np.argmax(psd[freqs_of_interest][all_peaks])]]\n    max_freq = frequencies[freqs_of_interest][max_idx]\n    MI = max_peak / np.trapezoid(psd[freqs_of_interest])\n\n    return max_freq, MI, psd[freqs_of_interest], frequencies[freqs_of_interest], acf\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.pcorrelate","title":"<code>pcorrelate(t, u, bins)</code>","text":"<p>Compute the correlation of two arrays of discrete events (point-process).</p> <p>This function computes the correlation of two time series of events using an arbitrary array of lag-bins. It implements the algorithm described in Laurence (2006) (https://doi.org/10.1364/OL.31.000829).</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>ndarray</code> <p>First array of \"points\" to correlate. The array needs to be monotonically increasing.</p> required <code>u</code> <code>ndarray</code> <p>Second array of \"points\" to correlate. The array needs to be monotonically increasing.</p> required <code>bins</code> <code>ndarray</code> <p>Array of bin edges where correlation is computed.</p> required <p>Returns:</p> Name Type Description <code>G</code> <code>ndarray</code> <p>Array containing the correlation of <code>t</code> and <code>u</code>. The size is <code>len(bins) - 1</code>.</p> Notes <ul> <li>This method is designed for efficiently computing the correlation between   two point processes, such as photon arrival times or event positions.</li> <li>The algorithm is implemented with a focus on performance, leveraging   Numba for JIT compilation.</li> </ul> References <p>Laurence, T., et al. (2006).</p> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>@numba.jit(nopython=True)\ndef pcorrelate(t: np.ndarray, u: np.ndarray, bins: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute the correlation of two arrays of discrete events (point-process).\n\n    This function computes the correlation of two time series of events\n    using an arbitrary array of lag-bins. It implements the algorithm described\n    in Laurence (2006) (https://doi.org/10.1364/OL.31.000829).\n\n    Parameters\n    ----------\n    t : np.ndarray\n        First array of \"points\" to correlate. The array needs to be monotonically increasing.\n    u : np.ndarray\n        Second array of \"points\" to correlate. The array needs to be monotonically increasing.\n    bins : np.ndarray\n        Array of bin edges where correlation is computed.\n\n    Returns\n    -------\n    G : np.ndarray\n        Array containing the correlation of `t` and `u`. The size is `len(bins) - 1`.\n\n    Notes\n    -----\n    - This method is designed for efficiently computing the correlation between\n      two point processes, such as photon arrival times or event positions.\n    - The algorithm is implemented with a focus on performance, leveraging\n      Numba for JIT compilation.\n\n    References\n    ----------\n    Laurence, T., et al. (2006).\n    \"\"\"\n    nbins = len(bins) - 1\n\n    # Array of counts (histogram)\n    counts = np.zeros(nbins, dtype=np.int64)\n\n    # For each bins, imin is the index of first `u` &gt;= of each left bin edge\n    imin = np.zeros(nbins, dtype=np.int64)\n    # For each bins, imax is the index of first `u` &gt;= of each right bin edge\n    imax = np.zeros(nbins, dtype=np.int64)\n\n    # For each ti, perform binning of (u - ti) and accumulate counts in Y\n    for ti in t:\n        for k, (tau_min, tau_max) in enumerate(zip(bins[:-1], bins[1:])):\n            if k == 0:\n                j = imin[k]\n                # We start by finding the index of the first `u` element\n                # which is &gt;= of the first bin edge `tau_min`\n                while j &lt; len(u):\n                    if u[j] - ti &gt;= tau_min:\n                        break\n                    j += 1\n\n            imin[k] = j\n            if imax[k] &gt; j:\n                j = imax[k]\n            while j &lt; len(u):\n                if u[j] - ti &gt;= tau_max:\n                    break\n                j += 1\n            imax[k] = j\n            # Now j is the index of the first `u` element &gt;= of\n            # the next bin left edge\n        counts += imax - imin\n    G = counts / np.diff(bins)\n    return G\n</code></pre>"},{"location":"reference/neuro_py/process/precession_utils/#neuro_py.process.precession_utils.spatial_phase_precession","title":"<code>spatial_phase_precession(circ, lin, slope_bounds=[-3 * np.pi, 3 * np.pi])</code>","text":"<p>Compute the circular-linear correlation as described in https://pubmed.ncbi.nlm.nih.gov/22487609/.</p> <p>Parameters:</p> Name Type Description Default <code>circ</code> <code>ndarray</code> <p>Circular data in radians (e.g., spike phases).</p> required <code>lin</code> <code>ndarray</code> <p>Linear data (e.g., spike positions).</p> required <code>slope_bounds</code> <code>Union[List[float], Tuple[float, float]]</code> <p>The slope range for optimization (default is [-3 * np.pi, 3 * np.pi]).</p> <code>[-3 * pi, 3 * pi]</code> <p>Returns:</p> Name Type Description <code>rho</code> <code>float</code> <p>Circular-linear correlation coefficient.</p> <code>pval</code> <code>float</code> <p>p-value for testing the significance of the correlation coefficient.</p> <code>sl</code> <code>float</code> <p>Slope of the circular-linear correlation.</p> <code>offs</code> <code>float</code> <p>Offset of the circular-linear correlation.</p> Notes <p>This method computes a circular-linear correlation and can handle cases where one or both variables may follow a uniform distribution. It differs from the linear-circular correlation used in other studies (e.g., https://science.sciencemag.org/content/340/6138/1342).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; circ = np.random.uniform(0, 2 * np.pi, 100)\n&gt;&gt;&gt; lin = np.random.uniform(0, 1, 100)\n&gt;&gt;&gt; rho, pval, sl, offs = spatial_phase_precession(circ, lin)\n&gt;&gt;&gt; print(f\"Correlation: {rho}, p-value: {pval}, slope: {sl}, offset: {offs}\")\n</code></pre> Source code in <code>neuro_py/process/precession_utils.py</code> <pre><code>def spatial_phase_precession(\n    circ: np.ndarray,\n    lin: np.ndarray,\n    slope_bounds: Union[List[float], Tuple[float, float]] = [-3 * np.pi, 3 * np.pi],\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"\n    Compute the circular-linear correlation as described in https://pubmed.ncbi.nlm.nih.gov/22487609/.\n\n    Parameters\n    ----------\n    circ : np.ndarray\n        Circular data in radians (e.g., spike phases).\n    lin : np.ndarray\n        Linear data (e.g., spike positions).\n    slope_bounds : Union[List[float], Tuple[float, float]], optional\n        The slope range for optimization (default is [-3 * np.pi, 3 * np.pi]).\n\n    Returns\n    -------\n    rho : float\n        Circular-linear correlation coefficient.\n    pval : float\n        p-value for testing the significance of the correlation coefficient.\n    sl : float\n        Slope of the circular-linear correlation.\n    offs : float\n        Offset of the circular-linear correlation.\n\n    Notes\n    -----\n    This method computes a circular-linear correlation and can handle cases\n    where one or both variables may follow a uniform distribution. It differs from\n    the linear-circular correlation used in other studies (e.g., https://science.sciencemag.org/content/340/6138/1342).\n\n    Examples\n    -------\n    &gt;&gt;&gt; circ = np.random.uniform(0, 2 * np.pi, 100)\n    &gt;&gt;&gt; lin = np.random.uniform(0, 1, 100)\n    &gt;&gt;&gt; rho, pval, sl, offs = spatial_phase_precession(circ, lin)\n    &gt;&gt;&gt; print(f\"Correlation: {rho}, p-value: {pval}, slope: {sl}, offset: {offs}\")\n    \"\"\"\n\n    # Get rid of all the nans in this data\n    nan_index = np.logical_or(np.isnan(circ), np.isnan(lin))\n    circ = circ[~nan_index]\n    lin = lin[~nan_index]\n\n    # Make sure there are still valid data\n    if np.size(lin) == 0:\n        return np.nan, np.nan, np.nan, np.nan\n\n    def myfun1(p):\n        return -np.sqrt(\n            (np.sum(np.cos(circ - (p * lin))) / len(circ)) ** 2\n            + (np.sum(np.sin(circ - (p * lin))) / len(circ)) ** 2\n        )\n\n    # finding the optimal slope, note that we have to restrict the range of slopes\n\n    sl = sp.optimize.fminbound(\n        myfun1,\n        slope_bounds[0] / (np.max(lin) - np.min(lin)),\n        slope_bounds[1] / (np.max(lin) - np.min(lin)),\n    )\n\n    # calculate offset\n    offs = np.arctan2(\n        np.sum(np.sin(circ - (sl * lin))), np.sum(np.cos(circ - (sl * lin)))\n    )\n    # offs = (offs + np.pi) % (2 * np.pi) - np.pi\n    offs = np.arctan2(np.sin(offs), np.cos(offs))\n\n    # circular variable derived from the linearization\n    linear_circ = np.mod(abs(sl) * lin, 2 * np.pi)\n\n    # # marginal distributions:\n    p1, z1 = pcs.rayleigh(circ)\n    p2, z2 = pcs.rayleigh(linear_circ)\n\n    # circular-linear correlation:\n    if (p1 &gt; 0.5) | (p2 &gt; 0.5):\n        # This means at least one of our variables may be a uniform distribution\n        rho, pval = corrcc_uniform(circ, linear_circ)\n    else:\n        rho, pval = corrcc(circ, linear_circ)\n\n    # Assign the correct sign to rho\n    if sl &lt; 0:\n        rho = -np.abs(rho)\n    else:\n        rho = np.abs(rho)\n\n    # if offs &lt; 0:\n    #     offs = offs + 2 * np.pi\n    # if offs &gt; np.pi:\n    #     offs = offs - 2 * np.pi\n\n    return rho, pval, sl, offs\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/","title":"neuro_py.process.pychronux","text":""},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.dpsschk","title":"<code>dpsschk(tapers, N, Fs)</code>","text":"<p>Check and generate DPSS tapers.</p> <p>Parameters:</p> Name Type Description Default <code>tapers</code> <code>Union[ndarray, Tuple[float, int]]</code> <p>Input can be either an array representing [NW, K] or a tuple with the number of tapers and the maximum number of tapers.</p> required <code>N</code> <code>int</code> <p>Number of points for FFT.</p> required <code>Fs</code> <code>float</code> <p>Sampling frequency.</p> required <p>Returns:</p> Name Type Description <code>tapers</code> <code>ndarray</code> <p>Tapers matrix, shape [tapers, eigenvalues].</p> Notes <p>The function computes DPSS (Discrete Prolate Spheroidal Sequences) tapers and scales them by the square root of the sampling frequency.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def dpsschk(\n    tapers: Union[np.ndarray, Tuple[float, int]], N: int, Fs: float\n) -&gt; np.ndarray:\n    \"\"\"\n    Check and generate DPSS tapers.\n\n    Parameters\n    ----------\n    tapers : Union[np.ndarray, Tuple[float, int]]\n        Input can be either an array representing [NW, K] or a tuple with\n        the number of tapers and the maximum number of tapers.\n    N : int\n        Number of points for FFT.\n    Fs : float\n        Sampling frequency.\n\n    Returns\n    -------\n    tapers : np.ndarray\n        Tapers matrix, shape [tapers, eigenvalues].\n\n    Notes\n    -----\n    The function computes DPSS (Discrete Prolate Spheroidal Sequences) tapers\n    and scales them by the square root of the sampling frequency.\n    \"\"\"\n    tapers, eigs = dpss(N, NW=tapers[0], Kmax=tapers[1], sym=False, return_ratios=True)\n    tapers = tapers * np.sqrt(Fs)\n    tapers = tapers.T\n    return tapers\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.get_tapers","title":"<code>get_tapers(N, bandwidth, *, fs=1.0, min_lambda=0.95, n_tapers=None)</code>","text":"<p>Compute tapers and associated energy concentrations for the Thomson multitaper method.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Length of taper.</p> required <code>bandwidth</code> <code>float</code> <p>Bandwidth of taper, in Hz.</p> required <code>fs</code> <code>float</code> <p>Sampling rate, in Hz. Default is 1 Hz.</p> <code>1.0</code> <code>min_lambda</code> <code>float</code> <p>Minimum energy concentration that each taper must satisfy. Default is 0.95.</p> <code>0.95</code> <code>n_tapers</code> <code>Optional[int]</code> <p>Number of tapers to compute. Default is to use all tapers that satisfy 'min_lambda'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tapers</code> <code>ndarray</code> <p>Array of tapers with shape (n_tapers, N).</p> <code>lambdas</code> <code>ndarray</code> <p>Energy concentrations for each taper with shape (n_tapers,).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If not enough tapers are available or if none of the tapers satisfy the minimum energy concentration criteria.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def get_tapers(\n    N: int,\n    bandwidth: float,\n    *,\n    fs: float = 1.0,\n    min_lambda: float = 0.95,\n    n_tapers: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute tapers and associated energy concentrations for the Thomson\n    multitaper method.\n\n    Parameters\n    ----------\n    N : int\n        Length of taper.\n    bandwidth : float\n        Bandwidth of taper, in Hz.\n    fs : float, optional\n        Sampling rate, in Hz. Default is 1 Hz.\n    min_lambda : float, optional\n        Minimum energy concentration that each taper must satisfy. Default is 0.95.\n    n_tapers : Optional[int], optional\n        Number of tapers to compute. Default is to use all tapers that satisfy 'min_lambda'.\n\n    Returns\n    -------\n    tapers : np.ndarray\n        Array of tapers with shape (n_tapers, N).\n    lambdas : np.ndarray\n        Energy concentrations for each taper with shape (n_tapers,).\n\n    Raises\n    ------\n    ValueError\n        If not enough tapers are available or if none of the tapers satisfy the\n        minimum energy concentration criteria.\n    \"\"\"\n\n    NW = bandwidth * N / fs\n    K = int(np.ceil(2 * NW)) - 1\n    if n_tapers is not None:\n        K = min(K, n_tapers)\n    if K &lt; 1:\n        raise ValueError(\n            f\"Not enough tapers, with 'NW' of {NW}. Increase the bandwidth or \"\n            \"use more data points\"\n        )\n\n    tapers, lambdas = dpss(N, NW=NW, Kmax=K, sym=False, norm=2, return_ratios=True)\n    mask = lambdas &gt; min_lambda\n    if not np.sum(mask) &gt; 0:\n        raise ValueError(\n            \"None of the tapers satisfied the minimum energy concentration\"\n            f\" criteria of {min_lambda}\"\n        )\n    tapers = tapers[mask]\n    lambdas = lambdas[mask]\n\n    if n_tapers is not None:\n        if n_tapers &gt; tapers.shape[0]:\n            raise ValueError(\n                f\"'n_tapers' of {n_tapers} is greater than the {tapers.shape[0]}\"\n                f\" that satisfied the minimum energy concentration criteria of {min_lambda}\"\n            )\n        tapers = tapers[:n_tapers]\n        lambdas = lambdas[:n_tapers]\n\n    return tapers, lambdas\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.getfgrid","title":"<code>getfgrid(Fs, nfft, fpass)</code>","text":"<p>Get frequency grid for evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>nfft</code> <code>int</code> <p>Number of points for FFT.</p> required <code>fpass</code> <code>List[float]</code> <p>Frequency range to evaluate (as [fmin, fmax]).</p> required <p>Returns:</p> Name Type Description <code>f</code> <code>ndarray</code> <p>Frequency vector within the specified range.</p> <code>findx</code> <code>ndarray</code> <p>Boolean array indicating the indices of the frequency vector that fall within the specified range.</p> Notes <p>The frequency vector is computed based on the sampling frequency and the number of FFT points. Only frequencies within the range defined by <code>fpass</code> are returned.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def getfgrid(Fs: int, nfft: int, fpass: List[float]) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get frequency grid for evaluation.\n\n    Parameters\n    ----------\n    Fs : int\n        Sampling frequency.\n    nfft : int\n        Number of points for FFT.\n    fpass : List[float]\n        Frequency range to evaluate (as [fmin, fmax]).\n\n    Returns\n    -------\n    f : np.ndarray\n        Frequency vector within the specified range.\n    findx : np.ndarray\n        Boolean array indicating the indices of the frequency vector that fall within the specified range.\n\n    Notes\n    -----\n    The frequency vector is computed based on the sampling frequency and the number of FFT points.\n    Only frequencies within the range defined by `fpass` are returned.\n    \"\"\"\n    df = Fs / nfft\n    f = np.arange(0, Fs + df, df)\n    f = f[0:nfft]\n    findx = (f &gt;= fpass[0]) &amp; (f &lt;= fpass[-1])\n    f = f[findx]\n    return f, findx\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtcoherencept","title":"<code>mtcoherencept(data1, data2, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper coherence for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>data1</code> <code>ndarray</code> <p>Array of spike times for the first signal (in seconds).</p> required <code>data2</code> <code>ndarray</code> <p>Array of spike times for the second signal (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product, by default 2.5.</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers, by default 4.</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate, by default None.</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series, by default None.</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Coherence between the two point processes.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtcoherencept(\n    data1: np.ndarray,\n    data2: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper coherence for point processes.\n\n    Parameters\n    ----------\n    data1 : np.ndarray\n        Array of spike times for the first signal (in seconds).\n    data2 : np.ndarray\n        Array of spike times for the second signal (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    NW : Union[int, float], optional\n        Time-bandwidth product, by default 2.5.\n    n_tapers : int, optional\n        Number of tapers, by default 4.\n    time_support : Union[list, None], optional\n        Time range to evaluate, by default None.\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series, by default None.\n    nfft : Optional[int], optional\n        Number of points for FFT, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        Coherence between the two point processes.\n    \"\"\"\n    # Check if data is a single unit and put in array\n    if isinstance(data1, np.ndarray):\n        data1 = np.array([data1])\n    if isinstance(data2, np.ndarray):\n        data2 = np.array([data2])\n\n    # Compute power spectral densities (PSD) for both spike trains\n    psd1 = mtspectrumpt(\n        data1, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n    psd2 = mtspectrumpt(\n        data2, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n\n    # Compute cross-spectral density (CSD) between the two spike trains\n    csd = mtcsdpt(\n        data1, data2, Fs, fpass, NW, n_tapers, time_support, tapers, tapers_ts, nfft\n    )\n\n    # Calculate coherence: |Sxy(f)|^2 / (Sxx(f) * Syy(f))\n    coherence = np.abs(csd[\"CSD\"].values) ** 2 / (psd1.values * psd2.values).flatten()\n\n    # Return coherence as a pandas DataFrame\n    coherence_df = pd.DataFrame(index=csd.index, data=coherence, columns=[\"Coherence\"])\n    return coherence_df\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtcsdpt","title":"<code>mtcsdpt(data1, data2, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper cross-spectral density (CSD) for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>data1</code> <code>ndarray</code> <p>Array of spike times for the first signal (in seconds).</p> required <code>data2</code> <code>ndarray</code> <p>Array of spike times for the second signal (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product, by default 2.5.</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers, by default 4.</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate, by default None.</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series, by default None.</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Cross-spectral density between the two point processes.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtcsdpt(\n    data1: np.ndarray,\n    data2: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper cross-spectral density (CSD) for point processes.\n\n    Parameters\n    ----------\n    data1 : np.ndarray\n        Array of spike times for the first signal (in seconds).\n    data2 : np.ndarray\n        Array of spike times for the second signal (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    NW : Union[int, float], optional\n        Time-bandwidth product, by default 2.5.\n    n_tapers : int, optional\n        Number of tapers, by default 4.\n    time_support : Union[list, None], optional\n        Time range to evaluate, by default None.\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues], by default None.\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series, by default None.\n    nfft : Optional[int], optional\n        Number of points for FFT, by default None.\n\n    Returns\n    -------\n    pd.DataFrame\n        Cross-spectral density between the two point processes.\n    \"\"\"\n    if time_support is not None:\n        mintime, maxtime = time_support\n    else:\n        mintime = min(np.min(data1), np.min(data2))\n        maxtime = max(np.max(data1), np.max(data2))\n    dt = 1 / Fs\n\n    # Create tapers if not provided\n    if tapers is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n        N = len(tapers_ts)\n        tapers, eigens = dpss(N, NW, n_tapers, return_ratios=True)\n\n    tapers = tapers.T\n    N = len(tapers_ts)\n\n    # Number of points in FFT\n    if nfft is None:\n        nfft = np.max([int(2 ** np.ceil(np.log2(N))), N])\n    f, findx = getfgrid(Fs, nfft, fpass)\n\n    # Compute the multitaper Fourier transforms of both spike trains\n    J1, Msp1, Nsp1 = mtfftpt(data1, tapers, nfft, tapers_ts, f, findx)\n    J2, Msp2, Nsp2 = mtfftpt(data2, tapers, nfft, tapers_ts, f, findx)\n\n    # Cross-spectral density: Sxy = mean(conjugate(J1) * J2)\n    csd = np.real(np.mean(np.conj(J1) * J2, axis=1))\n\n    csd_df = pd.DataFrame(index=f, data=csd, columns=[\"CSD\"])\n    return csd_df\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtfftc","title":"<code>mtfftc(data, tapers, nfft, Fs)</code>","text":"<p>Multi-taper Fourier Transform - Continuous Data (Single Signal)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of data (samples).</p> required <code>tapers</code> <code>ndarray</code> <p>Precomputed DPSS tapers with shape (samples, tapers).</p> required <code>nfft</code> <code>int</code> <p>Length of padded data for FFT.</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <p>Returns:</p> Name Type Description <code>J</code> <code>ndarray</code> <p>FFT in the form (nfft, K), where K is the number of tapers.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtfftc(data: np.ndarray, tapers: np.ndarray, nfft: int, Fs: int) -&gt; np.ndarray:\n    \"\"\"\n    Multi-taper Fourier Transform - Continuous Data (Single Signal)\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of data (samples).\n    tapers : np.ndarray\n        Precomputed DPSS tapers with shape (samples, tapers).\n    nfft : int\n        Length of padded data for FFT.\n    Fs : int\n        Sampling frequency.\n\n    Returns\n    -------\n    J : np.ndarray\n        FFT in the form (nfft, K), where K is the number of tapers.\n    \"\"\"\n    # Ensure data is 1D\n    if data.ndim != 1:\n        raise ValueError(\"Input data must be a 1D array.\")\n\n    NC = data.shape[0]  # Number of samples in data\n    NK, K = tapers.shape  # Number of samples and tapers\n\n    if NK != NC:\n        raise ValueError(\"Length of tapers is incompatible with length of data.\")\n\n    # Project data onto tapers\n    data_proj = data[:, np.newaxis] * tapers  # Shape: (samples, tapers)\n\n    # Compute FFT for each taper\n    J = np.fft.fft(data_proj, n=nfft, axis=0) / Fs  # Shape: (nfft, K)\n\n    return J\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtfftpt","title":"<code>mtfftpt(data, tapers, nfft, t, f, findx)</code>","text":"<p>Multitaper FFT for point process times.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of spike times (in seconds).</p> required <code>tapers</code> <code>ndarray</code> <p>Tapers from the DPSS method.</p> required <code>nfft</code> <code>int</code> <p>Number of points for FFT.</p> required <code>t</code> <code>ndarray</code> <p>Time vector.</p> required <code>f</code> <code>ndarray</code> <p>Frequency vector.</p> required <code>findx</code> <code>list of bool</code> <p>Frequency index.</p> required <p>Returns:</p> Name Type Description <code>J</code> <code>ndarray</code> <p>FFT of the data.</p> <code>Msp</code> <code>float</code> <p>Mean spikes per time.</p> <code>Nsp</code> <code>float</code> <p>Total number of spikes in data.</p> Notes <p>The function computes the multitaper FFT of spike times using the specified tapers and returns the FFT result, mean spikes, and total spike count.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtfftpt(\n    data: np.ndarray,\n    tapers: np.ndarray,\n    nfft: int,\n    t: np.ndarray,\n    f: np.ndarray,\n    findx: List[bool],\n) -&gt; Tuple[np.ndarray, float, float]:\n    \"\"\"\n    Multitaper FFT for point process times.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of spike times (in seconds).\n    tapers : np.ndarray\n        Tapers from the DPSS method.\n    nfft : int\n        Number of points for FFT.\n    t : np.ndarray\n        Time vector.\n    f : np.ndarray\n        Frequency vector.\n    findx : list of bool\n        Frequency index.\n\n    Returns\n    -------\n    J : np.ndarray\n        FFT of the data.\n    Msp : float\n        Mean spikes per time.\n    Nsp : float\n        Total number of spikes in data.\n\n    Notes\n    -----\n    The function computes the multitaper FFT of spike times using\n    the specified tapers and returns the FFT result, mean spikes,\n    and total spike count.\n    \"\"\"\n    K = tapers.shape[1]\n    nfreq = len(f)\n\n    # get the FFT of the tapers\n    H = np.zeros((nfft, K), dtype=np.complex128)\n    for i in np.arange(K):\n        H[:, i] = np.fft.fft(tapers[:, i], nfft, axis=0)\n\n    H = H[findx, :]\n    w = 2 * np.pi * f\n    dtmp = data\n    indx = np.logical_and(dtmp &gt;= np.min(t), dtmp &lt;= np.max(t))\n    if len(indx):\n        dtmp = dtmp[indx]\n    Nsp = len(dtmp)\n\n    # get the mean spike rate\n    Msp = Nsp / len(t)\n\n    if Msp != 0:\n        # Interpolate spike times for each taper\n        data_proj = np.empty((len(dtmp), K))\n        for i in range(K):\n            data_proj[:, i] = np.interp(dtmp, t, tapers[:, i])\n\n        def compute_J(k):\n            J_k = np.zeros(nfreq, dtype=np.complex128)\n            for i, freq in enumerate(w):\n                phase = -1j * freq * (dtmp - t[0])\n                J_k[i] = np.sum(np.exp(phase) * data_proj[:, k])\n            return J_k\n\n        J = np.array(Parallel(n_jobs=-1)(delayed(compute_J)(k) for k in range(K))).T\n\n        J -= H * Msp\n    else:\n        # No spikes: return zeros\n        J = np.zeros((nfreq, K), dtype=np.complex128)\n\n    return J, Msp, Nsp\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtspectrumc","title":"<code>mtspectrumc(data, Fs, fpass, tapers)</code>","text":"<p>Compute the multitaper power spectrum for continuous data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>1D array of continuous data (e.g., LFP).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency in Hz.</p> required <code>fpass</code> <code>list</code> <p>Frequency range to evaluate as [min_freq, max_freq].</p> required <code>tapers</code> <code>ndarray</code> <p>Tapers array with shape [NW, K] or [tapers, eigenvalues].</p> required <p>Returns:</p> Name Type Description <code>S</code> <code>Series</code> <p>Power spectrum with frequencies as the index.</p> Notes <p>This function utilizes the multitaper method for spectral estimation and returns the power spectrum as a pandas Series.</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtspectrumc(\n    data: np.ndarray, Fs: int, fpass: list, tapers: np.ndarray\n) -&gt; pd.Series:\n    \"\"\"\n    Compute the multitaper power spectrum for continuous data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        1D array of continuous data (e.g., LFP).\n    Fs : int\n        Sampling frequency in Hz.\n    fpass : list\n        Frequency range to evaluate as [min_freq, max_freq].\n    tapers : np.ndarray\n        Tapers array with shape [NW, K] or [tapers, eigenvalues].\n\n    Returns\n    -------\n    S : pd.Series\n        Power spectrum with frequencies as the index.\n\n    Notes\n    -----\n    This function utilizes the multitaper method for spectral estimation\n    and returns the power spectrum as a pandas Series.\n    \"\"\"\n    N = len(data)\n    nfft = np.max(\n        [int(2 ** np.ceil(np.log2(N))), N]\n    )  # number of points in fft of prolates\n    # get the frequency grid\n    f, findx = getfgrid(Fs, nfft, fpass)\n    # get the fft of the tapers\n    tapers = dpsschk(tapers, N, Fs)\n    # get the fft of the data\n    J = mtfftc(data, tapers, nfft, Fs)\n    # restrict fft of tapers to required frequencies\n    J = J[findx, :]\n    # get the power spectrum\n    S = np.real(np.mean(np.conj(J) * J, 1))\n    # return the power spectrum\n    return pd.Series(index=f, data=S)\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.mtspectrumpt","title":"<code>mtspectrumpt(data, Fs, fpass, NW=2.5, n_tapers=4, time_support=None, tapers=None, tapers_ts=None, nfft=None)</code>","text":"<p>Multitaper power spectrum estimation for point process data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of spike times (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency.</p> required <code>fpass</code> <code>list of float</code> <p>Frequency range to evaluate.</p> required <code>NW</code> <code>Union[int, float]</code> <p>Time-bandwidth product (default is 2.5).</p> <code>2.5</code> <code>n_tapers</code> <code>int</code> <p>Number of tapers (default is 4).</p> <code>4</code> <code>time_support</code> <code>Union[list, None]</code> <p>Time range to evaluate (default is None).</p> <code>None</code> <code>tapers</code> <code>Union[ndarray, None]</code> <p>Precomputed tapers, given as [NW, K] or [tapers, eigenvalues] (default is None).</p> <code>None</code> <code>tapers_ts</code> <code>Union[ndarray, None]</code> <p>Taper time series (default is None).</p> <code>None</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT (default is None).</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the power spectrum.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spec = pychronux.mtspectrumpt(\n&gt;&gt;&gt;    st.data,\n&gt;&gt;&gt;    100,\n&gt;&gt;&gt;    [1, 20],\n&gt;&gt;&gt;    NW=3,\n&gt;&gt;&gt;    n_tapers=5,\n&gt;&gt;&gt;    time_support=[st.support.start, st.support.stop],\n&gt;&gt;&gt;    nfft=500,\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def mtspectrumpt(\n    data: np.ndarray,\n    Fs: int,\n    fpass: list,\n    NW: Union[int, float] = 2.5,\n    n_tapers: int = 4,\n    time_support: Union[list, None] = None,\n    tapers: Union[np.ndarray, None] = None,\n    tapers_ts: Union[np.ndarray, None] = None,\n    nfft: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Multitaper power spectrum estimation for point process data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Array of spike times (in seconds).\n    Fs : int\n        Sampling frequency.\n    fpass : list of float\n        Frequency range to evaluate.\n    NW : Union[int, float], optional\n        Time-bandwidth product (default is 2.5).\n    n_tapers : int, optional\n        Number of tapers (default is 4).\n    time_support : Union[list, None], optional\n        Time range to evaluate (default is None).\n    tapers : Union[np.ndarray, None], optional\n        Precomputed tapers, given as [NW, K] or [tapers, eigenvalues] (default is None).\n    tapers_ts : Union[np.ndarray, None], optional\n        Taper time series (default is None).\n    nfft : Optional[int], optional\n        Number of points for FFT (default is None).\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the power spectrum.\n\n\n    Examples\n    -------\n    &gt;&gt;&gt; spec = pychronux.mtspectrumpt(\n    &gt;&gt;&gt;    st.data,\n    &gt;&gt;&gt;    100,\n    &gt;&gt;&gt;    [1, 20],\n    &gt;&gt;&gt;    NW=3,\n    &gt;&gt;&gt;    n_tapers=5,\n    &gt;&gt;&gt;    time_support=[st.support.start, st.support.stop],\n    &gt;&gt;&gt;    nfft=500,\n    &gt;&gt;&gt; )\n    \"\"\"\n\n    # check data\n    if len(data) == 0:\n        return pd.DataFrame()\n\n    # check frequency range\n    if fpass[0] &gt; fpass[1]:\n        raise ValueError(\n            \"Invalid frequency range: fpass[0] should be less than fpass[1].\"\n        )\n\n    if time_support is not None:\n        mintime, maxtime = time_support\n    else:\n        if data.dtype == np.object_:\n            mintime = np.min(np.concatenate(data))\n            maxtime = np.max(np.concatenate(data))\n        else:\n            mintime = np.min(data)\n            maxtime = np.max(data)\n\n    dt = 1 / Fs\n\n    if tapers is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n        N = len(tapers_ts)\n        tapers, eigens = dpss(N, NW, n_tapers, return_ratios=True)\n        tapers = tapers.T\n\n    if tapers_ts is None:\n        tapers_ts = np.arange(mintime - dt, maxtime + dt, dt)\n\n    N = len(tapers_ts)\n    # number of points in fft of prolates\n    if nfft is None:\n        nfft = np.max([int(2 ** np.ceil(np.log2(N))), N])\n    f, findx = getfgrid(Fs, nfft, fpass)\n\n    spec = np.zeros((len(f), len(data)))\n    for i, d in enumerate(data):\n        J, _, _ = mtfftpt(d, tapers, nfft, tapers_ts, f, findx)\n        spec[:, i] = np.real(np.mean(np.conj(J) * J, 1))\n\n    spectrum_df = pd.DataFrame(index=f, columns=np.arange(len(data)), dtype=np.float64)\n    spectrum_df[:] = spec\n    return spectrum_df\n</code></pre>"},{"location":"reference/neuro_py/process/pychronux/#neuro_py.process.pychronux.point_spectra","title":"<code>point_spectra(times, Fs=1250, freq_range=[1, 20], tapers0=[3, 5], pad=0, nfft=None)</code>","text":"<p>Compute multitaper power spectrum for point processes.</p> <p>Parameters:</p> Name Type Description Default <code>times</code> <code>ndarray</code> <p>Array of spike times (in seconds).</p> required <code>Fs</code> <code>int</code> <p>Sampling frequency (default is 1250 Hz).</p> <code>1250</code> <code>freq_range</code> <code>List[float]</code> <p>Frequency range to evaluate (default is [1, 20] Hz).</p> <code>[1, 20]</code> <code>tapers0</code> <code>List[int]</code> <p>Time-bandwidth product and number of tapers (default is [3, 5]). The time-bandwidth product is used to compute the tapers.</p> <code>[3, 5]</code> <code>pad</code> <code>int</code> <p>Padding for the FFT (default is 0).</p> <code>0</code> <code>nfft</code> <code>Optional[int]</code> <p>Number of points for FFT (default is None).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>spectra</code> <code>ndarray</code> <p>Power spectrum.</p> <code>f</code> <code>ndarray</code> <p>Frequency vector.</p> Notes <p>Alternative function to <code>mtspectrumpt</code> for computing the power spectrum</p> Source code in <code>neuro_py/process/pychronux.py</code> <pre><code>def point_spectra(\n    times: np.ndarray,\n    Fs: int = 1250,\n    freq_range: List[float] = [1, 20],\n    tapers0: List[int] = [3, 5],\n    pad: int = 0,\n    nfft: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute multitaper power spectrum for point processes.\n\n    Parameters\n    ----------\n    times : np.ndarray\n        Array of spike times (in seconds).\n    Fs : int, optional\n        Sampling frequency (default is 1250 Hz).\n    freq_range : List[float], optional\n        Frequency range to evaluate (default is [1, 20] Hz).\n    tapers0 : List[int], optional\n        Time-bandwidth product and number of tapers (default is [3, 5]).\n        The time-bandwidth product is used to compute the tapers.\n    pad : int, optional\n        Padding for the FFT (default is 0).\n    nfft : Optional[int], optional\n        Number of points for FFT (default is None).\n\n    Returns\n    -------\n    spectra : np.ndarray\n        Power spectrum.\n    f : np.ndarray\n        Frequency vector.\n\n    Notes\n    -----\n    Alternative function to `mtspectrumpt` for computing the power spectrum\n    \"\"\"\n\n    # generate frequency grid\n    timesRange = [min(times), max(times)]\n    window = np.floor(np.diff(timesRange))\n    nSamplesPerWindow = int(np.round(Fs * window[0]))\n    if nfft is None:\n        nfft = np.max(\n            [(int(2 ** np.ceil(np.log2(nSamplesPerWindow))) + pad), nSamplesPerWindow]\n        )\n    fAll = np.linspace(0, Fs, int(nfft))\n    frequency_ind = (fAll &gt;= freq_range[0]) &amp; (fAll &lt;= freq_range[1])\n\n    # Generate tapers\n    tapers, _ = dpss(nSamplesPerWindow, tapers0[0], tapers0[1], return_ratios=True)\n    tapers = tapers * np.sqrt(Fs)\n\n    # Compute FFT of tapers and restrict to required frequencies\n    H = np.fft.fft(tapers, n=nfft, axis=1)  # Shape: (K, nfft)\n    H = H[:, frequency_ind]  # Shape: (K, Nf)\n\n    # Angular frequencies\n    f = fAll[frequency_ind]\n    w = 2 * np.pi * f\n\n    # Time grid\n    timegrid = np.linspace(timesRange[0], timesRange[1], nSamplesPerWindow)\n\n    # Ensure times are within range\n    data = times[(times &gt;= timegrid[0]) &amp; (times &lt;= timegrid[-1])]\n\n    # Project spike times onto tapers\n    data_proj = [np.interp(data, timegrid, taper) for taper in tapers]\n    data_proj = np.vstack(data_proj)  # Shape: (K, len(data))\n\n    # Compute multitaper spectrum\n    exponential = np.exp(\n        np.outer(-1j * w, (data - timegrid[0]))\n    )  # Shape: (Nf, len(data))\n    J = exponential @ data_proj.T - H.T * len(data) / len(timegrid)  # Shape: (Nf, K)\n    spectra = np.squeeze(np.mean(np.real(np.conj(J) * J), axis=1))  # Mean across tapers\n\n    return spectra, f\n</code></pre>"},{"location":"reference/neuro_py/process/utils/","title":"neuro_py.process.utils","text":""},{"location":"reference/neuro_py/process/utils/#neuro_py.process.utils.average_diagonal","title":"<code>average_diagonal(mat)</code>","text":"<p>Average values over all offset diagonals of a 2D array.</p> <p>Parameters:</p> Name Type Description Default <code>mat</code> <code>ndarray</code> <p>2D array from which to compute the average values over diagonals.</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>ndarray</code> <p>1D array containing the average values over all offset diagonals.</p> Notes <p>The method used for computing averages is based on the concept of accumulating values along each diagonal offset and then dividing by the number of elements in each diagonal.</p> Reference <p>https://stackoverflow.com/questions/71362928/average-values-over-all-offset-diagonals</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def average_diagonal(mat: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Average values over all offset diagonals of a 2D array.\n\n    Parameters\n    ----------\n    mat : np.ndarray\n        2D array from which to compute the average values over diagonals.\n\n    Returns\n    -------\n    output : np.ndarray\n        1D array containing the average values over all offset diagonals.\n\n    Notes\n    -----\n    The method used for computing averages is based on the concept of\n    accumulating values along each diagonal offset and then dividing by\n    the number of elements in each diagonal.\n\n    Reference\n    ---------\n    https://stackoverflow.com/questions/71362928/average-values-over-all-offset-diagonals\n    \"\"\"\n    n = mat.shape[0]\n    output = np.zeros(n * 2 - 1, dtype=np.float64)\n    for i in range(n - 1, -1, -1):\n        output[i : i + n] += mat[n - 1 - i]\n    output[0:n] /= np.arange(1, n + 1, 1, dtype=np.float64)\n    output[n:] /= np.arange(n - 1, 0, -1, dtype=np.float64)\n    return output\n</code></pre>"},{"location":"reference/neuro_py/process/utils/#neuro_py.process.utils.circular_shift","title":"<code>circular_shift(m, s)</code>","text":"<p>Circularly shift matrix rows or columns by specified amounts.</p> <p>Each matrix row (or column) is circularly shifted by a different amount.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>ndarray</code> <p>Matrix to rotate. Should be a 2D array.</p> required <code>s</code> <code>ndarray</code> <p>Shift amounts for each row (horizontal vector) or column (vertical vector). Should be a 1D array.</p> required <p>Returns:</p> Name Type Description <code>shifted</code> <code>ndarray</code> <p>Matrix <code>m</code> with rows (or columns) circularly shifted by the amounts in <code>s</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>s</code> is not a vector of integers or if <code>m</code> is not a 2D matrix. If the sizes of <code>m</code> and <code>s</code> are incompatible.</p> Notes <p>This function is adapted from CircularShift.m, Copyright (C) 2012 by Micha\u00ebl Zugaro.</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def circular_shift(m: np.ndarray, s: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Circularly shift matrix rows or columns by specified amounts.\n\n    Each matrix row (or column) is circularly shifted by a different amount.\n\n    Parameters\n    ----------\n    m : np.ndarray\n        Matrix to rotate. Should be a 2D array.\n    s : np.ndarray\n        Shift amounts for each row (horizontal vector) or column (vertical vector).\n        Should be a 1D array.\n\n    Returns\n    -------\n    shifted : np.ndarray\n        Matrix `m` with rows (or columns) circularly shifted by the amounts in `s`.\n\n    Raises\n    ------\n    ValueError\n        If `s` is not a vector of integers or if `m` is not a 2D matrix.\n        If the sizes of `m` and `s` are incompatible.\n\n    Notes\n    -----\n    This function is adapted from CircularShift.m, Copyright (C) 2012 by Micha\u00ebl Zugaro.\n    \"\"\"\n    # Check number of parameters\n    if len(s.shape) != 1:\n        raise ValueError(\"Second parameter is not a vector of integers.\")\n    if len(m.shape) != 2:\n        raise ValueError(\"First parameter is not a 2D matrix.\")\n\n    mm, nm = m.shape\n    # if s is 1d array, add dimension\n    if len(s.shape) == 1:\n        s = s[np.newaxis, :]\n    ms, ns = s.shape\n\n    # Check parameter sizes\n    if mm != ms and nm != ns:\n        raise ValueError(\"Incompatible parameter sizes.\")\n\n    # The algorithm below works along columns; transpose if necessary\n    s = -np.ravel(s)\n    if ns == 1:\n        m = m.T\n        mm, nm = m.shape\n\n    # Shift matrix S, where Sij is the vertical shift for element ij\n    shift = np.tile(s, (mm, 1))\n\n    # Before we start, each element Mij has a linear index Aij.\n    # After circularly shifting the rows, it will have a linear index Bij.\n    # We now construct Bij.\n\n    # First, create matrix C where each item Cij = i (row number)\n    lines = np.tile(np.arange(mm)[:, np.newaxis], (1, nm))\n    # Next, update C so that Cij becomes the target row number (after circular shift)\n    lines = np.mod(lines + shift, mm)\n    # lines[lines == 0] = mm\n    # Finally, transform Cij into a linear index, yielding Bij\n    indices = lines + np.tile(np.arange(nm) * mm, (mm, 1))\n\n    # Circular shift (reshape so that it is not transformed into a vector)\n    shifted = m.ravel()[(indices.flatten() - 1).astype(int)].reshape(mm, nm)\n\n    # flip matrix right to left\n    # shifted = np.fliplr(shifted)\n\n    shifted = np.flipud(shifted)\n\n    # Transpose back if necessary\n    if ns == 1:\n        shifted = shifted.T\n\n    return shifted\n</code></pre>"},{"location":"reference/neuro_py/process/utils/#neuro_py.process.utils.compute_image_spread","title":"<code>compute_image_spread(X, exponent=2, normalize=True)</code>","text":"<p>Compute the spread of an image using the square root of a weighted moment.</p> <p>The spread is calculated as the square root of a weighted moment of the image, where the weights are derived from the deviations of each pixel from the center of mass (COM) of the image.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A 2D numpy array of shape (numBinsY, numBinsX). If <code>normalize</code> is True, the input is assumed to represent a probability distribution.</p> required <code>exponent</code> <code>float</code> <p>The exponent used in the moment calculation. Default is 2.</p> <code>2</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the input array so that its sum is 1. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>spread</code> <code>float</code> <p>The computed spread, defined as the square root of the weighted moment.</p> <code>image_moment</code> <code>float</code> <p>The raw weighted moment of the image.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n&gt;&gt;&gt; spread, image_moment = compute_image_spread(X, exponent=2)\n&gt;&gt;&gt; print(spread)\n0.5704157028642128\n&gt;&gt;&gt; print(image_moment)\n0.325374074074074\n</code></pre> References <p>Widloski &amp; Foster, 2022</p> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def compute_image_spread(\n    X: np.ndarray, exponent: float = 2, normalize: bool = True\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Compute the spread of an image using the square root of a weighted moment.\n\n    The spread is calculated as the square root of a weighted moment of the image,\n    where the weights are derived from the deviations of each pixel from the\n    center of mass (COM) of the image.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A 2D numpy array of shape (numBinsY, numBinsX). If `normalize` is True,\n        the input is assumed to represent a probability distribution.\n    exponent : float, optional\n        The exponent used in the moment calculation. Default is 2.\n    normalize : bool, optional\n        If True, normalize the input array so that its sum is 1. Default is True.\n\n    Returns\n    -------\n    spread : float\n        The computed spread, defined as the square root of the weighted moment.\n    image_moment : float\n        The raw weighted moment of the image.\n\n    Examples\n    --------\n    &gt;&gt;&gt; X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n    &gt;&gt;&gt; spread, image_moment = compute_image_spread(X, exponent=2)\n    &gt;&gt;&gt; print(spread)\n    0.5704157028642128\n    &gt;&gt;&gt; print(image_moment)\n    0.325374074074074\n\n    References\n    ----------\n    Widloski &amp; Foster, 2022\n    \"\"\"\n    if np.allclose(X, 0):\n        return np.nan, np.nan  # Return NaN if the input is all zero\n\n    if normalize:\n        X = X / np.nansum(X)  # Normalize the input\n\n    numBinsY, numBinsX = X.shape\n\n    # Compute center of mass (COM) for the X (columns) direction.\n    cols = np.arange(1, numBinsX + 1)\n    sumX = np.nansum(X, axis=0)  # sum over rows, shape: (numBinsX,)\n    totalX = np.nansum(sumX)\n    # Add a small correction term\n    comX = np.nansum(sumX * cols) / totalX + 0.5 / numBinsX\n\n    # Compute center of mass for the Y (rows) direction.\n    rows = np.arange(1, numBinsY + 1)\n    sumY = np.nansum(X, axis=1)  # sum over columns, shape: (numBinsY,)\n    totalY = np.nansum(sumY)\n    comY = np.nansum(sumY * rows) / totalY + 0.5 / numBinsY\n\n    # Create a meshgrid for the bin indices (using 1-indexing like MATLAB)\n    XX, YY = np.meshgrid(np.arange(1, numBinsX + 1), np.arange(1, numBinsY + 1))\n\n    # Compute the weighted moment using the product of the deviations raised to the given exponent.\n    # For each bin, we compute:\n    #     |XX - comX|^exponent * |YY - comY|^exponent * X(i,j)\n    moment = np.nansum(\n        (np.abs(XX - comX) ** exponent) * (np.abs(YY - comY) ** exponent) * X\n    )\n\n    # Normalize by the total probability.\n    image_moment = moment / np.nansum(X)\n\n    # The spread is the square root of the image moment.\n    spread = np.sqrt(image_moment)\n\n    return spread, image_moment\n</code></pre>"},{"location":"reference/neuro_py/process/utils/#neuro_py.process.utils.remove_inactive_cells","title":"<code>remove_inactive_cells(st, cell_metrics=None, epochs=None, min_spikes=100)</code>","text":"<p>remove_inactive_cells: Remove cells with fewer than min_spikes spikes per sub-epoch</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>SpikeTrainArray object containing spike times for multiple cells.</p> required <code>cell_metrics</code> <code>DataFrame</code> <p>DataFrame containing metrics for each cell (e.g., quality metrics).</p> <code>None</code> <code>epochs</code> <code>EpochArray or list of EpochArray</code> <p>If a list of EpochArray objects is provided, each EpochArray object is treated as a sub-epoch. If a single EpochArray object is provided, each interval in the EpochArray object is treated as a sub-epoch.</p> <code>None</code> <code>min_spikes</code> <code>int</code> <p>Minimum number of spikes required per sub-epoch to retain a cell. Default is 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>Tuple[SpikeTrainArray, Union[DataFrame, None]]</code> <p>A tuple containing: - SpikeTrainArray object with inactive cells removed. - DataFrame containing cell metrics with inactive cells removed (if provided).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.intervals import truncate_epoch\n&gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n&gt;&gt;&gt;     find_multitask_pre_post,\n&gt;&gt;&gt;     compress_repeated_epochs,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; import nelpy as nel\n&gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells\n</code></pre> <pre><code>&gt;&gt;&gt; # load data from session\n&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load spikes and cell metrics (cm)\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n&gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n&gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; beh_epochs = nel.EpochArray(\n&gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n&gt;&gt;&gt; )\n&gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"NREMstate\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; theta_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"THETA\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; # create list of restricted epochs\n&gt;&gt;&gt; restict_epochs = []\n&gt;&gt;&gt; for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n&gt;&gt;&gt;     if epoch_label in \"pre\":\n&gt;&gt;&gt;         # get cumulative hours of sleep\n&gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n&gt;&gt;&gt;     elif epoch_label in \"post\":\n&gt;&gt;&gt;         # get cumulative hours of sleep\n&gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n&gt;&gt;&gt;     else:\n&gt;&gt;&gt;         # get theta during task\n&gt;&gt;&gt;         epoch_restrict = epoch &amp; theta_epochs\n&gt;&gt;&gt;     restict_epochs.append(epoch_restrict)\n</code></pre> <pre><code>&gt;&gt;&gt; # remove inactive cells\n&gt;&gt;&gt; st, cm = remove_inactive_cells(st, cm, restict_epochs)\n</code></pre> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def remove_inactive_cells(\n    st: nel.core._eventarray.SpikeTrainArray,\n    cell_metrics: Union[pd.DataFrame, None] = None,\n    epochs: Union[\n        List[nel.core._intervalarray.EpochArray],\n        nel.core._intervalarray.EpochArray,\n        None,\n    ] = None,\n    min_spikes: int = 100,\n) -&gt; Tuple[nel.core._eventarray.SpikeTrainArray, Union[pd.DataFrame, None]]:\n    \"\"\"\n    remove_inactive_cells: Remove cells with fewer than min_spikes spikes per sub-epoch\n\n    Parameters\n    ----------\n    st : SpikeTrainArray\n        SpikeTrainArray object containing spike times for multiple cells.\n\n    cell_metrics : pd.DataFrame, optional\n        DataFrame containing metrics for each cell (e.g., quality metrics).\n\n    epochs : EpochArray or list of EpochArray, optional\n        If a list of EpochArray objects is provided, each EpochArray object\n        is treated as a sub-epoch. If a single EpochArray object is provided,\n        each interval in the EpochArray object is treated as a sub-epoch.\n\n    min_spikes : int, optional\n        Minimum number of spikes required per sub-epoch to retain a cell.\n        Default is 100.\n\n    Returns\n    -------\n    Tuple[SpikeTrainArray, Union[pd.DataFrame, None]]\n        A tuple containing:\n        - SpikeTrainArray object with inactive cells removed.\n        - DataFrame containing cell metrics with inactive cells removed (if provided).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.intervals import truncate_epoch\n    &gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n    &gt;&gt;&gt;     find_multitask_pre_post,\n    &gt;&gt;&gt;     compress_repeated_epochs,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; import nelpy as nel\n    &gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells\n\n    &gt;&gt;&gt; # load data from session\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n\n    &gt;&gt;&gt; # load spikes and cell metrics (cm)\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n    &gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n    &gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"NREMstate\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; theta_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"THETA\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; # create list of restricted epochs\n    &gt;&gt;&gt; restict_epochs = []\n    &gt;&gt;&gt; for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n    &gt;&gt;&gt;     if epoch_label in \"pre\":\n    &gt;&gt;&gt;         # get cumulative hours of sleep\n    &gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n    &gt;&gt;&gt;     elif epoch_label in \"post\":\n    &gt;&gt;&gt;         # get cumulative hours of sleep\n    &gt;&gt;&gt;         epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=3600)\n    &gt;&gt;&gt;     else:\n    &gt;&gt;&gt;         # get theta during task\n    &gt;&gt;&gt;         epoch_restrict = epoch &amp; theta_epochs\n    &gt;&gt;&gt;     restict_epochs.append(epoch_restrict)\n\n    &gt;&gt;&gt; # remove inactive cells\n    &gt;&gt;&gt; st, cm = remove_inactive_cells(st, cm, restict_epochs)\n    \"\"\"\n\n    def return_results(st, cell_metrics):\n        if cell_metrics is None:\n            return st\n        else:\n            return st, cell_metrics\n\n    # check data types\n    if not isinstance(st, nel.core._eventarray.SpikeTrainArray):\n        raise ValueError(\"st must be a SpikeTrainArray object\")\n\n    if not isinstance(cell_metrics, (pd.core.frame.DataFrame, type(None))):\n        raise ValueError(\"cell_metrics must be a DataFrame object\")\n\n    if not isinstance(epochs, (nel.core._intervalarray.EpochArray, list)):\n        raise ValueError(\n            \"epochs must be an EpochArray object or a list of EpochArray objects\"\n        )\n\n    if isinstance(epochs, list):\n        for epoch in epochs:\n            if not isinstance(epoch, nel.core._intervalarray.EpochArray):\n                raise ValueError(\"list of epochs must contain EpochArray objects\")\n\n    # check if st is empty\n    if st.isempty:\n        return return_results(st, cell_metrics)\n\n    # check if epochs is empty\n    if isinstance(epochs, nel.core._intervalarray.EpochArray):\n        if epochs.isempty:\n            return return_results(st, cell_metrics)\n\n    # check if cell_metrics is empty\n    if cell_metrics is not None and cell_metrics.empty:\n        return return_results(st, cell_metrics)\n\n    # check if min_spikes is less than 1\n    if min_spikes &lt; 1:\n        return return_results(st, cell_metrics)\n\n    # check if st and cell_metrics have the same number of units\n    if cell_metrics is not None and st.n_units != cell_metrics.shape[0]:\n        # assert error message\n        raise ValueError(\"st and cell_metrics must have the same number of units\")\n\n    spk_thres_met = []\n    # check if each cell has at least min_spikes spikes in each epoch\n    for epoch_restrict in epochs:\n        if st[epoch_restrict].isempty:\n            spk_thres_met.append([False] * st.n_units)\n            continue\n        spk_thres_met.append(st[epoch_restrict].n_events &gt;= min_spikes)\n\n    good_idx = np.vstack(spk_thres_met).all(axis=0)\n\n    # remove inactive cells\n    st = st.iloc[:, good_idx]\n    if cell_metrics is not None:\n        cell_metrics = cell_metrics[good_idx]\n\n    return return_results(st, cell_metrics)\n</code></pre>"},{"location":"reference/neuro_py/process/utils/#neuro_py.process.utils.remove_inactive_cells_pre_task_post","title":"<code>remove_inactive_cells_pre_task_post(st, cell_metrics=None, beh_epochs=None, nrem_epochs=None, theta_epochs=None, min_spikes=100, nrem_time=3600)</code>","text":"<p>remove_inactive_cells_pre_task_post: Remove cells with fewer than min_spikes spikes per pre/task/post</p> <p>Parameters:</p> Name Type Description Default <code>st</code> <code>SpikeTrainArray</code> <p>SpikeTrainArray object containing spike times for multiple cells.</p> required <code>cell_metrics</code> <code>DataFrame</code> <p>DataFrame containing metrics for each cell (e.g., quality metrics).</p> <code>None</code> <code>beh_epochs</code> <code>EpochArray</code> <p>EpochArray object containing pre/task/post epochs.</p> <code>None</code> <code>nrem_epochs</code> <code>EpochArray</code> <p>EpochArray object containing NREM epochs.</p> <code>None</code> <code>theta_epochs</code> <code>EpochArray</code> <p>EpochArray object containing theta epochs.</p> <code>None</code> <code>min_spikes</code> <code>int</code> <p>Minimum number of spikes required per pre/task/post. Default is 100.</p> <code>100</code> <code>nrem_time</code> <code>int or float</code> <p>Time in seconds to truncate NREM epochs. Default is 3600 seconds.</p> <code>3600</code> <p>Returns:</p> Type Description <code>Tuple[SpikeTrainArray, Union[DataFrame, None]]</code> <p>A tuple containing: - SpikeTrainArray object with inactive cells removed. - DataFrame containing cell metrics with inactive cells removed (if provided).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells_pre_task_post\n&gt;&gt;&gt; from neuro_py.io import loading\n&gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n&gt;&gt;&gt;     find_multitask_pre_post,\n&gt;&gt;&gt;     compress_repeated_epochs,\n&gt;&gt;&gt; )\n&gt;&gt;&gt; mport nelpy as nel\n</code></pre> <pre><code>&gt;&gt;&gt; # load data from session\n&gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n</code></pre> <pre><code>&gt;&gt;&gt; # load spikes and cell metrics (cm)\n&gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n</code></pre> <pre><code>&gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n&gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n&gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; beh_epochs = nel.EpochArray(\n&gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n&gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n&gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"NREMstate\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; theta_epochs = nel.EpochArray(\n&gt;&gt;&gt;     state_dict[\"THETA\"],\n&gt;&gt;&gt; )\n</code></pre> <pre><code>&gt;&gt;&gt; st,cm = remove_inactive_cells_pre_task_post(st,cm,beh_epochs,nrem_epochs,theta_epochs)\n</code></pre> Source code in <code>neuro_py/process/utils.py</code> <pre><code>def remove_inactive_cells_pre_task_post(\n    st: nel.core._eventarray.SpikeTrainArray,\n    cell_metrics: Union[pd.core.frame.DataFrame, None] = None,\n    beh_epochs: nel.core._intervalarray.EpochArray = None,\n    nrem_epochs: nel.core._intervalarray.EpochArray = None,\n    theta_epochs: nel.core._intervalarray.EpochArray = None,\n    min_spikes: int = 100,\n    nrem_time: Union[int, float] = 3600,\n) -&gt; tuple:\n    \"\"\"\n    remove_inactive_cells_pre_task_post: Remove cells with fewer than min_spikes spikes per pre/task/post\n\n    Parameters\n    ----------\n    st : SpikeTrainArray\n        SpikeTrainArray object containing spike times for multiple cells.\n\n    cell_metrics : pd.DataFrame, optional\n        DataFrame containing metrics for each cell (e.g., quality metrics).\n\n    beh_epochs : EpochArray\n        EpochArray object containing pre/task/post epochs.\n\n    nrem_epochs : EpochArray\n        EpochArray object containing NREM epochs.\n\n    theta_epochs : EpochArray\n        EpochArray object containing theta epochs.\n\n    min_spikes : int, optional\n        Minimum number of spikes required per pre/task/post. Default is 100.\n\n    nrem_time : int or float, optional\n        Time in seconds to truncate NREM epochs. Default is 3600 seconds.\n\n    Returns\n    -------\n    Tuple[nel.core._eventarray.SpikeTrainArray, Union[pd.DataFrame, None]]\n        A tuple containing:\n        - SpikeTrainArray object with inactive cells removed.\n        - DataFrame containing cell metrics with inactive cells removed (if provided).\n\n    Examples\n    -------\n    &gt;&gt;&gt; from neuro_py.process.utils import remove_inactive_cells_pre_task_post\n    &gt;&gt;&gt; from neuro_py.io import loading\n    &gt;&gt;&gt; from neuro_py.session.locate_epochs import (\n    &gt;&gt;&gt;     find_multitask_pre_post,\n    &gt;&gt;&gt;     compress_repeated_epochs,\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; mport nelpy as nel\n\n    &gt;&gt;&gt; # load data from session\n    &gt;&gt;&gt; basepath = r\"Z:\\Data\\hpc_ctx_project\\HP04\\day_1_20240320\"\n\n    &gt;&gt;&gt; # load spikes and cell metrics (cm)\n    &gt;&gt;&gt; st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n\n    &gt;&gt;&gt; # load epochs and apply multitask epoch restrictions\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = compress_repeated_epochs(epoch_df)\n    &gt;&gt;&gt; pre_task_post = find_multitask_pre_post(\n    &gt;&gt;&gt;     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; beh_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     epoch_df.iloc[pre_task_post[0]][[\"startTime\", \"stopTime\"]].values\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; # load sleep states to restrict to NREM and theta\n    &gt;&gt;&gt; state_dict = loading.load_SleepState_states(basepath)\n    &gt;&gt;&gt; nrem_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"NREMstate\"],\n    &gt;&gt;&gt; )\n    &gt;&gt;&gt; theta_epochs = nel.EpochArray(\n    &gt;&gt;&gt;     state_dict[\"THETA\"],\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; st,cm = remove_inactive_cells_pre_task_post(st,cm,beh_epochs,nrem_epochs,theta_epochs)\n    \"\"\"\n\n    # check data types (further checks are done in remove_inactive_cells)\n    if not isinstance(beh_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"beh_epochs must be an EpochArray object\")\n\n    if not isinstance(nrem_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"nrem_epochs must be an EpochArray object\")\n\n    if not isinstance(theta_epochs, nel.core._intervalarray.EpochArray):\n        raise ValueError(\"theta_epochs must be an EpochArray object\")\n\n    # create list of restricted epochs\n    restict_epochs = []\n    for epoch, epoch_label in zip(beh_epochs, [\"pre\", \"task\", \"post\"]):\n        if epoch_label in \"pre\":\n            # get cumulative hours of sleep\n            epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=nrem_time)\n        elif epoch_label in \"post\":\n            # get cumulative hours of sleep\n            epoch_restrict = truncate_epoch(epoch &amp; nrem_epochs, time=nrem_time)\n        else:\n            # get theta during task\n            epoch_restrict = epoch &amp; theta_epochs\n        restict_epochs.append(epoch_restrict)\n\n    return remove_inactive_cells(\n        st, cell_metrics, restict_epochs, min_spikes=min_spikes\n    )\n</code></pre>"},{"location":"reference/neuro_py/raw/","title":"neuro_py.raw","text":""},{"location":"reference/neuro_py/raw/#neuro_py.raw.cut_artifacts","title":"<code>cut_artifacts(filepath, n_channels, cut_intervals, precision='int16', output_filepath=None)</code>","text":"<p>Remove user-defined periods from recordings in a binary file, resulting in a shorter file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the original binary file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels in the file.</p> required <code>cut_intervals</code> <code>List[Tuple[int, int]]</code> <p>List of intervals (start, end) in sample indices to remove. Assumes sorted and non-overlapping.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>output_filepath</code> <code>str</code> <p>Path to save the modified binary file. If None, appends \"_cut\" to the original filename.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def cut_artifacts(\n    filepath: str,\n    n_channels: int,\n    cut_intervals: List[Tuple[int, int]],\n    precision: str = \"int16\",\n    output_filepath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Remove user-defined periods from recordings in a binary file, resulting in a shorter file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the original binary file.\n    n_channels : int\n        Number of channels in the file.\n    cut_intervals : List[Tuple[int, int]]\n        List of intervals (start, end) in sample indices to remove. Assumes sorted and non-overlapping.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    output_filepath : str, optional\n        Path to save the modified binary file. If None, appends \"_cut\" to the original filename.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # Check if file exists\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File '{filepath}' does not exist.\")\n\n    # Set default output filepath\n    if output_filepath is None:\n        output_filepath = os.path.splitext(filepath)[0] + \"_cut.dat\"\n\n    # Check for valid intervals\n    for start, end in cut_intervals:\n        if start &gt;= end:\n            raise ValueError(\n                f\"Invalid interval: ({start}, {end}). Start must be less than end.\"\n            )\n\n    # Map the original file and calculate parameters\n    bytes_size = np.dtype(precision).itemsize\n    with open(filepath, \"rb\") as f:\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n\n    data = np.memmap(filepath, dtype=precision, mode=\"r\", shape=(n_samples, n_channels))\n\n    # Identify the indices to keep\n    keep_mask = np.ones(n_samples, dtype=bool)\n    for start, end in cut_intervals:\n        if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n            keep_mask[start:end] = False\n        else:\n            warnings.warn(\n                f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n            )\n\n    keep_indices = np.flatnonzero(keep_mask)\n\n    # Create a new binary file with only the retained data\n    with open(output_filepath, \"wb\") as output_file:\n        for start_idx in range(0, len(keep_indices), 10_000):  # Process in chunks\n            chunk_indices = keep_indices[start_idx : start_idx + 10_000]\n            output_file.write(data[chunk_indices].tobytes())\n\n    del data  # Release memory-mapped file\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.cut_artifacts_intan","title":"<code>cut_artifacts_intan(folder_name, n_channels_amplifier, cut_intervals, verbose=True)</code>","text":"<p>Cut specified artifact intervals from Intan data files.</p> <p>This function iterates through a set of Intan data files (amplifier, auxiliary, digitalin, digitalout, analogin, time, and supply), and for each file, it removes artifacts within the specified intervals by invoking the <code>cut_artifacts</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>The folder where the Intan data files are located.</p> required <code>n_channels_amplifier</code> <code>int</code> <p>The number of amplifier channels used in the amplifier data file.</p> required <code>cut_intervals</code> <code>List[Tuple[int, int]]</code> <p>A list of intervals (start, end) in sample indices to remove artifacts. Each tuple represents the start and end sample index for an artifact to be cut. Assumes sorted and non-overlapping intervals.</p> required <p>Returns:</p> Type Description <code>None</code> <p>This function modifies the files in place, so there is no return value.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the amplifier data file does not exist in the provided folder.</p> <code>ValueError</code> <p>If video files are found in the folder, as this function does not support video files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fs = 20_000\n&gt;&gt;&gt; cut_artifacts_intan(\n...     folder_name = r\"path/to/data\",\n...     n_channels_amplifier = 128,\n...     cut_intervals = (np.array([[394.4, 394.836], [400, 401], [404, 405]]) * fs).astype(int)\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def cut_artifacts_intan(\n    folder_name: str,\n    n_channels_amplifier: int,\n    cut_intervals: List[Tuple[int, int]],\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"\n    Cut specified artifact intervals from Intan data files.\n\n    This function iterates through a set of Intan data files (amplifier, auxiliary,\n    digitalin, digitalout, analogin, time, and supply), and for each file, it removes\n    artifacts within the specified intervals by invoking the `cut_artifacts` function.\n\n    Parameters\n    ----------\n    folder_name : str\n        The folder where the Intan data files are located.\n    n_channels_amplifier : int\n        The number of amplifier channels used in the amplifier data file.\n    cut_intervals : List[Tuple[int, int]]\n        A list of intervals (start, end) in sample indices to remove artifacts.\n        Each tuple represents the start and end sample index for an artifact to be cut.\n        Assumes sorted and non-overlapping intervals.\n\n    Returns\n    -------\n    None\n        This function modifies the files in place, so there is no return value.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the amplifier data file does not exist in the provided folder.\n    ValueError\n        If video files are found in the folder, as this function does not support video files.\n\n    Examples\n    --------\n    &gt;&gt;&gt; fs = 20_000\n    &gt;&gt;&gt; cut_artifacts_intan(\n    ...     folder_name = r\"path/to/data\",\n    ...     n_channels_amplifier = 128,\n    ...     cut_intervals = (np.array([[394.4, 394.836], [400, 401], [404, 405]]) * fs).astype(int)\n    ... )\n    \"\"\"\n\n    # refuse to cut artifacts if any video file exist in folder\n    video_files = [f for f in os.listdir(folder_name) if f.endswith(\".avi\")]\n    if video_files:\n        raise ValueError(f\"Video files found in folder, refusing to cut: {video_files}\")\n\n    # Define data types for each file (from Intan documentation)\n    files_table = {\n        \"amplifier\": \"int16\",\n        \"auxiliary\": \"uint16\",\n        \"digitalin\": \"uint16\",\n        \"digitalout\": \"uint16\",\n        \"analogin\": \"uint16\",\n        \"time\": \"int32\",\n        \"supply\": \"uint16\",\n    }\n\n    # determine number of samples from amplifier file\n    amplifier_file_path = os.path.join(folder_name, \"amplifier.dat\")\n    if not os.path.exists(amplifier_file_path):\n        raise FileNotFoundError(f\"File '{amplifier_file_path}' does not exist.\")\n\n    # get number of bytes per sample\n    bytes_size = np.dtype(files_table[\"amplifier\"]).itemsize\n\n    # each file should have the same number of samples\n    n_samples = os.path.getsize(amplifier_file_path) // (\n        n_channels_amplifier * bytes_size\n    )\n\n    for file_name, precision in files_table.items():\n        file_path = os.path.join(folder_name, f\"{file_name}.dat\")\n\n        if os.path.exists(file_path):\n            if verbose:\n                print(f\"Processing {file_name}.dat file...\")\n\n            # get number of bytes per sample\n            bytes_size = np.dtype(precision).itemsize\n\n            # determine number of channels from n_samples\n            n_channels = int(os.path.getsize(file_path) / n_samples / bytes_size)\n\n            # for time file, cut and offset timestamps\n            if file_name == \"time\":\n                output_filepath = os.path.splitext(file_path)[0] + \"_cut.dat\"\n\n                with open(output_filepath, \"wb\") as output_file:\n                    # time indices as continuous array\n                    filtered_time = np.arange(\n                        n_samples - sum(end - start for start, end in cut_intervals),\n                        dtype=np.int32,\n                    )\n\n                    # write to file\n                    output_file.write(filtered_time.tobytes())\n            else:\n                # cut artifacts\n                cut_artifacts(file_path, n_channels, cut_intervals, precision)\n\n    # Calculate the expected number of samples after cutting\n    total_samples_cut = sum(end - start for start, end in cut_intervals)\n    expected_n_samples = n_samples - total_samples_cut\n\n    # === Validation Section ===\n    # Verify all `_cut.dat` files have the correct number of samples\n    for file_name, precision in files_table.items():\n        output_file_path = os.path.join(folder_name, f\"{file_name}_cut.dat\")\n        original_file_path = os.path.join(folder_name, f\"{file_name}.dat\")\n\n        if os.path.exists(output_file_path) and os.path.exists(original_file_path):\n            # Dynamically calculate the number of channels\n            bytes_size = np.dtype(precision).itemsize\n            n_channels = os.path.getsize(original_file_path) // (n_samples * bytes_size)\n\n            # Calculate the expected file size\n            expected_size = expected_n_samples * n_channels * bytes_size\n            actual_size = os.path.getsize(output_file_path)\n\n            if actual_size != expected_size:\n                raise RuntimeError(\n                    f\"{file_name}_cut.dat has an incorrect size. \"\n                    f\"Expected {expected_size} bytes but found {actual_size} bytes.\"\n                )\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.fill_missing_channels","title":"<code>fill_missing_channels(basepath, n_channels, filename, missing_channels, precision='int16', chunk_size=10000)</code>","text":"<p>Fill missing channels in a large binary file with zeros, processing in chunks. This function is useful when some channels were accidently deactivated during recording.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the binary file.</p> required <code>n_channels</code> <code>int</code> <p>Total number of channels in the binary file (including the missing ones).</p> required <code>filename</code> <code>str</code> <p>Name of the binary file to modify.</p> required <code>missing_channels</code> <code>List[int]</code> <p>List of missing channel indices to be filled with zeros.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>chunk_size</code> <code>int</code> <p>Number of samples per chunk, by default 10,000.</p> <code>10000</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the modified binary file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fill_missing_channels(\n...    r\"U:\\data\\hpc_ctx_project\\HP13\\HP13_day1_20241030\\HP13_cheeseboard_241030_153710\",\n...    128,\n...    'amplifier.dat',\n...    missing_channels = [0]\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def fill_missing_channels(\n    basepath: str,\n    n_channels: int,\n    filename: str,\n    missing_channels: List[int],\n    precision: str = \"int16\",\n    chunk_size: int = 10_000,\n) -&gt; str:\n    \"\"\"\n    Fill missing channels in a large binary file with zeros, processing in chunks.\n    This function is useful when some channels were accidently deactivated during recording.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the binary file.\n    n_channels : int\n        Total number of channels in the binary file (including the missing ones).\n    filename : str\n        Name of the binary file to modify.\n    missing_channels : List[int]\n        List of missing channel indices to be filled with zeros.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    chunk_size : int, optional\n        Number of samples per chunk, by default 10,000.\n\n    Returns\n    -------\n    str\n        Path to the modified binary file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; fill_missing_channels(\n    ...    r\"U:\\\\data\\\\hpc_ctx_project\\\\HP13\\\\HP13_day1_20241030\\\\HP13_cheeseboard_241030_153710\",\n    ...    128,\n    ...    'amplifier.dat',\n    ...    missing_channels = [0]\n    ... )\n    \"\"\"\n    file_path = os.path.join(basepath, filename)\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Binary file '{file_path}' does not exist.\")\n\n    dtype = np.dtype(precision)\n    bytes_per_sample = dtype.itemsize\n    present_channels = [ch for ch in range(n_channels) if ch not in missing_channels]\n\n    # Calculate total number of samples\n    file_size = os.path.getsize(file_path)\n    n_samples = file_size // (bytes_per_sample * (n_channels - len(missing_channels)))\n    if file_size % (bytes_per_sample * (n_channels - len(missing_channels))) != 0:\n        raise ValueError(\"Data size is not consistent with expected shape.\")\n\n    # Prepare output file path\n    new_file_path = os.path.join(basepath, f\"corrected_{filename}\")\n\n    # Process file in chunks\n    with open(file_path, \"rb\") as f_in, open(new_file_path, \"wb\") as f_out:\n        for start in range(0, n_samples, chunk_size):\n            # Read a chunk of data\n            chunk = np.fromfile(\n                f_in,\n                dtype=dtype,\n                count=chunk_size * (n_channels - len(missing_channels)),\n            )\n            chunk = chunk.reshape(-1, n_channels - len(missing_channels))\n\n            # Create a new array with missing channels filled with zeros\n            chunk_full = np.zeros((chunk.shape[0], n_channels), dtype=dtype)\n            chunk_full[:, present_channels] = chunk\n\n            # Write the chunk with missing channels added to the new file\n            chunk_full.tofile(f_out)\n\n    return new_file_path\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.phy_log_to_epocharray","title":"<code>phy_log_to_epocharray(filename, merge_gap=30)</code>","text":"<p>Extract timestamps from a Phy log file and convert them to a nel.EpochArray. Will estimate the amount of time it took to spikesort a session.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the Phy log file.</p> required <code>merge_gap</code> <code>float</code> <p>The number of seconds to merge timestamps, by default 30</p> <code>30</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>A nel.EpochArray containing the timestamps.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import neuro_py as npy\n&gt;&gt;&gt; filename = r\"D:\\KiloSort\\HP18\\hp18_day11_20250415\\Kilosort_2025-04-16_224949\\phy.log\"\n&gt;&gt;&gt; timestamps = npy.raw.phy_log_to_epocharray(filename)\n&gt;&gt;&gt; timestamps\n&lt;EpochArray at 0x1f6c7da5710: 80 epochs&gt; of length 4:02:01:591 hours\n</code></pre> Source code in <code>neuro_py/raw/spike_sorting.py</code> <pre><code>def phy_log_to_epocharray(filename: str, merge_gap: float = 30):\n    \"\"\"\n    Extract timestamps from a Phy log file and convert them to a nel.EpochArray.\n    Will estimate the amount of time it took to spikesort a session.\n\n    Parameters\n    ----------\n    filename : str\n        The path to the Phy log file.\n    merge_gap : float, optional\n        The number of seconds to merge timestamps, by default 30\n\n    Returns\n    -------\n    nel.EpochArray\n        A nel.EpochArray containing the timestamps.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import neuro_py as npy\n    &gt;&gt;&gt; filename = r\"D:\\KiloSort\\HP18\\hp18_day11_20250415\\Kilosort_2025-04-16_224949\\phy.log\"\n    &gt;&gt;&gt; timestamps = npy.raw.phy_log_to_epocharray(filename)\n    &gt;&gt;&gt; timestamps\n    &lt;EpochArray at 0x1f6c7da5710: 80 epochs&gt; of length 4:02:01:591 hours\n\n    \"\"\"\n\n    # Read the log file\n    try:\n        with open(filename, \"r\") as file:\n            log_lines = file.readlines()\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Log file not found: {filename}\")\n\n    # Define the regex pattern to extract timestamps\n    timestamp_pattern = re.compile(r\"\\x1b\\[\\d+m(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\")\n\n    # Extract timestamps using the regex pattern\n    timestamps = []\n    for line in log_lines:\n        match = timestamp_pattern.search(line)\n        if match:\n            timestamps.append(match.group(1))\n\n    # Create a Pandas DataFrame\n    df = pd.DataFrame(timestamps, columns=[\"Timestamp\"])\n\n    # Convert the 'Timestamp' column to datetime format\n    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%H:%M:%S.%f\")\n\n    # Convert timestamps to total seconds (including milliseconds)\n    df[\"Seconds\"] = (\n        df[\"Timestamp\"].dt.hour * 3600\n        + df[\"Timestamp\"].dt.minute * 60\n        + df[\"Timestamp\"].dt.second\n        + df[\"Timestamp\"].dt.microsecond / 1e6\n    )\n    df[\"continous\"] = df.Seconds.diff().abs().cumsum()\n\n    intervals = np.array([df.continous[1:], df.continous[1:]]).T\n\n    return nel.EpochArray(intervals).merge(gap=merge_gap)\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.remove_artifacts","title":"<code>remove_artifacts(filepath, n_channels, zero_intervals, precision='int16', mode='linear', channels_to_remove=None)</code>","text":"<p>Silence user-defined periods from recordings in a binary file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the binary file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels in the file.</p> required <code>zero_intervals</code> <code>List[Tuple[int, int]]</code> <p>List of intervals (start, end) in sample indices to zero out.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>mode</code> <code>str</code> <p>Mode of interpolation. Options are:</p> <ul> <li>\"zeros\": Zero out the interval.</li> <li>\"linear\": Interpolate linearly between the start and end of the interval (default).</li> <li>\"gaussian\": (Not implemented, TBD) Interpolate using a Gaussian function with the same variance as in the recordings, on a per-channel basis.</li> </ul> <code>'linear'</code> <code>channels_to_remove</code> <code>List[int]</code> <p>List of channels (0-based indices) to remove artifacts from. If None, remove artifacts from all channels.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fs = 20_000\n&gt;&gt;&gt; remove_artifacts(\n...     r\"U:\\data\\hpc_ctx_project\\HP13\\HP13_day12_20241112\\HP13_day12_20241112.dat\",\n...     n_channels=128,\n...     zero_intervals=(bad_intervals.data * fs).astype(int),\n...     channels_to_remove=[0, 1, 2]  # Only remove artifacts from channels 0, 1, and 2\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def remove_artifacts(\n    filepath: str,\n    n_channels: int,\n    zero_intervals: List[Tuple[int, int]],\n    precision: str = \"int16\",\n    mode: str = \"linear\",\n    channels_to_remove: Optional[List[int]] = None,\n) -&gt; None:\n    \"\"\"\n    Silence user-defined periods from recordings in a binary file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the binary file.\n    n_channels : int\n        Number of channels in the file.\n    zero_intervals : List[Tuple[int, int]]\n        List of intervals (start, end) in sample indices to zero out.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    mode : str, optional\n        Mode of interpolation. Options are:\n\n        - **\"zeros\"**: Zero out the interval.\n        - **\"linear\"**: Interpolate linearly between the start and end of the interval (default).\n        - **\"gaussian\"**: *(Not implemented, TBD)* Interpolate using a Gaussian function with the same variance as in the recordings, on a per-channel basis.\n\n    channels_to_remove : List[int], optional\n        List of channels (0-based indices) to remove artifacts from. If None, remove artifacts from all channels.\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; fs = 20_000\n    &gt;&gt;&gt; remove_artifacts(\n    ...     r\"U:\\\\data\\\\hpc_ctx_project\\\\HP13\\\\HP13_day12_20241112\\\\HP13_day12_20241112.dat\",\n    ...     n_channels=128,\n    ...     zero_intervals=(bad_intervals.data * fs).astype(int),\n    ...     channels_to_remove=[0, 1, 2]  # Only remove artifacts from channels 0, 1, and 2\n    ... )\n    \"\"\"\n    # Check if file exists\n    if not os.path.exists(filepath):\n        warnings.warn(\"File does not exist.\")\n        return\n\n    # Open the file in memory-mapped mode for read/write\n    bytes_size = np.dtype(precision).itemsize\n    with open(filepath, \"rb\") as f:\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n\n    # Map the file to memory in read-write mode\n    data = np.memmap(\n        filepath, dtype=precision, mode=\"r+\", shape=(n_samples, n_channels)\n    )\n    try:\n        # if shape is (2,) then it is a single interval, then add dimension\n        if np.shape(zero_intervals) == (2,):\n            zero_intervals = np.expand_dims(zero_intervals, axis=0)\n\n        # If no specific channels are provided, process all channels\n        if channels_to_remove is None:\n            channels_to_remove = list(range(n_channels))\n\n        # Zero out the specified intervals\n        if mode == \"zeros\":\n            zero_value = np.zeros((1, n_channels), dtype=precision)\n            for start, end in zero_intervals:\n                if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n                    data[start:end, channels_to_remove] = zero_value[\n                        0, channels_to_remove\n                    ]\n                else:\n                    warnings.warn(\n                        f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n                    )\n        elif mode == \"linear\":\n            for start, end in zero_intervals:\n                if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n                    for ch in channels_to_remove:\n                        # Compute float interpolation and round before casting\n                        interpolated = np.linspace(\n                            data[start, ch],\n                            data[end, ch],\n                            end - start,\n                        ).astype(data.dtype)  # Ensure consistent dtype\n                        data[start:end, ch] = interpolated\n                else:\n                    warnings.warn(\n                        f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n                    )\n        elif mode == \"gaussian\":\n            # not implemented error message\n            raise NotImplementedError(\"Gaussian mode not implemented.\")\n\n            # max_samples = 10_000\n            # rng = np.random.default_rng()\n\n            # # Compute valid regions and sample\n            # valid_mask = np.ones(n_samples, dtype=bool)\n            # for start, end in zero_intervals:\n            #     valid_mask[start:end] = False\n\n            # valid_indices = np.flatnonzero(valid_mask)\n            # sampled_indices = rng.choice(\n            #     valid_indices, size=min(max_samples, len(valid_indices)), replace=False\n            # )\n            # sampled_data = data[sampled_indices, :]\n\n            # # Compute mean and std for each channel\n            # means = np.mean(sampled_data, axis=0)\n            # stds = np.std(sampled_data, axis=0)\n\n            # from scipy.signal import butter, filtfilt\n\n            # def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n            #     nyquist = 0.5 * fs\n            #     low = lowcut / nyquist\n            #     high = highcut / nyquist\n            #     b, a = butter(order, [low, high], btype=\"band\")\n            #     return filtfilt(b, a, signal, axis=0)\n\n            # # Parameters for bandpass filter\n            # lowcut = 0.5\n            # highcut = 100\n\n            # for start, end in zero_intervals:\n            #     if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n            #         interval_length = end - start\n            #         raw_noise = rng.normal(\n            #             loc=means, scale=stds, size=(interval_length, n_channels)\n            #         ).astype(precision)\n\n            #         # Apply bandpass filter with handling for potential issues\n            #         try:\n            #             filtered_noise = bandpass_filter(raw_noise, lowcut, highcut, fs)\n            #             filtered_noise = np.nan_to_num(filtered_noise, nan=0.0)\n            #         except ValueError:\n            #             warnings.warn(f\"Filtering failed for interval ({start}, {end}), skipping.\")\n            #             continue\n\n            #         # Prevent overwriting with unexpected data types\n            #         data[start:end, :] = filtered_noise.astype(data.dtype)\n            #     else:\n            #         warnings.warn(f\"Interval ({start}, {end}) is out of bounds and was skipped.\")\n\n    finally:\n        # Explicitly flush and release the memory-mapped object\n        data.flush()\n        del data\n        gc.collect()\n\n    # Save a log file with intervals zeroed out\n    log_file = os.path.splitext(filepath)[0] + \"_zeroed_intervals.log\"\n    try:\n        with open(log_file, \"w\") as f:\n            f.write(f\"Zeroed intervals: {zero_intervals.tolist()}\\n\")\n    except Exception as e:\n        warnings.warn(f\"Failed to create log file: {e}\")\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.reorder_channels","title":"<code>reorder_channels(file_path, n_channels, channel_order, precision='int16', chunk_size=100000)</code>","text":"<p>Reorder channels in a large binary file, processing sequentially with a progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file of the binary file to modify.</p> required <code>n_channels</code> <code>int</code> <p>Total number of channels in the binary file.</p> required <code>channel_order</code> <code>List[int]</code> <p>List of channel indices specifying the new order of channels.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>chunk_size</code> <code>int</code> <p>Number of samples to process at a time, by default 100000. Adjust based on your available memory.</p> <code>100000</code> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def reorder_channels(\n    file_path: str,\n    n_channels: int,\n    channel_order: List[int],\n    precision: str = \"int16\",\n    chunk_size: int = 100000,  # Process this many samples at a time\n):\n    \"\"\"\n    Reorder channels in a large binary file, processing sequentially with a progress bar.\n\n    Parameters\n    ----------\n    file_path : str\n        Path to the file of the binary file to modify.\n    n_channels : int\n        Total number of channels in the binary file.\n    channel_order : List[int]\n        List of channel indices specifying the new order of channels.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    chunk_size : int, optional\n        Number of samples to process at a time, by default 100000.\n        Adjust based on your available memory.\n    \"\"\"\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Binary file '{file_path}' does not exist.\")\n\n    dtype = np.dtype(precision)\n    bytes_per_sample = dtype.itemsize\n\n    # Calculate total number of samples\n    file_size = os.path.getsize(file_path)\n    n_samples = file_size // (bytes_per_sample * n_channels)\n    if file_size % (bytes_per_sample * n_channels) != 0:\n        raise ValueError(\"Data size is not consistent with expected shape.\")\n\n    # Prepare output file path\n    filename = os.path.basename(file_path)\n    basepath = os.path.dirname(file_path)\n    new_file_path = os.path.join(basepath, f\"reordered_{filename}\")\n\n    # Create an empty output file of the correct size\n    with open(new_file_path, \"wb\") as f:\n        f.truncate(n_samples * n_channels * bytes_per_sample)\n\n    # Process the file sequentially in chunks\n    with tqdm(total=n_samples, desc=\"Processing\", unit=\"samples\") as pbar:\n        for start in range(0, n_samples, chunk_size):\n            end = min(start + chunk_size, n_samples)\n\n            # Memory-map the input file for this chunk\n            data = np.memmap(\n                file_path,\n                dtype=dtype,\n                mode=\"r\",\n                shape=(end - start, n_channels),\n                offset=start * n_channels * dtype.itemsize,\n            )\n\n            # Memory-map the output file for this chunk\n            reordered_data = np.memmap(\n                new_file_path,\n                dtype=dtype,\n                mode=\"r+\",\n                shape=(end - start, n_channels),\n                offset=start * n_channels * dtype.itemsize,\n            )\n\n            # Reorder the channels\n            reordered_data[:] = data[:, channel_order]\n\n            # Flush changes to disk\n            reordered_data.flush()\n\n            # Update progress bar\n            pbar.update(end - start)\n</code></pre>"},{"location":"reference/neuro_py/raw/#neuro_py.raw.spike_sorting_progress","title":"<code>spike_sorting_progress(file, wait_time=300, hue='amp')</code>","text":"<p>Monitor the progress of a spike sorting process by checking the number of unsorted clusters in a tsv file. Will plot the progress in real-time and estimate the remaining time.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>The path to the cluster_info.tsv file containing the spike sorting results.</p> required <code>wait_time</code> <code>float</code> <p>The time to wait between checks, in seconds. Default is 300 seconds (5 minutes).</p> <code>300</code> <code>hue</code> <code>str</code> <p>The column to use for the hue in the plot. Default is \"amp\". (\"id\",\"amp\",\"ch\",\"depth\",\"fr\",\"group\",\"n_spikes\",\"sh\")</p> <code>'amp'</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import neuro_py as npy\n&gt;&gt;&gt; npy.raw.spike_sorting_progress(r\"D:\\KiloSort\\hp18_day12_20250416\\Kilosort_2025-04-17_161532\\cluster_info.tsv\")\n</code></pre> Notes <p>This function assumes a specific way of spike sorting in phy: - Once cleaning/merging is done for a unit, the unit is marked good - Needs at least 1 unit marked good to start the process</p> Source code in <code>neuro_py/raw/spike_sorting.py</code> <pre><code>def spike_sorting_progress(file: str, wait_time: float = 300, hue: str = \"amp\"):\n    \"\"\"\n    Monitor the progress of a spike sorting process by checking the number of unsorted clusters in a tsv file.\n    Will plot the progress in real-time and estimate the remaining time.\n\n    Parameters\n    ----------\n    file : str\n        The path to the cluster_info.tsv file containing the spike sorting results.\n    wait_time : float, optional\n        The time to wait between checks, in seconds. Default is 300 seconds (5 minutes).\n    hue : str, optional\n        The column to use for the hue in the plot. Default is \"amp\". (\"id\",\"amp\",\"ch\",\"depth\",\"fr\",\"group\",\"n_spikes\",\"sh\")\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; import neuro_py as npy\n    &gt;&gt;&gt; npy.raw.spike_sorting_progress(r\"D:\\KiloSort\\hp18_day12_20250416\\Kilosort_2025-04-17_161532\\cluster_info.tsv\")\n\n    Notes\n    ------\n    This function assumes a specific way of spike sorting in phy:\n    - Once cleaning/merging is done for a unit, the unit is marked good\n    - Needs at least 1 unit marked good to start the process\n\n\n    \"\"\"\n\n    # dark mode plotting\n    plt.style.use(\"dark_background\")\n\n    def safe_read_csv(file, retries=3):\n        for _ in range(retries):\n            try:\n                return pd.read_csv(file, sep=\"\\t\")\n            except (pd.errors.EmptyDataError, PermissionError):\n                time.sleep(1)\n        raise IOError(f\"Failed to read {file} after {retries} attempts.\")\n\n    # Function to count unsorted clusters\n    def count_unsorted_clusters(file):\n        df = safe_read_csv(file)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=FutureWarning)\n            df[\"group\"].replace(np.nan, \"unsorted\", inplace=True)\n\n        first_good = df.query('group==\"good\"').index[0]\n        df_before_good = df.loc[: first_good - 1].copy()\n\n        n_unsorted = df_before_good.query('group==\"unsorted\"').shape[0]\n        n_sorted = df.query('group==\"good\"').shape[0]\n        return n_unsorted, n_sorted\n\n    # Initial count of unsorted clusters\n    initial_unsorted, _ = count_unsorted_clusters(file)\n    print(f\"Initial unsorted clusters: {initial_unsorted}\")\n\n    # Set a flag to indicate whether the process is complete\n    completed = False\n    # List to store the time and unsorted count for rate calculation\n    time_unsorted_data = [(0, initial_unsorted)]\n\n    # Create a figure and axes for the plot\n    plt.ion()  # Enable interactive mode\n    fig, ax = plt.subplots(\n        2, 1, figsize=(10, 7), sharex=True, gridspec_kw={\"height_ratios\": [1, 4]}\n    )\n\n    while not completed:\n        time.sleep(wait_time)  # Wait for x minutes\n\n        current_unsorted, n_sorted = count_unsorted_clusters(file)\n        current_time = (\n            time_unsorted_data[-1][0] + wait_time / 60\n        )  # Increment time by x minutes\n        time_unsorted_data.append((current_time, current_unsorted))\n\n        sorted_clusters = (\n            time_unsorted_data[0][1] - current_unsorted\n        )  # Number of clusters sorted so far\n\n        if sorted_clusters &gt; 0:\n            # Use all previous data points to calculate an average rate of sorting\n            total_time_elapsed = sum(\n                [\n                    time_unsorted_data[i + 1][0] - time_unsorted_data[i][0]\n                    for i in range(len(time_unsorted_data) - 1)\n                ]\n            )\n            total_clusters_sorted = sum(\n                [\n                    time_unsorted_data[i][1] - time_unsorted_data[i + 1][1]\n                    for i in range(len(time_unsorted_data) - 1)\n                ]\n            )\n\n            average_rate_of_sorting = (\n                total_clusters_sorted / total_time_elapsed\n            )  # Average clusters sorted per minute\n            estimated_time_remaining = (\n                current_unsorted / average_rate_of_sorting\n            )  # Estimate the time remaining\n\n            progress_text = (\n                f\"Time elapsed: {current_time} minutes\\n\"\n                f\"Current unsorted clusters: {current_unsorted}\\n\"\n                f\"Sorted clusters: {n_sorted}\\n\"\n                f\"Average rate of sorting: {average_rate_of_sorting:.2f} clusters/minute\\n\"\n                f\"Estimated time to completion: {estimated_time_remaining:.2f} minutes\"\n            )\n\n            # Check if sorting is complete\n            if current_unsorted == 0:\n                completed = True\n                progress_text += \"\\nSorting complete!\"\n        else:\n            progress_text = f\"No progress made in the last {current_time} minutes. Check if the process is working correctly.\"\n\n        # Update the plot\n        df = safe_read_csv(file)\n        df[\"group\"] = df[\"group\"].replace(np.nan, \"unsorted\")\n\n        # Clear only the plot axes (not the printed output)\n        for a in ax:\n            a.clear()\n\n        # Set plot limits\n        ax[0].set_xlim(df.sh.min(), df.sh.max())\n        ax[1].set_xlim(df.sh.min(), df.sh.max())\n\n        # Create the stripplot\n        sns.stripplot(\n            data=df[[\"depth\", \"sh\"]]\n            .value_counts()\n            .reset_index()\n            .sort_values(by=[\"sh\"]),\n            x=\"sh\",\n            y=\"depth\",\n            ax=ax[1],\n            jitter=False,\n            legend=False,\n            color=\"white\",\n            alpha=0.5,\n        )\n\n        sns.stripplot(\n            data=df.query('group==\"good\"'),\n            x=\"sh\",\n            y=\"depth\",\n            hue=hue,\n            ax=ax[1],\n            jitter=True,\n            legend=False,\n            palette=\"rainbow\",\n        )\n\n        count_df = (\n            df.query('group==\"good\"')\n            .groupby(\"sh\", observed=True)\n            .size()\n            .reset_index(name=\"counts\")\n        )\n\n        sns.barplot(data=count_df, x=\"sh\", y=\"counts\", ax=ax[0], palette=\"winter\")\n        for p in ax[0].patches:\n            ax[0].annotate(\n                f\"{int(p.get_height())}\",\n                (p.get_x() + p.get_width() / 2.0, p.get_height()),\n                ha=\"center\",\n                va=\"bottom\",\n                fontsize=8,\n                color=\"white\",\n            )\n        ax[0].set_ylabel(\"Number of \\n clusters\")\n        ax[1].set_xlabel(\"Shank\")\n        ax[1].set_ylabel(\"Depth (um)\")\n\n        sns.despine()\n        # Draw the plot\n        plt.draw()\n        plt.pause(0.01)  # Pause to allow the plot to updateg\n\n        # Display progress text below the plot\n        clear_output(wait=True)  # Clear only the previous plot and progress text\n        display(fig)  # Display the updated plot\n        print(progress_text)  # Display the progress text below the plot\n\n    # Close the interactive plot after completion\n    plt.ioff()\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/raw/preprocessing/","title":"neuro_py.raw.preprocessing","text":""},{"location":"reference/neuro_py/raw/preprocessing/#neuro_py.raw.preprocessing.cut_artifacts","title":"<code>cut_artifacts(filepath, n_channels, cut_intervals, precision='int16', output_filepath=None)</code>","text":"<p>Remove user-defined periods from recordings in a binary file, resulting in a shorter file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the original binary file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels in the file.</p> required <code>cut_intervals</code> <code>List[Tuple[int, int]]</code> <p>List of intervals (start, end) in sample indices to remove. Assumes sorted and non-overlapping.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>output_filepath</code> <code>str</code> <p>Path to save the modified binary file. If None, appends \"_cut\" to the original filename.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def cut_artifacts(\n    filepath: str,\n    n_channels: int,\n    cut_intervals: List[Tuple[int, int]],\n    precision: str = \"int16\",\n    output_filepath: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Remove user-defined periods from recordings in a binary file, resulting in a shorter file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the original binary file.\n    n_channels : int\n        Number of channels in the file.\n    cut_intervals : List[Tuple[int, int]]\n        List of intervals (start, end) in sample indices to remove. Assumes sorted and non-overlapping.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    output_filepath : str, optional\n        Path to save the modified binary file. If None, appends \"_cut\" to the original filename.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # Check if file exists\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"File '{filepath}' does not exist.\")\n\n    # Set default output filepath\n    if output_filepath is None:\n        output_filepath = os.path.splitext(filepath)[0] + \"_cut.dat\"\n\n    # Check for valid intervals\n    for start, end in cut_intervals:\n        if start &gt;= end:\n            raise ValueError(\n                f\"Invalid interval: ({start}, {end}). Start must be less than end.\"\n            )\n\n    # Map the original file and calculate parameters\n    bytes_size = np.dtype(precision).itemsize\n    with open(filepath, \"rb\") as f:\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n\n    data = np.memmap(filepath, dtype=precision, mode=\"r\", shape=(n_samples, n_channels))\n\n    # Identify the indices to keep\n    keep_mask = np.ones(n_samples, dtype=bool)\n    for start, end in cut_intervals:\n        if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n            keep_mask[start:end] = False\n        else:\n            warnings.warn(\n                f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n            )\n\n    keep_indices = np.flatnonzero(keep_mask)\n\n    # Create a new binary file with only the retained data\n    with open(output_filepath, \"wb\") as output_file:\n        for start_idx in range(0, len(keep_indices), 10_000):  # Process in chunks\n            chunk_indices = keep_indices[start_idx : start_idx + 10_000]\n            output_file.write(data[chunk_indices].tobytes())\n\n    del data  # Release memory-mapped file\n</code></pre>"},{"location":"reference/neuro_py/raw/preprocessing/#neuro_py.raw.preprocessing.cut_artifacts_intan","title":"<code>cut_artifacts_intan(folder_name, n_channels_amplifier, cut_intervals, verbose=True)</code>","text":"<p>Cut specified artifact intervals from Intan data files.</p> <p>This function iterates through a set of Intan data files (amplifier, auxiliary, digitalin, digitalout, analogin, time, and supply), and for each file, it removes artifacts within the specified intervals by invoking the <code>cut_artifacts</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>folder_name</code> <code>str</code> <p>The folder where the Intan data files are located.</p> required <code>n_channels_amplifier</code> <code>int</code> <p>The number of amplifier channels used in the amplifier data file.</p> required <code>cut_intervals</code> <code>List[Tuple[int, int]]</code> <p>A list of intervals (start, end) in sample indices to remove artifacts. Each tuple represents the start and end sample index for an artifact to be cut. Assumes sorted and non-overlapping intervals.</p> required <p>Returns:</p> Type Description <code>None</code> <p>This function modifies the files in place, so there is no return value.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the amplifier data file does not exist in the provided folder.</p> <code>ValueError</code> <p>If video files are found in the folder, as this function does not support video files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fs = 20_000\n&gt;&gt;&gt; cut_artifacts_intan(\n...     folder_name = r\"path/to/data\",\n...     n_channels_amplifier = 128,\n...     cut_intervals = (np.array([[394.4, 394.836], [400, 401], [404, 405]]) * fs).astype(int)\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def cut_artifacts_intan(\n    folder_name: str,\n    n_channels_amplifier: int,\n    cut_intervals: List[Tuple[int, int]],\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"\n    Cut specified artifact intervals from Intan data files.\n\n    This function iterates through a set of Intan data files (amplifier, auxiliary,\n    digitalin, digitalout, analogin, time, and supply), and for each file, it removes\n    artifacts within the specified intervals by invoking the `cut_artifacts` function.\n\n    Parameters\n    ----------\n    folder_name : str\n        The folder where the Intan data files are located.\n    n_channels_amplifier : int\n        The number of amplifier channels used in the amplifier data file.\n    cut_intervals : List[Tuple[int, int]]\n        A list of intervals (start, end) in sample indices to remove artifacts.\n        Each tuple represents the start and end sample index for an artifact to be cut.\n        Assumes sorted and non-overlapping intervals.\n\n    Returns\n    -------\n    None\n        This function modifies the files in place, so there is no return value.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the amplifier data file does not exist in the provided folder.\n    ValueError\n        If video files are found in the folder, as this function does not support video files.\n\n    Examples\n    --------\n    &gt;&gt;&gt; fs = 20_000\n    &gt;&gt;&gt; cut_artifacts_intan(\n    ...     folder_name = r\"path/to/data\",\n    ...     n_channels_amplifier = 128,\n    ...     cut_intervals = (np.array([[394.4, 394.836], [400, 401], [404, 405]]) * fs).astype(int)\n    ... )\n    \"\"\"\n\n    # refuse to cut artifacts if any video file exist in folder\n    video_files = [f for f in os.listdir(folder_name) if f.endswith(\".avi\")]\n    if video_files:\n        raise ValueError(f\"Video files found in folder, refusing to cut: {video_files}\")\n\n    # Define data types for each file (from Intan documentation)\n    files_table = {\n        \"amplifier\": \"int16\",\n        \"auxiliary\": \"uint16\",\n        \"digitalin\": \"uint16\",\n        \"digitalout\": \"uint16\",\n        \"analogin\": \"uint16\",\n        \"time\": \"int32\",\n        \"supply\": \"uint16\",\n    }\n\n    # determine number of samples from amplifier file\n    amplifier_file_path = os.path.join(folder_name, \"amplifier.dat\")\n    if not os.path.exists(amplifier_file_path):\n        raise FileNotFoundError(f\"File '{amplifier_file_path}' does not exist.\")\n\n    # get number of bytes per sample\n    bytes_size = np.dtype(files_table[\"amplifier\"]).itemsize\n\n    # each file should have the same number of samples\n    n_samples = os.path.getsize(amplifier_file_path) // (\n        n_channels_amplifier * bytes_size\n    )\n\n    for file_name, precision in files_table.items():\n        file_path = os.path.join(folder_name, f\"{file_name}.dat\")\n\n        if os.path.exists(file_path):\n            if verbose:\n                print(f\"Processing {file_name}.dat file...\")\n\n            # get number of bytes per sample\n            bytes_size = np.dtype(precision).itemsize\n\n            # determine number of channels from n_samples\n            n_channels = int(os.path.getsize(file_path) / n_samples / bytes_size)\n\n            # for time file, cut and offset timestamps\n            if file_name == \"time\":\n                output_filepath = os.path.splitext(file_path)[0] + \"_cut.dat\"\n\n                with open(output_filepath, \"wb\") as output_file:\n                    # time indices as continuous array\n                    filtered_time = np.arange(\n                        n_samples - sum(end - start for start, end in cut_intervals),\n                        dtype=np.int32,\n                    )\n\n                    # write to file\n                    output_file.write(filtered_time.tobytes())\n            else:\n                # cut artifacts\n                cut_artifacts(file_path, n_channels, cut_intervals, precision)\n\n    # Calculate the expected number of samples after cutting\n    total_samples_cut = sum(end - start for start, end in cut_intervals)\n    expected_n_samples = n_samples - total_samples_cut\n\n    # === Validation Section ===\n    # Verify all `_cut.dat` files have the correct number of samples\n    for file_name, precision in files_table.items():\n        output_file_path = os.path.join(folder_name, f\"{file_name}_cut.dat\")\n        original_file_path = os.path.join(folder_name, f\"{file_name}.dat\")\n\n        if os.path.exists(output_file_path) and os.path.exists(original_file_path):\n            # Dynamically calculate the number of channels\n            bytes_size = np.dtype(precision).itemsize\n            n_channels = os.path.getsize(original_file_path) // (n_samples * bytes_size)\n\n            # Calculate the expected file size\n            expected_size = expected_n_samples * n_channels * bytes_size\n            actual_size = os.path.getsize(output_file_path)\n\n            if actual_size != expected_size:\n                raise RuntimeError(\n                    f\"{file_name}_cut.dat has an incorrect size. \"\n                    f\"Expected {expected_size} bytes but found {actual_size} bytes.\"\n                )\n</code></pre>"},{"location":"reference/neuro_py/raw/preprocessing/#neuro_py.raw.preprocessing.fill_missing_channels","title":"<code>fill_missing_channels(basepath, n_channels, filename, missing_channels, precision='int16', chunk_size=10000)</code>","text":"<p>Fill missing channels in a large binary file with zeros, processing in chunks. This function is useful when some channels were accidently deactivated during recording.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>Path to the folder containing the binary file.</p> required <code>n_channels</code> <code>int</code> <p>Total number of channels in the binary file (including the missing ones).</p> required <code>filename</code> <code>str</code> <p>Name of the binary file to modify.</p> required <code>missing_channels</code> <code>List[int]</code> <p>List of missing channel indices to be filled with zeros.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>chunk_size</code> <code>int</code> <p>Number of samples per chunk, by default 10,000.</p> <code>10000</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the modified binary file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fill_missing_channels(\n...    r\"U:\\data\\hpc_ctx_project\\HP13\\HP13_day1_20241030\\HP13_cheeseboard_241030_153710\",\n...    128,\n...    'amplifier.dat',\n...    missing_channels = [0]\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def fill_missing_channels(\n    basepath: str,\n    n_channels: int,\n    filename: str,\n    missing_channels: List[int],\n    precision: str = \"int16\",\n    chunk_size: int = 10_000,\n) -&gt; str:\n    \"\"\"\n    Fill missing channels in a large binary file with zeros, processing in chunks.\n    This function is useful when some channels were accidently deactivated during recording.\n\n    Parameters\n    ----------\n    basepath : str\n        Path to the folder containing the binary file.\n    n_channels : int\n        Total number of channels in the binary file (including the missing ones).\n    filename : str\n        Name of the binary file to modify.\n    missing_channels : List[int]\n        List of missing channel indices to be filled with zeros.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    chunk_size : int, optional\n        Number of samples per chunk, by default 10,000.\n\n    Returns\n    -------\n    str\n        Path to the modified binary file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; fill_missing_channels(\n    ...    r\"U:\\\\data\\\\hpc_ctx_project\\\\HP13\\\\HP13_day1_20241030\\\\HP13_cheeseboard_241030_153710\",\n    ...    128,\n    ...    'amplifier.dat',\n    ...    missing_channels = [0]\n    ... )\n    \"\"\"\n    file_path = os.path.join(basepath, filename)\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Binary file '{file_path}' does not exist.\")\n\n    dtype = np.dtype(precision)\n    bytes_per_sample = dtype.itemsize\n    present_channels = [ch for ch in range(n_channels) if ch not in missing_channels]\n\n    # Calculate total number of samples\n    file_size = os.path.getsize(file_path)\n    n_samples = file_size // (bytes_per_sample * (n_channels - len(missing_channels)))\n    if file_size % (bytes_per_sample * (n_channels - len(missing_channels))) != 0:\n        raise ValueError(\"Data size is not consistent with expected shape.\")\n\n    # Prepare output file path\n    new_file_path = os.path.join(basepath, f\"corrected_{filename}\")\n\n    # Process file in chunks\n    with open(file_path, \"rb\") as f_in, open(new_file_path, \"wb\") as f_out:\n        for start in range(0, n_samples, chunk_size):\n            # Read a chunk of data\n            chunk = np.fromfile(\n                f_in,\n                dtype=dtype,\n                count=chunk_size * (n_channels - len(missing_channels)),\n            )\n            chunk = chunk.reshape(-1, n_channels - len(missing_channels))\n\n            # Create a new array with missing channels filled with zeros\n            chunk_full = np.zeros((chunk.shape[0], n_channels), dtype=dtype)\n            chunk_full[:, present_channels] = chunk\n\n            # Write the chunk with missing channels added to the new file\n            chunk_full.tofile(f_out)\n\n    return new_file_path\n</code></pre>"},{"location":"reference/neuro_py/raw/preprocessing/#neuro_py.raw.preprocessing.remove_artifacts","title":"<code>remove_artifacts(filepath, n_channels, zero_intervals, precision='int16', mode='linear', channels_to_remove=None)</code>","text":"<p>Silence user-defined periods from recordings in a binary file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the binary file.</p> required <code>n_channels</code> <code>int</code> <p>Number of channels in the file.</p> required <code>zero_intervals</code> <code>List[Tuple[int, int]]</code> <p>List of intervals (start, end) in sample indices to zero out.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>mode</code> <code>str</code> <p>Mode of interpolation. Options are:</p> <ul> <li>\"zeros\": Zero out the interval.</li> <li>\"linear\": Interpolate linearly between the start and end of the interval (default).</li> <li>\"gaussian\": (Not implemented, TBD) Interpolate using a Gaussian function with the same variance as in the recordings, on a per-channel basis.</li> </ul> <code>'linear'</code> <code>channels_to_remove</code> <code>List[int]</code> <p>List of channels (0-based indices) to remove artifacts from. If None, remove artifacts from all channels.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fs = 20_000\n&gt;&gt;&gt; remove_artifacts(\n...     r\"U:\\data\\hpc_ctx_project\\HP13\\HP13_day12_20241112\\HP13_day12_20241112.dat\",\n...     n_channels=128,\n...     zero_intervals=(bad_intervals.data * fs).astype(int),\n...     channels_to_remove=[0, 1, 2]  # Only remove artifacts from channels 0, 1, and 2\n... )\n</code></pre> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def remove_artifacts(\n    filepath: str,\n    n_channels: int,\n    zero_intervals: List[Tuple[int, int]],\n    precision: str = \"int16\",\n    mode: str = \"linear\",\n    channels_to_remove: Optional[List[int]] = None,\n) -&gt; None:\n    \"\"\"\n    Silence user-defined periods from recordings in a binary file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the binary file.\n    n_channels : int\n        Number of channels in the file.\n    zero_intervals : List[Tuple[int, int]]\n        List of intervals (start, end) in sample indices to zero out.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    mode : str, optional\n        Mode of interpolation. Options are:\n\n        - **\"zeros\"**: Zero out the interval.\n        - **\"linear\"**: Interpolate linearly between the start and end of the interval (default).\n        - **\"gaussian\"**: *(Not implemented, TBD)* Interpolate using a Gaussian function with the same variance as in the recordings, on a per-channel basis.\n\n    channels_to_remove : List[int], optional\n        List of channels (0-based indices) to remove artifacts from. If None, remove artifacts from all channels.\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; fs = 20_000\n    &gt;&gt;&gt; remove_artifacts(\n    ...     r\"U:\\\\data\\\\hpc_ctx_project\\\\HP13\\\\HP13_day12_20241112\\\\HP13_day12_20241112.dat\",\n    ...     n_channels=128,\n    ...     zero_intervals=(bad_intervals.data * fs).astype(int),\n    ...     channels_to_remove=[0, 1, 2]  # Only remove artifacts from channels 0, 1, and 2\n    ... )\n    \"\"\"\n    # Check if file exists\n    if not os.path.exists(filepath):\n        warnings.warn(\"File does not exist.\")\n        return\n\n    # Open the file in memory-mapped mode for read/write\n    bytes_size = np.dtype(precision).itemsize\n    with open(filepath, \"rb\") as f:\n        startoffile = f.seek(0, 0)\n        endoffile = f.seek(0, 2)\n        n_samples = int((endoffile - startoffile) / n_channels / bytes_size)\n\n    # Map the file to memory in read-write mode\n    data = np.memmap(\n        filepath, dtype=precision, mode=\"r+\", shape=(n_samples, n_channels)\n    )\n    try:\n        # if shape is (2,) then it is a single interval, then add dimension\n        if np.shape(zero_intervals) == (2,):\n            zero_intervals = np.expand_dims(zero_intervals, axis=0)\n\n        # If no specific channels are provided, process all channels\n        if channels_to_remove is None:\n            channels_to_remove = list(range(n_channels))\n\n        # Zero out the specified intervals\n        if mode == \"zeros\":\n            zero_value = np.zeros((1, n_channels), dtype=precision)\n            for start, end in zero_intervals:\n                if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n                    data[start:end, channels_to_remove] = zero_value[\n                        0, channels_to_remove\n                    ]\n                else:\n                    warnings.warn(\n                        f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n                    )\n        elif mode == \"linear\":\n            for start, end in zero_intervals:\n                if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n                    for ch in channels_to_remove:\n                        # Compute float interpolation and round before casting\n                        interpolated = np.linspace(\n                            data[start, ch],\n                            data[end, ch],\n                            end - start,\n                        ).astype(data.dtype)  # Ensure consistent dtype\n                        data[start:end, ch] = interpolated\n                else:\n                    warnings.warn(\n                        f\"Interval ({start}, {end}) is out of bounds and was skipped.\"\n                    )\n        elif mode == \"gaussian\":\n            # not implemented error message\n            raise NotImplementedError(\"Gaussian mode not implemented.\")\n\n            # max_samples = 10_000\n            # rng = np.random.default_rng()\n\n            # # Compute valid regions and sample\n            # valid_mask = np.ones(n_samples, dtype=bool)\n            # for start, end in zero_intervals:\n            #     valid_mask[start:end] = False\n\n            # valid_indices = np.flatnonzero(valid_mask)\n            # sampled_indices = rng.choice(\n            #     valid_indices, size=min(max_samples, len(valid_indices)), replace=False\n            # )\n            # sampled_data = data[sampled_indices, :]\n\n            # # Compute mean and std for each channel\n            # means = np.mean(sampled_data, axis=0)\n            # stds = np.std(sampled_data, axis=0)\n\n            # from scipy.signal import butter, filtfilt\n\n            # def bandpass_filter(signal, lowcut, highcut, fs, order=4):\n            #     nyquist = 0.5 * fs\n            #     low = lowcut / nyquist\n            #     high = highcut / nyquist\n            #     b, a = butter(order, [low, high], btype=\"band\")\n            #     return filtfilt(b, a, signal, axis=0)\n\n            # # Parameters for bandpass filter\n            # lowcut = 0.5\n            # highcut = 100\n\n            # for start, end in zero_intervals:\n            #     if 0 &lt;= start &lt; n_samples and 0 &lt; end &lt;= n_samples:\n            #         interval_length = end - start\n            #         raw_noise = rng.normal(\n            #             loc=means, scale=stds, size=(interval_length, n_channels)\n            #         ).astype(precision)\n\n            #         # Apply bandpass filter with handling for potential issues\n            #         try:\n            #             filtered_noise = bandpass_filter(raw_noise, lowcut, highcut, fs)\n            #             filtered_noise = np.nan_to_num(filtered_noise, nan=0.0)\n            #         except ValueError:\n            #             warnings.warn(f\"Filtering failed for interval ({start}, {end}), skipping.\")\n            #             continue\n\n            #         # Prevent overwriting with unexpected data types\n            #         data[start:end, :] = filtered_noise.astype(data.dtype)\n            #     else:\n            #         warnings.warn(f\"Interval ({start}, {end}) is out of bounds and was skipped.\")\n\n    finally:\n        # Explicitly flush and release the memory-mapped object\n        data.flush()\n        del data\n        gc.collect()\n\n    # Save a log file with intervals zeroed out\n    log_file = os.path.splitext(filepath)[0] + \"_zeroed_intervals.log\"\n    try:\n        with open(log_file, \"w\") as f:\n            f.write(f\"Zeroed intervals: {zero_intervals.tolist()}\\n\")\n    except Exception as e:\n        warnings.warn(f\"Failed to create log file: {e}\")\n</code></pre>"},{"location":"reference/neuro_py/raw/preprocessing/#neuro_py.raw.preprocessing.reorder_channels","title":"<code>reorder_channels(file_path, n_channels, channel_order, precision='int16', chunk_size=100000)</code>","text":"<p>Reorder channels in a large binary file, processing sequentially with a progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file of the binary file to modify.</p> required <code>n_channels</code> <code>int</code> <p>Total number of channels in the binary file.</p> required <code>channel_order</code> <code>List[int]</code> <p>List of channel indices specifying the new order of channels.</p> required <code>precision</code> <code>str</code> <p>Data precision, by default \"int16\".</p> <code>'int16'</code> <code>chunk_size</code> <code>int</code> <p>Number of samples to process at a time, by default 100000. Adjust based on your available memory.</p> <code>100000</code> Source code in <code>neuro_py/raw/preprocessing.py</code> <pre><code>def reorder_channels(\n    file_path: str,\n    n_channels: int,\n    channel_order: List[int],\n    precision: str = \"int16\",\n    chunk_size: int = 100000,  # Process this many samples at a time\n):\n    \"\"\"\n    Reorder channels in a large binary file, processing sequentially with a progress bar.\n\n    Parameters\n    ----------\n    file_path : str\n        Path to the file of the binary file to modify.\n    n_channels : int\n        Total number of channels in the binary file.\n    channel_order : List[int]\n        List of channel indices specifying the new order of channels.\n    precision : str, optional\n        Data precision, by default \"int16\".\n    chunk_size : int, optional\n        Number of samples to process at a time, by default 100000.\n        Adjust based on your available memory.\n    \"\"\"\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Binary file '{file_path}' does not exist.\")\n\n    dtype = np.dtype(precision)\n    bytes_per_sample = dtype.itemsize\n\n    # Calculate total number of samples\n    file_size = os.path.getsize(file_path)\n    n_samples = file_size // (bytes_per_sample * n_channels)\n    if file_size % (bytes_per_sample * n_channels) != 0:\n        raise ValueError(\"Data size is not consistent with expected shape.\")\n\n    # Prepare output file path\n    filename = os.path.basename(file_path)\n    basepath = os.path.dirname(file_path)\n    new_file_path = os.path.join(basepath, f\"reordered_{filename}\")\n\n    # Create an empty output file of the correct size\n    with open(new_file_path, \"wb\") as f:\n        f.truncate(n_samples * n_channels * bytes_per_sample)\n\n    # Process the file sequentially in chunks\n    with tqdm(total=n_samples, desc=\"Processing\", unit=\"samples\") as pbar:\n        for start in range(0, n_samples, chunk_size):\n            end = min(start + chunk_size, n_samples)\n\n            # Memory-map the input file for this chunk\n            data = np.memmap(\n                file_path,\n                dtype=dtype,\n                mode=\"r\",\n                shape=(end - start, n_channels),\n                offset=start * n_channels * dtype.itemsize,\n            )\n\n            # Memory-map the output file for this chunk\n            reordered_data = np.memmap(\n                new_file_path,\n                dtype=dtype,\n                mode=\"r+\",\n                shape=(end - start, n_channels),\n                offset=start * n_channels * dtype.itemsize,\n            )\n\n            # Reorder the channels\n            reordered_data[:] = data[:, channel_order]\n\n            # Flush changes to disk\n            reordered_data.flush()\n\n            # Update progress bar\n            pbar.update(end - start)\n</code></pre>"},{"location":"reference/neuro_py/raw/spike_sorting/","title":"neuro_py.raw.spike_sorting","text":""},{"location":"reference/neuro_py/raw/spike_sorting/#neuro_py.raw.spike_sorting.phy_log_to_epocharray","title":"<code>phy_log_to_epocharray(filename, merge_gap=30)</code>","text":"<p>Extract timestamps from a Phy log file and convert them to a nel.EpochArray. Will estimate the amount of time it took to spikesort a session.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the Phy log file.</p> required <code>merge_gap</code> <code>float</code> <p>The number of seconds to merge timestamps, by default 30</p> <code>30</code> <p>Returns:</p> Type Description <code>EpochArray</code> <p>A nel.EpochArray containing the timestamps.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import neuro_py as npy\n&gt;&gt;&gt; filename = r\"D:\\KiloSort\\HP18\\hp18_day11_20250415\\Kilosort_2025-04-16_224949\\phy.log\"\n&gt;&gt;&gt; timestamps = npy.raw.phy_log_to_epocharray(filename)\n&gt;&gt;&gt; timestamps\n&lt;EpochArray at 0x1f6c7da5710: 80 epochs&gt; of length 4:02:01:591 hours\n</code></pre> Source code in <code>neuro_py/raw/spike_sorting.py</code> <pre><code>def phy_log_to_epocharray(filename: str, merge_gap: float = 30):\n    \"\"\"\n    Extract timestamps from a Phy log file and convert them to a nel.EpochArray.\n    Will estimate the amount of time it took to spikesort a session.\n\n    Parameters\n    ----------\n    filename : str\n        The path to the Phy log file.\n    merge_gap : float, optional\n        The number of seconds to merge timestamps, by default 30\n\n    Returns\n    -------\n    nel.EpochArray\n        A nel.EpochArray containing the timestamps.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import neuro_py as npy\n    &gt;&gt;&gt; filename = r\"D:\\KiloSort\\HP18\\hp18_day11_20250415\\Kilosort_2025-04-16_224949\\phy.log\"\n    &gt;&gt;&gt; timestamps = npy.raw.phy_log_to_epocharray(filename)\n    &gt;&gt;&gt; timestamps\n    &lt;EpochArray at 0x1f6c7da5710: 80 epochs&gt; of length 4:02:01:591 hours\n\n    \"\"\"\n\n    # Read the log file\n    try:\n        with open(filename, \"r\") as file:\n            log_lines = file.readlines()\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Log file not found: {filename}\")\n\n    # Define the regex pattern to extract timestamps\n    timestamp_pattern = re.compile(r\"\\x1b\\[\\d+m(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\")\n\n    # Extract timestamps using the regex pattern\n    timestamps = []\n    for line in log_lines:\n        match = timestamp_pattern.search(line)\n        if match:\n            timestamps.append(match.group(1))\n\n    # Create a Pandas DataFrame\n    df = pd.DataFrame(timestamps, columns=[\"Timestamp\"])\n\n    # Convert the 'Timestamp' column to datetime format\n    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%H:%M:%S.%f\")\n\n    # Convert timestamps to total seconds (including milliseconds)\n    df[\"Seconds\"] = (\n        df[\"Timestamp\"].dt.hour * 3600\n        + df[\"Timestamp\"].dt.minute * 60\n        + df[\"Timestamp\"].dt.second\n        + df[\"Timestamp\"].dt.microsecond / 1e6\n    )\n    df[\"continous\"] = df.Seconds.diff().abs().cumsum()\n\n    intervals = np.array([df.continous[1:], df.continous[1:]]).T\n\n    return nel.EpochArray(intervals).merge(gap=merge_gap)\n</code></pre>"},{"location":"reference/neuro_py/raw/spike_sorting/#neuro_py.raw.spike_sorting.spike_sorting_progress","title":"<code>spike_sorting_progress(file, wait_time=300, hue='amp')</code>","text":"<p>Monitor the progress of a spike sorting process by checking the number of unsorted clusters in a tsv file. Will plot the progress in real-time and estimate the remaining time.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>The path to the cluster_info.tsv file containing the spike sorting results.</p> required <code>wait_time</code> <code>float</code> <p>The time to wait between checks, in seconds. Default is 300 seconds (5 minutes).</p> <code>300</code> <code>hue</code> <code>str</code> <p>The column to use for the hue in the plot. Default is \"amp\". (\"id\",\"amp\",\"ch\",\"depth\",\"fr\",\"group\",\"n_spikes\",\"sh\")</p> <code>'amp'</code> <p>Returns:</p> Type Description <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import neuro_py as npy\n&gt;&gt;&gt; npy.raw.spike_sorting_progress(r\"D:\\KiloSort\\hp18_day12_20250416\\Kilosort_2025-04-17_161532\\cluster_info.tsv\")\n</code></pre> Notes <p>This function assumes a specific way of spike sorting in phy: - Once cleaning/merging is done for a unit, the unit is marked good - Needs at least 1 unit marked good to start the process</p> Source code in <code>neuro_py/raw/spike_sorting.py</code> <pre><code>def spike_sorting_progress(file: str, wait_time: float = 300, hue: str = \"amp\"):\n    \"\"\"\n    Monitor the progress of a spike sorting process by checking the number of unsorted clusters in a tsv file.\n    Will plot the progress in real-time and estimate the remaining time.\n\n    Parameters\n    ----------\n    file : str\n        The path to the cluster_info.tsv file containing the spike sorting results.\n    wait_time : float, optional\n        The time to wait between checks, in seconds. Default is 300 seconds (5 minutes).\n    hue : str, optional\n        The column to use for the hue in the plot. Default is \"amp\". (\"id\",\"amp\",\"ch\",\"depth\",\"fr\",\"group\",\"n_spikes\",\"sh\")\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    &gt;&gt;&gt; import neuro_py as npy\n    &gt;&gt;&gt; npy.raw.spike_sorting_progress(r\"D:\\KiloSort\\hp18_day12_20250416\\Kilosort_2025-04-17_161532\\cluster_info.tsv\")\n\n    Notes\n    ------\n    This function assumes a specific way of spike sorting in phy:\n    - Once cleaning/merging is done for a unit, the unit is marked good\n    - Needs at least 1 unit marked good to start the process\n\n\n    \"\"\"\n\n    # dark mode plotting\n    plt.style.use(\"dark_background\")\n\n    def safe_read_csv(file, retries=3):\n        for _ in range(retries):\n            try:\n                return pd.read_csv(file, sep=\"\\t\")\n            except (pd.errors.EmptyDataError, PermissionError):\n                time.sleep(1)\n        raise IOError(f\"Failed to read {file} after {retries} attempts.\")\n\n    # Function to count unsorted clusters\n    def count_unsorted_clusters(file):\n        df = safe_read_csv(file)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=FutureWarning)\n            df[\"group\"].replace(np.nan, \"unsorted\", inplace=True)\n\n        first_good = df.query('group==\"good\"').index[0]\n        df_before_good = df.loc[: first_good - 1].copy()\n\n        n_unsorted = df_before_good.query('group==\"unsorted\"').shape[0]\n        n_sorted = df.query('group==\"good\"').shape[0]\n        return n_unsorted, n_sorted\n\n    # Initial count of unsorted clusters\n    initial_unsorted, _ = count_unsorted_clusters(file)\n    print(f\"Initial unsorted clusters: {initial_unsorted}\")\n\n    # Set a flag to indicate whether the process is complete\n    completed = False\n    # List to store the time and unsorted count for rate calculation\n    time_unsorted_data = [(0, initial_unsorted)]\n\n    # Create a figure and axes for the plot\n    plt.ion()  # Enable interactive mode\n    fig, ax = plt.subplots(\n        2, 1, figsize=(10, 7), sharex=True, gridspec_kw={\"height_ratios\": [1, 4]}\n    )\n\n    while not completed:\n        time.sleep(wait_time)  # Wait for x minutes\n\n        current_unsorted, n_sorted = count_unsorted_clusters(file)\n        current_time = (\n            time_unsorted_data[-1][0] + wait_time / 60\n        )  # Increment time by x minutes\n        time_unsorted_data.append((current_time, current_unsorted))\n\n        sorted_clusters = (\n            time_unsorted_data[0][1] - current_unsorted\n        )  # Number of clusters sorted so far\n\n        if sorted_clusters &gt; 0:\n            # Use all previous data points to calculate an average rate of sorting\n            total_time_elapsed = sum(\n                [\n                    time_unsorted_data[i + 1][0] - time_unsorted_data[i][0]\n                    for i in range(len(time_unsorted_data) - 1)\n                ]\n            )\n            total_clusters_sorted = sum(\n                [\n                    time_unsorted_data[i][1] - time_unsorted_data[i + 1][1]\n                    for i in range(len(time_unsorted_data) - 1)\n                ]\n            )\n\n            average_rate_of_sorting = (\n                total_clusters_sorted / total_time_elapsed\n            )  # Average clusters sorted per minute\n            estimated_time_remaining = (\n                current_unsorted / average_rate_of_sorting\n            )  # Estimate the time remaining\n\n            progress_text = (\n                f\"Time elapsed: {current_time} minutes\\n\"\n                f\"Current unsorted clusters: {current_unsorted}\\n\"\n                f\"Sorted clusters: {n_sorted}\\n\"\n                f\"Average rate of sorting: {average_rate_of_sorting:.2f} clusters/minute\\n\"\n                f\"Estimated time to completion: {estimated_time_remaining:.2f} minutes\"\n            )\n\n            # Check if sorting is complete\n            if current_unsorted == 0:\n                completed = True\n                progress_text += \"\\nSorting complete!\"\n        else:\n            progress_text = f\"No progress made in the last {current_time} minutes. Check if the process is working correctly.\"\n\n        # Update the plot\n        df = safe_read_csv(file)\n        df[\"group\"] = df[\"group\"].replace(np.nan, \"unsorted\")\n\n        # Clear only the plot axes (not the printed output)\n        for a in ax:\n            a.clear()\n\n        # Set plot limits\n        ax[0].set_xlim(df.sh.min(), df.sh.max())\n        ax[1].set_xlim(df.sh.min(), df.sh.max())\n\n        # Create the stripplot\n        sns.stripplot(\n            data=df[[\"depth\", \"sh\"]]\n            .value_counts()\n            .reset_index()\n            .sort_values(by=[\"sh\"]),\n            x=\"sh\",\n            y=\"depth\",\n            ax=ax[1],\n            jitter=False,\n            legend=False,\n            color=\"white\",\n            alpha=0.5,\n        )\n\n        sns.stripplot(\n            data=df.query('group==\"good\"'),\n            x=\"sh\",\n            y=\"depth\",\n            hue=hue,\n            ax=ax[1],\n            jitter=True,\n            legend=False,\n            palette=\"rainbow\",\n        )\n\n        count_df = (\n            df.query('group==\"good\"')\n            .groupby(\"sh\", observed=True)\n            .size()\n            .reset_index(name=\"counts\")\n        )\n\n        sns.barplot(data=count_df, x=\"sh\", y=\"counts\", ax=ax[0], palette=\"winter\")\n        for p in ax[0].patches:\n            ax[0].annotate(\n                f\"{int(p.get_height())}\",\n                (p.get_x() + p.get_width() / 2.0, p.get_height()),\n                ha=\"center\",\n                va=\"bottom\",\n                fontsize=8,\n                color=\"white\",\n            )\n        ax[0].set_ylabel(\"Number of \\n clusters\")\n        ax[1].set_xlabel(\"Shank\")\n        ax[1].set_ylabel(\"Depth (um)\")\n\n        sns.despine()\n        # Draw the plot\n        plt.draw()\n        plt.pause(0.01)  # Pause to allow the plot to updateg\n\n        # Display progress text below the plot\n        clear_output(wait=True)  # Clear only the previous plot and progress text\n        display(fig)  # Display the updated plot\n        print(progress_text)  # Display the progress text below the plot\n\n    # Close the interactive plot after completion\n    plt.ioff()\n    plt.show()\n</code></pre>"},{"location":"reference/neuro_py/session/","title":"neuro_py.session","text":""},{"location":"reference/neuro_py/session/#neuro_py.session.compress_repeated_epochs","title":"<code>compress_repeated_epochs(epoch_df, epoch_name=None)</code>","text":"<p>Compress repeated epochs in an epoch DataFrame. If consecutive epochs have the same name, they will be combined into a single epoch with the earliest startTime and the latest stopTime.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>A DataFrame containing epoch information. Must have columns <code>environment</code>, <code>startTime</code>, and <code>stopTime</code>.</p> required <code>epoch_name</code> <code>str</code> <p>If provided, only compress epochs with this specific name. If None, compress all consecutive epochs with the same name.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame where consecutive epochs with the same name are compressed into a single epoch.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'environment': ['sleep', 'sleep', 'wmaze', 'wmaze', 'sleep'],\n...     'startTime': [0, 100, 200, 300, 400],\n...     'stopTime': [99, 199, 299, 399, 499]\n... })\n&gt;&gt;&gt; compress_repeated_epochs(epoch_df)\n  environment  startTime  stopTime\n0       sleep          0       199\n1       wmaze        200       399\n2       sleep        400       499\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def compress_repeated_epochs(epoch_df, epoch_name=None):\n    \"\"\"\n    Compress repeated epochs in an epoch DataFrame. If consecutive epochs have the same name,\n    they will be combined into a single epoch with the earliest startTime and the latest stopTime.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        A DataFrame containing epoch information. Must have columns `environment`, `startTime`, and `stopTime`.\n    epoch_name : str, optional\n        If provided, only compress epochs with this specific name. If None, compress all consecutive epochs with the same name.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame where consecutive epochs with the same name are compressed into a single epoch.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'environment': ['sleep', 'sleep', 'wmaze', 'wmaze', 'sleep'],\n    ...     'startTime': [0, 100, 200, 300, 400],\n    ...     'stopTime': [99, 199, 299, 399, 499]\n    ... })\n    &gt;&gt;&gt; compress_repeated_epochs(epoch_df)\n      environment  startTime  stopTime\n    0       sleep          0       199\n    1       wmaze        200       399\n    2       sleep        400       499\n    \"\"\"\n    if epoch_name is None:\n        match = np.zeros([epoch_df.environment.shape[0]])\n        match[match == 0] = np.nan\n        for i, ep in enumerate(epoch_df.environment[:-1]):\n            if np.isnan(match[i]):\n                # find match in current and next epoch\n                if ep == epoch_df.environment.iloc[i + 1]:\n                    match[i : i + 2] = i\n                    # given match, see if there are more matches\n                    for match_i in np.arange(1, epoch_df.environment[:-1].shape[0]):\n                        if i + 1 + match_i == epoch_df.environment.shape[0]:\n                            break\n                        if ep == epoch_df.environment.iloc[i + 1 + match_i]:\n                            match[i : i + 1 + match_i + 1] = i\n                        else:\n                            break\n    else:\n        match = np.zeros([epoch_df.environment.shape[0]])\n        match[match == 0] = np.nan\n        for i, ep in enumerate(epoch_df.environment[:-1]):\n            if np.isnan(match[i]):\n                # find match in current and next epoch\n                if (ep == epoch_df.environment.iloc[i + 1]) &amp; (ep == epoch_name):\n                    match[i : i + 2] = i\n                    # given match, see if there are more matches\n                    for match_i in np.arange(1, epoch_df.environment[:-1].shape[0]):\n                        if i + 1 + match_i == epoch_df.environment.shape[0]:\n                            break\n                        if ep == epoch_df.environment.iloc[i + 1 + match_i]:\n                            match[i : i + 1 + match_i + 1] = i\n                        else:\n                            break\n\n    for i in range(len(match)):\n        if np.isnan(match[i]):\n            # make nans large numbers that are unlikely to be real epoch\n            match[i] = (i + 1) * 2000\n\n    # iter through each epoch indicator to get start and stop\n    results = pd.DataFrame()\n    no_nan_match = match[~np.isnan(match)]\n    for m in pd.unique(no_nan_match):\n        temp_dict = {}\n        for item in epoch_df.keys():\n            temp_dict[item] = epoch_df[match == m][item].iloc[0]\n\n        temp_dict[\"startTime\"] = epoch_df[match == m].startTime.min()\n        temp_dict[\"stopTime\"] = epoch_df[match == m].stopTime.max()\n\n        temp_df = pd.DataFrame.from_dict(temp_dict, orient=\"index\").T\n\n        results = pd.concat([results, temp_df], ignore_index=True)\n    return results\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.find_env_paradigm_pre_task_post","title":"<code>find_env_paradigm_pre_task_post(epoch_df, env='sleep', paradigm='memory')</code>","text":"<p>Find indices of epochs that match a sequence of environment and paradigm patterns, specifically looking for a pre-task-post structure.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>DataFrame containing epoch information with columns such as 'environment' and 'behavioralParadigm'.</p> required <code>env</code> <code>str</code> <p>The environment pattern to search for (default is \"sleep\").</p> <code>'sleep'</code> <code>paradigm</code> <code>str</code> <p>The behavioral paradigm pattern to search for (default is \"memory\").</p> <code>'memory'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array where <code>True</code> indicates that the epoch is part of a pre-task-post sequence (i.e., sleep-task-sleep) based on the provided environment and paradigm.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'name': ['EE.042', 'EE.045', 'EE.046', 'EE.049', 'EE.050'],\n...     'startTime': [0.0, 995.9384, 3336.3928, 5722.444, 7511.244],\n...     'stopTime': [995.9384, 3336.3928, 5722.444, 7511.244, 9387.644],\n...     'environment': ['sleep', 'tmaze', 'sleep', 'tmaze', 'sleep'],\n...     'behavioralParadigm': [np.nan, 'Spontaneous alternation task', np.nan, 'Working memory task', np.nan]\n... })\n&gt;&gt;&gt; idx = find_env_paradigm_pre_task_post(epoch_df)\n&gt;&gt;&gt; epoch_df[idx]\n      name  startTime   stopTime environment        behavioralParadigm\n2  EE.046   3336.3928  5722.444       sleep                        NaN\n3  EE.049   5722.444   7511.244      tmaze         Working memory task\n4  EE.050   7511.244   9387.644       sleep                        NaN\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_env_paradigm_pre_task_post(\n    epoch_df: pd.DataFrame, env: str = \"sleep\", paradigm: str = \"memory\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Find indices of epochs that match a sequence of environment and paradigm\n    patterns, specifically looking for a pre-task-post structure.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        DataFrame containing epoch information with columns such as 'environment' and 'behavioralParadigm'.\n    env : str, optional\n        The environment pattern to search for (default is \"sleep\").\n    paradigm : str, optional\n        The behavioral paradigm pattern to search for (default is \"memory\").\n\n    Returns\n    -------\n    np.ndarray\n        A boolean array where `True` indicates that the epoch is part of a pre-task-post sequence\n        (i.e., sleep-task-sleep) based on the provided environment and paradigm.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'name': ['EE.042', 'EE.045', 'EE.046', 'EE.049', 'EE.050'],\n    ...     'startTime': [0.0, 995.9384, 3336.3928, 5722.444, 7511.244],\n    ...     'stopTime': [995.9384, 3336.3928, 5722.444, 7511.244, 9387.644],\n    ...     'environment': ['sleep', 'tmaze', 'sleep', 'tmaze', 'sleep'],\n    ...     'behavioralParadigm': [np.nan, 'Spontaneous alternation task', np.nan, 'Working memory task', np.nan]\n    ... })\n    &gt;&gt;&gt; idx = find_env_paradigm_pre_task_post(epoch_df)\n    &gt;&gt;&gt; epoch_df[idx]\n          name  startTime   stopTime environment        behavioralParadigm\n    2  EE.046   3336.3928  5722.444       sleep                        NaN\n    3  EE.049   5722.444   7511.244      tmaze         Working memory task\n    4  EE.050   7511.244   9387.644       sleep                        NaN\n    \"\"\"\n    # compress back to back sleep epochs\n    epoch_df_ = compress_repeated_epochs(epoch_df, epoch_name=\"sleep\")\n    # make col with env and paradigm\n    epoch_df_[\"sleep_ind\"] = (\n        epoch_df_.environment + \"_\" + epoch_df_.behavioralParadigm.astype(str)\n    )\n    # locate env and paradigm of choice with this col\n    epoch_df_[\"sleep_ind\"] = epoch_df_[\"sleep_ind\"].str.contains(env + \"|\" + paradigm)\n    # the pattern we are looking for is all True\n\n    # https://stackoverflow.com/questions/48710783/pandas-find-and-index-rows-that-match-row-sequence-pattern\n    pat = np.asarray([True, True, True])\n    N = len(pat)\n    idx = (\n        epoch_df_[\"sleep_ind\"]\n        .rolling(window=N, min_periods=N)\n        .apply(lambda x: (x == pat).all())\n        .mask(lambda x: x == 0)\n        .bfill(limit=N - 1)\n        .fillna(0)\n        .astype(bool)\n    ).values\n    return idx\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.find_epoch_pattern","title":"<code>find_epoch_pattern(env, pattern)</code>","text":"<p>Finds the first occurrence of a contiguous pattern of epochs in the environment list.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>list or Series</code> <p>The environment list or pandas Series representing the epochs.</p> required <code>pattern</code> <code>list of str</code> <p>The pattern to search for in the environment list.</p> required <p>Returns:</p> Type Description <code>tuple of (np.ndarray, np.ndarray) or (None, None)</code> <p>Returns a tuple where the first element is a boolean mask indicating the positions of the found pattern, and the second element is an array of indices where the pattern occurs. If the pattern is not found, returns (None, None).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; pattern_idx,_ = find_epoch_pattern(epoch_df.environment,['sleep','linear','sleep'])\n&gt;&gt;&gt; epoch_df.loc[pattern_idx]\n    name                    startTime       stopTime        environment     behavioralParadigm      notes\n0   preSleep_210411_064951  0.0000      9544.56315  sleep       NaN                 NaN\n1   maze_210411_095201          9544.5632   11752.80635     linear      novel                   novel\n2   postSleep_210411_103522 11752.8064      23817.68955     sleep       novel                   novel\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_epoch_pattern(\n    env: Union[List[str], pd.Series], pattern: List[str]\n) -&gt; Union[Tuple[np.ndarray, np.ndarray], Tuple[None, None]]:\n    \"\"\"\n    Finds the first occurrence of a contiguous pattern of epochs in the environment list.\n\n    Parameters\n    ----------\n    env : list or pd.Series\n        The environment list or pandas Series representing the epochs.\n    pattern : list of str\n        The pattern to search for in the environment list.\n\n    Returns\n    -------\n    tuple of (np.ndarray, np.ndarray) or (None, None)\n        Returns a tuple where the first element is a boolean mask indicating the positions of the found pattern,\n        and the second element is an array of indices where the pattern occurs.\n        If the pattern is not found, returns (None, None).\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; pattern_idx,_ = find_epoch_pattern(epoch_df.environment,['sleep','linear','sleep'])\n    &gt;&gt;&gt; epoch_df.loc[pattern_idx]\n        name\t                startTime\tstopTime\tenvironment\tbehavioralParadigm\tnotes\n    0\tpreSleep_210411_064951\t0.0000\t    9544.56315\tsleep\t    NaN\t                NaN\n    1\tmaze_210411_095201\t    9544.5632\t11752.80635\tlinear\t    novel\t            novel\n    2\tpostSleep_210411_103522\t11752.8064\t23817.68955\tsleep\t    novel\t            novel\n    \"\"\"\n\n    env = list(env)\n    pattern = list(pattern)\n\n    if len(env) &lt; len(pattern):\n        return None, None\n\n    dummy = np.zeros(len(env))\n\n    for i in range(len(env) - len(pattern) + 1):\n        if pattern == env[i : i + len(pattern)]:\n            dummy[i : i + len(pattern)] = 1\n            dummy = dummy == 1\n            return dummy, np.arange(i, i + len(pattern))\n    return None, None\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.find_multitask_pre_post","title":"<code>find_multitask_pre_post(env, task_tag=None, post_sleep_flank=False, pre_sleep_common=False)</code>","text":"<p>Find the row indices for pre-task/post-task sleep epochs in the given environment from a DataFrame column.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Series</code> <p>Column from the DataFrame representing the session epochs data.</p> required <code>task_tag</code> <code>str</code> <p>A string indicating the task(s) (e.g., \"linear\", \"linear|box\") to filter for. If None, all non-sleep epochs are considered as task epochs.</p> <code>None</code> <code>post_sleep_flank</code> <code>bool</code> <p>If True, ensure that the post-task sleep epoch directly follows the task.</p> <code>False</code> <code>pre_sleep_common</code> <code>bool</code> <p>If True, use the first pre-task sleep epoch as the pre-task sleep for all tasks.</p> <code>False</code> <p>Returns:</p> Type Description <code>list of list of int, or None</code> <p>A list of indices for pre-task, task, and post-task epochs in the format [pre_task, task, post_task]. If no such sequence is found, returns None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'environment': ['sleep', 'linear', 'sleep', 'box', 'sleep']\n... })\n&gt;&gt;&gt; find_multitask_pre_post(epoch_df['environment'], task_tag='linear')\n[[0, 1, 2]]\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_multitask_pre_post(\n    env: pd.Series,\n    task_tag: Union[None, str] = None,\n    post_sleep_flank: bool = False,\n    pre_sleep_common: bool = False,\n) -&gt; Union[List[List[int]], None]:\n    \"\"\"\n    Find the row indices for pre-task/post-task sleep epochs in the given environment from a DataFrame column.\n\n    Parameters\n    ----------\n    env : pd.Series\n        Column from the DataFrame representing the session epochs data.\n    task_tag : str, optional\n        A string indicating the task(s) (e.g., \"linear\", \"linear|box\") to filter for.\n        If None, all non-sleep epochs are considered as task epochs.\n    post_sleep_flank : bool, optional\n        If True, ensure that the post-task sleep epoch directly follows the task.\n    pre_sleep_common : bool, optional\n        If True, use the first pre-task sleep epoch as the pre-task sleep for all tasks.\n\n    Returns\n    -------\n    list of list of int, or None\n        A list of indices for pre-task, task, and post-task epochs in the format [pre_task, task, post_task].\n        If no such sequence is found, returns None.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'environment': ['sleep', 'linear', 'sleep', 'box', 'sleep']\n    ... })\n    &gt;&gt;&gt; find_multitask_pre_post(epoch_df['environment'], task_tag='linear')\n    [[0, 1, 2]]\n    \"\"\"\n    # Find the row indices that contain the search string in the specified column\n    if task_tag is None:\n        task_bool = ~env.str.contains(\"sleep\", case=False)\n    else:\n        task_bool = env.str.contains(task_tag, case=False)\n    sleep_bool = env.str.contains(\"sleep\", case=False)\n\n    # find the task indices\n    task_idx = np.where(task_bool)[0]\n    # remove 0 index, task can never be first\n    task_idx = task_idx[task_idx != 0]\n    # find the sleep indices\n    sleep_idx = np.where(sleep_bool)[0]\n\n    pre_task_post = []\n    for task in task_idx:\n        temp = sleep_idx - task\n        pre_task = sleep_idx[temp &lt; 0]\n        post_task = sleep_idx[temp &gt; 0]\n\n        if len(post_task) == 0:\n            logging.warning(\"no post_task sleep for task epoch \" + str(task))\n        elif len(pre_task) == 0:\n            logging.warning(\"no pre_task sleep for task epoch \" + str(task))\n        else:\n            pre_task_post.append([pre_task[-1], task, post_task[0]])\n\n    if len(pre_task_post) == 0:\n        pre_task_post = None\n\n    # search for epochs where the last epoch is 1 more than the first epoch\n    if post_sleep_flank and pre_task_post is not None:\n        pre_task_post_ = []\n        for seq in pre_task_post:\n            if seq[-1] - seq[1] == 1:\n                pre_task_post_.append(seq)\n        pre_task_post = pre_task_post_\n\n    # make the first pre task sleep the same pre task in subsequent tasks\n    if pre_sleep_common and pre_task_post is not None:\n        pre_task_post_ = []\n        for seq in pre_task_post:\n            pre_task_post_.append([pre_task_post[0][0], seq[1], seq[2]])\n        pre_task_post = pre_task_post_\n\n    return pre_task_post\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.find_pre_task_post","title":"<code>find_pre_task_post(env, pre_post_label='sleep')</code>","text":"<p>Finds the first contiguous epochs that meet the pre/task/post pattern in the environment list.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>list or ndarray</code> <p>List or array of environment labels (e.g., 'sleep', 'wmaze', etc.).</p> required <code>pre_post_label</code> <code>str</code> <p>Label used to identify pre and post sleep epochs (default is 'sleep').</p> <code>'sleep'</code> <p>Returns:</p> Name Type Description <code>dummy</code> <code>ndarray or None</code> <p>A boolean array where the identified pre/task/post epochs are marked as True. If no pattern is found, returns None.</p> <code>indices</code> <code>list or None</code> <p>A list of indices where the pre/task/post epochs are found. If no pattern is found, returns None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = ['sleep', 'wmaze', 'sleep']\n&gt;&gt;&gt; find_pre_task_post(env)\n(array([ True,  True,  True]), [0, 1, 2])\n</code></pre> Notes <p>This function identifies a pattern where the pre-task-post epochs are of the form: - pre-sleep (pre_post_label) - task (any label other than pre_post_label) - post-sleep (pre_post_label)</p> <p>The function returns the indices of the first occurrence of such a pattern.</p> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_pre_task_post(\n    env: Union[List[str], np.ndarray], pre_post_label: str = \"sleep\"\n) -&gt; Tuple[Union[np.ndarray, None], Union[List[int], None]]:\n    \"\"\"\n    Finds the first contiguous epochs that meet the pre/task/post pattern in the environment list.\n\n    Parameters\n    ----------\n    env : list or np.ndarray\n        List or array of environment labels (e.g., 'sleep', 'wmaze', etc.).\n    pre_post_label : str, optional\n        Label used to identify pre and post sleep epochs (default is 'sleep').\n\n    Returns\n    -------\n    dummy : np.ndarray or None\n        A boolean array where the identified pre/task/post epochs are marked as True.\n        If no pattern is found, returns None.\n    indices : list or None\n        A list of indices where the pre/task/post epochs are found. If no pattern is found, returns None.\n\n    Examples\n    -------\n    &gt;&gt;&gt; env = ['sleep', 'wmaze', 'sleep']\n    &gt;&gt;&gt; find_pre_task_post(env)\n    (array([ True,  True,  True]), [0, 1, 2])\n\n    Notes\n    -----\n    This function identifies a pattern where the pre-task-post epochs are of the form:\n    - pre-sleep (pre_post_label)\n    - task (any label other than pre_post_label)\n    - post-sleep (pre_post_label)\n\n    The function returns the indices of the first occurrence of such a pattern.\n    \"\"\"\n    if len(env) &lt; 3:\n        return None, None\n    numeric_idx = (pre_post_label == env) * 1\n    dummy = np.zeros_like(numeric_idx) == 1\n    if all(numeric_idx[:3] == [1, 0, 1]):\n        dummy[:3] = True\n        return dummy, [0, 1, 2]\n    else:\n        for i in np.arange(len(numeric_idx) + 3):\n            if 3 + i &gt; len(numeric_idx):\n                return None, None\n            if all(numeric_idx[0 + i : 3 + i] == [1, 0, 1]):\n                dummy[0 + i : 3 + i] = True\n                return dummy, [0, 1, 2] + i\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.find_pre_task_post_optimize_novel","title":"<code>find_pre_task_post_optimize_novel(epoch_df, novel_indicators=[1, 'novel', '1'])</code>","text":"<p>Find pre-task-post epochs in the DataFrame, optimizing for novel epochs.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>DataFrame containing epochs information with 'environment' and 'behavioralParadigm' columns.</p> required <code>novel_indicators</code> <code>list of [int, str]</code> <p>List of indicators used to identify novel epochs in the 'behavioralParadigm' column (default is [1, \"novel\", \"1\"]).</p> <code>[1, 'novel', '1']</code> <p>Returns:</p> Type Description <code>DataFrame or None</code> <p>A DataFrame with pre-task-post epochs, or None if no such pattern is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = find_pre_task_post_optimize_novel(epoch_df)\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_pre_task_post_optimize_novel(\n    epoch_df: pd.DataFrame, novel_indicators: List[Union[int, str]] = [1, \"novel\", \"1\"]\n) -&gt; Union[pd.DataFrame, None]:\n    \"\"\"\n    Find pre-task-post epochs in the DataFrame, optimizing for novel epochs.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        DataFrame containing epochs information with 'environment' and 'behavioralParadigm' columns.\n    novel_indicators : list of [int, str], optional\n        List of indicators used to identify novel epochs in the 'behavioralParadigm' column (default is [1, \"novel\", \"1\"]).\n\n    Returns\n    -------\n    pd.DataFrame or None\n        A DataFrame with pre-task-post epochs, or None if no such pattern is found.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = find_pre_task_post_optimize_novel(epoch_df)\n    \"\"\"\n    # set sleep to nan\n    epoch_df.loc[epoch_df.environment == \"sleep\", \"behavioralParadigm\"] = np.nan\n    # Search for novel epochs\n    novel_mask = epoch_df.behavioralParadigm.isin(novel_indicators)\n    if novel_mask.any():\n        # Find the first novel epoch\n        idx = np.where(novel_mask)[0][0]\n        # Select the first novel epoch and the epochs before and after it\n        mask = np.hstack([idx - 1, idx, idx + 1])\n        # If any of the epochs are negative, skip (this means the novel epoch was the first epoch)\n        if any(mask &lt; 0):\n            pass\n        else:\n            epoch_df_temp = epoch_df.loc[mask]\n            # Find pre task post epochs in this subset\n            idx = find_pre_task_post(epoch_df_temp.environment)\n            # If no pre task post epochs are found, skip\n            if idx is None or idx[0] is None:\n                pass\n            else:\n                epoch_df = epoch_df_temp.reset_index(drop=True)\n    # Find the first pre task post epoch in epoch_df, if the df was modified that will be used\n    idx, _ = find_pre_task_post(epoch_df.environment)\n    if idx is None:\n        return None\n    epoch_df = epoch_df.loc[idx].reset_index(drop=True)\n    return epoch_df\n</code></pre>"},{"location":"reference/neuro_py/session/#neuro_py.session.get_experience_level","title":"<code>get_experience_level(behavioralParadigm)</code>","text":"<p>Extract the experience level from the behavioralParadigm column.</p> <p>The experience level is the number of times the animal has run the task, inferred from the behavioralParadigm column.</p> <p>Parameters:</p> Name Type Description Default <code>behavioralParadigm</code> <code>Series</code> <p>A single entry or value from the behavioralParadigm column of an epoch.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The experience level as an integer. Returns NaN if experience cannot be determined.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; experience = get_experience_level(current_epoch_df.iloc[1].behavioralParadigm)\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def get_experience_level(behavioralParadigm: pd.Series) -&gt; int:\n    \"\"\"\n    Extract the experience level from the behavioralParadigm column.\n\n    The experience level is the number of times the animal has run the task,\n    inferred from the behavioralParadigm column.\n\n    Parameters\n    ----------\n    behavioralParadigm : pd.Series\n        A single entry or value from the behavioralParadigm column of an epoch.\n\n    Returns\n    -------\n    int\n        The experience level as an integer. Returns NaN if experience cannot be determined.\n\n    Examples\n    --------\n    &gt;&gt;&gt; experience = get_experience_level(current_epoch_df.iloc[1].behavioralParadigm)\n    \"\"\"\n    if behavioralParadigm == \"novel\":\n        experience = 1\n    else:\n        try:\n            # extract first number from string\n            experience = int(re.findall(r\"\\d+\", behavioralParadigm)[0])\n        except Exception:\n            try:\n                # extract experience level from behavioralParadigm column if it is a number\n                experience = int(behavioralParadigm)\n            except Exception:\n                experience = np.nan\n    return experience\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/","title":"neuro_py.session.locate_epochs","text":""},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.compress_repeated_epochs","title":"<code>compress_repeated_epochs(epoch_df, epoch_name=None)</code>","text":"<p>Compress repeated epochs in an epoch DataFrame. If consecutive epochs have the same name, they will be combined into a single epoch with the earliest startTime and the latest stopTime.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>A DataFrame containing epoch information. Must have columns <code>environment</code>, <code>startTime</code>, and <code>stopTime</code>.</p> required <code>epoch_name</code> <code>str</code> <p>If provided, only compress epochs with this specific name. If None, compress all consecutive epochs with the same name.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame where consecutive epochs with the same name are compressed into a single epoch.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'environment': ['sleep', 'sleep', 'wmaze', 'wmaze', 'sleep'],\n...     'startTime': [0, 100, 200, 300, 400],\n...     'stopTime': [99, 199, 299, 399, 499]\n... })\n&gt;&gt;&gt; compress_repeated_epochs(epoch_df)\n  environment  startTime  stopTime\n0       sleep          0       199\n1       wmaze        200       399\n2       sleep        400       499\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def compress_repeated_epochs(epoch_df, epoch_name=None):\n    \"\"\"\n    Compress repeated epochs in an epoch DataFrame. If consecutive epochs have the same name,\n    they will be combined into a single epoch with the earliest startTime and the latest stopTime.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        A DataFrame containing epoch information. Must have columns `environment`, `startTime`, and `stopTime`.\n    epoch_name : str, optional\n        If provided, only compress epochs with this specific name. If None, compress all consecutive epochs with the same name.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame where consecutive epochs with the same name are compressed into a single epoch.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'environment': ['sleep', 'sleep', 'wmaze', 'wmaze', 'sleep'],\n    ...     'startTime': [0, 100, 200, 300, 400],\n    ...     'stopTime': [99, 199, 299, 399, 499]\n    ... })\n    &gt;&gt;&gt; compress_repeated_epochs(epoch_df)\n      environment  startTime  stopTime\n    0       sleep          0       199\n    1       wmaze        200       399\n    2       sleep        400       499\n    \"\"\"\n    if epoch_name is None:\n        match = np.zeros([epoch_df.environment.shape[0]])\n        match[match == 0] = np.nan\n        for i, ep in enumerate(epoch_df.environment[:-1]):\n            if np.isnan(match[i]):\n                # find match in current and next epoch\n                if ep == epoch_df.environment.iloc[i + 1]:\n                    match[i : i + 2] = i\n                    # given match, see if there are more matches\n                    for match_i in np.arange(1, epoch_df.environment[:-1].shape[0]):\n                        if i + 1 + match_i == epoch_df.environment.shape[0]:\n                            break\n                        if ep == epoch_df.environment.iloc[i + 1 + match_i]:\n                            match[i : i + 1 + match_i + 1] = i\n                        else:\n                            break\n    else:\n        match = np.zeros([epoch_df.environment.shape[0]])\n        match[match == 0] = np.nan\n        for i, ep in enumerate(epoch_df.environment[:-1]):\n            if np.isnan(match[i]):\n                # find match in current and next epoch\n                if (ep == epoch_df.environment.iloc[i + 1]) &amp; (ep == epoch_name):\n                    match[i : i + 2] = i\n                    # given match, see if there are more matches\n                    for match_i in np.arange(1, epoch_df.environment[:-1].shape[0]):\n                        if i + 1 + match_i == epoch_df.environment.shape[0]:\n                            break\n                        if ep == epoch_df.environment.iloc[i + 1 + match_i]:\n                            match[i : i + 1 + match_i + 1] = i\n                        else:\n                            break\n\n    for i in range(len(match)):\n        if np.isnan(match[i]):\n            # make nans large numbers that are unlikely to be real epoch\n            match[i] = (i + 1) * 2000\n\n    # iter through each epoch indicator to get start and stop\n    results = pd.DataFrame()\n    no_nan_match = match[~np.isnan(match)]\n    for m in pd.unique(no_nan_match):\n        temp_dict = {}\n        for item in epoch_df.keys():\n            temp_dict[item] = epoch_df[match == m][item].iloc[0]\n\n        temp_dict[\"startTime\"] = epoch_df[match == m].startTime.min()\n        temp_dict[\"stopTime\"] = epoch_df[match == m].stopTime.max()\n\n        temp_df = pd.DataFrame.from_dict(temp_dict, orient=\"index\").T\n\n        results = pd.concat([results, temp_df], ignore_index=True)\n    return results\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.find_env_paradigm_pre_task_post","title":"<code>find_env_paradigm_pre_task_post(epoch_df, env='sleep', paradigm='memory')</code>","text":"<p>Find indices of epochs that match a sequence of environment and paradigm patterns, specifically looking for a pre-task-post structure.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>DataFrame containing epoch information with columns such as 'environment' and 'behavioralParadigm'.</p> required <code>env</code> <code>str</code> <p>The environment pattern to search for (default is \"sleep\").</p> <code>'sleep'</code> <code>paradigm</code> <code>str</code> <p>The behavioral paradigm pattern to search for (default is \"memory\").</p> <code>'memory'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array where <code>True</code> indicates that the epoch is part of a pre-task-post sequence (i.e., sleep-task-sleep) based on the provided environment and paradigm.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'name': ['EE.042', 'EE.045', 'EE.046', 'EE.049', 'EE.050'],\n...     'startTime': [0.0, 995.9384, 3336.3928, 5722.444, 7511.244],\n...     'stopTime': [995.9384, 3336.3928, 5722.444, 7511.244, 9387.644],\n...     'environment': ['sleep', 'tmaze', 'sleep', 'tmaze', 'sleep'],\n...     'behavioralParadigm': [np.nan, 'Spontaneous alternation task', np.nan, 'Working memory task', np.nan]\n... })\n&gt;&gt;&gt; idx = find_env_paradigm_pre_task_post(epoch_df)\n&gt;&gt;&gt; epoch_df[idx]\n      name  startTime   stopTime environment        behavioralParadigm\n2  EE.046   3336.3928  5722.444       sleep                        NaN\n3  EE.049   5722.444   7511.244      tmaze         Working memory task\n4  EE.050   7511.244   9387.644       sleep                        NaN\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_env_paradigm_pre_task_post(\n    epoch_df: pd.DataFrame, env: str = \"sleep\", paradigm: str = \"memory\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Find indices of epochs that match a sequence of environment and paradigm\n    patterns, specifically looking for a pre-task-post structure.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        DataFrame containing epoch information with columns such as 'environment' and 'behavioralParadigm'.\n    env : str, optional\n        The environment pattern to search for (default is \"sleep\").\n    paradigm : str, optional\n        The behavioral paradigm pattern to search for (default is \"memory\").\n\n    Returns\n    -------\n    np.ndarray\n        A boolean array where `True` indicates that the epoch is part of a pre-task-post sequence\n        (i.e., sleep-task-sleep) based on the provided environment and paradigm.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'name': ['EE.042', 'EE.045', 'EE.046', 'EE.049', 'EE.050'],\n    ...     'startTime': [0.0, 995.9384, 3336.3928, 5722.444, 7511.244],\n    ...     'stopTime': [995.9384, 3336.3928, 5722.444, 7511.244, 9387.644],\n    ...     'environment': ['sleep', 'tmaze', 'sleep', 'tmaze', 'sleep'],\n    ...     'behavioralParadigm': [np.nan, 'Spontaneous alternation task', np.nan, 'Working memory task', np.nan]\n    ... })\n    &gt;&gt;&gt; idx = find_env_paradigm_pre_task_post(epoch_df)\n    &gt;&gt;&gt; epoch_df[idx]\n          name  startTime   stopTime environment        behavioralParadigm\n    2  EE.046   3336.3928  5722.444       sleep                        NaN\n    3  EE.049   5722.444   7511.244      tmaze         Working memory task\n    4  EE.050   7511.244   9387.644       sleep                        NaN\n    \"\"\"\n    # compress back to back sleep epochs\n    epoch_df_ = compress_repeated_epochs(epoch_df, epoch_name=\"sleep\")\n    # make col with env and paradigm\n    epoch_df_[\"sleep_ind\"] = (\n        epoch_df_.environment + \"_\" + epoch_df_.behavioralParadigm.astype(str)\n    )\n    # locate env and paradigm of choice with this col\n    epoch_df_[\"sleep_ind\"] = epoch_df_[\"sleep_ind\"].str.contains(env + \"|\" + paradigm)\n    # the pattern we are looking for is all True\n\n    # https://stackoverflow.com/questions/48710783/pandas-find-and-index-rows-that-match-row-sequence-pattern\n    pat = np.asarray([True, True, True])\n    N = len(pat)\n    idx = (\n        epoch_df_[\"sleep_ind\"]\n        .rolling(window=N, min_periods=N)\n        .apply(lambda x: (x == pat).all())\n        .mask(lambda x: x == 0)\n        .bfill(limit=N - 1)\n        .fillna(0)\n        .astype(bool)\n    ).values\n    return idx\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.find_epoch_pattern","title":"<code>find_epoch_pattern(env, pattern)</code>","text":"<p>Finds the first occurrence of a contiguous pattern of epochs in the environment list.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>list or Series</code> <p>The environment list or pandas Series representing the epochs.</p> required <code>pattern</code> <code>list of str</code> <p>The pattern to search for in the environment list.</p> required <p>Returns:</p> Type Description <code>tuple of (np.ndarray, np.ndarray) or (None, None)</code> <p>Returns a tuple where the first element is a boolean mask indicating the positions of the found pattern, and the second element is an array of indices where the pattern occurs. If the pattern is not found, returns (None, None).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; pattern_idx,_ = find_epoch_pattern(epoch_df.environment,['sleep','linear','sleep'])\n&gt;&gt;&gt; epoch_df.loc[pattern_idx]\n    name                    startTime       stopTime        environment     behavioralParadigm      notes\n0   preSleep_210411_064951  0.0000      9544.56315  sleep       NaN                 NaN\n1   maze_210411_095201          9544.5632   11752.80635     linear      novel                   novel\n2   postSleep_210411_103522 11752.8064      23817.68955     sleep       novel                   novel\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_epoch_pattern(\n    env: Union[List[str], pd.Series], pattern: List[str]\n) -&gt; Union[Tuple[np.ndarray, np.ndarray], Tuple[None, None]]:\n    \"\"\"\n    Finds the first occurrence of a contiguous pattern of epochs in the environment list.\n\n    Parameters\n    ----------\n    env : list or pd.Series\n        The environment list or pandas Series representing the epochs.\n    pattern : list of str\n        The pattern to search for in the environment list.\n\n    Returns\n    -------\n    tuple of (np.ndarray, np.ndarray) or (None, None)\n        Returns a tuple where the first element is a boolean mask indicating the positions of the found pattern,\n        and the second element is an array of indices where the pattern occurs.\n        If the pattern is not found, returns (None, None).\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; pattern_idx,_ = find_epoch_pattern(epoch_df.environment,['sleep','linear','sleep'])\n    &gt;&gt;&gt; epoch_df.loc[pattern_idx]\n        name\t                startTime\tstopTime\tenvironment\tbehavioralParadigm\tnotes\n    0\tpreSleep_210411_064951\t0.0000\t    9544.56315\tsleep\t    NaN\t                NaN\n    1\tmaze_210411_095201\t    9544.5632\t11752.80635\tlinear\t    novel\t            novel\n    2\tpostSleep_210411_103522\t11752.8064\t23817.68955\tsleep\t    novel\t            novel\n    \"\"\"\n\n    env = list(env)\n    pattern = list(pattern)\n\n    if len(env) &lt; len(pattern):\n        return None, None\n\n    dummy = np.zeros(len(env))\n\n    for i in range(len(env) - len(pattern) + 1):\n        if pattern == env[i : i + len(pattern)]:\n            dummy[i : i + len(pattern)] = 1\n            dummy = dummy == 1\n            return dummy, np.arange(i, i + len(pattern))\n    return None, None\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.find_multitask_pre_post","title":"<code>find_multitask_pre_post(env, task_tag=None, post_sleep_flank=False, pre_sleep_common=False)</code>","text":"<p>Find the row indices for pre-task/post-task sleep epochs in the given environment from a DataFrame column.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Series</code> <p>Column from the DataFrame representing the session epochs data.</p> required <code>task_tag</code> <code>str</code> <p>A string indicating the task(s) (e.g., \"linear\", \"linear|box\") to filter for. If None, all non-sleep epochs are considered as task epochs.</p> <code>None</code> <code>post_sleep_flank</code> <code>bool</code> <p>If True, ensure that the post-task sleep epoch directly follows the task.</p> <code>False</code> <code>pre_sleep_common</code> <code>bool</code> <p>If True, use the first pre-task sleep epoch as the pre-task sleep for all tasks.</p> <code>False</code> <p>Returns:</p> Type Description <code>list of list of int, or None</code> <p>A list of indices for pre-task, task, and post-task epochs in the format [pre_task, task, post_task]. If no such sequence is found, returns None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = pd.DataFrame({\n...     'environment': ['sleep', 'linear', 'sleep', 'box', 'sleep']\n... })\n&gt;&gt;&gt; find_multitask_pre_post(epoch_df['environment'], task_tag='linear')\n[[0, 1, 2]]\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_multitask_pre_post(\n    env: pd.Series,\n    task_tag: Union[None, str] = None,\n    post_sleep_flank: bool = False,\n    pre_sleep_common: bool = False,\n) -&gt; Union[List[List[int]], None]:\n    \"\"\"\n    Find the row indices for pre-task/post-task sleep epochs in the given environment from a DataFrame column.\n\n    Parameters\n    ----------\n    env : pd.Series\n        Column from the DataFrame representing the session epochs data.\n    task_tag : str, optional\n        A string indicating the task(s) (e.g., \"linear\", \"linear|box\") to filter for.\n        If None, all non-sleep epochs are considered as task epochs.\n    post_sleep_flank : bool, optional\n        If True, ensure that the post-task sleep epoch directly follows the task.\n    pre_sleep_common : bool, optional\n        If True, use the first pre-task sleep epoch as the pre-task sleep for all tasks.\n\n    Returns\n    -------\n    list of list of int, or None\n        A list of indices for pre-task, task, and post-task epochs in the format [pre_task, task, post_task].\n        If no such sequence is found, returns None.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = pd.DataFrame({\n    ...     'environment': ['sleep', 'linear', 'sleep', 'box', 'sleep']\n    ... })\n    &gt;&gt;&gt; find_multitask_pre_post(epoch_df['environment'], task_tag='linear')\n    [[0, 1, 2]]\n    \"\"\"\n    # Find the row indices that contain the search string in the specified column\n    if task_tag is None:\n        task_bool = ~env.str.contains(\"sleep\", case=False)\n    else:\n        task_bool = env.str.contains(task_tag, case=False)\n    sleep_bool = env.str.contains(\"sleep\", case=False)\n\n    # find the task indices\n    task_idx = np.where(task_bool)[0]\n    # remove 0 index, task can never be first\n    task_idx = task_idx[task_idx != 0]\n    # find the sleep indices\n    sleep_idx = np.where(sleep_bool)[0]\n\n    pre_task_post = []\n    for task in task_idx:\n        temp = sleep_idx - task\n        pre_task = sleep_idx[temp &lt; 0]\n        post_task = sleep_idx[temp &gt; 0]\n\n        if len(post_task) == 0:\n            logging.warning(\"no post_task sleep for task epoch \" + str(task))\n        elif len(pre_task) == 0:\n            logging.warning(\"no pre_task sleep for task epoch \" + str(task))\n        else:\n            pre_task_post.append([pre_task[-1], task, post_task[0]])\n\n    if len(pre_task_post) == 0:\n        pre_task_post = None\n\n    # search for epochs where the last epoch is 1 more than the first epoch\n    if post_sleep_flank and pre_task_post is not None:\n        pre_task_post_ = []\n        for seq in pre_task_post:\n            if seq[-1] - seq[1] == 1:\n                pre_task_post_.append(seq)\n        pre_task_post = pre_task_post_\n\n    # make the first pre task sleep the same pre task in subsequent tasks\n    if pre_sleep_common and pre_task_post is not None:\n        pre_task_post_ = []\n        for seq in pre_task_post:\n            pre_task_post_.append([pre_task_post[0][0], seq[1], seq[2]])\n        pre_task_post = pre_task_post_\n\n    return pre_task_post\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.find_pre_task_post","title":"<code>find_pre_task_post(env, pre_post_label='sleep')</code>","text":"<p>Finds the first contiguous epochs that meet the pre/task/post pattern in the environment list.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>list or ndarray</code> <p>List or array of environment labels (e.g., 'sleep', 'wmaze', etc.).</p> required <code>pre_post_label</code> <code>str</code> <p>Label used to identify pre and post sleep epochs (default is 'sleep').</p> <code>'sleep'</code> <p>Returns:</p> Name Type Description <code>dummy</code> <code>ndarray or None</code> <p>A boolean array where the identified pre/task/post epochs are marked as True. If no pattern is found, returns None.</p> <code>indices</code> <code>list or None</code> <p>A list of indices where the pre/task/post epochs are found. If no pattern is found, returns None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; env = ['sleep', 'wmaze', 'sleep']\n&gt;&gt;&gt; find_pre_task_post(env)\n(array([ True,  True,  True]), [0, 1, 2])\n</code></pre> Notes <p>This function identifies a pattern where the pre-task-post epochs are of the form: - pre-sleep (pre_post_label) - task (any label other than pre_post_label) - post-sleep (pre_post_label)</p> <p>The function returns the indices of the first occurrence of such a pattern.</p> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_pre_task_post(\n    env: Union[List[str], np.ndarray], pre_post_label: str = \"sleep\"\n) -&gt; Tuple[Union[np.ndarray, None], Union[List[int], None]]:\n    \"\"\"\n    Finds the first contiguous epochs that meet the pre/task/post pattern in the environment list.\n\n    Parameters\n    ----------\n    env : list or np.ndarray\n        List or array of environment labels (e.g., 'sleep', 'wmaze', etc.).\n    pre_post_label : str, optional\n        Label used to identify pre and post sleep epochs (default is 'sleep').\n\n    Returns\n    -------\n    dummy : np.ndarray or None\n        A boolean array where the identified pre/task/post epochs are marked as True.\n        If no pattern is found, returns None.\n    indices : list or None\n        A list of indices where the pre/task/post epochs are found. If no pattern is found, returns None.\n\n    Examples\n    -------\n    &gt;&gt;&gt; env = ['sleep', 'wmaze', 'sleep']\n    &gt;&gt;&gt; find_pre_task_post(env)\n    (array([ True,  True,  True]), [0, 1, 2])\n\n    Notes\n    -----\n    This function identifies a pattern where the pre-task-post epochs are of the form:\n    - pre-sleep (pre_post_label)\n    - task (any label other than pre_post_label)\n    - post-sleep (pre_post_label)\n\n    The function returns the indices of the first occurrence of such a pattern.\n    \"\"\"\n    if len(env) &lt; 3:\n        return None, None\n    numeric_idx = (pre_post_label == env) * 1\n    dummy = np.zeros_like(numeric_idx) == 1\n    if all(numeric_idx[:3] == [1, 0, 1]):\n        dummy[:3] = True\n        return dummy, [0, 1, 2]\n    else:\n        for i in np.arange(len(numeric_idx) + 3):\n            if 3 + i &gt; len(numeric_idx):\n                return None, None\n            if all(numeric_idx[0 + i : 3 + i] == [1, 0, 1]):\n                dummy[0 + i : 3 + i] = True\n                return dummy, [0, 1, 2] + i\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.find_pre_task_post_optimize_novel","title":"<code>find_pre_task_post_optimize_novel(epoch_df, novel_indicators=[1, 'novel', '1'])</code>","text":"<p>Find pre-task-post epochs in the DataFrame, optimizing for novel epochs.</p> <p>Parameters:</p> Name Type Description Default <code>epoch_df</code> <code>DataFrame</code> <p>DataFrame containing epochs information with 'environment' and 'behavioralParadigm' columns.</p> required <code>novel_indicators</code> <code>list of [int, str]</code> <p>List of indicators used to identify novel epochs in the 'behavioralParadigm' column (default is [1, \"novel\", \"1\"]).</p> <code>[1, 'novel', '1']</code> <p>Returns:</p> Type Description <code>DataFrame or None</code> <p>A DataFrame with pre-task-post epochs, or None if no such pattern is found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n&gt;&gt;&gt; epoch_df = find_pre_task_post_optimize_novel(epoch_df)\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def find_pre_task_post_optimize_novel(\n    epoch_df: pd.DataFrame, novel_indicators: List[Union[int, str]] = [1, \"novel\", \"1\"]\n) -&gt; Union[pd.DataFrame, None]:\n    \"\"\"\n    Find pre-task-post epochs in the DataFrame, optimizing for novel epochs.\n\n    Parameters\n    ----------\n    epoch_df : pd.DataFrame\n        DataFrame containing epochs information with 'environment' and 'behavioralParadigm' columns.\n    novel_indicators : list of [int, str], optional\n        List of indicators used to identify novel epochs in the 'behavioralParadigm' column (default is [1, \"novel\", \"1\"]).\n\n    Returns\n    -------\n    pd.DataFrame or None\n        A DataFrame with pre-task-post epochs, or None if no such pattern is found.\n\n    Examples\n    -------\n    &gt;&gt;&gt; epoch_df = loading.load_epoch(basepath)\n    &gt;&gt;&gt; epoch_df = find_pre_task_post_optimize_novel(epoch_df)\n    \"\"\"\n    # set sleep to nan\n    epoch_df.loc[epoch_df.environment == \"sleep\", \"behavioralParadigm\"] = np.nan\n    # Search for novel epochs\n    novel_mask = epoch_df.behavioralParadigm.isin(novel_indicators)\n    if novel_mask.any():\n        # Find the first novel epoch\n        idx = np.where(novel_mask)[0][0]\n        # Select the first novel epoch and the epochs before and after it\n        mask = np.hstack([idx - 1, idx, idx + 1])\n        # If any of the epochs are negative, skip (this means the novel epoch was the first epoch)\n        if any(mask &lt; 0):\n            pass\n        else:\n            epoch_df_temp = epoch_df.loc[mask]\n            # Find pre task post epochs in this subset\n            idx = find_pre_task_post(epoch_df_temp.environment)\n            # If no pre task post epochs are found, skip\n            if idx is None or idx[0] is None:\n                pass\n            else:\n                epoch_df = epoch_df_temp.reset_index(drop=True)\n    # Find the first pre task post epoch in epoch_df, if the df was modified that will be used\n    idx, _ = find_pre_task_post(epoch_df.environment)\n    if idx is None:\n        return None\n    epoch_df = epoch_df.loc[idx].reset_index(drop=True)\n    return epoch_df\n</code></pre>"},{"location":"reference/neuro_py/session/locate_epochs/#neuro_py.session.locate_epochs.get_experience_level","title":"<code>get_experience_level(behavioralParadigm)</code>","text":"<p>Extract the experience level from the behavioralParadigm column.</p> <p>The experience level is the number of times the animal has run the task, inferred from the behavioralParadigm column.</p> <p>Parameters:</p> Name Type Description Default <code>behavioralParadigm</code> <code>Series</code> <p>A single entry or value from the behavioralParadigm column of an epoch.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The experience level as an integer. Returns NaN if experience cannot be determined.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; experience = get_experience_level(current_epoch_df.iloc[1].behavioralParadigm)\n</code></pre> Source code in <code>neuro_py/session/locate_epochs.py</code> <pre><code>def get_experience_level(behavioralParadigm: pd.Series) -&gt; int:\n    \"\"\"\n    Extract the experience level from the behavioralParadigm column.\n\n    The experience level is the number of times the animal has run the task,\n    inferred from the behavioralParadigm column.\n\n    Parameters\n    ----------\n    behavioralParadigm : pd.Series\n        A single entry or value from the behavioralParadigm column of an epoch.\n\n    Returns\n    -------\n    int\n        The experience level as an integer. Returns NaN if experience cannot be determined.\n\n    Examples\n    --------\n    &gt;&gt;&gt; experience = get_experience_level(current_epoch_df.iloc[1].behavioralParadigm)\n    \"\"\"\n    if behavioralParadigm == \"novel\":\n        experience = 1\n    else:\n        try:\n            # extract first number from string\n            experience = int(re.findall(r\"\\d+\", behavioralParadigm)[0])\n        except Exception:\n            try:\n                # extract experience level from behavioralParadigm column if it is a number\n                experience = int(behavioralParadigm)\n            except Exception:\n                experience = np.nan\n    return experience\n</code></pre>"},{"location":"reference/neuro_py/spikes/","title":"neuro_py.spikes","text":""},{"location":"reference/neuro_py/spikes/#neuro_py.spikes.BurstIndex_Royer_2012","title":"<code>BurstIndex_Royer_2012(autocorrs)</code>","text":"<p>Calculate the burst index from Royer et al. (2012). The burst index ranges from -1 to 1, where: -1 indicates non-bursty behavior, and 1 indicates bursty behavior.</p> <p>Parameters:</p> Name Type Description Default <code>autocorrs</code> <code>DataFrame</code> <p>Autocorrelograms of spike trains, with time (in seconds) as index and correlation values as columns.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of burst indices for each autocorrelogram column.</p> Notes <p>The burst index is calculated as:     burst_idx = (peak - baseline) / max(peak, baseline)</p> <ul> <li>Peak is calculated as the maximum of the autocorrelogram between 2-9 ms.</li> <li>Baseline is calculated as the mean of the autocorrelogram between 40-50 ms.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; burst_idx = BurstIndex_Royer_2012(autocorr_df)\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def BurstIndex_Royer_2012(autocorrs: pd.DataFrame) -&gt; list:\n    \"\"\"\n    Calculate the burst index from Royer et al. (2012).\n    The burst index ranges from -1 to 1, where:\n    -1 indicates non-bursty behavior, and 1 indicates bursty behavior.\n\n    Parameters\n    ----------\n    autocorrs : pd.DataFrame\n        Autocorrelograms of spike trains, with time (in seconds) as index and\n        correlation values as columns.\n\n    Returns\n    -------\n    list\n        List of burst indices for each autocorrelogram column.\n\n    Notes\n    -----\n    The burst index is calculated as:\n        burst_idx = (peak - baseline) / max(peak, baseline)\n\n    - Peak is calculated as the maximum of the autocorrelogram between 2-9 ms.\n    - Baseline is calculated as the mean of the autocorrelogram between 40-50 ms.\n\n    Examples\n    -------\n    &gt;&gt;&gt; burst_idx = BurstIndex_Royer_2012(autocorr_df)\n    \"\"\"\n    # peak range 2 - 9 ms\n    peak = autocorrs.loc[0.002:0.009].max()\n    # baseline idx 40 - 50 ms\n    baseline = autocorrs.loc[0.04:0.05].mean()\n\n    burst_idx = []\n    for p, b in zip(peak, baseline):\n        if (p is None) | (b is None):\n            burst_idx.append(np.nan)\n            continue\n        if p &gt; b:\n            burst_idx.append((p - b) / p)\n        elif p &lt; b:\n            burst_idx.append((p - b) / b)\n        else:\n            burst_idx.append(np.nan)\n    return burst_idx\n</code></pre>"},{"location":"reference/neuro_py/spikes/#neuro_py.spikes.get_spindices","title":"<code>get_spindices(data)</code>","text":"<p>Spike timestamps and IDs from each spike train in a time-sorted DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Spike times for each spike train, where each element is an array of spike times for a neuron.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Sorted spike times and the corresponding spikes' neuron IDs</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spike_trains = [np.array([0.1, 0.2, 0.4]), np.array([0.15, 0.35])]\n&gt;&gt;&gt; spikes = get_spindices(spike_trains)\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def get_spindices(data: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"\n    Spike timestamps and IDs from each spike train in a time-sorted DataFrame.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Spike times for each spike train, where each element is an array of\n        spike times for a neuron.\n\n    Returns\n    -------\n    pd.DataFrame\n        Sorted spike times and the corresponding spikes' neuron IDs\n\n    Examples\n    -------\n    &gt;&gt;&gt; spike_trains = [np.array([0.1, 0.2, 0.4]), np.array([0.15, 0.35])]\n    &gt;&gt;&gt; spikes = get_spindices(spike_trains)\n    \"\"\"\n    spikes_id = np.repeat(np.arange(len(data)), [len(spk) for spk in data])\n\n    spikes = pd.DataFrame({\"spike_times\": np.concatenate(data), \"spike_id\": spikes_id})\n    spikes.sort_values(\"spike_times\", inplace=True)\n    return spikes\n</code></pre>"},{"location":"reference/neuro_py/spikes/#neuro_py.spikes.select_burst_spikes","title":"<code>select_burst_spikes(spikes, mode='bursts', isiBursts=0.006, isiSpikes=0.02)</code>","text":"<p>Discriminate bursts versus single spikes based on inter-spike intervals.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>ndarray</code> <p>Array of spike times.</p> required <code>mode</code> <code>str</code> <p>Either 'bursts' (default) or 'single'.</p> <code>'bursts'</code> <code>isiBursts</code> <code>float</code> <p>Maximum inter-spike interval for bursts (default = 0.006 seconds).</p> <code>0.006</code> <code>isiSpikes</code> <code>float</code> <p>Minimum inter-spike interval for single spikes (default = 0.020 seconds).</p> <code>0.02</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array indicating for each spike whether it matches the criterion.</p> Notes <p>Adapted from: http://fmatoolbox.sourceforge.net/Contents/FMAToolbox/Analyses/SelectSpikes.html</p> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def select_burst_spikes(\n    spikes: np.ndarray,\n    mode: str = \"bursts\",\n    isiBursts: float = 0.006,\n    isiSpikes: float = 0.020,\n) -&gt; np.ndarray:\n    \"\"\"\n    Discriminate bursts versus single spikes based on inter-spike intervals.\n\n    Parameters\n    ----------\n    spikes : np.ndarray\n        Array of spike times.\n    mode : str, optional\n        Either 'bursts' (default) or 'single'.\n    isiBursts : float, optional\n        Maximum inter-spike interval for bursts (default = 0.006 seconds).\n    isiSpikes : float, optional\n        Minimum inter-spike interval for single spikes (default = 0.020 seconds).\n\n    Returns\n    -------\n    np.ndarray\n        A boolean array indicating for each spike whether it matches the criterion.\n\n    Notes\n    -----\n    Adapted from: http://fmatoolbox.sourceforge.net/Contents/FMAToolbox/Analyses/SelectSpikes.html\n    \"\"\"\n\n    dt = np.diff(spikes)\n\n    if mode == \"bursts\":\n        b = dt &lt; isiBursts\n        # either next or previous isi &lt; threshold\n        selected = np.insert(b, 0, False, axis=0) | np.append(b, False)\n    else:\n        s = dt &gt; isiSpikes\n        # either next or previous isi &gt; threshold\n        selected = np.insert(s, 0, False, axis=0) &amp; np.append(s, False)\n\n    return selected\n</code></pre>"},{"location":"reference/neuro_py/spikes/#neuro_py.spikes.spindices_to_ndarray","title":"<code>spindices_to_ndarray(spikes, spike_id=None)</code>","text":"<p>Convert spike times and spike IDs from a DataFrame into a list of arrays, where each array contains the spike times for a given spike train.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>DataFrame</code> <p>DataFrame containing 'spike_times' and 'spike_id' columns, sorted by 'spike_times'.</p> required <code>spike_id</code> <code>list or ndarray</code> <p>List or array of spike IDs to search for in the DataFrame. If None, all spike IDs are used.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>A list of arrays, each containing the spike times for a corresponding spike train.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spike_trains = spindices_to_ndarray(spikes_df, spike_id=[0, 1, 2])\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def spindices_to_ndarray(\n    spikes: pd.DataFrame, spike_id: Union[List[int], np.ndarray, None] = None\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Convert spike times and spike IDs from a DataFrame into a list of arrays,\n    where each array contains the spike times for a given spike train.\n\n    Parameters\n    ----------\n    spikes : pd.DataFrame\n        DataFrame containing 'spike_times' and 'spike_id' columns, sorted by\n        'spike_times'.\n    spike_id : list or np.ndarray, optional\n        List or array of spike IDs to search for in the DataFrame. If None, all\n        spike IDs are used.\n\n    Returns\n    -------\n    List[np.ndarray]\n        A list of arrays, each containing the spike times for a corresponding\n        spike train.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spike_trains = spindices_to_ndarray(spikes_df, spike_id=[0, 1, 2])\n    \"\"\"\n    if spike_id is None:\n        spike_id = spikes.spike_id.unique()\n    data = [spikes[spikes.spike_id == spk_i].spike_times.values for spk_i in spike_id]\n    return data\n</code></pre>"},{"location":"reference/neuro_py/spikes/spike_tools/","title":"neuro_py.spikes.spike_tools","text":""},{"location":"reference/neuro_py/spikes/spike_tools/#neuro_py.spikes.spike_tools.BurstIndex_Royer_2012","title":"<code>BurstIndex_Royer_2012(autocorrs)</code>","text":"<p>Calculate the burst index from Royer et al. (2012). The burst index ranges from -1 to 1, where: -1 indicates non-bursty behavior, and 1 indicates bursty behavior.</p> <p>Parameters:</p> Name Type Description Default <code>autocorrs</code> <code>DataFrame</code> <p>Autocorrelograms of spike trains, with time (in seconds) as index and correlation values as columns.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of burst indices for each autocorrelogram column.</p> Notes <p>The burst index is calculated as:     burst_idx = (peak - baseline) / max(peak, baseline)</p> <ul> <li>Peak is calculated as the maximum of the autocorrelogram between 2-9 ms.</li> <li>Baseline is calculated as the mean of the autocorrelogram between 40-50 ms.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; burst_idx = BurstIndex_Royer_2012(autocorr_df)\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def BurstIndex_Royer_2012(autocorrs: pd.DataFrame) -&gt; list:\n    \"\"\"\n    Calculate the burst index from Royer et al. (2012).\n    The burst index ranges from -1 to 1, where:\n    -1 indicates non-bursty behavior, and 1 indicates bursty behavior.\n\n    Parameters\n    ----------\n    autocorrs : pd.DataFrame\n        Autocorrelograms of spike trains, with time (in seconds) as index and\n        correlation values as columns.\n\n    Returns\n    -------\n    list\n        List of burst indices for each autocorrelogram column.\n\n    Notes\n    -----\n    The burst index is calculated as:\n        burst_idx = (peak - baseline) / max(peak, baseline)\n\n    - Peak is calculated as the maximum of the autocorrelogram between 2-9 ms.\n    - Baseline is calculated as the mean of the autocorrelogram between 40-50 ms.\n\n    Examples\n    -------\n    &gt;&gt;&gt; burst_idx = BurstIndex_Royer_2012(autocorr_df)\n    \"\"\"\n    # peak range 2 - 9 ms\n    peak = autocorrs.loc[0.002:0.009].max()\n    # baseline idx 40 - 50 ms\n    baseline = autocorrs.loc[0.04:0.05].mean()\n\n    burst_idx = []\n    for p, b in zip(peak, baseline):\n        if (p is None) | (b is None):\n            burst_idx.append(np.nan)\n            continue\n        if p &gt; b:\n            burst_idx.append((p - b) / p)\n        elif p &lt; b:\n            burst_idx.append((p - b) / b)\n        else:\n            burst_idx.append(np.nan)\n    return burst_idx\n</code></pre>"},{"location":"reference/neuro_py/spikes/spike_tools/#neuro_py.spikes.spike_tools.get_spindices","title":"<code>get_spindices(data)</code>","text":"<p>Spike timestamps and IDs from each spike train in a time-sorted DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Spike times for each spike train, where each element is an array of spike times for a neuron.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Sorted spike times and the corresponding spikes' neuron IDs</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spike_trains = [np.array([0.1, 0.2, 0.4]), np.array([0.15, 0.35])]\n&gt;&gt;&gt; spikes = get_spindices(spike_trains)\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def get_spindices(data: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"\n    Spike timestamps and IDs from each spike train in a time-sorted DataFrame.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Spike times for each spike train, where each element is an array of\n        spike times for a neuron.\n\n    Returns\n    -------\n    pd.DataFrame\n        Sorted spike times and the corresponding spikes' neuron IDs\n\n    Examples\n    -------\n    &gt;&gt;&gt; spike_trains = [np.array([0.1, 0.2, 0.4]), np.array([0.15, 0.35])]\n    &gt;&gt;&gt; spikes = get_spindices(spike_trains)\n    \"\"\"\n    spikes_id = np.repeat(np.arange(len(data)), [len(spk) for spk in data])\n\n    spikes = pd.DataFrame({\"spike_times\": np.concatenate(data), \"spike_id\": spikes_id})\n    spikes.sort_values(\"spike_times\", inplace=True)\n    return spikes\n</code></pre>"},{"location":"reference/neuro_py/spikes/spike_tools/#neuro_py.spikes.spike_tools.select_burst_spikes","title":"<code>select_burst_spikes(spikes, mode='bursts', isiBursts=0.006, isiSpikes=0.02)</code>","text":"<p>Discriminate bursts versus single spikes based on inter-spike intervals.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>ndarray</code> <p>Array of spike times.</p> required <code>mode</code> <code>str</code> <p>Either 'bursts' (default) or 'single'.</p> <code>'bursts'</code> <code>isiBursts</code> <code>float</code> <p>Maximum inter-spike interval for bursts (default = 0.006 seconds).</p> <code>0.006</code> <code>isiSpikes</code> <code>float</code> <p>Minimum inter-spike interval for single spikes (default = 0.020 seconds).</p> <code>0.02</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array indicating for each spike whether it matches the criterion.</p> Notes <p>Adapted from: http://fmatoolbox.sourceforge.net/Contents/FMAToolbox/Analyses/SelectSpikes.html</p> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def select_burst_spikes(\n    spikes: np.ndarray,\n    mode: str = \"bursts\",\n    isiBursts: float = 0.006,\n    isiSpikes: float = 0.020,\n) -&gt; np.ndarray:\n    \"\"\"\n    Discriminate bursts versus single spikes based on inter-spike intervals.\n\n    Parameters\n    ----------\n    spikes : np.ndarray\n        Array of spike times.\n    mode : str, optional\n        Either 'bursts' (default) or 'single'.\n    isiBursts : float, optional\n        Maximum inter-spike interval for bursts (default = 0.006 seconds).\n    isiSpikes : float, optional\n        Minimum inter-spike interval for single spikes (default = 0.020 seconds).\n\n    Returns\n    -------\n    np.ndarray\n        A boolean array indicating for each spike whether it matches the criterion.\n\n    Notes\n    -----\n    Adapted from: http://fmatoolbox.sourceforge.net/Contents/FMAToolbox/Analyses/SelectSpikes.html\n    \"\"\"\n\n    dt = np.diff(spikes)\n\n    if mode == \"bursts\":\n        b = dt &lt; isiBursts\n        # either next or previous isi &lt; threshold\n        selected = np.insert(b, 0, False, axis=0) | np.append(b, False)\n    else:\n        s = dt &gt; isiSpikes\n        # either next or previous isi &gt; threshold\n        selected = np.insert(s, 0, False, axis=0) &amp; np.append(s, False)\n\n    return selected\n</code></pre>"},{"location":"reference/neuro_py/spikes/spike_tools/#neuro_py.spikes.spike_tools.spindices_to_ndarray","title":"<code>spindices_to_ndarray(spikes, spike_id=None)</code>","text":"<p>Convert spike times and spike IDs from a DataFrame into a list of arrays, where each array contains the spike times for a given spike train.</p> <p>Parameters:</p> Name Type Description Default <code>spikes</code> <code>DataFrame</code> <p>DataFrame containing 'spike_times' and 'spike_id' columns, sorted by 'spike_times'.</p> required <code>spike_id</code> <code>list or ndarray</code> <p>List or array of spike IDs to search for in the DataFrame. If None, all spike IDs are used.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>A list of arrays, each containing the spike times for a corresponding spike train.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spike_trains = spindices_to_ndarray(spikes_df, spike_id=[0, 1, 2])\n</code></pre> Source code in <code>neuro_py/spikes/spike_tools.py</code> <pre><code>def spindices_to_ndarray(\n    spikes: pd.DataFrame, spike_id: Union[List[int], np.ndarray, None] = None\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Convert spike times and spike IDs from a DataFrame into a list of arrays,\n    where each array contains the spike times for a given spike train.\n\n    Parameters\n    ----------\n    spikes : pd.DataFrame\n        DataFrame containing 'spike_times' and 'spike_id' columns, sorted by\n        'spike_times'.\n    spike_id : list or np.ndarray, optional\n        List or array of spike IDs to search for in the DataFrame. If None, all\n        spike IDs are used.\n\n    Returns\n    -------\n    List[np.ndarray]\n        A list of arrays, each containing the spike times for a corresponding\n        spike train.\n\n    Examples\n    -------\n    &gt;&gt;&gt; spike_trains = spindices_to_ndarray(spikes_df, spike_id=[0, 1, 2])\n    \"\"\"\n    if spike_id is None:\n        spike_id = spikes.spike_id.unique()\n    data = [spikes[spikes.spike_id == spk_i].spike_times.values for spk_i in spike_id]\n    return data\n</code></pre>"},{"location":"reference/neuro_py/stats/","title":"neuro_py.stats","text":""},{"location":"reference/neuro_py/stats/#neuro_py.stats.MultivariateRegressor","title":"<code>MultivariateRegressor</code>","text":"<p>               Bases: <code>object</code></p> <p>Multivariate Linear Regressor.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An n-by-d matrix of features.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of targets.</p> required <code>reg</code> <code>Optional[float]</code> <p>A regularization parameter (default is None).</p> <code>None</code> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class MultivariateRegressor(object):\n    \"\"\"\n    Multivariate Linear Regressor.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        An n-by-d matrix of features.\n    Y : np.ndarray\n        An n-by-D matrix of targets.\n    reg : Optional[float], optional\n        A regularization parameter (default is None).\n    \"\"\"\n\n    def __init__(self, X: np.ndarray, Y: np.ndarray, reg: Optional[float] = None):\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n\n        W1 = np.linalg.pinv(np.dot(X.T, X) + reg * sparse.eye(np.size(X, 1)))\n        W2 = np.dot(X, W1)\n        self.W = np.dot(Y.T, W2)\n\n    def __str__(self) -&gt; str:\n        return \"Multivariate Linear Regression\"\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Return the predicted Y for input X.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        return np.array(np.dot(X, self.W.T))\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Return the coefficient of determination R^2 of the prediction.\"\"\"\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.MultivariateRegressor.predict","title":"<code>predict(X)</code>","text":"<p>Return the predicted Y for input X.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return the predicted Y for input X.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    return np.array(np.dot(X, self.W.T))\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.MultivariateRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Return the coefficient of determination R^2 of the prediction.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Return the coefficient of determination R^2 of the prediction.\"\"\"\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.ReducedRankRegressor","title":"<code>ReducedRankRegressor</code>","text":"<p>               Bases: <code>object</code></p> <p>Reduced Rank Regressor (linear 'bottlenecking' or 'multitask learning').</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An n-by-d matrix of features.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of targets.</p> required <code>rank</code> <code>int</code> <p>A rank constraint.</p> required <code>reg</code> <code>Optional[float]</code> <p>A regularization parameter (default is None).</p> <code>None</code> References <p>Implemented by Chris Rayner (2015). dchrisrayner AT gmail DOT com</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class ReducedRankRegressor(object):\n    \"\"\"\n    Reduced Rank Regressor (linear 'bottlenecking' or 'multitask learning').\n\n    Parameters\n    ----------\n    X : np.ndarray\n        An n-by-d matrix of features.\n    Y : np.ndarray\n        An n-by-D matrix of targets.\n    rank : int\n        A rank constraint.\n    reg : Optional[float], optional\n        A regularization parameter (default is None).\n\n    References\n    ----\n    Implemented by Chris Rayner (2015).\n    dchrisrayner AT gmail DOT com\n    \"\"\"\n\n    def __init__(\n        self, X: np.ndarray, Y: np.ndarray, rank: int, reg: Optional[float] = None\n    ):\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n        self.rank = rank\n\n        CXX = X.T @ X + reg * sparse.eye(np.size(X, 1))\n        CXY = X.T @ Y\n        _U, _S, V = np.linalg.svd(CXY.T @ (np.linalg.pinv(CXX) @ CXY))\n        self.W = V[0:rank, :].T\n        self.A = (np.linalg.pinv(CXX) @ (CXY @ self.W)).T\n\n    def __str__(self) -&gt; str:\n        return \"Reduced Rank Regressor (rank = {})\".format(self.rank)\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict Y from X.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        return np.asarray(X @ (self.A.T @ self.W.T))\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Score the model.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.ReducedRankRegressor.predict","title":"<code>predict(X)</code>","text":"<p>Predict Y from X.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Predict Y from X.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    return np.asarray(X @ (self.A.T @ self.W.T))\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.ReducedRankRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Score the model.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Score the model.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    if np.size(np.shape(Y)) == 1:\n        Y = np.reshape(Y, (-1, 1))\n\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.SystemIdentifier","title":"<code>SystemIdentifier</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple Subspace System Identifier.</p> <p>This class identifies a linear dynamical system based on given input and output data using subspace methods.</p> <p>Parameters:</p> Name Type Description Default <code>U</code> <code>ndarray</code> <p>An n-by-d matrix of control inputs.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of output observations.</p> required <code>statedim</code> <code>int</code> <p>The dimension of the internal state variable.</p> required <code>reg</code> <code>float</code> <p>Regularization parameter (default is None, which is set to 0).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>A</code> <code>ndarray</code> <p>State transition matrix.</p> <code>B</code> <code>ndarray</code> <p>Control input matrix.</p> <code>C</code> <code>ndarray</code> <p>Output matrix.</p> <code>D</code> <code>ndarray</code> <p>Feedforward matrix.</p> Source code in <code>neuro_py/stats/system_identifier.py</code> <pre><code>class SystemIdentifier(object):\n    \"\"\"\n    Simple Subspace System Identifier.\n\n    This class identifies a linear dynamical system based on given input and output data using subspace methods.\n\n    Parameters\n    ----------\n    U : np.ndarray\n        An n-by-d matrix of control inputs.\n    Y : np.ndarray\n        An n-by-D matrix of output observations.\n    statedim : int\n        The dimension of the internal state variable.\n    reg : float, optional\n        Regularization parameter (default is None, which is set to 0).\n\n    Attributes\n    ----------\n    A : np.ndarray\n        State transition matrix.\n    B : np.ndarray\n        Control input matrix.\n    C : np.ndarray\n        Output matrix.\n    D : np.ndarray\n        Feedforward matrix.\n    \"\"\"\n\n    def __init__(\n        self,\n        U: np.ndarray,\n        Y: np.ndarray,\n        statedim: int,\n        reg: Union[float, None] = None,\n    ):\n        if np.size(np.shape(U)) == 1:\n            U = np.reshape(U, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n\n        yDim = np.size(Y, 1)\n        uDim = np.size(U, 1)\n\n        self.output_size = np.size(Y, 1)  # placeholder\n\n        # number of samples of past/future we'll mash together into a 'state'\n        width = 1\n        # total number of past/future pairings we get as a result\n        K = np.size(U, 0) - 2 * width + 1\n\n        # build hankel matrices containing pasts and futures\n        U_p = np.array([np.ravel(U[t : t + width]) for t in range(K)]).T\n        U_f = np.array([np.ravel(U[t + width : t + 2 * width]) for t in range(K)]).T\n        Y_p = np.array([np.ravel(Y[t : t + width]) for t in range(K)]).T\n        Y_f = np.array([np.ravel(Y[t + width : t + 2 * width]) for t in range(K)]).T\n\n        # solve the eigenvalue problem\n        YfUfT = np.dot(Y_f, U_f.T)\n        YfUpT = np.dot(Y_f, U_p.T)\n        YfYpT = np.dot(Y_f, Y_p.T)\n        UfUpT = np.dot(U_f, U_p.T)\n        UfYpT = np.dot(U_f, Y_p.T)\n        UpYpT = np.dot(U_p, Y_p.T)\n        F = sparse.bmat(\n            [\n                [None, YfUfT, YfUpT, YfYpT],\n                [YfUfT.T, None, UfUpT, UfYpT],\n                [YfUpT.T, UfUpT.T, None, UpYpT],\n                [YfYpT.T, UfYpT.T, UpYpT.T, None],\n            ]\n        )\n        Ginv = sparse.bmat(\n            [\n                [np.linalg.pinv(np.dot(Y_f, Y_f.T)), None, None, None],\n                [None, np.linalg.pinv(np.dot(U_f, U_f.T)), None, None],\n                [None, None, np.linalg.pinv(np.dot(U_p, U_p.T)), None],\n                [None, None, None, np.linalg.pinv(np.dot(Y_p, Y_p.T))],\n            ]\n        )\n        F = F - sparse.eye(sp.size(F, 0)) * reg\n\n        # Take smallest eigenvalues\n        _, W = sparse_linalg.eigs(Ginv.dot(F), k=statedim, which=\"SR\")\n\n        # State sequence is a weighted combination of the past\n        W_U_p = W[width * (yDim + uDim) : width * (yDim + uDim + uDim), :]\n        W_Y_p = W[width * (yDim + uDim + uDim) :, :]\n        X_hist = np.dot(W_U_p.T, U_p) + np.dot(W_Y_p.T, Y_p)\n\n        # Regress; trim inputs to match the states we retrieved\n        R = np.concatenate((X_hist[:, :-1], U[width:-width].T), 0)\n        L = np.concatenate((X_hist[:, 1:], Y[width:-width].T), 0)\n        RRi = np.linalg.pinv(np.dot(R, R.T))\n        RL = np.dot(R, L.T)\n        Sys = np.dot(RRi, RL).T\n        self.A = Sys[:statedim, :statedim]\n        self.B = Sys[:statedim, statedim:]\n        self.C = Sys[statedim:, :statedim]\n        self.D = Sys[statedim:, statedim:]\n\n    def __str__(self) -&gt; str:\n        return \"Linear Dynamical System\"\n\n    def predict(self, U: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Predict output given the control inputs.\n\n        Parameters\n        ----------\n        U : np.ndarray\n            Control inputs, shape (n_samples, n_controls).\n\n        Returns\n        -------\n        np.ndarray\n            Predicted outputs, shape (n_samples, n_outputs).\n        \"\"\"\n        # If U is a vector, reshape it\n        if np.size(np.shape(U)) == 1:\n            U = np.reshape(U, (-1, 1))\n\n        # assume some random initial state\n        X = np.reshape(np.random.randn(np.size(self.A, 1)), (1, -1))\n\n        # intitial output\n        Y = np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, U[0]), (1, -1))\n\n        # generate next state\n        X = np.concatenate(\n            (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, U[0]), (1, -1)))\n        )\n\n        # and so forth\n        for u in U[1:]:\n            Y = np.concatenate(\n                (Y, np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, u), (1, -1)))\n            )\n            X = np.concatenate(\n                (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, u), (1, -1)))\n            )\n\n        return Y\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.SystemIdentifier.predict","title":"<code>predict(U)</code>","text":"<p>Predict output given the control inputs.</p> <p>Parameters:</p> Name Type Description Default <code>U</code> <code>ndarray</code> <p>Control inputs, shape (n_samples, n_controls).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted outputs, shape (n_samples, n_outputs).</p> Source code in <code>neuro_py/stats/system_identifier.py</code> <pre><code>def predict(self, U: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict output given the control inputs.\n\n    Parameters\n    ----------\n    U : np.ndarray\n        Control inputs, shape (n_samples, n_controls).\n\n    Returns\n    -------\n    np.ndarray\n        Predicted outputs, shape (n_samples, n_outputs).\n    \"\"\"\n    # If U is a vector, reshape it\n    if np.size(np.shape(U)) == 1:\n        U = np.reshape(U, (-1, 1))\n\n    # assume some random initial state\n    X = np.reshape(np.random.randn(np.size(self.A, 1)), (1, -1))\n\n    # intitial output\n    Y = np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, U[0]), (1, -1))\n\n    # generate next state\n    X = np.concatenate(\n        (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, U[0]), (1, -1)))\n    )\n\n    # and so forth\n    for u in U[1:]:\n        Y = np.concatenate(\n            (Y, np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, u), (1, -1)))\n        )\n        X = np.concatenate(\n            (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, u), (1, -1)))\n        )\n\n    return Y\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.kernelReducedRankRegressor","title":"<code>kernelReducedRankRegressor</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>Kernel Reduced Rank Ridge Regression.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>The rank constraint (default is 10).</p> <code>10</code> <code>reg</code> <code>float</code> <p>The regularization parameter (default is 1).</p> <code>1</code> <code>P_rr</code> <code>Optional[ndarray]</code> <p>The P matrix for reduced rank (default is None).</p> <code>None</code> <code>Q_fr</code> <code>Optional[ndarray]</code> <p>The Q matrix for fitted values (default is None).</p> <code>None</code> <code>trainX</code> <code>Optional[ndarray]</code> <p>The training features (default is None).</p> <code>None</code> References <p>Mukherjee, S. (DOI:10.1002/sam.10138) Code by Michele Svanera (2017-June).</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class kernelReducedRankRegressor(BaseEstimator):\n    \"\"\"\n    Kernel Reduced Rank Ridge Regression.\n\n    Parameters\n    ----------\n    rank : int, optional\n        The rank constraint (default is 10).\n    reg : float, optional\n        The regularization parameter (default is 1).\n    P_rr : Optional[np.ndarray], optional\n        The P matrix for reduced rank (default is None).\n    Q_fr : Optional[np.ndarray], optional\n        The Q matrix for fitted values (default is None).\n    trainX : Optional[np.ndarray], optional\n        The training features (default is None).\n\n    References\n    ----------\n    Mukherjee, S. (DOI:10.1002/sam.10138)\n    Code by Michele Svanera (2017-June).\n    \"\"\"\n\n    def __init__(\n        self,\n        rank: int = 10,\n        reg: float = 1,\n        P_rr: Optional[np.ndarray] = None,\n        Q_fr: Optional[np.ndarray] = None,\n        trainX: Optional[np.ndarray] = None,\n    ):\n        self.rank = rank\n        self.reg = reg\n        self.P_rr = P_rr\n        self.Q_fr = Q_fr\n        self.trainX = trainX\n\n    def __str__(self) -&gt; str:\n        return \"kernel Reduced Rank Ridge Regression by Mukherjee (rank = {})\".format(\n            self.rank\n        )\n\n    def fit(self, X: np.ndarray, Y: np.ndarray) -&gt; None:\n        # use try/except blog with exceptions!\n        self.rank = int(self.rank)\n\n        K_X = np.dot(X, X.T)\n        tmp_1 = self.reg * np.identity(K_X.shape[0]) + K_X\n        Q_fr = np.linalg.solve(tmp_1, Y)\n        P_fr = scipy.linalg.eig(np.dot(Y.T, np.dot(K_X, Q_fr)))[1].real\n        P_rr = np.dot(P_fr[:, 0 : self.rank], P_fr[:, 0 : self.rank].T)\n\n        self.Q_fr = Q_fr\n        self.P_rr = P_rr\n        self.trainX = X\n\n    def predict(self, testX: np.ndarray) -&gt; np.ndarray:\n        # use try/except blog with exceptions!\n\n        K_Xx = np.dot(testX, self.trainX.T)\n        Yhat = np.dot(K_Xx, np.dot(self.Q_fr, self.P_rr))\n\n        return Yhat\n\n    def rrr_scorer(self, Yhat: np.ndarray, Ytest: np.ndarray) -&gt; float:\n        diag_corr = (np.diag(np.corrcoef(Ytest, Yhat))).mean()\n        return diag_corr\n\n    ## Optional\n    def get_params(self, deep: bool = True) -&gt; dict:\n        return {\"rank\": self.rank, \"reg\": self.reg}\n\n    #\n    #    def set_params(self, **parameters):\n    #        for parameter, value in parameters.items():\n    #            self.setattr(parameter, value)\n    #        return self\n\n    def mse(self, X: np.ndarray, y_true: np.ndarray) -&gt; float:\n        \"\"\"\n        Score the model on test data.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The test data features.\n        y_true : np.ndarray\n            The true target values.\n\n        Returns\n        -------\n        float\n            The mean squared error of the predictions.\n        \"\"\"\n        Yhat = self.predict(X).real\n        MSE = (np.power((y_true - Yhat), 2) / np.prod(y_true.shape)).mean()\n        return MSE\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Score the model.\"\"\"\n\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.kernelReducedRankRegressor.mse","title":"<code>mse(X, y_true)</code>","text":"<p>Score the model on test data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The test data features.</p> required <code>y_true</code> <code>ndarray</code> <p>The true target values.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean squared error of the predictions.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def mse(self, X: np.ndarray, y_true: np.ndarray) -&gt; float:\n    \"\"\"\n    Score the model on test data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The test data features.\n    y_true : np.ndarray\n        The true target values.\n\n    Returns\n    -------\n    float\n        The mean squared error of the predictions.\n    \"\"\"\n    Yhat = self.predict(X).real\n    MSE = (np.power((y_true - Yhat), 2) / np.prod(y_true.shape)).mean()\n    return MSE\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.kernelReducedRankRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Score the model.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Score the model.\"\"\"\n\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.center","title":"<code>center(*args, **kwargs)</code>","text":"<p>Centers the data on its circular mean.</p> <p>Each non-keyword argument is another data array that is centered.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>The mean is computed along this dimension (default is None). Must be used as a keyword argument!</p> required <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple of centered data arrays.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@mod2pi\ndef center(*args: np.ndarray, **kwargs: Optional[dict]) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"\n    Centers the data on its circular mean.\n\n    Each non-keyword argument is another data array that is centered.\n\n    Parameters\n    ----------\n    axis : int, optional\n        The mean is computed along this dimension (default is None).\n        **Must be used as a keyword argument!**\n\n    Returns\n    -------\n    tuple of np.ndarray\n        Tuple of centered data arrays.\n    \"\"\"\n\n    axis = kwargs.pop(\"axis\", None)\n    if axis is None:\n        axis = 0\n        args = [a.ravel() for a in args]\n\n    reshaper = tuple(\n        slice(None, None) if i != axis else np.newaxis\n        for i in range(len(args[0].shape))\n    )\n    if len(args) == 1:\n        return args[0] - mean(args[0], axis=axis)\n    else:\n        return tuple(\n            [\n                a - mean(a, axis=axis)[reshaper]\n                for a in args\n                if isinstance(a, np.ndarray)\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.confidence_intervals","title":"<code>confidence_intervals(X, conf=0.95, estimator=np.nanmean, n_boot=1000, random_state=None)</code>","text":"<p>Calculate upper and lower confidence intervals on a matrix using a specified estimator.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A numpy ndarray of shape (n_signals, n_samples).</p> required <code>conf</code> <code>float</code> <p>Confidence level value (default is 0.95).</p> <code>0.95</code> <code>estimator</code> <code>Callable</code> <p>Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.</p> <code>nanmean</code> <code>n_boot</code> <code>int</code> <p>Number of bootstrap samples for CI if estimator is not mean/median (default: 1000).</p> <code>1000</code> <code>random_state</code> <code>int</code> <p>Random seed for bootstrapping.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>lower</code> <code>ndarray</code> <p>Lower bounds of the confidence intervals (shape: (n_signals,)).</p> <code>upper</code> <code>ndarray</code> <p>Upper bounds of the confidence intervals (shape: (n_signals,)).</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def confidence_intervals(\n    X: np.ndarray,\n    conf: float = 0.95,\n    estimator: Callable = np.nanmean,\n    n_boot: int = 1000,\n    random_state: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate upper and lower confidence intervals on a matrix using a specified estimator.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A numpy ndarray of shape (n_signals, n_samples).\n    conf : float, optional\n        Confidence level value (default is 0.95).\n    estimator : Callable, optional\n        Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.\n    n_boot : int, optional\n        Number of bootstrap samples for CI if estimator is not mean/median (default: 1000).\n    random_state : int, optional\n        Random seed for bootstrapping.\n\n    Returns\n    -------\n    lower : np.ndarray\n        Lower bounds of the confidence intervals (shape: (n_signals,)).\n    upper : np.ndarray\n        Upper bounds of the confidence intervals (shape: (n_signals,)).\n    \"\"\"\n    if estimator in (np.nanmean, bn.nanmean, np.nanmedian, bn.nanmedian):\n        # compute interval for each column using t-interval\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            interval = [\n                stats.t.interval(\n                    conf,\n                    len(a) - 1,\n                    loc=estimator(a),\n                    scale=stats.sem(a, nan_policy=\"omit\"),\n                )\n                for a in X.T\n            ]\n        interval = np.vstack(interval)\n        lower = interval[:, 0]\n        upper = interval[:, 1]\n    else:\n        # Bootstrap CI for arbitrary estimator\n        rng = np.random.default_rng(random_state)\n        n_signals = X.shape[1]\n        boot_stats = np.empty((n_boot, n_signals))\n        for i in range(n_boot):\n            sample_idx = rng.integers(0, X.shape[0], size=X.shape[0])\n            boot_stats[i] = estimator(X[sample_idx, :], axis=0)\n        lower = np.percentile(boot_stats, 100 * (1 - conf) / 2, axis=0)\n        upper = np.percentile(boot_stats, 100 * (1 + conf) / 2, axis=0)\n    return lower, upper\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.get_significant_events","title":"<code>get_significant_events(scores, shuffled_scores, q=95, tail='both')</code>","text":"<p>Return the significant events based on percentiles, the p-values, and the standard deviation of the scores in terms of the shuffled scores.</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>Union[list, ndarray]</code> <p>The array of scores for which to calculate significant events.</p> required <code>shuffled_scores</code> <code>ndarray</code> <p>The array of scores obtained from randomized data (shape: (n_shuffles, n_events)).</p> required <code>q</code> <code>float</code> <p>Percentile to compute, which must be between 0 and 100 inclusive (default is 95).</p> <code>95</code> <code>tail</code> <code>str</code> <p>Tail for the test, which can be 'left', 'right', or 'both' (default is 'both').</p> <code>'both'</code> <p>Returns:</p> Name Type Description <code>sig_event_idx</code> <code>ndarray</code> <p>Indices (from 0 to n_events-1) of significant events.</p> <code>pvalues</code> <code>ndarray</code> <p>The p-values.</p> <code>stddev</code> <code>ndarray</code> <p>The standard deviation of the scores in terms of the shuffled scores.</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def get_significant_events(\n    scores: Union[list, np.ndarray],\n    shuffled_scores: np.ndarray,\n    q: float = 95,\n    tail: str = \"both\",\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Return the significant events based on percentiles,\n    the p-values, and the standard deviation of the scores\n    in terms of the shuffled scores.\n\n    Parameters\n    ----------\n    scores : Union[list, np.ndarray]\n        The array of scores for which to calculate significant events.\n    shuffled_scores : np.ndarray\n        The array of scores obtained from randomized data (shape: (n_shuffles, n_events)).\n    q : float, optional\n        Percentile to compute, which must be between 0 and 100 inclusive (default is 95).\n    tail : str, optional\n        Tail for the test, which can be 'left', 'right', or 'both' (default is 'both').\n\n    Returns\n    -------\n    sig_event_idx : np.ndarray\n        Indices (from 0 to n_events-1) of significant events.\n    pvalues : np.ndarray\n        The p-values.\n    stddev : np.ndarray\n        The standard deviation of the scores in terms of the shuffled scores.\n    \"\"\"\n    # check shape and correct if needed\n    if isinstance(scores, list) | isinstance(scores, np.ndarray):\n        if shuffled_scores.shape[1] != len(scores):\n            shuffled_scores = shuffled_scores.T\n\n    n = shuffled_scores.shape[0]\n    if tail == \"both\":\n        r = np.sum(np.abs(shuffled_scores) &gt;= np.abs(scores), axis=0)\n    elif tail == \"right\":\n        r = np.sum(shuffled_scores &gt;= scores, axis=0)\n    elif tail == \"left\":\n        r = np.sum(shuffled_scores &lt;= scores, axis=0)\n    else:\n        raise ValueError(\"tail must be 'left', 'right', or 'both'\")\n    pvalues = (r + 1) / (n + 1)\n\n    # set nan scores to 1\n    if isinstance(np.isnan(scores), np.ndarray):\n        pvalues[np.isnan(scores)] = 1\n\n    if tail == \"both\":\n        threshold = np.percentile(np.abs(shuffled_scores), axis=0, q=q)\n        sig_event_idx = np.where(np.abs(scores) &gt; threshold)[0]\n    elif tail == \"right\":\n        threshold = np.percentile(shuffled_scores, axis=0, q=q)\n        sig_event_idx = np.where(scores &gt; threshold)[0]\n    elif tail == \"left\":\n        threshold = np.percentile(shuffled_scores, axis=0, q=100 - q)\n        sig_event_idx = np.where(scores &lt; threshold)[0]\n\n    # calculate how many standard deviations away from shuffle\n    if tail == \"both\":\n        stddev = (\n            np.abs(scores) - np.nanmean(np.abs(shuffled_scores), axis=0)\n        ) / np.nanstd(np.abs(shuffled_scores), axis=0)\n    elif tail == \"right\":\n        stddev = (scores - np.nanmean(shuffled_scores, axis=0)) / np.nanstd(\n            shuffled_scores, axis=0\n        )\n    elif tail == \"left\":\n        stddev = (np.nanmean(shuffled_scores, axis=0) - scores) / np.nanstd(\n            shuffled_scores, axis=0\n        )\n\n    return np.atleast_1d(sig_event_idx), np.atleast_1d(pvalues), np.atleast_1d(stddev)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.get_var","title":"<code>get_var(f, varnames, args, kwargs)</code>","text":"<p>Retrieve indices of specified variables from a function's argument list.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable</code> <p>The function from which to retrieve variable information.</p> required <code>varnames</code> <code>list of str</code> <p>The names of the variables to retrieve.</p> required <code>args</code> <code>list</code> <p>Positional arguments passed to the function.</p> required <code>kwargs</code> <code>dict</code> <p>Keyword arguments passed to the function.</p> required <p>Returns:</p> Type Description <code>tuple of (list of int, list of str)</code> <p>A tuple containing two elements: - A list of indices of the specified variables in the function's argument list. - A list of keys for the keyword arguments that correspond to the specified variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a specified variable is not found in the function's argument list.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def get_var(\n    f: Callable, varnames: List[str], args: List[Any], kwargs: Dict[str, Any]\n) -&gt; Tuple[List[int], List[str]]:\n    \"\"\"\n    Retrieve indices of specified variables from a function's argument list.\n\n    Parameters\n    ----------\n    f : Callable\n        The function from which to retrieve variable information.\n    varnames : list of str\n        The names of the variables to retrieve.\n    args : list\n        Positional arguments passed to the function.\n    kwargs : dict\n        Keyword arguments passed to the function.\n\n    Returns\n    -------\n    tuple of (list of int, list of str)\n        A tuple containing two elements:\n        - A list of indices of the specified variables in the function's argument list.\n        - A list of keys for the keyword arguments that correspond to the specified variables.\n\n    Raises\n    ------\n    ValueError\n        If a specified variable is not found in the function's argument list.\n    \"\"\"\n    fvarnames = f.__code__.co_varnames\n\n    var_idx = []\n    kwar_keys = []\n    for varname in varnames:\n        if varname in fvarnames:\n            var_pos = fvarnames.index(varname)\n        else:\n            raise ValueError(\n                \"Function %s does not have variable %s.\" % (f.__name__, varnames)\n            )\n        if len(args) &gt;= var_pos + 1:\n            var_idx.append(var_pos)\n        elif varname in kwargs:\n            kwar_keys.append(varname)\n        else:\n            raise ValueError(\"%s was not specified in  %s.\" % (varnames, f.__name__))\n\n    return var_idx, kwar_keys\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.ideal_data","title":"<code>ideal_data(num, dimX, dimY, rrank, noise=1)</code>","text":"<p>Generate low-rank data.</p> <p>Parameters:</p> Name Type Description Default <code>num</code> <code>int</code> <p>Number of samples.</p> required <code>dimX</code> <code>int</code> <p>Dimensionality of the input data.</p> required <code>dimY</code> <code>int</code> <p>Dimensionality of the output data.</p> required <code>rrank</code> <code>int</code> <p>Rank of the low-rank structure.</p> required <code>noise</code> <code>float</code> <p>Standard deviation of the noise added to the output data (default is 1).</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple containing: - X : np.ndarray     The generated input data of shape (num, dimX). - Y : np.ndarray     The generated output data of shape (num, dimY).</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def ideal_data(\n    num: int, dimX: int, dimY: int, rrank: int, noise: float = 1\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generate low-rank data.\n\n    Parameters\n    ----------\n    num : int\n        Number of samples.\n    dimX : int\n        Dimensionality of the input data.\n    dimY : int\n        Dimensionality of the output data.\n    rrank : int\n        Rank of the low-rank structure.\n    noise : float, optional\n        Standard deviation of the noise added to the output data (default is 1).\n\n    Returns\n    -------\n    tuple[np.ndarray, np.ndarray]\n        A tuple containing:\n        - X : np.ndarray\n            The generated input data of shape (num, dimX).\n        - Y : np.ndarray\n            The generated output data of shape (num, dimY).\n\n    \"\"\"\n    X = np.random.randn(num, dimX)\n    W = np.random.randn(dimX, rrank) @ np.random.randn(rrank, dimY)\n    Y = X @ W + np.random.randn(num, dimY) * noise\n    return X, Y\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.mean_ci_limits","title":"<code>mean_ci_limits(alpha, ci=0.95, w=None, d=None, axis=None)</code>","text":"<p>Computes the confidence limits on the mean for circular data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>ci</code> <code>float</code> <p>Confidence interval limits are computed. Default is 0.95.</p> <code>0.95</code> <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data. If supplied, correction factor is used to correct for bias in estimation of r, in radians.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Dimension along which to compute the result. Default is None (across all dimensions).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Confidence limit width d; mean \u00b1 d yields upper/lower (1 - xi)% confidence limit.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def mean_ci_limits(\n    alpha: np.ndarray,\n    ci: float = 0.95,\n    w: Optional[np.ndarray] = None,\n    d: Optional[float] = None,\n    axis: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes the confidence limits on the mean for circular data.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of angles in radians.\n    ci : float, optional\n        Confidence interval limits are computed. Default is 0.95.\n    w : np.ndarray, optional\n        Number of incidences in case of binned angle data.\n    d : float, optional\n        Spacing of bin centers for binned data. If supplied,\n        correction factor is used to correct for bias in\n        estimation of r, in radians.\n    axis : int, optional\n        Dimension along which to compute the result. Default is None\n        (across all dimensions).\n\n    Returns\n    -------\n    np.ndarray\n        Confidence limit width d; mean \u00b1 d yields upper/lower\n        (1 - xi)% confidence limit.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    assert alpha.shape == w.shape, \"Dimensions of data and w do not match!\"\n\n    r = np.atleast_1d(resultant_vector_length(alpha, w=w, d=d, axis=axis))\n    n = np.atleast_1d(np.sum(w, axis=axis))\n\n    R = n * r\n    c2 = stats.chi2.ppf(ci, df=1)\n\n    t = np.nan * np.empty_like(r)\n\n    idx = (r &lt; 0.9) &amp; (r &gt; np.sqrt(c2 / 2 / n))\n    t[idx] = np.sqrt(\n        (2 * n[idx] * (2 * R[idx] ** 2 - n[idx] * c2)) / (4 * n[idx] - c2)\n    )  # eq. 26.24\n\n    idx2 = r &gt;= 0.9\n    t[idx2] = np.sqrt(\n        n[idx2] ** 2 - (n[idx2] ** 2 - R[idx2] ** 2) * np.exp(c2 / n[idx2])\n    )  # equ. 26.25\n\n    if not np.all(idx | idx2):\n        raise UserWarning(\n            \"\"\"Requirements for confidence levels not met:\n                CI limits require a certain concentration of the data around the mean\"\"\"\n        )\n\n    return np.squeeze(np.arccos(t / R))\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.percentile","title":"<code>percentile(alpha, q, q0, axis=None, ci=None, bootstrap_iter=None)</code>","text":"<p>Computes circular percentiles.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Array with circular samples.</p> required <code>q</code> <code>float or iterable of float</code> <p>Percentiles in [0, 100] (single number or iterable).</p> required <code>q0</code> <code>float</code> <p>Value of the 0 percentile.</p> required <code>axis</code> <code>int</code> <p>Percentiles will be computed along this axis. If None, percentiles will be computed over the entire array.</p> <code>None</code> <code>ci</code> <code>float</code> <p>If not None, confidence level is bootstrapped.</p> <code>None</code> <code>bootstrap_iter</code> <code>int</code> <p>Number of bootstrap iterations (number of samples if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed percentiles.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@mod2pi\n@bootstrap(1, \"circular\")\ndef percentile(alpha, q, q0, axis=None, ci=None, bootstrap_iter=None):\n    \"\"\"\n    Computes circular percentiles.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Array with circular samples.\n    q : float or iterable of float\n        Percentiles in [0, 100] (single number or iterable).\n    q0 : float\n        Value of the 0 percentile.\n    axis : int, optional\n        Percentiles will be computed along this axis.\n        If None, percentiles will be computed over the entire array.\n    ci : float, optional\n        If not None, confidence level is bootstrapped.\n    bootstrap_iter : int, optional\n        Number of bootstrap iterations (number of samples if None).\n\n    Returns\n    -------\n    np.ndarray\n        Computed percentiles.\n    \"\"\"\n    if axis is None:\n        alpha = (alpha.ravel() - q0) % (2 * np.pi)\n    else:\n        if len(q0.shape) == len(alpha.shape) - 1:\n            reshaper = tuple(\n                slice(None, None) if i != axis else np.newaxis\n                for i in range(len(alpha.shape))\n            )\n            q0 = q0[reshaper]\n        elif not len(q0.shape) == len(alpha.shape):\n            raise ValueError(\"Dimensions of start and alpha are inconsistent!\")\n\n        alpha = (alpha - q0) % (2 * np.pi)\n\n    ret = []\n    if axis is not None:\n        selector = tuple(\n            slice(None) if i != axis else 0 for i in range(len(alpha.shape))\n        )\n        q0 = q0[selector]\n\n    for qq in np.atleast_1d(q):\n        ret.append(np.percentile(alpha, qq, axis=axis) + q0)\n\n    if not hasattr(q, \"__iter__\"):  # if q is not some sort of list, array, etc\n        return np.asarray(ret).squeeze()\n    else:\n        return np.asarray(ret)\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.rayleigh","title":"<code>rayleigh(alpha, w=None, d=None, axis=None)</code>","text":"<p>Computes Rayleigh test for non-uniformity of circular data.</p> <p>H0: the population is uniformly distributed around the circle HA: the population is not distributed uniformly around the circle</p> <p>Assumption: the distribution has maximally one mode and the data is sampled from a von Mises distribution!</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data, if supplied. Correction factor is used to correct for bias in estimation of r.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Compute along this dimension, default is None; if None, the array is raveled.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pval</code> <code>float</code> <p>Two-tailed p-value.</p> <code>z</code> <code>float</code> <p>Value of the z-statistic.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@swap2zeroaxis([\"alpha\", \"w\"], [0, 1])\ndef rayleigh(\n    alpha: np.ndarray, w: np.ndarray = None, d: float = None, axis: int = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Computes Rayleigh test for non-uniformity of circular data.\n\n    H0: the population is uniformly distributed around the circle\n    HA: the population is not distributed uniformly around the circle\n\n    Assumption: the distribution has maximally one mode and the data is\n    sampled from a von Mises distribution!\n\n    Parameters\n    ----------\n    alpha : ndarray\n        Sample of angles in radians.\n    w : ndarray, optional\n        Number of incidences in case of binned angle data.\n    d : float, optional\n        Spacing of bin centers for binned data, if supplied.\n        Correction factor is used to correct for bias in estimation of r.\n    axis : int, optional\n        Compute along this dimension, default is None; if None, the array is raveled.\n\n    Returns\n    -------\n    pval : float\n        Two-tailed p-value.\n    z : float\n        Value of the z-statistic.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    assert w.shape == alpha.shape, \"Dimensions of alpha and w must match\"\n\n    r = resultant_vector_length(alpha, w=w, d=d, axis=axis)\n    n = np.sum(w, axis=axis)\n\n    # compute Rayleigh's R (equ. 27.1)\n    R = n * r\n\n    # compute Rayleigh's z (equ. 27.2)\n    z = R**2 / n\n\n    # compute p value using approxation in Zar, p. 617\n    pval = np.exp(np.sqrt(1 + 4 * n + 4 * (n**2 - R**2)) - (1 + 2 * n))\n\n    return pval, z\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.regress_out","title":"<code>regress_out(a, b)</code>","text":"<p>Regress b from a while keeping a's original mean.</p> <p>This function performs regression of variable b from variable a while preserving the original mean of a. It calculates the residual component of a that remains after removing the effect of b using ordinary least squares.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>The variable to be regressed. Must be 1-dimensional.</p> required <code>b</code> <code>ndarray</code> <p>The variable to regress on a. Must be 1-dimensional.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The residual of a after regressing out b. Has the same shape as a.</p> Notes <p>Adapted from the seaborn function of the same name: https://github.com/mwaskom/seaborn/blob/824c102525e6a29cde9bca1ce0096d50588fda6b/seaborn/regression.py#L337</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def regress_out(a: np.ndarray, b: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Regress b from a while keeping a's original mean.\n\n    This function performs regression of variable b from variable a while\n    preserving the original mean of a. It calculates the residual component\n    of a that remains after removing the effect of b using ordinary least squares.\n\n    Parameters\n    ----------\n    a : np.ndarray\n        The variable to be regressed. Must be 1-dimensional.\n    b : np.ndarray\n        The variable to regress on a. Must be 1-dimensional.\n\n    Returns\n    -------\n    np.ndarray\n        The residual of a after regressing out b. Has the same shape as a.\n\n    Notes\n    -----\n    Adapted from the seaborn function of the same name:\n    https://github.com/mwaskom/seaborn/blob/824c102525e6a29cde9bca1ce0096d50588fda6b/seaborn/regression.py#L337\n    \"\"\"\n    # remove nans and infs from a and b, and make a_result vector for output\n    valid_mask = np.isfinite(a) &amp; np.isfinite(b)\n    a_valid = np.asarray(a)[valid_mask]\n    b_valid = np.asarray(b)[valid_mask]\n\n    # remove mean from a and b\n    a_mean = a_valid.mean() if a_valid.size &gt; 0 else 0.0\n    a_centered = a_valid - a_mean\n    b_centered = b_valid - b_valid.mean() if b_valid.size &gt; 0 else b_valid\n\n    # calculate regression and subtract from a to get a_prime\n    if b_centered.size &gt; 0:\n        b_mat = np.c_[b_centered]\n        a_prime = a_centered - b_mat @ np.linalg.pinv(b_mat) @ a_centered\n        a_prime = np.asarray(a_prime + a_mean).reshape(a_centered.shape)\n    else:\n        a_prime = a_centered\n\n    # Build output: fill with np.nan where invalid, otherwise with result\n    a_result = np.empty_like(a, dtype=float)\n    a_result[:] = np.nan\n    a_result[valid_mask] = a_prime\n    return a_result\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.reindex_df","title":"<code>reindex_df(df, weight_col)</code>","text":"<p>Expand the dataframe by weights.</p> <p>This function expands the dataframe to prepare for resampling, resulting in 1 row per count per sample, which is helpful when making weighted proportion plots.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to be expanded.</p> required <code>weight_col</code> <code>str</code> <p>The column name that contains weights (should be int).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A new pandas dataframe with resampling based on the weights.</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def reindex_df(df: pd.DataFrame, weight_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Expand the dataframe by weights.\n\n    This function expands the dataframe to prepare for resampling,\n    resulting in 1 row per count per sample, which is helpful\n    when making weighted proportion plots.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The pandas dataframe to be expanded.\n    weight_col : str\n        The column name that contains weights (should be int).\n\n    Returns\n    -------\n    pd.DataFrame\n        A new pandas dataframe with resampling based on the weights.\n    \"\"\"\n\n    df = df.reindex(df.index.repeat(df[weight_col])).copy()\n\n    df.reset_index(drop=True, inplace=True)\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/stats/#neuro_py.stats.resultant_vector_length","title":"<code>resultant_vector_length(alpha, w=None, d=None, axis=None, axial_correction=1, ci=None, bootstrap_iter=None)</code>","text":"<p>Computes the mean resultant vector length for circular data.</p> <p>This statistic is sometimes also called vector strength.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>ci</code> <code>float</code> <p>Confidence limits computed via bootstrapping. Default is None.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data. If supplied, correction factor is used to correct for bias in estimation of r, in radians.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Dimension along which to compute the result. Default is None (across all dimensions).</p> <code>None</code> <code>axial_correction</code> <code>int</code> <p>Axial correction factor (2, 3, 4,...). Default is 1.</p> <code>1</code> <code>bootstrap_iter</code> <code>int</code> <p>Number of bootstrap iterations (number of samples if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Mean resultant vector length.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@bootstrap(1, \"linear\")\ndef resultant_vector_length(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    d: Optional[float] = None,\n    axis: Optional[int] = None,\n    axial_correction: int = 1,\n    ci: Optional[float] = None,\n    bootstrap_iter: Optional[int] = None,\n) -&gt; float:\n    \"\"\"\n    Computes the mean resultant vector length for circular data.\n\n    This statistic is sometimes also called vector strength.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of angles in radians.\n    w : np.ndarray, optional\n        Number of incidences in case of binned angle data.\n    ci : float, optional\n        Confidence limits computed via bootstrapping. Default is None.\n    d : float, optional\n        Spacing of bin centers for binned data. If supplied,\n        correction factor is used to correct for bias in\n        estimation of r, in radians.\n    axis : int, optional\n        Dimension along which to compute the result. Default is None\n        (across all dimensions).\n    axial_correction : int, optional\n        Axial correction factor (2, 3, 4,...). Default is 1.\n    bootstrap_iter : int, optional\n        Number of bootstrap iterations (number of samples if None).\n\n    Returns\n    -------\n    float\n        Mean resultant vector length.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n    if axis is None:\n        axis = 0\n        alpha = alpha.ravel()\n        if w is not None:\n            w = w.ravel()\n\n    cmean = _complex_mean(alpha, w=w, axis=axis, axial_correction=axial_correction)\n\n    # obtain length\n    r = np.abs(cmean)\n\n    # for data with known spacing, apply correction factor to correct for bias\n    # in the estimation of r (see Zar, p. 601, equ. 26.16)\n    if d is not None:\n        if axial_correction &gt; 1:\n            warnings.warn(\"Axial correction ignored for bias correction.\")\n        r *= d / 2 / np.sin(d / 2)\n    return r\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/","title":"neuro_py.stats.circ_stats","text":""},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.bootstrap","title":"<code>bootstrap</code>","text":"<p>Decorator to implement bootstrapping. It looks for the arguments ci, axis, and bootstrap_iter to determine the proper parameters for bootstrapping. The argument scale determines whether the percentile is taken on a circular scale or on a linear scale.</p> <p>Parameters:</p> Name Type Description Default <code>no_bootstrap</code> <code>int</code> <p>The number of arguments that are bootstrapped (e.g., for correlation it would be two, for median it would be one).</p> required <code>scale</code> <code>str</code> <p>Linear or circular scale (default is 'linear').</p> <code>'linear'</code> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>class bootstrap:\n    \"\"\"\n    Decorator to implement bootstrapping. It looks for the arguments ci, axis,\n    and bootstrap_iter to determine the proper parameters for bootstrapping.\n    The argument scale determines whether the percentile is taken on a circular\n    scale or on a linear scale.\n\n    Parameters\n    ----------\n    no_bootstrap : int\n        The number of arguments that are bootstrapped\n        (e.g., for correlation it would be two, for median it would be one).\n    scale : str, optional\n        Linear or circular scale (default is 'linear').\n    \"\"\"\n\n    def __init__(self, no_bootstrap, scale=\"linear\"):\n        self.no_boostrap = no_bootstrap\n        self.scale = scale\n\n    def _get_var(self, f, what, default, args, kwargs, remove=False):\n        varnames = f.__code__.co_varnames\n\n        if what in varnames:\n            what_idx = varnames.index(what)\n        else:\n            raise ValueError(\n                \"Function %s does not have variable %s.\" % (f.__name__, what)\n            )\n\n        if len(args) &gt;= what_idx + 1:\n            val = args[what_idx]\n            if remove:\n                args[what_idx] = default\n        else:\n            val = default\n\n        return val\n\n    def __call__(self, f):\n        def wrapper(f, *args, **kwargs):\n            args = list(args)\n            ci = self._get_var(f, \"ci\", None, args, kwargs, remove=True)\n            bootstrap_iter = self._get_var(\n                f, \"bootstrap_iter\", None, args, kwargs, remove=True\n            )\n            axis = self._get_var(f, \"axis\", None, args, kwargs)\n\n            alpha = args[: self.no_boostrap]\n            args0 = args[self.no_boostrap :]\n\n            if bootstrap_iter is None:\n                bootstrap_iter = (\n                    alpha[0].shape[axis] if axis is not None else alpha[0].size\n                )\n\n            r0 = f(*(alpha + args0), **kwargs)\n            if ci is not None:\n                r = np.asarray(\n                    [\n                        f(*(list(a) + args0), **kwargs)\n                        for a in nd_bootstrap(\n                            alpha, bootstrap_iter, axis=axis, strip_tuple_if_one=False\n                        )\n                    ]\n                )\n\n                if self.scale == \"linear\":\n                    ci_low, ci_high = np.percentile(\n                        r, [(1 - ci) / 2 * 100, (1 + ci) / 2 * 100], axis=0\n                    )\n                elif self.scale == \"circular\":\n                    ci_low, ci_high = percentile(\n                        r,\n                        [(1 - ci) / 2 * 100, (1 + ci) / 2 * 100],\n                        q0=(r0 + np.pi) % (2 * np.pi),\n                        axis=0,\n                    )\n                else:\n                    raise ValueError(\"Scale %s not known!\" % (self.scale,))\n                return r0, CI(ci_low, ci_high)\n            else:\n                return r0\n\n        return decorator(wrapper, f)\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.swap2zeroaxis","title":"<code>swap2zeroaxis</code>","text":"<p>Decorator to swap specified axes of input arguments to zero and swap them back in output.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>list of str</code> <p>The names of the input arguments for which the axes are swapped.</p> required <code>out_idx</code> <code>list of int</code> <p>The indices of the output arguments whose axes will be swapped back.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If a specified output index is inconsistent with a single output argument.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @swap2zeroaxis(['x', 'y'], [0, 1])\n&gt;&gt;&gt; def dummy(x, y, z, axis=None):\n&gt;&gt;&gt;    return np.mean(x[::2, ...], axis=0), np.mean(y[::2, ...], axis=0), z\n</code></pre> <p>This creates a new function that:</p> <ul> <li>Either swaps the specified axes to zero for the arguments <code>x</code> and <code>y</code>   if <code>axis</code> is specified in the wrapped function, or flattens <code>x</code> and <code>y</code>.</li> <li>Swaps back the axes from the output arguments, assuming the outputs lost   one dimension during the function (e.g., like <code>numpy.mean(x, axis=1)</code>).</li> </ul> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>class swap2zeroaxis:\n    \"\"\"\n    Decorator to swap specified axes of input arguments to zero and swap them back in output.\n\n    Parameters\n    ----------\n    inputs : list of str\n        The names of the input arguments for which the axes are swapped.\n    out_idx : list of int\n        The indices of the output arguments whose axes will be swapped back.\n\n    Raises\n    ------\n    ValueError\n        If a specified output index is inconsistent with a single output argument.\n\n    Examples\n    --------\n\n    &gt;&gt;&gt; @swap2zeroaxis(['x', 'y'], [0, 1])\n    &gt;&gt;&gt; def dummy(x, y, z, axis=None):\n    &gt;&gt;&gt;    return np.mean(x[::2, ...], axis=0), np.mean(y[::2, ...], axis=0), z\n\n    This creates a new function that:\n\n    - Either swaps the specified axes to zero for the arguments `x` and `y`\n      if `axis` is specified in the wrapped function, or flattens `x` and `y`.\n    - Swaps back the axes from the output arguments, assuming the outputs lost\n      one dimension during the function (e.g., like `numpy.mean(x, axis=1)`).\n    \"\"\"\n\n    def __init__(self, inputs: list[str], out_idx: list[int]):\n        self.inputs = inputs\n        self.out_idx = out_idx\n\n    def __call__(self, f: callable) -&gt; callable:\n        def _deco(f: callable, *args: tuple, **kwargs: dict) -&gt; tuple:\n            to_swap_idx, to_swap_keys = get_var(f, self.inputs, args, kwargs)\n            args = list(args)\n\n            # extract axis parameter\n            try:\n                axis_idx, axis_kw = get_var(f, [\"axis\"], args, kwargs)\n                if len(axis_idx) == 0 and len(axis_kw) == 0:\n                    axis = None\n                else:\n                    if len(axis_idx) &gt; 0:\n                        axis, args[axis_idx[0]] = args[axis_idx[0]], 0\n                    else:\n                        axis, kwargs[axis_kw[0]] = kwargs[axis_kw[0]], 0\n            except ValueError:\n                axis = None\n\n            # adjust axes or flatten\n            if axis is not None:\n                for i in to_swap_idx:\n                    if args[i] is not None:\n                        args[i] = args[i].swapaxes(0, axis)\n                for k in to_swap_keys:\n                    if kwargs[k] is not None:\n                        kwargs[k] = kwargs[k].swapaxes(0, axis)\n            else:\n                for i in to_swap_idx:\n                    if args[i] is not None:\n                        args[i] = args[i].ravel()\n                for k in to_swap_keys:\n                    if kwargs[k] is not None:\n                        kwargs[k] = kwargs[k].ravel()\n\n            # compute function\n            outputs = f(*args, **kwargs)\n\n            # swap everything back into place\n            if len(self.out_idx) &gt; 0 and axis is not None:\n                if isinstance(outputs, tuple):\n                    outputs = list(outputs)\n                    for i in self.out_idx:\n                        outputs[i] = (\n                            outputs[i][np.newaxis, ...].swapaxes(0, axis).squeeze()\n                        )\n\n                    return tuple(outputs)\n                else:\n                    if self.out_idx != [0]:\n                        raise ValueError(\n                            \"Single output argument and out_idx \\\n                                         != [0] are inconsistent!\"\n                        )\n                    return outputs[np.newaxis, ...].swapaxes(0, axis).squeeze()\n            else:\n                return outputs\n\n        return decorator(_deco, f)\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats._complex_mean","title":"<code>_complex_mean(alpha, w=None, axis=None, axial_correction=1)</code>","text":"<p>Compute the weighted mean of complex values.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Array of angles (in radians) representing complex values.</p> required <code>w</code> <code>ndarray</code> <p>Array of weights corresponding to the alpha values. If None, uniform weights are used.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Axis along which the mean is computed. If None, the mean is computed over the entire array.</p> <code>None</code> <code>axial_correction</code> <code>float</code> <p>Correction factor for the angles (default is 1).</p> <code>1</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Weighted mean of the complex values.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def _complex_mean(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    axis: Optional[int] = None,\n    axial_correction: float = 1,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the weighted mean of complex values.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Array of angles (in radians) representing complex values.\n    w : np.ndarray, optional\n        Array of weights corresponding to the alpha values. If None, uniform weights are used.\n    axis : int, optional\n        Axis along which the mean is computed. If None, the mean is computed over the entire array.\n    axial_correction : float, optional\n        Correction factor for the angles (default is 1).\n\n    Returns\n    -------\n    np.ndarray\n        Weighted mean of the complex values.\n    \"\"\"\n    if w is None:\n        w = np.ones_like(alpha)\n    alpha = np.asarray(alpha)\n\n    assert w.shape == alpha.shape, (\n        \"Dimensions of data \"\n        + str(alpha.shape)\n        + \" and w \"\n        + str(w.shape)\n        + \" do not match!\"\n    )\n\n    return (w * np.exp(1j * alpha * axial_correction)).sum(axis=axis) / np.sum(\n        w, axis=axis\n    )\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.center","title":"<code>center(*args, **kwargs)</code>","text":"<p>Centers the data on its circular mean.</p> <p>Each non-keyword argument is another data array that is centered.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>The mean is computed along this dimension (default is None). Must be used as a keyword argument!</p> required <p>Returns:</p> Type Description <code>tuple of np.ndarray</code> <p>Tuple of centered data arrays.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@mod2pi\ndef center(*args: np.ndarray, **kwargs: Optional[dict]) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"\n    Centers the data on its circular mean.\n\n    Each non-keyword argument is another data array that is centered.\n\n    Parameters\n    ----------\n    axis : int, optional\n        The mean is computed along this dimension (default is None).\n        **Must be used as a keyword argument!**\n\n    Returns\n    -------\n    tuple of np.ndarray\n        Tuple of centered data arrays.\n    \"\"\"\n\n    axis = kwargs.pop(\"axis\", None)\n    if axis is None:\n        axis = 0\n        args = [a.ravel() for a in args]\n\n    reshaper = tuple(\n        slice(None, None) if i != axis else np.newaxis\n        for i in range(len(args[0].shape))\n    )\n    if len(args) == 1:\n        return args[0] - mean(args[0], axis=axis)\n    else:\n        return tuple(\n            [\n                a - mean(a, axis=axis)[reshaper]\n                for a in args\n                if isinstance(a, np.ndarray)\n            ]\n        )\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.get_var","title":"<code>get_var(f, varnames, args, kwargs)</code>","text":"<p>Retrieve indices of specified variables from a function's argument list.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable</code> <p>The function from which to retrieve variable information.</p> required <code>varnames</code> <code>list of str</code> <p>The names of the variables to retrieve.</p> required <code>args</code> <code>list</code> <p>Positional arguments passed to the function.</p> required <code>kwargs</code> <code>dict</code> <p>Keyword arguments passed to the function.</p> required <p>Returns:</p> Type Description <code>tuple of (list of int, list of str)</code> <p>A tuple containing two elements: - A list of indices of the specified variables in the function's argument list. - A list of keys for the keyword arguments that correspond to the specified variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a specified variable is not found in the function's argument list.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def get_var(\n    f: Callable, varnames: List[str], args: List[Any], kwargs: Dict[str, Any]\n) -&gt; Tuple[List[int], List[str]]:\n    \"\"\"\n    Retrieve indices of specified variables from a function's argument list.\n\n    Parameters\n    ----------\n    f : Callable\n        The function from which to retrieve variable information.\n    varnames : list of str\n        The names of the variables to retrieve.\n    args : list\n        Positional arguments passed to the function.\n    kwargs : dict\n        Keyword arguments passed to the function.\n\n    Returns\n    -------\n    tuple of (list of int, list of str)\n        A tuple containing two elements:\n        - A list of indices of the specified variables in the function's argument list.\n        - A list of keys for the keyword arguments that correspond to the specified variables.\n\n    Raises\n    ------\n    ValueError\n        If a specified variable is not found in the function's argument list.\n    \"\"\"\n    fvarnames = f.__code__.co_varnames\n\n    var_idx = []\n    kwar_keys = []\n    for varname in varnames:\n        if varname in fvarnames:\n            var_pos = fvarnames.index(varname)\n        else:\n            raise ValueError(\n                \"Function %s does not have variable %s.\" % (f.__name__, varnames)\n            )\n        if len(args) &gt;= var_pos + 1:\n            var_idx.append(var_pos)\n        elif varname in kwargs:\n            kwar_keys.append(varname)\n        else:\n            raise ValueError(\"%s was not specified in  %s.\" % (varnames, f.__name__))\n\n    return var_idx, kwar_keys\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.mean","title":"<code>mean(alpha, w=None, ci=None, d=None, axis=None, axial_correction=1)</code>","text":"<p>Compute mean direction of circular data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Circular data.</p> required <code>w</code> <code>ndarray</code> <p>Weightings in case of binned angle data.</p> <code>None</code> <code>ci</code> <code>float</code> <p>If not None, the upper and lower 100*ci% confidence interval is returned as well.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data. If supplied, correction factor is used to correct for bias in estimation of r, in radians.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Compute along this dimension. Default is None (across all dimensions).</p> <code>None</code> <code>axial_correction</code> <code>int</code> <p>Axial correction (2,3,4,...). Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>float or Tuple[float, CI]</code> <p>Circular mean if ci is None, or circular mean as well as lower and upper confidence interval limits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = 2 * np.pi * np.random.rand(10)\n&gt;&gt;&gt; mu, (ci_l, ci_u) = mean(data, ci=0.95)\n</code></pre> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@mod2pi\ndef mean(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    ci: Optional[float] = None,\n    d: Optional[float] = None,\n    axis: Optional[int] = None,\n    axial_correction: int = 1,\n) -&gt; Union[float, Tuple[float, CI]]:\n    \"\"\"\n    Compute mean direction of circular data.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Circular data.\n    w : np.ndarray, optional\n        Weightings in case of binned angle data.\n    ci : float, optional\n        If not None, the upper and lower 100*ci% confidence\n        interval is returned as well.\n    d : float, optional\n        Spacing of bin centers for binned data. If supplied,\n        correction factor is used to correct for bias in\n        estimation of r, in radians.\n    axis : int, optional\n        Compute along this dimension. Default is None\n        (across all dimensions).\n    axial_correction : int, optional\n        Axial correction (2,3,4,...). Default is 1.\n\n    Returns\n    -------\n    float or Tuple[float, CI]\n        Circular mean if ci is None, or circular mean as well as lower and\n        upper confidence interval limits.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; data = 2 * np.pi * np.random.rand(10)\n    &gt;&gt;&gt; mu, (ci_l, ci_u) = mean(data, ci=0.95)\n    \"\"\"\n\n    cmean = _complex_mean(alpha, w=w, axis=axis, axial_correction=axial_correction)\n\n    mu = np.angle(cmean) / axial_correction\n\n    if ci is None:\n        return mu\n    else:\n        if axial_correction &gt; 1:  # TODO: implement CI for axial correction\n            warnings.warn(\"Axial correction ignored for confidence intervals.\")\n        t = mean_ci_limits(alpha, ci=ci, w=w, d=d, axis=axis)\n        return mu, CI(mu - t, mu + t)\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.mean_ci_limits","title":"<code>mean_ci_limits(alpha, ci=0.95, w=None, d=None, axis=None)</code>","text":"<p>Computes the confidence limits on the mean for circular data.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>ci</code> <code>float</code> <p>Confidence interval limits are computed. Default is 0.95.</p> <code>0.95</code> <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data. If supplied, correction factor is used to correct for bias in estimation of r, in radians.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Dimension along which to compute the result. Default is None (across all dimensions).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Confidence limit width d; mean \u00b1 d yields upper/lower (1 - xi)% confidence limit.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def mean_ci_limits(\n    alpha: np.ndarray,\n    ci: float = 0.95,\n    w: Optional[np.ndarray] = None,\n    d: Optional[float] = None,\n    axis: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes the confidence limits on the mean for circular data.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of angles in radians.\n    ci : float, optional\n        Confidence interval limits are computed. Default is 0.95.\n    w : np.ndarray, optional\n        Number of incidences in case of binned angle data.\n    d : float, optional\n        Spacing of bin centers for binned data. If supplied,\n        correction factor is used to correct for bias in\n        estimation of r, in radians.\n    axis : int, optional\n        Dimension along which to compute the result. Default is None\n        (across all dimensions).\n\n    Returns\n    -------\n    np.ndarray\n        Confidence limit width d; mean \u00b1 d yields upper/lower\n        (1 - xi)% confidence limit.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    assert alpha.shape == w.shape, \"Dimensions of data and w do not match!\"\n\n    r = np.atleast_1d(resultant_vector_length(alpha, w=w, d=d, axis=axis))\n    n = np.atleast_1d(np.sum(w, axis=axis))\n\n    R = n * r\n    c2 = stats.chi2.ppf(ci, df=1)\n\n    t = np.nan * np.empty_like(r)\n\n    idx = (r &lt; 0.9) &amp; (r &gt; np.sqrt(c2 / 2 / n))\n    t[idx] = np.sqrt(\n        (2 * n[idx] * (2 * R[idx] ** 2 - n[idx] * c2)) / (4 * n[idx] - c2)\n    )  # eq. 26.24\n\n    idx2 = r &gt;= 0.9\n    t[idx2] = np.sqrt(\n        n[idx2] ** 2 - (n[idx2] ** 2 - R[idx2] ** 2) * np.exp(c2 / n[idx2])\n    )  # equ. 26.25\n\n    if not np.all(idx | idx2):\n        raise UserWarning(\n            \"\"\"Requirements for confidence levels not met:\n                CI limits require a certain concentration of the data around the mean\"\"\"\n        )\n\n    return np.squeeze(np.arccos(t / R))\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.mod2pi","title":"<code>mod2pi(f)</code>","text":"<p>Decorator to apply modulo 2*pi on the output of the function.</p> <p>The decorated function must either return a tuple of numpy.ndarrays or a numpy.ndarray itself.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable</code> <p>The function to be decorated.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>A wrapper function that applies modulo 2*pi on the output.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def mod2pi(f: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to apply modulo 2*pi on the output of the function.\n\n    The decorated function must either return a tuple of numpy.ndarrays or a\n    numpy.ndarray itself.\n\n    Parameters\n    ----------\n    f : Callable\n        The function to be decorated.\n\n    Returns\n    -------\n    Callable\n        A wrapper function that applies modulo 2*pi on the output.\n    \"\"\"\n\n    def wrapper(f, *args, **kwargs):\n        ret = f(*args, **kwargs)\n\n        if isinstance(ret, tuple):\n            ret2 = []\n            for r in ret:\n                if isinstance(r, np.ndarray) or np.isscalar(r):\n                    ret2.append(r % (2 * np.pi))\n                elif isinstance(r, CI):\n                    ret2.append(CI(r.lower % (2 * np.pi), r.upper % (2 * np.pi)))\n                else:\n                    raise TypeError(\"Type not known!\")\n            return tuple(ret2)\n        elif isinstance(ret, np.ndarray) or np.isscalar(ret):\n            return ret % (2 * np.pi)\n        else:\n            raise TypeError(\"Type not known!\")\n\n    return decorator(wrapper, f)\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.nd_bootstrap","title":"<code>nd_bootstrap(data, iterations, axis=None, strip_tuple_if_one=True)</code>","text":"<p>Bootstrap iterator for several n-dimensional data arrays.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Iterable[ndarray]</code> <p>Iterable containing the data arrays.</p> required <code>iterations</code> <code>int</code> <p>Number of bootstrap iterations.</p> required <code>axis</code> <code>Union[int, None]</code> <p>Bootstrapping is performed along this axis. If None, the data is flattened.</p> <code>None</code> <code>strip_tuple_if_one</code> <code>bool</code> <p>If True, return a single array without tuple if only one data array is provided.</p> <code>True</code> <p>Yields:</p> Type Description <code>Tuple[ndarray, ...]</code> <p>Bootstrapped data arrays for each iteration.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>def nd_bootstrap(\n    data: Iterable[np.ndarray],\n    iterations: int,\n    axis: Union[int, None] = None,\n    strip_tuple_if_one: bool = True,\n) -&gt; Generator[Union[np.ndarray, Tuple[np.ndarray, ...]], None, None]:\n    \"\"\"\n    Bootstrap iterator for several n-dimensional data arrays.\n\n    Parameters\n    ----------\n    data : Iterable[np.ndarray]\n        Iterable containing the data arrays.\n    iterations : int\n        Number of bootstrap iterations.\n    axis : Union[int, None], optional\n        Bootstrapping is performed along this axis. If None, the data is flattened.\n    strip_tuple_if_one : bool, optional\n        If True, return a single array without tuple if only one data array is provided.\n\n    Yields\n    ------\n    Tuple[np.ndarray, ...]\n        Bootstrapped data arrays for each iteration.\n    \"\"\"\n    shape0 = data[0].shape\n    if axis is None:\n        axis = 0\n        data = [d.ravel() for d in data]\n\n    n = len(data[0].shape)\n    K = len(data)\n    data0 = []\n\n    if axis is not None:\n        m = data[0].shape[axis]\n        to = tuple([axis]) + tuple(range(axis)) + tuple(range(axis + 1, n))\n        fro = tuple(range(1, axis + 1)) + (0,) + tuple(range(axis + 1, n))\n        for i in range(K):\n            data0.append(data[i].transpose(to))\n\n        for i in range(iterations):\n            idx = np.random.randint(m, size=(m,))\n            if len(data) == 1 and strip_tuple_if_one:\n                yield (\n                    data0[0][np.ix_(idx), ...].squeeze().transpose(fro).reshape(shape0)\n                )\n            else:\n                yield tuple(\n                    a[np.ix_(idx), ...].squeeze().transpose(fro).reshape(shape0)\n                    for a in data0\n                )\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.percentile","title":"<code>percentile(alpha, q, q0, axis=None, ci=None, bootstrap_iter=None)</code>","text":"<p>Computes circular percentiles.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Array with circular samples.</p> required <code>q</code> <code>float or iterable of float</code> <p>Percentiles in [0, 100] (single number or iterable).</p> required <code>q0</code> <code>float</code> <p>Value of the 0 percentile.</p> required <code>axis</code> <code>int</code> <p>Percentiles will be computed along this axis. If None, percentiles will be computed over the entire array.</p> <code>None</code> <code>ci</code> <code>float</code> <p>If not None, confidence level is bootstrapped.</p> <code>None</code> <code>bootstrap_iter</code> <code>int</code> <p>Number of bootstrap iterations (number of samples if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Computed percentiles.</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@mod2pi\n@bootstrap(1, \"circular\")\ndef percentile(alpha, q, q0, axis=None, ci=None, bootstrap_iter=None):\n    \"\"\"\n    Computes circular percentiles.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Array with circular samples.\n    q : float or iterable of float\n        Percentiles in [0, 100] (single number or iterable).\n    q0 : float\n        Value of the 0 percentile.\n    axis : int, optional\n        Percentiles will be computed along this axis.\n        If None, percentiles will be computed over the entire array.\n    ci : float, optional\n        If not None, confidence level is bootstrapped.\n    bootstrap_iter : int, optional\n        Number of bootstrap iterations (number of samples if None).\n\n    Returns\n    -------\n    np.ndarray\n        Computed percentiles.\n    \"\"\"\n    if axis is None:\n        alpha = (alpha.ravel() - q0) % (2 * np.pi)\n    else:\n        if len(q0.shape) == len(alpha.shape) - 1:\n            reshaper = tuple(\n                slice(None, None) if i != axis else np.newaxis\n                for i in range(len(alpha.shape))\n            )\n            q0 = q0[reshaper]\n        elif not len(q0.shape) == len(alpha.shape):\n            raise ValueError(\"Dimensions of start and alpha are inconsistent!\")\n\n        alpha = (alpha - q0) % (2 * np.pi)\n\n    ret = []\n    if axis is not None:\n        selector = tuple(\n            slice(None) if i != axis else 0 for i in range(len(alpha.shape))\n        )\n        q0 = q0[selector]\n\n    for qq in np.atleast_1d(q):\n        ret.append(np.percentile(alpha, qq, axis=axis) + q0)\n\n    if not hasattr(q, \"__iter__\"):  # if q is not some sort of list, array, etc\n        return np.asarray(ret).squeeze()\n    else:\n        return np.asarray(ret)\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.rayleigh","title":"<code>rayleigh(alpha, w=None, d=None, axis=None)</code>","text":"<p>Computes Rayleigh test for non-uniformity of circular data.</p> <p>H0: the population is uniformly distributed around the circle HA: the population is not distributed uniformly around the circle</p> <p>Assumption: the distribution has maximally one mode and the data is sampled from a von Mises distribution!</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data, if supplied. Correction factor is used to correct for bias in estimation of r.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Compute along this dimension, default is None; if None, the array is raveled.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pval</code> <code>float</code> <p>Two-tailed p-value.</p> <code>z</code> <code>float</code> <p>Value of the z-statistic.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@swap2zeroaxis([\"alpha\", \"w\"], [0, 1])\ndef rayleigh(\n    alpha: np.ndarray, w: np.ndarray = None, d: float = None, axis: int = None\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Computes Rayleigh test for non-uniformity of circular data.\n\n    H0: the population is uniformly distributed around the circle\n    HA: the population is not distributed uniformly around the circle\n\n    Assumption: the distribution has maximally one mode and the data is\n    sampled from a von Mises distribution!\n\n    Parameters\n    ----------\n    alpha : ndarray\n        Sample of angles in radians.\n    w : ndarray, optional\n        Number of incidences in case of binned angle data.\n    d : float, optional\n        Spacing of bin centers for binned data, if supplied.\n        Correction factor is used to correct for bias in estimation of r.\n    axis : int, optional\n        Compute along this dimension, default is None; if None, the array is raveled.\n\n    Returns\n    -------\n    pval : float\n        Two-tailed p-value.\n    z : float\n        Value of the z-statistic.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n\n    if w is None:\n        w = np.ones_like(alpha)\n\n    assert w.shape == alpha.shape, \"Dimensions of alpha and w must match\"\n\n    r = resultant_vector_length(alpha, w=w, d=d, axis=axis)\n    n = np.sum(w, axis=axis)\n\n    # compute Rayleigh's R (equ. 27.1)\n    R = n * r\n\n    # compute Rayleigh's z (equ. 27.2)\n    z = R**2 / n\n\n    # compute p value using approxation in Zar, p. 617\n    pval = np.exp(np.sqrt(1 + 4 * n + 4 * (n**2 - R**2)) - (1 + 2 * n))\n\n    return pval, z\n</code></pre>"},{"location":"reference/neuro_py/stats/circ_stats/#neuro_py.stats.circ_stats.resultant_vector_length","title":"<code>resultant_vector_length(alpha, w=None, d=None, axis=None, axial_correction=1, ci=None, bootstrap_iter=None)</code>","text":"<p>Computes the mean resultant vector length for circular data.</p> <p>This statistic is sometimes also called vector strength.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Sample of angles in radians.</p> required <code>w</code> <code>ndarray</code> <p>Number of incidences in case of binned angle data.</p> <code>None</code> <code>ci</code> <code>float</code> <p>Confidence limits computed via bootstrapping. Default is None.</p> <code>None</code> <code>d</code> <code>float</code> <p>Spacing of bin centers for binned data. If supplied, correction factor is used to correct for bias in estimation of r, in radians.</p> <code>None</code> <code>axis</code> <code>int</code> <p>Dimension along which to compute the result. Default is None (across all dimensions).</p> <code>None</code> <code>axial_correction</code> <code>int</code> <p>Axial correction factor (2, 3, 4,...). Default is 1.</p> <code>1</code> <code>bootstrap_iter</code> <code>int</code> <p>Number of bootstrap iterations (number of samples if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>Mean resultant vector length.</p> References <p>[Fisher1995], [Jammalamadaka2001], [Zar2009]_</p> Source code in <code>neuro_py/stats/circ_stats.py</code> <pre><code>@bootstrap(1, \"linear\")\ndef resultant_vector_length(\n    alpha: np.ndarray,\n    w: Optional[np.ndarray] = None,\n    d: Optional[float] = None,\n    axis: Optional[int] = None,\n    axial_correction: int = 1,\n    ci: Optional[float] = None,\n    bootstrap_iter: Optional[int] = None,\n) -&gt; float:\n    \"\"\"\n    Computes the mean resultant vector length for circular data.\n\n    This statistic is sometimes also called vector strength.\n\n    Parameters\n    ----------\n    alpha : np.ndarray\n        Sample of angles in radians.\n    w : np.ndarray, optional\n        Number of incidences in case of binned angle data.\n    ci : float, optional\n        Confidence limits computed via bootstrapping. Default is None.\n    d : float, optional\n        Spacing of bin centers for binned data. If supplied,\n        correction factor is used to correct for bias in\n        estimation of r, in radians.\n    axis : int, optional\n        Dimension along which to compute the result. Default is None\n        (across all dimensions).\n    axial_correction : int, optional\n        Axial correction factor (2, 3, 4,...). Default is 1.\n    bootstrap_iter : int, optional\n        Number of bootstrap iterations (number of samples if None).\n\n    Returns\n    -------\n    float\n        Mean resultant vector length.\n\n    References\n    ----------\n    [Fisher1995]_, [Jammalamadaka2001]_, [Zar2009]_\n    \"\"\"\n    if axis is None:\n        axis = 0\n        alpha = alpha.ravel()\n        if w is not None:\n            w = w.ravel()\n\n    cmean = _complex_mean(alpha, w=w, axis=axis, axial_correction=axial_correction)\n\n    # obtain length\n    r = np.abs(cmean)\n\n    # for data with known spacing, apply correction factor to correct for bias\n    # in the estimation of r (see Zar, p. 601, equ. 26.16)\n    if d is not None:\n        if axial_correction &gt; 1:\n            warnings.warn(\"Axial correction ignored for bias correction.\")\n        r *= d / 2 / np.sin(d / 2)\n    return r\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/","title":"neuro_py.stats.regression","text":""},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.MultivariateRegressor","title":"<code>MultivariateRegressor</code>","text":"<p>               Bases: <code>object</code></p> <p>Multivariate Linear Regressor.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An n-by-d matrix of features.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of targets.</p> required <code>reg</code> <code>Optional[float]</code> <p>A regularization parameter (default is None).</p> <code>None</code> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class MultivariateRegressor(object):\n    \"\"\"\n    Multivariate Linear Regressor.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        An n-by-d matrix of features.\n    Y : np.ndarray\n        An n-by-D matrix of targets.\n    reg : Optional[float], optional\n        A regularization parameter (default is None).\n    \"\"\"\n\n    def __init__(self, X: np.ndarray, Y: np.ndarray, reg: Optional[float] = None):\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n\n        W1 = np.linalg.pinv(np.dot(X.T, X) + reg * sparse.eye(np.size(X, 1)))\n        W2 = np.dot(X, W1)\n        self.W = np.dot(Y.T, W2)\n\n    def __str__(self) -&gt; str:\n        return \"Multivariate Linear Regression\"\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Return the predicted Y for input X.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        return np.array(np.dot(X, self.W.T))\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Return the coefficient of determination R^2 of the prediction.\"\"\"\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.MultivariateRegressor.predict","title":"<code>predict(X)</code>","text":"<p>Return the predicted Y for input X.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Return the predicted Y for input X.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    return np.array(np.dot(X, self.W.T))\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.MultivariateRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Return the coefficient of determination R^2 of the prediction.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Return the coefficient of determination R^2 of the prediction.\"\"\"\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.ReducedRankRegressor","title":"<code>ReducedRankRegressor</code>","text":"<p>               Bases: <code>object</code></p> <p>Reduced Rank Regressor (linear 'bottlenecking' or 'multitask learning').</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An n-by-d matrix of features.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of targets.</p> required <code>rank</code> <code>int</code> <p>A rank constraint.</p> required <code>reg</code> <code>Optional[float]</code> <p>A regularization parameter (default is None).</p> <code>None</code> References <p>Implemented by Chris Rayner (2015). dchrisrayner AT gmail DOT com</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class ReducedRankRegressor(object):\n    \"\"\"\n    Reduced Rank Regressor (linear 'bottlenecking' or 'multitask learning').\n\n    Parameters\n    ----------\n    X : np.ndarray\n        An n-by-d matrix of features.\n    Y : np.ndarray\n        An n-by-D matrix of targets.\n    rank : int\n        A rank constraint.\n    reg : Optional[float], optional\n        A regularization parameter (default is None).\n\n    References\n    ----\n    Implemented by Chris Rayner (2015).\n    dchrisrayner AT gmail DOT com\n    \"\"\"\n\n    def __init__(\n        self, X: np.ndarray, Y: np.ndarray, rank: int, reg: Optional[float] = None\n    ):\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n        self.rank = rank\n\n        CXX = X.T @ X + reg * sparse.eye(np.size(X, 1))\n        CXY = X.T @ Y\n        _U, _S, V = np.linalg.svd(CXY.T @ (np.linalg.pinv(CXX) @ CXY))\n        self.W = V[0:rank, :].T\n        self.A = (np.linalg.pinv(CXX) @ (CXY @ self.W)).T\n\n    def __str__(self) -&gt; str:\n        return \"Reduced Rank Regressor (rank = {})\".format(self.rank)\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict Y from X.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        return np.asarray(X @ (self.A.T @ self.W.T))\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Score the model.\"\"\"\n        if np.size(np.shape(X)) == 1:\n            X = np.reshape(X, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.ReducedRankRegressor.predict","title":"<code>predict(X)</code>","text":"<p>Predict Y from X.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Predict Y from X.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    return np.asarray(X @ (self.A.T @ self.W.T))\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.ReducedRankRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Score the model.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Score the model.\"\"\"\n    if np.size(np.shape(X)) == 1:\n        X = np.reshape(X, (-1, 1))\n    if np.size(np.shape(Y)) == 1:\n        Y = np.reshape(Y, (-1, 1))\n\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.kernelReducedRankRegressor","title":"<code>kernelReducedRankRegressor</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>Kernel Reduced Rank Ridge Regression.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>The rank constraint (default is 10).</p> <code>10</code> <code>reg</code> <code>float</code> <p>The regularization parameter (default is 1).</p> <code>1</code> <code>P_rr</code> <code>Optional[ndarray]</code> <p>The P matrix for reduced rank (default is None).</p> <code>None</code> <code>Q_fr</code> <code>Optional[ndarray]</code> <p>The Q matrix for fitted values (default is None).</p> <code>None</code> <code>trainX</code> <code>Optional[ndarray]</code> <p>The training features (default is None).</p> <code>None</code> References <p>Mukherjee, S. (DOI:10.1002/sam.10138) Code by Michele Svanera (2017-June).</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>class kernelReducedRankRegressor(BaseEstimator):\n    \"\"\"\n    Kernel Reduced Rank Ridge Regression.\n\n    Parameters\n    ----------\n    rank : int, optional\n        The rank constraint (default is 10).\n    reg : float, optional\n        The regularization parameter (default is 1).\n    P_rr : Optional[np.ndarray], optional\n        The P matrix for reduced rank (default is None).\n    Q_fr : Optional[np.ndarray], optional\n        The Q matrix for fitted values (default is None).\n    trainX : Optional[np.ndarray], optional\n        The training features (default is None).\n\n    References\n    ----------\n    Mukherjee, S. (DOI:10.1002/sam.10138)\n    Code by Michele Svanera (2017-June).\n    \"\"\"\n\n    def __init__(\n        self,\n        rank: int = 10,\n        reg: float = 1,\n        P_rr: Optional[np.ndarray] = None,\n        Q_fr: Optional[np.ndarray] = None,\n        trainX: Optional[np.ndarray] = None,\n    ):\n        self.rank = rank\n        self.reg = reg\n        self.P_rr = P_rr\n        self.Q_fr = Q_fr\n        self.trainX = trainX\n\n    def __str__(self) -&gt; str:\n        return \"kernel Reduced Rank Ridge Regression by Mukherjee (rank = {})\".format(\n            self.rank\n        )\n\n    def fit(self, X: np.ndarray, Y: np.ndarray) -&gt; None:\n        # use try/except blog with exceptions!\n        self.rank = int(self.rank)\n\n        K_X = np.dot(X, X.T)\n        tmp_1 = self.reg * np.identity(K_X.shape[0]) + K_X\n        Q_fr = np.linalg.solve(tmp_1, Y)\n        P_fr = scipy.linalg.eig(np.dot(Y.T, np.dot(K_X, Q_fr)))[1].real\n        P_rr = np.dot(P_fr[:, 0 : self.rank], P_fr[:, 0 : self.rank].T)\n\n        self.Q_fr = Q_fr\n        self.P_rr = P_rr\n        self.trainX = X\n\n    def predict(self, testX: np.ndarray) -&gt; np.ndarray:\n        # use try/except blog with exceptions!\n\n        K_Xx = np.dot(testX, self.trainX.T)\n        Yhat = np.dot(K_Xx, np.dot(self.Q_fr, self.P_rr))\n\n        return Yhat\n\n    def rrr_scorer(self, Yhat: np.ndarray, Ytest: np.ndarray) -&gt; float:\n        diag_corr = (np.diag(np.corrcoef(Ytest, Yhat))).mean()\n        return diag_corr\n\n    ## Optional\n    def get_params(self, deep: bool = True) -&gt; dict:\n        return {\"rank\": self.rank, \"reg\": self.reg}\n\n    #\n    #    def set_params(self, **parameters):\n    #        for parameter, value in parameters.items():\n    #            self.setattr(parameter, value)\n    #        return self\n\n    def mse(self, X: np.ndarray, y_true: np.ndarray) -&gt; float:\n        \"\"\"\n        Score the model on test data.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            The test data features.\n        y_true : np.ndarray\n            The true target values.\n\n        Returns\n        -------\n        float\n            The mean squared error of the predictions.\n        \"\"\"\n        Yhat = self.predict(X).real\n        MSE = (np.power((y_true - Yhat), 2) / np.prod(y_true.shape)).mean()\n        return MSE\n\n    def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n        \"\"\"Score the model.\"\"\"\n\n        y_pred = self.predict(X)\n        return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.kernelReducedRankRegressor.mse","title":"<code>mse(X, y_true)</code>","text":"<p>Score the model on test data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The test data features.</p> required <code>y_true</code> <code>ndarray</code> <p>The true target values.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean squared error of the predictions.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def mse(self, X: np.ndarray, y_true: np.ndarray) -&gt; float:\n    \"\"\"\n    Score the model on test data.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        The test data features.\n    y_true : np.ndarray\n        The true target values.\n\n    Returns\n    -------\n    float\n        The mean squared error of the predictions.\n    \"\"\"\n    Yhat = self.predict(X).real\n    MSE = (np.power((y_true - Yhat), 2) / np.prod(y_true.shape)).mean()\n    return MSE\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.kernelReducedRankRegressor.score","title":"<code>score(X, Y)</code>","text":"<p>Score the model.</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def score(self, X: np.ndarray, Y: np.ndarray) -&gt; float:\n    \"\"\"Score the model.\"\"\"\n\n    y_pred = self.predict(X)\n    return r2_score(Y, y_pred)\n</code></pre>"},{"location":"reference/neuro_py/stats/regression/#neuro_py.stats.regression.ideal_data","title":"<code>ideal_data(num, dimX, dimY, rrank, noise=1)</code>","text":"<p>Generate low-rank data.</p> <p>Parameters:</p> Name Type Description Default <code>num</code> <code>int</code> <p>Number of samples.</p> required <code>dimX</code> <code>int</code> <p>Dimensionality of the input data.</p> required <code>dimY</code> <code>int</code> <p>Dimensionality of the output data.</p> required <code>rrank</code> <code>int</code> <p>Rank of the low-rank structure.</p> required <code>noise</code> <code>float</code> <p>Standard deviation of the noise added to the output data (default is 1).</p> <code>1</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple containing: - X : np.ndarray     The generated input data of shape (num, dimX). - Y : np.ndarray     The generated output data of shape (num, dimY).</p> Source code in <code>neuro_py/stats/regression.py</code> <pre><code>def ideal_data(\n    num: int, dimX: int, dimY: int, rrank: int, noise: float = 1\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generate low-rank data.\n\n    Parameters\n    ----------\n    num : int\n        Number of samples.\n    dimX : int\n        Dimensionality of the input data.\n    dimY : int\n        Dimensionality of the output data.\n    rrank : int\n        Rank of the low-rank structure.\n    noise : float, optional\n        Standard deviation of the noise added to the output data (default is 1).\n\n    Returns\n    -------\n    tuple[np.ndarray, np.ndarray]\n        A tuple containing:\n        - X : np.ndarray\n            The generated input data of shape (num, dimX).\n        - Y : np.ndarray\n            The generated output data of shape (num, dimY).\n\n    \"\"\"\n    X = np.random.randn(num, dimX)\n    W = np.random.randn(dimX, rrank) @ np.random.randn(rrank, dimY)\n    Y = X @ W + np.random.randn(num, dimY) * noise\n    return X, Y\n</code></pre>"},{"location":"reference/neuro_py/stats/stats/","title":"neuro_py.stats.stats","text":""},{"location":"reference/neuro_py/stats/stats/#neuro_py.stats.stats.confidence_intervals","title":"<code>confidence_intervals(X, conf=0.95, estimator=np.nanmean, n_boot=1000, random_state=None)</code>","text":"<p>Calculate upper and lower confidence intervals on a matrix using a specified estimator.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>A numpy ndarray of shape (n_signals, n_samples).</p> required <code>conf</code> <code>float</code> <p>Confidence level value (default is 0.95).</p> <code>0.95</code> <code>estimator</code> <code>Callable</code> <p>Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.</p> <code>nanmean</code> <code>n_boot</code> <code>int</code> <p>Number of bootstrap samples for CI if estimator is not mean/median (default: 1000).</p> <code>1000</code> <code>random_state</code> <code>int</code> <p>Random seed for bootstrapping.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>lower</code> <code>ndarray</code> <p>Lower bounds of the confidence intervals (shape: (n_signals,)).</p> <code>upper</code> <code>ndarray</code> <p>Upper bounds of the confidence intervals (shape: (n_signals,)).</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def confidence_intervals(\n    X: np.ndarray,\n    conf: float = 0.95,\n    estimator: Callable = np.nanmean,\n    n_boot: int = 1000,\n    random_state: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate upper and lower confidence intervals on a matrix using a specified estimator.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        A numpy ndarray of shape (n_signals, n_samples).\n    conf : float, optional\n        Confidence level value (default is 0.95).\n    estimator : Callable, optional\n        Function to use for central tendency (default: np.nanmean). You may use numpy (np.nanmean, np.nanmedian, etc.) or Bottleneck (bn.nanmean, bn.nanmedian, etc.) for faster computation.\n    n_boot : int, optional\n        Number of bootstrap samples for CI if estimator is not mean/median (default: 1000).\n    random_state : int, optional\n        Random seed for bootstrapping.\n\n    Returns\n    -------\n    lower : np.ndarray\n        Lower bounds of the confidence intervals (shape: (n_signals,)).\n    upper : np.ndarray\n        Upper bounds of the confidence intervals (shape: (n_signals,)).\n    \"\"\"\n    if estimator in (np.nanmean, bn.nanmean, np.nanmedian, bn.nanmedian):\n        # compute interval for each column using t-interval\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            interval = [\n                stats.t.interval(\n                    conf,\n                    len(a) - 1,\n                    loc=estimator(a),\n                    scale=stats.sem(a, nan_policy=\"omit\"),\n                )\n                for a in X.T\n            ]\n        interval = np.vstack(interval)\n        lower = interval[:, 0]\n        upper = interval[:, 1]\n    else:\n        # Bootstrap CI for arbitrary estimator\n        rng = np.random.default_rng(random_state)\n        n_signals = X.shape[1]\n        boot_stats = np.empty((n_boot, n_signals))\n        for i in range(n_boot):\n            sample_idx = rng.integers(0, X.shape[0], size=X.shape[0])\n            boot_stats[i] = estimator(X[sample_idx, :], axis=0)\n        lower = np.percentile(boot_stats, 100 * (1 - conf) / 2, axis=0)\n        upper = np.percentile(boot_stats, 100 * (1 + conf) / 2, axis=0)\n    return lower, upper\n</code></pre>"},{"location":"reference/neuro_py/stats/stats/#neuro_py.stats.stats.get_significant_events","title":"<code>get_significant_events(scores, shuffled_scores, q=95, tail='both')</code>","text":"<p>Return the significant events based on percentiles, the p-values, and the standard deviation of the scores in terms of the shuffled scores.</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>Union[list, ndarray]</code> <p>The array of scores for which to calculate significant events.</p> required <code>shuffled_scores</code> <code>ndarray</code> <p>The array of scores obtained from randomized data (shape: (n_shuffles, n_events)).</p> required <code>q</code> <code>float</code> <p>Percentile to compute, which must be between 0 and 100 inclusive (default is 95).</p> <code>95</code> <code>tail</code> <code>str</code> <p>Tail for the test, which can be 'left', 'right', or 'both' (default is 'both').</p> <code>'both'</code> <p>Returns:</p> Name Type Description <code>sig_event_idx</code> <code>ndarray</code> <p>Indices (from 0 to n_events-1) of significant events.</p> <code>pvalues</code> <code>ndarray</code> <p>The p-values.</p> <code>stddev</code> <code>ndarray</code> <p>The standard deviation of the scores in terms of the shuffled scores.</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def get_significant_events(\n    scores: Union[list, np.ndarray],\n    shuffled_scores: np.ndarray,\n    q: float = 95,\n    tail: str = \"both\",\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Return the significant events based on percentiles,\n    the p-values, and the standard deviation of the scores\n    in terms of the shuffled scores.\n\n    Parameters\n    ----------\n    scores : Union[list, np.ndarray]\n        The array of scores for which to calculate significant events.\n    shuffled_scores : np.ndarray\n        The array of scores obtained from randomized data (shape: (n_shuffles, n_events)).\n    q : float, optional\n        Percentile to compute, which must be between 0 and 100 inclusive (default is 95).\n    tail : str, optional\n        Tail for the test, which can be 'left', 'right', or 'both' (default is 'both').\n\n    Returns\n    -------\n    sig_event_idx : np.ndarray\n        Indices (from 0 to n_events-1) of significant events.\n    pvalues : np.ndarray\n        The p-values.\n    stddev : np.ndarray\n        The standard deviation of the scores in terms of the shuffled scores.\n    \"\"\"\n    # check shape and correct if needed\n    if isinstance(scores, list) | isinstance(scores, np.ndarray):\n        if shuffled_scores.shape[1] != len(scores):\n            shuffled_scores = shuffled_scores.T\n\n    n = shuffled_scores.shape[0]\n    if tail == \"both\":\n        r = np.sum(np.abs(shuffled_scores) &gt;= np.abs(scores), axis=0)\n    elif tail == \"right\":\n        r = np.sum(shuffled_scores &gt;= scores, axis=0)\n    elif tail == \"left\":\n        r = np.sum(shuffled_scores &lt;= scores, axis=0)\n    else:\n        raise ValueError(\"tail must be 'left', 'right', or 'both'\")\n    pvalues = (r + 1) / (n + 1)\n\n    # set nan scores to 1\n    if isinstance(np.isnan(scores), np.ndarray):\n        pvalues[np.isnan(scores)] = 1\n\n    if tail == \"both\":\n        threshold = np.percentile(np.abs(shuffled_scores), axis=0, q=q)\n        sig_event_idx = np.where(np.abs(scores) &gt; threshold)[0]\n    elif tail == \"right\":\n        threshold = np.percentile(shuffled_scores, axis=0, q=q)\n        sig_event_idx = np.where(scores &gt; threshold)[0]\n    elif tail == \"left\":\n        threshold = np.percentile(shuffled_scores, axis=0, q=100 - q)\n        sig_event_idx = np.where(scores &lt; threshold)[0]\n\n    # calculate how many standard deviations away from shuffle\n    if tail == \"both\":\n        stddev = (\n            np.abs(scores) - np.nanmean(np.abs(shuffled_scores), axis=0)\n        ) / np.nanstd(np.abs(shuffled_scores), axis=0)\n    elif tail == \"right\":\n        stddev = (scores - np.nanmean(shuffled_scores, axis=0)) / np.nanstd(\n            shuffled_scores, axis=0\n        )\n    elif tail == \"left\":\n        stddev = (np.nanmean(shuffled_scores, axis=0) - scores) / np.nanstd(\n            shuffled_scores, axis=0\n        )\n\n    return np.atleast_1d(sig_event_idx), np.atleast_1d(pvalues), np.atleast_1d(stddev)\n</code></pre>"},{"location":"reference/neuro_py/stats/stats/#neuro_py.stats.stats.regress_out","title":"<code>regress_out(a, b)</code>","text":"<p>Regress b from a while keeping a's original mean.</p> <p>This function performs regression of variable b from variable a while preserving the original mean of a. It calculates the residual component of a that remains after removing the effect of b using ordinary least squares.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>The variable to be regressed. Must be 1-dimensional.</p> required <code>b</code> <code>ndarray</code> <p>The variable to regress on a. Must be 1-dimensional.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The residual of a after regressing out b. Has the same shape as a.</p> Notes <p>Adapted from the seaborn function of the same name: https://github.com/mwaskom/seaborn/blob/824c102525e6a29cde9bca1ce0096d50588fda6b/seaborn/regression.py#L337</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def regress_out(a: np.ndarray, b: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Regress b from a while keeping a's original mean.\n\n    This function performs regression of variable b from variable a while\n    preserving the original mean of a. It calculates the residual component\n    of a that remains after removing the effect of b using ordinary least squares.\n\n    Parameters\n    ----------\n    a : np.ndarray\n        The variable to be regressed. Must be 1-dimensional.\n    b : np.ndarray\n        The variable to regress on a. Must be 1-dimensional.\n\n    Returns\n    -------\n    np.ndarray\n        The residual of a after regressing out b. Has the same shape as a.\n\n    Notes\n    -----\n    Adapted from the seaborn function of the same name:\n    https://github.com/mwaskom/seaborn/blob/824c102525e6a29cde9bca1ce0096d50588fda6b/seaborn/regression.py#L337\n    \"\"\"\n    # remove nans and infs from a and b, and make a_result vector for output\n    valid_mask = np.isfinite(a) &amp; np.isfinite(b)\n    a_valid = np.asarray(a)[valid_mask]\n    b_valid = np.asarray(b)[valid_mask]\n\n    # remove mean from a and b\n    a_mean = a_valid.mean() if a_valid.size &gt; 0 else 0.0\n    a_centered = a_valid - a_mean\n    b_centered = b_valid - b_valid.mean() if b_valid.size &gt; 0 else b_valid\n\n    # calculate regression and subtract from a to get a_prime\n    if b_centered.size &gt; 0:\n        b_mat = np.c_[b_centered]\n        a_prime = a_centered - b_mat @ np.linalg.pinv(b_mat) @ a_centered\n        a_prime = np.asarray(a_prime + a_mean).reshape(a_centered.shape)\n    else:\n        a_prime = a_centered\n\n    # Build output: fill with np.nan where invalid, otherwise with result\n    a_result = np.empty_like(a, dtype=float)\n    a_result[:] = np.nan\n    a_result[valid_mask] = a_prime\n    return a_result\n</code></pre>"},{"location":"reference/neuro_py/stats/stats/#neuro_py.stats.stats.reindex_df","title":"<code>reindex_df(df, weight_col)</code>","text":"<p>Expand the dataframe by weights.</p> <p>This function expands the dataframe to prepare for resampling, resulting in 1 row per count per sample, which is helpful when making weighted proportion plots.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to be expanded.</p> required <code>weight_col</code> <code>str</code> <p>The column name that contains weights (should be int).</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A new pandas dataframe with resampling based on the weights.</p> Source code in <code>neuro_py/stats/stats.py</code> <pre><code>def reindex_df(df: pd.DataFrame, weight_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Expand the dataframe by weights.\n\n    This function expands the dataframe to prepare for resampling,\n    resulting in 1 row per count per sample, which is helpful\n    when making weighted proportion plots.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The pandas dataframe to be expanded.\n    weight_col : str\n        The column name that contains weights (should be int).\n\n    Returns\n    -------\n    pd.DataFrame\n        A new pandas dataframe with resampling based on the weights.\n    \"\"\"\n\n    df = df.reindex(df.index.repeat(df[weight_col])).copy()\n\n    df.reset_index(drop=True, inplace=True)\n\n    return df\n</code></pre>"},{"location":"reference/neuro_py/stats/system_identifier/","title":"neuro_py.stats.system_identifier","text":"<p>Subspace system identification with regularization. Requires scipy to be installed.</p> <p>Implemented by Chris Rayner (2015) dchrisrayner AT gmail DOT com</p> <p>Based on a talk on Subspace System Identification by Tijl De Bie (2005):</p> <p>Assume every output (y_i) is a function of the input (u_i) and the current state x_i of the system, i.e.,    y_i = dot(C, x_i) + dot(D, u_i) Also assume the system state evolves after every input:    x_(i+1) = dot(A, x_i) + dot(B, u_i) This is a linear dynamical system.</p>"},{"location":"reference/neuro_py/stats/system_identifier/#neuro_py.stats.system_identifier.SystemIdentifier","title":"<code>SystemIdentifier</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple Subspace System Identifier.</p> <p>This class identifies a linear dynamical system based on given input and output data using subspace methods.</p> <p>Parameters:</p> Name Type Description Default <code>U</code> <code>ndarray</code> <p>An n-by-d matrix of control inputs.</p> required <code>Y</code> <code>ndarray</code> <p>An n-by-D matrix of output observations.</p> required <code>statedim</code> <code>int</code> <p>The dimension of the internal state variable.</p> required <code>reg</code> <code>float</code> <p>Regularization parameter (default is None, which is set to 0).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>A</code> <code>ndarray</code> <p>State transition matrix.</p> <code>B</code> <code>ndarray</code> <p>Control input matrix.</p> <code>C</code> <code>ndarray</code> <p>Output matrix.</p> <code>D</code> <code>ndarray</code> <p>Feedforward matrix.</p> Source code in <code>neuro_py/stats/system_identifier.py</code> <pre><code>class SystemIdentifier(object):\n    \"\"\"\n    Simple Subspace System Identifier.\n\n    This class identifies a linear dynamical system based on given input and output data using subspace methods.\n\n    Parameters\n    ----------\n    U : np.ndarray\n        An n-by-d matrix of control inputs.\n    Y : np.ndarray\n        An n-by-D matrix of output observations.\n    statedim : int\n        The dimension of the internal state variable.\n    reg : float, optional\n        Regularization parameter (default is None, which is set to 0).\n\n    Attributes\n    ----------\n    A : np.ndarray\n        State transition matrix.\n    B : np.ndarray\n        Control input matrix.\n    C : np.ndarray\n        Output matrix.\n    D : np.ndarray\n        Feedforward matrix.\n    \"\"\"\n\n    def __init__(\n        self,\n        U: np.ndarray,\n        Y: np.ndarray,\n        statedim: int,\n        reg: Union[float, None] = None,\n    ):\n        if np.size(np.shape(U)) == 1:\n            U = np.reshape(U, (-1, 1))\n        if np.size(np.shape(Y)) == 1:\n            Y = np.reshape(Y, (-1, 1))\n        if reg is None:\n            reg = 0\n\n        yDim = np.size(Y, 1)\n        uDim = np.size(U, 1)\n\n        self.output_size = np.size(Y, 1)  # placeholder\n\n        # number of samples of past/future we'll mash together into a 'state'\n        width = 1\n        # total number of past/future pairings we get as a result\n        K = np.size(U, 0) - 2 * width + 1\n\n        # build hankel matrices containing pasts and futures\n        U_p = np.array([np.ravel(U[t : t + width]) for t in range(K)]).T\n        U_f = np.array([np.ravel(U[t + width : t + 2 * width]) for t in range(K)]).T\n        Y_p = np.array([np.ravel(Y[t : t + width]) for t in range(K)]).T\n        Y_f = np.array([np.ravel(Y[t + width : t + 2 * width]) for t in range(K)]).T\n\n        # solve the eigenvalue problem\n        YfUfT = np.dot(Y_f, U_f.T)\n        YfUpT = np.dot(Y_f, U_p.T)\n        YfYpT = np.dot(Y_f, Y_p.T)\n        UfUpT = np.dot(U_f, U_p.T)\n        UfYpT = np.dot(U_f, Y_p.T)\n        UpYpT = np.dot(U_p, Y_p.T)\n        F = sparse.bmat(\n            [\n                [None, YfUfT, YfUpT, YfYpT],\n                [YfUfT.T, None, UfUpT, UfYpT],\n                [YfUpT.T, UfUpT.T, None, UpYpT],\n                [YfYpT.T, UfYpT.T, UpYpT.T, None],\n            ]\n        )\n        Ginv = sparse.bmat(\n            [\n                [np.linalg.pinv(np.dot(Y_f, Y_f.T)), None, None, None],\n                [None, np.linalg.pinv(np.dot(U_f, U_f.T)), None, None],\n                [None, None, np.linalg.pinv(np.dot(U_p, U_p.T)), None],\n                [None, None, None, np.linalg.pinv(np.dot(Y_p, Y_p.T))],\n            ]\n        )\n        F = F - sparse.eye(sp.size(F, 0)) * reg\n\n        # Take smallest eigenvalues\n        _, W = sparse_linalg.eigs(Ginv.dot(F), k=statedim, which=\"SR\")\n\n        # State sequence is a weighted combination of the past\n        W_U_p = W[width * (yDim + uDim) : width * (yDim + uDim + uDim), :]\n        W_Y_p = W[width * (yDim + uDim + uDim) :, :]\n        X_hist = np.dot(W_U_p.T, U_p) + np.dot(W_Y_p.T, Y_p)\n\n        # Regress; trim inputs to match the states we retrieved\n        R = np.concatenate((X_hist[:, :-1], U[width:-width].T), 0)\n        L = np.concatenate((X_hist[:, 1:], Y[width:-width].T), 0)\n        RRi = np.linalg.pinv(np.dot(R, R.T))\n        RL = np.dot(R, L.T)\n        Sys = np.dot(RRi, RL).T\n        self.A = Sys[:statedim, :statedim]\n        self.B = Sys[:statedim, statedim:]\n        self.C = Sys[statedim:, :statedim]\n        self.D = Sys[statedim:, statedim:]\n\n    def __str__(self) -&gt; str:\n        return \"Linear Dynamical System\"\n\n    def predict(self, U: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Predict output given the control inputs.\n\n        Parameters\n        ----------\n        U : np.ndarray\n            Control inputs, shape (n_samples, n_controls).\n\n        Returns\n        -------\n        np.ndarray\n            Predicted outputs, shape (n_samples, n_outputs).\n        \"\"\"\n        # If U is a vector, reshape it\n        if np.size(np.shape(U)) == 1:\n            U = np.reshape(U, (-1, 1))\n\n        # assume some random initial state\n        X = np.reshape(np.random.randn(np.size(self.A, 1)), (1, -1))\n\n        # intitial output\n        Y = np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, U[0]), (1, -1))\n\n        # generate next state\n        X = np.concatenate(\n            (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, U[0]), (1, -1)))\n        )\n\n        # and so forth\n        for u in U[1:]:\n            Y = np.concatenate(\n                (Y, np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, u), (1, -1)))\n            )\n            X = np.concatenate(\n                (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, u), (1, -1)))\n            )\n\n        return Y\n</code></pre>"},{"location":"reference/neuro_py/stats/system_identifier/#neuro_py.stats.system_identifier.SystemIdentifier.predict","title":"<code>predict(U)</code>","text":"<p>Predict output given the control inputs.</p> <p>Parameters:</p> Name Type Description Default <code>U</code> <code>ndarray</code> <p>Control inputs, shape (n_samples, n_controls).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted outputs, shape (n_samples, n_outputs).</p> Source code in <code>neuro_py/stats/system_identifier.py</code> <pre><code>def predict(self, U: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Predict output given the control inputs.\n\n    Parameters\n    ----------\n    U : np.ndarray\n        Control inputs, shape (n_samples, n_controls).\n\n    Returns\n    -------\n    np.ndarray\n        Predicted outputs, shape (n_samples, n_outputs).\n    \"\"\"\n    # If U is a vector, reshape it\n    if np.size(np.shape(U)) == 1:\n        U = np.reshape(U, (-1, 1))\n\n    # assume some random initial state\n    X = np.reshape(np.random.randn(np.size(self.A, 1)), (1, -1))\n\n    # intitial output\n    Y = np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, U[0]), (1, -1))\n\n    # generate next state\n    X = np.concatenate(\n        (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, U[0]), (1, -1)))\n    )\n\n    # and so forth\n    for u in U[1:]:\n        Y = np.concatenate(\n            (Y, np.reshape(np.dot(self.C, X[-1]) + np.dot(self.D, u), (1, -1)))\n        )\n        X = np.concatenate(\n            (X, np.reshape(np.dot(self.A, X[-1]) + np.dot(self.B, u), (1, -1)))\n        )\n\n    return Y\n</code></pre>"},{"location":"reference/neuro_py/stats/system_identifier/#neuro_py.stats.system_identifier.ideal_data","title":"<code>ideal_data(num, dimU, dimY, dimX, noise=1.0)</code>","text":"<p>Generate linear system data.</p> <p>This function creates randomized linear system matrices and simulates a linear system with specified dimensions. The resulting output data includes added noise.</p> <p>Parameters:</p> Name Type Description Default <code>num</code> <code>int</code> <p>Number of time points (samples).</p> required <code>dimU</code> <code>int</code> <p>Dimensionality of the input (control inputs).</p> required <code>dimY</code> <code>int</code> <p>Dimensionality of the output.</p> required <code>dimX</code> <code>int</code> <p>Dimensionality of the state.</p> required <code>noise</code> <code>float</code> <p>Standard deviation of the noise added to the output (default: 1.0).</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>U : np.ndarray     Random input data of shape (num, dimU). Y : np.ndarray     Output data of shape (num, dimY) with added noise.</p> Source code in <code>neuro_py/stats/system_identifier.py</code> <pre><code>def ideal_data(\n    num: int, dimU: int, dimY: int, dimX: int, noise: float = 1.0\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate linear system data.\n\n    This function creates randomized linear system matrices and simulates a linear\n    system with specified dimensions. The resulting output data includes added noise.\n\n    Parameters\n    ----------\n    num : int\n        Number of time points (samples).\n    dimU : int\n        Dimensionality of the input (control inputs).\n    dimY : int\n        Dimensionality of the output.\n    dimX : int\n        Dimensionality of the state.\n    noise : float\n        Standard deviation of the noise added to the output (default: 1.0).\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        U : np.ndarray\n            Random input data of shape (num, dimU).\n        Y : np.ndarray\n            Output data of shape (num, dimY) with added noise.\n    \"\"\"\n    # generate randomized linear system matrices\n    A = np.random.randn(dimX, dimX)\n    B = np.random.randn(dimX, dimU)\n    C = np.random.randn(dimY, dimX)\n    D = np.random.randn(dimY, dimU)\n\n    # make sure state evolution is stable\n    U, S, V = np.linalg.svd(A)\n    A = np.dot(U, np.dot(np.lib.diag(S / max(S)), V))\n    U, S, V = np.linalg.svd(B)\n    S2 = np.zeros((np.size(U, 1), np.size(V, 0)))\n    S2[:, : np.size(U, 1)] = np.lib.diag(S / max(S))\n    B = np.dot(U, np.dot(S2, V))\n\n    # random input\n    U = np.random.randn(num, dimU)\n\n    # initial state\n    X = np.reshape(np.random.randn(dimX), (1, -1))\n\n    # initial output\n    Y = np.reshape(np.dot(C, X[-1]) + np.dot(D, U[0]), (1, -1))\n\n    # generate next state\n    X = np.concatenate((X, np.reshape(np.dot(A, X[-1]) + np.dot(B, U[0]), (1, -1))))\n\n    # and so forth\n    for u in U[1:]:\n        Y = np.concatenate((Y, np.reshape(np.dot(C, X[-1]) + np.dot(D, u), (1, -1))))\n        X = np.concatenate((X, np.reshape(np.dot(A, X[-1]) + np.dot(B, u), (1, -1))))\n\n    return U, Y + np.random.randn(num, dimY) * noise\n</code></pre>"},{"location":"reference/neuro_py/tuning/","title":"neuro_py.tuning","text":""},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap","title":"<code>SpatialMap</code>","text":"<p>               Bases: <code>NDimensionalBinner</code></p> <p>SpatialMap: make a spatial map tuning curve     maps timestamps or continuous signals onto positions</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>object</code> <p>Position data (nelpy.AnalogSignal or nel.PositionArray).</p> required <code>st</code> <code>object</code> <p>Spike train data (nelpy.SpikeTrain or nelpy.AnalogSignal).</p> required <code>speed</code> <code>Optional[object]</code> <p>Speed data (nelpy.AnalogSignal), recommended input: from non-epoched data.</p> <code>None</code> <code>dim</code> <code>Optional[int]</code> <p>Dimension of the map (1 or 2) deprecated.</p> <code>None</code> <code>dir_epoch</code> <code>Optional[object]</code> <p>Epochs of the running direction, for linear data (nelpy.Epoch) deprecated.</p> <code>None</code> <code>speed_thres</code> <code>Union[int, float]</code> <p>Speed threshold for running. Default is 4.</p> <code>4</code> <code>s_binsize</code> <code>Union[int, float, List[Union[int, float]], ndarray]</code> <p>Bin size for the spatial map. Can be a single value (used for all dimensions) or an array/list with bin sizes for each dimension. Default is 3.</p> <code>3</code> <code>x_minmax</code> <code>Optional[List[Union[int, float]]]</code> <p>Min and max x values for the spatial map.</p> <code>None</code> <code>y_minmax</code> <code>Optional[List[Union[int, float]]]</code> <p>Min and max y values for the spatial map.</p> <code>None</code> <code>dim_minmax</code> <code>Optional[List[List[Union[int, float]]]]</code> <p>Min and max values for each dimension. Should be a list of [min, max] pairs, one for each dimension. If provided, takes precedence over x_minmax and y_minmax. Example: [[0, 100], [-50, 50], [0, 200]] for 3D data.</p> <code>None</code> <code>tuning_curve_sigma</code> <code>Union[int, float, List[Union[int, float]], ndarray]</code> <p>Sigma for the tuning curve. Can be a single value (used for all dimensions) or an array/list with sigma values for each dimension. Default is 3.</p> <code>3</code> <code>smooth_mode</code> <code>str</code> <p>Mode for smoothing curve (str) reflect, constant, nearest, mirror, wrap. Default is \"reflect\".</p> <code>'reflect'</code> <code>min_duration</code> <code>float</code> <p>Minimum duration for a tuning curve. Default is 0.1.</p> <code>0.1</code> <code>minbgrate</code> <code>Union[int, float]</code> <p>Minimum firing rate for tuning curve; will set to this if lower. Default is 0.</p> <code>0</code> <code>n_shuff</code> <code>int</code> <p>Number of position shuffles for spatial information. Default is 500.</p> <code>500</code> <code>parallel_shuff</code> <code>bool</code> <p>Parallelize shuffling. Default is True.</p> <code>True</code> <code>place_field_thres</code> <code>Union[int, float]</code> <p>Percent of continuous region of peak firing rate. Default is 0.2.</p> <code>0.2</code> <code>place_field_min_size</code> <code>Optional[Union[int, float]]</code> <p>Minimum size of place field (cm).</p> <code>None</code> <code>place_field_max_size</code> <code>Optional[Union[int, float]]</code> <p>Maximum size of place field (cm).</p> <code>None</code> <code>place_field_min_peak</code> <code>Union[int, float]</code> <p>Minimum peak rate of place field. Default is 3.</p> <code>3</code> <code>place_field_sigma</code> <code>Union[int, float]</code> <p>Extra smoothing sigma to apply before field detection. Default is 2.</p> <code>2</code> <code>max_gap</code> <code>float</code> <p>Maximum gap size (in seconds) to interpolate over. Default is 0.1.</p> <code>0.1</code> <p>Attributes:</p> Name Type Description <code>tc</code> <code>TuningCurve</code> <p>Tuning curves.</p> <code>st_run</code> <code>SpikeTrain</code> <p>Spike train restricted to running epochs.</p> <code>bst_run</code> <code>binnedSpikeTrain</code> <p>Binned spike train restricted to running epochs.</p> <code>speed</code> <code>Optional[AnalogSignal]</code> <p>Speed data.</p> <code>run_epochs</code> <code>EpochArray</code> <p>Running epochs.</p> <code>_min_allowed_gap</code> <code>float</code> <p>Computed minimum allowed value for <code>max_gap</code> (seconds). This is calculated as (1/pos.fs) * (1 + tol) and is used when a user supplies a <code>max_gap</code> smaller than the sampling interval; in that case <code>self.max_gap</code> will be clamped to this value.</p> Notes <p>Place field detector (.find_fields()) is sensitive to many parameters. For 2D, it is highly recommended to have good environmental sampling. In brief testing with 300cm linear track, optimal 1D parameters were:     place_field_min_size=15     place_field_max_size=None     place_field_min_peak=3     place_field_sigma=None     place_field_thres=.33</p> TODO <p>Place field detector currently collects field width and peak rate for peak place field. In the future, these should be stored for all sub fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import nelpy as nel\n&gt;&gt;&gt; from neuro_py.tuning.maps import SpatialMap\n&gt;&gt;&gt; # Create synthetic position and spike data\n&gt;&gt;&gt; pos = nel.AnalogSignalArray(data=np.random.rand(2, 1000)*20, timestamps=np.linspace(0, 100, 1000))\n&gt;&gt;&gt; st = nel.SpikeTrainArray(time=np.sort(np.random.rand(10, 1000), axis=1), fs=1000.0)\n&gt;&gt;&gt; # Create a spatial map with 3 cm bins\n&gt;&gt;&gt; spatial_map = SpatialMap(pos=pos, st=st, s_binsize=3)\n&gt;&gt;&gt; print(spatial_map)\n&lt;TuningCurve2D at 0x21ea37a9110&gt; with shape (10, 7, 7)\n</code></pre> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>class SpatialMap(NDimensionalBinner):\n    \"\"\"\n    SpatialMap: make a spatial map tuning curve\n        maps timestamps or continuous signals onto positions\n\n    Parameters\n    ----------\n    pos : object\n        Position data (nelpy.AnalogSignal or nel.PositionArray).\n    st : object\n        Spike train data (nelpy.SpikeTrain or nelpy.AnalogSignal).\n    speed : Optional[object]\n        Speed data (nelpy.AnalogSignal), recommended input: from non-epoched data.\n    dim : Optional[int]\n        Dimension of the map (1 or 2) *deprecated*.\n    dir_epoch : Optional[object]\n        Epochs of the running direction, for linear data (nelpy.Epoch) *deprecated*.\n    speed_thres : Union[int, float], optional\n        Speed threshold for running. Default is 4.\n    s_binsize : Union[int, float, List[Union[int, float]], np.ndarray], optional\n        Bin size for the spatial map. Can be a single value (used for all dimensions)\n        or an array/list with bin sizes for each dimension. Default is 3.\n    x_minmax : Optional[List[Union[int, float]]], optional\n        Min and max x values for the spatial map.\n    y_minmax : Optional[List[Union[int, float]]], optional\n        Min and max y values for the spatial map.\n    dim_minmax : Optional[List[List[Union[int, float]]]], optional\n        Min and max values for each dimension. Should be a list of [min, max] pairs,\n        one for each dimension. If provided, takes precedence over x_minmax and y_minmax.\n        Example: [[0, 100], [-50, 50], [0, 200]] for 3D data.\n    tuning_curve_sigma : Union[int, float, List[Union[int, float]], np.ndarray], optional\n        Sigma for the tuning curve. Can be a single value (used for all dimensions)\n        or an array/list with sigma values for each dimension. Default is 3.\n    smooth_mode : str, optional\n        Mode for smoothing curve (str) reflect, constant, nearest, mirror, wrap. Default is \"reflect\".\n    min_duration : float, optional\n        Minimum duration for a tuning curve. Default is 0.1.\n    minbgrate : Union[int, float], optional\n        Minimum firing rate for tuning curve; will set to this if lower. Default is 0.\n    n_shuff : int, optional\n        Number of position shuffles for spatial information. Default is 500.\n    parallel_shuff : bool, optional\n        Parallelize shuffling. Default is True.\n    place_field_thres : Union[int, float], optional\n        Percent of continuous region of peak firing rate. Default is 0.2.\n    place_field_min_size : Optional[Union[int, float]]\n        Minimum size of place field (cm).\n    place_field_max_size : Optional[Union[int, float]]\n        Maximum size of place field (cm).\n    place_field_min_peak : Union[int, float], optional\n        Minimum peak rate of place field. Default is 3.\n    place_field_sigma : Union[int, float], optional\n        Extra smoothing sigma to apply before field detection. Default is 2.\n    max_gap : float, optional\n        Maximum gap size (in seconds) to interpolate over. Default is 0.1.\n\n    Attributes\n    ----------\n    tc : nelpy.TuningCurve\n        Tuning curves.\n    st_run : nelpy.SpikeTrain\n        Spike train restricted to running epochs.\n    bst_run : nelpy.binnedSpikeTrain\n        Binned spike train restricted to running epochs.\n    speed : Optional[nnelpy.AnalogSignal]\n        Speed data.\n    run_epochs : nelpy.EpochArray\n        Running epochs.\n    _min_allowed_gap : float\n        Computed minimum allowed value for `max_gap` (seconds). This is\n        calculated as (1/pos.fs) * (1 + tol) and is used when a user\n        supplies a `max_gap` smaller than the sampling interval; in that\n        case `self.max_gap` will be clamped to this value.\n\n    Notes\n    -----\n    Place field detector (.find_fields()) is sensitive to many parameters.\n    For 2D, it is highly recommended to have good environmental sampling.\n    In brief testing with 300cm linear track, optimal 1D parameters were:\n        place_field_min_size=15\n        place_field_max_size=None\n        place_field_min_peak=3\n        place_field_sigma=None\n        place_field_thres=.33\n\n    TODO\n    ----\n    Place field detector currently collects field width and peak rate for peak place field.\n    In the future, these should be stored for all sub fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import nelpy as nel\n    &gt;&gt;&gt; from neuro_py.tuning.maps import SpatialMap\n    &gt;&gt;&gt; # Create synthetic position and spike data\n    &gt;&gt;&gt; pos = nel.AnalogSignalArray(data=np.random.rand(2, 1000)*20, timestamps=np.linspace(0, 100, 1000))\n    &gt;&gt;&gt; st = nel.SpikeTrainArray(time=np.sort(np.random.rand(10, 1000), axis=1), fs=1000.0)\n    &gt;&gt;&gt; # Create a spatial map with 3 cm bins\n    &gt;&gt;&gt; spatial_map = SpatialMap(pos=pos, st=st, s_binsize=3)\n    &gt;&gt;&gt; print(spatial_map)\n    &lt;TuningCurve2D at 0x21ea37a9110&gt; with shape (10, 7, 7)\n    \"\"\"\n\n    def __init__(\n        self,\n        pos: object,\n        st: object,\n        speed: Optional[object] = None,\n        dim: Optional[int] = None,  # deprecated\n        dir_epoch: Optional[object] = None,  # deprecated\n        speed_thres: Union[int, float] = 4,\n        s_binsize: Union[int, float, List[Union[int, float]], np.ndarray] = 3,\n        tuning_curve_sigma: Union[int, float, List[Union[int, float]], np.ndarray] = 3,\n        x_minmax: Optional[List[Union[int, float]]] = None,\n        y_minmax: Optional[List[Union[int, float]]] = None,\n        dim_minmax: Optional[List[List[Union[int, float]]]] = None,\n        smooth_mode: str = \"reflect\",\n        min_duration: float = 0.1,\n        minbgrate: Union[int, float] = 0,\n        n_shuff: int = 500,\n        parallel_shuff: bool = True,\n        place_field_thres: Union[int, float] = 0.2,\n        place_field_min_size: Optional[Union[int, float]] = None,\n        place_field_max_size: Optional[Union[int, float]] = None,\n        place_field_min_peak: Union[int, float] = 3,\n        place_field_sigma: Union[int, float] = 2,\n        max_gap: float = 0.1,\n    ) -&gt; None:\n        # Initialize the parent class\n        super().__init__()\n\n        # add all the inputs to self\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n\n        # Handle s_binsize input: normalize to array format\n        self.dim = pos.n_signals\n        if np.isscalar(s_binsize):\n            # Single value: use for all dimensions\n            self.s_binsize_array = np.full(self.dim, s_binsize)\n        else:\n            # Array/list: convert to numpy array\n            self.s_binsize_array = np.asarray(s_binsize)\n            if len(self.s_binsize_array) != self.dim:\n                raise ValueError(\n                    f\"Length of s_binsize array ({len(self.s_binsize_array)}) must match \"\n                    f\"number of position dimensions ({self.dim})\"\n                )\n\n        # Keep original s_binsize for backward compatibility in some methods\n        if np.isscalar(s_binsize):\n            self.s_binsize = s_binsize\n        else:\n            # For backward compatibility, use the first dimension's bin size\n            self.s_binsize = self.s_binsize_array[0]\n\n        # Handle dim_minmax input: normalize min/max values for each dimension\n        if dim_minmax is not None:\n            # Convert to numpy array for easier handling\n            self.dim_minmax_array = np.asarray(dim_minmax)\n            if self.dim_minmax_array.shape != (self.dim, 2):\n                raise ValueError(\n                    f\"dim_minmax must be a list of [min, max] pairs with shape ({self.dim}, 2), \"\n                    f\"got shape {self.dim_minmax_array.shape}\"\n                )\n            # Override x_minmax and y_minmax if provided\n            if self.dim &gt;= 1:\n                self.x_minmax = list(self.dim_minmax_array[0])\n            if self.dim &gt;= 2:\n                self.y_minmax = list(self.dim_minmax_array[1])\n        else:\n            # Create dim_minmax_array from existing x_minmax, y_minmax, or auto-determine\n            self.dim_minmax_array = np.zeros((self.dim, 2))\n            for dim_idx in range(self.dim):\n                if dim_idx == 0 and self.x_minmax is not None:\n                    self.dim_minmax_array[dim_idx] = self.x_minmax\n                elif dim_idx == 1 and self.y_minmax is not None:\n                    self.dim_minmax_array[dim_idx] = self.y_minmax\n                else:\n                    # Auto-determine min/max for this dimension\n                    self.dim_minmax_array[dim_idx, 0] = np.floor(\n                        np.nanmin(pos.data[dim_idx, :])\n                    )\n                    self.dim_minmax_array[dim_idx, 1] = np.ceil(\n                        np.nanmax(pos.data[dim_idx, :])\n                    )\n\n        # Handle tuning_curve_sigma input: normalize to array format\n        if np.isscalar(tuning_curve_sigma):\n            # Single value: use for all dimensions\n            self.tuning_curve_sigma_array = np.full(self.dim, tuning_curve_sigma)\n        else:\n            # Array/list: convert to numpy array\n            self.tuning_curve_sigma_array = np.asarray(tuning_curve_sigma)\n            if len(self.tuning_curve_sigma_array) != self.dim:\n                raise ValueError(\n                    f\"Length of tuning_curve_sigma array ({len(self.tuning_curve_sigma_array)}) must match \"\n                    f\"number of position dimensions ({self.dim})\"\n                )\n\n        # Keep original tuning_curve_sigma for backward compatibility in some methods\n        if np.isscalar(tuning_curve_sigma):\n            self.tuning_curve_sigma = tuning_curve_sigma\n        else:\n            # For backward compatibility, use the first dimension's sigma\n            self.tuning_curve_sigma = self.tuning_curve_sigma_array[0]\n\n        # Verify inputs: make sure pos and st are nelpy objects\n        if not isinstance(\n            pos, (nel.core._analogsignalarray.AnalogSignalArray, nel.core.PositionArray)\n        ):\n            raise TypeError(\"pos must be nelpy.AnalogSignal or nelpy.PositionArray\")\n        if not isinstance(\n            st,\n            (\n                nel.core._eventarray.SpikeTrainArray,\n                nel.core._analogsignalarray.AnalogSignalArray,\n            ),\n        ):\n            raise TypeError(\n                \"st must be nelpy.SpikeTrain or nelpy.BinnedSpikeTrainArray\"\n            )\n\n        # check data is not empty\n        if pos.isempty or st.isempty:\n            raise ValueError(\"pos and st must not be empty\")\n\n        # check if pos all nan\n        if np.all(np.isnan(pos.data)):\n            raise ValueError(\"Position data cannot contain all NaN values\")\n\n        # Ensure max_gap is not smaller than the position sampling interval\n        # (max_gap is in seconds; pos.fs is samples per second).\n        # Use a small tolerance when computing the minimum allowed gap so\n        # floating point rounding of pos timestamps doesn't cause spurious\n        # failures. If the user provided a smaller max_gap, clamp it up and\n        # warn rather than raising an exception to preserve backward\n        # compatibility and avoid breaking existing tests.\n        tol_for_min_gap = 1e-3\n        min_gap = 1.0 / pos.fs\n        min_allowed = min_gap * (1.0 + tol_for_min_gap)\n        # expose the computed minimum allowed gap on the instance\n        self._min_allowed_gap = float(min_allowed)\n        if self.max_gap &lt; min_allowed:\n            logging.warning(\n                \"Provided max_gap (%s) is smaller than the position sampling interval (%s); \"\n                \"clamping max_gap to %s\",\n                self.max_gap,\n                min_gap,\n                min_allowed,\n            )\n            # Mutate the value used internally so subsequent non-gap interval logic is safe\n            self.max_gap = float(min_allowed)\n\n        # get speed and running epochs (highly recommended you calculate\n        #   speed before hand on non epoched data)\n        if speed_thres &gt; 0:\n            if self.speed is None:\n                self.speed = nel.utils.ddt_asa(\n                    self.pos, smooth=True, sigma=0.1, norm=True\n                )\n\n            self.run_epochs = nel.utils.get_run_epochs(\n                self.speed, v1=self.speed_thres, v2=self.speed_thres\n            ).merge()\n        else:\n            self.run_epochs = self.pos.support.copy()\n\n        # Narrow run_epochs to only the continuous (non-gap) segments of the\n        # position trace so that later interpolation can safely use\n        # np.interp without masking across large dropouts. We build epochs\n        # from contiguous position timestamps (gaps &lt;= max_gap) and then\n        # intersect those with the existing run_epochs.\n        # mask out NaN samples across any dimension\n        mask = ~np.isnan(self.pos.data).any(axis=0)\n        ts = self.pos.abscissa_vals[mask]\n        if ts.size &gt; 0:\n            tol = 1e-3\n            thresh = self.max_gap * (1.0 + tol)\n\n            # find large gaps in the (clean) timestamp vector\n            diffs = np.diff(ts)\n            gap_idx = np.where(diffs &gt; thresh)[0]\n\n            # segment start/end indices in ts\n            seg_starts_idx = np.concatenate(([0], gap_idx + 1))\n            seg_ends_idx = np.concatenate((gap_idx, [len(ts) - 1]))\n\n            starts = ts[seg_starts_idx]\n            ends = ts[seg_ends_idx]\n\n            self.run_epochs = self.run_epochs &amp; nel.EpochArray(\n                np.vstack((starts, ends)).T\n            )\n\n        # calculate maps, 1d, 2d, or N-dimensional\n        self.dim = pos.n_signals\n        if pos.n_signals == 2:\n            self.tc, self.st_run = self.map_2d()\n        elif pos.n_signals == 1:\n            self.tc, self.st_run = self.map_1d()\n        elif pos.n_signals &gt; 2:\n            self.tc, self.st_run = self.map_nd()\n        else:\n            raise ValueError(\"pos dims must be &gt;= 1\")\n\n        # find place fields. Currently only collects metrics from peak field\n        # self.find_fields()\n\n    def map_1d(\n        self,\n        pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n        use_base_class: bool = False,\n    ) -&gt; tuple:\n        \"\"\"Maps 1D data for the spatial tuning curve.\n\n        Parameters\n        ----------\n        pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n            Position data.\n        use_base_class : bool, optional\n            Whether to use the new NDimensionalBinner base class functionality.\n            Default is False to maintain backward compatibility.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # dir_epoch is deprecated input\n        if self.dir_epoch is not None:\n            # warn user\n            logging.warning(\n                \"dir_epoch is deprecated and will be removed. Epoch data by direction prior to calling SpatialMap\"\n            )\n            self.st = self.st[self.dir_epoch]\n            self.pos = self.pos[self.dir_epoch]\n\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Use dimension-specific min/max values (dimension 0 for 1D)\n        x_min, x_max = self.dim_minmax_array[0]\n\n        # Use dimension-specific bin size for x-axis (dimension 0)\n        x_binsize = self.s_binsize_array[0]\n        self.x_edges = np.arange(x_min, x_max + x_binsize, x_binsize)\n\n        # Use new base class method if requested\n        if use_base_class:\n            bin_edges = [self.x_edges]\n            tc, occupancy, ratemap = self.create_nd_tuning_curve(\n                st_data=st_run,\n                pos_data=pos_run,\n                bin_edges=bin_edges,\n                min_duration=self.min_duration,\n                minbgrate=self.minbgrate,\n                tuning_curve_sigma=self.tuning_curve_sigma_array,\n                smooth_mode=self.smooth_mode,\n            )\n            return tc, st_run\n\n        # Original implementation\n        # compute occupancy\n        occupancy = self.compute_occupancy_1d(pos_run)\n\n        # compute ratemap (in Hz)\n        ratemap = self.compute_ratemap_1d(st_run, pos_run, occupancy)\n\n        # enforce minimum background firing rate\n        # background firing rate of xx Hz\n        ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n        # enforce minimum background occupancy\n        for uu in range(st_run.data.shape[0]):\n            ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n        # add to nelpy tuning curve class\n        tc = nel.TuningCurve1D(\n            ratemap=ratemap,\n            extmin=x_min,\n            extmax=x_max,\n        )\n\n        tc._occupancy = occupancy\n\n        if self.tuning_curve_sigma is not None:\n            if self.tuning_curve_sigma &gt; 0:\n                tc.smooth(\n                    sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n                )\n\n        return tc, st_run\n\n    def compute_occupancy_1d(self, pos_run: object) -&gt; np.ndarray:\n        \"\"\"Computes the occupancy for 1D position data.\n\n        Parameters\n        ----------\n        pos_run : object\n            Restricted position data for running.\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy values per bin.\n        \"\"\"\n        occupancy, _ = np.histogram(pos_run.data[0, :], bins=self.x_edges)\n        return occupancy / pos_run.fs\n\n    def compute_ratemap_1d(\n        self, st_run: object, pos_run: object, occupancy: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"Computes the ratemap for 1D data.\n\n        Parameters\n        ----------\n        st_run : object\n            Spike train data restricted to running epochs.\n        pos_run : object\n            Position data restricted to running epochs.\n        occupancy : np.ndarray\n            Occupancy values per bin.\n\n        Returns\n        -------\n        np.ndarray\n            Ratemap values for the given spike and position data.\n        \"\"\"\n        # initialize ratemap\n        ratemap = np.zeros((st_run.data.shape[0], occupancy.shape[0]))\n\n        if st_run.isempty:\n            return ratemap\n\n        mask = ~np.isnan(pos_run.data).any(axis=0)\n        x_pos, ts = (\n            pos_run.data[0, mask],\n            pos_run.abscissa_vals[mask],\n        )\n        # if data to map is spike train (point process)\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            for i in range(st_run.data.shape[0]):\n                # get spike counts in each bin\n                (\n                    ratemap[i, : len(self.x_edges)],\n                    _,\n                ) = np.histogram(\n                    np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                    bins=self.x_edges,\n                )\n\n        # if data to map is analog signal (continuous)\n        elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n            # get x location for every sample and mask invalid positions\n            x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n            positions = x.reshape(-1, 1)\n            valid_mask = ~np.isnan(positions).any(axis=1)\n\n            if np.any(valid_mask):\n                # Use 1D binned statistic to compute mean values per bin\n                pos_valid = positions[valid_mask][:, 0]\n                for uu in range(st_run.data.shape[0]):\n                    vals = st_run.data[uu, valid_mask]\n                    ratemap[uu], _, _ = binned_statistic_dd(\n                        pos_valid,\n                        vals,\n                        statistic=\"mean\",\n                        bins=[self.x_edges],\n                    )\n\n        # divide by occupancy only for spike-train (counts -&gt; rates).\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n        # remove nans and infs\n        bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n        ratemap[bad_idx] = 0\n\n        return ratemap\n\n    def map_2d(\n        self,\n        pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n        use_base_class: bool = False,\n    ) -&gt; tuple:\n        \"\"\"Maps 2D data for the spatial tuning curve.\n\n        Parameters\n        ----------\n        pos : Union[nel.AnalogSignalArray, nel.PositionArray]\n            Position data.\n        use_base_class : bool, optional\n            Whether to use the new NDimensionalBinner base class functionality.\n            Default is False to maintain backward compatibility.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Use dimension-specific min/max values\n        ext_xmin, ext_xmax = self.dim_minmax_array[0]\n        ext_ymin, ext_ymax = self.dim_minmax_array[1]\n\n        # create bin edges\n        # Use dimension-specific bin sizes\n        x_binsize = self.s_binsize_array[0]\n        y_binsize = self.s_binsize_array[1]\n        self.x_edges = np.arange(ext_xmin, ext_xmax + x_binsize, x_binsize)\n        self.y_edges = np.arange(ext_ymin, ext_ymax + y_binsize, y_binsize)\n\n        # Use new base class method if requested\n        if use_base_class:\n            bin_edges = [self.x_edges, self.y_edges]\n            tc, occupancy, ratemap = self.create_nd_tuning_curve(\n                st_data=st_run,\n                pos_data=pos_run,\n                bin_edges=bin_edges,\n                min_duration=self.min_duration,\n                minbgrate=self.minbgrate,\n                tuning_curve_sigma=self.tuning_curve_sigma_array,\n                smooth_mode=self.smooth_mode,\n            )\n            return tc, st_run\n\n        # Original implementation\n        # number of bins in each dimension\n        ext_nx, ext_ny = len(self.x_edges), len(self.y_edges)\n\n        # compute occupancy\n        occupancy = self.compute_occupancy_2d(pos_run)\n\n        # compute ratemap (in Hz)\n        ratemap = self.compute_ratemap_2d(st_run, pos_run, occupancy)\n\n        # enforce minimum background occupancy\n        for uu in range(st_run.data.shape[0]):\n            ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n        # enforce minimum background firing rate\n        # background firing rate of xx Hz\n        ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n        tc = nel.TuningCurve2D(\n            ratemap=ratemap,\n            ext_xmin=ext_xmin,\n            ext_ymin=ext_ymin,\n            ext_xmax=ext_xmax,\n            ext_ymax=ext_ymax,\n            ext_ny=ext_ny,\n            ext_nx=ext_nx,\n        )\n        tc._occupancy = occupancy\n\n        if self.tuning_curve_sigma is not None:\n            if self.tuning_curve_sigma &gt; 0:\n                tc.smooth(\n                    sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n                )\n\n        return tc, st_run\n\n    def compute_occupancy_2d(self, pos_run: object) -&gt; np.ndarray:\n        \"\"\"Computes the occupancy for 2D position data.\n\n        Parameters\n        ----------\n        pos_run : object\n            Restricted position data for running.\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy values per bin.\n        \"\"\"\n        occupancy, _, _ = np.histogram2d(\n            pos_run.data[0, :], pos_run.data[1, :], bins=(self.x_edges, self.y_edges)\n        )\n        return occupancy / pos_run.fs\n\n    def compute_ratemap_2d(\n        self, st_run: object, pos_run: object, occupancy: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"Computes the ratemap for 2D data.\n\n        Parameters\n        ----------\n        st_run : object\n            Spike train data restricted to running epochs.\n        pos_run : object\n            Position data restricted to running epochs.\n        occupancy : np.ndarray\n            Occupancy values per bin.\n\n        Returns\n        -------\n        np.ndarray\n            Ratemap values for the given spike and position data.\n        \"\"\"\n        ratemap = np.zeros(\n            (st_run.data.shape[0], occupancy.shape[0], occupancy.shape[1])\n        )\n        if st_run.isempty:\n            return ratemap\n\n        # remove nans from position data for interpolation\n        mask = ~np.isnan(pos_run.data).any(axis=0)\n        x_pos, y_pos, ts = (\n            pos_run.data[0, mask],\n            pos_run.data[1, mask],\n            pos_run.abscissa_vals[mask],\n        )\n\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            for i in range(st_run.data.shape[0]):\n                ratemap[i, : len(self.x_edges), : len(self.y_edges)], _, _ = (\n                    np.histogram2d(\n                        np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                        np.interp(st_run.data[i], ts, y_pos, left=np.nan, right=np.nan),\n                        bins=(self.x_edges, self.y_edges),\n                    )\n                )\n\n        elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n            x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n            y = np.interp(st_run.abscissa_vals, ts, y_pos, left=np.nan, right=np.nan)\n            positions = np.vstack((x, y)).T\n            valid_mask = ~np.isnan(positions).any(axis=1)\n\n            if np.any(valid_mask):\n                pos_valid = positions[valid_mask]\n                for uu in range(st_run.data.shape[0]):\n                    vals = st_run.data[uu, valid_mask]\n                    ratemap[uu], _, _ = binned_statistic_dd(\n                        pos_valid,\n                        vals,\n                        statistic=\"mean\",\n                        bins=(self.x_edges, self.y_edges),\n                    )\n\n        # divide by occupancy only for spike-train (counts -&gt; rates).\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n        bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n        ratemap[bad_idx] = 0\n\n        return ratemap\n\n    def map_nd(\n        self, pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None\n    ) -&gt; tuple:\n        \"\"\"Maps N-dimensional data for the spatial tuning curve using the base class.\n\n        Parameters\n        ----------\n        pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n            Position data.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Create bin edges for each dimension\n        bin_edges = []\n        for dim_idx in range(self.dim):\n            # Use dimension-specific min/max from dim_minmax_array\n            dim_min, dim_max = self.dim_minmax_array[dim_idx]\n\n            # Use dimension-specific bin size\n            dim_binsize = self.s_binsize_array[dim_idx]\n            edges = np.arange(dim_min, dim_max + dim_binsize, dim_binsize)\n            bin_edges.append(edges)\n\n        # Store bin edges for compatibility with existing code\n        self.x_edges = bin_edges[0]\n        if len(bin_edges) &gt; 1:\n            self.y_edges = bin_edges[1]\n\n        # Use the base class method to create the tuning curve\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n\n        return tc, st_run\n\n    def shuffle_spatial_information(self) -&gt; np.ndarray:\n        \"\"\"Shuffle spatial information and compute p-values for observed vs. null.\n\n        This method creates shuffled coordinates of the position data and computes\n        spatial information for each shuffle. The p-values for the observed\n        spatial information against the null distribution are calculated.\n\n        Returns\n        -------\n        np.ndarray\n            P-values for the spatial information.\n        \"\"\"\n\n        def create_shuffled_coordinates(\n            X: np.ndarray, n_shuff: int = 500\n        ) -&gt; List[np.ndarray]:\n            \"\"\"Create shuffled coordinates by rolling the original coordinates.\n\n            Parameters\n            ----------\n            X : np.ndarray\n                Original position data.\n            n_shuff : int, optional\n                Number of shuffles to create (default is 500).\n\n            Returns\n            -------\n            List[np.ndarray]\n                List of shuffled coordinates.\n            \"\"\"\n            range_ = X.shape[1]\n\n            # if fewer coordinates then shuffles, reduce number of shuffles to n coords\n            n_shuff = np.min([range_, n_shuff])\n\n            surrogate = np.random.choice(\n                np.arange(-range_, range_), size=n_shuff, replace=False\n            )\n            x_temp = []\n            for n in surrogate:\n                x_temp.append(np.roll(X, n, axis=1))\n\n            return x_temp\n\n        def get_spatial_infos(pos_shuff: np.ndarray, ts: np.ndarray, dim: int) -&gt; float:\n            \"\"\"Get spatial information for shuffled position data.\n\n            Parameters\n            ----------\n            pos_shuff : np.ndarray\n                Shuffled position data.\n            ts : np.ndarray\n                Timestamps corresponding to the shuffled data.\n            dim : int\n                Dimension of the spatial data (1 or 2).\n\n            Returns\n            -------\n            float\n                Spatial information calculated from the tuning curve.\n            \"\"\"\n            pos_shuff = nel.AnalogSignalArray(\n                data=pos_shuff,\n                timestamps=ts,\n            )\n            if dim == 1:\n                tc, _ = self.map_1d(pos_shuff)\n                return tc.spatial_information()\n            elif dim == 2:\n                tc, _ = self.map_2d(pos_shuff)\n                return tc.spatial_information()\n            else:\n                tc, _ = self.map_nd(pos_shuff)\n                return tc.spatial_information()\n\n        # Restrict position data to running epochs before creating shuffles so\n        # the null distribution reflects the actual samples used for mapping\n        # (avoid pulling non-running or gap samples into shuffles).\n        pos_run = self.pos[self.run_epochs]\n        pos_data_shuff = create_shuffled_coordinates(pos_run.data, n_shuff=self.n_shuff)\n\n        # construct tuning curves for each position shuffle\n        if self.parallel_shuff:\n            num_cores = multiprocessing.cpu_count()\n            shuffle_spatial_info = Parallel(n_jobs=num_cores)(\n                delayed(get_spatial_infos)(\n                    pos_data_shuff[i], pos_run.abscissa_vals, self.dim\n                )\n                for i in range(self.n_shuff)\n            )\n        else:\n            shuffle_spatial_info = [\n                get_spatial_infos(pos_data_shuff[i], pos_run.abscissa_vals, self.dim)\n                for i in range(self.n_shuff)\n            ]\n\n        # calculate p values for the obs vs null\n        _, self.spatial_information_pvalues, self.spatial_information_zscore = (\n            get_significant_events(\n                self.tc.spatial_information(), np.array(shuffle_spatial_info)\n            )\n        )\n\n        return self.spatial_information_pvalues\n\n    def find_fields(self) -&gt; None:\n        \"\"\"Find place fields in the spatial maps.\n\n        This method detects place fields from the spatial maps and calculates\n        their properties, including width, peak firing rate, and a mask for\n        each detected field.\n        \"\"\"\n        from skimage import measure\n\n        field_width = []\n        peak_rate = []\n        mask = []\n\n        if self.place_field_max_size is None and self.dim == 1:\n            # For 1D, use the bin size for dimension 0\n            self.place_field_max_size = self.tc.n_bins * self.s_binsize_array[0]\n        elif self.place_field_max_size is None and self.dim == 2:\n            # For 2D, use the average of both dimensions or the maximum\n            avg_binsize = np.mean(self.s_binsize_array[:2])\n            self.place_field_max_size = self.tc.n_bins * avg_binsize\n\n        if self.dim == 1:\n            # Use bin size for dimension 0 (x-axis)\n            x_binsize = self.s_binsize_array[0]\n            for ratemap_ in self.tc.ratemap:\n                map_fields = fields.map_stats2(\n                    ratemap_,\n                    threshold=self.place_field_thres,\n                    min_size=self.place_field_min_size / x_binsize,\n                    max_size=self.place_field_max_size / x_binsize,\n                    min_peak=self.place_field_min_peak,\n                    sigma=self.place_field_sigma,\n                )\n                if len(map_fields[\"sizes\"]) == 0:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(map_fields[\"fields\"])\n                else:\n                    field_width.append(\n                        np.array(map_fields[\"sizes\"]).max() * len(ratemap_) * x_binsize\n                    )\n                    peak_rate.append(np.array(map_fields[\"peaks\"]).max())\n                    mask.append(map_fields[\"fields\"])\n\n        if self.dim == 2:\n            # Use average of x and y bin sizes for 2D field calculations\n            avg_binsize = np.mean(self.s_binsize_array[:2])\n            for ratemap_ in self.tc.ratemap:\n                peaks = fields.compute_2d_place_fields(\n                    ratemap_,\n                    min_firing_rate=self.place_field_min_peak,\n                    thresh=self.place_field_thres,\n                    min_size=(self.place_field_min_size / avg_binsize),\n                    max_size=(self.place_field_max_size / avg_binsize),\n                    sigma=self.place_field_sigma,\n                )\n                # field coords of fields using contours\n                bc = measure.find_contours(\n                    peaks, 0, fully_connected=\"low\", positive_orientation=\"low\"\n                )\n                if len(bc) == 0:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(peaks)\n                elif np.vstack(bc).shape[0] &lt; 3:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(peaks)\n                else:\n                    field_width.append(np.max(pdist(bc[0], \"euclidean\")) * avg_binsize)\n                    # field_ids = np.unique(peaks)\n                    peak_rate.append(ratemap_[peaks == 1].max())\n                    mask.append(peaks)\n\n        self.tc.field_width = np.array(field_width)\n        self.tc.field_peak_rate = np.array(peak_rate)\n        self.tc.field_mask = np.array(mask)\n        self.tc.n_fields = np.array(\n            [len(np.unique(mask_)) - 1 for mask_ in self.tc.field_mask]\n        )\n\n    def save_mat_file(self, basepath: str, UID: Optional[Any] = None) -&gt; None:\n        \"\"\"Save firing rate map data to a .mat file in MATLAB format.\n\n        The saved file will contain the following variables:\n        - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps.\n        - field: a 1xN cell array containing the field masks, if they exist.\n        - n_fields: the number of fields detected.\n        - size: the width of the detected fields.\n        - peak: the peak firing rate of the detected fields.\n        - occupancy: the occupancy map.\n        - spatial_information: the spatial information of the ratemaps.\n        - spatial_sparsity: the spatial sparsity of the ratemaps.\n        - x_bins: the bin edges for the x-axis of the ratemaps.\n        - y_bins: the bin edges for the y-axis of the ratemaps.\n        - run_epochs: the time points at which the animal was running.\n        - speed: the speed data.\n        - timestamps: the timestamps for the speed data.\n        - pos: the position data.\n\n        The file will be saved to a .mat file with the name `basepath.ratemap.firingRateMap.mat`,\n        where `basepath` is the base path of the data.\n\n        Parameters\n        ----------\n        basepath : str\n            The base path for saving the .mat file.\n        UID : Optional[Any], optional\n            A unique identifier for the data (default is None).\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self.dim == 1:\n            raise ValueError(\"1d storeage not implemented\")\n\n        # set up dict\n        firingRateMap = {}\n\n        # store UID if exist\n        if UID is not None:\n            firingRateMap[\"UID\"] = UID.tolist()\n\n        # set up empty fields for conversion to matlab cell array\n        firingRateMap[\"map\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n        firingRateMap[\"field\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n\n        # Iterate over the ratemaps and store each one in a cell of the cell array\n        for i, ratemap in enumerate(self.tc.ratemap):\n            firingRateMap[\"map\"][i] = ratemap\n\n        # store occupancy\n        firingRateMap[\"occupancy\"] = self.tc.occupancy\n\n        # store bin edges\n        firingRateMap[\"x_bins\"] = self.tc.xbins.tolist()\n        firingRateMap[\"y_bins\"] = self.tc.ybins.tolist()\n\n        # store field mask if exist\n        if hasattr(self.tc, \"field_mask\"):\n            for i, field_mask in enumerate(self.tc.field_mask):\n                firingRateMap[\"field\"][i] = field_mask\n\n            # store field finding info\n            firingRateMap[\"n_fields\"] = self.tc.n_fields.tolist()\n            firingRateMap[\"size\"] = self.tc.field_width.tolist()\n            firingRateMap[\"peak\"] = self.tc.field_peak_rate.tolist()\n\n        # store spatial metrics\n        firingRateMap[\"spatial_information\"] = self.tc.spatial_information().tolist()\n        if hasattr(self, \"spatial_information_pvalues\"):\n            firingRateMap[\"spatial_information_pvalues\"] = (\n                self.spatial_information_pvalues.tolist()\n            )\n        firingRateMap[\"spatial_sparsity\"] = self.tc.spatial_sparsity().tolist()\n\n        # store position speed and timestamps\n        firingRateMap[\"timestamps\"] = self.speed.abscissa_vals.tolist()\n        firingRateMap[\"pos\"] = self.pos.data\n        firingRateMap[\"speed\"] = self.speed.data.tolist()\n        firingRateMap[\"run_epochs\"] = self.run_epochs.time.tolist()\n\n        # store epoch interval\n        firingRateMap[\"epoch_interval\"] = [\n            self.pos.support.start,\n            self.pos.support.stop,\n        ]\n\n        # save matlab file\n        savemat(\n            os.path.join(\n                basepath, os.path.basename(basepath) + \".ratemap.firingRateMap.mat\"\n            ),\n            {\"firingRateMap\": firingRateMap},\n        )\n\n    def _unit_subset(self, unit_list):\n        newtuningcurve = copy.copy(self)\n        newtuningcurve.st = newtuningcurve.st._unit_subset(unit_list)\n        newtuningcurve.st_run = newtuningcurve.st_run._unit_subset(unit_list)\n        newtuningcurve.tc = self.tc._unit_subset(unit_list)\n        return newtuningcurve\n\n    @property\n    def is2d(self):\n        return self.tc.is2d\n\n    @property\n    def occupancy(self):\n        return self.tc._occupancy\n\n    @property\n    def n_units(self):\n        return self.tc.n_units\n\n    @property\n    def shape(self):\n        return self.tc.shape\n\n    def __repr__(self):\n        return self.tc.__repr__()\n\n    @property\n    def isempty(self):\n        return self.tc.isempty\n\n    @property\n    def ratemap(self):\n        return self.tc.ratemap\n\n    def __len__(self):\n        return self.tc.__len__()\n\n    def smooth(self, **kwargs):\n        return self.tc.smooth(**kwargs)\n\n    @property\n    def mean(self):\n        return self.tc.mean\n\n    @property\n    def std(self):\n        return self.tc.std\n\n    @property\n    def max(self):\n        return self.tc.max\n\n    @property\n    def min(self):\n        return self.tc.min\n\n    @property\n    def mask(self):\n        return self.tc.mask\n\n    @property\n    def n_bins(self):\n        return self.tc.n_bins\n\n    @property\n    def n_xbins(self):\n        return self.tc.n_xbins\n\n    @property\n    def n_ybins(self):\n        return self.tc.n_ybins\n\n    @property\n    def xbins(self):\n        return self.tc.xbins\n\n    @property\n    def ybins(self):\n        return self.tc.ybins\n\n    @property\n    def xbin_centers(self):\n        return self.tc.xbin_centers\n\n    @property\n    def ybin_centers(self):\n        return self.tc.ybin_centers\n\n    @property\n    def bin_centers(self):\n        return self.tc.bin_centers\n\n    @property\n    def bins(self):\n        return self.tc.bins\n\n    def normalize(self, **kwargs):\n        return self.tc.normalize(**kwargs)\n\n    @property\n    def spatial_sparsity(self):\n        return self.tc.spatial_sparsity\n\n    @property\n    def spatial_information(self):\n        return self.tc.spatial_information\n\n    @property\n    def information_rate(self):\n        return self.tc.information_rate\n\n    @property\n    def spatial_selectivity(self):\n        return self.tc.spatial_selectivity\n\n    def __sub__(self, other):\n        return self.tc.__sub__(other)\n\n    def __mul__(self, other):\n        return self.tc.__mul__(other)\n\n    def __rmul__(self, other):\n        return self.tc.__rmul__(other)\n\n    def __truediv__(self, other):\n        return self.tc.__truediv__(other)\n\n    def __iter__(self):\n        return self.tc.__iter__()\n\n    def __next__(self):\n        return self.tc.__next__()\n\n    def __getitem__(self, *idx):\n        return self.tc.__getitem__(*idx)\n\n    def _get_peak_firing_order_idx(self):\n        return self.tc._get_peak_firing_order_idx()\n\n    def get_peak_firing_order_ids(self):\n        return self.tc.get_peak_firing_order_ids()\n\n    def _reorder_units_by_idx(self):\n        return self.tc._reorder_units_by_idx()\n\n    def reorder_units_by_ids(self):\n        return self.tc.reorder_units_by_ids()\n\n    def reorder_units(self):\n        return self.tc.reorder_units()\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.compute_occupancy_1d","title":"<code>compute_occupancy_1d(pos_run)</code>","text":"<p>Computes the occupancy for 1D position data.</p> <p>Parameters:</p> Name Type Description Default <code>pos_run</code> <code>object</code> <p>Restricted position data for running.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Occupancy values per bin.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_occupancy_1d(self, pos_run: object) -&gt; np.ndarray:\n    \"\"\"Computes the occupancy for 1D position data.\n\n    Parameters\n    ----------\n    pos_run : object\n        Restricted position data for running.\n\n    Returns\n    -------\n    np.ndarray\n        Occupancy values per bin.\n    \"\"\"\n    occupancy, _ = np.histogram(pos_run.data[0, :], bins=self.x_edges)\n    return occupancy / pos_run.fs\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.compute_occupancy_2d","title":"<code>compute_occupancy_2d(pos_run)</code>","text":"<p>Computes the occupancy for 2D position data.</p> <p>Parameters:</p> Name Type Description Default <code>pos_run</code> <code>object</code> <p>Restricted position data for running.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Occupancy values per bin.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_occupancy_2d(self, pos_run: object) -&gt; np.ndarray:\n    \"\"\"Computes the occupancy for 2D position data.\n\n    Parameters\n    ----------\n    pos_run : object\n        Restricted position data for running.\n\n    Returns\n    -------\n    np.ndarray\n        Occupancy values per bin.\n    \"\"\"\n    occupancy, _, _ = np.histogram2d(\n        pos_run.data[0, :], pos_run.data[1, :], bins=(self.x_edges, self.y_edges)\n    )\n    return occupancy / pos_run.fs\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.compute_ratemap_1d","title":"<code>compute_ratemap_1d(st_run, pos_run, occupancy)</code>","text":"<p>Computes the ratemap for 1D data.</p> <p>Parameters:</p> Name Type Description Default <code>st_run</code> <code>object</code> <p>Spike train data restricted to running epochs.</p> required <code>pos_run</code> <code>object</code> <p>Position data restricted to running epochs.</p> required <code>occupancy</code> <code>ndarray</code> <p>Occupancy values per bin.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Ratemap values for the given spike and position data.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_ratemap_1d(\n    self, st_run: object, pos_run: object, occupancy: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Computes the ratemap for 1D data.\n\n    Parameters\n    ----------\n    st_run : object\n        Spike train data restricted to running epochs.\n    pos_run : object\n        Position data restricted to running epochs.\n    occupancy : np.ndarray\n        Occupancy values per bin.\n\n    Returns\n    -------\n    np.ndarray\n        Ratemap values for the given spike and position data.\n    \"\"\"\n    # initialize ratemap\n    ratemap = np.zeros((st_run.data.shape[0], occupancy.shape[0]))\n\n    if st_run.isempty:\n        return ratemap\n\n    mask = ~np.isnan(pos_run.data).any(axis=0)\n    x_pos, ts = (\n        pos_run.data[0, mask],\n        pos_run.abscissa_vals[mask],\n    )\n    # if data to map is spike train (point process)\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        for i in range(st_run.data.shape[0]):\n            # get spike counts in each bin\n            (\n                ratemap[i, : len(self.x_edges)],\n                _,\n            ) = np.histogram(\n                np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                bins=self.x_edges,\n            )\n\n    # if data to map is analog signal (continuous)\n    elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n        # get x location for every sample and mask invalid positions\n        x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n        positions = x.reshape(-1, 1)\n        valid_mask = ~np.isnan(positions).any(axis=1)\n\n        if np.any(valid_mask):\n            # Use 1D binned statistic to compute mean values per bin\n            pos_valid = positions[valid_mask][:, 0]\n            for uu in range(st_run.data.shape[0]):\n                vals = st_run.data[uu, valid_mask]\n                ratemap[uu], _, _ = binned_statistic_dd(\n                    pos_valid,\n                    vals,\n                    statistic=\"mean\",\n                    bins=[self.x_edges],\n                )\n\n    # divide by occupancy only for spike-train (counts -&gt; rates).\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n    # remove nans and infs\n    bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n    ratemap[bad_idx] = 0\n\n    return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.compute_ratemap_2d","title":"<code>compute_ratemap_2d(st_run, pos_run, occupancy)</code>","text":"<p>Computes the ratemap for 2D data.</p> <p>Parameters:</p> Name Type Description Default <code>st_run</code> <code>object</code> <p>Spike train data restricted to running epochs.</p> required <code>pos_run</code> <code>object</code> <p>Position data restricted to running epochs.</p> required <code>occupancy</code> <code>ndarray</code> <p>Occupancy values per bin.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Ratemap values for the given spike and position data.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_ratemap_2d(\n    self, st_run: object, pos_run: object, occupancy: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Computes the ratemap for 2D data.\n\n    Parameters\n    ----------\n    st_run : object\n        Spike train data restricted to running epochs.\n    pos_run : object\n        Position data restricted to running epochs.\n    occupancy : np.ndarray\n        Occupancy values per bin.\n\n    Returns\n    -------\n    np.ndarray\n        Ratemap values for the given spike and position data.\n    \"\"\"\n    ratemap = np.zeros(\n        (st_run.data.shape[0], occupancy.shape[0], occupancy.shape[1])\n    )\n    if st_run.isempty:\n        return ratemap\n\n    # remove nans from position data for interpolation\n    mask = ~np.isnan(pos_run.data).any(axis=0)\n    x_pos, y_pos, ts = (\n        pos_run.data[0, mask],\n        pos_run.data[1, mask],\n        pos_run.abscissa_vals[mask],\n    )\n\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        for i in range(st_run.data.shape[0]):\n            ratemap[i, : len(self.x_edges), : len(self.y_edges)], _, _ = (\n                np.histogram2d(\n                    np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                    np.interp(st_run.data[i], ts, y_pos, left=np.nan, right=np.nan),\n                    bins=(self.x_edges, self.y_edges),\n                )\n            )\n\n    elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n        x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n        y = np.interp(st_run.abscissa_vals, ts, y_pos, left=np.nan, right=np.nan)\n        positions = np.vstack((x, y)).T\n        valid_mask = ~np.isnan(positions).any(axis=1)\n\n        if np.any(valid_mask):\n            pos_valid = positions[valid_mask]\n            for uu in range(st_run.data.shape[0]):\n                vals = st_run.data[uu, valid_mask]\n                ratemap[uu], _, _ = binned_statistic_dd(\n                    pos_valid,\n                    vals,\n                    statistic=\"mean\",\n                    bins=(self.x_edges, self.y_edges),\n                )\n\n    # divide by occupancy only for spike-train (counts -&gt; rates).\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n    bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n    ratemap[bad_idx] = 0\n\n    return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.find_fields","title":"<code>find_fields()</code>","text":"<p>Find place fields in the spatial maps.</p> <p>This method detects place fields from the spatial maps and calculates their properties, including width, peak firing rate, and a mask for each detected field.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def find_fields(self) -&gt; None:\n    \"\"\"Find place fields in the spatial maps.\n\n    This method detects place fields from the spatial maps and calculates\n    their properties, including width, peak firing rate, and a mask for\n    each detected field.\n    \"\"\"\n    from skimage import measure\n\n    field_width = []\n    peak_rate = []\n    mask = []\n\n    if self.place_field_max_size is None and self.dim == 1:\n        # For 1D, use the bin size for dimension 0\n        self.place_field_max_size = self.tc.n_bins * self.s_binsize_array[0]\n    elif self.place_field_max_size is None and self.dim == 2:\n        # For 2D, use the average of both dimensions or the maximum\n        avg_binsize = np.mean(self.s_binsize_array[:2])\n        self.place_field_max_size = self.tc.n_bins * avg_binsize\n\n    if self.dim == 1:\n        # Use bin size for dimension 0 (x-axis)\n        x_binsize = self.s_binsize_array[0]\n        for ratemap_ in self.tc.ratemap:\n            map_fields = fields.map_stats2(\n                ratemap_,\n                threshold=self.place_field_thres,\n                min_size=self.place_field_min_size / x_binsize,\n                max_size=self.place_field_max_size / x_binsize,\n                min_peak=self.place_field_min_peak,\n                sigma=self.place_field_sigma,\n            )\n            if len(map_fields[\"sizes\"]) == 0:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(map_fields[\"fields\"])\n            else:\n                field_width.append(\n                    np.array(map_fields[\"sizes\"]).max() * len(ratemap_) * x_binsize\n                )\n                peak_rate.append(np.array(map_fields[\"peaks\"]).max())\n                mask.append(map_fields[\"fields\"])\n\n    if self.dim == 2:\n        # Use average of x and y bin sizes for 2D field calculations\n        avg_binsize = np.mean(self.s_binsize_array[:2])\n        for ratemap_ in self.tc.ratemap:\n            peaks = fields.compute_2d_place_fields(\n                ratemap_,\n                min_firing_rate=self.place_field_min_peak,\n                thresh=self.place_field_thres,\n                min_size=(self.place_field_min_size / avg_binsize),\n                max_size=(self.place_field_max_size / avg_binsize),\n                sigma=self.place_field_sigma,\n            )\n            # field coords of fields using contours\n            bc = measure.find_contours(\n                peaks, 0, fully_connected=\"low\", positive_orientation=\"low\"\n            )\n            if len(bc) == 0:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(peaks)\n            elif np.vstack(bc).shape[0] &lt; 3:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(peaks)\n            else:\n                field_width.append(np.max(pdist(bc[0], \"euclidean\")) * avg_binsize)\n                # field_ids = np.unique(peaks)\n                peak_rate.append(ratemap_[peaks == 1].max())\n                mask.append(peaks)\n\n    self.tc.field_width = np.array(field_width)\n    self.tc.field_peak_rate = np.array(peak_rate)\n    self.tc.field_mask = np.array(mask)\n    self.tc.n_fields = np.array(\n        [len(np.unique(mask_)) - 1 for mask_ in self.tc.field_mask]\n    )\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.map_1d","title":"<code>map_1d(pos=None, use_base_class=False)</code>","text":"<p>Maps 1D data for the spatial tuning curve.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Optional[Union[AnalogSignalArray, PositionArray]]</code> <p>Position data.</p> <code>None</code> <code>use_base_class</code> <code>bool</code> <p>Whether to use the new NDimensionalBinner base class functionality. Default is False to maintain backward compatibility.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_1d(\n    self,\n    pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n    use_base_class: bool = False,\n) -&gt; tuple:\n    \"\"\"Maps 1D data for the spatial tuning curve.\n\n    Parameters\n    ----------\n    pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n        Position data.\n    use_base_class : bool, optional\n        Whether to use the new NDimensionalBinner base class functionality.\n        Default is False to maintain backward compatibility.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # dir_epoch is deprecated input\n    if self.dir_epoch is not None:\n        # warn user\n        logging.warning(\n            \"dir_epoch is deprecated and will be removed. Epoch data by direction prior to calling SpatialMap\"\n        )\n        self.st = self.st[self.dir_epoch]\n        self.pos = self.pos[self.dir_epoch]\n\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Use dimension-specific min/max values (dimension 0 for 1D)\n    x_min, x_max = self.dim_minmax_array[0]\n\n    # Use dimension-specific bin size for x-axis (dimension 0)\n    x_binsize = self.s_binsize_array[0]\n    self.x_edges = np.arange(x_min, x_max + x_binsize, x_binsize)\n\n    # Use new base class method if requested\n    if use_base_class:\n        bin_edges = [self.x_edges]\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n        return tc, st_run\n\n    # Original implementation\n    # compute occupancy\n    occupancy = self.compute_occupancy_1d(pos_run)\n\n    # compute ratemap (in Hz)\n    ratemap = self.compute_ratemap_1d(st_run, pos_run, occupancy)\n\n    # enforce minimum background firing rate\n    # background firing rate of xx Hz\n    ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n    # enforce minimum background occupancy\n    for uu in range(st_run.data.shape[0]):\n        ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n    # add to nelpy tuning curve class\n    tc = nel.TuningCurve1D(\n        ratemap=ratemap,\n        extmin=x_min,\n        extmax=x_max,\n    )\n\n    tc._occupancy = occupancy\n\n    if self.tuning_curve_sigma is not None:\n        if self.tuning_curve_sigma &gt; 0:\n            tc.smooth(\n                sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n            )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.map_2d","title":"<code>map_2d(pos=None, use_base_class=False)</code>","text":"<p>Maps 2D data for the spatial tuning curve.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Union[AnalogSignalArray, PositionArray]</code> <p>Position data.</p> <code>None</code> <code>use_base_class</code> <code>bool</code> <p>Whether to use the new NDimensionalBinner base class functionality. Default is False to maintain backward compatibility.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_2d(\n    self,\n    pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n    use_base_class: bool = False,\n) -&gt; tuple:\n    \"\"\"Maps 2D data for the spatial tuning curve.\n\n    Parameters\n    ----------\n    pos : Union[nel.AnalogSignalArray, nel.PositionArray]\n        Position data.\n    use_base_class : bool, optional\n        Whether to use the new NDimensionalBinner base class functionality.\n        Default is False to maintain backward compatibility.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Use dimension-specific min/max values\n    ext_xmin, ext_xmax = self.dim_minmax_array[0]\n    ext_ymin, ext_ymax = self.dim_minmax_array[1]\n\n    # create bin edges\n    # Use dimension-specific bin sizes\n    x_binsize = self.s_binsize_array[0]\n    y_binsize = self.s_binsize_array[1]\n    self.x_edges = np.arange(ext_xmin, ext_xmax + x_binsize, x_binsize)\n    self.y_edges = np.arange(ext_ymin, ext_ymax + y_binsize, y_binsize)\n\n    # Use new base class method if requested\n    if use_base_class:\n        bin_edges = [self.x_edges, self.y_edges]\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n        return tc, st_run\n\n    # Original implementation\n    # number of bins in each dimension\n    ext_nx, ext_ny = len(self.x_edges), len(self.y_edges)\n\n    # compute occupancy\n    occupancy = self.compute_occupancy_2d(pos_run)\n\n    # compute ratemap (in Hz)\n    ratemap = self.compute_ratemap_2d(st_run, pos_run, occupancy)\n\n    # enforce minimum background occupancy\n    for uu in range(st_run.data.shape[0]):\n        ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n    # enforce minimum background firing rate\n    # background firing rate of xx Hz\n    ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n    tc = nel.TuningCurve2D(\n        ratemap=ratemap,\n        ext_xmin=ext_xmin,\n        ext_ymin=ext_ymin,\n        ext_xmax=ext_xmax,\n        ext_ymax=ext_ymax,\n        ext_ny=ext_ny,\n        ext_nx=ext_nx,\n    )\n    tc._occupancy = occupancy\n\n    if self.tuning_curve_sigma is not None:\n        if self.tuning_curve_sigma &gt; 0:\n            tc.smooth(\n                sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n            )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.map_nd","title":"<code>map_nd(pos=None)</code>","text":"<p>Maps N-dimensional data for the spatial tuning curve using the base class.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Optional[Union[AnalogSignalArray, PositionArray]]</code> <p>Position data.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_nd(\n    self, pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None\n) -&gt; tuple:\n    \"\"\"Maps N-dimensional data for the spatial tuning curve using the base class.\n\n    Parameters\n    ----------\n    pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n        Position data.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Create bin edges for each dimension\n    bin_edges = []\n    for dim_idx in range(self.dim):\n        # Use dimension-specific min/max from dim_minmax_array\n        dim_min, dim_max = self.dim_minmax_array[dim_idx]\n\n        # Use dimension-specific bin size\n        dim_binsize = self.s_binsize_array[dim_idx]\n        edges = np.arange(dim_min, dim_max + dim_binsize, dim_binsize)\n        bin_edges.append(edges)\n\n    # Store bin edges for compatibility with existing code\n    self.x_edges = bin_edges[0]\n    if len(bin_edges) &gt; 1:\n        self.y_edges = bin_edges[1]\n\n    # Use the base class method to create the tuning curve\n    tc, occupancy, ratemap = self.create_nd_tuning_curve(\n        st_data=st_run,\n        pos_data=pos_run,\n        bin_edges=bin_edges,\n        min_duration=self.min_duration,\n        minbgrate=self.minbgrate,\n        tuning_curve_sigma=self.tuning_curve_sigma_array,\n        smooth_mode=self.smooth_mode,\n    )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.save_mat_file","title":"<code>save_mat_file(basepath, UID=None)</code>","text":"<p>Save firing rate map data to a .mat file in MATLAB format.</p> <p>The saved file will contain the following variables: - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps. - field: a 1xN cell array containing the field masks, if they exist. - n_fields: the number of fields detected. - size: the width of the detected fields. - peak: the peak firing rate of the detected fields. - occupancy: the occupancy map. - spatial_information: the spatial information of the ratemaps. - spatial_sparsity: the spatial sparsity of the ratemaps. - x_bins: the bin edges for the x-axis of the ratemaps. - y_bins: the bin edges for the y-axis of the ratemaps. - run_epochs: the time points at which the animal was running. - speed: the speed data. - timestamps: the timestamps for the speed data. - pos: the position data.</p> <p>The file will be saved to a .mat file with the name <code>basepath.ratemap.firingRateMap.mat</code>, where <code>basepath</code> is the base path of the data.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for saving the .mat file.</p> required <code>UID</code> <code>Optional[Any]</code> <p>A unique identifier for the data (default is None).</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def save_mat_file(self, basepath: str, UID: Optional[Any] = None) -&gt; None:\n    \"\"\"Save firing rate map data to a .mat file in MATLAB format.\n\n    The saved file will contain the following variables:\n    - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps.\n    - field: a 1xN cell array containing the field masks, if they exist.\n    - n_fields: the number of fields detected.\n    - size: the width of the detected fields.\n    - peak: the peak firing rate of the detected fields.\n    - occupancy: the occupancy map.\n    - spatial_information: the spatial information of the ratemaps.\n    - spatial_sparsity: the spatial sparsity of the ratemaps.\n    - x_bins: the bin edges for the x-axis of the ratemaps.\n    - y_bins: the bin edges for the y-axis of the ratemaps.\n    - run_epochs: the time points at which the animal was running.\n    - speed: the speed data.\n    - timestamps: the timestamps for the speed data.\n    - pos: the position data.\n\n    The file will be saved to a .mat file with the name `basepath.ratemap.firingRateMap.mat`,\n    where `basepath` is the base path of the data.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for saving the .mat file.\n    UID : Optional[Any], optional\n        A unique identifier for the data (default is None).\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if self.dim == 1:\n        raise ValueError(\"1d storeage not implemented\")\n\n    # set up dict\n    firingRateMap = {}\n\n    # store UID if exist\n    if UID is not None:\n        firingRateMap[\"UID\"] = UID.tolist()\n\n    # set up empty fields for conversion to matlab cell array\n    firingRateMap[\"map\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n    firingRateMap[\"field\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n\n    # Iterate over the ratemaps and store each one in a cell of the cell array\n    for i, ratemap in enumerate(self.tc.ratemap):\n        firingRateMap[\"map\"][i] = ratemap\n\n    # store occupancy\n    firingRateMap[\"occupancy\"] = self.tc.occupancy\n\n    # store bin edges\n    firingRateMap[\"x_bins\"] = self.tc.xbins.tolist()\n    firingRateMap[\"y_bins\"] = self.tc.ybins.tolist()\n\n    # store field mask if exist\n    if hasattr(self.tc, \"field_mask\"):\n        for i, field_mask in enumerate(self.tc.field_mask):\n            firingRateMap[\"field\"][i] = field_mask\n\n        # store field finding info\n        firingRateMap[\"n_fields\"] = self.tc.n_fields.tolist()\n        firingRateMap[\"size\"] = self.tc.field_width.tolist()\n        firingRateMap[\"peak\"] = self.tc.field_peak_rate.tolist()\n\n    # store spatial metrics\n    firingRateMap[\"spatial_information\"] = self.tc.spatial_information().tolist()\n    if hasattr(self, \"spatial_information_pvalues\"):\n        firingRateMap[\"spatial_information_pvalues\"] = (\n            self.spatial_information_pvalues.tolist()\n        )\n    firingRateMap[\"spatial_sparsity\"] = self.tc.spatial_sparsity().tolist()\n\n    # store position speed and timestamps\n    firingRateMap[\"timestamps\"] = self.speed.abscissa_vals.tolist()\n    firingRateMap[\"pos\"] = self.pos.data\n    firingRateMap[\"speed\"] = self.speed.data.tolist()\n    firingRateMap[\"run_epochs\"] = self.run_epochs.time.tolist()\n\n    # store epoch interval\n    firingRateMap[\"epoch_interval\"] = [\n        self.pos.support.start,\n        self.pos.support.stop,\n    ]\n\n    # save matlab file\n    savemat(\n        os.path.join(\n            basepath, os.path.basename(basepath) + \".ratemap.firingRateMap.mat\"\n        ),\n        {\"firingRateMap\": firingRateMap},\n    )\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.SpatialMap.shuffle_spatial_information","title":"<code>shuffle_spatial_information()</code>","text":"<p>Shuffle spatial information and compute p-values for observed vs. null.</p> <p>This method creates shuffled coordinates of the position data and computes spatial information for each shuffle. The p-values for the observed spatial information against the null distribution are calculated.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>P-values for the spatial information.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def shuffle_spatial_information(self) -&gt; np.ndarray:\n    \"\"\"Shuffle spatial information and compute p-values for observed vs. null.\n\n    This method creates shuffled coordinates of the position data and computes\n    spatial information for each shuffle. The p-values for the observed\n    spatial information against the null distribution are calculated.\n\n    Returns\n    -------\n    np.ndarray\n        P-values for the spatial information.\n    \"\"\"\n\n    def create_shuffled_coordinates(\n        X: np.ndarray, n_shuff: int = 500\n    ) -&gt; List[np.ndarray]:\n        \"\"\"Create shuffled coordinates by rolling the original coordinates.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Original position data.\n        n_shuff : int, optional\n            Number of shuffles to create (default is 500).\n\n        Returns\n        -------\n        List[np.ndarray]\n            List of shuffled coordinates.\n        \"\"\"\n        range_ = X.shape[1]\n\n        # if fewer coordinates then shuffles, reduce number of shuffles to n coords\n        n_shuff = np.min([range_, n_shuff])\n\n        surrogate = np.random.choice(\n            np.arange(-range_, range_), size=n_shuff, replace=False\n        )\n        x_temp = []\n        for n in surrogate:\n            x_temp.append(np.roll(X, n, axis=1))\n\n        return x_temp\n\n    def get_spatial_infos(pos_shuff: np.ndarray, ts: np.ndarray, dim: int) -&gt; float:\n        \"\"\"Get spatial information for shuffled position data.\n\n        Parameters\n        ----------\n        pos_shuff : np.ndarray\n            Shuffled position data.\n        ts : np.ndarray\n            Timestamps corresponding to the shuffled data.\n        dim : int\n            Dimension of the spatial data (1 or 2).\n\n        Returns\n        -------\n        float\n            Spatial information calculated from the tuning curve.\n        \"\"\"\n        pos_shuff = nel.AnalogSignalArray(\n            data=pos_shuff,\n            timestamps=ts,\n        )\n        if dim == 1:\n            tc, _ = self.map_1d(pos_shuff)\n            return tc.spatial_information()\n        elif dim == 2:\n            tc, _ = self.map_2d(pos_shuff)\n            return tc.spatial_information()\n        else:\n            tc, _ = self.map_nd(pos_shuff)\n            return tc.spatial_information()\n\n    # Restrict position data to running epochs before creating shuffles so\n    # the null distribution reflects the actual samples used for mapping\n    # (avoid pulling non-running or gap samples into shuffles).\n    pos_run = self.pos[self.run_epochs]\n    pos_data_shuff = create_shuffled_coordinates(pos_run.data, n_shuff=self.n_shuff)\n\n    # construct tuning curves for each position shuffle\n    if self.parallel_shuff:\n        num_cores = multiprocessing.cpu_count()\n        shuffle_spatial_info = Parallel(n_jobs=num_cores)(\n            delayed(get_spatial_infos)(\n                pos_data_shuff[i], pos_run.abscissa_vals, self.dim\n            )\n            for i in range(self.n_shuff)\n        )\n    else:\n        shuffle_spatial_info = [\n            get_spatial_infos(pos_data_shuff[i], pos_run.abscissa_vals, self.dim)\n            for i in range(self.n_shuff)\n        ]\n\n    # calculate p values for the obs vs null\n    _, self.spatial_information_pvalues, self.spatial_information_zscore = (\n        get_significant_events(\n            self.tc.spatial_information(), np.array(shuffle_spatial_info)\n        )\n    )\n\n    return self.spatial_information_pvalues\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.calculate_field_centers","title":"<code>calculate_field_centers(rate_map, labels, center_method='maxima')</code>","text":"<p>Finds center of fields at labels.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>labels</code> <code>ndarray</code> <p>Labeled fields.</p> required <code>center_method</code> <code>str</code> <p>Method to calculate the center; either 'maxima' or 'center_of_mass'. Default is 'maxima'.</p> <code>'maxima'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates of the center for each field.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid center_method is provided.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def calculate_field_centers(\n    rate_map: np.ndarray, labels: np.ndarray, center_method: str = \"maxima\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Finds center of fields at labels.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    labels : np.ndarray\n        Labeled fields.\n    center_method : str\n        Method to calculate the center; either 'maxima' or 'center_of_mass'. Default is 'maxima'.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates of the center for each field.\n\n    Raises\n    ------\n    ValueError\n        If an invalid center_method is provided.\n    \"\"\"\n    indices = np.arange(1, np.max(labels) + 1)\n    if center_method == \"maxima\":\n        bc = ndimage.maximum_position(rate_map, labels=labels, index=indices)\n    elif center_method == \"center_of_mass\":\n        bc = ndimage.center_of_mass(rate_map, labels=labels, index=indices)\n    else:\n        raise ValueError(\"invalid center_method flag '{}'\".format(center_method))\n\n    if not bc:\n        # empty list\n        return bc\n\n    bc = np.array(bc)\n    bc[:, [0, 1]] = bc[:, [1, 0]]  # y, x -&gt; x, y\n    return bc\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.compute_2d_place_fields","title":"<code>compute_2d_place_fields(firing_rate, min_firing_rate=1, thresh=0.2, min_size=100, max_size=200, sigma=None, filter_size=3)</code>","text":"<p>Compute place fields from the firing rate.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>2D array of firing rates (NxN).</p> required <code>min_firing_rate</code> <code>float</code> <p>Minimum firing rate in Hz. Default is 1.</p> <code>1</code> <code>thresh</code> <code>float</code> <p>Percentage of local max. Default is 0.2.</p> <code>0.2</code> <code>min_size</code> <code>int</code> <p>Minimum size of place field in pixels. Default is 100.</p> <code>100</code> <code>max_size</code> <code>int</code> <p>Maximum size of place field in pixels. Default is 200.</p> <code>200</code> <code>sigma</code> <code>Optional[float]</code> <p>Standard deviation for Gaussian smoothing. Default is None.</p> <code>None</code> <code>filter_size</code> <code>int</code> <p>Size of the filter used to find local maxima. Default is 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>2D array of receptive fields labeled with unique integers.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_2d_place_fields(\n    firing_rate: np.ndarray,\n    min_firing_rate: float = 1,\n    thresh: float = 0.2,\n    min_size: int = 100,\n    max_size: int = 200,\n    sigma: Optional[float] = None,\n    filter_size: int = 3,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute place fields from the firing rate.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        2D array of firing rates (NxN).\n    min_firing_rate : float, optional\n        Minimum firing rate in Hz. Default is 1.\n    thresh : float, optional\n        Percentage of local max. Default is 0.2.\n    min_size : int, optional\n        Minimum size of place field in pixels. Default is 100.\n    max_size : int, optional\n        Maximum size of place field in pixels. Default is 200.\n    sigma : Optional[float], optional\n        Standard deviation for Gaussian smoothing. Default is None.\n    filter_size : int, optional\n        Size of the filter used to find local maxima. Default is 3.\n\n    Returns\n    -------\n    np.ndarray\n        2D array of receptive fields labeled with unique integers.\n    \"\"\"\n    firing_rate_orig = firing_rate.copy()\n\n    if sigma is not None:\n        firing_rate = ndimage.gaussian_filter(firing_rate, sigma)\n\n    local_maxima_inds = firing_rate == ndimage.maximum_filter(\n        firing_rate, size=filter_size\n    )\n    receptive_fields = np.zeros(firing_rate.shape, dtype=int)\n    n_receptive_fields = 0\n    firing_rate = firing_rate.copy()\n    for local_max in np.flipud(np.sort(firing_rate[local_maxima_inds])):\n        labeled_image, num_labels = ndimage.label(\n            firing_rate &gt; max(local_max * thresh, min_firing_rate)\n        )\n\n        if not num_labels:  # nothing above min_firing_thresh\n            continue\n        for i in range(1, num_labels + 1):\n            image_label = labeled_image == i\n            if local_max in firing_rate[image_label]:\n                break\n            if np.sum(image_label) &gt;= min_size:\n                n_receptive_fields += 1\n                receptive_fields[image_label] = n_receptive_fields\n                firing_rate[image_label] = 0\n\n    receptive_fields = remove_fields_by_area(\n        receptive_fields, int(min_size), maximum_field_area=max_size\n    )\n    if n_receptive_fields &gt; 0:\n        receptive_fields = sort_fields_by_rate(\n            firing_rate_orig, receptive_fields, func=np.max\n        )\n    return receptive_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.compute_crossings","title":"<code>compute_crossings(field_indices)</code>","text":"<p>Compute indices at which a field is entered or exited.</p> <p>Parameters:</p> Name Type Description Default <code>field_indices</code> <code>ndarray</code> <p>1D array, typically obtained with in_field.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Indices at which fields are entered and exited.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_crossings(field_indices: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute indices at which a field is entered or exited.\n\n    Parameters\n    ----------\n    field_indices : np.ndarray\n        1D array, typically obtained with in_field.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Indices at which fields are entered and exited.\n    \"\"\"\n    # make sure to start and end outside fields\n    field_indices = np.concatenate(([0], field_indices.astype(bool).astype(int), [0]))\n    (enter,) = np.where(np.diff(field_indices) == 1)\n    (exit,) = np.where(np.diff(field_indices) == -1)\n    assert len(enter) == len(exit), (len(enter), len(exit))\n    return enter, exit\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.compute_linear_place_fields","title":"<code>compute_linear_place_fields(firing_rate, min_window_size=5, min_firing_rate=1.0, thresh=0.5)</code>","text":"<p>Find consecutive bins where all are &gt;= threshold of local max firing rate and the local max is &gt; min_firing_rate.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>Array of firing rates.</p> required <code>min_window_size</code> <code>int</code> <p>Minimum size of the window. Default is 5.</p> <code>5</code> <code>min_firing_rate</code> <code>float</code> <p>Minimum firing rate to consider a bin. Default is 1.0.</p> <code>1.0</code> <code>thresh</code> <code>float</code> <p>Threshold percentage of local max. Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean array indicating place fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_linear_place_fields(\n    firing_rate: np.ndarray,\n    min_window_size: int = 5,\n    min_firing_rate: float = 1.0,\n    thresh: float = 0.5,\n) -&gt; np.ndarray:\n    \"\"\"\n    Find consecutive bins where all are &gt;= threshold of local max firing rate\n    and the local max is &gt; min_firing_rate.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        Array of firing rates.\n    min_window_size : int, optional\n        Minimum size of the window. Default is 5.\n    min_firing_rate : float, optional\n        Minimum firing rate to consider a bin. Default is 1.0.\n    thresh : float, optional\n        Threshold percentage of local max. Default is 0.5.\n\n    Returns\n    -------\n    np.ndarray\n        Boolean array indicating place fields.\n    \"\"\"\n    is_place_field = np.zeros(len(firing_rate), dtype=\"bool\")\n    for start in range(len(firing_rate) - min_window_size):\n        for fin in range(start + min_window_size, len(firing_rate)):\n            window = firing_rate[start:fin]\n            mm = max(window)\n            if mm &gt; min_firing_rate and all(window &gt; thresh * mm):\n                is_place_field[start:fin] = True\n            else:\n                break\n\n    return is_place_field\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.consecutive","title":"<code>consecutive(array, stepsize)</code>","text":"<p>Splits array when distance between neighboring points is further than the stepsize.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Array to be split.</p> required <code>stepsize</code> <code>float</code> <p>Minimum distance to consider points as separate.</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List of arrays, split when jump greater than stepsize.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def consecutive(array: np.ndarray, stepsize: float) -&gt; List[np.ndarray]:\n    \"\"\"\n    Splits array when distance between neighboring points is further than the stepsize.\n\n    Parameters\n    ----------\n    array : np.ndarray\n        Array to be split.\n    stepsize : float\n        Minimum distance to consider points as separate.\n\n    Returns\n    -------\n    List[np.ndarray]\n        List of arrays, split when jump greater than stepsize.\n    \"\"\"\n    return np.split(array, np.where(np.diff(array) &gt; stepsize)[0] + 1)\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.detect_firing_fields","title":"<code>detect_firing_fields(image_gray, max_sigma=30, log_num_sigma=10, log_thres=0.1, dog_thres=0.1, doh_thres=0.01)</code>","text":"<p>Detect firing fields in a grayscale image using different blob detection methods.</p> <p>Parameters:</p> Name Type Description Default <code>image_gray</code> <code>ndarray</code> <p>Grayscale image to analyze.</p> required <code>max_sigma</code> <code>int</code> <p>The maximum standard deviation for Gaussian filter.</p> <code>30</code> <code>log_num_sigma</code> <code>int</code> <p>The number of sigma values for the Laplacian of Gaussian.</p> <code>10</code> <code>log_thres</code> <code>float</code> <p>Threshold for Laplacian of Gaussian blobs.</p> <code>0.1</code> <code>dog_thres</code> <code>float</code> <p>Threshold for Difference of Gaussian blobs.</p> <code>0.1</code> <code>doh_thres</code> <code>float</code> <p>Threshold for Determinant of Hessian blobs.</p> <code>0.01</code> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def detect_firing_fields(\n    image_gray: np.ndarray,\n    max_sigma: int = 30,\n    log_num_sigma: int = 10,\n    log_thres: float = 0.1,\n    dog_thres: float = 0.1,\n    doh_thres: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Detect firing fields in a grayscale image using different blob detection methods.\n\n    Parameters\n    ----------\n    image_gray : np.ndarray\n        Grayscale image to analyze.\n    max_sigma : int, optional\n        The maximum standard deviation for Gaussian filter.\n    log_num_sigma : int, optional\n        The number of sigma values for the Laplacian of Gaussian.\n    log_thres : float, optional\n        Threshold for Laplacian of Gaussian blobs.\n    dog_thres : float, optional\n        Threshold for Difference of Gaussian blobs.\n    doh_thres : float, optional\n        Threshold for Determinant of Hessian blobs.\n    \"\"\"\n    from skimage.feature import blob_dog, blob_doh, blob_log\n\n    plt.imshow(image_gray, origin=\"lower\")\n\n    blobs_log = blob_log(\n        image_gray, max_sigma=max_sigma, num_sigma=log_num_sigma, threshold=log_thres\n    )\n    # Compute radii in the 3rd column.\n    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n\n    blobs_dog = blob_dog(image_gray, max_sigma=max_sigma, threshold=dog_thres)\n    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n\n    blobs_doh = blob_doh(image_gray, max_sigma=max_sigma, threshold=doh_thres)\n\n    blobs_list = [blobs_log, blobs_dog, blobs_doh]\n    colors = [\"yellow\", \"lime\", \"red\"]\n    titles = [\n        \"Laplacian of Gaussian\",\n        \"Difference of Gaussian\",\n        \"Determinant of Hessian\",\n    ]\n    sequence = zip(blobs_list, colors, titles)\n\n    fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n    ax = axes.ravel()\n\n    for idx, (blobs, color, title) in enumerate(sequence):\n        ax[idx].set_title(title)\n        ax[idx].imshow(image_gray, interpolation=\"nearest\", origin=\"lower\")\n        for blob in blobs:\n            y, x, r = blob\n            c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n            ax[idx].add_patch(c)\n        ax[idx].set_axis_off()\n\n    plt.tight_layout()\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.distance_to_edge_function","title":"<code>distance_to_edge_function(x_c, y_c, field, box_size, interpolation='linear', contour_level=0.8)</code>","text":"<p>Returns a function which, for a given angle, returns the distance to the edge of the field from the center.</p> <p>Parameters:</p> Name Type Description Default <code>x_c</code> <code>float</code> <p>X-coordinate of the center.</p> required <code>y_c</code> <code>float</code> <p>Y-coordinate of the center.</p> required <code>field</code> <code>ndarray</code> <p>2D array with ones at field bins and zeros elsewhere.</p> required <code>box_size</code> <code>Tuple[float, float]</code> <p>Size of the box (arena).</p> required <code>interpolation</code> <code>str</code> <p>Type of interpolation to use. Default is \"linear\".</p> <code>'linear'</code> <code>contour_level</code> <code>float</code> <p>Contour level to use for finding edges. Default is 0.8.</p> <code>0.8</code> <p>Returns:</p> Type Description <code>Callable[[float], float]</code> <p>A function that takes an angle and returns the distance to the edge of the field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def distance_to_edge_function(\n    x_c: float,\n    y_c: float,\n    field: np.ndarray,\n    box_size: Tuple[float, float],\n    interpolation: str = \"linear\",\n    contour_level: float = 0.8,\n) -&gt; Callable[[float], float]:\n    \"\"\"\n    Returns a function which, for a given angle, returns the distance to\n    the edge of the field from the center.\n\n    Parameters\n    ----------\n    x_c : float\n        X-coordinate of the center.\n    y_c : float\n        Y-coordinate of the center.\n    field : np.ndarray\n        2D array with ones at field bins and zeros elsewhere.\n    box_size : Tuple[float, float]\n        Size of the box (arena).\n    interpolation : str, optional\n        Type of interpolation to use. Default is \"linear\".\n    contour_level : float, optional\n        Contour level to use for finding edges. Default is 0.8.\n\n    Returns\n    -------\n    Callable[[float], float]\n        A function that takes an angle and returns the distance to the edge of the field.\n    \"\"\"\n    from skimage import measure\n\n    contours = measure.find_contours(field, level=contour_level)\n\n    box_dim = np.array(box_size)\n    edge_x, edge_y = (contours[0] * box_dim / (np.array(field.shape) - (1, 1))).T\n\n    # # angle between 0 and 2\\pi\n    angles = np.arctan2((edge_y - y_c), (edge_x - x_c)) % (2 * np.pi)\n    a_sort = np.argsort(angles)\n    angles = angles[a_sort]\n    edge_x = edge_x[a_sort]\n    edge_y = edge_y[a_sort]\n\n    # # Fill in edge values for the interpolation\n    pad_a = np.pad(angles, 2, mode=\"linear_ramp\", end_values=(0, 2 * np.pi))\n    ev_x = (edge_x[0] + edge_x[-1]) / 2\n    pad_x = np.pad(edge_x, 2, mode=\"linear_ramp\", end_values=ev_x)\n    ev_y = (edge_y[0] + edge_y[-1]) / 2\n    pad_y = np.pad(edge_y, 2, mode=\"linear_ramp\", end_values=ev_y)\n\n    if interpolation == \"cubic\":\n        mask = np.where(np.diff(pad_a) == 0)\n        pad_a = np.delete(pad_a, mask)\n        pad_x = np.delete(pad_x, mask)\n        pad_y = np.delete(pad_y, mask)\n\n    x_func = interp1d(pad_a, pad_x, kind=interpolation)\n    y_func = interp1d(pad_a, pad_y, kind=interpolation)\n\n    def dist_func(angle: float) -&gt; float:\n        \"\"\"\n        Computes the distance from the center to the edge of the field at a given angle.\n\n        Parameters\n        ----------\n        angle : float\n            Angle in radians.\n\n        Returns\n        -------\n        float\n            Distance to the edge of the field from the center.\n        \"\"\"\n        x = x_func(angle)\n        y = y_func(angle)\n        dist = np.sqrt((x - x_c) ** 2 + (y - y_c) ** 2)\n        return dist\n\n    return dist_func\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.find_field","title":"<code>find_field(firing_rate, threshold)</code>","text":"<p>Find the field in the firing rate that exceeds the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>Array of firing rates.</p> required <code>threshold</code> <code>float</code> <p>Threshold for detection.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing the image label and the same label.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_field(\n    firing_rate: np.ndarray, threshold: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the field in the firing rate that exceeds the threshold.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        Array of firing rates.\n    threshold : float\n        Threshold for detection.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple containing the image label and the same label.\n    \"\"\"\n    mm = np.max(firing_rate)\n\n    labeled_image, num_labels = ndimage.label(firing_rate &gt; threshold)\n    for i in range(1, num_labels + 1):\n        image_label = labeled_image == i\n        if mm in firing_rate[image_label]:\n            return image_label, image_label\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.find_field2","title":"<code>find_field2(firing_rate, thresh)</code>","text":"<p>Find the field in a 1D firing rate array that exceeds the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>1D array of firing rates.</p> required <code>thresh</code> <code>float</code> <p>Threshold for detection.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing two boolean arrays: the first indicates the buffer area and the second indicates the field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_field2(\n    firing_rate: np.ndarray, thresh: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the field in a 1D firing rate array that exceeds the threshold.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        1D array of firing rates.\n    thresh : float\n        Threshold for detection.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple containing two boolean arrays:\n        the first indicates the buffer area and the second indicates the field.\n    \"\"\"\n    firing_rate = np.array(firing_rate)\n    imm = np.argmax(firing_rate)\n    mm = np.max(firing_rate)\n    # TODO: make more efficient by using argmax instead of where()[0]\n    first = np.where(np.diff(firing_rate[:imm]) &lt; 0)[0]\n    if len(first) == 0:\n        first = 0\n    else:\n        first = first[-1] + 2\n\n    last = np.where(np.diff(firing_rate[imm:]) &gt; 0)[0]\n\n    if len(last) == 0:\n        last = len(firing_rate)\n    else:\n        last = last[0] + imm + 1\n    field_buffer = np.zeros(firing_rate.shape, dtype=\"bool\")\n    field_buffer[first:last] = True\n    field = field_buffer &amp; (firing_rate &gt; thresh * mm)\n\n    return field_buffer, field\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.find_fields_1d","title":"<code>find_fields_1d(tuning, hz_thresh=5, min_length=1, max_length=20, max_mean_firing=10)</code>","text":"<p>Finds the location of maximum spiking.</p> <p>Parameters:</p> Name Type Description Default <code>tuning</code> <code>List[ndarray]</code> <p>Each inner array contains the tuning curves for an individual neuron.</p> required <code>hz_thresh</code> <code>float</code> <p>Any bin with firing above this value is considered to be part of a field. Default is 5.</p> <code>5</code> <code>min_length</code> <code>int</code> <p>Minimum length of field (in tuning curve bin units). Default is 1.</p> <code>1</code> <code>max_length</code> <code>int</code> <p>Maximum length of field (in tuning curve bin units). Default is 20.</p> <code>20</code> <code>max_mean_firing</code> <code>float</code> <p>Only neurons with a mean firing rate less than this amount are considered for having place fields. Default is 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>Where the key is the neuron number (int), and the value is a list of arrays (int) that are indices into the tuning curve where the field occurs. Each inner array contains the indices for a given place field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_fields_1d(\n    tuning: List[np.ndarray],\n    hz_thresh: float = 5,\n    min_length: int = 1,\n    max_length: int = 20,\n    max_mean_firing: float = 10,\n) -&gt; dict:\n    \"\"\"\n    Finds the location of maximum spiking.\n\n    Parameters\n    ----------\n    tuning : List[np.ndarray]\n        Each inner array contains the tuning curves for an individual neuron.\n    hz_thresh : float, optional\n        Any bin with firing above this value is considered to be part of a field. Default is 5.\n    min_length : int, optional\n        Minimum length of field (in tuning curve bin units). Default is 1.\n    max_length : int, optional\n        Maximum length of field (in tuning curve bin units). Default is 20.\n    max_mean_firing : float, optional\n        Only neurons with a mean firing rate less than this amount are considered for\n        having place fields. Default is 10.\n\n    Returns\n    -------\n    dict\n        Where the key is the neuron number (int), and the value is a list of arrays (int)\n        that are indices into the tuning curve where the field occurs.\n        Each inner array contains the indices for a given place field.\n    \"\"\"\n    fields = []\n    for neuron_tc in tuning:\n        if np.mean(neuron_tc) &lt; max_mean_firing:\n            neuron_field = np.zeros(neuron_tc.shape[0])\n            for i, this_bin in enumerate(neuron_tc):\n                if this_bin &gt; hz_thresh:\n                    neuron_field[i] = 1\n            fields.append(neuron_field)\n        else:\n            fields.append(np.array([]))\n\n    fields_idx = dict()\n    for i, neuron_fields in enumerate(fields):\n        field_idx = np.nonzero(neuron_fields)[0]\n        fields_idx[i] = consecutive(field_idx, stepsize=1)\n\n    with_fields = dict()\n    for key in fields_idx:\n        for field in fields_idx[key]:\n            if len(field) &gt; max_length:\n                continue\n            elif min_length &lt;= len(field):\n                with_fields[key] = fields_idx[key]\n                continue\n    return with_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.find_peaks","title":"<code>find_peaks(image, filter_size=3)</code>","text":"<p>Find peaks sorted by distance from the center of the image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The input image.</p> required <code>filter_size</code> <code>int</code> <p>The size of the filter used to find peaks.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates for peaks in the image as [row, column].</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_peaks(image: np.ndarray, filter_size: int = 3) -&gt; np.ndarray:\n    \"\"\"\n    Find peaks sorted by distance from the center of the image.\n\n    Parameters\n    ----------\n    image : np.ndarray\n        The input image.\n    filter_size : int, optional\n        The size of the filter used to find peaks.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates for peaks in the image as [row, column].\n    \"\"\"\n    image = image.copy()\n    image[~np.isfinite(image)] = 0\n    image_max = ndimage.maximum_filter(image, size=filter_size)\n    is_maxima = image == image_max\n    labels, num_objects = ndimage.label(is_maxima)\n    indices = np.arange(1, num_objects + 1)\n    peaks = ndimage.maximum_position(image, labels=labels, index=indices)\n    peaks = np.array(peaks)\n    center = (np.array(image.shape) - 1) / 2\n    distances = np.linalg.norm(peaks - center, axis=1)\n    peaks = peaks[distances.argsort()]\n    return peaks\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.map_pass_to_unit_circle","title":"<code>map_pass_to_unit_circle(x, y, t, x_c, y_c, field=None, box_size=None, dist_func=None)</code>","text":"<p>Uses three vectors {v, p, q} to map the passes to the unit circle. v is the average velocity vector of the pass, p is the vector from the position (x, y) to the center of the field, and q is the vector from the center to the edge through (x, y).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>X-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Y-coordinates.</p> required <code>t</code> <code>ndarray</code> <p>Time data.</p> required <code>x_c</code> <code>float</code> <p>X-coordinate of the center of the field.</p> required <code>y_c</code> <code>float</code> <p>Y-coordinate of the center of the field.</p> required <code>field</code> <code>Optional[ndarray]</code> <p>2D array indicating the location of the field.</p> <code>None</code> <code>box_size</code> <code>Optional[Tuple[float, float]]</code> <p>Size of the box (arena).</p> <code>None</code> <code>dist_func</code> <code>Optional[Callable[[float], float]]</code> <p>Function that computes distance to bump edge from center. Default is distance_to_edge_function with linear interpolation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray]</code> <p>r : Array of distances to origin on unit circle. theta : Array of angles to axis defined by mean velocity vector. pdcd : Array of distances to peak projected onto the current direction. pdmd : Array of distances to peak projected onto the mean direction.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If neither dist_func nor both field and box_size are provided.</p> References: <p>.. [1] Jeewajee A, Barry C, Douchamps V, Manson D, Lever C, Burgess N. Theta        phase precession of grid and place cell firing in open environments.        Philos Trans R Soc Lond B Biol Sci. 2013 Dec 23;369(1635):20120532</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def map_pass_to_unit_circle(\n    x: np.ndarray,\n    y: np.ndarray,\n    t: np.ndarray,\n    x_c: float,\n    y_c: float,\n    field: Optional[np.ndarray] = None,\n    box_size: Optional[Tuple[float, float]] = None,\n    dist_func: Optional[Callable[[float], float]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Uses three vectors {v, p, q} to map the passes to the unit circle. v\n    is the average velocity vector of the pass, p is the vector from the\n    position (x, y) to the center of the field, and q is the vector from the\n    center to the edge through (x, y).\n\n    Parameters\n    ----------\n    x : np.ndarray\n        X-coordinates.\n    y : np.ndarray\n        Y-coordinates.\n    t : np.ndarray\n        Time data.\n    x_c : float\n        X-coordinate of the center of the field.\n    y_c : float\n        Y-coordinate of the center of the field.\n    field : Optional[np.ndarray], optional\n        2D array indicating the location of the field.\n    box_size : Optional[Tuple[float, float]], optional\n        Size of the box (arena).\n    dist_func : Optional[Callable[[float], float]], optional\n        Function that computes distance to bump edge from center. Default is\n        distance_to_edge_function with linear interpolation.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n        r : Array of distances to origin on unit circle.\n        theta : Array of angles to axis defined by mean velocity vector.\n        pdcd : Array of distances to peak projected onto the current direction.\n        pdmd : Array of distances to peak projected onto the mean direction.\n\n    Raises\n    ------\n    AssertionError\n        If neither dist_func nor both field and box_size are provided.\n\n    References:\n    -----------\n    .. [1] Jeewajee A, Barry C, Douchamps V, Manson D, Lever C, Burgess N. Theta\n           phase precession of grid and place cell firing in open environments.\n           Philos Trans R Soc Lond B Biol Sci. 2013 Dec 23;369(1635):20120532\n    \"\"\"\n    if dist_func is None:\n        assert field is not None and box_size is not None, (\n            'either provide \"dist_func\" or \"field\" and \"box_size\"'\n        )\n        dist_func = distance_to_edge_function(\n            x_c, y_c, field, box_size, interpolation=\"linear\"\n        )\n    pos = np.array((x, y))\n\n    # vector from pos to center p\n    p_vec = ((x_c, y_c) - pos.T).T\n    # angle between x-axis and negative vector p\n    angle = (np.arctan2(p_vec[1], p_vec[0]) + np.pi) % (2 * np.pi)\n    # distance from center to edge at each angle\n    q = dist_func(angle)\n    # distance from center to pos\n    p = np.linalg.norm(p_vec, axis=0)\n    # r-coordinate on unit circle\n    r = p / q\n\n    dpos = np.gradient(pos, axis=1)\n    dt = np.gradient(t)\n    velocity = np.divide(dpos, dt)\n\n    # mean velocity vector v\n    mean_velocity = np.average(velocity, axis=1)\n    # angle on unit circle, run is rotated such that mean velocity vector\n    # is toward positive x\n    theta = (angle - np.arctan2(mean_velocity[1], mean_velocity[0])) % (2 * np.pi)\n\n    w_pdcd = angle - np.arctan2(velocity[1], velocity[0])\n    pdcd = r * np.cos(w_pdcd)\n\n    w_pdmd = angle - np.arctan2(mean_velocity[1], mean_velocity[0])\n    pdmd = r * np.cos(w_pdmd)\n    return r, theta, pdcd, pdmd\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.map_stats2","title":"<code>map_stats2(firing_rate, threshold=0.1, min_size=5, max_size=None, min_peak=1.0, sigma=None, min_peak_to_trough_ratio=2.0)</code>","text":"<p>Map statistics of firing rate fields.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>1D array of firing rates.</p> required <code>threshold</code> <code>float</code> <p>Threshold for field detection. Default is 0.1.</p> <code>0.1</code> <code>min_size</code> <code>int</code> <p>Minimum size of detected fields. Default is 5.</p> <code>5</code> <code>max_size</code> <code>Optional[int]</code> <p>Maximum size of detected fields. Default is None, which sets it to the length of firing_rate.</p> <code>None</code> <code>min_peak</code> <code>float</code> <p>Minimum peak firing rate to consider a field valid. Default is 1.0.</p> <code>1.0</code> <code>sigma</code> <code>Optional[float]</code> <p>Standard deviation for Gaussian smoothing. Default is None.</p> <code>None</code> <code>min_peak_to_trough_ratio</code> <code>float</code> <p>Minimum ratio between peak and trough values within a detected field. Default is 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>A dictionary containing the sizes, peaks, means, and fields of detected firing rate fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def map_stats2(\n    firing_rate: np.ndarray,\n    threshold: float = 0.1,\n    min_size: int = 5,\n    max_size: Optional[int] = None,\n    min_peak: float = 1.0,\n    sigma: Optional[float] = None,\n    min_peak_to_trough_ratio: float = 2.0,\n) -&gt; Dict[str, List[float]]:\n    \"\"\"\n    Map statistics of firing rate fields.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        1D array of firing rates.\n    threshold : float, optional\n        Threshold for field detection. Default is 0.1.\n    min_size : int, optional\n        Minimum size of detected fields. Default is 5.\n    max_size : Optional[int], optional\n        Maximum size of detected fields. Default is None, which sets it to the length of firing_rate.\n    min_peak : float, optional\n        Minimum peak firing rate to consider a field valid. Default is 1.0.\n    sigma : Optional[float], optional\n        Standard deviation for Gaussian smoothing. Default is None.\n    min_peak_to_trough_ratio : float, optional\n        Minimum ratio between peak and trough values within a detected field. Default is 2.0.\n\n    Returns\n    -------\n    Dict[str, List[float]]\n        A dictionary containing the sizes, peaks, means, and fields of detected firing rate fields.\n\n    \"\"\"\n    if sigma is not None:\n        firing_rate = ndimage.gaussian_filter1d(firing_rate, sigma)\n\n    if max_size is None:\n        max_size = len(firing_rate)\n\n    firing_rate = firing_rate.copy()\n    firing_rate = firing_rate - np.min(firing_rate)\n    out = dict(sizes=list(), peaks=list(), means=list())\n    out[\"fields\"] = np.zeros(firing_rate.shape)\n    field_counter = 1\n    while True:\n        peak = np.max(firing_rate)\n        if peak &lt; min_peak:\n            break\n        field_buffer, field = find_field(firing_rate, threshold)\n        field_size = np.sum(field)\n        if (\n            (field_size &gt; min_size)\n            and (field_size &lt; max_size)\n            and (\n                np.max(firing_rate[field])\n                &gt; (min_peak_to_trough_ratio * np.min(firing_rate[field_buffer]))\n            )\n        ):\n            out[\"fields\"][field] = field_counter\n            out[\"sizes\"].append(float(field_size) / len(firing_rate))\n            out[\"peaks\"].append(peak)\n            out[\"means\"].append(np.mean(firing_rate[field]))\n            field_counter += 1\n        firing_rate[field_buffer] = 0\n\n    return out\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.remove_fields_by_area","title":"<code>remove_fields_by_area(fields, minimum_field_area, maximum_field_area=None)</code>","text":"<p>Sets fields below minimum area to zero, measured as the number of bins in a field.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>ndarray</code> <p>The fields.</p> required <code>minimum_field_area</code> <code>int</code> <p>Minimum field area (number of bins in a field).</p> required <code>maximum_field_area</code> <code>Optional[int]</code> <p>Maximum field area (number of bins in a field). Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Fields with number of bins below minimum_field_area are set to zero.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If minimum_field_area is not an integer.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def remove_fields_by_area(\n    fields: np.ndarray,\n    minimum_field_area: int,\n    maximum_field_area: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Sets fields below minimum area to zero, measured as the number of bins in a field.\n\n    Parameters\n    ----------\n    fields : np.ndarray\n        The fields.\n    minimum_field_area : int\n        Minimum field area (number of bins in a field).\n    maximum_field_area : Optional[int]\n        Maximum field area (number of bins in a field). Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        Fields with number of bins below minimum_field_area are set to zero.\n\n    Raises\n    ------\n    ValueError\n        If minimum_field_area is not an integer.\n    \"\"\"\n    if not isinstance(minimum_field_area, (int, np.integer)):\n        raise ValueError(\"'minimum_field_area' should be int\")\n\n    if maximum_field_area is None:\n        maximum_field_area = len(fields.flatten())\n    ## variant\n    # fields_areas = scipy.ndimage.measurements.sum(\n    #     np.ones_like(fields), fields, index=np.arange(fields.max() + 1))\n    # fields_area = fields_areas[fields]\n    # fields[fields_area &lt; minimum_field_area] = 0\n\n    labels, counts = np.unique(fields, return_counts=True)\n    for lab, count in zip(labels, counts):\n        if lab != 0:\n            if (count &lt; minimum_field_area) | (count &gt; maximum_field_area):\n                fields[fields == lab] = 0\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.separate_fields_by_dilation","title":"<code>separate_fields_by_dilation(rate_map, seed=2.5, sigma=2.5, minimum_field_area=None)</code>","text":"<p>Separates fields by the Laplace of Gaussian (LoG) on the rate map subtracted by a reconstruction of the rate map using dilation.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>seed</code> <code>float</code> <p>Magnitude of dilation.</p> <code>2.5</code> <code>sigma</code> <code>float</code> <p>Standard deviation of Gaussian to separate fields. Default is 2.5.</p> <code>2.5</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> References <p>.. [1] https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_regional_maxima.html</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_dilation(\n    rate_map: np.ndarray,\n    seed: float = 2.5,\n    sigma: float = 2.5,\n    minimum_field_area: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields by the Laplace of Gaussian (LoG)\n    on the rate map subtracted by a reconstruction of the rate map using\n    dilation.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    seed : float\n        Magnitude of dilation.\n    sigma : float\n        Standard deviation of Gaussian to separate fields. Default is 2.5.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n\n    References\n    ----------\n    .. [1] https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_regional_maxima.html\n    \"\"\"\n    from skimage.morphology import reconstruction\n\n    rate_map_norm = (rate_map - rate_map.mean()) / rate_map.std()\n    dilated = reconstruction(rate_map_norm - seed, rate_map_norm, method=\"dilation\")\n    rate_map_reconstructed = rate_map_norm - dilated\n\n    laplacian = ndimage.gaussian_laplace(rate_map_reconstructed, sigma)\n    laplacian[laplacian &gt; 0] = 0\n    fields, _ = ndimage.label(laplacian)\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.separate_fields_by_laplace","title":"<code>separate_fields_by_laplace(rate_map, threshold=0, minimum_field_area=None)</code>","text":"<p>Separates fields using the Laplacian to identify fields separated by a negative second derivative.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>threshold</code> <code>float</code> <p>Value of Laplacian to separate fields by relative to the minima. Should be on the interval 0 to 1, where 0 cuts off at 0 and 1 cuts off at min(laplace(rate_map)). Default is 0.</p> <code>0</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_laplace(\n    rate_map: np.ndarray, threshold: float = 0, minimum_field_area: Optional[int] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields using the Laplacian to identify fields separated by\n    a negative second derivative.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    threshold : float\n        Value of Laplacian to separate fields by relative to the minima.\n        Should be on the interval 0 to 1, where 0 cuts off at 0 and\n        1 cuts off at min(laplace(rate_map)). Default is 0.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n    \"\"\"\n\n    laplacian = ndimage.laplace(rate_map)\n\n    laplacian[laplacian &gt; threshold * np.min(laplacian)] = 0\n\n    # Labels areas of the laplacian not connected by values &gt; 0.\n    fields, _ = ndimage.label(laplacian)\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.separate_fields_by_laplace_of_gaussian","title":"<code>separate_fields_by_laplace_of_gaussian(rate_map, sigma=2, minimum_field_area=None)</code>","text":"<p>Separates fields using the Laplace of Gaussian (LoG) to identify fields separated by a negative second derivative. Works best if no smoothing is applied to the rate map, preferably with interpolated NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>sigma</code> <code>float</code> <p>Standard deviation of Gaussian to separate fields. Default is 2.</p> <code>2</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_laplace_of_gaussian(\n    rate_map: np.ndarray, sigma: float = 2, minimum_field_area: Optional[int] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields using the Laplace of Gaussian (LoG) to identify fields\n    separated by a negative second derivative. Works best if no smoothing is\n    applied to the rate map, preferably with interpolated NaNs.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    sigma : float\n        Standard deviation of Gaussian to separate fields. Default is 2.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n    \"\"\"\n    laplacian = ndimage.gaussian_laplace(rate_map, sigma)\n    laplacian[laplacian &gt; 0] = 0\n\n    # Labels areas of the laplacian not connected by values &gt; 0.\n    fields, _ = ndimage.label(laplacian)\n\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.sort_fields_by_rate","title":"<code>sort_fields_by_rate(rate_map, fields, func=None)</code>","text":"<p>Sort fields by the rate value of each field.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>The rate map.</p> required <code>fields</code> <code>ndarray</code> <p>The fields of the same shape as rate_map.</p> required <code>func</code> <code>Callable</code> <p>Function returning value to sort after, default is np.max.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def sort_fields_by_rate(\n    rate_map: np.ndarray,\n    fields: np.ndarray,\n    func: Optional[Callable[[np.ndarray], Any]] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Sort fields by the rate value of each field.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        The rate map.\n    fields : np.ndarray\n        The fields of the same shape as rate_map.\n    func : Callable, optional\n        Function returning value to sort after, default is np.max.\n\n    Returns\n    -------\n    np.ndarray\n        Sorted fields.\n    \"\"\"\n    indx = np.sort(np.unique(fields.ravel()))\n    func = func or np.max\n    # Sort by largest peak\n    rate_means = ndimage.labeled_comprehension(\n        rate_map, fields, indx, func, np.float64, 0\n    )\n    sort = np.argsort(rate_means)[::-1]\n\n    sorted_fields = np.zeros_like(fields)\n    for indx_i, indx_ in enumerate(indx[sort]):\n        if indx_ == 0:\n            continue\n        sorted_fields[fields == indx_] = np.max(sorted_fields) + 1\n\n    # new rate map with fields &gt; min_size, sorted\n    # sorted_fields = np.zeros_like(fields)\n    # for i in range(indx.max() + 1):\n    #     sorted_fields[fields == sort[i] + 1] = i + 1\n\n    return sorted_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/#neuro_py.tuning.which_field","title":"<code>which_field(x, y, fields, box_size)</code>","text":"<p>Returns which spatial field each (x, y) position is in.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>X-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Y-coordinates, must have the same length as x.</p> required <code>fields</code> <code>ndarray</code> <p>Labeled fields, where each field is defined by an area separated by zeros. The fields are labeled with indices from [1:].</p> required <code>box_size</code> <code>List[float]</code> <p>Extents of the arena.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array-like x and y with fields-labeled indices.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If x and y do not have the same length.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def which_field(\n    x: np.ndarray, y: np.ndarray, fields: np.ndarray, box_size: List[float]\n) -&gt; np.ndarray:\n    \"\"\"\n    Returns which spatial field each (x, y) position is in.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        X-coordinates.\n    y : np.ndarray\n        Y-coordinates, must have the same length as x.\n    fields : np.ndarray\n        Labeled fields, where each field is defined by an area separated by\n        zeros. The fields are labeled with indices from [1:].\n    box_size : List[float]\n        Extents of the arena.\n\n    Returns\n    -------\n    np.ndarray\n        Array-like x and y with fields-labeled indices.\n\n    Raises\n    ------\n    ValueError\n        If x and y do not have the same length.\n    \"\"\"\n    if len(x) != len(y):\n        raise ValueError(\"x and y must have same length\")\n\n    sx, sy = fields.shape\n    # bin sizes\n    dx = box_size[0] / sx\n    dy = box_size[1] / sy\n    x_bins = dx + np.arange(0, box_size[0] + dx, dx)\n    y_bins = dy + np.arange(0, box_size[1] + dx, dy)\n    # x_bins = np.arange(0, box_size[0] + dx, dx)\n    # y_bins = np.arange(0, box_size[1] + dx, dy)\n    ix = np.digitize(x, x_bins)\n    iy = np.digitize(y, y_bins)\n\n    # fix for boundaries:\n    ix[ix == sx] = sx - 1\n    iy[iy == sy] = sy - 1\n    return np.array(fields[ix, iy])\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/","title":"neuro_py.tuning.fields","text":""},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.calculate_field_centers","title":"<code>calculate_field_centers(rate_map, labels, center_method='maxima')</code>","text":"<p>Finds center of fields at labels.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>labels</code> <code>ndarray</code> <p>Labeled fields.</p> required <code>center_method</code> <code>str</code> <p>Method to calculate the center; either 'maxima' or 'center_of_mass'. Default is 'maxima'.</p> <code>'maxima'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates of the center for each field.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid center_method is provided.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def calculate_field_centers(\n    rate_map: np.ndarray, labels: np.ndarray, center_method: str = \"maxima\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Finds center of fields at labels.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    labels : np.ndarray\n        Labeled fields.\n    center_method : str\n        Method to calculate the center; either 'maxima' or 'center_of_mass'. Default is 'maxima'.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates of the center for each field.\n\n    Raises\n    ------\n    ValueError\n        If an invalid center_method is provided.\n    \"\"\"\n    indices = np.arange(1, np.max(labels) + 1)\n    if center_method == \"maxima\":\n        bc = ndimage.maximum_position(rate_map, labels=labels, index=indices)\n    elif center_method == \"center_of_mass\":\n        bc = ndimage.center_of_mass(rate_map, labels=labels, index=indices)\n    else:\n        raise ValueError(\"invalid center_method flag '{}'\".format(center_method))\n\n    if not bc:\n        # empty list\n        return bc\n\n    bc = np.array(bc)\n    bc[:, [0, 1]] = bc[:, [1, 0]]  # y, x -&gt; x, y\n    return bc\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.compute_2d_place_fields","title":"<code>compute_2d_place_fields(firing_rate, min_firing_rate=1, thresh=0.2, min_size=100, max_size=200, sigma=None, filter_size=3)</code>","text":"<p>Compute place fields from the firing rate.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>2D array of firing rates (NxN).</p> required <code>min_firing_rate</code> <code>float</code> <p>Minimum firing rate in Hz. Default is 1.</p> <code>1</code> <code>thresh</code> <code>float</code> <p>Percentage of local max. Default is 0.2.</p> <code>0.2</code> <code>min_size</code> <code>int</code> <p>Minimum size of place field in pixels. Default is 100.</p> <code>100</code> <code>max_size</code> <code>int</code> <p>Maximum size of place field in pixels. Default is 200.</p> <code>200</code> <code>sigma</code> <code>Optional[float]</code> <p>Standard deviation for Gaussian smoothing. Default is None.</p> <code>None</code> <code>filter_size</code> <code>int</code> <p>Size of the filter used to find local maxima. Default is 3.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>2D array of receptive fields labeled with unique integers.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_2d_place_fields(\n    firing_rate: np.ndarray,\n    min_firing_rate: float = 1,\n    thresh: float = 0.2,\n    min_size: int = 100,\n    max_size: int = 200,\n    sigma: Optional[float] = None,\n    filter_size: int = 3,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute place fields from the firing rate.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        2D array of firing rates (NxN).\n    min_firing_rate : float, optional\n        Minimum firing rate in Hz. Default is 1.\n    thresh : float, optional\n        Percentage of local max. Default is 0.2.\n    min_size : int, optional\n        Minimum size of place field in pixels. Default is 100.\n    max_size : int, optional\n        Maximum size of place field in pixels. Default is 200.\n    sigma : Optional[float], optional\n        Standard deviation for Gaussian smoothing. Default is None.\n    filter_size : int, optional\n        Size of the filter used to find local maxima. Default is 3.\n\n    Returns\n    -------\n    np.ndarray\n        2D array of receptive fields labeled with unique integers.\n    \"\"\"\n    firing_rate_orig = firing_rate.copy()\n\n    if sigma is not None:\n        firing_rate = ndimage.gaussian_filter(firing_rate, sigma)\n\n    local_maxima_inds = firing_rate == ndimage.maximum_filter(\n        firing_rate, size=filter_size\n    )\n    receptive_fields = np.zeros(firing_rate.shape, dtype=int)\n    n_receptive_fields = 0\n    firing_rate = firing_rate.copy()\n    for local_max in np.flipud(np.sort(firing_rate[local_maxima_inds])):\n        labeled_image, num_labels = ndimage.label(\n            firing_rate &gt; max(local_max * thresh, min_firing_rate)\n        )\n\n        if not num_labels:  # nothing above min_firing_thresh\n            continue\n        for i in range(1, num_labels + 1):\n            image_label = labeled_image == i\n            if local_max in firing_rate[image_label]:\n                break\n            if np.sum(image_label) &gt;= min_size:\n                n_receptive_fields += 1\n                receptive_fields[image_label] = n_receptive_fields\n                firing_rate[image_label] = 0\n\n    receptive_fields = remove_fields_by_area(\n        receptive_fields, int(min_size), maximum_field_area=max_size\n    )\n    if n_receptive_fields &gt; 0:\n        receptive_fields = sort_fields_by_rate(\n            firing_rate_orig, receptive_fields, func=np.max\n        )\n    return receptive_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.compute_crossings","title":"<code>compute_crossings(field_indices)</code>","text":"<p>Compute indices at which a field is entered or exited.</p> <p>Parameters:</p> Name Type Description Default <code>field_indices</code> <code>ndarray</code> <p>1D array, typically obtained with in_field.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Indices at which fields are entered and exited.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_crossings(field_indices: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute indices at which a field is entered or exited.\n\n    Parameters\n    ----------\n    field_indices : np.ndarray\n        1D array, typically obtained with in_field.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Indices at which fields are entered and exited.\n    \"\"\"\n    # make sure to start and end outside fields\n    field_indices = np.concatenate(([0], field_indices.astype(bool).astype(int), [0]))\n    (enter,) = np.where(np.diff(field_indices) == 1)\n    (exit,) = np.where(np.diff(field_indices) == -1)\n    assert len(enter) == len(exit), (len(enter), len(exit))\n    return enter, exit\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.compute_linear_place_fields","title":"<code>compute_linear_place_fields(firing_rate, min_window_size=5, min_firing_rate=1.0, thresh=0.5)</code>","text":"<p>Find consecutive bins where all are &gt;= threshold of local max firing rate and the local max is &gt; min_firing_rate.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>Array of firing rates.</p> required <code>min_window_size</code> <code>int</code> <p>Minimum size of the window. Default is 5.</p> <code>5</code> <code>min_firing_rate</code> <code>float</code> <p>Minimum firing rate to consider a bin. Default is 1.0.</p> <code>1.0</code> <code>thresh</code> <code>float</code> <p>Threshold percentage of local max. Default is 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean array indicating place fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def compute_linear_place_fields(\n    firing_rate: np.ndarray,\n    min_window_size: int = 5,\n    min_firing_rate: float = 1.0,\n    thresh: float = 0.5,\n) -&gt; np.ndarray:\n    \"\"\"\n    Find consecutive bins where all are &gt;= threshold of local max firing rate\n    and the local max is &gt; min_firing_rate.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        Array of firing rates.\n    min_window_size : int, optional\n        Minimum size of the window. Default is 5.\n    min_firing_rate : float, optional\n        Minimum firing rate to consider a bin. Default is 1.0.\n    thresh : float, optional\n        Threshold percentage of local max. Default is 0.5.\n\n    Returns\n    -------\n    np.ndarray\n        Boolean array indicating place fields.\n    \"\"\"\n    is_place_field = np.zeros(len(firing_rate), dtype=\"bool\")\n    for start in range(len(firing_rate) - min_window_size):\n        for fin in range(start + min_window_size, len(firing_rate)):\n            window = firing_rate[start:fin]\n            mm = max(window)\n            if mm &gt; min_firing_rate and all(window &gt; thresh * mm):\n                is_place_field[start:fin] = True\n            else:\n                break\n\n    return is_place_field\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.consecutive","title":"<code>consecutive(array, stepsize)</code>","text":"<p>Splits array when distance between neighboring points is further than the stepsize.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Array to be split.</p> required <code>stepsize</code> <code>float</code> <p>Minimum distance to consider points as separate.</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List of arrays, split when jump greater than stepsize.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def consecutive(array: np.ndarray, stepsize: float) -&gt; List[np.ndarray]:\n    \"\"\"\n    Splits array when distance between neighboring points is further than the stepsize.\n\n    Parameters\n    ----------\n    array : np.ndarray\n        Array to be split.\n    stepsize : float\n        Minimum distance to consider points as separate.\n\n    Returns\n    -------\n    List[np.ndarray]\n        List of arrays, split when jump greater than stepsize.\n    \"\"\"\n    return np.split(array, np.where(np.diff(array) &gt; stepsize)[0] + 1)\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.detect_firing_fields","title":"<code>detect_firing_fields(image_gray, max_sigma=30, log_num_sigma=10, log_thres=0.1, dog_thres=0.1, doh_thres=0.01)</code>","text":"<p>Detect firing fields in a grayscale image using different blob detection methods.</p> <p>Parameters:</p> Name Type Description Default <code>image_gray</code> <code>ndarray</code> <p>Grayscale image to analyze.</p> required <code>max_sigma</code> <code>int</code> <p>The maximum standard deviation for Gaussian filter.</p> <code>30</code> <code>log_num_sigma</code> <code>int</code> <p>The number of sigma values for the Laplacian of Gaussian.</p> <code>10</code> <code>log_thres</code> <code>float</code> <p>Threshold for Laplacian of Gaussian blobs.</p> <code>0.1</code> <code>dog_thres</code> <code>float</code> <p>Threshold for Difference of Gaussian blobs.</p> <code>0.1</code> <code>doh_thres</code> <code>float</code> <p>Threshold for Determinant of Hessian blobs.</p> <code>0.01</code> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def detect_firing_fields(\n    image_gray: np.ndarray,\n    max_sigma: int = 30,\n    log_num_sigma: int = 10,\n    log_thres: float = 0.1,\n    dog_thres: float = 0.1,\n    doh_thres: float = 0.01,\n) -&gt; None:\n    \"\"\"\n    Detect firing fields in a grayscale image using different blob detection methods.\n\n    Parameters\n    ----------\n    image_gray : np.ndarray\n        Grayscale image to analyze.\n    max_sigma : int, optional\n        The maximum standard deviation for Gaussian filter.\n    log_num_sigma : int, optional\n        The number of sigma values for the Laplacian of Gaussian.\n    log_thres : float, optional\n        Threshold for Laplacian of Gaussian blobs.\n    dog_thres : float, optional\n        Threshold for Difference of Gaussian blobs.\n    doh_thres : float, optional\n        Threshold for Determinant of Hessian blobs.\n    \"\"\"\n    from skimage.feature import blob_dog, blob_doh, blob_log\n\n    plt.imshow(image_gray, origin=\"lower\")\n\n    blobs_log = blob_log(\n        image_gray, max_sigma=max_sigma, num_sigma=log_num_sigma, threshold=log_thres\n    )\n    # Compute radii in the 3rd column.\n    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n\n    blobs_dog = blob_dog(image_gray, max_sigma=max_sigma, threshold=dog_thres)\n    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n\n    blobs_doh = blob_doh(image_gray, max_sigma=max_sigma, threshold=doh_thres)\n\n    blobs_list = [blobs_log, blobs_dog, blobs_doh]\n    colors = [\"yellow\", \"lime\", \"red\"]\n    titles = [\n        \"Laplacian of Gaussian\",\n        \"Difference of Gaussian\",\n        \"Determinant of Hessian\",\n    ]\n    sequence = zip(blobs_list, colors, titles)\n\n    fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n    ax = axes.ravel()\n\n    for idx, (blobs, color, title) in enumerate(sequence):\n        ax[idx].set_title(title)\n        ax[idx].imshow(image_gray, interpolation=\"nearest\", origin=\"lower\")\n        for blob in blobs:\n            y, x, r = blob\n            c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n            ax[idx].add_patch(c)\n        ax[idx].set_axis_off()\n\n    plt.tight_layout()\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.distance_to_edge_function","title":"<code>distance_to_edge_function(x_c, y_c, field, box_size, interpolation='linear', contour_level=0.8)</code>","text":"<p>Returns a function which, for a given angle, returns the distance to the edge of the field from the center.</p> <p>Parameters:</p> Name Type Description Default <code>x_c</code> <code>float</code> <p>X-coordinate of the center.</p> required <code>y_c</code> <code>float</code> <p>Y-coordinate of the center.</p> required <code>field</code> <code>ndarray</code> <p>2D array with ones at field bins and zeros elsewhere.</p> required <code>box_size</code> <code>Tuple[float, float]</code> <p>Size of the box (arena).</p> required <code>interpolation</code> <code>str</code> <p>Type of interpolation to use. Default is \"linear\".</p> <code>'linear'</code> <code>contour_level</code> <code>float</code> <p>Contour level to use for finding edges. Default is 0.8.</p> <code>0.8</code> <p>Returns:</p> Type Description <code>Callable[[float], float]</code> <p>A function that takes an angle and returns the distance to the edge of the field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def distance_to_edge_function(\n    x_c: float,\n    y_c: float,\n    field: np.ndarray,\n    box_size: Tuple[float, float],\n    interpolation: str = \"linear\",\n    contour_level: float = 0.8,\n) -&gt; Callable[[float], float]:\n    \"\"\"\n    Returns a function which, for a given angle, returns the distance to\n    the edge of the field from the center.\n\n    Parameters\n    ----------\n    x_c : float\n        X-coordinate of the center.\n    y_c : float\n        Y-coordinate of the center.\n    field : np.ndarray\n        2D array with ones at field bins and zeros elsewhere.\n    box_size : Tuple[float, float]\n        Size of the box (arena).\n    interpolation : str, optional\n        Type of interpolation to use. Default is \"linear\".\n    contour_level : float, optional\n        Contour level to use for finding edges. Default is 0.8.\n\n    Returns\n    -------\n    Callable[[float], float]\n        A function that takes an angle and returns the distance to the edge of the field.\n    \"\"\"\n    from skimage import measure\n\n    contours = measure.find_contours(field, level=contour_level)\n\n    box_dim = np.array(box_size)\n    edge_x, edge_y = (contours[0] * box_dim / (np.array(field.shape) - (1, 1))).T\n\n    # # angle between 0 and 2\\pi\n    angles = np.arctan2((edge_y - y_c), (edge_x - x_c)) % (2 * np.pi)\n    a_sort = np.argsort(angles)\n    angles = angles[a_sort]\n    edge_x = edge_x[a_sort]\n    edge_y = edge_y[a_sort]\n\n    # # Fill in edge values for the interpolation\n    pad_a = np.pad(angles, 2, mode=\"linear_ramp\", end_values=(0, 2 * np.pi))\n    ev_x = (edge_x[0] + edge_x[-1]) / 2\n    pad_x = np.pad(edge_x, 2, mode=\"linear_ramp\", end_values=ev_x)\n    ev_y = (edge_y[0] + edge_y[-1]) / 2\n    pad_y = np.pad(edge_y, 2, mode=\"linear_ramp\", end_values=ev_y)\n\n    if interpolation == \"cubic\":\n        mask = np.where(np.diff(pad_a) == 0)\n        pad_a = np.delete(pad_a, mask)\n        pad_x = np.delete(pad_x, mask)\n        pad_y = np.delete(pad_y, mask)\n\n    x_func = interp1d(pad_a, pad_x, kind=interpolation)\n    y_func = interp1d(pad_a, pad_y, kind=interpolation)\n\n    def dist_func(angle: float) -&gt; float:\n        \"\"\"\n        Computes the distance from the center to the edge of the field at a given angle.\n\n        Parameters\n        ----------\n        angle : float\n            Angle in radians.\n\n        Returns\n        -------\n        float\n            Distance to the edge of the field from the center.\n        \"\"\"\n        x = x_func(angle)\n        y = y_func(angle)\n        dist = np.sqrt((x - x_c) ** 2 + (y - y_c) ** 2)\n        return dist\n\n    return dist_func\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.find_field","title":"<code>find_field(firing_rate, threshold)</code>","text":"<p>Find the field in the firing rate that exceeds the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>Array of firing rates.</p> required <code>threshold</code> <code>float</code> <p>Threshold for detection.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing the image label and the same label.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_field(\n    firing_rate: np.ndarray, threshold: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the field in the firing rate that exceeds the threshold.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        Array of firing rates.\n    threshold : float\n        Threshold for detection.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple containing the image label and the same label.\n    \"\"\"\n    mm = np.max(firing_rate)\n\n    labeled_image, num_labels = ndimage.label(firing_rate &gt; threshold)\n    for i in range(1, num_labels + 1):\n        image_label = labeled_image == i\n        if mm in firing_rate[image_label]:\n            return image_label, image_label\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.find_field2","title":"<code>find_field2(firing_rate, thresh)</code>","text":"<p>Find the field in a 1D firing rate array that exceeds the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>1D array of firing rates.</p> required <code>thresh</code> <code>float</code> <p>Threshold for detection.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple containing two boolean arrays: the first indicates the buffer area and the second indicates the field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_field2(\n    firing_rate: np.ndarray, thresh: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the field in a 1D firing rate array that exceeds the threshold.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        1D array of firing rates.\n    thresh : float\n        Threshold for detection.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        Tuple containing two boolean arrays:\n        the first indicates the buffer area and the second indicates the field.\n    \"\"\"\n    firing_rate = np.array(firing_rate)\n    imm = np.argmax(firing_rate)\n    mm = np.max(firing_rate)\n    # TODO: make more efficient by using argmax instead of where()[0]\n    first = np.where(np.diff(firing_rate[:imm]) &lt; 0)[0]\n    if len(first) == 0:\n        first = 0\n    else:\n        first = first[-1] + 2\n\n    last = np.where(np.diff(firing_rate[imm:]) &gt; 0)[0]\n\n    if len(last) == 0:\n        last = len(firing_rate)\n    else:\n        last = last[0] + imm + 1\n    field_buffer = np.zeros(firing_rate.shape, dtype=\"bool\")\n    field_buffer[first:last] = True\n    field = field_buffer &amp; (firing_rate &gt; thresh * mm)\n\n    return field_buffer, field\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.find_fields_1d","title":"<code>find_fields_1d(tuning, hz_thresh=5, min_length=1, max_length=20, max_mean_firing=10)</code>","text":"<p>Finds the location of maximum spiking.</p> <p>Parameters:</p> Name Type Description Default <code>tuning</code> <code>List[ndarray]</code> <p>Each inner array contains the tuning curves for an individual neuron.</p> required <code>hz_thresh</code> <code>float</code> <p>Any bin with firing above this value is considered to be part of a field. Default is 5.</p> <code>5</code> <code>min_length</code> <code>int</code> <p>Minimum length of field (in tuning curve bin units). Default is 1.</p> <code>1</code> <code>max_length</code> <code>int</code> <p>Maximum length of field (in tuning curve bin units). Default is 20.</p> <code>20</code> <code>max_mean_firing</code> <code>float</code> <p>Only neurons with a mean firing rate less than this amount are considered for having place fields. Default is 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>Where the key is the neuron number (int), and the value is a list of arrays (int) that are indices into the tuning curve where the field occurs. Each inner array contains the indices for a given place field.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_fields_1d(\n    tuning: List[np.ndarray],\n    hz_thresh: float = 5,\n    min_length: int = 1,\n    max_length: int = 20,\n    max_mean_firing: float = 10,\n) -&gt; dict:\n    \"\"\"\n    Finds the location of maximum spiking.\n\n    Parameters\n    ----------\n    tuning : List[np.ndarray]\n        Each inner array contains the tuning curves for an individual neuron.\n    hz_thresh : float, optional\n        Any bin with firing above this value is considered to be part of a field. Default is 5.\n    min_length : int, optional\n        Minimum length of field (in tuning curve bin units). Default is 1.\n    max_length : int, optional\n        Maximum length of field (in tuning curve bin units). Default is 20.\n    max_mean_firing : float, optional\n        Only neurons with a mean firing rate less than this amount are considered for\n        having place fields. Default is 10.\n\n    Returns\n    -------\n    dict\n        Where the key is the neuron number (int), and the value is a list of arrays (int)\n        that are indices into the tuning curve where the field occurs.\n        Each inner array contains the indices for a given place field.\n    \"\"\"\n    fields = []\n    for neuron_tc in tuning:\n        if np.mean(neuron_tc) &lt; max_mean_firing:\n            neuron_field = np.zeros(neuron_tc.shape[0])\n            for i, this_bin in enumerate(neuron_tc):\n                if this_bin &gt; hz_thresh:\n                    neuron_field[i] = 1\n            fields.append(neuron_field)\n        else:\n            fields.append(np.array([]))\n\n    fields_idx = dict()\n    for i, neuron_fields in enumerate(fields):\n        field_idx = np.nonzero(neuron_fields)[0]\n        fields_idx[i] = consecutive(field_idx, stepsize=1)\n\n    with_fields = dict()\n    for key in fields_idx:\n        for field in fields_idx[key]:\n            if len(field) &gt; max_length:\n                continue\n            elif min_length &lt;= len(field):\n                with_fields[key] = fields_idx[key]\n                continue\n    return with_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.find_peaks","title":"<code>find_peaks(image, filter_size=3)</code>","text":"<p>Find peaks sorted by distance from the center of the image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>The input image.</p> required <code>filter_size</code> <code>int</code> <p>The size of the filter used to find peaks.</p> <code>3</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Coordinates for peaks in the image as [row, column].</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def find_peaks(image: np.ndarray, filter_size: int = 3) -&gt; np.ndarray:\n    \"\"\"\n    Find peaks sorted by distance from the center of the image.\n\n    Parameters\n    ----------\n    image : np.ndarray\n        The input image.\n    filter_size : int, optional\n        The size of the filter used to find peaks.\n\n    Returns\n    -------\n    np.ndarray\n        Coordinates for peaks in the image as [row, column].\n    \"\"\"\n    image = image.copy()\n    image[~np.isfinite(image)] = 0\n    image_max = ndimage.maximum_filter(image, size=filter_size)\n    is_maxima = image == image_max\n    labels, num_objects = ndimage.label(is_maxima)\n    indices = np.arange(1, num_objects + 1)\n    peaks = ndimage.maximum_position(image, labels=labels, index=indices)\n    peaks = np.array(peaks)\n    center = (np.array(image.shape) - 1) / 2\n    distances = np.linalg.norm(peaks - center, axis=1)\n    peaks = peaks[distances.argsort()]\n    return peaks\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.map_pass_to_unit_circle","title":"<code>map_pass_to_unit_circle(x, y, t, x_c, y_c, field=None, box_size=None, dist_func=None)</code>","text":"<p>Uses three vectors {v, p, q} to map the passes to the unit circle. v is the average velocity vector of the pass, p is the vector from the position (x, y) to the center of the field, and q is the vector from the center to the edge through (x, y).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>X-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Y-coordinates.</p> required <code>t</code> <code>ndarray</code> <p>Time data.</p> required <code>x_c</code> <code>float</code> <p>X-coordinate of the center of the field.</p> required <code>y_c</code> <code>float</code> <p>Y-coordinate of the center of the field.</p> required <code>field</code> <code>Optional[ndarray]</code> <p>2D array indicating the location of the field.</p> <code>None</code> <code>box_size</code> <code>Optional[Tuple[float, float]]</code> <p>Size of the box (arena).</p> <code>None</code> <code>dist_func</code> <code>Optional[Callable[[float], float]]</code> <p>Function that computes distance to bump edge from center. Default is distance_to_edge_function with linear interpolation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray]</code> <p>r : Array of distances to origin on unit circle. theta : Array of angles to axis defined by mean velocity vector. pdcd : Array of distances to peak projected onto the current direction. pdmd : Array of distances to peak projected onto the mean direction.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If neither dist_func nor both field and box_size are provided.</p> References: <p>.. [1] Jeewajee A, Barry C, Douchamps V, Manson D, Lever C, Burgess N. Theta        phase precession of grid and place cell firing in open environments.        Philos Trans R Soc Lond B Biol Sci. 2013 Dec 23;369(1635):20120532</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def map_pass_to_unit_circle(\n    x: np.ndarray,\n    y: np.ndarray,\n    t: np.ndarray,\n    x_c: float,\n    y_c: float,\n    field: Optional[np.ndarray] = None,\n    box_size: Optional[Tuple[float, float]] = None,\n    dist_func: Optional[Callable[[float], float]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Uses three vectors {v, p, q} to map the passes to the unit circle. v\n    is the average velocity vector of the pass, p is the vector from the\n    position (x, y) to the center of the field, and q is the vector from the\n    center to the edge through (x, y).\n\n    Parameters\n    ----------\n    x : np.ndarray\n        X-coordinates.\n    y : np.ndarray\n        Y-coordinates.\n    t : np.ndarray\n        Time data.\n    x_c : float\n        X-coordinate of the center of the field.\n    y_c : float\n        Y-coordinate of the center of the field.\n    field : Optional[np.ndarray], optional\n        2D array indicating the location of the field.\n    box_size : Optional[Tuple[float, float]], optional\n        Size of the box (arena).\n    dist_func : Optional[Callable[[float], float]], optional\n        Function that computes distance to bump edge from center. Default is\n        distance_to_edge_function with linear interpolation.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n        r : Array of distances to origin on unit circle.\n        theta : Array of angles to axis defined by mean velocity vector.\n        pdcd : Array of distances to peak projected onto the current direction.\n        pdmd : Array of distances to peak projected onto the mean direction.\n\n    Raises\n    ------\n    AssertionError\n        If neither dist_func nor both field and box_size are provided.\n\n    References:\n    -----------\n    .. [1] Jeewajee A, Barry C, Douchamps V, Manson D, Lever C, Burgess N. Theta\n           phase precession of grid and place cell firing in open environments.\n           Philos Trans R Soc Lond B Biol Sci. 2013 Dec 23;369(1635):20120532\n    \"\"\"\n    if dist_func is None:\n        assert field is not None and box_size is not None, (\n            'either provide \"dist_func\" or \"field\" and \"box_size\"'\n        )\n        dist_func = distance_to_edge_function(\n            x_c, y_c, field, box_size, interpolation=\"linear\"\n        )\n    pos = np.array((x, y))\n\n    # vector from pos to center p\n    p_vec = ((x_c, y_c) - pos.T).T\n    # angle between x-axis and negative vector p\n    angle = (np.arctan2(p_vec[1], p_vec[0]) + np.pi) % (2 * np.pi)\n    # distance from center to edge at each angle\n    q = dist_func(angle)\n    # distance from center to pos\n    p = np.linalg.norm(p_vec, axis=0)\n    # r-coordinate on unit circle\n    r = p / q\n\n    dpos = np.gradient(pos, axis=1)\n    dt = np.gradient(t)\n    velocity = np.divide(dpos, dt)\n\n    # mean velocity vector v\n    mean_velocity = np.average(velocity, axis=1)\n    # angle on unit circle, run is rotated such that mean velocity vector\n    # is toward positive x\n    theta = (angle - np.arctan2(mean_velocity[1], mean_velocity[0])) % (2 * np.pi)\n\n    w_pdcd = angle - np.arctan2(velocity[1], velocity[0])\n    pdcd = r * np.cos(w_pdcd)\n\n    w_pdmd = angle - np.arctan2(mean_velocity[1], mean_velocity[0])\n    pdmd = r * np.cos(w_pdmd)\n    return r, theta, pdcd, pdmd\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.map_stats2","title":"<code>map_stats2(firing_rate, threshold=0.1, min_size=5, max_size=None, min_peak=1.0, sigma=None, min_peak_to_trough_ratio=2.0)</code>","text":"<p>Map statistics of firing rate fields.</p> <p>Parameters:</p> Name Type Description Default <code>firing_rate</code> <code>ndarray</code> <p>1D array of firing rates.</p> required <code>threshold</code> <code>float</code> <p>Threshold for field detection. Default is 0.1.</p> <code>0.1</code> <code>min_size</code> <code>int</code> <p>Minimum size of detected fields. Default is 5.</p> <code>5</code> <code>max_size</code> <code>Optional[int]</code> <p>Maximum size of detected fields. Default is None, which sets it to the length of firing_rate.</p> <code>None</code> <code>min_peak</code> <code>float</code> <p>Minimum peak firing rate to consider a field valid. Default is 1.0.</p> <code>1.0</code> <code>sigma</code> <code>Optional[float]</code> <p>Standard deviation for Gaussian smoothing. Default is None.</p> <code>None</code> <code>min_peak_to_trough_ratio</code> <code>float</code> <p>Minimum ratio between peak and trough values within a detected field. Default is 2.0.</p> <code>2.0</code> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>A dictionary containing the sizes, peaks, means, and fields of detected firing rate fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def map_stats2(\n    firing_rate: np.ndarray,\n    threshold: float = 0.1,\n    min_size: int = 5,\n    max_size: Optional[int] = None,\n    min_peak: float = 1.0,\n    sigma: Optional[float] = None,\n    min_peak_to_trough_ratio: float = 2.0,\n) -&gt; Dict[str, List[float]]:\n    \"\"\"\n    Map statistics of firing rate fields.\n\n    Parameters\n    ----------\n    firing_rate : np.ndarray\n        1D array of firing rates.\n    threshold : float, optional\n        Threshold for field detection. Default is 0.1.\n    min_size : int, optional\n        Minimum size of detected fields. Default is 5.\n    max_size : Optional[int], optional\n        Maximum size of detected fields. Default is None, which sets it to the length of firing_rate.\n    min_peak : float, optional\n        Minimum peak firing rate to consider a field valid. Default is 1.0.\n    sigma : Optional[float], optional\n        Standard deviation for Gaussian smoothing. Default is None.\n    min_peak_to_trough_ratio : float, optional\n        Minimum ratio between peak and trough values within a detected field. Default is 2.0.\n\n    Returns\n    -------\n    Dict[str, List[float]]\n        A dictionary containing the sizes, peaks, means, and fields of detected firing rate fields.\n\n    \"\"\"\n    if sigma is not None:\n        firing_rate = ndimage.gaussian_filter1d(firing_rate, sigma)\n\n    if max_size is None:\n        max_size = len(firing_rate)\n\n    firing_rate = firing_rate.copy()\n    firing_rate = firing_rate - np.min(firing_rate)\n    out = dict(sizes=list(), peaks=list(), means=list())\n    out[\"fields\"] = np.zeros(firing_rate.shape)\n    field_counter = 1\n    while True:\n        peak = np.max(firing_rate)\n        if peak &lt; min_peak:\n            break\n        field_buffer, field = find_field(firing_rate, threshold)\n        field_size = np.sum(field)\n        if (\n            (field_size &gt; min_size)\n            and (field_size &lt; max_size)\n            and (\n                np.max(firing_rate[field])\n                &gt; (min_peak_to_trough_ratio * np.min(firing_rate[field_buffer]))\n            )\n        ):\n            out[\"fields\"][field] = field_counter\n            out[\"sizes\"].append(float(field_size) / len(firing_rate))\n            out[\"peaks\"].append(peak)\n            out[\"means\"].append(np.mean(firing_rate[field]))\n            field_counter += 1\n        firing_rate[field_buffer] = 0\n\n    return out\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.remove_fields_by_area","title":"<code>remove_fields_by_area(fields, minimum_field_area, maximum_field_area=None)</code>","text":"<p>Sets fields below minimum area to zero, measured as the number of bins in a field.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>ndarray</code> <p>The fields.</p> required <code>minimum_field_area</code> <code>int</code> <p>Minimum field area (number of bins in a field).</p> required <code>maximum_field_area</code> <code>Optional[int]</code> <p>Maximum field area (number of bins in a field). Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Fields with number of bins below minimum_field_area are set to zero.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If minimum_field_area is not an integer.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def remove_fields_by_area(\n    fields: np.ndarray,\n    minimum_field_area: int,\n    maximum_field_area: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Sets fields below minimum area to zero, measured as the number of bins in a field.\n\n    Parameters\n    ----------\n    fields : np.ndarray\n        The fields.\n    minimum_field_area : int\n        Minimum field area (number of bins in a field).\n    maximum_field_area : Optional[int]\n        Maximum field area (number of bins in a field). Default is None.\n\n    Returns\n    -------\n    np.ndarray\n        Fields with number of bins below minimum_field_area are set to zero.\n\n    Raises\n    ------\n    ValueError\n        If minimum_field_area is not an integer.\n    \"\"\"\n    if not isinstance(minimum_field_area, (int, np.integer)):\n        raise ValueError(\"'minimum_field_area' should be int\")\n\n    if maximum_field_area is None:\n        maximum_field_area = len(fields.flatten())\n    ## variant\n    # fields_areas = scipy.ndimage.measurements.sum(\n    #     np.ones_like(fields), fields, index=np.arange(fields.max() + 1))\n    # fields_area = fields_areas[fields]\n    # fields[fields_area &lt; minimum_field_area] = 0\n\n    labels, counts = np.unique(fields, return_counts=True)\n    for lab, count in zip(labels, counts):\n        if lab != 0:\n            if (count &lt; minimum_field_area) | (count &gt; maximum_field_area):\n                fields[fields == lab] = 0\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.separate_fields_by_dilation","title":"<code>separate_fields_by_dilation(rate_map, seed=2.5, sigma=2.5, minimum_field_area=None)</code>","text":"<p>Separates fields by the Laplace of Gaussian (LoG) on the rate map subtracted by a reconstruction of the rate map using dilation.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>seed</code> <code>float</code> <p>Magnitude of dilation.</p> <code>2.5</code> <code>sigma</code> <code>float</code> <p>Standard deviation of Gaussian to separate fields. Default is 2.5.</p> <code>2.5</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> References <p>.. [1] https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_regional_maxima.html</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_dilation(\n    rate_map: np.ndarray,\n    seed: float = 2.5,\n    sigma: float = 2.5,\n    minimum_field_area: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields by the Laplace of Gaussian (LoG)\n    on the rate map subtracted by a reconstruction of the rate map using\n    dilation.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    seed : float\n        Magnitude of dilation.\n    sigma : float\n        Standard deviation of Gaussian to separate fields. Default is 2.5.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n\n    References\n    ----------\n    .. [1] https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_regional_maxima.html\n    \"\"\"\n    from skimage.morphology import reconstruction\n\n    rate_map_norm = (rate_map - rate_map.mean()) / rate_map.std()\n    dilated = reconstruction(rate_map_norm - seed, rate_map_norm, method=\"dilation\")\n    rate_map_reconstructed = rate_map_norm - dilated\n\n    laplacian = ndimage.gaussian_laplace(rate_map_reconstructed, sigma)\n    laplacian[laplacian &gt; 0] = 0\n    fields, _ = ndimage.label(laplacian)\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.separate_fields_by_laplace","title":"<code>separate_fields_by_laplace(rate_map, threshold=0, minimum_field_area=None)</code>","text":"<p>Separates fields using the Laplacian to identify fields separated by a negative second derivative.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>threshold</code> <code>float</code> <p>Value of Laplacian to separate fields by relative to the minima. Should be on the interval 0 to 1, where 0 cuts off at 0 and 1 cuts off at min(laplace(rate_map)). Default is 0.</p> <code>0</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_laplace(\n    rate_map: np.ndarray, threshold: float = 0, minimum_field_area: Optional[int] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields using the Laplacian to identify fields separated by\n    a negative second derivative.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    threshold : float\n        Value of Laplacian to separate fields by relative to the minima.\n        Should be on the interval 0 to 1, where 0 cuts off at 0 and\n        1 cuts off at min(laplace(rate_map)). Default is 0.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n    \"\"\"\n\n    laplacian = ndimage.laplace(rate_map)\n\n    laplacian[laplacian &gt; threshold * np.min(laplacian)] = 0\n\n    # Labels areas of the laplacian not connected by values &gt; 0.\n    fields, _ = ndimage.label(laplacian)\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.separate_fields_by_laplace_of_gaussian","title":"<code>separate_fields_by_laplace_of_gaussian(rate_map, sigma=2, minimum_field_area=None)</code>","text":"<p>Separates fields using the Laplace of Gaussian (LoG) to identify fields separated by a negative second derivative. Works best if no smoothing is applied to the rate map, preferably with interpolated NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>2D array representing firing rate in each bin.</p> required <code>sigma</code> <code>float</code> <p>Standard deviation of Gaussian to separate fields. Default is 2.</p> <code>2</code> <code>minimum_field_area</code> <code>Optional[int]</code> <p>Minimum number of bins to consider it a field. Default is None (all fields are kept).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Labels with areas filled with the same value, corresponding to fields in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the field (sum of all field values) with 0 elsewhere.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def separate_fields_by_laplace_of_gaussian(\n    rate_map: np.ndarray, sigma: float = 2, minimum_field_area: Optional[int] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Separates fields using the Laplace of Gaussian (LoG) to identify fields\n    separated by a negative second derivative. Works best if no smoothing is\n    applied to the rate map, preferably with interpolated NaNs.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        2D array representing firing rate in each bin.\n    sigma : float\n        Standard deviation of Gaussian to separate fields. Default is 2.\n    minimum_field_area : Optional[int]\n        Minimum number of bins to consider it a field. Default is None (all fields are kept).\n\n    Returns\n    -------\n    np.ndarray\n        Labels with areas filled with the same value, corresponding to fields\n        in rate_map. The fill values are in range(1, nFields + 1), sorted by size of the\n        field (sum of all field values) with 0 elsewhere.\n    \"\"\"\n    laplacian = ndimage.gaussian_laplace(rate_map, sigma)\n    laplacian[laplacian &gt; 0] = 0\n\n    # Labels areas of the laplacian not connected by values &gt; 0.\n    fields, _ = ndimage.label(laplacian)\n\n    fields = sort_fields_by_rate(rate_map, fields)\n    if minimum_field_area is not None:\n        fields = remove_fields_by_area(fields, minimum_field_area)\n    return fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.sort_fields_by_rate","title":"<code>sort_fields_by_rate(rate_map, fields, func=None)</code>","text":"<p>Sort fields by the rate value of each field.</p> <p>Parameters:</p> Name Type Description Default <code>rate_map</code> <code>ndarray</code> <p>The rate map.</p> required <code>fields</code> <code>ndarray</code> <p>The fields of the same shape as rate_map.</p> required <code>func</code> <code>Callable</code> <p>Function returning value to sort after, default is np.max.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted fields.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def sort_fields_by_rate(\n    rate_map: np.ndarray,\n    fields: np.ndarray,\n    func: Optional[Callable[[np.ndarray], Any]] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Sort fields by the rate value of each field.\n\n    Parameters\n    ----------\n    rate_map : np.ndarray\n        The rate map.\n    fields : np.ndarray\n        The fields of the same shape as rate_map.\n    func : Callable, optional\n        Function returning value to sort after, default is np.max.\n\n    Returns\n    -------\n    np.ndarray\n        Sorted fields.\n    \"\"\"\n    indx = np.sort(np.unique(fields.ravel()))\n    func = func or np.max\n    # Sort by largest peak\n    rate_means = ndimage.labeled_comprehension(\n        rate_map, fields, indx, func, np.float64, 0\n    )\n    sort = np.argsort(rate_means)[::-1]\n\n    sorted_fields = np.zeros_like(fields)\n    for indx_i, indx_ in enumerate(indx[sort]):\n        if indx_ == 0:\n            continue\n        sorted_fields[fields == indx_] = np.max(sorted_fields) + 1\n\n    # new rate map with fields &gt; min_size, sorted\n    # sorted_fields = np.zeros_like(fields)\n    # for i in range(indx.max() + 1):\n    #     sorted_fields[fields == sort[i] + 1] = i + 1\n\n    return sorted_fields\n</code></pre>"},{"location":"reference/neuro_py/tuning/fields/#neuro_py.tuning.fields.which_field","title":"<code>which_field(x, y, fields, box_size)</code>","text":"<p>Returns which spatial field each (x, y) position is in.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>X-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Y-coordinates, must have the same length as x.</p> required <code>fields</code> <code>ndarray</code> <p>Labeled fields, where each field is defined by an area separated by zeros. The fields are labeled with indices from [1:].</p> required <code>box_size</code> <code>List[float]</code> <p>Extents of the arena.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array-like x and y with fields-labeled indices.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If x and y do not have the same length.</p> Source code in <code>neuro_py/tuning/fields.py</code> <pre><code>def which_field(\n    x: np.ndarray, y: np.ndarray, fields: np.ndarray, box_size: List[float]\n) -&gt; np.ndarray:\n    \"\"\"\n    Returns which spatial field each (x, y) position is in.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        X-coordinates.\n    y : np.ndarray\n        Y-coordinates, must have the same length as x.\n    fields : np.ndarray\n        Labeled fields, where each field is defined by an area separated by\n        zeros. The fields are labeled with indices from [1:].\n    box_size : List[float]\n        Extents of the arena.\n\n    Returns\n    -------\n    np.ndarray\n        Array-like x and y with fields-labeled indices.\n\n    Raises\n    ------\n    ValueError\n        If x and y do not have the same length.\n    \"\"\"\n    if len(x) != len(y):\n        raise ValueError(\"x and y must have same length\")\n\n    sx, sy = fields.shape\n    # bin sizes\n    dx = box_size[0] / sx\n    dy = box_size[1] / sy\n    x_bins = dx + np.arange(0, box_size[0] + dx, dx)\n    y_bins = dy + np.arange(0, box_size[1] + dx, dy)\n    # x_bins = np.arange(0, box_size[0] + dx, dx)\n    # y_bins = np.arange(0, box_size[1] + dx, dy)\n    ix = np.digitize(x, x_bins)\n    iy = np.digitize(y, y_bins)\n\n    # fix for boundaries:\n    ix[ix == sx] = sx - 1\n    iy[iy == sy] = sy - 1\n    return np.array(fields[ix, iy])\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/","title":"neuro_py.tuning.maps","text":""},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.NDimensionalBinner","title":"<code>NDimensionalBinner</code>","text":"<p>Base class for N-dimensional binning of data (point process or continuous) over arbitrary dimensions.</p> <p>This class provides low-level functionality to create N-dimensional tuning curves by binning spike train or continuous data along multiple spatial or behavioral dimensions.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>class NDimensionalBinner:\n    \"\"\"\n    Base class for N-dimensional binning of data (point process or continuous)\n    over arbitrary dimensions.\n\n    This class provides low-level functionality to create N-dimensional tuning curves\n    by binning spike train or continuous data along multiple spatial or behavioral dimensions.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def create_nd_tuning_curve(\n        self,\n        st_data: Union[nel.SpikeTrainArray, nel.AnalogSignalArray],\n        pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n        bin_edges: List[np.ndarray],\n        min_duration: float = 0.1,\n        minbgrate: Union[int, float] = 0,\n        tuning_curve_sigma: Optional[\n            Union[int, float, List[Union[int, float]], np.ndarray]\n        ] = None,\n        smooth_mode: str = \"reflect\",\n    ) -&gt; tuple:\n        \"\"\"\n        Create an N-dimensional tuning curve from spike and position data.\n\n        Parameters\n        ----------\n        st_data : object\n            Spike train data (nelpy.SpikeTrainArray or nelpy.AnalogSignalArray).\n        pos_data : object\n            Position data (nelpy.AnalogSignalArray or nelpy.PositionArray).\n        bin_edges : List[np.ndarray]\n            List of bin edges for each dimension.\n        min_duration : float, optional\n            Minimum duration for a valid bin. Default is 0.1.\n        minbgrate : Union[int, float], optional\n            Minimum background firing rate. Default is 0.\n        tuning_curve_sigma : Optional[Union[int, float, List[Union[int, float]], np.ndarray]], optional\n            Sigma for smoothing. Can be a single value (used for all dimensions)\n            or an array/list with sigma values for each dimension. Default is None (no smoothing).\n        smooth_mode : str, optional\n            Smoothing mode. Default is \"reflect\".\n\n        Notes\n        -----\n        max_gap is not used here; position continuity should be enforced by\n        the caller (for example, SpatialMap narrows run_epochs using its\n        own `max_gap` attribute).\n\n        Returns\n        -------\n        tuple\n            A tuple containing (tuning_curve, occupancy, ratemap)\n        \"\"\"\n        # Determine number of dimensions\n        n_dims = len(bin_edges)\n\n        if n_dims != pos_data.n_signals:\n            raise ValueError(\n                f\"Number of bin_edges ({n_dims}) must match position dimensions ({pos_data.n_signals})\"\n            )\n\n        # Compute occupancy\n        occupancy = self._compute_occupancy_nd(pos_data, bin_edges)\n\n        # Compute ratemap\n        ratemap = self._compute_ratemap_nd(st_data, pos_data, occupancy, bin_edges)\n\n        # Apply minimum background firing rate (before minimum duration check)\n        ratemap[ratemap &lt; minbgrate] = minbgrate\n\n        # Apply minimum background occupancy (after minimum background firing rate)\n        for uu in range(st_data.data.shape[0]):\n            ratemap[uu][occupancy &lt; min_duration] = 0\n\n        # Create appropriate tuning curve object based on dimensions\n        if n_dims == 1:\n            tc = nel.TuningCurve1D(\n                ratemap=ratemap,\n                extmin=bin_edges[0][0],\n                extmax=bin_edges[0][-1],\n            )\n        elif n_dims == 2:\n            tc = nel.TuningCurve2D(\n                ratemap=ratemap,\n                ext_xmin=bin_edges[0][0],\n                ext_ymin=bin_edges[1][0],\n                ext_xmax=bin_edges[0][-1],\n                ext_ymax=bin_edges[1][-1],\n                ext_ny=len(bin_edges[1]) - 1,\n                ext_nx=len(bin_edges[0]) - 1,\n            )\n        else:\n            # For N-dimensional (N &gt; 2), use nelpy's TuningCurveND class\n            # Calculate extents for each dimension\n            ext_min = [bin_edges[i][0] for i in range(n_dims)]\n            ext_max = [bin_edges[i][-1] for i in range(n_dims)]\n            tc = nel.TuningCurveND(ratemap=ratemap, ext_min=ext_min, ext_max=ext_max)\n\n        tc._occupancy = occupancy\n\n        # Apply smoothing if requested\n        if tuning_curve_sigma is not None:\n            # Handle array or scalar sigma values\n            if np.isscalar(tuning_curve_sigma):\n                # Single value: use for all dimensions\n                if tuning_curve_sigma &gt; 0 and hasattr(tc, \"smooth\"):\n                    tc.smooth(sigma=tuning_curve_sigma, inplace=True, mode=smooth_mode)\n            else:\n                # Array/list: convert to numpy array\n                sigma_array = np.asarray(tuning_curve_sigma)\n                if len(sigma_array) != n_dims:\n                    raise ValueError(\n                        f\"Length of tuning_curve_sigma array ({len(sigma_array)}) must match \"\n                        f\"number of dimensions ({n_dims})\"\n                    )\n\n                # Check if any sigma values are positive and smooth if so\n                if np.any(sigma_array &gt; 0) and hasattr(tc, \"smooth\"):\n                    tc.smooth(sigma=sigma_array, inplace=True, mode=smooth_mode)\n\n        return tc, occupancy, ratemap\n\n    def _compute_occupancy_nd(\n        self,\n        pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n        bin_edges: List[np.ndarray],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Compute N-dimensional occupancy.\n\n        Parameters\n        ----------\n        pos_data : object\n            Position data.\n        bin_edges : List[np.ndarray]\n            Bin edges for each dimension.\n\n        Returns\n        -------\n        np.ndarray\n            N-dimensional occupancy array.\n        \"\"\"\n        n_dims = len(bin_edges)\n\n        if n_dims == 1:\n            occupancy, _ = np.histogram(pos_data.data[0, :], bins=bin_edges[0])\n        elif n_dims == 2:\n            occupancy, _, _ = np.histogram2d(\n                pos_data.data[0, :],\n                pos_data.data[1, :],\n                bins=(bin_edges[0], bin_edges[1]),\n            )\n        else:\n            # For N-dimensional histograms\n            occupancy, _ = np.histogramdd(\n                pos_data.data.T,  # Transpose to get (n_samples, n_dims)\n                bins=bin_edges,\n            )\n\n        return occupancy / pos_data.fs\n\n    def _compute_ratemap_nd(\n        self,\n        st_data: Union[nel.SpikeTrainArray, nel.AnalogSignalArray],\n        pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n        occupancy: np.ndarray,\n        bin_edges: List[np.ndarray],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Compute N-dimensional ratemap.\n\n        Parameters\n        ----------\n        st_data : Union[nel.SpikeTrainArray, nel.AnalogSignalArray]\n            Spike train data.\n        pos_data : Union[nel.AnalogSignalArray, nel.PositionArray]\n            Position data.\n        occupancy : np.ndarray\n            Occupancy array.\n        bin_edges : List[np.ndarray]\n            Bin edges for each dimension.\n\n        Notes\n        -----\n        This implementation assumes the caller has ensured continuity of\n        position timestamps (for example by intersecting run epochs with\n        contiguous position segments). Interpolation is performed with\n        numpy.interp(..., left=np.nan, right=np.nan).\n\n        Returns\n        -------\n        np.ndarray\n            N-dimensional ratemap.\n        \"\"\"\n        n_dims = len(bin_edges)\n\n        # Initialize ratemap with proper shape\n        ratemap_shape = [st_data.data.shape[0]] + list(occupancy.shape)\n        ratemap = np.zeros(ratemap_shape)\n\n        if st_data.isempty:\n            return ratemap\n\n        # Remove NaNs from position data for interpolation\n        mask = ~np.isnan(pos_data.data).any(axis=0)\n        pos_clean = pos_data.data[:, mask]\n        ts_clean = pos_data.abscissa_vals[mask]\n\n        # Handle point process data (spike trains)\n        if isinstance(st_data, nel.core._eventarray.SpikeTrainArray):\n            for i in range(st_data.data.shape[0]):\n                # Interpolate spike positions\n                spike_positions = []\n                for dim in range(n_dims):\n                    spike_pos_dim = np.interp(\n                        st_data.data[i],\n                        ts_clean,\n                        pos_clean[dim],\n                        left=np.nan,\n                        right=np.nan,\n                    )\n                    spike_positions.append(spike_pos_dim)\n\n                # Bin spikes\n                if n_dims == 1:\n                    counts, _ = np.histogram(spike_positions[0], bins=bin_edges[0])\n                    ratemap[i] = counts\n                elif n_dims == 2:\n                    counts, _, _ = np.histogram2d(\n                        spike_positions[0],\n                        spike_positions[1],\n                        bins=(bin_edges[0], bin_edges[1]),\n                    )\n                    ratemap[i] = counts\n                else:\n                    counts, _ = np.histogramdd(\n                        np.array(spike_positions).T, bins=bin_edges\n                    )\n                    ratemap[i] = counts\n\n        # Handle continuous data (analog signals)\n        elif isinstance(st_data, nel.core._analogsignalarray.AnalogSignalArray):\n            # Interpolate position at signal timestamps\n            signal_positions = []\n            for dim in range(n_dims):\n                pos_interp = np.interp(\n                    st_data.abscissa_vals,\n                    ts_clean,\n                    pos_clean[dim],\n                    left=np.nan,\n                    right=np.nan,\n                )\n                signal_positions.append(pos_interp)\n\n            # Use scipy's binned_statistic_dd for efficient N-D binning.\n            # Build positions array with shape (n_timepoints, n_dims)\n            positions = np.vstack(signal_positions).T\n\n            # Mask out invalid (NaN) positions\n            valid_mask = ~np.isnan(positions).any(axis=1)\n\n            if np.any(valid_mask):\n                pos_valid = positions[valid_mask]\n                for uu in range(st_data.data.shape[0]):\n                    vals = st_data.data[uu, valid_mask]\n                    # Use mean for analog signals: average value per spatial bin\n                    ratemap[uu], _, _ = binned_statistic_dd(\n                        pos_valid, vals, statistic=\"mean\", bins=bin_edges\n                    )\n\n        # Normalize by occupancy only for spike-train (counts -&gt; rates).\n        # Analog signals were binned as means already and should not be divided.\n        if isinstance(st_data, nel.core._eventarray.SpikeTrainArray):\n            # Handle division by zero using broadcasting (avoids memory-intensive tiling)\n            occupancy_expanded = np.expand_dims(occupancy, 0)  # Add unit dimension\n            np.divide(\n                ratemap, occupancy_expanded, where=occupancy_expanded != 0, out=ratemap\n            )\n\n        # Remove NaNs and infs\n        bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n        ratemap[bad_idx] = 0\n\n        return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.NDimensionalBinner._compute_occupancy_nd","title":"<code>_compute_occupancy_nd(pos_data, bin_edges)</code>","text":"<p>Compute N-dimensional occupancy.</p> <p>Parameters:</p> Name Type Description Default <code>pos_data</code> <code>object</code> <p>Position data.</p> required <code>bin_edges</code> <code>List[ndarray]</code> <p>Bin edges for each dimension.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>N-dimensional occupancy array.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def _compute_occupancy_nd(\n    self,\n    pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n    bin_edges: List[np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute N-dimensional occupancy.\n\n    Parameters\n    ----------\n    pos_data : object\n        Position data.\n    bin_edges : List[np.ndarray]\n        Bin edges for each dimension.\n\n    Returns\n    -------\n    np.ndarray\n        N-dimensional occupancy array.\n    \"\"\"\n    n_dims = len(bin_edges)\n\n    if n_dims == 1:\n        occupancy, _ = np.histogram(pos_data.data[0, :], bins=bin_edges[0])\n    elif n_dims == 2:\n        occupancy, _, _ = np.histogram2d(\n            pos_data.data[0, :],\n            pos_data.data[1, :],\n            bins=(bin_edges[0], bin_edges[1]),\n        )\n    else:\n        # For N-dimensional histograms\n        occupancy, _ = np.histogramdd(\n            pos_data.data.T,  # Transpose to get (n_samples, n_dims)\n            bins=bin_edges,\n        )\n\n    return occupancy / pos_data.fs\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.NDimensionalBinner._compute_ratemap_nd","title":"<code>_compute_ratemap_nd(st_data, pos_data, occupancy, bin_edges)</code>","text":"<p>Compute N-dimensional ratemap.</p> <p>Parameters:</p> Name Type Description Default <code>st_data</code> <code>Union[SpikeTrainArray, AnalogSignalArray]</code> <p>Spike train data.</p> required <code>pos_data</code> <code>Union[AnalogSignalArray, PositionArray]</code> <p>Position data.</p> required <code>occupancy</code> <code>ndarray</code> <p>Occupancy array.</p> required <code>bin_edges</code> <code>List[ndarray]</code> <p>Bin edges for each dimension.</p> required Notes <p>This implementation assumes the caller has ensured continuity of position timestamps (for example by intersecting run epochs with contiguous position segments). Interpolation is performed with numpy.interp(..., left=np.nan, right=np.nan).</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>N-dimensional ratemap.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def _compute_ratemap_nd(\n    self,\n    st_data: Union[nel.SpikeTrainArray, nel.AnalogSignalArray],\n    pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n    occupancy: np.ndarray,\n    bin_edges: List[np.ndarray],\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute N-dimensional ratemap.\n\n    Parameters\n    ----------\n    st_data : Union[nel.SpikeTrainArray, nel.AnalogSignalArray]\n        Spike train data.\n    pos_data : Union[nel.AnalogSignalArray, nel.PositionArray]\n        Position data.\n    occupancy : np.ndarray\n        Occupancy array.\n    bin_edges : List[np.ndarray]\n        Bin edges for each dimension.\n\n    Notes\n    -----\n    This implementation assumes the caller has ensured continuity of\n    position timestamps (for example by intersecting run epochs with\n    contiguous position segments). Interpolation is performed with\n    numpy.interp(..., left=np.nan, right=np.nan).\n\n    Returns\n    -------\n    np.ndarray\n        N-dimensional ratemap.\n    \"\"\"\n    n_dims = len(bin_edges)\n\n    # Initialize ratemap with proper shape\n    ratemap_shape = [st_data.data.shape[0]] + list(occupancy.shape)\n    ratemap = np.zeros(ratemap_shape)\n\n    if st_data.isempty:\n        return ratemap\n\n    # Remove NaNs from position data for interpolation\n    mask = ~np.isnan(pos_data.data).any(axis=0)\n    pos_clean = pos_data.data[:, mask]\n    ts_clean = pos_data.abscissa_vals[mask]\n\n    # Handle point process data (spike trains)\n    if isinstance(st_data, nel.core._eventarray.SpikeTrainArray):\n        for i in range(st_data.data.shape[0]):\n            # Interpolate spike positions\n            spike_positions = []\n            for dim in range(n_dims):\n                spike_pos_dim = np.interp(\n                    st_data.data[i],\n                    ts_clean,\n                    pos_clean[dim],\n                    left=np.nan,\n                    right=np.nan,\n                )\n                spike_positions.append(spike_pos_dim)\n\n            # Bin spikes\n            if n_dims == 1:\n                counts, _ = np.histogram(spike_positions[0], bins=bin_edges[0])\n                ratemap[i] = counts\n            elif n_dims == 2:\n                counts, _, _ = np.histogram2d(\n                    spike_positions[0],\n                    spike_positions[1],\n                    bins=(bin_edges[0], bin_edges[1]),\n                )\n                ratemap[i] = counts\n            else:\n                counts, _ = np.histogramdd(\n                    np.array(spike_positions).T, bins=bin_edges\n                )\n                ratemap[i] = counts\n\n    # Handle continuous data (analog signals)\n    elif isinstance(st_data, nel.core._analogsignalarray.AnalogSignalArray):\n        # Interpolate position at signal timestamps\n        signal_positions = []\n        for dim in range(n_dims):\n            pos_interp = np.interp(\n                st_data.abscissa_vals,\n                ts_clean,\n                pos_clean[dim],\n                left=np.nan,\n                right=np.nan,\n            )\n            signal_positions.append(pos_interp)\n\n        # Use scipy's binned_statistic_dd for efficient N-D binning.\n        # Build positions array with shape (n_timepoints, n_dims)\n        positions = np.vstack(signal_positions).T\n\n        # Mask out invalid (NaN) positions\n        valid_mask = ~np.isnan(positions).any(axis=1)\n\n        if np.any(valid_mask):\n            pos_valid = positions[valid_mask]\n            for uu in range(st_data.data.shape[0]):\n                vals = st_data.data[uu, valid_mask]\n                # Use mean for analog signals: average value per spatial bin\n                ratemap[uu], _, _ = binned_statistic_dd(\n                    pos_valid, vals, statistic=\"mean\", bins=bin_edges\n                )\n\n    # Normalize by occupancy only for spike-train (counts -&gt; rates).\n    # Analog signals were binned as means already and should not be divided.\n    if isinstance(st_data, nel.core._eventarray.SpikeTrainArray):\n        # Handle division by zero using broadcasting (avoids memory-intensive tiling)\n        occupancy_expanded = np.expand_dims(occupancy, 0)  # Add unit dimension\n        np.divide(\n            ratemap, occupancy_expanded, where=occupancy_expanded != 0, out=ratemap\n        )\n\n    # Remove NaNs and infs\n    bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n    ratemap[bad_idx] = 0\n\n    return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.NDimensionalBinner.create_nd_tuning_curve","title":"<code>create_nd_tuning_curve(st_data, pos_data, bin_edges, min_duration=0.1, minbgrate=0, tuning_curve_sigma=None, smooth_mode='reflect')</code>","text":"<p>Create an N-dimensional tuning curve from spike and position data.</p> <p>Parameters:</p> Name Type Description Default <code>st_data</code> <code>object</code> <p>Spike train data (nelpy.SpikeTrainArray or nelpy.AnalogSignalArray).</p> required <code>pos_data</code> <code>object</code> <p>Position data (nelpy.AnalogSignalArray or nelpy.PositionArray).</p> required <code>bin_edges</code> <code>List[ndarray]</code> <p>List of bin edges for each dimension.</p> required <code>min_duration</code> <code>float</code> <p>Minimum duration for a valid bin. Default is 0.1.</p> <code>0.1</code> <code>minbgrate</code> <code>Union[int, float]</code> <p>Minimum background firing rate. Default is 0.</p> <code>0</code> <code>tuning_curve_sigma</code> <code>Optional[Union[int, float, List[Union[int, float]], ndarray]]</code> <p>Sigma for smoothing. Can be a single value (used for all dimensions) or an array/list with sigma values for each dimension. Default is None (no smoothing).</p> <code>None</code> <code>smooth_mode</code> <code>str</code> <p>Smoothing mode. Default is \"reflect\".</p> <code>'reflect'</code> Notes <p>max_gap is not used here; position continuity should be enforced by the caller (for example, SpatialMap narrows run_epochs using its own <code>max_gap</code> attribute).</p> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing (tuning_curve, occupancy, ratemap)</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def create_nd_tuning_curve(\n    self,\n    st_data: Union[nel.SpikeTrainArray, nel.AnalogSignalArray],\n    pos_data: Union[nel.AnalogSignalArray, nel.PositionArray],\n    bin_edges: List[np.ndarray],\n    min_duration: float = 0.1,\n    minbgrate: Union[int, float] = 0,\n    tuning_curve_sigma: Optional[\n        Union[int, float, List[Union[int, float]], np.ndarray]\n    ] = None,\n    smooth_mode: str = \"reflect\",\n) -&gt; tuple:\n    \"\"\"\n    Create an N-dimensional tuning curve from spike and position data.\n\n    Parameters\n    ----------\n    st_data : object\n        Spike train data (nelpy.SpikeTrainArray or nelpy.AnalogSignalArray).\n    pos_data : object\n        Position data (nelpy.AnalogSignalArray or nelpy.PositionArray).\n    bin_edges : List[np.ndarray]\n        List of bin edges for each dimension.\n    min_duration : float, optional\n        Minimum duration for a valid bin. Default is 0.1.\n    minbgrate : Union[int, float], optional\n        Minimum background firing rate. Default is 0.\n    tuning_curve_sigma : Optional[Union[int, float, List[Union[int, float]], np.ndarray]], optional\n        Sigma for smoothing. Can be a single value (used for all dimensions)\n        or an array/list with sigma values for each dimension. Default is None (no smoothing).\n    smooth_mode : str, optional\n        Smoothing mode. Default is \"reflect\".\n\n    Notes\n    -----\n    max_gap is not used here; position continuity should be enforced by\n    the caller (for example, SpatialMap narrows run_epochs using its\n    own `max_gap` attribute).\n\n    Returns\n    -------\n    tuple\n        A tuple containing (tuning_curve, occupancy, ratemap)\n    \"\"\"\n    # Determine number of dimensions\n    n_dims = len(bin_edges)\n\n    if n_dims != pos_data.n_signals:\n        raise ValueError(\n            f\"Number of bin_edges ({n_dims}) must match position dimensions ({pos_data.n_signals})\"\n        )\n\n    # Compute occupancy\n    occupancy = self._compute_occupancy_nd(pos_data, bin_edges)\n\n    # Compute ratemap\n    ratemap = self._compute_ratemap_nd(st_data, pos_data, occupancy, bin_edges)\n\n    # Apply minimum background firing rate (before minimum duration check)\n    ratemap[ratemap &lt; minbgrate] = minbgrate\n\n    # Apply minimum background occupancy (after minimum background firing rate)\n    for uu in range(st_data.data.shape[0]):\n        ratemap[uu][occupancy &lt; min_duration] = 0\n\n    # Create appropriate tuning curve object based on dimensions\n    if n_dims == 1:\n        tc = nel.TuningCurve1D(\n            ratemap=ratemap,\n            extmin=bin_edges[0][0],\n            extmax=bin_edges[0][-1],\n        )\n    elif n_dims == 2:\n        tc = nel.TuningCurve2D(\n            ratemap=ratemap,\n            ext_xmin=bin_edges[0][0],\n            ext_ymin=bin_edges[1][0],\n            ext_xmax=bin_edges[0][-1],\n            ext_ymax=bin_edges[1][-1],\n            ext_ny=len(bin_edges[1]) - 1,\n            ext_nx=len(bin_edges[0]) - 1,\n        )\n    else:\n        # For N-dimensional (N &gt; 2), use nelpy's TuningCurveND class\n        # Calculate extents for each dimension\n        ext_min = [bin_edges[i][0] for i in range(n_dims)]\n        ext_max = [bin_edges[i][-1] for i in range(n_dims)]\n        tc = nel.TuningCurveND(ratemap=ratemap, ext_min=ext_min, ext_max=ext_max)\n\n    tc._occupancy = occupancy\n\n    # Apply smoothing if requested\n    if tuning_curve_sigma is not None:\n        # Handle array or scalar sigma values\n        if np.isscalar(tuning_curve_sigma):\n            # Single value: use for all dimensions\n            if tuning_curve_sigma &gt; 0 and hasattr(tc, \"smooth\"):\n                tc.smooth(sigma=tuning_curve_sigma, inplace=True, mode=smooth_mode)\n        else:\n            # Array/list: convert to numpy array\n            sigma_array = np.asarray(tuning_curve_sigma)\n            if len(sigma_array) != n_dims:\n                raise ValueError(\n                    f\"Length of tuning_curve_sigma array ({len(sigma_array)}) must match \"\n                    f\"number of dimensions ({n_dims})\"\n                )\n\n            # Check if any sigma values are positive and smooth if so\n            if np.any(sigma_array &gt; 0) and hasattr(tc, \"smooth\"):\n                tc.smooth(sigma=sigma_array, inplace=True, mode=smooth_mode)\n\n    return tc, occupancy, ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap","title":"<code>SpatialMap</code>","text":"<p>               Bases: <code>NDimensionalBinner</code></p> <p>SpatialMap: make a spatial map tuning curve     maps timestamps or continuous signals onto positions</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>object</code> <p>Position data (nelpy.AnalogSignal or nel.PositionArray).</p> required <code>st</code> <code>object</code> <p>Spike train data (nelpy.SpikeTrain or nelpy.AnalogSignal).</p> required <code>speed</code> <code>Optional[object]</code> <p>Speed data (nelpy.AnalogSignal), recommended input: from non-epoched data.</p> <code>None</code> <code>dim</code> <code>Optional[int]</code> <p>Dimension of the map (1 or 2) deprecated.</p> <code>None</code> <code>dir_epoch</code> <code>Optional[object]</code> <p>Epochs of the running direction, for linear data (nelpy.Epoch) deprecated.</p> <code>None</code> <code>speed_thres</code> <code>Union[int, float]</code> <p>Speed threshold for running. Default is 4.</p> <code>4</code> <code>s_binsize</code> <code>Union[int, float, List[Union[int, float]], ndarray]</code> <p>Bin size for the spatial map. Can be a single value (used for all dimensions) or an array/list with bin sizes for each dimension. Default is 3.</p> <code>3</code> <code>x_minmax</code> <code>Optional[List[Union[int, float]]]</code> <p>Min and max x values for the spatial map.</p> <code>None</code> <code>y_minmax</code> <code>Optional[List[Union[int, float]]]</code> <p>Min and max y values for the spatial map.</p> <code>None</code> <code>dim_minmax</code> <code>Optional[List[List[Union[int, float]]]]</code> <p>Min and max values for each dimension. Should be a list of [min, max] pairs, one for each dimension. If provided, takes precedence over x_minmax and y_minmax. Example: [[0, 100], [-50, 50], [0, 200]] for 3D data.</p> <code>None</code> <code>tuning_curve_sigma</code> <code>Union[int, float, List[Union[int, float]], ndarray]</code> <p>Sigma for the tuning curve. Can be a single value (used for all dimensions) or an array/list with sigma values for each dimension. Default is 3.</p> <code>3</code> <code>smooth_mode</code> <code>str</code> <p>Mode for smoothing curve (str) reflect, constant, nearest, mirror, wrap. Default is \"reflect\".</p> <code>'reflect'</code> <code>min_duration</code> <code>float</code> <p>Minimum duration for a tuning curve. Default is 0.1.</p> <code>0.1</code> <code>minbgrate</code> <code>Union[int, float]</code> <p>Minimum firing rate for tuning curve; will set to this if lower. Default is 0.</p> <code>0</code> <code>n_shuff</code> <code>int</code> <p>Number of position shuffles for spatial information. Default is 500.</p> <code>500</code> <code>parallel_shuff</code> <code>bool</code> <p>Parallelize shuffling. Default is True.</p> <code>True</code> <code>place_field_thres</code> <code>Union[int, float]</code> <p>Percent of continuous region of peak firing rate. Default is 0.2.</p> <code>0.2</code> <code>place_field_min_size</code> <code>Optional[Union[int, float]]</code> <p>Minimum size of place field (cm).</p> <code>None</code> <code>place_field_max_size</code> <code>Optional[Union[int, float]]</code> <p>Maximum size of place field (cm).</p> <code>None</code> <code>place_field_min_peak</code> <code>Union[int, float]</code> <p>Minimum peak rate of place field. Default is 3.</p> <code>3</code> <code>place_field_sigma</code> <code>Union[int, float]</code> <p>Extra smoothing sigma to apply before field detection. Default is 2.</p> <code>2</code> <code>max_gap</code> <code>float</code> <p>Maximum gap size (in seconds) to interpolate over. Default is 0.1.</p> <code>0.1</code> <p>Attributes:</p> Name Type Description <code>tc</code> <code>TuningCurve</code> <p>Tuning curves.</p> <code>st_run</code> <code>SpikeTrain</code> <p>Spike train restricted to running epochs.</p> <code>bst_run</code> <code>binnedSpikeTrain</code> <p>Binned spike train restricted to running epochs.</p> <code>speed</code> <code>Optional[AnalogSignal]</code> <p>Speed data.</p> <code>run_epochs</code> <code>EpochArray</code> <p>Running epochs.</p> <code>_min_allowed_gap</code> <code>float</code> <p>Computed minimum allowed value for <code>max_gap</code> (seconds). This is calculated as (1/pos.fs) * (1 + tol) and is used when a user supplies a <code>max_gap</code> smaller than the sampling interval; in that case <code>self.max_gap</code> will be clamped to this value.</p> Notes <p>Place field detector (.find_fields()) is sensitive to many parameters. For 2D, it is highly recommended to have good environmental sampling. In brief testing with 300cm linear track, optimal 1D parameters were:     place_field_min_size=15     place_field_max_size=None     place_field_min_peak=3     place_field_sigma=None     place_field_thres=.33</p> TODO <p>Place field detector currently collects field width and peak rate for peak place field. In the future, these should be stored for all sub fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import nelpy as nel\n&gt;&gt;&gt; from neuro_py.tuning.maps import SpatialMap\n&gt;&gt;&gt; # Create synthetic position and spike data\n&gt;&gt;&gt; pos = nel.AnalogSignalArray(data=np.random.rand(2, 1000)*20, timestamps=np.linspace(0, 100, 1000))\n&gt;&gt;&gt; st = nel.SpikeTrainArray(time=np.sort(np.random.rand(10, 1000), axis=1), fs=1000.0)\n&gt;&gt;&gt; # Create a spatial map with 3 cm bins\n&gt;&gt;&gt; spatial_map = SpatialMap(pos=pos, st=st, s_binsize=3)\n&gt;&gt;&gt; print(spatial_map)\n&lt;TuningCurve2D at 0x21ea37a9110&gt; with shape (10, 7, 7)\n</code></pre> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>class SpatialMap(NDimensionalBinner):\n    \"\"\"\n    SpatialMap: make a spatial map tuning curve\n        maps timestamps or continuous signals onto positions\n\n    Parameters\n    ----------\n    pos : object\n        Position data (nelpy.AnalogSignal or nel.PositionArray).\n    st : object\n        Spike train data (nelpy.SpikeTrain or nelpy.AnalogSignal).\n    speed : Optional[object]\n        Speed data (nelpy.AnalogSignal), recommended input: from non-epoched data.\n    dim : Optional[int]\n        Dimension of the map (1 or 2) *deprecated*.\n    dir_epoch : Optional[object]\n        Epochs of the running direction, for linear data (nelpy.Epoch) *deprecated*.\n    speed_thres : Union[int, float], optional\n        Speed threshold for running. Default is 4.\n    s_binsize : Union[int, float, List[Union[int, float]], np.ndarray], optional\n        Bin size for the spatial map. Can be a single value (used for all dimensions)\n        or an array/list with bin sizes for each dimension. Default is 3.\n    x_minmax : Optional[List[Union[int, float]]], optional\n        Min and max x values for the spatial map.\n    y_minmax : Optional[List[Union[int, float]]], optional\n        Min and max y values for the spatial map.\n    dim_minmax : Optional[List[List[Union[int, float]]]], optional\n        Min and max values for each dimension. Should be a list of [min, max] pairs,\n        one for each dimension. If provided, takes precedence over x_minmax and y_minmax.\n        Example: [[0, 100], [-50, 50], [0, 200]] for 3D data.\n    tuning_curve_sigma : Union[int, float, List[Union[int, float]], np.ndarray], optional\n        Sigma for the tuning curve. Can be a single value (used for all dimensions)\n        or an array/list with sigma values for each dimension. Default is 3.\n    smooth_mode : str, optional\n        Mode for smoothing curve (str) reflect, constant, nearest, mirror, wrap. Default is \"reflect\".\n    min_duration : float, optional\n        Minimum duration for a tuning curve. Default is 0.1.\n    minbgrate : Union[int, float], optional\n        Minimum firing rate for tuning curve; will set to this if lower. Default is 0.\n    n_shuff : int, optional\n        Number of position shuffles for spatial information. Default is 500.\n    parallel_shuff : bool, optional\n        Parallelize shuffling. Default is True.\n    place_field_thres : Union[int, float], optional\n        Percent of continuous region of peak firing rate. Default is 0.2.\n    place_field_min_size : Optional[Union[int, float]]\n        Minimum size of place field (cm).\n    place_field_max_size : Optional[Union[int, float]]\n        Maximum size of place field (cm).\n    place_field_min_peak : Union[int, float], optional\n        Minimum peak rate of place field. Default is 3.\n    place_field_sigma : Union[int, float], optional\n        Extra smoothing sigma to apply before field detection. Default is 2.\n    max_gap : float, optional\n        Maximum gap size (in seconds) to interpolate over. Default is 0.1.\n\n    Attributes\n    ----------\n    tc : nelpy.TuningCurve\n        Tuning curves.\n    st_run : nelpy.SpikeTrain\n        Spike train restricted to running epochs.\n    bst_run : nelpy.binnedSpikeTrain\n        Binned spike train restricted to running epochs.\n    speed : Optional[nnelpy.AnalogSignal]\n        Speed data.\n    run_epochs : nelpy.EpochArray\n        Running epochs.\n    _min_allowed_gap : float\n        Computed minimum allowed value for `max_gap` (seconds). This is\n        calculated as (1/pos.fs) * (1 + tol) and is used when a user\n        supplies a `max_gap` smaller than the sampling interval; in that\n        case `self.max_gap` will be clamped to this value.\n\n    Notes\n    -----\n    Place field detector (.find_fields()) is sensitive to many parameters.\n    For 2D, it is highly recommended to have good environmental sampling.\n    In brief testing with 300cm linear track, optimal 1D parameters were:\n        place_field_min_size=15\n        place_field_max_size=None\n        place_field_min_peak=3\n        place_field_sigma=None\n        place_field_thres=.33\n\n    TODO\n    ----\n    Place field detector currently collects field width and peak rate for peak place field.\n    In the future, these should be stored for all sub fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import nelpy as nel\n    &gt;&gt;&gt; from neuro_py.tuning.maps import SpatialMap\n    &gt;&gt;&gt; # Create synthetic position and spike data\n    &gt;&gt;&gt; pos = nel.AnalogSignalArray(data=np.random.rand(2, 1000)*20, timestamps=np.linspace(0, 100, 1000))\n    &gt;&gt;&gt; st = nel.SpikeTrainArray(time=np.sort(np.random.rand(10, 1000), axis=1), fs=1000.0)\n    &gt;&gt;&gt; # Create a spatial map with 3 cm bins\n    &gt;&gt;&gt; spatial_map = SpatialMap(pos=pos, st=st, s_binsize=3)\n    &gt;&gt;&gt; print(spatial_map)\n    &lt;TuningCurve2D at 0x21ea37a9110&gt; with shape (10, 7, 7)\n    \"\"\"\n\n    def __init__(\n        self,\n        pos: object,\n        st: object,\n        speed: Optional[object] = None,\n        dim: Optional[int] = None,  # deprecated\n        dir_epoch: Optional[object] = None,  # deprecated\n        speed_thres: Union[int, float] = 4,\n        s_binsize: Union[int, float, List[Union[int, float]], np.ndarray] = 3,\n        tuning_curve_sigma: Union[int, float, List[Union[int, float]], np.ndarray] = 3,\n        x_minmax: Optional[List[Union[int, float]]] = None,\n        y_minmax: Optional[List[Union[int, float]]] = None,\n        dim_minmax: Optional[List[List[Union[int, float]]]] = None,\n        smooth_mode: str = \"reflect\",\n        min_duration: float = 0.1,\n        minbgrate: Union[int, float] = 0,\n        n_shuff: int = 500,\n        parallel_shuff: bool = True,\n        place_field_thres: Union[int, float] = 0.2,\n        place_field_min_size: Optional[Union[int, float]] = None,\n        place_field_max_size: Optional[Union[int, float]] = None,\n        place_field_min_peak: Union[int, float] = 3,\n        place_field_sigma: Union[int, float] = 2,\n        max_gap: float = 0.1,\n    ) -&gt; None:\n        # Initialize the parent class\n        super().__init__()\n\n        # add all the inputs to self\n        self.__dict__.update(locals())\n        del self.__dict__[\"self\"]\n\n        # Handle s_binsize input: normalize to array format\n        self.dim = pos.n_signals\n        if np.isscalar(s_binsize):\n            # Single value: use for all dimensions\n            self.s_binsize_array = np.full(self.dim, s_binsize)\n        else:\n            # Array/list: convert to numpy array\n            self.s_binsize_array = np.asarray(s_binsize)\n            if len(self.s_binsize_array) != self.dim:\n                raise ValueError(\n                    f\"Length of s_binsize array ({len(self.s_binsize_array)}) must match \"\n                    f\"number of position dimensions ({self.dim})\"\n                )\n\n        # Keep original s_binsize for backward compatibility in some methods\n        if np.isscalar(s_binsize):\n            self.s_binsize = s_binsize\n        else:\n            # For backward compatibility, use the first dimension's bin size\n            self.s_binsize = self.s_binsize_array[0]\n\n        # Handle dim_minmax input: normalize min/max values for each dimension\n        if dim_minmax is not None:\n            # Convert to numpy array for easier handling\n            self.dim_minmax_array = np.asarray(dim_minmax)\n            if self.dim_minmax_array.shape != (self.dim, 2):\n                raise ValueError(\n                    f\"dim_minmax must be a list of [min, max] pairs with shape ({self.dim}, 2), \"\n                    f\"got shape {self.dim_minmax_array.shape}\"\n                )\n            # Override x_minmax and y_minmax if provided\n            if self.dim &gt;= 1:\n                self.x_minmax = list(self.dim_minmax_array[0])\n            if self.dim &gt;= 2:\n                self.y_minmax = list(self.dim_minmax_array[1])\n        else:\n            # Create dim_minmax_array from existing x_minmax, y_minmax, or auto-determine\n            self.dim_minmax_array = np.zeros((self.dim, 2))\n            for dim_idx in range(self.dim):\n                if dim_idx == 0 and self.x_minmax is not None:\n                    self.dim_minmax_array[dim_idx] = self.x_minmax\n                elif dim_idx == 1 and self.y_minmax is not None:\n                    self.dim_minmax_array[dim_idx] = self.y_minmax\n                else:\n                    # Auto-determine min/max for this dimension\n                    self.dim_minmax_array[dim_idx, 0] = np.floor(\n                        np.nanmin(pos.data[dim_idx, :])\n                    )\n                    self.dim_minmax_array[dim_idx, 1] = np.ceil(\n                        np.nanmax(pos.data[dim_idx, :])\n                    )\n\n        # Handle tuning_curve_sigma input: normalize to array format\n        if np.isscalar(tuning_curve_sigma):\n            # Single value: use for all dimensions\n            self.tuning_curve_sigma_array = np.full(self.dim, tuning_curve_sigma)\n        else:\n            # Array/list: convert to numpy array\n            self.tuning_curve_sigma_array = np.asarray(tuning_curve_sigma)\n            if len(self.tuning_curve_sigma_array) != self.dim:\n                raise ValueError(\n                    f\"Length of tuning_curve_sigma array ({len(self.tuning_curve_sigma_array)}) must match \"\n                    f\"number of position dimensions ({self.dim})\"\n                )\n\n        # Keep original tuning_curve_sigma for backward compatibility in some methods\n        if np.isscalar(tuning_curve_sigma):\n            self.tuning_curve_sigma = tuning_curve_sigma\n        else:\n            # For backward compatibility, use the first dimension's sigma\n            self.tuning_curve_sigma = self.tuning_curve_sigma_array[0]\n\n        # Verify inputs: make sure pos and st are nelpy objects\n        if not isinstance(\n            pos, (nel.core._analogsignalarray.AnalogSignalArray, nel.core.PositionArray)\n        ):\n            raise TypeError(\"pos must be nelpy.AnalogSignal or nelpy.PositionArray\")\n        if not isinstance(\n            st,\n            (\n                nel.core._eventarray.SpikeTrainArray,\n                nel.core._analogsignalarray.AnalogSignalArray,\n            ),\n        ):\n            raise TypeError(\n                \"st must be nelpy.SpikeTrain or nelpy.BinnedSpikeTrainArray\"\n            )\n\n        # check data is not empty\n        if pos.isempty or st.isempty:\n            raise ValueError(\"pos and st must not be empty\")\n\n        # check if pos all nan\n        if np.all(np.isnan(pos.data)):\n            raise ValueError(\"Position data cannot contain all NaN values\")\n\n        # Ensure max_gap is not smaller than the position sampling interval\n        # (max_gap is in seconds; pos.fs is samples per second).\n        # Use a small tolerance when computing the minimum allowed gap so\n        # floating point rounding of pos timestamps doesn't cause spurious\n        # failures. If the user provided a smaller max_gap, clamp it up and\n        # warn rather than raising an exception to preserve backward\n        # compatibility and avoid breaking existing tests.\n        tol_for_min_gap = 1e-3\n        min_gap = 1.0 / pos.fs\n        min_allowed = min_gap * (1.0 + tol_for_min_gap)\n        # expose the computed minimum allowed gap on the instance\n        self._min_allowed_gap = float(min_allowed)\n        if self.max_gap &lt; min_allowed:\n            logging.warning(\n                \"Provided max_gap (%s) is smaller than the position sampling interval (%s); \"\n                \"clamping max_gap to %s\",\n                self.max_gap,\n                min_gap,\n                min_allowed,\n            )\n            # Mutate the value used internally so subsequent non-gap interval logic is safe\n            self.max_gap = float(min_allowed)\n\n        # get speed and running epochs (highly recommended you calculate\n        #   speed before hand on non epoched data)\n        if speed_thres &gt; 0:\n            if self.speed is None:\n                self.speed = nel.utils.ddt_asa(\n                    self.pos, smooth=True, sigma=0.1, norm=True\n                )\n\n            self.run_epochs = nel.utils.get_run_epochs(\n                self.speed, v1=self.speed_thres, v2=self.speed_thres\n            ).merge()\n        else:\n            self.run_epochs = self.pos.support.copy()\n\n        # Narrow run_epochs to only the continuous (non-gap) segments of the\n        # position trace so that later interpolation can safely use\n        # np.interp without masking across large dropouts. We build epochs\n        # from contiguous position timestamps (gaps &lt;= max_gap) and then\n        # intersect those with the existing run_epochs.\n        # mask out NaN samples across any dimension\n        mask = ~np.isnan(self.pos.data).any(axis=0)\n        ts = self.pos.abscissa_vals[mask]\n        if ts.size &gt; 0:\n            tol = 1e-3\n            thresh = self.max_gap * (1.0 + tol)\n\n            # find large gaps in the (clean) timestamp vector\n            diffs = np.diff(ts)\n            gap_idx = np.where(diffs &gt; thresh)[0]\n\n            # segment start/end indices in ts\n            seg_starts_idx = np.concatenate(([0], gap_idx + 1))\n            seg_ends_idx = np.concatenate((gap_idx, [len(ts) - 1]))\n\n            starts = ts[seg_starts_idx]\n            ends = ts[seg_ends_idx]\n\n            self.run_epochs = self.run_epochs &amp; nel.EpochArray(\n                np.vstack((starts, ends)).T\n            )\n\n        # calculate maps, 1d, 2d, or N-dimensional\n        self.dim = pos.n_signals\n        if pos.n_signals == 2:\n            self.tc, self.st_run = self.map_2d()\n        elif pos.n_signals == 1:\n            self.tc, self.st_run = self.map_1d()\n        elif pos.n_signals &gt; 2:\n            self.tc, self.st_run = self.map_nd()\n        else:\n            raise ValueError(\"pos dims must be &gt;= 1\")\n\n        # find place fields. Currently only collects metrics from peak field\n        # self.find_fields()\n\n    def map_1d(\n        self,\n        pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n        use_base_class: bool = False,\n    ) -&gt; tuple:\n        \"\"\"Maps 1D data for the spatial tuning curve.\n\n        Parameters\n        ----------\n        pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n            Position data.\n        use_base_class : bool, optional\n            Whether to use the new NDimensionalBinner base class functionality.\n            Default is False to maintain backward compatibility.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # dir_epoch is deprecated input\n        if self.dir_epoch is not None:\n            # warn user\n            logging.warning(\n                \"dir_epoch is deprecated and will be removed. Epoch data by direction prior to calling SpatialMap\"\n            )\n            self.st = self.st[self.dir_epoch]\n            self.pos = self.pos[self.dir_epoch]\n\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Use dimension-specific min/max values (dimension 0 for 1D)\n        x_min, x_max = self.dim_minmax_array[0]\n\n        # Use dimension-specific bin size for x-axis (dimension 0)\n        x_binsize = self.s_binsize_array[0]\n        self.x_edges = np.arange(x_min, x_max + x_binsize, x_binsize)\n\n        # Use new base class method if requested\n        if use_base_class:\n            bin_edges = [self.x_edges]\n            tc, occupancy, ratemap = self.create_nd_tuning_curve(\n                st_data=st_run,\n                pos_data=pos_run,\n                bin_edges=bin_edges,\n                min_duration=self.min_duration,\n                minbgrate=self.minbgrate,\n                tuning_curve_sigma=self.tuning_curve_sigma_array,\n                smooth_mode=self.smooth_mode,\n            )\n            return tc, st_run\n\n        # Original implementation\n        # compute occupancy\n        occupancy = self.compute_occupancy_1d(pos_run)\n\n        # compute ratemap (in Hz)\n        ratemap = self.compute_ratemap_1d(st_run, pos_run, occupancy)\n\n        # enforce minimum background firing rate\n        # background firing rate of xx Hz\n        ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n        # enforce minimum background occupancy\n        for uu in range(st_run.data.shape[0]):\n            ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n        # add to nelpy tuning curve class\n        tc = nel.TuningCurve1D(\n            ratemap=ratemap,\n            extmin=x_min,\n            extmax=x_max,\n        )\n\n        tc._occupancy = occupancy\n\n        if self.tuning_curve_sigma is not None:\n            if self.tuning_curve_sigma &gt; 0:\n                tc.smooth(\n                    sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n                )\n\n        return tc, st_run\n\n    def compute_occupancy_1d(self, pos_run: object) -&gt; np.ndarray:\n        \"\"\"Computes the occupancy for 1D position data.\n\n        Parameters\n        ----------\n        pos_run : object\n            Restricted position data for running.\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy values per bin.\n        \"\"\"\n        occupancy, _ = np.histogram(pos_run.data[0, :], bins=self.x_edges)\n        return occupancy / pos_run.fs\n\n    def compute_ratemap_1d(\n        self, st_run: object, pos_run: object, occupancy: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"Computes the ratemap for 1D data.\n\n        Parameters\n        ----------\n        st_run : object\n            Spike train data restricted to running epochs.\n        pos_run : object\n            Position data restricted to running epochs.\n        occupancy : np.ndarray\n            Occupancy values per bin.\n\n        Returns\n        -------\n        np.ndarray\n            Ratemap values for the given spike and position data.\n        \"\"\"\n        # initialize ratemap\n        ratemap = np.zeros((st_run.data.shape[0], occupancy.shape[0]))\n\n        if st_run.isempty:\n            return ratemap\n\n        mask = ~np.isnan(pos_run.data).any(axis=0)\n        x_pos, ts = (\n            pos_run.data[0, mask],\n            pos_run.abscissa_vals[mask],\n        )\n        # if data to map is spike train (point process)\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            for i in range(st_run.data.shape[0]):\n                # get spike counts in each bin\n                (\n                    ratemap[i, : len(self.x_edges)],\n                    _,\n                ) = np.histogram(\n                    np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                    bins=self.x_edges,\n                )\n\n        # if data to map is analog signal (continuous)\n        elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n            # get x location for every sample and mask invalid positions\n            x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n            positions = x.reshape(-1, 1)\n            valid_mask = ~np.isnan(positions).any(axis=1)\n\n            if np.any(valid_mask):\n                # Use 1D binned statistic to compute mean values per bin\n                pos_valid = positions[valid_mask][:, 0]\n                for uu in range(st_run.data.shape[0]):\n                    vals = st_run.data[uu, valid_mask]\n                    ratemap[uu], _, _ = binned_statistic_dd(\n                        pos_valid,\n                        vals,\n                        statistic=\"mean\",\n                        bins=[self.x_edges],\n                    )\n\n        # divide by occupancy only for spike-train (counts -&gt; rates).\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n        # remove nans and infs\n        bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n        ratemap[bad_idx] = 0\n\n        return ratemap\n\n    def map_2d(\n        self,\n        pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n        use_base_class: bool = False,\n    ) -&gt; tuple:\n        \"\"\"Maps 2D data for the spatial tuning curve.\n\n        Parameters\n        ----------\n        pos : Union[nel.AnalogSignalArray, nel.PositionArray]\n            Position data.\n        use_base_class : bool, optional\n            Whether to use the new NDimensionalBinner base class functionality.\n            Default is False to maintain backward compatibility.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Use dimension-specific min/max values\n        ext_xmin, ext_xmax = self.dim_minmax_array[0]\n        ext_ymin, ext_ymax = self.dim_minmax_array[1]\n\n        # create bin edges\n        # Use dimension-specific bin sizes\n        x_binsize = self.s_binsize_array[0]\n        y_binsize = self.s_binsize_array[1]\n        self.x_edges = np.arange(ext_xmin, ext_xmax + x_binsize, x_binsize)\n        self.y_edges = np.arange(ext_ymin, ext_ymax + y_binsize, y_binsize)\n\n        # Use new base class method if requested\n        if use_base_class:\n            bin_edges = [self.x_edges, self.y_edges]\n            tc, occupancy, ratemap = self.create_nd_tuning_curve(\n                st_data=st_run,\n                pos_data=pos_run,\n                bin_edges=bin_edges,\n                min_duration=self.min_duration,\n                minbgrate=self.minbgrate,\n                tuning_curve_sigma=self.tuning_curve_sigma_array,\n                smooth_mode=self.smooth_mode,\n            )\n            return tc, st_run\n\n        # Original implementation\n        # number of bins in each dimension\n        ext_nx, ext_ny = len(self.x_edges), len(self.y_edges)\n\n        # compute occupancy\n        occupancy = self.compute_occupancy_2d(pos_run)\n\n        # compute ratemap (in Hz)\n        ratemap = self.compute_ratemap_2d(st_run, pos_run, occupancy)\n\n        # enforce minimum background occupancy\n        for uu in range(st_run.data.shape[0]):\n            ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n        # enforce minimum background firing rate\n        # background firing rate of xx Hz\n        ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n        tc = nel.TuningCurve2D(\n            ratemap=ratemap,\n            ext_xmin=ext_xmin,\n            ext_ymin=ext_ymin,\n            ext_xmax=ext_xmax,\n            ext_ymax=ext_ymax,\n            ext_ny=ext_ny,\n            ext_nx=ext_nx,\n        )\n        tc._occupancy = occupancy\n\n        if self.tuning_curve_sigma is not None:\n            if self.tuning_curve_sigma &gt; 0:\n                tc.smooth(\n                    sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n                )\n\n        return tc, st_run\n\n    def compute_occupancy_2d(self, pos_run: object) -&gt; np.ndarray:\n        \"\"\"Computes the occupancy for 2D position data.\n\n        Parameters\n        ----------\n        pos_run : object\n            Restricted position data for running.\n\n        Returns\n        -------\n        np.ndarray\n            Occupancy values per bin.\n        \"\"\"\n        occupancy, _, _ = np.histogram2d(\n            pos_run.data[0, :], pos_run.data[1, :], bins=(self.x_edges, self.y_edges)\n        )\n        return occupancy / pos_run.fs\n\n    def compute_ratemap_2d(\n        self, st_run: object, pos_run: object, occupancy: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"Computes the ratemap for 2D data.\n\n        Parameters\n        ----------\n        st_run : object\n            Spike train data restricted to running epochs.\n        pos_run : object\n            Position data restricted to running epochs.\n        occupancy : np.ndarray\n            Occupancy values per bin.\n\n        Returns\n        -------\n        np.ndarray\n            Ratemap values for the given spike and position data.\n        \"\"\"\n        ratemap = np.zeros(\n            (st_run.data.shape[0], occupancy.shape[0], occupancy.shape[1])\n        )\n        if st_run.isempty:\n            return ratemap\n\n        # remove nans from position data for interpolation\n        mask = ~np.isnan(pos_run.data).any(axis=0)\n        x_pos, y_pos, ts = (\n            pos_run.data[0, mask],\n            pos_run.data[1, mask],\n            pos_run.abscissa_vals[mask],\n        )\n\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            for i in range(st_run.data.shape[0]):\n                ratemap[i, : len(self.x_edges), : len(self.y_edges)], _, _ = (\n                    np.histogram2d(\n                        np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                        np.interp(st_run.data[i], ts, y_pos, left=np.nan, right=np.nan),\n                        bins=(self.x_edges, self.y_edges),\n                    )\n                )\n\n        elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n            x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n            y = np.interp(st_run.abscissa_vals, ts, y_pos, left=np.nan, right=np.nan)\n            positions = np.vstack((x, y)).T\n            valid_mask = ~np.isnan(positions).any(axis=1)\n\n            if np.any(valid_mask):\n                pos_valid = positions[valid_mask]\n                for uu in range(st_run.data.shape[0]):\n                    vals = st_run.data[uu, valid_mask]\n                    ratemap[uu], _, _ = binned_statistic_dd(\n                        pos_valid,\n                        vals,\n                        statistic=\"mean\",\n                        bins=(self.x_edges, self.y_edges),\n                    )\n\n        # divide by occupancy only for spike-train (counts -&gt; rates).\n        if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n            np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n        bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n        ratemap[bad_idx] = 0\n\n        return ratemap\n\n    def map_nd(\n        self, pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None\n    ) -&gt; tuple:\n        \"\"\"Maps N-dimensional data for the spatial tuning curve using the base class.\n\n        Parameters\n        ----------\n        pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n            Position data.\n\n        Returns\n        -------\n        tuple\n            A tuple containing the tuning curve and restricted spike train.\n        \"\"\"\n        # restrict spike trains to those epochs during which the animal was running\n        st_run = self.st[self.run_epochs]\n\n        # log warning if st_run is empty following restriction\n        if st_run.isempty:\n            logging.warning(\n                \"No spike trains during running epochs\"\n            )  # This will log it but not raise a warning\n            warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n        # take pos as input for case of shuffling\n        if pos is not None:\n            pos_run = pos[self.run_epochs]\n        else:\n            pos_run = self.pos[self.run_epochs]\n\n        # Create bin edges for each dimension\n        bin_edges = []\n        for dim_idx in range(self.dim):\n            # Use dimension-specific min/max from dim_minmax_array\n            dim_min, dim_max = self.dim_minmax_array[dim_idx]\n\n            # Use dimension-specific bin size\n            dim_binsize = self.s_binsize_array[dim_idx]\n            edges = np.arange(dim_min, dim_max + dim_binsize, dim_binsize)\n            bin_edges.append(edges)\n\n        # Store bin edges for compatibility with existing code\n        self.x_edges = bin_edges[0]\n        if len(bin_edges) &gt; 1:\n            self.y_edges = bin_edges[1]\n\n        # Use the base class method to create the tuning curve\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n\n        return tc, st_run\n\n    def shuffle_spatial_information(self) -&gt; np.ndarray:\n        \"\"\"Shuffle spatial information and compute p-values for observed vs. null.\n\n        This method creates shuffled coordinates of the position data and computes\n        spatial information for each shuffle. The p-values for the observed\n        spatial information against the null distribution are calculated.\n\n        Returns\n        -------\n        np.ndarray\n            P-values for the spatial information.\n        \"\"\"\n\n        def create_shuffled_coordinates(\n            X: np.ndarray, n_shuff: int = 500\n        ) -&gt; List[np.ndarray]:\n            \"\"\"Create shuffled coordinates by rolling the original coordinates.\n\n            Parameters\n            ----------\n            X : np.ndarray\n                Original position data.\n            n_shuff : int, optional\n                Number of shuffles to create (default is 500).\n\n            Returns\n            -------\n            List[np.ndarray]\n                List of shuffled coordinates.\n            \"\"\"\n            range_ = X.shape[1]\n\n            # if fewer coordinates then shuffles, reduce number of shuffles to n coords\n            n_shuff = np.min([range_, n_shuff])\n\n            surrogate = np.random.choice(\n                np.arange(-range_, range_), size=n_shuff, replace=False\n            )\n            x_temp = []\n            for n in surrogate:\n                x_temp.append(np.roll(X, n, axis=1))\n\n            return x_temp\n\n        def get_spatial_infos(pos_shuff: np.ndarray, ts: np.ndarray, dim: int) -&gt; float:\n            \"\"\"Get spatial information for shuffled position data.\n\n            Parameters\n            ----------\n            pos_shuff : np.ndarray\n                Shuffled position data.\n            ts : np.ndarray\n                Timestamps corresponding to the shuffled data.\n            dim : int\n                Dimension of the spatial data (1 or 2).\n\n            Returns\n            -------\n            float\n                Spatial information calculated from the tuning curve.\n            \"\"\"\n            pos_shuff = nel.AnalogSignalArray(\n                data=pos_shuff,\n                timestamps=ts,\n            )\n            if dim == 1:\n                tc, _ = self.map_1d(pos_shuff)\n                return tc.spatial_information()\n            elif dim == 2:\n                tc, _ = self.map_2d(pos_shuff)\n                return tc.spatial_information()\n            else:\n                tc, _ = self.map_nd(pos_shuff)\n                return tc.spatial_information()\n\n        # Restrict position data to running epochs before creating shuffles so\n        # the null distribution reflects the actual samples used for mapping\n        # (avoid pulling non-running or gap samples into shuffles).\n        pos_run = self.pos[self.run_epochs]\n        pos_data_shuff = create_shuffled_coordinates(pos_run.data, n_shuff=self.n_shuff)\n\n        # construct tuning curves for each position shuffle\n        if self.parallel_shuff:\n            num_cores = multiprocessing.cpu_count()\n            shuffle_spatial_info = Parallel(n_jobs=num_cores)(\n                delayed(get_spatial_infos)(\n                    pos_data_shuff[i], pos_run.abscissa_vals, self.dim\n                )\n                for i in range(self.n_shuff)\n            )\n        else:\n            shuffle_spatial_info = [\n                get_spatial_infos(pos_data_shuff[i], pos_run.abscissa_vals, self.dim)\n                for i in range(self.n_shuff)\n            ]\n\n        # calculate p values for the obs vs null\n        _, self.spatial_information_pvalues, self.spatial_information_zscore = (\n            get_significant_events(\n                self.tc.spatial_information(), np.array(shuffle_spatial_info)\n            )\n        )\n\n        return self.spatial_information_pvalues\n\n    def find_fields(self) -&gt; None:\n        \"\"\"Find place fields in the spatial maps.\n\n        This method detects place fields from the spatial maps and calculates\n        their properties, including width, peak firing rate, and a mask for\n        each detected field.\n        \"\"\"\n        from skimage import measure\n\n        field_width = []\n        peak_rate = []\n        mask = []\n\n        if self.place_field_max_size is None and self.dim == 1:\n            # For 1D, use the bin size for dimension 0\n            self.place_field_max_size = self.tc.n_bins * self.s_binsize_array[0]\n        elif self.place_field_max_size is None and self.dim == 2:\n            # For 2D, use the average of both dimensions or the maximum\n            avg_binsize = np.mean(self.s_binsize_array[:2])\n            self.place_field_max_size = self.tc.n_bins * avg_binsize\n\n        if self.dim == 1:\n            # Use bin size for dimension 0 (x-axis)\n            x_binsize = self.s_binsize_array[0]\n            for ratemap_ in self.tc.ratemap:\n                map_fields = fields.map_stats2(\n                    ratemap_,\n                    threshold=self.place_field_thres,\n                    min_size=self.place_field_min_size / x_binsize,\n                    max_size=self.place_field_max_size / x_binsize,\n                    min_peak=self.place_field_min_peak,\n                    sigma=self.place_field_sigma,\n                )\n                if len(map_fields[\"sizes\"]) == 0:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(map_fields[\"fields\"])\n                else:\n                    field_width.append(\n                        np.array(map_fields[\"sizes\"]).max() * len(ratemap_) * x_binsize\n                    )\n                    peak_rate.append(np.array(map_fields[\"peaks\"]).max())\n                    mask.append(map_fields[\"fields\"])\n\n        if self.dim == 2:\n            # Use average of x and y bin sizes for 2D field calculations\n            avg_binsize = np.mean(self.s_binsize_array[:2])\n            for ratemap_ in self.tc.ratemap:\n                peaks = fields.compute_2d_place_fields(\n                    ratemap_,\n                    min_firing_rate=self.place_field_min_peak,\n                    thresh=self.place_field_thres,\n                    min_size=(self.place_field_min_size / avg_binsize),\n                    max_size=(self.place_field_max_size / avg_binsize),\n                    sigma=self.place_field_sigma,\n                )\n                # field coords of fields using contours\n                bc = measure.find_contours(\n                    peaks, 0, fully_connected=\"low\", positive_orientation=\"low\"\n                )\n                if len(bc) == 0:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(peaks)\n                elif np.vstack(bc).shape[0] &lt; 3:\n                    field_width.append(np.nan)\n                    peak_rate.append(np.nan)\n                    mask.append(peaks)\n                else:\n                    field_width.append(np.max(pdist(bc[0], \"euclidean\")) * avg_binsize)\n                    # field_ids = np.unique(peaks)\n                    peak_rate.append(ratemap_[peaks == 1].max())\n                    mask.append(peaks)\n\n        self.tc.field_width = np.array(field_width)\n        self.tc.field_peak_rate = np.array(peak_rate)\n        self.tc.field_mask = np.array(mask)\n        self.tc.n_fields = np.array(\n            [len(np.unique(mask_)) - 1 for mask_ in self.tc.field_mask]\n        )\n\n    def save_mat_file(self, basepath: str, UID: Optional[Any] = None) -&gt; None:\n        \"\"\"Save firing rate map data to a .mat file in MATLAB format.\n\n        The saved file will contain the following variables:\n        - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps.\n        - field: a 1xN cell array containing the field masks, if they exist.\n        - n_fields: the number of fields detected.\n        - size: the width of the detected fields.\n        - peak: the peak firing rate of the detected fields.\n        - occupancy: the occupancy map.\n        - spatial_information: the spatial information of the ratemaps.\n        - spatial_sparsity: the spatial sparsity of the ratemaps.\n        - x_bins: the bin edges for the x-axis of the ratemaps.\n        - y_bins: the bin edges for the y-axis of the ratemaps.\n        - run_epochs: the time points at which the animal was running.\n        - speed: the speed data.\n        - timestamps: the timestamps for the speed data.\n        - pos: the position data.\n\n        The file will be saved to a .mat file with the name `basepath.ratemap.firingRateMap.mat`,\n        where `basepath` is the base path of the data.\n\n        Parameters\n        ----------\n        basepath : str\n            The base path for saving the .mat file.\n        UID : Optional[Any], optional\n            A unique identifier for the data (default is None).\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self.dim == 1:\n            raise ValueError(\"1d storeage not implemented\")\n\n        # set up dict\n        firingRateMap = {}\n\n        # store UID if exist\n        if UID is not None:\n            firingRateMap[\"UID\"] = UID.tolist()\n\n        # set up empty fields for conversion to matlab cell array\n        firingRateMap[\"map\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n        firingRateMap[\"field\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n\n        # Iterate over the ratemaps and store each one in a cell of the cell array\n        for i, ratemap in enumerate(self.tc.ratemap):\n            firingRateMap[\"map\"][i] = ratemap\n\n        # store occupancy\n        firingRateMap[\"occupancy\"] = self.tc.occupancy\n\n        # store bin edges\n        firingRateMap[\"x_bins\"] = self.tc.xbins.tolist()\n        firingRateMap[\"y_bins\"] = self.tc.ybins.tolist()\n\n        # store field mask if exist\n        if hasattr(self.tc, \"field_mask\"):\n            for i, field_mask in enumerate(self.tc.field_mask):\n                firingRateMap[\"field\"][i] = field_mask\n\n            # store field finding info\n            firingRateMap[\"n_fields\"] = self.tc.n_fields.tolist()\n            firingRateMap[\"size\"] = self.tc.field_width.tolist()\n            firingRateMap[\"peak\"] = self.tc.field_peak_rate.tolist()\n\n        # store spatial metrics\n        firingRateMap[\"spatial_information\"] = self.tc.spatial_information().tolist()\n        if hasattr(self, \"spatial_information_pvalues\"):\n            firingRateMap[\"spatial_information_pvalues\"] = (\n                self.spatial_information_pvalues.tolist()\n            )\n        firingRateMap[\"spatial_sparsity\"] = self.tc.spatial_sparsity().tolist()\n\n        # store position speed and timestamps\n        firingRateMap[\"timestamps\"] = self.speed.abscissa_vals.tolist()\n        firingRateMap[\"pos\"] = self.pos.data\n        firingRateMap[\"speed\"] = self.speed.data.tolist()\n        firingRateMap[\"run_epochs\"] = self.run_epochs.time.tolist()\n\n        # store epoch interval\n        firingRateMap[\"epoch_interval\"] = [\n            self.pos.support.start,\n            self.pos.support.stop,\n        ]\n\n        # save matlab file\n        savemat(\n            os.path.join(\n                basepath, os.path.basename(basepath) + \".ratemap.firingRateMap.mat\"\n            ),\n            {\"firingRateMap\": firingRateMap},\n        )\n\n    def _unit_subset(self, unit_list):\n        newtuningcurve = copy.copy(self)\n        newtuningcurve.st = newtuningcurve.st._unit_subset(unit_list)\n        newtuningcurve.st_run = newtuningcurve.st_run._unit_subset(unit_list)\n        newtuningcurve.tc = self.tc._unit_subset(unit_list)\n        return newtuningcurve\n\n    @property\n    def is2d(self):\n        return self.tc.is2d\n\n    @property\n    def occupancy(self):\n        return self.tc._occupancy\n\n    @property\n    def n_units(self):\n        return self.tc.n_units\n\n    @property\n    def shape(self):\n        return self.tc.shape\n\n    def __repr__(self):\n        return self.tc.__repr__()\n\n    @property\n    def isempty(self):\n        return self.tc.isempty\n\n    @property\n    def ratemap(self):\n        return self.tc.ratemap\n\n    def __len__(self):\n        return self.tc.__len__()\n\n    def smooth(self, **kwargs):\n        return self.tc.smooth(**kwargs)\n\n    @property\n    def mean(self):\n        return self.tc.mean\n\n    @property\n    def std(self):\n        return self.tc.std\n\n    @property\n    def max(self):\n        return self.tc.max\n\n    @property\n    def min(self):\n        return self.tc.min\n\n    @property\n    def mask(self):\n        return self.tc.mask\n\n    @property\n    def n_bins(self):\n        return self.tc.n_bins\n\n    @property\n    def n_xbins(self):\n        return self.tc.n_xbins\n\n    @property\n    def n_ybins(self):\n        return self.tc.n_ybins\n\n    @property\n    def xbins(self):\n        return self.tc.xbins\n\n    @property\n    def ybins(self):\n        return self.tc.ybins\n\n    @property\n    def xbin_centers(self):\n        return self.tc.xbin_centers\n\n    @property\n    def ybin_centers(self):\n        return self.tc.ybin_centers\n\n    @property\n    def bin_centers(self):\n        return self.tc.bin_centers\n\n    @property\n    def bins(self):\n        return self.tc.bins\n\n    def normalize(self, **kwargs):\n        return self.tc.normalize(**kwargs)\n\n    @property\n    def spatial_sparsity(self):\n        return self.tc.spatial_sparsity\n\n    @property\n    def spatial_information(self):\n        return self.tc.spatial_information\n\n    @property\n    def information_rate(self):\n        return self.tc.information_rate\n\n    @property\n    def spatial_selectivity(self):\n        return self.tc.spatial_selectivity\n\n    def __sub__(self, other):\n        return self.tc.__sub__(other)\n\n    def __mul__(self, other):\n        return self.tc.__mul__(other)\n\n    def __rmul__(self, other):\n        return self.tc.__rmul__(other)\n\n    def __truediv__(self, other):\n        return self.tc.__truediv__(other)\n\n    def __iter__(self):\n        return self.tc.__iter__()\n\n    def __next__(self):\n        return self.tc.__next__()\n\n    def __getitem__(self, *idx):\n        return self.tc.__getitem__(*idx)\n\n    def _get_peak_firing_order_idx(self):\n        return self.tc._get_peak_firing_order_idx()\n\n    def get_peak_firing_order_ids(self):\n        return self.tc.get_peak_firing_order_ids()\n\n    def _reorder_units_by_idx(self):\n        return self.tc._reorder_units_by_idx()\n\n    def reorder_units_by_ids(self):\n        return self.tc.reorder_units_by_ids()\n\n    def reorder_units(self):\n        return self.tc.reorder_units()\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.compute_occupancy_1d","title":"<code>compute_occupancy_1d(pos_run)</code>","text":"<p>Computes the occupancy for 1D position data.</p> <p>Parameters:</p> Name Type Description Default <code>pos_run</code> <code>object</code> <p>Restricted position data for running.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Occupancy values per bin.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_occupancy_1d(self, pos_run: object) -&gt; np.ndarray:\n    \"\"\"Computes the occupancy for 1D position data.\n\n    Parameters\n    ----------\n    pos_run : object\n        Restricted position data for running.\n\n    Returns\n    -------\n    np.ndarray\n        Occupancy values per bin.\n    \"\"\"\n    occupancy, _ = np.histogram(pos_run.data[0, :], bins=self.x_edges)\n    return occupancy / pos_run.fs\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.compute_occupancy_2d","title":"<code>compute_occupancy_2d(pos_run)</code>","text":"<p>Computes the occupancy for 2D position data.</p> <p>Parameters:</p> Name Type Description Default <code>pos_run</code> <code>object</code> <p>Restricted position data for running.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Occupancy values per bin.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_occupancy_2d(self, pos_run: object) -&gt; np.ndarray:\n    \"\"\"Computes the occupancy for 2D position data.\n\n    Parameters\n    ----------\n    pos_run : object\n        Restricted position data for running.\n\n    Returns\n    -------\n    np.ndarray\n        Occupancy values per bin.\n    \"\"\"\n    occupancy, _, _ = np.histogram2d(\n        pos_run.data[0, :], pos_run.data[1, :], bins=(self.x_edges, self.y_edges)\n    )\n    return occupancy / pos_run.fs\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.compute_ratemap_1d","title":"<code>compute_ratemap_1d(st_run, pos_run, occupancy)</code>","text":"<p>Computes the ratemap for 1D data.</p> <p>Parameters:</p> Name Type Description Default <code>st_run</code> <code>object</code> <p>Spike train data restricted to running epochs.</p> required <code>pos_run</code> <code>object</code> <p>Position data restricted to running epochs.</p> required <code>occupancy</code> <code>ndarray</code> <p>Occupancy values per bin.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Ratemap values for the given spike and position data.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_ratemap_1d(\n    self, st_run: object, pos_run: object, occupancy: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Computes the ratemap for 1D data.\n\n    Parameters\n    ----------\n    st_run : object\n        Spike train data restricted to running epochs.\n    pos_run : object\n        Position data restricted to running epochs.\n    occupancy : np.ndarray\n        Occupancy values per bin.\n\n    Returns\n    -------\n    np.ndarray\n        Ratemap values for the given spike and position data.\n    \"\"\"\n    # initialize ratemap\n    ratemap = np.zeros((st_run.data.shape[0], occupancy.shape[0]))\n\n    if st_run.isempty:\n        return ratemap\n\n    mask = ~np.isnan(pos_run.data).any(axis=0)\n    x_pos, ts = (\n        pos_run.data[0, mask],\n        pos_run.abscissa_vals[mask],\n    )\n    # if data to map is spike train (point process)\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        for i in range(st_run.data.shape[0]):\n            # get spike counts in each bin\n            (\n                ratemap[i, : len(self.x_edges)],\n                _,\n            ) = np.histogram(\n                np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                bins=self.x_edges,\n            )\n\n    # if data to map is analog signal (continuous)\n    elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n        # get x location for every sample and mask invalid positions\n        x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n        positions = x.reshape(-1, 1)\n        valid_mask = ~np.isnan(positions).any(axis=1)\n\n        if np.any(valid_mask):\n            # Use 1D binned statistic to compute mean values per bin\n            pos_valid = positions[valid_mask][:, 0]\n            for uu in range(st_run.data.shape[0]):\n                vals = st_run.data[uu, valid_mask]\n                ratemap[uu], _, _ = binned_statistic_dd(\n                    pos_valid,\n                    vals,\n                    statistic=\"mean\",\n                    bins=[self.x_edges],\n                )\n\n    # divide by occupancy only for spike-train (counts -&gt; rates).\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n    # remove nans and infs\n    bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n    ratemap[bad_idx] = 0\n\n    return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.compute_ratemap_2d","title":"<code>compute_ratemap_2d(st_run, pos_run, occupancy)</code>","text":"<p>Computes the ratemap for 2D data.</p> <p>Parameters:</p> Name Type Description Default <code>st_run</code> <code>object</code> <p>Spike train data restricted to running epochs.</p> required <code>pos_run</code> <code>object</code> <p>Position data restricted to running epochs.</p> required <code>occupancy</code> <code>ndarray</code> <p>Occupancy values per bin.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Ratemap values for the given spike and position data.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def compute_ratemap_2d(\n    self, st_run: object, pos_run: object, occupancy: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Computes the ratemap for 2D data.\n\n    Parameters\n    ----------\n    st_run : object\n        Spike train data restricted to running epochs.\n    pos_run : object\n        Position data restricted to running epochs.\n    occupancy : np.ndarray\n        Occupancy values per bin.\n\n    Returns\n    -------\n    np.ndarray\n        Ratemap values for the given spike and position data.\n    \"\"\"\n    ratemap = np.zeros(\n        (st_run.data.shape[0], occupancy.shape[0], occupancy.shape[1])\n    )\n    if st_run.isempty:\n        return ratemap\n\n    # remove nans from position data for interpolation\n    mask = ~np.isnan(pos_run.data).any(axis=0)\n    x_pos, y_pos, ts = (\n        pos_run.data[0, mask],\n        pos_run.data[1, mask],\n        pos_run.abscissa_vals[mask],\n    )\n\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        for i in range(st_run.data.shape[0]):\n            ratemap[i, : len(self.x_edges), : len(self.y_edges)], _, _ = (\n                np.histogram2d(\n                    np.interp(st_run.data[i], ts, x_pos, left=np.nan, right=np.nan),\n                    np.interp(st_run.data[i], ts, y_pos, left=np.nan, right=np.nan),\n                    bins=(self.x_edges, self.y_edges),\n                )\n            )\n\n    elif isinstance(st_run, nel.core._analogsignalarray.AnalogSignalArray):\n        x = np.interp(st_run.abscissa_vals, ts, x_pos, left=np.nan, right=np.nan)\n        y = np.interp(st_run.abscissa_vals, ts, y_pos, left=np.nan, right=np.nan)\n        positions = np.vstack((x, y)).T\n        valid_mask = ~np.isnan(positions).any(axis=1)\n\n        if np.any(valid_mask):\n            pos_valid = positions[valid_mask]\n            for uu in range(st_run.data.shape[0]):\n                vals = st_run.data[uu, valid_mask]\n                ratemap[uu], _, _ = binned_statistic_dd(\n                    pos_valid,\n                    vals,\n                    statistic=\"mean\",\n                    bins=(self.x_edges, self.y_edges),\n                )\n\n    # divide by occupancy only for spike-train (counts -&gt; rates).\n    if isinstance(st_run, nel.core._eventarray.SpikeTrainArray):\n        np.divide(ratemap, occupancy, where=occupancy != 0, out=ratemap)\n\n    bad_idx = np.isnan(ratemap) | np.isinf(ratemap)\n    ratemap[bad_idx] = 0\n\n    return ratemap\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.find_fields","title":"<code>find_fields()</code>","text":"<p>Find place fields in the spatial maps.</p> <p>This method detects place fields from the spatial maps and calculates their properties, including width, peak firing rate, and a mask for each detected field.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def find_fields(self) -&gt; None:\n    \"\"\"Find place fields in the spatial maps.\n\n    This method detects place fields from the spatial maps and calculates\n    their properties, including width, peak firing rate, and a mask for\n    each detected field.\n    \"\"\"\n    from skimage import measure\n\n    field_width = []\n    peak_rate = []\n    mask = []\n\n    if self.place_field_max_size is None and self.dim == 1:\n        # For 1D, use the bin size for dimension 0\n        self.place_field_max_size = self.tc.n_bins * self.s_binsize_array[0]\n    elif self.place_field_max_size is None and self.dim == 2:\n        # For 2D, use the average of both dimensions or the maximum\n        avg_binsize = np.mean(self.s_binsize_array[:2])\n        self.place_field_max_size = self.tc.n_bins * avg_binsize\n\n    if self.dim == 1:\n        # Use bin size for dimension 0 (x-axis)\n        x_binsize = self.s_binsize_array[0]\n        for ratemap_ in self.tc.ratemap:\n            map_fields = fields.map_stats2(\n                ratemap_,\n                threshold=self.place_field_thres,\n                min_size=self.place_field_min_size / x_binsize,\n                max_size=self.place_field_max_size / x_binsize,\n                min_peak=self.place_field_min_peak,\n                sigma=self.place_field_sigma,\n            )\n            if len(map_fields[\"sizes\"]) == 0:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(map_fields[\"fields\"])\n            else:\n                field_width.append(\n                    np.array(map_fields[\"sizes\"]).max() * len(ratemap_) * x_binsize\n                )\n                peak_rate.append(np.array(map_fields[\"peaks\"]).max())\n                mask.append(map_fields[\"fields\"])\n\n    if self.dim == 2:\n        # Use average of x and y bin sizes for 2D field calculations\n        avg_binsize = np.mean(self.s_binsize_array[:2])\n        for ratemap_ in self.tc.ratemap:\n            peaks = fields.compute_2d_place_fields(\n                ratemap_,\n                min_firing_rate=self.place_field_min_peak,\n                thresh=self.place_field_thres,\n                min_size=(self.place_field_min_size / avg_binsize),\n                max_size=(self.place_field_max_size / avg_binsize),\n                sigma=self.place_field_sigma,\n            )\n            # field coords of fields using contours\n            bc = measure.find_contours(\n                peaks, 0, fully_connected=\"low\", positive_orientation=\"low\"\n            )\n            if len(bc) == 0:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(peaks)\n            elif np.vstack(bc).shape[0] &lt; 3:\n                field_width.append(np.nan)\n                peak_rate.append(np.nan)\n                mask.append(peaks)\n            else:\n                field_width.append(np.max(pdist(bc[0], \"euclidean\")) * avg_binsize)\n                # field_ids = np.unique(peaks)\n                peak_rate.append(ratemap_[peaks == 1].max())\n                mask.append(peaks)\n\n    self.tc.field_width = np.array(field_width)\n    self.tc.field_peak_rate = np.array(peak_rate)\n    self.tc.field_mask = np.array(mask)\n    self.tc.n_fields = np.array(\n        [len(np.unique(mask_)) - 1 for mask_ in self.tc.field_mask]\n    )\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.map_1d","title":"<code>map_1d(pos=None, use_base_class=False)</code>","text":"<p>Maps 1D data for the spatial tuning curve.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Optional[Union[AnalogSignalArray, PositionArray]]</code> <p>Position data.</p> <code>None</code> <code>use_base_class</code> <code>bool</code> <p>Whether to use the new NDimensionalBinner base class functionality. Default is False to maintain backward compatibility.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_1d(\n    self,\n    pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n    use_base_class: bool = False,\n) -&gt; tuple:\n    \"\"\"Maps 1D data for the spatial tuning curve.\n\n    Parameters\n    ----------\n    pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n        Position data.\n    use_base_class : bool, optional\n        Whether to use the new NDimensionalBinner base class functionality.\n        Default is False to maintain backward compatibility.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # dir_epoch is deprecated input\n    if self.dir_epoch is not None:\n        # warn user\n        logging.warning(\n            \"dir_epoch is deprecated and will be removed. Epoch data by direction prior to calling SpatialMap\"\n        )\n        self.st = self.st[self.dir_epoch]\n        self.pos = self.pos[self.dir_epoch]\n\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Use dimension-specific min/max values (dimension 0 for 1D)\n    x_min, x_max = self.dim_minmax_array[0]\n\n    # Use dimension-specific bin size for x-axis (dimension 0)\n    x_binsize = self.s_binsize_array[0]\n    self.x_edges = np.arange(x_min, x_max + x_binsize, x_binsize)\n\n    # Use new base class method if requested\n    if use_base_class:\n        bin_edges = [self.x_edges]\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n        return tc, st_run\n\n    # Original implementation\n    # compute occupancy\n    occupancy = self.compute_occupancy_1d(pos_run)\n\n    # compute ratemap (in Hz)\n    ratemap = self.compute_ratemap_1d(st_run, pos_run, occupancy)\n\n    # enforce minimum background firing rate\n    # background firing rate of xx Hz\n    ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n    # enforce minimum background occupancy\n    for uu in range(st_run.data.shape[0]):\n        ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n    # add to nelpy tuning curve class\n    tc = nel.TuningCurve1D(\n        ratemap=ratemap,\n        extmin=x_min,\n        extmax=x_max,\n    )\n\n    tc._occupancy = occupancy\n\n    if self.tuning_curve_sigma is not None:\n        if self.tuning_curve_sigma &gt; 0:\n            tc.smooth(\n                sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n            )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.map_2d","title":"<code>map_2d(pos=None, use_base_class=False)</code>","text":"<p>Maps 2D data for the spatial tuning curve.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Union[AnalogSignalArray, PositionArray]</code> <p>Position data.</p> <code>None</code> <code>use_base_class</code> <code>bool</code> <p>Whether to use the new NDimensionalBinner base class functionality. Default is False to maintain backward compatibility.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_2d(\n    self,\n    pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None,\n    use_base_class: bool = False,\n) -&gt; tuple:\n    \"\"\"Maps 2D data for the spatial tuning curve.\n\n    Parameters\n    ----------\n    pos : Union[nel.AnalogSignalArray, nel.PositionArray]\n        Position data.\n    use_base_class : bool, optional\n        Whether to use the new NDimensionalBinner base class functionality.\n        Default is False to maintain backward compatibility.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Use dimension-specific min/max values\n    ext_xmin, ext_xmax = self.dim_minmax_array[0]\n    ext_ymin, ext_ymax = self.dim_minmax_array[1]\n\n    # create bin edges\n    # Use dimension-specific bin sizes\n    x_binsize = self.s_binsize_array[0]\n    y_binsize = self.s_binsize_array[1]\n    self.x_edges = np.arange(ext_xmin, ext_xmax + x_binsize, x_binsize)\n    self.y_edges = np.arange(ext_ymin, ext_ymax + y_binsize, y_binsize)\n\n    # Use new base class method if requested\n    if use_base_class:\n        bin_edges = [self.x_edges, self.y_edges]\n        tc, occupancy, ratemap = self.create_nd_tuning_curve(\n            st_data=st_run,\n            pos_data=pos_run,\n            bin_edges=bin_edges,\n            min_duration=self.min_duration,\n            minbgrate=self.minbgrate,\n            tuning_curve_sigma=self.tuning_curve_sigma_array,\n            smooth_mode=self.smooth_mode,\n        )\n        return tc, st_run\n\n    # Original implementation\n    # number of bins in each dimension\n    ext_nx, ext_ny = len(self.x_edges), len(self.y_edges)\n\n    # compute occupancy\n    occupancy = self.compute_occupancy_2d(pos_run)\n\n    # compute ratemap (in Hz)\n    ratemap = self.compute_ratemap_2d(st_run, pos_run, occupancy)\n\n    # enforce minimum background occupancy\n    for uu in range(st_run.data.shape[0]):\n        ratemap[uu][occupancy &lt; self.min_duration] = 0\n\n    # enforce minimum background firing rate\n    # background firing rate of xx Hz\n    ratemap[ratemap &lt; self.minbgrate] = self.minbgrate\n\n    tc = nel.TuningCurve2D(\n        ratemap=ratemap,\n        ext_xmin=ext_xmin,\n        ext_ymin=ext_ymin,\n        ext_xmax=ext_xmax,\n        ext_ymax=ext_ymax,\n        ext_ny=ext_ny,\n        ext_nx=ext_nx,\n    )\n    tc._occupancy = occupancy\n\n    if self.tuning_curve_sigma is not None:\n        if self.tuning_curve_sigma &gt; 0:\n            tc.smooth(\n                sigma=self.tuning_curve_sigma, inplace=True, mode=self.smooth_mode\n            )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.map_nd","title":"<code>map_nd(pos=None)</code>","text":"<p>Maps N-dimensional data for the spatial tuning curve using the base class.</p> <p>Parameters:</p> Name Type Description Default <code>pos</code> <code>Optional[Union[AnalogSignalArray, PositionArray]]</code> <p>Position data.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the tuning curve and restricted spike train.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def map_nd(\n    self, pos: Optional[Union[nel.AnalogSignalArray, nel.PositionArray]] = None\n) -&gt; tuple:\n    \"\"\"Maps N-dimensional data for the spatial tuning curve using the base class.\n\n    Parameters\n    ----------\n    pos : Optional[Union[nel.AnalogSignalArray, nel.PositionArray]]\n        Position data.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the tuning curve and restricted spike train.\n    \"\"\"\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = self.st[self.run_epochs]\n\n    # log warning if st_run is empty following restriction\n    if st_run.isempty:\n        logging.warning(\n            \"No spike trains during running epochs\"\n        )  # This will log it but not raise a warning\n        warnings.warn(\"No spike trains during running epochs\", UserWarning)\n\n    # take pos as input for case of shuffling\n    if pos is not None:\n        pos_run = pos[self.run_epochs]\n    else:\n        pos_run = self.pos[self.run_epochs]\n\n    # Create bin edges for each dimension\n    bin_edges = []\n    for dim_idx in range(self.dim):\n        # Use dimension-specific min/max from dim_minmax_array\n        dim_min, dim_max = self.dim_minmax_array[dim_idx]\n\n        # Use dimension-specific bin size\n        dim_binsize = self.s_binsize_array[dim_idx]\n        edges = np.arange(dim_min, dim_max + dim_binsize, dim_binsize)\n        bin_edges.append(edges)\n\n    # Store bin edges for compatibility with existing code\n    self.x_edges = bin_edges[0]\n    if len(bin_edges) &gt; 1:\n        self.y_edges = bin_edges[1]\n\n    # Use the base class method to create the tuning curve\n    tc, occupancy, ratemap = self.create_nd_tuning_curve(\n        st_data=st_run,\n        pos_data=pos_run,\n        bin_edges=bin_edges,\n        min_duration=self.min_duration,\n        minbgrate=self.minbgrate,\n        tuning_curve_sigma=self.tuning_curve_sigma_array,\n        smooth_mode=self.smooth_mode,\n    )\n\n    return tc, st_run\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.save_mat_file","title":"<code>save_mat_file(basepath, UID=None)</code>","text":"<p>Save firing rate map data to a .mat file in MATLAB format.</p> <p>The saved file will contain the following variables: - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps. - field: a 1xN cell array containing the field masks, if they exist. - n_fields: the number of fields detected. - size: the width of the detected fields. - peak: the peak firing rate of the detected fields. - occupancy: the occupancy map. - spatial_information: the spatial information of the ratemaps. - spatial_sparsity: the spatial sparsity of the ratemaps. - x_bins: the bin edges for the x-axis of the ratemaps. - y_bins: the bin edges for the y-axis of the ratemaps. - run_epochs: the time points at which the animal was running. - speed: the speed data. - timestamps: the timestamps for the speed data. - pos: the position data.</p> <p>The file will be saved to a .mat file with the name <code>basepath.ratemap.firingRateMap.mat</code>, where <code>basepath</code> is the base path of the data.</p> <p>Parameters:</p> Name Type Description Default <code>basepath</code> <code>str</code> <p>The base path for saving the .mat file.</p> required <code>UID</code> <code>Optional[Any]</code> <p>A unique identifier for the data (default is None).</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def save_mat_file(self, basepath: str, UID: Optional[Any] = None) -&gt; None:\n    \"\"\"Save firing rate map data to a .mat file in MATLAB format.\n\n    The saved file will contain the following variables:\n    - map: a 1xN cell array containing the ratemaps, where N is the number of ratemaps.\n    - field: a 1xN cell array containing the field masks, if they exist.\n    - n_fields: the number of fields detected.\n    - size: the width of the detected fields.\n    - peak: the peak firing rate of the detected fields.\n    - occupancy: the occupancy map.\n    - spatial_information: the spatial information of the ratemaps.\n    - spatial_sparsity: the spatial sparsity of the ratemaps.\n    - x_bins: the bin edges for the x-axis of the ratemaps.\n    - y_bins: the bin edges for the y-axis of the ratemaps.\n    - run_epochs: the time points at which the animal was running.\n    - speed: the speed data.\n    - timestamps: the timestamps for the speed data.\n    - pos: the position data.\n\n    The file will be saved to a .mat file with the name `basepath.ratemap.firingRateMap.mat`,\n    where `basepath` is the base path of the data.\n\n    Parameters\n    ----------\n    basepath : str\n        The base path for saving the .mat file.\n    UID : Optional[Any], optional\n        A unique identifier for the data (default is None).\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if self.dim == 1:\n        raise ValueError(\"1d storeage not implemented\")\n\n    # set up dict\n    firingRateMap = {}\n\n    # store UID if exist\n    if UID is not None:\n        firingRateMap[\"UID\"] = UID.tolist()\n\n    # set up empty fields for conversion to matlab cell array\n    firingRateMap[\"map\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n    firingRateMap[\"field\"] = np.empty(self.tc.ratemap.shape[0], dtype=object)\n\n    # Iterate over the ratemaps and store each one in a cell of the cell array\n    for i, ratemap in enumerate(self.tc.ratemap):\n        firingRateMap[\"map\"][i] = ratemap\n\n    # store occupancy\n    firingRateMap[\"occupancy\"] = self.tc.occupancy\n\n    # store bin edges\n    firingRateMap[\"x_bins\"] = self.tc.xbins.tolist()\n    firingRateMap[\"y_bins\"] = self.tc.ybins.tolist()\n\n    # store field mask if exist\n    if hasattr(self.tc, \"field_mask\"):\n        for i, field_mask in enumerate(self.tc.field_mask):\n            firingRateMap[\"field\"][i] = field_mask\n\n        # store field finding info\n        firingRateMap[\"n_fields\"] = self.tc.n_fields.tolist()\n        firingRateMap[\"size\"] = self.tc.field_width.tolist()\n        firingRateMap[\"peak\"] = self.tc.field_peak_rate.tolist()\n\n    # store spatial metrics\n    firingRateMap[\"spatial_information\"] = self.tc.spatial_information().tolist()\n    if hasattr(self, \"spatial_information_pvalues\"):\n        firingRateMap[\"spatial_information_pvalues\"] = (\n            self.spatial_information_pvalues.tolist()\n        )\n    firingRateMap[\"spatial_sparsity\"] = self.tc.spatial_sparsity().tolist()\n\n    # store position speed and timestamps\n    firingRateMap[\"timestamps\"] = self.speed.abscissa_vals.tolist()\n    firingRateMap[\"pos\"] = self.pos.data\n    firingRateMap[\"speed\"] = self.speed.data.tolist()\n    firingRateMap[\"run_epochs\"] = self.run_epochs.time.tolist()\n\n    # store epoch interval\n    firingRateMap[\"epoch_interval\"] = [\n        self.pos.support.start,\n        self.pos.support.stop,\n    ]\n\n    # save matlab file\n    savemat(\n        os.path.join(\n            basepath, os.path.basename(basepath) + \".ratemap.firingRateMap.mat\"\n        ),\n        {\"firingRateMap\": firingRateMap},\n    )\n</code></pre>"},{"location":"reference/neuro_py/tuning/maps/#neuro_py.tuning.maps.SpatialMap.shuffle_spatial_information","title":"<code>shuffle_spatial_information()</code>","text":"<p>Shuffle spatial information and compute p-values for observed vs. null.</p> <p>This method creates shuffled coordinates of the position data and computes spatial information for each shuffle. The p-values for the observed spatial information against the null distribution are calculated.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>P-values for the spatial information.</p> Source code in <code>neuro_py/tuning/maps.py</code> <pre><code>def shuffle_spatial_information(self) -&gt; np.ndarray:\n    \"\"\"Shuffle spatial information and compute p-values for observed vs. null.\n\n    This method creates shuffled coordinates of the position data and computes\n    spatial information for each shuffle. The p-values for the observed\n    spatial information against the null distribution are calculated.\n\n    Returns\n    -------\n    np.ndarray\n        P-values for the spatial information.\n    \"\"\"\n\n    def create_shuffled_coordinates(\n        X: np.ndarray, n_shuff: int = 500\n    ) -&gt; List[np.ndarray]:\n        \"\"\"Create shuffled coordinates by rolling the original coordinates.\n\n        Parameters\n        ----------\n        X : np.ndarray\n            Original position data.\n        n_shuff : int, optional\n            Number of shuffles to create (default is 500).\n\n        Returns\n        -------\n        List[np.ndarray]\n            List of shuffled coordinates.\n        \"\"\"\n        range_ = X.shape[1]\n\n        # if fewer coordinates then shuffles, reduce number of shuffles to n coords\n        n_shuff = np.min([range_, n_shuff])\n\n        surrogate = np.random.choice(\n            np.arange(-range_, range_), size=n_shuff, replace=False\n        )\n        x_temp = []\n        for n in surrogate:\n            x_temp.append(np.roll(X, n, axis=1))\n\n        return x_temp\n\n    def get_spatial_infos(pos_shuff: np.ndarray, ts: np.ndarray, dim: int) -&gt; float:\n        \"\"\"Get spatial information for shuffled position data.\n\n        Parameters\n        ----------\n        pos_shuff : np.ndarray\n            Shuffled position data.\n        ts : np.ndarray\n            Timestamps corresponding to the shuffled data.\n        dim : int\n            Dimension of the spatial data (1 or 2).\n\n        Returns\n        -------\n        float\n            Spatial information calculated from the tuning curve.\n        \"\"\"\n        pos_shuff = nel.AnalogSignalArray(\n            data=pos_shuff,\n            timestamps=ts,\n        )\n        if dim == 1:\n            tc, _ = self.map_1d(pos_shuff)\n            return tc.spatial_information()\n        elif dim == 2:\n            tc, _ = self.map_2d(pos_shuff)\n            return tc.spatial_information()\n        else:\n            tc, _ = self.map_nd(pos_shuff)\n            return tc.spatial_information()\n\n    # Restrict position data to running epochs before creating shuffles so\n    # the null distribution reflects the actual samples used for mapping\n    # (avoid pulling non-running or gap samples into shuffles).\n    pos_run = self.pos[self.run_epochs]\n    pos_data_shuff = create_shuffled_coordinates(pos_run.data, n_shuff=self.n_shuff)\n\n    # construct tuning curves for each position shuffle\n    if self.parallel_shuff:\n        num_cores = multiprocessing.cpu_count()\n        shuffle_spatial_info = Parallel(n_jobs=num_cores)(\n            delayed(get_spatial_infos)(\n                pos_data_shuff[i], pos_run.abscissa_vals, self.dim\n            )\n            for i in range(self.n_shuff)\n        )\n    else:\n        shuffle_spatial_info = [\n            get_spatial_infos(pos_data_shuff[i], pos_run.abscissa_vals, self.dim)\n            for i in range(self.n_shuff)\n        ]\n\n    # calculate p values for the obs vs null\n    _, self.spatial_information_pvalues, self.spatial_information_zscore = (\n        get_significant_events(\n            self.tc.spatial_information(), np.array(shuffle_spatial_info)\n        )\n    )\n\n    return self.spatial_information_pvalues\n</code></pre>"},{"location":"reference/neuro_py/util/","title":"neuro_py.util","text":""},{"location":"reference/neuro_py/util/#neuro_py.util._check_dependency","title":"<code>_check_dependency(module_name, extra)</code>","text":"<p>Check if a module is installed, and raise an ImportError with a helpful message if not.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The name of the module to check.</p> required <code>extra</code> <code>str</code> <p>The name of the extra requirement group (e.g., 'csd') to suggest in the error message.</p> required Source code in <code>neuro_py/util/_dependencies.py</code> <pre><code>def _check_dependency(module_name: str, extra: str) -&gt; None:\n    \"\"\"\n    Check if a module is installed, and raise an ImportError with a helpful message if not.\n\n    Parameters\n    ----------\n    module_name : str\n        The name of the module to check.\n    extra : str\n        The name of the extra requirement group (e.g., 'csd') to suggest in the error message.\n    \"\"\"\n    try:\n        __import__(module_name)\n    except ImportError:\n        raise ImportError(\n            f\"{module_name} is not installed. Please install it to use this function. \"\n            f\"Run: pip install -e .[{extra}]\"\n        )\n</code></pre>"},{"location":"reference/neuro_py/util/#neuro_py.util.circular_interp","title":"<code>circular_interp(x, xp, fp)</code>","text":"<p>Circular interpolation of data. This function performs interpolation on circular data, such as angles, using sine and cosine.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The x-coordinates at which to evaluate the interpolated values.</p> required <code>xp</code> <code>ndarray</code> <p>The x-coordinates of the data points, must be increasing.</p> required <code>fp</code> <code>ndarray</code> <p>The y-coordinates of the data points, same length as <code>xp</code>, [-\u03c0, \u03c0] or [0, 2\u03c0].</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The interpolated values in radians, in the same range as the input fp data.</p> Source code in <code>neuro_py/util/array.py</code> <pre><code>def circular_interp(x: np.ndarray, xp: np.ndarray, fp: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Circular interpolation of data.\n    This function performs interpolation on circular data, such as angles, using sine and cosine.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        The x-coordinates at which to evaluate the interpolated values.\n    xp : np.ndarray\n        The x-coordinates of the data points, must be increasing.\n    fp : np.ndarray\n        The y-coordinates of the data points, same length as `xp`, [-\u03c0, \u03c0] or [0, 2\u03c0].\n\n    Returns\n    -------\n    np.ndarray\n        The interpolated values in radians, in the same range as the input fp data.\n    \"\"\"\n    if len(xp) != len(fp):\n        raise ValueError(\"xp and fp must have the same length.\")\n    if len(xp) &lt; 2:\n        raise ValueError(\"At least two points are required for interpolation.\")\n    if not np.all(np.diff(xp) &gt; 0):\n        raise ValueError(\"xp must be strictly increasing.\")\n\n    # interpolate sine and cosine components\n    s = np.interp(x, xp, np.sin(fp))\n    c = np.interp(x, xp, np.cos(fp))\n    # return the angle formed by sine and cosine\n    result = np.arctan2(s, c)\n\n    # Detect if input data uses [0, 2\u03c0] convention instead of [-\u03c0, \u03c0]\n    # Simple heuristic: if all input values are non-negative, assume [0, 2\u03c0]\n    if np.all(fp &gt;= 0):\n        # Convert from [-\u03c0, \u03c0] to [0, 2\u03c0]\n        result = (result + 2 * np.pi) % (2 * np.pi)\n\n    return result\n</code></pre>"},{"location":"reference/neuro_py/util/#neuro_py.util.find_terminal_masked_indices","title":"<code>find_terminal_masked_indices(mask, axis)</code>","text":"<p>Find the first and last indices of non-masked values along an axis.</p> <p>Only tested upto 2D arrays. If <code>mask</code> is empty along <code>axis</code>, the first and last indices are set to 0 and the last index along the axis, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask of <code>arr</code>.</p> required <code>axis</code> <code>int</code> <p>Axis along which to find the first and last indices.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>First index of non-masked values along <code>axis</code>.</p> <code>ndarray</code> <p>Last index of non-masked values along <code>axis</code>.</p> <p>Examples:</p> <p>1D Example:</p> <pre><code>&gt;&gt;&gt; mask = np.array([0, 0, 1, 1, 0])\n&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n(2, 3)\n</code></pre> <p>2D Example (along rows):</p> <pre><code>&gt;&gt;&gt; mask = np.array([[0, 0, 1],\n...                  [1, 1, 0],\n...                  [0, 0, 0]])\n&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=1)\n(array([2, 0, 0]), array([2, 1, -1]))\n</code></pre> <p>2D Example (along columns):</p> <pre><code>&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n(array([1, 1, 0]), array([1, 1, 0]))\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def find_terminal_masked_indices(\n    mask: np.ndarray, axis: int\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the first and last indices of non-masked values along an axis.\n\n    Only tested upto 2D arrays. If `mask` is empty along `axis`, the first and\n    last indices are set to 0 and the last index along the axis, respectively.\n\n    Parameters\n    ----------\n    mask : np.ndarray\n        Mask of `arr`.\n    axis : int\n        Axis along which to find the first and last indices.\n\n    Returns\n    -------\n    np.ndarray\n        First index of non-masked values along `axis`.\n    np.ndarray\n        Last index of non-masked values along `axis`.\n\n    Examples\n    --------\n    1D Example:\n    &gt;&gt;&gt; mask = np.array([0, 0, 1, 1, 0])\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n    (2, 3)\n\n    2D Example (along rows):\n    &gt;&gt;&gt; mask = np.array([[0, 0, 1],\n    ...                  [1, 1, 0],\n    ...                  [0, 0, 0]])\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=1)\n    (array([2, 0, 0]), array([2, 1, -1]))\n\n    2D Example (along columns):\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n    (array([1, 1, 0]), array([1, 1, 0]))\n    \"\"\"\n    first_idx = np.argmax(mask, axis=axis)\n    reversed_mask = np.flip(mask, axis=axis)\n    last_idx = mask.shape[axis] - np.argmax(reversed_mask, axis=axis) - 1\n\n    return first_idx, last_idx\n</code></pre>"},{"location":"reference/neuro_py/util/#neuro_py.util.is_nested","title":"<code>is_nested(array)</code>","text":"<p>Check if an array is nested.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the array is nested, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_nested(np.array([1, 2, 3]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([[1, 2], [3, 4]]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([np.array([1, 2]), np.array([3, 4, 5])], dtype=object))\nTrue\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def is_nested(array: np.ndarray) -&gt; bool:\n    \"\"\"\n    Check if an array is nested.\n\n    Parameters\n    ----------\n    array : np.ndarray\n        Input array.\n\n    Returns\n    -------\n    bool\n        True if the array is nested, False otherwise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; is_nested(np.array([1, 2, 3]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([[1, 2], [3, 4]]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([np.array([1, 2]), np.array([3, 4, 5])], dtype=object))\n    True\n    \"\"\"\n    if array.dtype != object:\n        return False\n    return any(isinstance(item, np.ndarray) for item in array)\n</code></pre>"},{"location":"reference/neuro_py/util/#neuro_py.util.replace_border_zeros_with_nan","title":"<code>replace_border_zeros_with_nan(arr)</code>","text":"<p>Replace zero values at the borders of each dimension of a n-dimensional array with NaN.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with zero values at the borders replaced with NaN.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; arr = np.arange(27).reshape(3, 3, 3)\n&gt;&gt;&gt; arr[0, 2] = arr[2, 2] = arr[2, 0, 0] = arr[1, 1, 1] = 0\n&gt;&gt;&gt; replace_border_zeros_with_nan(arr)\narray([[[nan,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [nan, nan, nan]],\n</code></pre> <pre><code>   [[ 9., 10., 11.],\n    [12.,  0., 14.],\n    [15., 16., 17.]],\n\n   [[nan, 19., 20.],\n    [21., 22., 23.],\n    [nan, nan, nan]]])\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def replace_border_zeros_with_nan(arr: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Replace zero values at the borders of each dimension of a n-dimensional\n    array with NaN.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array.\n\n    Returns\n    -------\n    np.ndarray\n        Array with zero values at the borders replaced with NaN.\n\n    Examples\n    --------\n    &gt;&gt;&gt; arr = np.arange(27).reshape(3, 3, 3)\n    &gt;&gt;&gt; arr[0, 2] = arr[2, 2] = arr[2, 0, 0] = arr[1, 1, 1] = 0\n    &gt;&gt;&gt; replace_border_zeros_with_nan(arr)\n    array([[[nan,  1.,  2.],\n            [ 3.,  4.,  5.],\n            [nan, nan, nan]],\n\n           [[ 9., 10., 11.],\n            [12.,  0., 14.],\n            [15., 16., 17.]],\n\n           [[nan, 19., 20.],\n            [21., 22., 23.],\n            [nan, nan, nan]]])\n    \"\"\"\n    arr = np.array(arr, dtype=float)\n    dims = arr.shape\n\n    for axis in range(len(dims)):\n        # Find indices where zero values start and stop\n        for idx in np.ndindex(*[dims[i] for i in range(len(dims)) if i != axis]):\n            slicer = list(idx)\n            slicer.insert(\n                axis, slice(None)\n            )  # Insert the full slice along the current axis\n\n            # Check for first sequence of zeros\n            subarray = arr[tuple(slicer)]\n            first_zero_indices = np.where(np.cumsum(subarray != 0) == 0)[0]\n            if len(first_zero_indices) &gt; 0:\n                subarray[first_zero_indices] = np.nan\n\n            # Check for last sequence of zeros\n            last_zero_indices = np.where(np.cumsum(subarray[::-1] != 0) == 0)[0]\n            if len(last_zero_indices) &gt; 0:\n                subarray[-last_zero_indices - 1] = np.nan\n\n            arr[tuple(slicer)] = subarray  # Replace modified subarray\n\n    return arr\n</code></pre>"},{"location":"reference/neuro_py/util/#neuro_py.util.shrink","title":"<code>shrink(matrix, row_bin_size, column_bin_size)</code>","text":"<p>Shrink a 2D matrix by averaging non-overlapping blocks.</p> <p>This reduces the resolution of the matrix by taking the mean of (row_bin_size x column_bin_size)-sized blocks. If the matrix size is not divisible by the bin sizes, NaNs are appended as evenly as possible.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>ndarray</code> <p>2D input array.</p> required <code>row_bin_size</code> <code>int</code> <p>Number of rows to average together.</p> required <code>column_bin_size</code> <code>int</code> <p>Number of columns to average together.</p> required <p>Returns:</p> Name Type Description <code>shrunk</code> <code>ndarray</code> <p>The downsampled (shrunk) matrix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; matrix = np.array([[1, 2, 3, 4],\n...                    [4, 5, 6, 7],\n...                    [7, 8, 9, 10]])\n&gt;&gt;&gt; shrink(matrix, 2, 2)\narray([[3., 5.],\n       [7.5, 9.5]])\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def shrink(matrix: np.ndarray, row_bin_size: int, column_bin_size: int) -&gt; np.ndarray:\n    \"\"\"\n    Shrink a 2D matrix by averaging non-overlapping blocks.\n\n    This reduces the resolution of the matrix by taking the mean of\n    (row_bin_size x column_bin_size)-sized blocks. If the matrix size\n    is not divisible by the bin sizes, NaNs are appended as evenly as possible.\n\n    Parameters\n    ----------\n    matrix : np.ndarray\n        2D input array.\n    row_bin_size : int\n        Number of rows to average together.\n    column_bin_size : int\n        Number of columns to average together.\n\n    Returns\n    -------\n    shrunk : np.ndarray\n        The downsampled (shrunk) matrix.\n\n    Examples\n    --------\n    &gt;&gt;&gt; matrix = np.array([[1, 2, 3, 4],\n    ...                    [4, 5, 6, 7],\n    ...                    [7, 8, 9, 10]])\n    &gt;&gt;&gt; shrink(matrix, 2, 2)\n    array([[3., 5.],\n           [7.5, 9.5]])\n    \"\"\"\n    matrix = np.asarray(matrix, dtype=float)\n\n    # Input validation\n    if not (isinstance(row_bin_size, int) and row_bin_size &gt;= 1):\n        raise ValueError(\"row_bin_size must be a positive integer (&gt;= 1)\")\n    if not (isinstance(column_bin_size, int) and column_bin_size &gt;= 1):\n        raise ValueError(\"column_bin_size must be a positive integer (&gt;= 1)\")\n    if matrix.ndim != 2:\n        raise ValueError(\"matrix must be a 2D array\")\n\n    n_rows, n_cols = matrix.shape\n\n    # Determine padded size\n    new_rows = int(np.ceil(n_rows / row_bin_size) * row_bin_size)\n    new_cols = int(np.ceil(n_cols / column_bin_size) * column_bin_size)\n\n    # Pad with NaNs as evenly as possible\n    if new_rows &gt; n_rows:\n        pad_rows = new_rows - n_rows\n        top = pad_rows // 2\n        bottom = pad_rows - top\n        matrix = np.pad(matrix, ((top, bottom), (0, 0)), constant_values=np.nan)\n\n    if new_cols &gt; n_cols:\n        pad_cols = new_cols - n_cols\n        left = pad_cols // 2\n        right = pad_cols - left\n        matrix = np.pad(matrix, ((0, 0), (left, right)), constant_values=np.nan)\n\n    # Reshape into block structure\n    r_blocks = new_rows // row_bin_size\n    c_blocks = new_cols // column_bin_size\n\n    # Efficiently compute block means ignoring NaNs\n    shrunk = np.nanmean(\n        matrix.reshape(r_blocks, row_bin_size, c_blocks, column_bin_size)\n        .swapaxes(1, 2)\n        .reshape(r_blocks, c_blocks, -1),\n        axis=2,\n    )\n\n    return shrunk\n</code></pre>"},{"location":"reference/neuro_py/util/array/","title":"neuro_py.util.array","text":""},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.circular_interp","title":"<code>circular_interp(x, xp, fp)</code>","text":"<p>Circular interpolation of data. This function performs interpolation on circular data, such as angles, using sine and cosine.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The x-coordinates at which to evaluate the interpolated values.</p> required <code>xp</code> <code>ndarray</code> <p>The x-coordinates of the data points, must be increasing.</p> required <code>fp</code> <code>ndarray</code> <p>The y-coordinates of the data points, same length as <code>xp</code>, [-\u03c0, \u03c0] or [0, 2\u03c0].</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The interpolated values in radians, in the same range as the input fp data.</p> Source code in <code>neuro_py/util/array.py</code> <pre><code>def circular_interp(x: np.ndarray, xp: np.ndarray, fp: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Circular interpolation of data.\n    This function performs interpolation on circular data, such as angles, using sine and cosine.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        The x-coordinates at which to evaluate the interpolated values.\n    xp : np.ndarray\n        The x-coordinates of the data points, must be increasing.\n    fp : np.ndarray\n        The y-coordinates of the data points, same length as `xp`, [-\u03c0, \u03c0] or [0, 2\u03c0].\n\n    Returns\n    -------\n    np.ndarray\n        The interpolated values in radians, in the same range as the input fp data.\n    \"\"\"\n    if len(xp) != len(fp):\n        raise ValueError(\"xp and fp must have the same length.\")\n    if len(xp) &lt; 2:\n        raise ValueError(\"At least two points are required for interpolation.\")\n    if not np.all(np.diff(xp) &gt; 0):\n        raise ValueError(\"xp must be strictly increasing.\")\n\n    # interpolate sine and cosine components\n    s = np.interp(x, xp, np.sin(fp))\n    c = np.interp(x, xp, np.cos(fp))\n    # return the angle formed by sine and cosine\n    result = np.arctan2(s, c)\n\n    # Detect if input data uses [0, 2\u03c0] convention instead of [-\u03c0, \u03c0]\n    # Simple heuristic: if all input values are non-negative, assume [0, 2\u03c0]\n    if np.all(fp &gt;= 0):\n        # Convert from [-\u03c0, \u03c0] to [0, 2\u03c0]\n        result = (result + 2 * np.pi) % (2 * np.pi)\n\n    return result\n</code></pre>"},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.find_terminal_masked_indices","title":"<code>find_terminal_masked_indices(mask, axis)</code>","text":"<p>Find the first and last indices of non-masked values along an axis.</p> <p>Only tested upto 2D arrays. If <code>mask</code> is empty along <code>axis</code>, the first and last indices are set to 0 and the last index along the axis, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask of <code>arr</code>.</p> required <code>axis</code> <code>int</code> <p>Axis along which to find the first and last indices.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>First index of non-masked values along <code>axis</code>.</p> <code>ndarray</code> <p>Last index of non-masked values along <code>axis</code>.</p> <p>Examples:</p> <p>1D Example:</p> <pre><code>&gt;&gt;&gt; mask = np.array([0, 0, 1, 1, 0])\n&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n(2, 3)\n</code></pre> <p>2D Example (along rows):</p> <pre><code>&gt;&gt;&gt; mask = np.array([[0, 0, 1],\n...                  [1, 1, 0],\n...                  [0, 0, 0]])\n&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=1)\n(array([2, 0, 0]), array([2, 1, -1]))\n</code></pre> <p>2D Example (along columns):</p> <pre><code>&gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n(array([1, 1, 0]), array([1, 1, 0]))\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def find_terminal_masked_indices(\n    mask: np.ndarray, axis: int\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find the first and last indices of non-masked values along an axis.\n\n    Only tested upto 2D arrays. If `mask` is empty along `axis`, the first and\n    last indices are set to 0 and the last index along the axis, respectively.\n\n    Parameters\n    ----------\n    mask : np.ndarray\n        Mask of `arr`.\n    axis : int\n        Axis along which to find the first and last indices.\n\n    Returns\n    -------\n    np.ndarray\n        First index of non-masked values along `axis`.\n    np.ndarray\n        Last index of non-masked values along `axis`.\n\n    Examples\n    --------\n    1D Example:\n    &gt;&gt;&gt; mask = np.array([0, 0, 1, 1, 0])\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n    (2, 3)\n\n    2D Example (along rows):\n    &gt;&gt;&gt; mask = np.array([[0, 0, 1],\n    ...                  [1, 1, 0],\n    ...                  [0, 0, 0]])\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=1)\n    (array([2, 0, 0]), array([2, 1, -1]))\n\n    2D Example (along columns):\n    &gt;&gt;&gt; find_terminal_masked_indices(mask, axis=0)\n    (array([1, 1, 0]), array([1, 1, 0]))\n    \"\"\"\n    first_idx = np.argmax(mask, axis=axis)\n    reversed_mask = np.flip(mask, axis=axis)\n    last_idx = mask.shape[axis] - np.argmax(reversed_mask, axis=axis) - 1\n\n    return first_idx, last_idx\n</code></pre>"},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.interp_max_gap","title":"<code>interp_max_gap(x, xp, fp, max_gap, fallback=np.nan)</code>","text":"<p>Interpolate with gap-aware masking.</p> <p>Perform a 1-D linear interpolation similar to :func:<code>numpy.interp</code>, but any points that fall into gaps between consecutive <code>xp</code> values that exceed <code>max_gap</code> are set to <code>fallback</code> instead of being interpolated.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array_like</code> <p>The x-coordinates at which to evaluate the interpolated values.</p> required <code>xp</code> <code>1-D sequence of floats</code> <p>The x-coordinates of the data points, must be increasing.</p> required <code>fp</code> <code>1-D sequence of floats</code> <p>The y-coordinates of the data points, same length as <code>xp</code>.</p> required <code>max_gap</code> <code>float</code> <p>Maximum allowed gap between consecutive points in <code>xp</code>. If the gap xp[i+1] - xp[i] is greater than <code>max_gap</code>, then any <code>x</code> that falls in the open interval (xp[i], xp[i+1]) will be assigned <code>fallback</code>.</p> required <code>fallback</code> <code>scalar</code> <p>Value to use for points falling inside a large gap or outside the extremes of <code>xp</code> (passed to <code>numpy.interp</code> as left/right). Default is <code>np.nan</code>.</p> <code>nan</code> <p>Returns:</p> Name Type Description <code>y_interpolated</code> <code>ndarray</code> <p>Interpolated values. Same shape as <code>x</code>.</p> Notes <p>This function delegates to :func:<code>numpy.interp</code> for the initial interpolation and then post-processes the output to mask values that lie within large gaps of the original <code>xp</code> grid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; xp = np.array([0, 1, 3])\n&gt;&gt;&gt; fp = np.array([0, 10, 30])\n&gt;&gt;&gt; x = np.array([0.5, 1.5, 2.5])\n&gt;&gt;&gt; interp_max_gap(x, xp, fp, max_gap=1.5)\narray([ 5., nan, nan])\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def interp_max_gap(\n    x: np.ndarray, xp: np.ndarray, fp: np.ndarray, max_gap: float, fallback=np.nan\n) -&gt; np.ndarray:\n    \"\"\"\n    Interpolate with gap-aware masking.\n\n    Perform a 1-D linear interpolation similar to :func:`numpy.interp`, but\n    any points that fall into gaps between consecutive `xp` values that\n    exceed `max_gap` are set to `fallback` instead of being interpolated.\n\n    Parameters\n    ----------\n    x : array_like\n        The x-coordinates at which to evaluate the interpolated values.\n    xp : 1-D sequence of floats\n        The x-coordinates of the data points, must be increasing.\n    fp : 1-D sequence of floats\n        The y-coordinates of the data points, same length as `xp`.\n    max_gap : float\n        Maximum allowed gap between consecutive points in `xp`. If the gap\n        xp[i+1] - xp[i] is greater than `max_gap`, then any `x` that falls in\n        the open interval (xp[i], xp[i+1]) will be assigned `fallback`.\n    fallback : scalar, optional\n        Value to use for points falling inside a large gap or outside the\n        extremes of `xp` (passed to ``numpy.interp`` as left/right). Default\n        is ``np.nan``.\n\n    Returns\n    -------\n    y_interpolated : ndarray\n        Interpolated values. Same shape as `x`.\n\n    Notes\n    -----\n    This function delegates to :func:`numpy.interp` for the initial\n    interpolation and then post-processes the output to mask values that lie\n    within large gaps of the original `xp` grid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; xp = np.array([0, 1, 3])\n    &gt;&gt;&gt; fp = np.array([0, 10, 30])\n    &gt;&gt;&gt; x = np.array([0.5, 1.5, 2.5])\n    &gt;&gt;&gt; interp_max_gap(x, xp, fp, max_gap=1.5)\n    array([ 5., nan, nan])\n    \"\"\"\n\n    y_interpolated = np.interp(x, xp, fp, left=fallback, right=fallback)\n\n    # Identify gaps in original data that exceed max_gap\n    diff_x = np.diff(xp)\n\n    # Find indices in x_new that fall within large gaps\n    for i in range(len(diff_x)):\n        if diff_x[i] &gt; max_gap:\n            # Get the range of x_new that falls in this large gap\n            mask = (x &gt; xp[i]) &amp; (x &lt; xp[i + 1])\n            y_interpolated[mask] = fallback  # Set to fallback value if gap is too large\n\n    return y_interpolated\n</code></pre>"},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.is_nested","title":"<code>is_nested(array)</code>","text":"<p>Check if an array is nested.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the array is nested, False otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_nested(np.array([1, 2, 3]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([[1, 2], [3, 4]]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; is_nested(np.array([np.array([1, 2]), np.array([3, 4, 5])], dtype=object))\nTrue\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def is_nested(array: np.ndarray) -&gt; bool:\n    \"\"\"\n    Check if an array is nested.\n\n    Parameters\n    ----------\n    array : np.ndarray\n        Input array.\n\n    Returns\n    -------\n    bool\n        True if the array is nested, False otherwise.\n\n    Examples\n    --------\n    &gt;&gt;&gt; is_nested(np.array([1, 2, 3]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([[1, 2], [3, 4]]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]))\n    False\n\n    &gt;&gt;&gt; is_nested(np.array([np.array([1, 2]), np.array([3, 4, 5])], dtype=object))\n    True\n    \"\"\"\n    if array.dtype != object:\n        return False\n    return any(isinstance(item, np.ndarray) for item in array)\n</code></pre>"},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.replace_border_zeros_with_nan","title":"<code>replace_border_zeros_with_nan(arr)</code>","text":"<p>Replace zero values at the borders of each dimension of a n-dimensional array with NaN.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with zero values at the borders replaced with NaN.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; arr = np.arange(27).reshape(3, 3, 3)\n&gt;&gt;&gt; arr[0, 2] = arr[2, 2] = arr[2, 0, 0] = arr[1, 1, 1] = 0\n&gt;&gt;&gt; replace_border_zeros_with_nan(arr)\narray([[[nan,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [nan, nan, nan]],\n</code></pre> <pre><code>   [[ 9., 10., 11.],\n    [12.,  0., 14.],\n    [15., 16., 17.]],\n\n   [[nan, 19., 20.],\n    [21., 22., 23.],\n    [nan, nan, nan]]])\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def replace_border_zeros_with_nan(arr: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Replace zero values at the borders of each dimension of a n-dimensional\n    array with NaN.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array.\n\n    Returns\n    -------\n    np.ndarray\n        Array with zero values at the borders replaced with NaN.\n\n    Examples\n    --------\n    &gt;&gt;&gt; arr = np.arange(27).reshape(3, 3, 3)\n    &gt;&gt;&gt; arr[0, 2] = arr[2, 2] = arr[2, 0, 0] = arr[1, 1, 1] = 0\n    &gt;&gt;&gt; replace_border_zeros_with_nan(arr)\n    array([[[nan,  1.,  2.],\n            [ 3.,  4.,  5.],\n            [nan, nan, nan]],\n\n           [[ 9., 10., 11.],\n            [12.,  0., 14.],\n            [15., 16., 17.]],\n\n           [[nan, 19., 20.],\n            [21., 22., 23.],\n            [nan, nan, nan]]])\n    \"\"\"\n    arr = np.array(arr, dtype=float)\n    dims = arr.shape\n\n    for axis in range(len(dims)):\n        # Find indices where zero values start and stop\n        for idx in np.ndindex(*[dims[i] for i in range(len(dims)) if i != axis]):\n            slicer = list(idx)\n            slicer.insert(\n                axis, slice(None)\n            )  # Insert the full slice along the current axis\n\n            # Check for first sequence of zeros\n            subarray = arr[tuple(slicer)]\n            first_zero_indices = np.where(np.cumsum(subarray != 0) == 0)[0]\n            if len(first_zero_indices) &gt; 0:\n                subarray[first_zero_indices] = np.nan\n\n            # Check for last sequence of zeros\n            last_zero_indices = np.where(np.cumsum(subarray[::-1] != 0) == 0)[0]\n            if len(last_zero_indices) &gt; 0:\n                subarray[-last_zero_indices - 1] = np.nan\n\n            arr[tuple(slicer)] = subarray  # Replace modified subarray\n\n    return arr\n</code></pre>"},{"location":"reference/neuro_py/util/array/#neuro_py.util.array.shrink","title":"<code>shrink(matrix, row_bin_size, column_bin_size)</code>","text":"<p>Shrink a 2D matrix by averaging non-overlapping blocks.</p> <p>This reduces the resolution of the matrix by taking the mean of (row_bin_size x column_bin_size)-sized blocks. If the matrix size is not divisible by the bin sizes, NaNs are appended as evenly as possible.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>ndarray</code> <p>2D input array.</p> required <code>row_bin_size</code> <code>int</code> <p>Number of rows to average together.</p> required <code>column_bin_size</code> <code>int</code> <p>Number of columns to average together.</p> required <p>Returns:</p> Name Type Description <code>shrunk</code> <code>ndarray</code> <p>The downsampled (shrunk) matrix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; matrix = np.array([[1, 2, 3, 4],\n...                    [4, 5, 6, 7],\n...                    [7, 8, 9, 10]])\n&gt;&gt;&gt; shrink(matrix, 2, 2)\narray([[3., 5.],\n       [7.5, 9.5]])\n</code></pre> Source code in <code>neuro_py/util/array.py</code> <pre><code>def shrink(matrix: np.ndarray, row_bin_size: int, column_bin_size: int) -&gt; np.ndarray:\n    \"\"\"\n    Shrink a 2D matrix by averaging non-overlapping blocks.\n\n    This reduces the resolution of the matrix by taking the mean of\n    (row_bin_size x column_bin_size)-sized blocks. If the matrix size\n    is not divisible by the bin sizes, NaNs are appended as evenly as possible.\n\n    Parameters\n    ----------\n    matrix : np.ndarray\n        2D input array.\n    row_bin_size : int\n        Number of rows to average together.\n    column_bin_size : int\n        Number of columns to average together.\n\n    Returns\n    -------\n    shrunk : np.ndarray\n        The downsampled (shrunk) matrix.\n\n    Examples\n    --------\n    &gt;&gt;&gt; matrix = np.array([[1, 2, 3, 4],\n    ...                    [4, 5, 6, 7],\n    ...                    [7, 8, 9, 10]])\n    &gt;&gt;&gt; shrink(matrix, 2, 2)\n    array([[3., 5.],\n           [7.5, 9.5]])\n    \"\"\"\n    matrix = np.asarray(matrix, dtype=float)\n\n    # Input validation\n    if not (isinstance(row_bin_size, int) and row_bin_size &gt;= 1):\n        raise ValueError(\"row_bin_size must be a positive integer (&gt;= 1)\")\n    if not (isinstance(column_bin_size, int) and column_bin_size &gt;= 1):\n        raise ValueError(\"column_bin_size must be a positive integer (&gt;= 1)\")\n    if matrix.ndim != 2:\n        raise ValueError(\"matrix must be a 2D array\")\n\n    n_rows, n_cols = matrix.shape\n\n    # Determine padded size\n    new_rows = int(np.ceil(n_rows / row_bin_size) * row_bin_size)\n    new_cols = int(np.ceil(n_cols / column_bin_size) * column_bin_size)\n\n    # Pad with NaNs as evenly as possible\n    if new_rows &gt; n_rows:\n        pad_rows = new_rows - n_rows\n        top = pad_rows // 2\n        bottom = pad_rows - top\n        matrix = np.pad(matrix, ((top, bottom), (0, 0)), constant_values=np.nan)\n\n    if new_cols &gt; n_cols:\n        pad_cols = new_cols - n_cols\n        left = pad_cols // 2\n        right = pad_cols - left\n        matrix = np.pad(matrix, ((0, 0), (left, right)), constant_values=np.nan)\n\n    # Reshape into block structure\n    r_blocks = new_rows // row_bin_size\n    c_blocks = new_cols // column_bin_size\n\n    # Efficiently compute block means ignoring NaNs\n    shrunk = np.nanmean(\n        matrix.reshape(r_blocks, row_bin_size, c_blocks, column_bin_size)\n        .swapaxes(1, 2)\n        .reshape(r_blocks, c_blocks, -1),\n        axis=2,\n    )\n\n    return shrunk\n</code></pre>"},{"location":"tutorials/attractor_landscape/","title":"Attractor Estimation","text":"In\u00a0[\u00a0]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\nimport warnings\n\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\nimport napari\nimport numpy as np\nimport scipy\nimport sklearn\nimport sklearn.decomposition\nfrom IPython.display import HTML\nfrom matplotlib.animation import FuncAnimation\nfrom napari_animation import Animation\n\nimport neuro_py as npy\n\nwarnings.simplefilter(\"ignore\", category=RuntimeWarning)\n</pre> %reload_ext autoreload %autoreload 2 import warnings  import ipywidgets as widgets import matplotlib.pyplot as plt import napari import numpy as np import scipy import sklearn import sklearn.decomposition from IPython.display import HTML from matplotlib.animation import FuncAnimation from napari_animation import Animation  import neuro_py as npy  warnings.simplefilter(\"ignore\", category=RuntimeWarning) In\u00a0[\u00a0]: Copied! <pre>def gaussian(X, X0, sig, A):\n    G = A * np.exp(-((X - X0) ** 2) / (2 * sig**2))\n    dG = G * (X0 - X) / sig**2\n    return -G, -dG\n\n\ndef mix_gaussians(X, Xp, a):\n    u1, du1 = gaussian(X, Xp[0], 1, a[0])\n    u2, du2 = gaussian(X, Xp[1], 1, a[1])\n    u3, du3 = gaussian(X, Xp[2], 1, a[2])\n    u = u1 + u2 + u3\n    du = du1 + du2 + du3\n    return u, du\n\n\ndef simulate_trials(Xp, a, num_trials, iterations, dt, noise_fac):\n    \"\"\"Simulate trials using Langevin dynamics with noise\"\"\"\n    lan_fac = noise_fac * np.sqrt(dt)\n    X_dyn = np.empty((num_trials, iterations))\n    for i in range(num_trials):\n        # random initial condition\n        X_dyn[i, 0] = np.random.choice(Xp) + np.random.randn() * lan_fac\n        for ii in range(iterations - 1):\n            # energy and gradient at current position\n            E, dE = mix_gaussians(X_dyn[i, ii], Xp, a)\n            X_dyn[i, ii + 1] = X_dyn[i, ii] - dt * dE + lan_fac * np.random.randn()\n    return X_dyn\n</pre> def gaussian(X, X0, sig, A):     G = A * np.exp(-((X - X0) ** 2) / (2 * sig**2))     dG = G * (X0 - X) / sig**2     return -G, -dG   def mix_gaussians(X, Xp, a):     u1, du1 = gaussian(X, Xp[0], 1, a[0])     u2, du2 = gaussian(X, Xp[1], 1, a[1])     u3, du3 = gaussian(X, Xp[2], 1, a[2])     u = u1 + u2 + u3     du = du1 + du2 + du3     return u, du   def simulate_trials(Xp, a, num_trials, iterations, dt, noise_fac):     \"\"\"Simulate trials using Langevin dynamics with noise\"\"\"     lan_fac = noise_fac * np.sqrt(dt)     X_dyn = np.empty((num_trials, iterations))     for i in range(num_trials):         # random initial condition         X_dyn[i, 0] = np.random.choice(Xp) + np.random.randn() * lan_fac         for ii in range(iterations - 1):             # energy and gradient at current position             E, dE = mix_gaussians(X_dyn[i, ii], Xp, a)             X_dyn[i, ii + 1] = X_dyn[i, ii] - dt * dE + lan_fac * np.random.randn()     return X_dyn <p>Set parameters for the simulation generating the synthetic data influenced by multiple bump attractors.</p> In\u00a0[\u00a0]: Copied! <pre>Xp = [-2.5, 0, 2.5]  # positions of the minima of bump attractors\nattractordepths = [0.25, 0.2, 0.25]\n\nntrials = 100\niterations = 5000\ndomain_bins = proj_bins = 100\ndt = 0.1  # time step\nnoise_fac = 0.15  # noise factor\n\n# generate data\nX_dyn = simulate_trials(Xp, attractordepths, ntrials, iterations, dt, noise_fac)\n</pre> Xp = [-2.5, 0, 2.5]  # positions of the minima of bump attractors attractordepths = [0.25, 0.2, 0.25]  ntrials = 100 iterations = 5000 domain_bins = proj_bins = 100 dt = 0.1  # time step noise_fac = 0.15  # noise factor  # generate data X_dyn = simulate_trials(Xp, attractordepths, ntrials, iterations, dt, noise_fac) In\u00a0[\u00a0]: Copied! <pre>potential_pos_t, grad_pos_t_svm, H, latentedges, domainedges = (\n    npy.ensemble.potential_landscape(X_dyn, proj_bins, domain_bins)\n)\n\n# Visualize\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\nX = np.arange(-10, 10, 0.0025)\n\nE, dE = mix_gaussians(X, Xp, attractordepths)\naxes[0].plot(X, E, linewidth=2, label=\"Potential\")\naxes[0].set_title(\"Potential Landscape\")\naxes[0].set_xlabel(\"Position\")\naxes[0].set_ylabel(\"Energy\")\n\nfor i in range(len(Xp)):\n    axes[0].plot(\n        X, gaussian(X, Xp[i], 1, attractordepths[i])[0], label=f\"Component {i}\"\n    )\naxes[0].legend()\n\nT = np.arange(0, iterations * dt, dt)\naxes[1].plot(T, X_dyn[0], linewidth=2, label=\"Trial 1\")\naxes[1].plot(T, X_dyn[-1], linewidth=2, label=f\"Trial {ntrials}\")\naxes[1].set_title(\"Dynamics of trials\")\naxes[1].set_xlabel(\"Time\")\naxes[1].set_ylabel(\"Position (X)\")\naxes[1].legend()\n\naxes[2].plot(X, E, linewidth=2, label=\"Potential\")\naxes[2].plot(latentedges[:-1], np.nanmean(potential_pos_t, axis=1), label=\"Fit\")\naxes[2].set_title(\"Potential Landscape Estimation\")\naxes[2].set_xlabel(\"Position\")\naxes[2].set_ylabel(\"Energy\")\naxes[2].legend()\n\nplt.show()\n</pre> potential_pos_t, grad_pos_t_svm, H, latentedges, domainedges = (     npy.ensemble.potential_landscape(X_dyn, proj_bins, domain_bins) )  # Visualize fig, axes = plt.subplots(1, 3, figsize=(15, 4)) X = np.arange(-10, 10, 0.0025)  E, dE = mix_gaussians(X, Xp, attractordepths) axes[0].plot(X, E, linewidth=2, label=\"Potential\") axes[0].set_title(\"Potential Landscape\") axes[0].set_xlabel(\"Position\") axes[0].set_ylabel(\"Energy\")  for i in range(len(Xp)):     axes[0].plot(         X, gaussian(X, Xp[i], 1, attractordepths[i])[0], label=f\"Component {i}\"     ) axes[0].legend()  T = np.arange(0, iterations * dt, dt) axes[1].plot(T, X_dyn[0], linewidth=2, label=\"Trial 1\") axes[1].plot(T, X_dyn[-1], linewidth=2, label=f\"Trial {ntrials}\") axes[1].set_title(\"Dynamics of trials\") axes[1].set_xlabel(\"Time\") axes[1].set_ylabel(\"Position (X)\") axes[1].legend()  axes[2].plot(X, E, linewidth=2, label=\"Potential\") axes[2].plot(latentedges[:-1], np.nanmean(potential_pos_t, axis=1), label=\"Fit\") axes[2].set_title(\"Potential Landscape Estimation\") axes[2].set_xlabel(\"Position\") axes[2].set_ylabel(\"Energy\") axes[2].legend()  plt.show() In\u00a0[5]: Copied! <pre>def gaussian_nd(X, X0, sig, A):  # -&gt; tuple:\n    \"\"\"n-dimensional Gaussian function\n\n    Parameters\n    ----------\n    X : np.ndarray\n        n-dimensional grid space. Shape: (n_points, ndim).\n    X0 : np.ndarray\n        Centers of the Gaussian for each dimension (same shape as X).\n    sig : np.ndarray or float\n        Standard deviations for each dimension (either same shape as X or a single float).\n    A : float\n        Amplitude of the Gaussian.\n\n    Returns\n    -------\n    G : np.ndarray\n        Value of the n-dimensional Gaussian function at X.\n    dG : np.ndarray\n        Derivative of the n-dimensional Gaussian function along each dimension.\n    \"\"\"\n    X = np.atleast_2d(X)\n    X0 = np.atleast_1d(X0)\n    sig = np.atleast_1d(sig)\n\n    # Ensure X0 and sig are compatible with each dimension of the grid\n    # assert len(X) == len(X0), \"X0 should have the same number of dimensions as X\"\n    # assert len(X) == len(sig), \"sig should have the same number of dimensions as X\"\n\n    # Compute the Gaussian function values across the grid\n    exponent = -np.sum((X - X0) ** 2 / (2 * sig**2), axis=-1)\n    G = A * np.exp(exponent)\n\n    # Use np.gradient to compute the derivative along each axis\n    dG = (((X0 - X) / sig**2).T * G).T  # shape: (n_points, ndim)\n\n    return -G, -dG\n\n\ndef mix_functions(X, Xp, a, std=1, func=gaussian_nd):\n    \"\"\"Sum of Gaussians.\n\n    Parameters\n    ----------\n    X : float\n        Position\n    Xp : list\n        Centers of the Gaussians\n    a : list\n        Amplitudes of the Gaussians\n    n : int\n        Number of Gaussians\n\n    Returns\n    -------\n    U : float\n        Mixture of Gaussians\n    dU : float\n        Derivative of the mixture of Gaussians\n    \"\"\"\n    for i, xp in enumerate(Xp):\n        if i == 0:\n            U, dU = func(X, xp, std, a[i])\n        else:\n            u, du = func(X, xp, std, a[i])\n            U += u\n            dU += du\n    return U, dU\n\n\ndef simulate_trials(\n    Xp,\n    a,\n    ntrials,\n    iterations,\n    dt,\n    noise_fac,\n    std=1,\n    ngaussians=3,\n    xstarts=None,\n    func=gaussian_nd,\n):\n    \"\"\"Simulate trials\n\n    Parameters\n    ----------\n    Xp : list\n        Centers of the Gaussians\n    a : list\n        Amplitudes of the Gaussians\n    ntrials : int\n        Number of trials\n    iterations : int\n        Number of iterations\n    dt : float\n        Time step\n    noise_fac : float\n        Noise factor\n\n    Returns\n    -------\n    X_dyn : array\n        Trajectories of the trials\n    \"\"\"\n    nnrns = len(np.atleast_1d(Xp[0]))\n    lan_fac = noise_fac * np.sqrt(dt)  # Langevin factor\n    X_dyn = np.empty((ntrials, iterations, nnrns))  # Trajectories of the trials\n    for i in range(ntrials):\n        sel_ix = np.random.randint(len(Xp))\n        if xstarts is None or len(xstarts) &lt;= i:\n            startstate = (\n                Xp[sel_ix] + np.random.randn(*X_dyn[i, 0].shape) * lan_fac\n            )  # random initial condition\n        else:\n            startstate = xstarts[i]\n        X_dyn[i, 0] = startstate\n        for ii in range(iterations - 1):\n            E, dE = mix_functions(X_dyn[i, ii], Xp, a, std=std, func=func)\n            X_dyn[i, ii + 1] = (\n                X_dyn[i, ii] - dt * dE + lan_fac * np.random.randn(*dE.shape)\n            )\n    return X_dyn\n</pre> def gaussian_nd(X, X0, sig, A):  # -&gt; tuple:     \"\"\"n-dimensional Gaussian function      Parameters     ----------     X : np.ndarray         n-dimensional grid space. Shape: (n_points, ndim).     X0 : np.ndarray         Centers of the Gaussian for each dimension (same shape as X).     sig : np.ndarray or float         Standard deviations for each dimension (either same shape as X or a single float).     A : float         Amplitude of the Gaussian.      Returns     -------     G : np.ndarray         Value of the n-dimensional Gaussian function at X.     dG : np.ndarray         Derivative of the n-dimensional Gaussian function along each dimension.     \"\"\"     X = np.atleast_2d(X)     X0 = np.atleast_1d(X0)     sig = np.atleast_1d(sig)      # Ensure X0 and sig are compatible with each dimension of the grid     # assert len(X) == len(X0), \"X0 should have the same number of dimensions as X\"     # assert len(X) == len(sig), \"sig should have the same number of dimensions as X\"      # Compute the Gaussian function values across the grid     exponent = -np.sum((X - X0) ** 2 / (2 * sig**2), axis=-1)     G = A * np.exp(exponent)      # Use np.gradient to compute the derivative along each axis     dG = (((X0 - X) / sig**2).T * G).T  # shape: (n_points, ndim)      return -G, -dG   def mix_functions(X, Xp, a, std=1, func=gaussian_nd):     \"\"\"Sum of Gaussians.      Parameters     ----------     X : float         Position     Xp : list         Centers of the Gaussians     a : list         Amplitudes of the Gaussians     n : int         Number of Gaussians      Returns     -------     U : float         Mixture of Gaussians     dU : float         Derivative of the mixture of Gaussians     \"\"\"     for i, xp in enumerate(Xp):         if i == 0:             U, dU = func(X, xp, std, a[i])         else:             u, du = func(X, xp, std, a[i])             U += u             dU += du     return U, dU   def simulate_trials(     Xp,     a,     ntrials,     iterations,     dt,     noise_fac,     std=1,     ngaussians=3,     xstarts=None,     func=gaussian_nd, ):     \"\"\"Simulate trials      Parameters     ----------     Xp : list         Centers of the Gaussians     a : list         Amplitudes of the Gaussians     ntrials : int         Number of trials     iterations : int         Number of iterations     dt : float         Time step     noise_fac : float         Noise factor      Returns     -------     X_dyn : array         Trajectories of the trials     \"\"\"     nnrns = len(np.atleast_1d(Xp[0]))     lan_fac = noise_fac * np.sqrt(dt)  # Langevin factor     X_dyn = np.empty((ntrials, iterations, nnrns))  # Trajectories of the trials     for i in range(ntrials):         sel_ix = np.random.randint(len(Xp))         if xstarts is None or len(xstarts) &lt;= i:             startstate = (                 Xp[sel_ix] + np.random.randn(*X_dyn[i, 0].shape) * lan_fac             )  # random initial condition         else:             startstate = xstarts[i]         X_dyn[i, 0] = startstate         for ii in range(iterations - 1):             E, dE = mix_functions(X_dyn[i, ii], Xp, a, std=std, func=func)             X_dyn[i, ii + 1] = (                 X_dyn[i, ii] - dt * dE + lan_fac * np.random.randn(*dE.shape)             )     return X_dyn In\u00a0[\u00a0]: Copied! <pre>Xp_1D = [0]  # Center of Gaussian\nvar_1D = 0.5  # Variance\nX_1D = np.linspace(-5, 5, 100).reshape(-1, 1)  # 1D input points\nA_1D = 1.0  # Amplitude\n\nG_1D, dG_1D = gaussian_nd(X_1D, Xp_1D, var_1D, A_1D)\n\nXp_2D = [0, 0]\nvar_2D = 1\nX_2D = np.random.randn(5000, 2)  # 2D input points\nA_2D = 1.0  # Amplitude\n\nG_2D, dG_2D = gaussian_nd(X_2D, Xp_2D, var_2D, A_2D)\n\n\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\n\naxes[0].plot(X_1D, G_1D, label=\"Gaussian\")\naxes[0].plot(X_1D, dG_1D, label=\"Derivative\")\naxes[0].set_title(\"1D Gaussian\")\naxes[0].set_xlabel(\"Position\")\naxes[0].set_ylabel(\"Potential\")\naxes[0].legend()\n\naxes[1].scatter(X_2D[:, 0], X_2D[:, 1], c=G_2D, cmap=\"viridis\", s=5)\n\naxes[1].set_title(\"2D Gaussian\")\naxes[1].set_xlabel(\"X\")\naxes[1].set_ylabel(\"Y\")\n\naxes[2].scatter(X_2D[:, 0], X_2D[:, 1], c=dG_2D[:, 0], cmap=\"viridis\", s=5)\naxes[2].set_title(\"2D Gaussian Derivative (X)\")\naxes[2].set_xlabel(\"X\")\naxes[2].set_ylabel(\"Y\")\n\naxes[3].scatter(X_2D[:, 0], X_2D[:, 1], c=dG_2D[:, 1], cmap=\"viridis\", s=5)\naxes[3].set_title(\"2D Gaussian Derivative (Y)\")\naxes[3].set_xlabel(\"X\")\naxes[3].set_ylabel(\"Y\")\n\nplt.show()\n</pre> Xp_1D = [0]  # Center of Gaussian var_1D = 0.5  # Variance X_1D = np.linspace(-5, 5, 100).reshape(-1, 1)  # 1D input points A_1D = 1.0  # Amplitude  G_1D, dG_1D = gaussian_nd(X_1D, Xp_1D, var_1D, A_1D)  Xp_2D = [0, 0] var_2D = 1 X_2D = np.random.randn(5000, 2)  # 2D input points A_2D = 1.0  # Amplitude  G_2D, dG_2D = gaussian_nd(X_2D, Xp_2D, var_2D, A_2D)   fig, axes = plt.subplots(1, 4, figsize=(20, 5))  axes[0].plot(X_1D, G_1D, label=\"Gaussian\") axes[0].plot(X_1D, dG_1D, label=\"Derivative\") axes[0].set_title(\"1D Gaussian\") axes[0].set_xlabel(\"Position\") axes[0].set_ylabel(\"Potential\") axes[0].legend()  axes[1].scatter(X_2D[:, 0], X_2D[:, 1], c=G_2D, cmap=\"viridis\", s=5)  axes[1].set_title(\"2D Gaussian\") axes[1].set_xlabel(\"X\") axes[1].set_ylabel(\"Y\")  axes[2].scatter(X_2D[:, 0], X_2D[:, 1], c=dG_2D[:, 0], cmap=\"viridis\", s=5) axes[2].set_title(\"2D Gaussian Derivative (X)\") axes[2].set_xlabel(\"X\") axes[2].set_ylabel(\"Y\")  axes[3].scatter(X_2D[:, 0], X_2D[:, 1], c=dG_2D[:, 1], cmap=\"viridis\", s=5) axes[3].set_title(\"2D Gaussian Derivative (Y)\") axes[3].set_xlabel(\"X\") axes[3].set_ylabel(\"Y\")  plt.show() <p>Set parameters for the simulation generating the synthetic data influenced by multiple bump attractors.</p> <p>Note: We artificially create <code>xstarts</code> throughout different simulations to set some of the initial states of the simulated trajectories to span the entire space for better coverage, which is not necessary in real data and intelligent initialization strategies can be used for simulations.</p> In\u00a0[\u00a0]: Copied! <pre>Xp = np.asarray([[-2, -2], [0, 0], [2, 2]])\nattractordepths = [0.25, 0.2, 0.25]\n\nntrials = 3000\niterations = 500\ndomain_bins = 20\nproj_bins = 25\n\ndt = 0.1  # time step\nnoise_fac = 0.1  # noise factor\n\n# Generate starting points\nposxstarts = np.linspace(-3.5, 3.5, 15)\nxstarts = np.asarray(np.meshgrid(posxstarts, posxstarts)).T.reshape(-1, 2)\nxstarts = np.repeat(xstarts, 5, axis=0)\nnp.random.shuffle(xstarts)\n\n# Simulate dynamics\nX_dyn = simulate_trials(\n    Xp,\n    attractordepths,\n    ntrials,\n    iterations,\n    dt,\n    noise_fac,\n    ngaussians=len(Xp),\n    xstarts=xstarts,\n    std=1,\n)\n</pre> Xp = np.asarray([[-2, -2], [0, 0], [2, 2]]) attractordepths = [0.25, 0.2, 0.25]  ntrials = 3000 iterations = 500 domain_bins = 20 proj_bins = 25  dt = 0.1  # time step noise_fac = 0.1  # noise factor  # Generate starting points posxstarts = np.linspace(-3.5, 3.5, 15) xstarts = np.asarray(np.meshgrid(posxstarts, posxstarts)).T.reshape(-1, 2) xstarts = np.repeat(xstarts, 5, axis=0) np.random.shuffle(xstarts)  # Simulate dynamics X_dyn = simulate_trials(     Xp,     attractordepths,     ntrials,     iterations,     dt,     noise_fac,     ngaussians=len(Xp),     xstarts=xstarts,     std=1, ) In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\npotential_pos, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (\n    npy.ensemble.potential_landscape_nd(\n        X_dyn,\n        [np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)],\n        domain_bins,\n    )\n)\n\nX = np.linspace(-3.5, 3.5, proj_bins)\ny = np.linspace(-3.5, 3.5, proj_bins)\nX, Y = np.meshgrid(X, y)\nX = np.stack((X, Y), axis=-1)\nX = X.reshape(-1, 2)\n\nE, dE = mix_functions(X, Xp, attractordepths, std=1, func=gaussian_nd)\n\ngaussians_nd = []\nfor i in range(len(Xp)):\n    gaussian = gaussian_nd(X, Xp[i], 1, attractordepths[i])[0].reshape(\n        proj_bins, proj_bins\n    )\n    gaussian = (gaussian - np.min(gaussian)) / (np.max(gaussian) - np.min(gaussian))\n    gaussians_nd.append(gaussian)\ngaussians_nd = np.stack(gaussians_nd, axis=-1)\n\n\ndef simulate(t=0):\n    fig = plt.figure(figsize=(17, 10))\n    axes = []\n\n    # make axes[0] 2D\n    axes.append(fig.add_subplot(2, 3, 1))\n    axes[-1].set_title(\"Potential Energy Landscape\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n\n    axes[-1].imshow(gaussians_nd[::-1])\n    # add color label for each attractor outside the plot colored: red, green, blue\n    colors = [\"cyan\", \"magenta\", \"yellow\"]\n    for i, txt in enumerate([\"Bump 1\", \"Bump 2\", \"Bump 3\"]):\n        axes[-1].text(gaussians_nd.shape[0], 2 * i, txt, color=colors[i])\n\n    # make axes[1] 3D\n    axes.append(fig.add_subplot(2, 3, 4, projection=\"3d\"))\n    X, Y = np.meshgrid(\n        np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)\n    )\n    axes[-1].plot_surface(X, Y, E.reshape(proj_bins, proj_bins), cmap=\"turbo\")\n    # plot the xstarts over the surface\n    axes[-1].scatter(xstarts[:, 0], xstarts[:, 1], c=\"b\", marker=\".\", alpha=0.05)\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    axes.append(fig.add_subplot(2, 3, 2))\n    for i in range(ntrials):\n        axes[-1].plot(*(X_dyn[i].T), color=\"black\", alpha=0.02)\n    axes[-1].plot(*(X_dyn[0].T), linewidth=1, label=\"Trial 1\", alpha=0.5)\n    # start with green and end with red\n    axes[-1].plot(*X_dyn[0, 0], \"go\", label=\"Start\")\n    axes[-1].plot(*X_dyn[0, -1], \"rx\", label=\"End\")\n    axes[-1].plot(*(X_dyn[-1].T), linewidth=1, label=f\"Trial {ntrials}\", alpha=0.5)\n    axes[-1].plot(*X_dyn[-1, 0], \"go\")\n    axes[-1].plot(*X_dyn[-1, -1], \"rx\")\n\n    axes[-1].set_title(\"Dynamics of trials\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].legend()\n\n    axes.append(fig.add_subplot(2, 3, 3, projection=\"3d\"))\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n    axes[-1].plot_surface(X, Y, np.nanmean(potential_pos, axis=0), cmap=\"turbo\")\n    axes[-1].set_title(\"Potential Estimation\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    axes.append(fig.add_subplot(2, 3, 5))\n    # plot vector field\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n    U = grad_pos_t_svm[:, :, t, 0]\n    V = grad_pos_t_svm[:, :, t, 1]\n    axes[-1].quiver(X, Y, U, V)\n    axes[-1].set_title(\"Phase plane\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n\n    axes.append(fig.add_subplot(2, 3, 6, projection=\"3d\"))\n    axes[-1].plot_surface(\n        X, Y, np.nanmean(potential_pos_t_nrns[:, :, t], axis=-1), cmap=\"turbo\"\n    )\n    axes[-1].set_title(\"Time-resolved Potential Estimation\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    plt.show()\n\n\n_ = widgets.interact(simulate, t=(0, domain_bins - 1))\n</pre> %matplotlib inline potential_pos, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (     npy.ensemble.potential_landscape_nd(         X_dyn,         [np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)],         domain_bins,     ) )  X = np.linspace(-3.5, 3.5, proj_bins) y = np.linspace(-3.5, 3.5, proj_bins) X, Y = np.meshgrid(X, y) X = np.stack((X, Y), axis=-1) X = X.reshape(-1, 2)  E, dE = mix_functions(X, Xp, attractordepths, std=1, func=gaussian_nd)  gaussians_nd = [] for i in range(len(Xp)):     gaussian = gaussian_nd(X, Xp[i], 1, attractordepths[i])[0].reshape(         proj_bins, proj_bins     )     gaussian = (gaussian - np.min(gaussian)) / (np.max(gaussian) - np.min(gaussian))     gaussians_nd.append(gaussian) gaussians_nd = np.stack(gaussians_nd, axis=-1)   def simulate(t=0):     fig = plt.figure(figsize=(17, 10))     axes = []      # make axes[0] 2D     axes.append(fig.add_subplot(2, 3, 1))     axes[-1].set_title(\"Potential Energy Landscape\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")      axes[-1].imshow(gaussians_nd[::-1])     # add color label for each attractor outside the plot colored: red, green, blue     colors = [\"cyan\", \"magenta\", \"yellow\"]     for i, txt in enumerate([\"Bump 1\", \"Bump 2\", \"Bump 3\"]):         axes[-1].text(gaussians_nd.shape[0], 2 * i, txt, color=colors[i])      # make axes[1] 3D     axes.append(fig.add_subplot(2, 3, 4, projection=\"3d\"))     X, Y = np.meshgrid(         np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)     )     axes[-1].plot_surface(X, Y, E.reshape(proj_bins, proj_bins), cmap=\"turbo\")     # plot the xstarts over the surface     axes[-1].scatter(xstarts[:, 0], xstarts[:, 1], c=\"b\", marker=\".\", alpha=0.05)     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      axes.append(fig.add_subplot(2, 3, 2))     for i in range(ntrials):         axes[-1].plot(*(X_dyn[i].T), color=\"black\", alpha=0.02)     axes[-1].plot(*(X_dyn[0].T), linewidth=1, label=\"Trial 1\", alpha=0.5)     # start with green and end with red     axes[-1].plot(*X_dyn[0, 0], \"go\", label=\"Start\")     axes[-1].plot(*X_dyn[0, -1], \"rx\", label=\"End\")     axes[-1].plot(*(X_dyn[-1].T), linewidth=1, label=f\"Trial {ntrials}\", alpha=0.5)     axes[-1].plot(*X_dyn[-1, 0], \"go\")     axes[-1].plot(*X_dyn[-1, -1], \"rx\")      axes[-1].set_title(\"Dynamics of trials\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].legend()      axes.append(fig.add_subplot(2, 3, 3, projection=\"3d\"))     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])     axes[-1].plot_surface(X, Y, np.nanmean(potential_pos, axis=0), cmap=\"turbo\")     axes[-1].set_title(\"Potential Estimation\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      axes.append(fig.add_subplot(2, 3, 5))     # plot vector field     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])     U = grad_pos_t_svm[:, :, t, 0]     V = grad_pos_t_svm[:, :, t, 1]     axes[-1].quiver(X, Y, U, V)     axes[-1].set_title(\"Phase plane\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")      axes.append(fig.add_subplot(2, 3, 6, projection=\"3d\"))     axes[-1].plot_surface(         X, Y, np.nanmean(potential_pos_t_nrns[:, :, t], axis=-1), cmap=\"turbo\"     )     axes[-1].set_title(\"Time-resolved Potential Estimation\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      plt.show()   _ = widgets.interact(simulate, t=(0, domain_bins - 1)) <pre>interactive(children=(IntSlider(value=0, description='t', max=19), Output()), _dom_classes=('widget-interact',\u2026</pre> <p>Visualize the time-resolved potential estimation to observe how the landscape evolves over time.</p> In\u00a0[\u00a0]: Copied! <pre>t_steps = domain_bins  # Number of time steps\n\n\ndef update_surface(t, ax, surf):\n    \"\"\"\n    Update the surface plot for time `t`.\n    \"\"\"\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n    Z = -np.nanmean(\n        np.asarray(\n            [np.nancumsum(grad_pos_t_svm[:, :, t, nrn], axis=nrn) for nrn in range(2)]\n        ),\n        axis=0,\n    )\n\n    surf[0].remove()  # Remove old surface\n    surf[0] = ax.plot_surface(X, Y, Z, cmap=\"viridis\", edgecolor=\"none\")\n\n\ndef animate(t):\n    \"\"\"\n    Update the plot for frame t and rotate the view.\n    \"\"\"\n    update_surface(t, ax, surf)\n    ax.view_init(elev=30, azim=t * 360 / t_steps)  # Rotate azimuth over time\n\n\n# Create figure and 3D plot\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111, projection=\"3d\")\nX, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\nZ = np.nanmean(potential_pos_t_nrns[:, :, 0], axis=-1)\n\nsurf = [ax.plot_surface(X, Y, Z, cmap=\"viridis\", edgecolor=\"none\")]\nax.set_xlabel(\"Position X\")\nax.set_ylabel(\"Position Y\")\nax.set_zlabel(\"Potential Energy\")\n\n# Animate\nanim = FuncAnimation(fig, animate, frames=t_steps, interval=100, blit=False)\nHTML(anim.to_jshtml())\n</pre> t_steps = domain_bins  # Number of time steps   def update_surface(t, ax, surf):     \"\"\"     Update the surface plot for time `t`.     \"\"\"     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])     Z = -np.nanmean(         np.asarray(             [np.nancumsum(grad_pos_t_svm[:, :, t, nrn], axis=nrn) for nrn in range(2)]         ),         axis=0,     )      surf[0].remove()  # Remove old surface     surf[0] = ax.plot_surface(X, Y, Z, cmap=\"viridis\", edgecolor=\"none\")   def animate(t):     \"\"\"     Update the plot for frame t and rotate the view.     \"\"\"     update_surface(t, ax, surf)     ax.view_init(elev=30, azim=t * 360 / t_steps)  # Rotate azimuth over time   # Create figure and 3D plot fig = plt.figure(figsize=(6, 6)) ax = fig.add_subplot(111, projection=\"3d\") X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0]) Z = np.nanmean(potential_pos_t_nrns[:, :, 0], axis=-1)  surf = [ax.plot_surface(X, Y, Z, cmap=\"viridis\", edgecolor=\"none\")] ax.set_xlabel(\"Position X\") ax.set_ylabel(\"Position Y\") ax.set_zlabel(\"Potential Energy\")  # Animate anim = FuncAnimation(fig, animate, frames=t_steps, interval=100, blit=False) HTML(anim.to_jshtml()) Out[\u00a0]: Once Loop Reflect <p>We simulate a 2D system with a ring attractor, a special case where attractors form a ring structure, defined by:</p> <p>$$ \\psi(x, y) = \\frac{1}{\\pi \\sigma^4} (1 - \\frac{x^2 + y^2}{2 _ \\sigma^2}) {\\rm e}^{-\\frac{x^2 + y^2}{2 _ \\sigma^2}}$$</p> <p>where $\\sigma$ is the standard deviation of the repulsive potential.</p> <p>Goal:</p> <ul> <li>To understand how ring attractors influence particle dynamics.</li> </ul> <p>Key Insights:</p> <ul> <li>Particles converge to the ring attractor, forming a stable ring structure.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>def mexican_hat_nd(X, X0, sig, A):\n    \"\"\"n-dimensional Mexican hat function\n\n    Negative normalized second derivative of a Gaussian function.\n\n    Parameters\n    ----------\n    X : np.ndarray\n        n-dimensional grid space. Shape: (n_points, ndim).\n    X0 : np.ndarray\n        Centers of the Mexican hat for each dimension (same shape as X).\n    sig : np.ndarray or float\n        Standard deviations for each dimension (either same shape as X or a single float).\n    A : float\n        Amplitude of the Mexican hat.\n\n    Returns\n    -------\n    G : np.ndarray\n        Value of the n-dimensional Mexican hat function at X.\n    dG : np.ndarray\n        Derivative of the n-dimensional Mexican hat function along each dimension.\n    \"\"\"\n    X = np.atleast_2d(X)\n    X0 = np.atleast_1d(X0)\n    sig = np.atleast_1d(sig)\n\n    # Compute the Mexican hat function values across the grid\n    exponent = np.sum((X - X0) ** 2 / (2 * sig**2), axis=-1)\n    M = A * (1 - exponent) * np.exp(-exponent) / sig**4\n\n    dM = -(\n        ((X - X0) / (np.pi * sig**6)).T * np.exp(-exponent) * (2 - exponent)\n    ).T  # shape: (n_points, ndim)\n\n    return M, dM\n</pre> def mexican_hat_nd(X, X0, sig, A):     \"\"\"n-dimensional Mexican hat function      Negative normalized second derivative of a Gaussian function.      Parameters     ----------     X : np.ndarray         n-dimensional grid space. Shape: (n_points, ndim).     X0 : np.ndarray         Centers of the Mexican hat for each dimension (same shape as X).     sig : np.ndarray or float         Standard deviations for each dimension (either same shape as X or a single float).     A : float         Amplitude of the Mexican hat.      Returns     -------     G : np.ndarray         Value of the n-dimensional Mexican hat function at X.     dG : np.ndarray         Derivative of the n-dimensional Mexican hat function along each dimension.     \"\"\"     X = np.atleast_2d(X)     X0 = np.atleast_1d(X0)     sig = np.atleast_1d(sig)      # Compute the Mexican hat function values across the grid     exponent = np.sum((X - X0) ** 2 / (2 * sig**2), axis=-1)     M = A * (1 - exponent) * np.exp(-exponent) / sig**4      dM = -(         ((X - X0) / (np.pi * sig**6)).T * np.exp(-exponent) * (2 - exponent)     ).T  # shape: (n_points, ndim)      return M, dM In\u00a0[\u00a0]: Copied! <pre>Xp_1D = [0]  # Center of Gaussian\ncov_1D = 0.5  # Variance\nX_1D = np.linspace(-5, 5, proj_bins).reshape(-1, 1)  # 1D input points\nA_1D = 1.0  # Amplitude\n\nG_1D, dG_1D = mexican_hat_nd(X_1D, Xp_1D, cov_1D, A_1D)\n\nXp_2D = [0, 0]\nX_2D = 3 * np.random.randn(7500, 2)  # 2D input points\nA_2D = 1.0  # Amplitude\n\nG_2D, dG_2D = mexican_hat_nd(X_2D, Xp_2D, 1, A_2D)\n\n\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\naxes = axes.ravel()\n\naxes[0].plot(X_1D, G_1D, label=\"Mexican Hat\")\naxes[0].plot(X_1D, dG_1D.ravel(), label=\"Derivative\")\naxes[0].set_title(\"1D Mexican Hat\")\naxes[0].set_xlabel(\"Position\")\naxes[0].set_ylabel(\"Value\")\naxes[0].legend()\n\naxes[1].remove()\naxes[1] = fig.add_subplot(1, 4, 2, projection=\"3d\")\nX, Y = np.meshgrid(X_1D, X_1D)\nX_in = np.stack((X, Y), axis=-1)\nX_in = X_in.reshape(-1, 2)\n# test mexican hat once\naxes[1].plot_surface(\n    X,\n    Y,\n    mexican_hat_nd(X_in, [0, 0], 1, 1)[0].reshape(proj_bins, proj_bins),\n    cmap=\"plasma\",\n)\n\naxes[1].set_title(\"2D Mexican Hat\")\naxes[1].set_xlabel(\"X\")\naxes[1].set_ylabel(\"Y\")\n\naxes[2].remove()\naxes[2] = fig.add_subplot(1, 4, 3, projection=\"3d\")\naxes[2].plot_surface(\n    X,\n    Y,\n    mexican_hat_nd(X_in, [0, 0], 1, 1)[1][:, 0].reshape(proj_bins, proj_bins),\n    cmap=\"plasma\",\n)\naxes[2].set_title(\"2D Mexican Hat Derivative (X)\")\naxes[2].set_xlabel(\"X\")\naxes[2].set_ylabel(\"Y\")\n\naxes[3].remove()\naxes[3] = fig.add_subplot(1, 4, 4, projection=\"3d\")\naxes[3].plot_surface(\n    X,\n    Y,\n    mexican_hat_nd(X_in, [0, 0], 1, 1)[1][:, 1].reshape(proj_bins, proj_bins),\n    cmap=\"plasma\",\n)\naxes[3].set_title(\"2D Mexican Hat Derivative (Y)\")\naxes[3].set_xlabel(\"X\")\naxes[3].set_ylabel(\"Y\")\n\n\nplt.show()\n</pre> Xp_1D = [0]  # Center of Gaussian cov_1D = 0.5  # Variance X_1D = np.linspace(-5, 5, proj_bins).reshape(-1, 1)  # 1D input points A_1D = 1.0  # Amplitude  G_1D, dG_1D = mexican_hat_nd(X_1D, Xp_1D, cov_1D, A_1D)  Xp_2D = [0, 0] X_2D = 3 * np.random.randn(7500, 2)  # 2D input points A_2D = 1.0  # Amplitude  G_2D, dG_2D = mexican_hat_nd(X_2D, Xp_2D, 1, A_2D)   fig, axes = plt.subplots(1, 4, figsize=(20, 5)) axes = axes.ravel()  axes[0].plot(X_1D, G_1D, label=\"Mexican Hat\") axes[0].plot(X_1D, dG_1D.ravel(), label=\"Derivative\") axes[0].set_title(\"1D Mexican Hat\") axes[0].set_xlabel(\"Position\") axes[0].set_ylabel(\"Value\") axes[0].legend()  axes[1].remove() axes[1] = fig.add_subplot(1, 4, 2, projection=\"3d\") X, Y = np.meshgrid(X_1D, X_1D) X_in = np.stack((X, Y), axis=-1) X_in = X_in.reshape(-1, 2) # test mexican hat once axes[1].plot_surface(     X,     Y,     mexican_hat_nd(X_in, [0, 0], 1, 1)[0].reshape(proj_bins, proj_bins),     cmap=\"plasma\", )  axes[1].set_title(\"2D Mexican Hat\") axes[1].set_xlabel(\"X\") axes[1].set_ylabel(\"Y\")  axes[2].remove() axes[2] = fig.add_subplot(1, 4, 3, projection=\"3d\") axes[2].plot_surface(     X,     Y,     mexican_hat_nd(X_in, [0, 0], 1, 1)[1][:, 0].reshape(proj_bins, proj_bins),     cmap=\"plasma\", ) axes[2].set_title(\"2D Mexican Hat Derivative (X)\") axes[2].set_xlabel(\"X\") axes[2].set_ylabel(\"Y\")  axes[3].remove() axes[3] = fig.add_subplot(1, 4, 4, projection=\"3d\") axes[3].plot_surface(     X,     Y,     mexican_hat_nd(X_in, [0, 0], 1, 1)[1][:, 1].reshape(proj_bins, proj_bins),     cmap=\"plasma\", ) axes[3].set_title(\"2D Mexican Hat Derivative (Y)\") axes[3].set_xlabel(\"X\") axes[3].set_ylabel(\"Y\")   plt.show() In\u00a0[\u00a0]: Copied! <pre>Xp = np.asarray([[0, 0]])\nattractordepths = [0.25]\n\nntrials = 3000\niterations = 100\ndomain_bins = 20\nproj_bins = 25\ndt = 0.2  # time step\nnoise_fac = 0.1  # noise factor\n\n# Generate starting points\nposxstarts = np.linspace(-3.5, 3.5, 15)\nxstarts = np.asarray(np.meshgrid(posxstarts, posxstarts)).T.reshape(-1, 2)\nxstarts = np.repeat(xstarts, 5, axis=0)\nnp.random.shuffle(xstarts)\n\n# Simulate dynamics\nX_dyn = simulate_trials(\n    Xp,\n    attractordepths,\n    ntrials,\n    iterations,\n    dt,\n    noise_fac,\n    ngaussians=len(Xp),\n    xstarts=xstarts,\n    func=mexican_hat_nd,\n)\n</pre> Xp = np.asarray([[0, 0]]) attractordepths = [0.25]  ntrials = 3000 iterations = 100 domain_bins = 20 proj_bins = 25 dt = 0.2  # time step noise_fac = 0.1  # noise factor  # Generate starting points posxstarts = np.linspace(-3.5, 3.5, 15) xstarts = np.asarray(np.meshgrid(posxstarts, posxstarts)).T.reshape(-1, 2) xstarts = np.repeat(xstarts, 5, axis=0) np.random.shuffle(xstarts)  # Simulate dynamics X_dyn = simulate_trials(     Xp,     attractordepths,     ntrials,     iterations,     dt,     noise_fac,     ngaussians=len(Xp),     xstarts=xstarts,     func=mexican_hat_nd, ) In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\npotential_pos, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (\n    npy.ensemble.potential_landscape_nd(\n        X_dyn,\n        [np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)],\n        domain_bins,\n    )\n)\n\nX = np.linspace(-3.5, 3.5, proj_bins)\ny = np.linspace(-3.5, 3.5, proj_bins)\nX, Y = np.meshgrid(X, y)\nX = np.stack((X, Y), axis=-1)\nX = X.reshape(-1, 2)\n\nE, dE = mix_functions(X, Xp, attractordepths, func=mexican_hat_nd)\n\ngaussians_nd = []\nfor i in range(len(Xp)):\n    gaussian = mexican_hat_nd(X, Xp[i], 1, attractordepths[i])[0].reshape(\n        proj_bins, proj_bins\n    )\n    gaussian = (gaussian - np.min(gaussian)) / (np.max(gaussian) - np.min(gaussian))\n    gaussians_nd.append(gaussian)\ngaussians_nd = np.stack(gaussians_nd, axis=-1)\n\n\ndef simulate(t=0):\n    fig = plt.figure(figsize=(17, 10))\n    axes = []\n\n    # make axes[0] 2D\n    axes.append(fig.add_subplot(2, 3, 1))\n    axes[-1].set_title(\"Potential Energy Landscape\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n\n    axes[-1].imshow(gaussians_nd[::-1], cmap=\"turbo\")\n\n    # make axes[1] 3D\n    axes.append(fig.add_subplot(2, 3, 4, projection=\"3d\"))\n    X, Y = np.meshgrid(\n        np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)\n    )\n    axes[-1].plot_surface(X, Y, E.reshape(proj_bins, proj_bins), cmap=\"turbo\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    axes.append(fig.add_subplot(2, 3, 2))\n    for i in range(ntrials):\n        axes[-1].plot(*(X_dyn[i].T), color=\"black\", alpha=0.02)\n    axes[-1].plot(*(X_dyn[0].T), linewidth=1, label=\"Trial 1\", alpha=0.5)\n    # start with green and end with red\n    axes[-1].plot(*X_dyn[0, 0], \"go\", label=\"Start\")\n    axes[-1].plot(*X_dyn[0, -1], \"rx\", label=\"End\")\n    axes[-1].plot(*(X_dyn[-1].T), linewidth=1, label=f\"Trial {ntrials}\", alpha=0.5)\n    axes[-1].plot(*X_dyn[-1, 0], \"go\")\n    axes[-1].plot(*X_dyn[-1, -1], \"rx\")\n\n    axes[-1].set_title(\"Dynamics of trials\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].legend()\n\n    axes.append(fig.add_subplot(2, 3, 3, projection=\"3d\"))\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n\n    axes[-1].plot_surface(X, Y, np.nanmean(potential_pos, axis=0), cmap=\"turbo\")\n    axes[-1].set_title(\"Potential Estimation\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    axes.append(fig.add_subplot(2, 3, 5))\n    # plot vector field\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n    U = grad_pos_t_svm[:, :, t, 0]\n    V = grad_pos_t_svm[:, :, t, 1]\n    axes[-1].quiver(X, Y, U, V)\n    axes[-1].set_title(\"Phase plane\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n\n    axes.append(fig.add_subplot(2, 3, 6, projection=\"3d\"))\n    X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\n\n    axes[-1].plot_surface(\n        X, Y, np.nanmean(potential_pos_t_nrns[:, :, t], axis=-1), cmap=\"turbo\"\n    )\n    axes[-1].set_title(\"Time-resolved Potential Estimation\")\n    axes[-1].set_xlabel(\"Position X\")\n    axes[-1].set_ylabel(\"Position Y\")\n    axes[-1].set_zlabel(\"Energy\")\n\n    plt.show()\n\n\n_ = widgets.interact(simulate, t=(0, domain_bins - 1))\n</pre> %matplotlib inline potential_pos, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (     npy.ensemble.potential_landscape_nd(         X_dyn,         [np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)],         domain_bins,     ) )  X = np.linspace(-3.5, 3.5, proj_bins) y = np.linspace(-3.5, 3.5, proj_bins) X, Y = np.meshgrid(X, y) X = np.stack((X, Y), axis=-1) X = X.reshape(-1, 2)  E, dE = mix_functions(X, Xp, attractordepths, func=mexican_hat_nd)  gaussians_nd = [] for i in range(len(Xp)):     gaussian = mexican_hat_nd(X, Xp[i], 1, attractordepths[i])[0].reshape(         proj_bins, proj_bins     )     gaussian = (gaussian - np.min(gaussian)) / (np.max(gaussian) - np.min(gaussian))     gaussians_nd.append(gaussian) gaussians_nd = np.stack(gaussians_nd, axis=-1)   def simulate(t=0):     fig = plt.figure(figsize=(17, 10))     axes = []      # make axes[0] 2D     axes.append(fig.add_subplot(2, 3, 1))     axes[-1].set_title(\"Potential Energy Landscape\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")      axes[-1].imshow(gaussians_nd[::-1], cmap=\"turbo\")      # make axes[1] 3D     axes.append(fig.add_subplot(2, 3, 4, projection=\"3d\"))     X, Y = np.meshgrid(         np.linspace(-3.5, 3.5, proj_bins), np.linspace(-3.5, 3.5, proj_bins)     )     axes[-1].plot_surface(X, Y, E.reshape(proj_bins, proj_bins), cmap=\"turbo\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      axes.append(fig.add_subplot(2, 3, 2))     for i in range(ntrials):         axes[-1].plot(*(X_dyn[i].T), color=\"black\", alpha=0.02)     axes[-1].plot(*(X_dyn[0].T), linewidth=1, label=\"Trial 1\", alpha=0.5)     # start with green and end with red     axes[-1].plot(*X_dyn[0, 0], \"go\", label=\"Start\")     axes[-1].plot(*X_dyn[0, -1], \"rx\", label=\"End\")     axes[-1].plot(*(X_dyn[-1].T), linewidth=1, label=f\"Trial {ntrials}\", alpha=0.5)     axes[-1].plot(*X_dyn[-1, 0], \"go\")     axes[-1].plot(*X_dyn[-1, -1], \"rx\")      axes[-1].set_title(\"Dynamics of trials\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].legend()      axes.append(fig.add_subplot(2, 3, 3, projection=\"3d\"))     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])      axes[-1].plot_surface(X, Y, np.nanmean(potential_pos, axis=0), cmap=\"turbo\")     axes[-1].set_title(\"Potential Estimation\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      axes.append(fig.add_subplot(2, 3, 5))     # plot vector field     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])     U = grad_pos_t_svm[:, :, t, 0]     V = grad_pos_t_svm[:, :, t, 1]     axes[-1].quiver(X, Y, U, V)     axes[-1].set_title(\"Phase plane\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")      axes.append(fig.add_subplot(2, 3, 6, projection=\"3d\"))     X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])      axes[-1].plot_surface(         X, Y, np.nanmean(potential_pos_t_nrns[:, :, t], axis=-1), cmap=\"turbo\"     )     axes[-1].set_title(\"Time-resolved Potential Estimation\")     axes[-1].set_xlabel(\"Position X\")     axes[-1].set_ylabel(\"Position Y\")     axes[-1].set_zlabel(\"Energy\")      plt.show()   _ = widgets.interact(simulate, t=(0, domain_bins - 1)) <pre>interactive(children=(IntSlider(value=0, description='t', max=19), Output()), _dom_classes=('widget-interact',\u2026</pre> <p>Visualize the time-resolved potential estimation for the ring attractor.</p> In\u00a0[\u00a0]: Copied! <pre>from matplotlib.animation import FuncAnimation\n\n# Dummy data to simulate inputs\nt_steps = domain_bins  # Number of time steps\n\n\ndef animate(t):\n    \"\"\"\n    Update the plot for frame t and rotate the view.\n    \"\"\"\n    update_surface(t, ax, surf)\n    ax.view_init(elev=30, azim=t / 2 * 360 / t_steps)  # Rotate azimuth over time\n\n\n# Create figure and 3D plot\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111, projection=\"3d\")\nX, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0])\nZ = np.nanmean(potential_pos_t_nrns[:, :, 0], axis=-1)\n\nsurf = [ax.plot_surface(X, Y, Z, cmap=\"turbo\", edgecolor=\"none\")]\nax.set_xlabel(\"Position X\")\nax.set_ylabel(\"Position Y\")\nax.set_zlabel(\"Potential Energy\")\n\n# Animate\nanim = FuncAnimation(fig, animate, frames=t_steps, interval=100, blit=False)\nHTML(anim.to_jshtml())\n</pre> from matplotlib.animation import FuncAnimation  # Dummy data to simulate inputs t_steps = domain_bins  # Number of time steps   def animate(t):     \"\"\"     Update the plot for frame t and rotate the view.     \"\"\"     update_surface(t, ax, surf)     ax.view_init(elev=30, azim=t / 2 * 360 / t_steps)  # Rotate azimuth over time   # Create figure and 3D plot fig = plt.figure(figsize=(6, 6)) ax = fig.add_subplot(111, projection=\"3d\") X, Y = np.meshgrid(latentedges[:-1, 0], latentedges[:-1, 0]) Z = np.nanmean(potential_pos_t_nrns[:, :, 0], axis=-1)  surf = [ax.plot_surface(X, Y, Z, cmap=\"turbo\", edgecolor=\"none\")] ax.set_xlabel(\"Position X\") ax.set_ylabel(\"Position Y\") ax.set_zlabel(\"Potential Energy\")  # Animate anim = FuncAnimation(fig, animate, frames=t_steps, interval=100, blit=False) HTML(anim.to_jshtml()) Out[\u00a0]: Once Loop Reflect In\u00a0[\u00a0]: Copied! <pre>Xp = np.asarray(\n    [\n        [-1.5, -1.5, -1.5],\n        [0, 0, 0],\n        [1.5, 1.5, 1.5],\n    ]\n)\nattractordepths = [1, 0.95, 1]\n\nntrials = 5000\niterations = 500\ndomain_bins = 20\nproj_bins = 20\ndt = 0.1  # time step\nnoise_fac = 0.05  # noise factor\nattractorfunc = gaussian_nd\n\n# Generate starting points\nposxstarts = np.linspace(-3.5, 3.5, 30)\nxstarts = np.asarray(np.meshgrid(posxstarts, posxstarts, posxstarts)).T.reshape(-1, 3)\nxstarts = np.repeat(xstarts, 1, axis=0)\nnp.random.shuffle(xstarts)\n\n# Simulate dynamics\nX_dyn = simulate_trials(\n    Xp,\n    attractordepths,\n    ntrials,\n    iterations,\n    dt,\n    noise_fac,\n    ngaussians=len(Xp),\n    xstarts=xstarts,\n    func=attractorfunc,\n    std=1,\n)  # shape: (ntrials, iterations, 3)\n</pre> Xp = np.asarray(     [         [-1.5, -1.5, -1.5],         [0, 0, 0],         [1.5, 1.5, 1.5],     ] ) attractordepths = [1, 0.95, 1]  ntrials = 5000 iterations = 500 domain_bins = 20 proj_bins = 20 dt = 0.1  # time step noise_fac = 0.05  # noise factor attractorfunc = gaussian_nd  # Generate starting points posxstarts = np.linspace(-3.5, 3.5, 30) xstarts = np.asarray(np.meshgrid(posxstarts, posxstarts, posxstarts)).T.reshape(-1, 3) xstarts = np.repeat(xstarts, 1, axis=0) np.random.shuffle(xstarts)  # Simulate dynamics X_dyn = simulate_trials(     Xp,     attractordepths,     ntrials,     iterations,     dt,     noise_fac,     ngaussians=len(Xp),     xstarts=xstarts,     func=attractorfunc,     std=1, )  # shape: (ntrials, iterations, 3) In\u00a0[\u00a0]: Copied! <pre># convert X_dyn to 2D with columns as (trial number, time step, x, y, z)\nX_dyn_2D = np.concatenate(\n    [\n        np.repeat(np.arange(ntrials), iterations).reshape(-1, 1),\n        np.broadcast_to(np.arange(iterations), (ntrials, iterations))\n        .flatten()\n        .reshape(-1, 1),\n        X_dyn.reshape(-1, 3),\n    ],\n    axis=1,\n)\n</pre> # convert X_dyn to 2D with columns as (trial number, time step, x, y, z) X_dyn_2D = np.concatenate(     [         np.repeat(np.arange(ntrials), iterations).reshape(-1, 1),         np.broadcast_to(np.arange(iterations), (ntrials, iterations))         .flatten()         .reshape(-1, 1),         X_dyn.reshape(-1, 3),     ],     axis=1, ) In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\nviewer.add_tracks(X_dyn_2D, tail_width=1, name=\"Dynamics of trials\")\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 90.0)\nanimation.capture_keyframe()\nmax_steps = int(viewer.dims.range[0][1])\n# rotate the camera 360 degrees while advancing the time\nfor i in range(0, max_steps, 3):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.075 * angle_inc,\n        0.0 + angle_inc,\n        90.0 + 0.1 * angle_inc,\n    )\n    viewer.dims.current_step = (i, *viewer.dims.current_step[1:])\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(\"anim3DTrajs.mp4\", canvas_only=True)\n\nHTML('&lt;video controls src=\"anim3DTrajs.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3) viewer.add_tracks(X_dyn_2D, tail_width=1, name=\"Dynamics of trials\")  animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 90.0) animation.capture_keyframe() max_steps = int(viewer.dims.range[0][1]) # rotate the camera 360 degrees while advancing the time for i in range(0, max_steps, 3):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.075 * angle_inc,         0.0 + angle_inc,         90.0 + 0.1 * angle_inc,     )     viewer.dims.current_step = (i, *viewer.dims.current_step[1:])     animation.capture_keyframe(steps=1)  animation.animate(\"anim3DTrajs.mp4\", canvas_only=True)  HTML('') <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/168 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1322, 786) to (1328, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n  1%|          | 1/168 [00:00&lt;00:59,  2.79it/s][swscaler @ 0x6294300] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 168/168 [00:38&lt;00:00,  4.34it/s]\n</pre> Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\npot_timeaveraged, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (\n    npy.ensemble.potential_landscape_nd(\n        X_dyn,\n        [\n            np.linspace(-3.5, 3.5, proj_bins),\n            np.linspace(-3.5, 3.5, proj_bins),\n            np.linspace(-3.5, 3.5, proj_bins),\n        ],\n        domain_bins,\n        nanborderempty=True,\n    )\n)\n\nX = np.linspace(-3.5, 3.5, proj_bins)\ny = np.linspace(-3.5, 3.5, proj_bins)\nX, Y, Z = np.meshgrid(X, y, y)\nX = np.stack((X, Y, Z), axis=-1)\nX = X.reshape(-1, 3)\n\nE, dE = mix_functions(X, Xp, attractordepths, func=mexican_hat_nd)\n\ngaussians_nd = []\nfor i in range(len(Xp)):\n    gaussian = attractorfunc(X, Xp[i], 1, attractordepths[i])[0].reshape(\n        proj_bins, proj_bins, proj_bins\n    )\n    gaussian = (gaussian - np.max(gaussian)) / (np.max(gaussian) - np.min(gaussian)) + 1\n    gaussians_nd.append(gaussian)\ngaussians_nd = np.stack(gaussians_nd, axis=-1)\n</pre> %matplotlib inline pot_timeaveraged, potential_pos_t_nrns, grad_pos_t_svm, H, latentedges, domainedges = (     npy.ensemble.potential_landscape_nd(         X_dyn,         [             np.linspace(-3.5, 3.5, proj_bins),             np.linspace(-3.5, 3.5, proj_bins),             np.linspace(-3.5, 3.5, proj_bins),         ],         domain_bins,         nanborderempty=True,     ) )  X = np.linspace(-3.5, 3.5, proj_bins) y = np.linspace(-3.5, 3.5, proj_bins) X, Y, Z = np.meshgrid(X, y, y) X = np.stack((X, Y, Z), axis=-1) X = X.reshape(-1, 3)  E, dE = mix_functions(X, Xp, attractordepths, func=mexican_hat_nd)  gaussians_nd = [] for i in range(len(Xp)):     gaussian = attractorfunc(X, Xp[i], 1, attractordepths[i])[0].reshape(         proj_bins, proj_bins, proj_bins     )     gaussian = (gaussian - np.max(gaussian)) / (np.max(gaussian) - np.min(gaussian)) + 1     gaussians_nd.append(gaussian) gaussians_nd = np.stack(gaussians_nd, axis=-1) <p>Potential energy landscape averaged over time provide a clearer view of the attractor structure.</p> In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\n\nviewer.add_image(\n    np.nanmean(pot_timeaveraged, axis=0),\n    colormap=\"twilight\",\n    interpolation2d=\"nearest\",\n    rendering=\"minip\",\n    name=\"Estimated Potential Energy Landscape\",\n)\n\nviewer.add_image(\n    gaussians_nd.mean(-1),\n    colormap=\"twilight\",\n    interpolation2d=\"nearest\",\n    rendering=\"minip\",\n    name=\"Original Potential Energy Landscape\",\n)\n\n# grid view\nviewer.grid.enabled = True\n\n# napari.utils.nbscreenshot(viewer, canvas_only=True)\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 90.0)\nanimation.capture_keyframe()\nmax_steps = 360\n# rotate the camera 360 degrees while advancing the time\nfor i in range(0, max_steps, 3):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.01 * angle_inc,\n        0.0 + 0.02 * angle_inc,\n        90.0 + angle_inc,\n    )\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(\"anim3DPot.mp4\", canvas_only=True)\n\nHTML('&lt;video controls src=\"anim3DPot.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3)  viewer.add_image(     np.nanmean(pot_timeaveraged, axis=0),     colormap=\"twilight\",     interpolation2d=\"nearest\",     rendering=\"minip\",     name=\"Estimated Potential Energy Landscape\", )  viewer.add_image(     gaussians_nd.mean(-1),     colormap=\"twilight\",     interpolation2d=\"nearest\",     rendering=\"minip\",     name=\"Original Potential Energy Landscape\", )  # grid view viewer.grid.enabled = True  # napari.utils.nbscreenshot(viewer, canvas_only=True)  animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 90.0) animation.capture_keyframe() max_steps = 360 # rotate the camera 360 degrees while advancing the time for i in range(0, max_steps, 3):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.01 * angle_inc,         0.0 + 0.02 * angle_inc,         90.0 + angle_inc,     )     animation.capture_keyframe(steps=1)  animation.animate(\"anim3DPot.mp4\", canvas_only=True)  HTML('') <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/121 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1307, 808) to (1312, 816) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n[swscaler @ 0x64e2300] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 121/121 [00:01&lt;00:00, 66.71it/s]\n</pre> Out[\u00a0]: <p>Time-resolved potential estimation visualizes the evolution of the landscape over time.</p> In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\npot_timeresolved = np.nanmean(\n    np.asarray(\n        [\n            potential_pos_t_nrns[:, :, :, :, nrn]\n            for nrn in range(potential_pos_t_nrns.shape[-1])\n        ]\n    ),\n    axis=0,\n)\n\nviewer.add_image(\n    pot_timeresolved.T,\n    colormap=\"twilight\",\n    interpolation=\"nearest\",\n    rendering=\"minip\",\n    name=\"Estimated Potential Energy Landscape\",\n)\n\n# grid view\nviewer.grid.enabled = True\n\n# napari.utils.nbscreenshot(viewer, canvas_only=True)\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 90.0)\nanimation.capture_keyframe()\nmax_steps = int(viewer.dims.range[0][1])\n# rotate the camera 360 degrees while advancing the time\nfor i in np.linspace(0, max_steps - 1, max_steps * 4):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.075 * angle_inc,\n        0.0 + angle_inc,\n        90.0 + 0.1 * angle_inc,\n    )\n    viewer.dims.current_step = (i, *viewer.dims.current_step[1:])\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(\"anim3DPotTimeResolved.mp4\", canvas_only=True)\n\nHTML('&lt;video controls src=\"anim3DPotTimeResolved.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3) pot_timeresolved = np.nanmean(     np.asarray(         [             potential_pos_t_nrns[:, :, :, :, nrn]             for nrn in range(potential_pos_t_nrns.shape[-1])         ]     ),     axis=0, )  viewer.add_image(     pot_timeresolved.T,     colormap=\"twilight\",     interpolation=\"nearest\",     rendering=\"minip\",     name=\"Estimated Potential Energy Landscape\", )  # grid view viewer.grid.enabled = True  # napari.utils.nbscreenshot(viewer, canvas_only=True)  animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 90.0) animation.capture_keyframe() max_steps = int(viewer.dims.range[0][1]) # rotate the camera 360 degrees while advancing the time for i in np.linspace(0, max_steps - 1, max_steps * 4):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.075 * angle_inc,         0.0 + angle_inc,         90.0 + 0.1 * angle_inc,     )     viewer.dims.current_step = (i, *viewer.dims.current_step[1:])     animation.capture_keyframe(steps=1)  animation.animate(\"anim3DPotTimeResolved.mp4\", canvas_only=True)  HTML('') <pre>/tmp/ipykernel_208666/2859654884.py:7: DeprecationWarning: Argument 'interpolation' is deprecated, please use 'interpolation2d' instead. The argument 'interpolation' was deprecated in 0.4.17 and it will be removed in 0.6.0.\n  viewer.add_image(pot_timeresolved.T, colormap='twilight', interpolation='nearest', rendering='minip',\n</pre> <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/81 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1307, 786) to (1312, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n[swscaler @ 0x59a91c0] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81/81 [00:01&lt;00:00, 75.12it/s]\n</pre> Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre># Do PCA on the data\npca = sklearn.decomposition.PCA(n_components=2)\nX_dyn_pca = pca.fit_transform(X_dyn_2D[:, 2:])\n\nviewer = napari.Viewer(ndisplay=2)\nviewer.add_tracks(\n    np.hstack((X_dyn_2D[:, :2], X_dyn_pca)), tail_width=1, name=\"Dynamics of trials\"\n)\n</pre> # Do PCA on the data pca = sklearn.decomposition.PCA(n_components=2) X_dyn_pca = pca.fit_transform(X_dyn_2D[:, 2:])  viewer = napari.Viewer(ndisplay=2) viewer.add_tracks(     np.hstack((X_dyn_2D[:, :2], X_dyn_pca)), tail_width=1, name=\"Dynamics of trials\" ) Out[\u00a0]: <pre>&lt;Tracks layer 'Dynamics of trials' at 0x7294c10ae880&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>def project_ndimage(\n    pot, proj_bins, pca\n):  # -&gt; NDArray:# -&gt; NDArray:# -&gt; NDArray:# -&gt; list:\n    \"\"\"\n    Compute the projected potentials in a reduced PCA space.\n\n    Parameters\n    ----------\n    pot : list of np.ndarray\n        List of potential landscapes for each neuron, where each element is an n-dimensional array.\n    proj_bins : int\n        Number of bins for projecting the data into reduced dimensions.\n    pca : sklearn.decomposition.PCA\n        PCA object to transform high-dimensional data to lower dimensions.\n\n    Returns\n    -------\n    pot_pos_projs : list of np.ndarray\n        List of projected potentials in the PCA-reduced space for each neuron.\n    \"\"\"\n    nnrns = len(pot)  # Number of neurons\n    ndim = pot[0].ndim  # Dimensionality of the potential landscape\n\n    # Flatten potential landscapes into a table\n    indices = np.indices(pot[0].shape).reshape(ndim, -1).T\n    pots_table = np.empty((len(indices), nnrns), dtype=float)\n    for ix, ndix in enumerate(indices):\n        pots_table[ix] = [pot[nrn][tuple(ndix)] for nrn in range(nnrns)]\n\n    # Prepare grid for PCA transformation\n    X = np.linspace(-3, 3, proj_bins)\n    mid_points = (X[1:] + X[:-1]) / 2  # Midpoints of the bins\n    grid = np.meshgrid(*[mid_points for _ in range(ndim)])\n    X = np.stack(grid, axis=-1).reshape(-1, ndim)\n\n    # Transform high-dimensional grid to PCA space\n    ndspace_proj = pca.transform(X)\n\n    # Handle NaN values in the potentials table\n    pots_table[np.isnan(pots_table)] = 0\n\n    # Project potentials into PCA space\n    pot_pos_projs = []\n    for nrn in range(nnrns):\n        # Compute the binned statistics\n        pot_pos_proj = scipy.stats.binned_statistic_dd(\n            ndspace_proj, pots_table[:, nrn], statistic=\"sum\", bins=proj_bins\n        ).statistic\n\n        # Count occurrences in each bin\n        H = scipy.stats.binned_statistic_dd(\n            ndspace_proj, pots_table[:, nrn], statistic=\"count\", bins=proj_bins\n        ).statistic\n\n        # Normalize and handle division by zero\n        pot_pos_proj = np.divide(pot_pos_proj, H, where=H != 0)\n        pot_pos_proj[H == 0] = np.nan  # Assign NaN to empty bins\n\n        pot_pos_projs.append(pot_pos_proj)\n    pot_pos_projs = np.asarray(pot_pos_projs)\n\n    return pot_pos_projs\n</pre> def project_ndimage(     pot, proj_bins, pca ):  # -&gt; NDArray:# -&gt; NDArray:# -&gt; NDArray:# -&gt; list:     \"\"\"     Compute the projected potentials in a reduced PCA space.      Parameters     ----------     pot : list of np.ndarray         List of potential landscapes for each neuron, where each element is an n-dimensional array.     proj_bins : int         Number of bins for projecting the data into reduced dimensions.     pca : sklearn.decomposition.PCA         PCA object to transform high-dimensional data to lower dimensions.      Returns     -------     pot_pos_projs : list of np.ndarray         List of projected potentials in the PCA-reduced space for each neuron.     \"\"\"     nnrns = len(pot)  # Number of neurons     ndim = pot[0].ndim  # Dimensionality of the potential landscape      # Flatten potential landscapes into a table     indices = np.indices(pot[0].shape).reshape(ndim, -1).T     pots_table = np.empty((len(indices), nnrns), dtype=float)     for ix, ndix in enumerate(indices):         pots_table[ix] = [pot[nrn][tuple(ndix)] for nrn in range(nnrns)]      # Prepare grid for PCA transformation     X = np.linspace(-3, 3, proj_bins)     mid_points = (X[1:] + X[:-1]) / 2  # Midpoints of the bins     grid = np.meshgrid(*[mid_points for _ in range(ndim)])     X = np.stack(grid, axis=-1).reshape(-1, ndim)      # Transform high-dimensional grid to PCA space     ndspace_proj = pca.transform(X)      # Handle NaN values in the potentials table     pots_table[np.isnan(pots_table)] = 0      # Project potentials into PCA space     pot_pos_projs = []     for nrn in range(nnrns):         # Compute the binned statistics         pot_pos_proj = scipy.stats.binned_statistic_dd(             ndspace_proj, pots_table[:, nrn], statistic=\"sum\", bins=proj_bins         ).statistic          # Count occurrences in each bin         H = scipy.stats.binned_statistic_dd(             ndspace_proj, pots_table[:, nrn], statistic=\"count\", bins=proj_bins         ).statistic          # Normalize and handle division by zero         pot_pos_proj = np.divide(pot_pos_proj, H, where=H != 0)         pot_pos_proj[H == 0] = np.nan  # Assign NaN to empty bins          pot_pos_projs.append(pot_pos_proj)     pot_pos_projs = np.asarray(pot_pos_projs)      return pot_pos_projs In\u00a0[\u00a0]: Copied! <pre># project potential landscape to 2D\nest_pot = np.asarray(\n    [np.mean(potential_pos_t_nrns[:, :, :, nrn], axis=-1) for nrn in range(3)]\n)\n\nest_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)\n\norig_pot_pos_projs = project_ndimage(gaussians_nd.T, proj_bins + 1, pca)\n\nest_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\naxes[0].imshow(np.nanmean(orig_pot_pos_projs, axis=0))\naxes[0].set_title(\"Original Potential Landscape Projection\")\naxes[1].set_xlabel(\"PC 1\")\naxes[1].set_ylabel(\"PC 2\")\naxes[1].imshow(np.nanmean(est_pot_pos_projs, axis=0))\naxes[1].set_title(\"Estimated Potential Landscape Projection\")\naxes[1].set_xlabel(\"PC 1\")\naxes[1].set_ylabel(\"PC 2\")\n\nplt.show()\n</pre> # project potential landscape to 2D est_pot = np.asarray(     [np.mean(potential_pos_t_nrns[:, :, :, nrn], axis=-1) for nrn in range(3)] )  est_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)  orig_pot_pos_projs = project_ndimage(gaussians_nd.T, proj_bins + 1, pca)  est_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)  fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].imshow(np.nanmean(orig_pot_pos_projs, axis=0)) axes[0].set_title(\"Original Potential Landscape Projection\") axes[1].set_xlabel(\"PC 1\") axes[1].set_ylabel(\"PC 2\") axes[1].imshow(np.nanmean(est_pot_pos_projs, axis=0)) axes[1].set_title(\"Estimated Potential Landscape Projection\") axes[1].set_xlabel(\"PC 1\") axes[1].set_ylabel(\"PC 2\")  plt.show() In\u00a0[\u00a0]: Copied! <pre>ndim = 4\nXp = np.asarray([np.ones(ndim) * 1.5, np.zeros(ndim), np.ones(ndim) * -1.5])\nattractordepths = [1, 0.95, 1]\n\nntrials = 1000\niterations = 500\ndomain_bins = 20\nproj_bins = 20\ndt = 0.1  # time step\nnoise_fac = 0.05  # noise factor\nattractorfunc = gaussian_nd\n\n# Generate starting points\nposxstarts = np.linspace(-3, 3, 8)\nxstarts = np.asarray(np.meshgrid(*[posxstarts] * ndim)).T.reshape(-1, ndim)\nxstarts = np.repeat(xstarts, 2, axis=0)\nnp.random.shuffle(xstarts)\n\n# Simulate dynamics\nX_dyn = simulate_trials(\n    Xp,\n    attractordepths,\n    ntrials,\n    iterations,\n    dt,\n    noise_fac,\n    ngaussians=len(Xp),\n    xstarts=xstarts,\n    func=attractorfunc,\n    std=1,\n)  # shape: (ntrials, iterations, 30)\n</pre> ndim = 4 Xp = np.asarray([np.ones(ndim) * 1.5, np.zeros(ndim), np.ones(ndim) * -1.5]) attractordepths = [1, 0.95, 1]  ntrials = 1000 iterations = 500 domain_bins = 20 proj_bins = 20 dt = 0.1  # time step noise_fac = 0.05  # noise factor attractorfunc = gaussian_nd  # Generate starting points posxstarts = np.linspace(-3, 3, 8) xstarts = np.asarray(np.meshgrid(*[posxstarts] * ndim)).T.reshape(-1, ndim) xstarts = np.repeat(xstarts, 2, axis=0) np.random.shuffle(xstarts)  # Simulate dynamics X_dyn = simulate_trials(     Xp,     attractordepths,     ntrials,     iterations,     dt,     noise_fac,     ngaussians=len(Xp),     xstarts=xstarts,     func=attractorfunc,     std=1, )  # shape: (ntrials, iterations, 30) In\u00a0[\u00a0]: Copied! <pre># convert X_dyn to 2D with columns as (trial number, time step, x, y, z)\n# Reduce high-dimensional data using PCA\npca = sklearn.decomposition.PCA(n_components=3)\n\nX_dyn_tabular = np.concatenate(\n    [\n        np.repeat(np.arange(ntrials), iterations).reshape(-1, 1),\n        np.broadcast_to(np.arange(iterations), (ntrials, iterations))\n        .flatten()\n        .reshape(-1, 1),\n        pca.fit_transform(X_dyn.reshape(-1, ndim)),\n    ],\n    axis=1,\n)\n</pre> # convert X_dyn to 2D with columns as (trial number, time step, x, y, z) # Reduce high-dimensional data using PCA pca = sklearn.decomposition.PCA(n_components=3)  X_dyn_tabular = np.concatenate(     [         np.repeat(np.arange(ntrials), iterations).reshape(-1, 1),         np.broadcast_to(np.arange(iterations), (ntrials, iterations))         .flatten()         .reshape(-1, 1),         pca.fit_transform(X_dyn.reshape(-1, ndim)),     ],     axis=1, ) In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\nviewer.add_tracks(X_dyn_tabular, tail_width=1, name=\"Dynamics of trials\")\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 90.0)\nanimation.capture_keyframe()\nmax_steps = int(viewer.dims.range[0][1])\n# rotate the camera 360 degrees while advancing the time\nfor i in range(0, max_steps, 3):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.075 * angle_inc,\n        0.0 + angle_inc,\n        90.0 + 0.1 * angle_inc,\n    )\n    viewer.dims.current_step = (i, *viewer.dims.current_step[1:])\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(f\"anim{ndim}DTrajs.mp4\", canvas_only=True)\n\nHTML(f'&lt;video controls src=\"anim{ndim}DTrajs.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3) viewer.add_tracks(X_dyn_tabular, tail_width=1, name=\"Dynamics of trials\")  animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 90.0) animation.capture_keyframe() max_steps = int(viewer.dims.range[0][1]) # rotate the camera 360 degrees while advancing the time for i in range(0, max_steps, 3):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.075 * angle_inc,         0.0 + angle_inc,         90.0 + 0.1 * angle_inc,     )     viewer.dims.current_step = (i, *viewer.dims.current_step[1:])     animation.capture_keyframe(steps=1)  animation.animate(f\"anim{ndim}DTrajs.mp4\", canvas_only=True)  HTML(f'') <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/168 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1322, 786) to (1328, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n[swscaler @ 0x6c1c300] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 168/168 [00:08&lt;00:00, 18.73it/s]\n</pre> Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>(\n    potential_timeaveraged,\n    potential_pos_t_nrns,\n    grad_pos_t_svm,\n    H,\n    latentedges,\n    domainedges,\n) = npy.ensemble.potential_landscape_nd(\n    X_dyn,\n    [np.linspace(-3, 3, proj_bins) for i in range(ndim)],\n    domain_bins,\n    nanborderempty=True,\n)\n\nX = np.linspace(-3, 3, proj_bins)\nX = np.meshgrid(*[X for _ in range(ndim)])\nX = np.stack(X, axis=-1)\nX = X.reshape(-1, ndim)\n\nE, dE = mix_functions(X, Xp, attractordepths, func=attractorfunc)\n\ngaussians_nd = []\nfor i in range(len(Xp)):\n    gaussian = attractorfunc(X, Xp[i], 1, attractordepths[i])[0].reshape(\n        *[proj_bins for _ in range(ndim)]\n    )\n    gaussian = (gaussian - np.max(gaussian)) / (np.max(gaussian) - np.min(gaussian)) + 1\n    gaussians_nd.append(gaussian)\ngaussians_nd = np.stack(gaussians_nd, axis=-1)\n</pre> (     potential_timeaveraged,     potential_pos_t_nrns,     grad_pos_t_svm,     H,     latentedges,     domainedges, ) = npy.ensemble.potential_landscape_nd(     X_dyn,     [np.linspace(-3, 3, proj_bins) for i in range(ndim)],     domain_bins,     nanborderempty=True, )  X = np.linspace(-3, 3, proj_bins) X = np.meshgrid(*[X for _ in range(ndim)]) X = np.stack(X, axis=-1) X = X.reshape(-1, ndim)  E, dE = mix_functions(X, Xp, attractordepths, func=attractorfunc)  gaussians_nd = [] for i in range(len(Xp)):     gaussian = attractorfunc(X, Xp[i], 1, attractordepths[i])[0].reshape(         *[proj_bins for _ in range(ndim)]     )     gaussian = (gaussian - np.max(gaussian)) / (np.max(gaussian) - np.min(gaussian)) + 1     gaussians_nd.append(gaussian) gaussians_nd = np.stack(gaussians_nd, axis=-1) In\u00a0[\u00a0]: Copied! <pre>orig_pot_pos_projs = project_ndimage(gaussians_nd.T, proj_bins + 1, pca)\n\n# avoid RuntimeWarning: Mean of empty slice\nest_pot = np.asarray(\n    [\n        np.nanmean(potential_pos_t_nrns[:, :, :, :, :, nrn], axis=-1)\n        for nrn in range(ndim)\n    ]\n)\nest_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\naxes[0].imshow(np.nanmean(np.nanmean(orig_pot_pos_projs, axis=0), axis=-1))\naxes[0].set_title(\"Original Potential Landscape Projection\")\naxes[0].set_xlabel(\"PC 1\")\naxes[0].set_ylabel(\"PC 2\")\naxes[1].imshow(np.nanmean(np.nanmean(est_pot_pos_projs, axis=0), axis=-1))\naxes[1].set_title(\"Estimated Potential Landscape Projection\")\naxes[1].set_xlabel(\"PC 1\")\naxes[1].set_ylabel(\"PC 2\")\n\nplt.show()\n</pre> orig_pot_pos_projs = project_ndimage(gaussians_nd.T, proj_bins + 1, pca)  # avoid RuntimeWarning: Mean of empty slice est_pot = np.asarray(     [         np.nanmean(potential_pos_t_nrns[:, :, :, :, :, nrn], axis=-1)         for nrn in range(ndim)     ] ) est_pot_pos_projs = project_ndimage(est_pot, proj_bins, pca)  fig, axes = plt.subplots(1, 2, figsize=(15, 5)) axes[0].imshow(np.nanmean(np.nanmean(orig_pot_pos_projs, axis=0), axis=-1)) axes[0].set_title(\"Original Potential Landscape Projection\") axes[0].set_xlabel(\"PC 1\") axes[0].set_ylabel(\"PC 2\") axes[1].imshow(np.nanmean(np.nanmean(est_pot_pos_projs, axis=0), axis=-1)) axes[1].set_title(\"Estimated Potential Landscape Projection\") axes[1].set_xlabel(\"PC 1\") axes[1].set_ylabel(\"PC 2\")  plt.show() <p>Visualize the PCA-projected ground truth and estimated potential landscapes to understand the attractor structure in the n-dimensional systems.</p> In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\n\nviewer.add_image(\n    np.nanmean(est_pot_pos_projs, axis=0),\n    colormap=\"twilight\",\n    interpolation2d=\"nearest\",\n    rendering=\"minip\",\n    name=\"Estimated Potential Energy Landscape\",\n)\n\nviewer.add_image(\n    np.nanmean(orig_pot_pos_projs, axis=0),\n    colormap=\"twilight\",\n    interpolation2d=\"nearest\",\n    rendering=\"minip\",\n    name=\"Original Potential Energy Landscape\",\n)\n\nviewer.grid.enabled = True\n\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 0.0)\nanimation.capture_keyframe()\nmax_steps = 360\n# rotate the camera 360 degrees while advancing the time\nfor i in range(0, max_steps, 3):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.01 * angle_inc,\n        0.0 + 0.02 * angle_inc,\n        0.0 + angle_inc,\n    )\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(f\"anim{ndim}DPot.mp4\", canvas_only=True)\n# viewer.close()\n\nHTML(f'&lt;video controls src=\"anim{ndim}DPot.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3)  viewer.add_image(     np.nanmean(est_pot_pos_projs, axis=0),     colormap=\"twilight\",     interpolation2d=\"nearest\",     rendering=\"minip\",     name=\"Estimated Potential Energy Landscape\", )  viewer.add_image(     np.nanmean(orig_pot_pos_projs, axis=0),     colormap=\"twilight\",     interpolation2d=\"nearest\",     rendering=\"minip\",     name=\"Original Potential Energy Landscape\", )  viewer.grid.enabled = True   animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 0.0) animation.capture_keyframe() max_steps = 360 # rotate the camera 360 degrees while advancing the time for i in range(0, max_steps, 3):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.01 * angle_inc,         0.0 + 0.02 * angle_inc,         0.0 + angle_inc,     )     animation.capture_keyframe(steps=1)  animation.animate(f\"anim{ndim}DPot.mp4\", canvas_only=True) # viewer.close()  HTML(f'') <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/121 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1307, 808) to (1312, 816) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n[swscaler @ 0x6f58300] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 121/121 [00:01&lt;00:00, 77.39it/s]\n</pre> Out[\u00a0]: <p>Visualize the time-resolved potential estimation for the 4D system.</p> In\u00a0[\u00a0]: Copied! <pre>viewer = napari.Viewer(ndisplay=3)\n\npot_timeresolved = np.asarray(\n    [\n        np.nanmean(project_ndimage(potential_pos_nrns, proj_bins, pca), axis=0)\n        for potential_pos_nrns in np.transpose(potential_pos_t_nrns, (4, 5, 0, 1, 2, 3))\n    ]\n)\n\nviewer.add_image(\n    pot_timeresolved,\n    colormap=\"twilight\",\n    interpolation2d=\"nearest\",\n    rendering=\"minip\",\n    name=\"Estimated Potential Energy Landscape\",\n)\n\n# grid view\nviewer.grid.enabled = True\n\n# napari.utils.nbscreenshot(viewer, canvas_only=True)\n\nanimation = Animation(viewer)\nviewer.update_console({\"animation\": animation})\n\nviewer.camera.angles = (0.0, 0.0, 0.0)\nanimation.capture_keyframe()\nmax_steps = int(viewer.dims.range[0][1])\n# rotate the camera 360 degrees while advancing the time\nfor i in np.linspace(0, max_steps - 1, max_steps * 4):\n    angle_inc = i * 360 / max_steps\n    viewer.camera.angles = (\n        0.0 + 0.075 * angle_inc,\n        0.0 + angle_inc,\n        90.0 + 0.1 * angle_inc,\n    )\n    viewer.dims.current_step = (i, *viewer.dims.current_step[1:])\n    animation.capture_keyframe(steps=1)\n\nanimation.animate(\"anim{ndim}DPotTimeResolved.mp4\", canvas_only=True)\n\nHTML(f'&lt;video controls src=\"anim{ndim}DPotTimeResolved.mp4\" /&gt;')\n</pre> viewer = napari.Viewer(ndisplay=3)  pot_timeresolved = np.asarray(     [         np.nanmean(project_ndimage(potential_pos_nrns, proj_bins, pca), axis=0)         for potential_pos_nrns in np.transpose(potential_pos_t_nrns, (4, 5, 0, 1, 2, 3))     ] )  viewer.add_image(     pot_timeresolved,     colormap=\"twilight\",     interpolation2d=\"nearest\",     rendering=\"minip\",     name=\"Estimated Potential Energy Landscape\", )  # grid view viewer.grid.enabled = True  # napari.utils.nbscreenshot(viewer, canvas_only=True)  animation = Animation(viewer) viewer.update_console({\"animation\": animation})  viewer.camera.angles = (0.0, 0.0, 0.0) animation.capture_keyframe() max_steps = int(viewer.dims.range[0][1]) # rotate the camera 360 degrees while advancing the time for i in np.linspace(0, max_steps - 1, max_steps * 4):     angle_inc = i * 360 / max_steps     viewer.camera.angles = (         0.0 + 0.075 * angle_inc,         0.0 + angle_inc,         90.0 + 0.1 * angle_inc,     )     viewer.dims.current_step = (i, *viewer.dims.current_step[1:])     animation.capture_keyframe(steps=1)  animation.animate(\"anim{ndim}DPotTimeResolved.mp4\", canvas_only=True)  HTML(f'') <pre>Rendering frames...\n</pre> <pre>  0%|          | 0/81 [00:00&lt;?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1307, 786) to (1312, 800) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n[swscaler @ 0x61401c0] Warning: data is not aligned! This can lead to a speed loss\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81/81 [00:01&lt;00:00, 77.96it/s]\n</pre> Out[\u00a0]:"},{"location":"tutorials/attractor_landscape/#attractor-estimation","title":"Attractor Estimation\u00b6","text":"<p>This tutorial demonstrates how to estimate potential energy landscapes for simulated dynamical systems with attractors in one, two, three, and higher dimensions. The goal is to understand the dynamics of systems governed by these landscapes and validate estimations against the ground truth.</p>"},{"location":"tutorials/attractor_landscape/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/attractor_landscape/#section-1-1d-energy-landscape","title":"Section 1: 1D Energy Landscape\u00b6","text":"<p>This section focuses on simulating and estimating a 1D energy landscape to provide a foundational understanding of attractor dynamics in a simple setting.</p>"},{"location":"tutorials/attractor_landscape/#section-11-simulate-trials-of-1d-activity-using-langevin-dynamics-with-noise","title":"Section 1.1: Simulate trials of 1D activity using Langevin dynamics with noise\u00b6","text":"<p>We simulate the dynamics of particles (or neural states) evolving under a 1D potential landscape influenced by noise. The dynamics are modeled using Langevin equations with parameters for attractor depths, positions, and noise.</p> <p>Goals:</p> <ul> <li>To visualize particle dynamics under a simple potential landscape.</li> <li>To understand how initial states and noise affects convergence to attractors and hence their estimation.</li> </ul> <p>Key Insights:</p> <ul> <li>Particle trajectories converge to the minima of the potential wells, confirming the attractor dynamics.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-12-analytically-estimate-the-1d-potential-energy-landscape","title":"Section 1.2: Analytically estimate the 1D potential energy landscape\u00b6","text":"<p>We analytically compute the 1D potential landscape and compare it to the ground-truth potential used to generate the synthetic data.</p> <p>Goal:</p> <ul> <li>To validate the simulation by comparing it to the analytical potential.</li> </ul> <p>Plot Descriptions:</p> <ol> <li>Potential Landscape: Displays the theoretical potential formed by the Gaussian mixture components.</li> <li>Dynamics of Trials: Shows the temporal evolution of particle positions for selected trials.</li> <li>Potential Landscape Estimation: Compares the analytical potential with the estimated potential.</li> </ol> <p>Key Insights:</p> <ul> <li>The estimated potential closely matches the analytical potential, confirming the method's validity.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-2-2d-energy-landscape","title":"Section 2: 2D Energy Landscape\u00b6","text":"<p>In this section, we extend the dynamics and estimation to two dimensions, introducing more complexity.</p>"},{"location":"tutorials/attractor_landscape/#section-21-simulate-trials-of-2d-activity-using-langevin-dynamics-with-noise","title":"Section 2.1: Simulate trials of 2D activity using Langevin dynamics with noise\u00b6","text":"<p>Simulate particle dynamics under a 2D potential landscape composed of Gaussian attractors.</p> <p>Goal:</p> <ul> <li>To explore how particle dynamics evolve in a 2D system with multiple attractors</li> </ul> <p>Key Insights:</p> <ul> <li>Particle trajectories converge to minima in 2D, clustering around attractor states.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-22-analytically-estimate-the-potential-energy-landscape","title":"Section 2.2: Analytically estimate the potential energy landscape\u00b6","text":"<p>Compute and validate the 2D potential landscape using analytical and simulated results.</p> <p>Plot Descriptions:</p> <ol> <li>Potential Energy Landscape: Visualizes the 2D attractor structure.</li> <li>Dynamics of Trials: Shows particle trajectories across the 2D plane.</li> <li>Phase Plane: Depicts vector fields indicating gradients toward attractor basins.</li> <li>Time-Resolved Potential Estimation: Highlights temporal changes in the estimated landscape.</li> </ol> <p>Key Insights:</p> <ul> <li>The agreement between the simulated dynamics and estimated landscapes demonstrates robustness in two dimensions.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-23-simulate-2d-trials-for-a-ring-attractor","title":"Section 2.3: Simulate 2D trials for a ring attractor\u00b6","text":""},{"location":"tutorials/attractor_landscape/#section-24-analytically-estimate-the-potential-energy-landscape","title":"Section 2.4: Analytically estimate the potential energy landscape\u00b6","text":"<p>Estimate the potential landscape for the ring attractor and compare it to the ground-truth potential.</p> <p>Plot Descriptions:</p> <ol> <li>Potential Energy Landscape: Displays the ring attractor structure.</li> <li>Dynamics of Trials: Shows particle trajectories in the 2D plane.</li> <li>Phase Plane: Depicts vector fields indicating gradients toward the ring attractor.</li> <li>Time-Resolved Potential Estimation: Highlights temporal changes in the estimated landscape.</li> </ol> <p>Key Insights:</p> <ul> <li>The estimated potential closely matches the analytical potential, confirming the method's validity.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-3-3d-energy-landscape","title":"Section 3: 3D Energy Landscape\u00b6","text":"<p>This section explores the dynamics and estimation of potential landscapes in three dimensions.</p>"},{"location":"tutorials/attractor_landscape/#section-31-simulate-3d-trials-using-langevin-dynamics-with-noise","title":"Section 3.1: Simulate 3D trials using Langevin dynamics with noise\u00b6","text":"<p>Simulate 3D dynamics under Gaussian attractors to examine the additional complexity introduced by higher dimensions.</p> <p>Purpose:</p> <ul> <li>To study how particle trajectories behave in a 3D space with noise.</li> </ul> <p>Plot Descriptions:</p> <ul> <li>Dynamics of Trials: Shows particle trajectories in the 3D space.</li> </ul> <p>Key Insights:</p> <ul> <li>Trajectories exhibit complex convergence patterns due to added dimensionality.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-32-analytically-estimate-the-potential-energy-landscape","title":"Section 3.2: Analytically estimate the potential energy landscape\u00b6","text":"<p>Visualize and validate the estimated 3D landscape against the analytical potential.</p> <p>Plot Descriptions:</p> <ul> <li>Potential Energy Landscape: Displays the 3D attractor structure.</li> <li>Time-Resolved Potential Estimation: Highlights temporal changes in the estimated landscape.</li> </ul> <p>Key Insights:</p> <ul> <li>The estimated potential closely matches the analytical potential, confirming the method's validity.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-33-potential-energy-landscape-dimensionality-reduction-via-pca","title":"Section 3.3: Potential energy landscape dimensionality reduction via PCA\u00b6","text":"<p>PCA is used to reduce the dimensionality of energy landscapes for better visualization and analysis.</p> <p>Purpose:</p> <ul> <li>To simplify the representation of high-dimensional landscapes.</li> </ul> <p>Key Insights:</p> <ul> <li>PCA-projected landscapes retain essential attractor characteristics.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-4-n-dimensional-energy-landscape","title":"Section 4: n-dimensional Energy Landscape\u00b6","text":""},{"location":"tutorials/attractor_landscape/#section-41-simulate-n-dimensional-trials-using-langevin-dynamics-with-noise","title":"Section 4.1: Simulate n-dimensional trials using Langevin dynamics with noise\u00b6","text":"<p>Simulate particle dynamics in an n-dimensional landscape to study the scalability of the methods.</p> <p>Purpose:</p> <ul> <li>To test how well the simulation and estimation approaches scale with dimensionality.</li> </ul> <p>Key Insights:</p> <ul> <li>Higher-dimensional systems pose challenges in visualization and computational requirements.</li> </ul>"},{"location":"tutorials/attractor_landscape/#section-42-analytically-estimate-the-potential-energy-landscape","title":"Section 4.2: Analytically estimate the potential energy landscape\u00b6","text":"<p>Validate the estimated n-dimensional potential against theoretical predictions using dimensionality reduction techniques like PCA.</p> <p>Key Insights:</p> <ul> <li>Projected landscapes in PCA space confirm the validity of estimations in high-dimensional systems.</li> </ul>"},{"location":"tutorials/attractor_landscape/#conclusion","title":"Conclusion\u00b6","text":"<p>This tutorial demonstrates the simulation and estimation of energy landscapes across varying dimensions. The analytical and simulated results show strong agreement, validating the robustness of the approach even in higher dimensions. These methods have potential applications in understanding complex neural systems governed by attractor dynamics.</p>"},{"location":"tutorials/batch_analysis/","title":"Batch Analysis","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport pandas as pd\n\nfrom neuro_py.process import batch_analysis\n</pre> %reload_ext autoreload %autoreload 2  import numpy as np import pandas as pd  from neuro_py.process import batch_analysis In\u00a0[2]: Copied! <pre>def toy_analysis(basepath, parameter_1=1, parameter_2=2):\n    results = pd.DataFrame()\n    results[\"basepath\"] = [basepath]\n    results[\"parameter_1\"] = parameter_1\n    results[\"parameter_2\"] = parameter_2\n    results[\"random_number\"] = np.random.randint(0, 100)\n    return results\n</pre> def toy_analysis(basepath, parameter_1=1, parameter_2=2):     results = pd.DataFrame()     results[\"basepath\"] = [basepath]     results[\"parameter_1\"] = parameter_1     results[\"parameter_2\"] = parameter_2     results[\"random_number\"] = np.random.randint(0, 100)     return results <p>For your project, you will have a <code>.csv</code> file with the <code>basepaths</code> you want to analyze. Here, I'm creating a <code>DataFrame</code> with the <code>basepaths</code> for the purpose of this notebook.</p> In\u00a0[3]: Copied! <pre>sessions = pd.DataFrame(\n    dict(\n        basepath=[\n            r\"U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227\",\n            r\"U:\\data\\hpc_ctx_project\\HP01\\day_2_20240228\",\n            r\"U:\\data\\hpc_ctx_project\\HP01\\day_3_20240229\",\n        ]\n    )\n)\n</pre> sessions = pd.DataFrame(     dict(         basepath=[             r\"U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227\",             r\"U:\\data\\hpc_ctx_project\\HP01\\day_2_20240228\",             r\"U:\\data\\hpc_ctx_project\\HP01\\day_3_20240229\",         ]     ) ) <p>You will need to define the path where you want to save the results of your analysis.</p> <p>It's useful to nest the analysis version in a subfolder (<code>toy_analysis\\toy_analysis_v1</code>) to keep track of the different versions of your analysis.</p> In\u00a0[4]: Copied! <pre>save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v1\"\n</pre> save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v1\" In\u00a0[5]: Copied! <pre>batch_analysis.run(\n    sessions,\n    save_path,\n    toy_analysis,\n    parallel=False,\n    verbose=True,\n)\n</pre> batch_analysis.run(     sessions,     save_path,     toy_analysis,     parallel=False,     verbose=True, ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 759.52it/s]</pre> <pre>U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227\nU:\\data\\hpc_ctx_project\\HP01\\day_2_20240228\nU:\\data\\hpc_ctx_project\\HP01\\day_3_20240229\n</pre> <pre>\n</pre> In\u00a0[6]: Copied! <pre>results = batch_analysis.load_results(save_path)\nresults\n</pre> results = batch_analysis.load_results(save_path) results Out[6]: basepath paramater_1 paramater_2 random_number 0 U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227 1 2 34 1 U:\\data\\hpc_ctx_project\\HP01\\day_2_20240228 1 2 30 2 U:\\data\\hpc_ctx_project\\HP01\\day_3_20240229 1 2 66 In\u00a0[7]: Copied! <pre>import glob\nimport os\nimport pickle\n\n\ndef toy_analysis_2(basepath, paramater_1=1, paramater_2=2):\n    results_df = pd.DataFrame()\n    results_df[\"basepath\"] = [basepath]\n    results_df[\"paramater_1\"] = paramater_1\n    results_df[\"paramater_2\"] = paramater_2\n    results_df[\"random_number\"] = np.random.randint(0, 100)\n\n    window_starttime, window_stoptime = [-1, 1]\n    window_bins = int(np.ceil(((window_stoptime - window_starttime) * 1000)))\n    time_lags = np.linspace(window_starttime, window_stoptime, window_bins)\n    psths = pd.DataFrame(\n        index=time_lags,\n        columns=np.arange(1),\n    )\n    psths[:] = np.random.rand(window_bins, 1)\n\n    results = {\n        \"results_df\": results_df,\n        \"psth\": psths,\n    }\n    return results\n\n\n# custom loader\ndef load_results(save_path, verbose=False):\n    # check if folder exists\n    if not os.path.exists(save_path):\n        raise ValueError(f\"folder {save_path} does not exist\")\n\n    # get all the sessions\n    sessions = glob.glob(save_path + os.sep + \"*.pkl\")\n\n    results_df = []\n    psths = []\n\n    # iterate over the sessions\n    for session in sessions:\n        if verbose:\n            print(session)\n\n        # load the session\n        with open(session, \"rb\") as f:\n            results_ = pickle.load(f)\n\n        if results_ is None:\n            continue\n        results_df.append(results_[\"results_df\"])\n        psths.append(results_[\"psth\"])\n\n    results_df = pd.concat(results_df, axis=0, ignore_index=True)\n    psths = pd.concat(psths, axis=1, ignore_index=True)\n\n    return results_df, psths\n</pre> import glob import os import pickle   def toy_analysis_2(basepath, paramater_1=1, paramater_2=2):     results_df = pd.DataFrame()     results_df[\"basepath\"] = [basepath]     results_df[\"paramater_1\"] = paramater_1     results_df[\"paramater_2\"] = paramater_2     results_df[\"random_number\"] = np.random.randint(0, 100)      window_starttime, window_stoptime = [-1, 1]     window_bins = int(np.ceil(((window_stoptime - window_starttime) * 1000)))     time_lags = np.linspace(window_starttime, window_stoptime, window_bins)     psths = pd.DataFrame(         index=time_lags,         columns=np.arange(1),     )     psths[:] = np.random.rand(window_bins, 1)      results = {         \"results_df\": results_df,         \"psth\": psths,     }     return results   # custom loader def load_results(save_path, verbose=False):     # check if folder exists     if not os.path.exists(save_path):         raise ValueError(f\"folder {save_path} does not exist\")      # get all the sessions     sessions = glob.glob(save_path + os.sep + \"*.pkl\")      results_df = []     psths = []      # iterate over the sessions     for session in sessions:         if verbose:             print(session)          # load the session         with open(session, \"rb\") as f:             results_ = pickle.load(f)          if results_ is None:             continue         results_df.append(results_[\"results_df\"])         psths.append(results_[\"psth\"])      results_df = pd.concat(results_df, axis=0, ignore_index=True)     psths = pd.concat(psths, axis=1, ignore_index=True)      return results_df, psths In\u00a0[8]: Copied! <pre>save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v2\"\n\nbatch_analysis.run(\n    sessions,\n    save_path,\n    toy_analysis_2,\n    parallel=False,\n    verbose=True,\n)\n</pre> save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v2\"  batch_analysis.run(     sessions,     save_path,     toy_analysis_2,     parallel=False,     verbose=True, ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 840.94it/s]</pre> <pre>U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227\nU:\\data\\hpc_ctx_project\\HP01\\day_2_20240228\nU:\\data\\hpc_ctx_project\\HP01\\day_3_20240229\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre>results_df, psths = load_results(save_path)\n\ndisplay(results_df)\ndisplay(psths)\n</pre> results_df, psths = load_results(save_path)  display(results_df) display(psths) basepath paramater_1 paramater_2 random_number 0 U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227 1 2 56 1 U:\\data\\hpc_ctx_project\\HP01\\day_2_20240228 1 2 32 2 U:\\data\\hpc_ctx_project\\HP01\\day_3_20240229 1 2 56 0 1 2 -1.000000 0.190685 0.490553 0.248958 -0.998999 0.078999 0.689063 0.40577 -0.997999 0.094847 0.788747 0.966084 -0.996998 0.287616 0.804512 0.846309 -0.995998 0.723807 0.996373 0.850087 ... ... ... ... 0.995998 0.023565 0.136486 0.120244 0.996998 0.298943 0.844828 0.227437 0.997999 0.514455 0.847778 0.782702 0.998999 0.975054 0.795339 0.898294 1.000000 0.122129 0.228904 0.168518 <p>2000 rows \u00d7 3 columns</p> In\u00a0[10]: Copied! <pre># Use HDF5 format for better performance and selective loading\nsave_path_hdf5 = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v3_hdf5\"\n\nbatch_analysis.run(\n    sessions,\n    save_path_hdf5,\n    toy_analysis_2,\n    parallel=False,\n    verbose=True,\n    format_type=\"hdf5\",  # Use HDF5 format\n)\n</pre> # Use HDF5 format for better performance and selective loading save_path_hdf5 = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v3_hdf5\"  batch_analysis.run(     sessions,     save_path_hdf5,     toy_analysis_2,     parallel=False,     verbose=True,     format_type=\"hdf5\",  # Use HDF5 format ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 380.03it/s]</pre> <pre>U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227\nU:\\data\\hpc_ctx_project\\HP01\\day_2_20240228\nU:\\data\\hpc_ctx_project\\HP01\\day_3_20240229\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre># Get a specific file path\nsession_file = batch_analysis.encode_file_path(\n    sessions.iloc[0][\"basepath\"], save_path_hdf5, format_type=\"hdf5\"\n)\n\nprint(f\"Loading from: {session_file}\")\n\n# Load only the results DataFrame\nresults_only = batch_analysis.load_specific_data(session_file, key=\"results_df\")\nprint(\"Results DataFrame only:\")\ndisplay(results_only)\n\n# Load only the PSTH data\npsth_only = batch_analysis.load_specific_data(session_file, key=\"psth\")\nprint(\"\\nPSTH data only:\")\ndisplay(psth_only.head())\n\n# Load everything (equivalent to not specifying a key)\nall_data = batch_analysis.load_specific_data(session_file)\nprint(f\"\\nAll data keys: {list(all_data.keys())}\")\n</pre> # Get a specific file path session_file = batch_analysis.encode_file_path(     sessions.iloc[0][\"basepath\"], save_path_hdf5, format_type=\"hdf5\" )  print(f\"Loading from: {session_file}\")  # Load only the results DataFrame results_only = batch_analysis.load_specific_data(session_file, key=\"results_df\") print(\"Results DataFrame only:\") display(results_only)  # Load only the PSTH data psth_only = batch_analysis.load_specific_data(session_file, key=\"psth\") print(\"\\nPSTH data only:\") display(psth_only.head())  # Load everything (equivalent to not specifying a key) all_data = batch_analysis.load_specific_data(session_file) print(f\"\\nAll data keys: {list(all_data.keys())}\") <pre>Loading from: Z:\\home\\ryanh\\projects\\hpc_ctx\\toy_analysis\\toy_analysis_v3_hdf5\\U---___data___hpc_ctx_project___HP01___day_1_20240227.h5\nResults DataFrame only:\n</pre> basepath paramater_1 paramater_2 random_number 0 U:\\data\\hpc_ctx_project\\HP01\\day_1_20240227 1 2 42 <pre>\nPSTH data only:\n</pre> 0 -1.000000 0.09495039896565927 -0.998999 0.025459594964744592 -0.997999 0.7897323765370252 -0.996998 0.3043882313446068 -0.995998 0.08990904706906877 <pre>\nAll data keys: ['psth', 'results_df']\n</pre>"},{"location":"tutorials/batch_analysis/#batch-analysis","title":"Batch Analysis\u00b6","text":""},{"location":"tutorials/batch_analysis/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/batch_analysis/#section-1-define-the-analysis","title":"Section 1: Define the analysis\u00b6","text":"<p>Here, I'm defining the analysis in the notebook, but in a real project, you would define it in a separate <code>.py</code> file and import it here.</p>"},{"location":"tutorials/batch_analysis/#section-2-run-the-analysis","title":"Section 2: Run the analysis\u00b6","text":"<p>Finally, you can run your analysis in batch mode. This will loop through the <code>basepaths</code> and save the results in the specified folder.</p> <p>The <code>batch_analysis</code> function is a general function that you can use for any analysis. You just need to pass the function you want to run, the <code>basepaths</code> you want to analyze, and the save path.</p> <p>If your analysis fails, running again will start from where it left off.</p> <p>There is a <code>parallel</code> option that you can set to <code>True</code> if you want to run the analysis in parallel. This will speed up the analysis if you have multiple cores.</p>"},{"location":"tutorials/batch_analysis/#section-3-load-the-results","title":"Section 3: Load the results\u00b6","text":"<p>There is a built in loader that concatenates the results of the analysis into a single <code>DataFrame</code>.</p>"},{"location":"tutorials/batch_analysis/#bonus-more-complicated-results","title":"Bonus: More complicated results\u00b6","text":"<p>Your results won't always fit nicely into a single <code>DataFrame</code>. Sometimes you will have multiple data types you need to save.</p> <p>For example, you might have values for each cell in a <code>DataFrame</code> and also PSTHs for each cell. Your analysis will store both in a dictionary and you will construct a custom loader in your analysis.</p>"},{"location":"tutorials/batch_analysis/#define-the-analysis","title":"Define the analysis\u00b6","text":""},{"location":"tutorials/batch_analysis/#run-the-analysis","title":"Run the analysis\u00b6","text":""},{"location":"tutorials/batch_analysis/#load-the-results","title":"Load the results\u00b6","text":""},{"location":"tutorials/batch_analysis/#section-4-hdf5-format-and-partial-loading","title":"Section 4: HDF5 Format and Partial Loading\u00b6","text":"<p>The batch analysis system now supports HDF5 format, which offers several advantages over pickle:</p> <ul> <li>Better performance for large datasets</li> <li>Selective loading of specific data components</li> <li>Cross-platform compatibility</li> <li>More efficient storage for numerical data</li> </ul>"},{"location":"tutorials/batch_analysis/#run-analysis-with-hdf5-format","title":"Run analysis with HDF5 format\u00b6","text":""},{"location":"tutorials/batch_analysis/#partial-loading-with-load_specific_data","title":"Partial loading with load_specific_data()\u00b6","text":""},{"location":"tutorials/batch_analysis/#when-to-use-hdf5-vs-pickle","title":"When to use HDF5 vs Pickle\u00b6","text":""},{"location":"tutorials/batch_analysis/#use-hdf5-when","title":"Use HDF5 when:\u00b6","text":"<ul> <li>Working with large datasets (&gt;100MB per file)</li> <li>You need to load only specific components</li> <li>Cross-platform compatibility is important</li> <li>You have mostly numerical data (pandas DataFrames, numpy arrays)</li> </ul>"},{"location":"tutorials/batch_analysis/#use-pickle-when","title":"Use Pickle when:\u00b6","text":"<ul> <li>Working with small datasets</li> <li>You have complex Python objects that don't translate well to HDF5</li> <li>You always need to load the complete dataset</li> <li>Simplicity is preferred</li> </ul> <p>This new functionality maintains backward compatibility while providing more efficient options for large-scale analyses.</p>"},{"location":"tutorials/bias_correlation/","title":"Bias Correlation","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\nimport copy\nimport logging\n\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\nimport nelpy as nel\nimport numpy as np\nimport scipy\n\nimport neuro_py as npy\n\n# Disable logging\nlogger = logging.getLogger()\nlogger.disabled = True\n\n# Set random seed for reproducibility\nnp.random.seed(0)\n</pre> %reload_ext autoreload %autoreload 2 import copy import logging  import ipywidgets as widgets import matplotlib.pyplot as plt import nelpy as nel import numpy as np import scipy  import neuro_py as npy  # Disable logging logger = logging.getLogger() logger.disabled = True  # Set random seed for reproducibility np.random.seed(0) In\u00a0[2]: Copied! <pre>def simulate_sequential_spikes(\n    nneurons=30,\n    minseqduration=0.05,\n    maxseqduration=0.15,\n    duration=1.0,\n    jitter=0.01,\n    reverseseqprob=0.0,\n    random=False,\n):\n    spikes = []\n    neuron_ids = []\n    max_nsequences = np.ceil(duration / minseqduration)\n    sequence_durations = np.random.uniform(\n        minseqduration, maxseqduration, int(max_nsequences)\n    )\n    # get index of last sequence that fits into duration\n    last_sequence = np.where(np.cumsum(sequence_durations) &lt;= duration)[0][-1]\n    sequence_durations = sequence_durations[: last_sequence + 1]\n    sequence_epochs = np.cumsum(sequence_durations)\n    sequence_epochs = np.asarray(\n        (np.r_[0, sequence_epochs][:-1], sequence_epochs)\n    ).T  # shape (nsequences, 2)\n\n    for seq_start, seq_end in sequence_epochs:\n        spike_ts = np.linspace(seq_start, seq_end, nneurons)\n        neuron_seqids = (\n            np.arange(nneurons)\n            if np.random.rand() &gt; reverseseqprob\n            else np.arange(nneurons)[::-1]\n        )\n        # add jitter\n        spike_ts += np.random.uniform(-jitter, jitter, nneurons)\n        spike_ts = np.sort(spike_ts)\n        # clip to sequence bounds\n        spike_ts = np.clip(spike_ts, seq_start, seq_end)\n        spikes.append(spike_ts)\n        neuron_ids.append(neuron_seqids)\n\n    spikes = np.concatenate(spikes)\n    neuron_ids = np.concatenate(neuron_ids)\n\n    if random:\n        neuron_ids = np.random.permutation(neuron_ids)\n\n    return spikes, neuron_ids, sequence_epochs\n</pre> def simulate_sequential_spikes(     nneurons=30,     minseqduration=0.05,     maxseqduration=0.15,     duration=1.0,     jitter=0.01,     reverseseqprob=0.0,     random=False, ):     spikes = []     neuron_ids = []     max_nsequences = np.ceil(duration / minseqduration)     sequence_durations = np.random.uniform(         minseqduration, maxseqduration, int(max_nsequences)     )     # get index of last sequence that fits into duration     last_sequence = np.where(np.cumsum(sequence_durations) &lt;= duration)[0][-1]     sequence_durations = sequence_durations[: last_sequence + 1]     sequence_epochs = np.cumsum(sequence_durations)     sequence_epochs = np.asarray(         (np.r_[0, sequence_epochs][:-1], sequence_epochs)     ).T  # shape (nsequences, 2)      for seq_start, seq_end in sequence_epochs:         spike_ts = np.linspace(seq_start, seq_end, nneurons)         neuron_seqids = (             np.arange(nneurons)             if np.random.rand() &gt; reverseseqprob             else np.arange(nneurons)[::-1]         )         # add jitter         spike_ts += np.random.uniform(-jitter, jitter, nneurons)         spike_ts = np.sort(spike_ts)         # clip to sequence bounds         spike_ts = np.clip(spike_ts, seq_start, seq_end)         spikes.append(spike_ts)         neuron_ids.append(neuron_seqids)      spikes = np.concatenate(spikes)     neuron_ids = np.concatenate(neuron_ids)      if random:         neuron_ids = np.random.permutation(neuron_ids)      return spikes, neuron_ids, sequence_epochs <p>Set parameters for simulation of spike data.</p> In\u00a0[3]: Copied! <pre>N_NEURONS = 15\nMIN_SEQ_DURATION = 0.05\nMAX_SEQ_DURATION = 0.15\nDURATION = 0.5\n</pre> N_NEURONS = 15 MIN_SEQ_DURATION = 0.05 MAX_SEQ_DURATION = 0.15 DURATION = 0.5 In\u00a0[4]: Copied! <pre>task_spikes, task_neurons, task_seq_epochs = simulate_sequential_spikes(\n    nneurons=N_NEURONS,\n    minseqduration=MIN_SEQ_DURATION,\n    maxseqduration=MAX_SEQ_DURATION,\n    duration=DURATION,\n    random=False,\n)\n\n# Visualize task spike data\nplt.figure(figsize=(12, 6))\nplt.scatter(task_spikes, task_neurons, c=\"k\", marker=\"|\", s=18)\nplt.title(\"Task Spike Data\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Neuron ID\")\nplt.show()\n</pre> task_spikes, task_neurons, task_seq_epochs = simulate_sequential_spikes(     nneurons=N_NEURONS,     minseqduration=MIN_SEQ_DURATION,     maxseqduration=MAX_SEQ_DURATION,     duration=DURATION,     random=False, )  # Visualize task spike data plt.figure(figsize=(12, 6)) plt.scatter(task_spikes, task_neurons, c=\"k\", marker=\"|\", s=18) plt.title(\"Task Spike Data\") plt.xlabel(\"Time\") plt.ylabel(\"Neuron ID\") plt.show() In\u00a0[5]: Copied! <pre>post_spikes_sig, post_neurons_sig, post_sig_seq_epochs = simulate_sequential_spikes(\n    nneurons=N_NEURONS,\n    minseqduration=MIN_SEQ_DURATION,\n    maxseqduration=MAX_SEQ_DURATION,\n    duration=DURATION,\n    random=False,\n)\npost_spikes_nonsig, post_neurons_nonsig, post_nonsig_seq_epochs = (\n    simulate_sequential_spikes(\n        nneurons=N_NEURONS,\n        minseqduration=MIN_SEQ_DURATION,\n        maxseqduration=MAX_SEQ_DURATION,\n        duration=DURATION,\n        random=True,\n    )\n)\n\n# Visualize significant post-task spike data\nplt.figure(figsize=(12, 6))\nplt.scatter(post_spikes_sig, post_neurons_sig, c=\"k\", marker=\"|\", s=18)\nplt.title(\"Significant Post-Task Spike Data\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Neuron ID\")\nplt.show()\n\n# Visualize non-significant post-task spike data\nplt.figure(figsize=(12, 6))\nplt.scatter(post_spikes_nonsig, post_neurons_nonsig, c=\"k\", marker=\"|\", s=18)\nplt.title(\"Non-Significant Post-Task Spike Data\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Neuron ID\")\nplt.show()\n</pre> post_spikes_sig, post_neurons_sig, post_sig_seq_epochs = simulate_sequential_spikes(     nneurons=N_NEURONS,     minseqduration=MIN_SEQ_DURATION,     maxseqduration=MAX_SEQ_DURATION,     duration=DURATION,     random=False, ) post_spikes_nonsig, post_neurons_nonsig, post_nonsig_seq_epochs = (     simulate_sequential_spikes(         nneurons=N_NEURONS,         minseqduration=MIN_SEQ_DURATION,         maxseqduration=MAX_SEQ_DURATION,         duration=DURATION,         random=True,     ) )  # Visualize significant post-task spike data plt.figure(figsize=(12, 6)) plt.scatter(post_spikes_sig, post_neurons_sig, c=\"k\", marker=\"|\", s=18) plt.title(\"Significant Post-Task Spike Data\") plt.xlabel(\"Time\") plt.ylabel(\"Neuron ID\") plt.show()  # Visualize non-significant post-task spike data plt.figure(figsize=(12, 6)) plt.scatter(post_spikes_nonsig, post_neurons_nonsig, c=\"k\", marker=\"|\", s=18) plt.title(\"Non-Significant Post-Task Spike Data\") plt.xlabel(\"Time\") plt.ylabel(\"Neuron ID\") plt.show() In\u00a0[6]: Copied! <pre>pbias = npy.ensemble.PairwiseBias(num_shuffles=100)\n\n# Analyze significant replay\nz_score_sig, p_value_sig, cosine_val_sig = pbias.fit_transform(\n    task_spikes,\n    task_neurons,\n    task_seq_epochs,\n    post_spikes_sig,\n    post_neurons_sig,\n    post_sig_seq_epochs,\n)\n\nprint(\"Significant Replay Results:\")\nprint(f\"Z-scores: {z_score_sig}\")\nprint(f\"P-values: {p_value_sig}\")\nprint(f\"Cosine values: {cosine_val_sig}\")\n\n# Analyze non-significant replay\nz_score_nonsig, p_value_nonsig, cosine_val_nonsig = pbias.transform(\n    post_spikes_nonsig, post_neurons_nonsig, post_nonsig_seq_epochs\n)\n\nprint(\"\\nNon-significant Replay Results:\")\nprint(f\"Z-scores: {z_score_nonsig}\")\nprint(f\"P-values: {p_value_nonsig}\")\nprint(f\"Cosine values: {cosine_val_nonsig}\")\n</pre> pbias = npy.ensemble.PairwiseBias(num_shuffles=100)  # Analyze significant replay z_score_sig, p_value_sig, cosine_val_sig = pbias.fit_transform(     task_spikes,     task_neurons,     task_seq_epochs,     post_spikes_sig,     post_neurons_sig,     post_sig_seq_epochs, )  print(\"Significant Replay Results:\") print(f\"Z-scores: {z_score_sig}\") print(f\"P-values: {p_value_sig}\") print(f\"Cosine values: {cosine_val_sig}\")  # Analyze non-significant replay z_score_nonsig, p_value_nonsig, cosine_val_nonsig = pbias.transform(     post_spikes_nonsig, post_neurons_nonsig, post_nonsig_seq_epochs )  print(\"\\nNon-significant Replay Results:\") print(f\"Z-scores: {z_score_nonsig}\") print(f\"P-values: {p_value_nonsig}\") print(f\"Cosine values: {cosine_val_nonsig}\") <pre>/home/cornell/Desktop/Kushaan/neuro_py/neuro_py/ensemble/replay.py:659: RuntimeWarning: Mean of empty slice\n</pre> <pre>Significant Replay Results:\nZ-scores: [6.01136055 5.2730831  4.95141898 5.19878733 5.22794518 5.24813793]\nP-values: [0.00990099 0.00990099 0.00990099 0.00990099 0.00990099 0.00990099]\nCosine values: [0.97669051 0.98048687 0.93398034 0.97551905 0.93848145 0.93954246]\n\nNon-significant Replay Results:\nZ-scores: [-0.97897708  0.46571559  0.25575207 -1.42404218]\nP-values: [0.82178218 0.31683168 0.43564356 0.92079208]\nCosine values: [-0.14344132  0.10520735  0.03944295 -0.16070039]\n</pre> In\u00a0[7]: Copied! <pre>fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n\nax1.bar(range(len(z_score_sig)), z_score_sig, alpha=0.7, label=\"Significant\")\nax1.bar(range(len(z_score_nonsig)), z_score_nonsig, alpha=0.7, label=\"Non-significant\")\nax1.set_title(\"Z-scores\")\nax1.set_xlabel(\"Epochs\")\nax1.set_ylabel(\"Z-score\")\nax1.legend()\n\nax2.bar(range(len(p_value_sig)), p_value_sig, alpha=0.7, label=\"Significant\")\nax2.bar(range(len(p_value_nonsig)), p_value_nonsig, alpha=0.7, label=\"Non-significant\")\nax2.set_title(\"P-values\")\nax2.set_xlabel(\"Epochs\")\nax2.set_ylabel(\"P-value\")\nax2.axhline(y=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\")\nax2.legend()\n\nax3.bar(range(len(cosine_val_sig)), cosine_val_sig, alpha=0.7, label=\"Significant\")\nax3.bar(\n    range(len(cosine_val_nonsig)), cosine_val_nonsig, alpha=0.7, label=\"Non-significant\"\n)\nax3.set_title(\"Cosine Values\")\nax3.set_xlabel(\"Epochs\")\nax3.set_ylabel(\"Cosine Similarity\")\nax3.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))  ax1.bar(range(len(z_score_sig)), z_score_sig, alpha=0.7, label=\"Significant\") ax1.bar(range(len(z_score_nonsig)), z_score_nonsig, alpha=0.7, label=\"Non-significant\") ax1.set_title(\"Z-scores\") ax1.set_xlabel(\"Epochs\") ax1.set_ylabel(\"Z-score\") ax1.legend()  ax2.bar(range(len(p_value_sig)), p_value_sig, alpha=0.7, label=\"Significant\") ax2.bar(range(len(p_value_nonsig)), p_value_nonsig, alpha=0.7, label=\"Non-significant\") ax2.set_title(\"P-values\") ax2.set_xlabel(\"Epochs\") ax2.set_ylabel(\"P-value\") ax2.axhline(y=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\") ax2.legend()  ax3.bar(range(len(cosine_val_sig)), cosine_val_sig, alpha=0.7, label=\"Significant\") ax3.bar(     range(len(cosine_val_nonsig)), cosine_val_nonsig, alpha=0.7, label=\"Non-significant\" ) ax3.set_title(\"Cosine Values\") ax3.set_xlabel(\"Epochs\") ax3.set_ylabel(\"Cosine Similarity\") ax3.legend()  plt.tight_layout() plt.show() In\u00a0[8]: Copied! <pre>post_spikes_rev, post_neurons_rev, post_rev_seq_epochs = simulate_sequential_spikes(\n    nneurons=N_NEURONS,\n    minseqduration=MIN_SEQ_DURATION,\n    maxseqduration=MAX_SEQ_DURATION,\n    duration=DURATION,\n    reverseseqprob=0.5,\n    random=False,\n)\n\n# Visualize reversed post-task spike data\nplt.figure(figsize=(12, 6))\nplt.scatter(post_spikes_rev, post_neurons_rev, c=\"k\", marker=\"|\", s=18)\nplt.title(\"Reversed Post-Task Spike Data\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Neuron ID\")\nplt.show()\n</pre> post_spikes_rev, post_neurons_rev, post_rev_seq_epochs = simulate_sequential_spikes(     nneurons=N_NEURONS,     minseqduration=MIN_SEQ_DURATION,     maxseqduration=MAX_SEQ_DURATION,     duration=DURATION,     reverseseqprob=0.5,     random=False, )  # Visualize reversed post-task spike data plt.figure(figsize=(12, 6)) plt.scatter(post_spikes_rev, post_neurons_rev, c=\"k\", marker=\"|\", s=18) plt.title(\"Reversed Post-Task Spike Data\") plt.xlabel(\"Time\") plt.ylabel(\"Neuron ID\") plt.show() In\u00a0[9]: Copied! <pre>z_score_rev_nonsig, p_value_rev_nonsig, cosine_val_rev_nonsig = pbias.transform(\n    post_spikes_rev, post_neurons_rev, post_rev_seq_epochs\n)\n\nprint(\"Reversed Replay Results without permitting reverse sequences:\")\nprint(f\"Z-scores: {z_score_rev_nonsig}\")\nprint(f\"P-values: {p_value_rev_nonsig}\")\nprint(f\"Cosine values: {cosine_val_rev_nonsig}\")\n\nz_score_rev_sig, p_value_rev_sig, cosine_val_rev_sig = pbias.transform(\n    post_spikes_rev, post_neurons_rev, post_rev_seq_epochs, allow_reverse_replay=True\n)\n\nprint(\"\\nReversed Replay Results while permitting reverse sequences:\")\nprint(f\"Z-scores: {z_score_rev_sig}\")\nprint(f\"P-values: {p_value_rev_sig}\")\nprint(f\"Cosine values: {cosine_val_rev_sig}\")\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n\nax1.bar(range(len(z_score_rev_sig)), z_score_rev_sig, alpha=0.7, label=\"Permit Reverse\")\nax1.bar(\n    range(len(z_score_rev_nonsig)), z_score_rev_nonsig, alpha=0.7, label=\"No Reverse\"\n)\nax1.set_title(\"Z-scores\")\nax1.set_xlabel(\"Epochs\")\nax1.set_ylabel(\"Z-score\")\nax1.legend()\n\nax2.bar(range(len(p_value_rev_sig)), p_value_rev_sig, alpha=0.7, label=\"Permit Reverse\")\nax2.bar(\n    range(len(p_value_rev_nonsig)), p_value_rev_nonsig, alpha=0.7, label=\"No Reverse\"\n)\nax2.set_title(\"P-values\")\nax2.set_xlabel(\"Epochs\")\nax2.set_ylabel(\"P-value\")\nax2.axhline(y=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\")\nax2.legend()\n\nax3.bar(\n    range(len(cosine_val_rev_sig)),\n    cosine_val_rev_sig,\n    alpha=0.7,\n    label=\"Permit Reverse\",\n)\nax3.bar(\n    range(len(cosine_val_rev_nonsig)),\n    cosine_val_rev_nonsig,\n    alpha=0.7,\n    label=\"No Reverse\",\n)\nax3.set_title(\"Cosine Values\")\nax3.set_xlabel(\"Epochs\")\nax3.set_ylabel(\"Cosine Similarity\")\nax3.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> z_score_rev_nonsig, p_value_rev_nonsig, cosine_val_rev_nonsig = pbias.transform(     post_spikes_rev, post_neurons_rev, post_rev_seq_epochs )  print(\"Reversed Replay Results without permitting reverse sequences:\") print(f\"Z-scores: {z_score_rev_nonsig}\") print(f\"P-values: {p_value_rev_nonsig}\") print(f\"Cosine values: {cosine_val_rev_nonsig}\")  z_score_rev_sig, p_value_rev_sig, cosine_val_rev_sig = pbias.transform(     post_spikes_rev, post_neurons_rev, post_rev_seq_epochs, allow_reverse_replay=True )  print(\"\\nReversed Replay Results while permitting reverse sequences:\") print(f\"Z-scores: {z_score_rev_sig}\") print(f\"P-values: {p_value_rev_sig}\") print(f\"Cosine values: {cosine_val_rev_sig}\")  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))  ax1.bar(range(len(z_score_rev_sig)), z_score_rev_sig, alpha=0.7, label=\"Permit Reverse\") ax1.bar(     range(len(z_score_rev_nonsig)), z_score_rev_nonsig, alpha=0.7, label=\"No Reverse\" ) ax1.set_title(\"Z-scores\") ax1.set_xlabel(\"Epochs\") ax1.set_ylabel(\"Z-score\") ax1.legend()  ax2.bar(range(len(p_value_rev_sig)), p_value_rev_sig, alpha=0.7, label=\"Permit Reverse\") ax2.bar(     range(len(p_value_rev_nonsig)), p_value_rev_nonsig, alpha=0.7, label=\"No Reverse\" ) ax2.set_title(\"P-values\") ax2.set_xlabel(\"Epochs\") ax2.set_ylabel(\"P-value\") ax2.axhline(y=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\") ax2.legend()  ax3.bar(     range(len(cosine_val_rev_sig)),     cosine_val_rev_sig,     alpha=0.7,     label=\"Permit Reverse\", ) ax3.bar(     range(len(cosine_val_rev_nonsig)),     cosine_val_rev_nonsig,     alpha=0.7,     label=\"No Reverse\", ) ax3.set_title(\"Cosine Values\") ax3.set_xlabel(\"Epochs\") ax3.set_ylabel(\"Cosine Similarity\") ax3.legend()  plt.tight_layout() plt.show() <pre>Reversed Replay Results without permitting reverse sequences:\nZ-scores: [-5.30841933 -5.45090389  5.03316704 -5.58233051  5.68234554]\nP-values: [1.         1.         0.00990099 1.         0.00990099]\nCosine values: [-0.94051679 -0.99374011  0.98048687 -0.98048687  0.98048687]\n\nReversed Replay Results while permitting reverse sequences:\nZ-scores: [-4.9703529  -5.2933867   5.88903521 -6.48384634  5.22551579]\nP-values: [0.00990099 0.00990099 0.00990099 0.00990099 0.00990099]\nCosine values: [-0.94051679 -0.99374011  0.98048687 -0.98048687  0.98048687]\n</pre> In\u00a0[10]: Copied! <pre>nrn_order = np.argsort(np.nansum(pbias.task_normalized, axis=1))\nsig_swr_indices = np.where(p_value_sig &lt; 0.001)[0]\n\n\ndef plot_replay(n) -&gt; None:\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n    start, end = post_rev_seq_epochs[n]\n    start_idx = np.searchsorted(post_spikes_rev, start, side=\"left\")\n    end_idx = np.searchsorted(post_spikes_rev, end, side=\"right\")\n\n    filtered_spikes = post_spikes_rev[start_idx:end_idx]\n    filtered_neurons = post_neurons_rev[start_idx:end_idx]\n\n    im = ax1.imshow(pbias.task_normalized[nrn_order, :][:, nrn_order], cmap=\"magma\")\n    ax1.set_title(\"Template Bias Matrix\")\n    ax1.set_xlabel(\"Neuron ID (reordered by bias direction)\")\n    ax1.set_ylabel(\"Neuron ID (reordered by bias direction)\")\n    plt.colorbar(im, ax=ax1)\n\n    bias = npy.ensemble.bias_matrix_fast(\n        filtered_spikes,\n        filtered_neurons,\n        total_neurons=N_NEURONS,\n        fillneutral=0.5,\n    )\n    bias = npy.ensemble.normalize_bias_matrix(bias)\n\n    im = ax2.imshow(bias[nrn_order, :][:, nrn_order], cmap=\"magma\")\n    ax2.set_title(\"Replay Bias Matrix\")\n    ax2.set_xlabel(\"Neuron ID (reordered by bias direction)\")\n    ax2.set_ylabel(\"Neuron ID (reordered by bias direction)\")\n    plt.colorbar(im, ax=ax2)\n\n    # order spikes and neuron ids by nrn_order\n    argsort = np.asarray(\n        sorted(\n            range(len(filtered_neurons)),\n            key=lambda x: nrn_order[int(filtered_neurons[x])],\n        )\n    )\n    spike_times = filtered_spikes[argsort]\n    spike_ids = filtered_neurons[argsort]\n    # raster plot\n    ax3.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\", s=18)\n    ax3.set_title(\"Replay Raster Plot\")\n    ax3.set_xlabel(\"Time\")\n    ax3.set_ylabel(\"Neuron ID (reordered by bias direction)\")\n    plt.tight_layout()\n    plt.show()\n\n\nwidgets.interact(\n    plot_replay,\n    n=widgets.IntSlider(min=0, max=len(post_rev_seq_epochs) - 1, step=1, value=0),\n);\n</pre> nrn_order = np.argsort(np.nansum(pbias.task_normalized, axis=1)) sig_swr_indices = np.where(p_value_sig &lt; 0.001)[0]   def plot_replay(n) -&gt; None:     fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))     start, end = post_rev_seq_epochs[n]     start_idx = np.searchsorted(post_spikes_rev, start, side=\"left\")     end_idx = np.searchsorted(post_spikes_rev, end, side=\"right\")      filtered_spikes = post_spikes_rev[start_idx:end_idx]     filtered_neurons = post_neurons_rev[start_idx:end_idx]      im = ax1.imshow(pbias.task_normalized[nrn_order, :][:, nrn_order], cmap=\"magma\")     ax1.set_title(\"Template Bias Matrix\")     ax1.set_xlabel(\"Neuron ID (reordered by bias direction)\")     ax1.set_ylabel(\"Neuron ID (reordered by bias direction)\")     plt.colorbar(im, ax=ax1)      bias = npy.ensemble.bias_matrix_fast(         filtered_spikes,         filtered_neurons,         total_neurons=N_NEURONS,         fillneutral=0.5,     )     bias = npy.ensemble.normalize_bias_matrix(bias)      im = ax2.imshow(bias[nrn_order, :][:, nrn_order], cmap=\"magma\")     ax2.set_title(\"Replay Bias Matrix\")     ax2.set_xlabel(\"Neuron ID (reordered by bias direction)\")     ax2.set_ylabel(\"Neuron ID (reordered by bias direction)\")     plt.colorbar(im, ax=ax2)      # order spikes and neuron ids by nrn_order     argsort = np.asarray(         sorted(             range(len(filtered_neurons)),             key=lambda x: nrn_order[int(filtered_neurons[x])],         )     )     spike_times = filtered_spikes[argsort]     spike_ids = filtered_neurons[argsort]     # raster plot     ax3.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\", s=18)     ax3.set_title(\"Replay Raster Plot\")     ax3.set_xlabel(\"Time\")     ax3.set_ylabel(\"Neuron ID (reordered by bias direction)\")     plt.tight_layout()     plt.show()   widgets.interact(     plot_replay,     n=widgets.IntSlider(min=0, max=len(post_rev_seq_epochs) - 1, step=1, value=0), ); <pre>interactive(children=(IntSlider(value=0, description='n', max=4), Output()), _dom_classes=('widget-interact',)\u2026</pre> In\u00a0[11]: Copied! <pre>basepath = r\"/run/user/1000/gvfs/smb-share:server=132.236.112.212,share=ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"\n\nepoch_df = npy.io.load_epoch(basepath)\n# get session bounds to provide support\nsession_bounds = nel.EpochArray(\n    [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n)\n# compress repeated sleep sessions\nepoch_df = npy.session.compress_repeated_epochs(epoch_df)\nbeh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))\n\nst, cell_metrics = npy.io.load_spikes(\n    basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1\"\n)\nspike_spindices = npy.spikes.get_spindices(st.data)\n\nswr = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n\ntheta = nel.EpochArray(npy.io.load_SleepState_states(basepath)[\"THETA\"])\n\ntask_idx = npy.process.in_intervals(\n    spike_spindices.spike_times, (beh_epochs[1] &amp; theta).data\n)\n</pre> basepath = r\"/run/user/1000/gvfs/smb-share:server=132.236.112.212,share=ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"  epoch_df = npy.io.load_epoch(basepath) # get session bounds to provide support session_bounds = nel.EpochArray(     [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]] ) # compress repeated sleep sessions epoch_df = npy.session.compress_repeated_epochs(epoch_df) beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))  st, cell_metrics = npy.io.load_spikes(     basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1\" ) spike_spindices = npy.spikes.get_spindices(st.data)  swr = npy.io.load_ripples_events(basepath, return_epoch_array=True)  theta = nel.EpochArray(npy.io.load_SleepState_states(basepath)[\"THETA\"])  task_idx = npy.process.in_intervals(     spike_spindices.spike_times, (beh_epochs[1] &amp; theta).data ) In\u00a0[12]: Copied! <pre>position_df = npy.io.load_animal_behavior(basepath)\n\n# put position into a nelpy position array for ease of use\npos = nel.AnalogSignalArray(\n    data=position_df[\"x\"].values.T,\n    timestamps=position_df.timestamps.values,\n)\n\n# get outbound and inbound epochs\n(outbound_epochs, inbound_epochs) = npy.behavior.get_linear_track_lap_epochs(\n    pos.abscissa_vals, pos.data[0], newLapThreshold=20\n)\n\noutbound_epochs, inbound_epochs\n</pre> position_df = npy.io.load_animal_behavior(basepath)  # put position into a nelpy position array for ease of use pos = nel.AnalogSignalArray(     data=position_df[\"x\"].values.T,     timestamps=position_df.timestamps.values, )  # get outbound and inbound epochs (outbound_epochs, inbound_epochs) = npy.behavior.get_linear_track_lap_epochs(     pos.abscissa_vals, pos.data[0], newLapThreshold=20 )  outbound_epochs, inbound_epochs Out[12]: <pre>(&lt;EpochArray at 0x72b5fc830640: 42 epochs&gt; of length 17:07:964 minutes,\n &lt;EpochArray at 0x72b5fc830b50: 43 epochs&gt; of length 17:17:974 minutes)</pre> In\u00a0[13]: Copied! <pre>overlap = npy.process.find_intersecting_intervals(\n    swr, beh_epochs[-1], return_indices=False\n)\n\n# intervals in set 1 that completely overlap with set 2\noverlap = swr.lengths == overlap\n</pre> overlap = npy.process.find_intersecting_intervals(     swr, beh_epochs[-1], return_indices=False )  # intervals in set 1 that completely overlap with set 2 overlap = swr.lengths == overlap In\u00a0[\u00a0]: Copied! <pre>pbias = npy.ensemble.PairwiseBias(num_shuffles=100)\n\npost_swrs = [\n    swr[overlap][i] for i, length in enumerate(swr[overlap].lengths) if length &gt; 0.08\n]\npost_swrs = nel.EpochArray(\n    [ep.data for ep in post_swrs if np.sum([len(spks) &gt; 0 for spks in st[ep].data]) &gt; 4]\n)\n\n# Analyze significant replay\nz_score_sig, p_value_sig, cosine_val_sig = pbias.fit_transform(\n    spike_spindices[\"spike_times\"].values,\n    spike_spindices[\"spike_id\"].values,\n    inbound_epochs.data,\n    spike_spindices[\"spike_times\"].values,\n    spike_spindices[\"spike_id\"].values,\n    post_swrs.data,\n    allow_reverse_replay=False,\n)\n\nprint(\"Significant Replay Results:\")\nprint(f\"Z-scores: {z_score_sig}\")\nprint(f\"P-values: {p_value_sig}\")\nprint(f\"Cosine values: {cosine_val_sig}\")\n</pre> pbias = npy.ensemble.PairwiseBias(num_shuffles=100)  post_swrs = [     swr[overlap][i] for i, length in enumerate(swr[overlap].lengths) if length &gt; 0.08 ] post_swrs = nel.EpochArray(     [ep.data for ep in post_swrs if np.sum([len(spks) &gt; 0 for spks in st[ep].data]) &gt; 4] )  # Analyze significant replay z_score_sig, p_value_sig, cosine_val_sig = pbias.fit_transform(     spike_spindices[\"spike_times\"].values,     spike_spindices[\"spike_id\"].values,     inbound_epochs.data,     spike_spindices[\"spike_times\"].values,     spike_spindices[\"spike_id\"].values,     post_swrs.data,     allow_reverse_replay=False, )  print(\"Significant Replay Results:\") print(f\"Z-scores: {z_score_sig}\") print(f\"P-values: {p_value_sig}\") print(f\"Cosine values: {cosine_val_sig}\") <pre>/home/cornell/Desktop/Kushaan/neuro_py/neuro_py/ensemble/replay.py:659: RuntimeWarning: Mean of empty slice\n</pre> <pre>Significant Replay Results:\nZ-scores: [ 0.11456589  1.83435469 -1.58224202 ... -0.57006536 -0.16616777\n -0.82254613]\nP-values: [0.46534653 0.01980198 0.95049505 ... 0.7029703  0.58415842 0.82178218]\nCosine values: [-0.00167047  0.04488326 -0.02968688 ... -0.00790766 -0.0016217\n -0.01274348]\n</pre> In\u00a0[15]: Copied! <pre>fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n\nax1.hist(z_score_sig, alpha=0.7, label=\"Significant\")\n# ax1.hist(z_score_nonsig, alpha=0.7, label='Non-significant')\nax1.set_title(\"Z-scores\")\nax1.set_ylabel(\"Count\")\nax1.set_xlabel(\"Z-score\")\nax1.legend()\n\nax2.hist((p_value_sig &lt; 0.05).astype(int), alpha=0.7, label=\"Significant\")\n# ax2.hist(p_value_nonsig, alpha=0.7, label='Non-significant')\nax2.set_title(\"P-values\")\nax2.set_xlabel(\"P-value\")\nax2.set_ylabel(\"Count\")\nax2.axvline(x=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\")\nax2.legend()\n\nax3.hist(cosine_val_sig, alpha=0.7, label=\"Significant\")\nax3.set_title(\"Cosine Values\")\nax3.set_xlabel(\"Cosine Similarity\")\nax3.set_ylabel(\"Count\")\nax3.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))  ax1.hist(z_score_sig, alpha=0.7, label=\"Significant\") # ax1.hist(z_score_nonsig, alpha=0.7, label='Non-significant') ax1.set_title(\"Z-scores\") ax1.set_ylabel(\"Count\") ax1.set_xlabel(\"Z-score\") ax1.legend()  ax2.hist((p_value_sig &lt; 0.05).astype(int), alpha=0.7, label=\"Significant\") # ax2.hist(p_value_nonsig, alpha=0.7, label='Non-significant') ax2.set_title(\"P-values\") ax2.set_xlabel(\"P-value\") ax2.set_ylabel(\"Count\") ax2.axvline(x=0.05, color=\"r\", linestyle=\"--\", label=\"p=0.05\") ax2.legend()  ax3.hist(cosine_val_sig, alpha=0.7, label=\"Significant\") ax3.set_title(\"Cosine Values\") ax3.set_xlabel(\"Cosine Similarity\") ax3.set_ylabel(\"Count\") ax3.legend()  plt.tight_layout() plt.show() In\u00a0[16]: Copied! <pre>SPATIAL_BIN_SIZE = 3\nBEHAVIOR_TIME_BIN_SIZE = 0.05\nREPLAY_TIME_BIN_SIZE = 0.02\nSPEED_THRESHOLD = 3\nTUNING_CURVE_SIGMA = 1\nPLACE_CELL_MIN_SPKS = 100\nPLACE_CELL_MIN_RATE = 1\nPLACE_CELL_PEAK_MIN_RATIO = 1.5\n\nN_SHUFFLES = 100\n</pre> SPATIAL_BIN_SIZE = 3 BEHAVIOR_TIME_BIN_SIZE = 0.05 REPLAY_TIME_BIN_SIZE = 0.02 SPEED_THRESHOLD = 3 TUNING_CURVE_SIGMA = 1 PLACE_CELL_MIN_SPKS = 100 PLACE_CELL_MIN_RATE = 1 PLACE_CELL_PEAK_MIN_RATIO = 1.5  N_SHUFFLES = 100 In\u00a0[17]: Copied! <pre>def get_tuning_curves(\n    pos, st_all, dir_epoch, speed_thres, time_binsize, s_binsize, tuning_curve_sigma\n):\n    spatial_maps = npy.tuning.SpatialMap(\n        pos,\n        st_all,\n        dim=1,\n        dir_epoch=dir_epoch,\n        s_binsize=s_binsize,\n        speed_thres=speed_thres,\n        tuning_curve_sigma=tuning_curve_sigma,\n        minbgrate=0.01,  # decoding does not like 0 firing rate\n    )\n\n    # restrict spike trains to those epochs during which the animal was running\n    st_run = st_all[dir_epoch][spatial_maps.run_epochs]\n\n    # bin running:\n    bst_run = st_run.bin(ds=time_binsize)\n\n    # return class 'auxiliary.TuningCurve1D'\n    #   instead of class 'maps.SpatialMap' for decoding.py compatibility\n    return spatial_maps.tc, st_run, bst_run, spatial_maps.run_epochs\n\n\ntc, st_run, bst_run, run_epochs = get_tuning_curves(\n    pos,\n    st,\n    inbound_epochs,\n    SPEED_THRESHOLD,\n    BEHAVIOR_TIME_BIN_SIZE,\n    SPATIAL_BIN_SIZE,\n    TUNING_CURVE_SIGMA,\n)\n</pre> def get_tuning_curves(     pos, st_all, dir_epoch, speed_thres, time_binsize, s_binsize, tuning_curve_sigma ):     spatial_maps = npy.tuning.SpatialMap(         pos,         st_all,         dim=1,         dir_epoch=dir_epoch,         s_binsize=s_binsize,         speed_thres=speed_thres,         tuning_curve_sigma=tuning_curve_sigma,         minbgrate=0.01,  # decoding does not like 0 firing rate     )      # restrict spike trains to those epochs during which the animal was running     st_run = st_all[dir_epoch][spatial_maps.run_epochs]      # bin running:     bst_run = st_run.bin(ds=time_binsize)      # return class 'auxiliary.TuningCurve1D'     #   instead of class 'maps.SpatialMap' for decoding.py compatibility     return spatial_maps.tc, st_run, bst_run, spatial_maps.run_epochs   tc, st_run, bst_run, run_epochs = get_tuning_curves(     pos,     st,     inbound_epochs,     SPEED_THRESHOLD,     BEHAVIOR_TIME_BIN_SIZE,     SPATIAL_BIN_SIZE,     TUNING_CURVE_SIGMA, ) In\u00a0[18]: Copied! <pre>def restrict_to_place_cells(\n    tc,\n    st_run,\n    bst_run,\n    st_all,\n    cell_metrics,\n    place_cell_min_spks,\n    place_cell_min_rate,\n    place_cell_peak_mean_ratio,\n):\n    # locate pyr cells with &gt;= 100 spikes, peak rate &gt;= 1 Hz, peak/mean ratio &gt;=1.5\n    peak_firing_rates = tc.max(axis=1)\n    mean_firing_rates = tc.mean(axis=1)\n    ratio = peak_firing_rates / mean_firing_rates\n\n    idx = (\n        (st_run.n_events &gt;= place_cell_min_spks)\n        &amp; (tc.ratemap.max(axis=1) &gt;= place_cell_min_rate)\n        &amp; (ratio &gt;= place_cell_peak_mean_ratio)\n    )\n    unit_ids_to_keep = (np.where(idx)[0] + 1).squeeze().tolist()\n\n    sta_placecells = st_all._unit_subset(unit_ids_to_keep)\n    tc = tc._unit_subset(unit_ids_to_keep)\n    total_units = sta_placecells.n_active\n    bst_run = bst_run.loc[:, unit_ids_to_keep]\n\n    # restrict cell_metrics to place cells\n    cell_metrics_ = cell_metrics[idx]\n\n    return sta_placecells, tc, bst_run, cell_metrics_, total_units\n\n\nsta_placecells, tc, bst_run, cell_metrics_, total_units = restrict_to_place_cells(\n    tc,\n    st_run,\n    bst_run,\n    st,\n    cell_metrics,\n    PLACE_CELL_MIN_SPKS,\n    PLACE_CELL_MIN_RATE,\n    PLACE_CELL_PEAK_MIN_RATIO,\n)\n</pre> def restrict_to_place_cells(     tc,     st_run,     bst_run,     st_all,     cell_metrics,     place_cell_min_spks,     place_cell_min_rate,     place_cell_peak_mean_ratio, ):     # locate pyr cells with &gt;= 100 spikes, peak rate &gt;= 1 Hz, peak/mean ratio &gt;=1.5     peak_firing_rates = tc.max(axis=1)     mean_firing_rates = tc.mean(axis=1)     ratio = peak_firing_rates / mean_firing_rates      idx = (         (st_run.n_events &gt;= place_cell_min_spks)         &amp; (tc.ratemap.max(axis=1) &gt;= place_cell_min_rate)         &amp; (ratio &gt;= place_cell_peak_mean_ratio)     )     unit_ids_to_keep = (np.where(idx)[0] + 1).squeeze().tolist()      sta_placecells = st_all._unit_subset(unit_ids_to_keep)     tc = tc._unit_subset(unit_ids_to_keep)     total_units = sta_placecells.n_active     bst_run = bst_run.loc[:, unit_ids_to_keep]      # restrict cell_metrics to place cells     cell_metrics_ = cell_metrics[idx]      return sta_placecells, tc, bst_run, cell_metrics_, total_units   sta_placecells, tc, bst_run, cell_metrics_, total_units = restrict_to_place_cells(     tc,     st_run,     bst_run,     st,     cell_metrics,     PLACE_CELL_MIN_SPKS,     PLACE_CELL_MIN_RATE,     PLACE_CELL_PEAK_MIN_RATIO, ) In\u00a0[19]: Copied! <pre>plt.imshow(tc.reorder_units().ratemap, aspect=\"auto\", interpolation=\"none\")\nplt.colorbar()\nplt.title(\"Place Cell Tuning Curves\")\nplt.xlabel(\"Spatial Bin\")\nplt.ylabel(\"Neurons (reordered by peak rate)\")\nplt.show()\n</pre> plt.imshow(tc.reorder_units().ratemap, aspect=\"auto\", interpolation=\"none\") plt.colorbar() plt.title(\"Place Cell Tuning Curves\") plt.xlabel(\"Spatial Bin\") plt.ylabel(\"Neurons (reordered by peak rate)\") plt.show() In\u00a0[20]: Copied! <pre>def decode_and_score(bst, tc, pos):  # -&gt; tuple[float, float] | tuple[Any, Any, Any]:\n    # access decoding accuracy on behavioral time scale\n    posteriors, lengths, mode_pth, mean_pth = nel.decoding.decode1D(\n        bst, tc, xmin=np.nanmin(pos.data), xmax=np.nanmax(pos.data)\n    )\n\n    actual_pos = np.interp(bst.bin_centers, pos.abscissa_vals, pos.data[0])\n\n    bad_idx = np.isnan(actual_pos) | np.isnan(mode_pth)\n    actual_pos = actual_pos[~bad_idx]\n    mode_pth = mode_pth[~bad_idx]\n    if len(actual_pos) == 0:\n        return np.nan, np.nan\n    slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(\n        actual_pos, mode_pth\n    )\n    median_error = np.nanmedian(np.abs(actual_pos - mode_pth))\n\n    return mode_pth, rvalue, median_error\n\n\ndef pooled_incoherent_shuffle_bst(bst):\n    out = copy.deepcopy(bst)\n    data = out._data\n\n    for uu in range(bst.n_units):\n        segment = np.atleast_1d(np.squeeze(data[uu, :]))\n        segment = np.roll(segment, np.random.randint(len(segment)))\n        data[uu, :] = segment\n    out._data = data\n    return out\n\n\ndef decode_and_shuff(bst, tc, pos, n_shuffles=500):\n    \"\"\" \"\"\"\n    pos_decoded, rvalue, median_error = decode_and_score(bst, tc, pos)\n\n    if n_shuffles &gt; 0:\n        rvalue_time_swap = np.zeros((n_shuffles, 1))\n        median_error_time_swap = np.zeros((n_shuffles, 1))\n\n    for shflidx in range(n_shuffles):\n        bst_shuff = pooled_incoherent_shuffle_bst(bst)\n        _, rvalue_time_swap[shflidx], median_error_time_swap[shflidx] = (\n            decode_and_score(bst_shuff, tc, pos)\n        )\n\n    return pos_decoded, rvalue, median_error, rvalue_time_swap, median_error_time_swap\n\n\nbst_run_beh = sta_placecells[inbound_epochs][run_epochs].bin(ds=BEHAVIOR_TIME_BIN_SIZE)\npos_decoded, decoding_r2, median_error, decoding_r2_shuff, _ = decode_and_shuff(\n    bst_run_beh, tc, pos[inbound_epochs][run_epochs], n_shuffles=N_SHUFFLES\n)\n</pre> def decode_and_score(bst, tc, pos):  # -&gt; tuple[float, float] | tuple[Any, Any, Any]:     # access decoding accuracy on behavioral time scale     posteriors, lengths, mode_pth, mean_pth = nel.decoding.decode1D(         bst, tc, xmin=np.nanmin(pos.data), xmax=np.nanmax(pos.data)     )      actual_pos = np.interp(bst.bin_centers, pos.abscissa_vals, pos.data[0])      bad_idx = np.isnan(actual_pos) | np.isnan(mode_pth)     actual_pos = actual_pos[~bad_idx]     mode_pth = mode_pth[~bad_idx]     if len(actual_pos) == 0:         return np.nan, np.nan     slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(         actual_pos, mode_pth     )     median_error = np.nanmedian(np.abs(actual_pos - mode_pth))      return mode_pth, rvalue, median_error   def pooled_incoherent_shuffle_bst(bst):     out = copy.deepcopy(bst)     data = out._data      for uu in range(bst.n_units):         segment = np.atleast_1d(np.squeeze(data[uu, :]))         segment = np.roll(segment, np.random.randint(len(segment)))         data[uu, :] = segment     out._data = data     return out   def decode_and_shuff(bst, tc, pos, n_shuffles=500):     \"\"\" \"\"\"     pos_decoded, rvalue, median_error = decode_and_score(bst, tc, pos)      if n_shuffles &gt; 0:         rvalue_time_swap = np.zeros((n_shuffles, 1))         median_error_time_swap = np.zeros((n_shuffles, 1))      for shflidx in range(n_shuffles):         bst_shuff = pooled_incoherent_shuffle_bst(bst)         _, rvalue_time_swap[shflidx], median_error_time_swap[shflidx] = (             decode_and_score(bst_shuff, tc, pos)         )      return pos_decoded, rvalue, median_error, rvalue_time_swap, median_error_time_swap   bst_run_beh = sta_placecells[inbound_epochs][run_epochs].bin(ds=BEHAVIOR_TIME_BIN_SIZE) pos_decoded, decoding_r2, median_error, decoding_r2_shuff, _ = decode_and_shuff(     bst_run_beh, tc, pos[inbound_epochs][run_epochs], n_shuffles=N_SHUFFLES ) In\u00a0[21]: Copied! <pre>replay_scores = []\nfor swr_ep in post_swrs:\n    bst = sta_placecells[swr_ep].bin(ds=REPLAY_TIME_BIN_SIZE)\n\n    slope, intercept, r2values = nel.analysis.replay.linregress_bst(bst, tc)\n    replay_scores.append(r2values.item())\n</pre> replay_scores = [] for swr_ep in post_swrs:     bst = sta_placecells[swr_ep].bin(ds=REPLAY_TIME_BIN_SIZE)      slope, intercept, r2values = nel.analysis.replay.linregress_bst(bst, tc)     replay_scores.append(r2values.item()) In\u00a0[22]: Copied! <pre># correlate replay scores with p-values\nscipy.stats.spearmanr(\n    np.abs(cosine_val_sig),  # Absolute to also consider reverse sequences\n    replay_scores,\n)\n</pre> # correlate replay scores with p-values scipy.stats.spearmanr(     np.abs(cosine_val_sig),  # Absolute to also consider reverse sequences     replay_scores, ) Out[22]: <pre>SignificanceResult(statistic=0.1982981181876735, pvalue=9.404532275254252e-11)</pre> <p>Visualize the significant replay events amongst the SWR events.</p> In\u00a0[23]: Copied! <pre>nrn_order = np.argsort(np.nansum(pbias.task_normalized, axis=1))\nsig_swr_indices = np.where(p_value_sig &lt; 0.05)[0]\n\n\ndef plot_replay(n):\n    fig, axes = plt.subplots(2, 3, figsize=(11, 8))\n    swrs_sig = post_swrs[sig_swr_indices]\n    sig_swr_index = np.atleast_2d(swrs_sig[n].data)\n    bias = npy.ensemble.bias_matrix_fast(\n        spike_spindices[\n            npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n        ][\"spike_times\"].values,\n        spike_spindices[\n            npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n        ][\"spike_id\"].values,\n        total_neurons=st.n_units,\n        fillneutral=0.5,\n    )\n    bias = npy.ensemble.normalize_bias_matrix(bias)\n    cossim = npy.ensemble.cosine_similarity_matrices(pbias.task_normalized, bias)\n    print(f\"Epoch {n} Cosine Similarity: {cossim}\")\n    ax = axes[0, 0]\n    ax.imshow(pbias.task_normalized[nrn_order, :][:, nrn_order], cmap=\"magma\")\n    ax.set_title(\"Template Bias Matrix\")\n    ax.set_xlabel(\"Neurons (reordered by bias direction)\")\n    ax.set_ylabel(\"Neurons (reordered by bias direction)\")\n\n    ax = axes[0, 1]\n    ax.imshow(bias[nrn_order, :][:, nrn_order], cmap=\"magma\")\n    ax.set_title(\"Replay Bias Matrix\")\n    ax.set_xlabel(\"Neurons (reordered by bias direction)\")\n    ax.set_ylabel(\"Neurons (reordered by bias direction)\")\n\n    spike_times = spike_spindices[\n        npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n    ][\"spike_times\"].values\n    spike_ids = spike_spindices[\n        npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n    ][\"spike_id\"].values\n    # # order spikes and neuron ids by nrn_order\n    # argsort = np.asarray(sorted(range(len(spike_ids)), key=lambda x: nrn_order[int(spike_ids[x])]))\n    # spike_times = spike_times[argsort]\n    # spike_ids = spike_ids[argsort]\n    spike_id_ordermap = dict(zip(nrn_order, range(len(nrn_order))))\n    spike_ids = np.asarray(\n        [spike_id_ordermap[int(spike_id)] for spike_id in spike_ids], dtype=int\n    )\n\n    # raster plot\n    ax = axes[0, 2]\n    ax.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\", s=18)\n    ax.set_title(\"Replay Raster Plot\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Neurons (reordered by bias direction)\")\n\n    bst = sta_placecells[swrs_sig[n]].bin(ds=REPLAY_TIME_BIN_SIZE)\n\n    posteriors, lengths, mode_pth, mean_pth = nel.decoding.decode1D(\n        bst, tc, xmin=np.nanmin(pos.data), xmax=np.nanmax(pos.data)\n    )\n\n    spike_times = spike_spindices[\n        npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n    ][\"spike_times\"].values\n    spike_ids = spike_spindices[\n        npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)\n    ][\"spike_id\"].values\n    spike_id_ordermap = np.asarray(tc.get_peak_firing_order_ids()) - 1\n    spike_id_ordermap = dict(zip(spike_id_ordermap, range(len(spike_id_ordermap))))\n    # filter non-place cells\n    spike_times = np.asarray(\n        [ts for i, ts in enumerate(spike_times) if spike_ids[i] in spike_id_ordermap]\n    )\n    spike_ids = np.asarray(\n        [id for id in spike_ids if id in spike_id_ordermap], dtype=int\n    )\n    # replace spike_ids with their peak firing order\n    spike_ids = np.asarray(\n        [spike_id_ordermap[int(spike_id)] for spike_id in spike_ids], dtype=int\n    )\n\n    ax = axes[1, 0]\n    ax.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\")\n    ax.set_title(\"Replay Raster Plot\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Neurons (reordered by peak firing order)\")\n\n    stswr = st[swrs_sig[n]]\n    stswr = stswr._unit_subset(tc.get_peak_firing_order_ids())\n    stswr.reorder_units_by_ids(tc.get_peak_firing_order_ids(), inplace=True)\n\n    ax = axes[1, 1]\n    ax.plot(mode_pth, color=\"r\", label=\"Mode Path\")\n    ax.plot(mean_pth, color=\"b\", label=\"Mean Path\")\n    ax.set_title(\"Decoded Path\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Position\")\n    ax.legend()\n\n    ax = axes[1, 2]\n    ax.imshow(posteriors, aspect=\"auto\")\n    ax.set_title(\"Posterior Probability\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Position Bins\")\n\n    plt.tight_layout()\n    plt.show()\n\n\nwidgets.interact(\n    plot_replay,\n    n=widgets.IntSlider(min=0, max=len(sig_swr_indices) - 1, step=1, value=0),\n);\n</pre> nrn_order = np.argsort(np.nansum(pbias.task_normalized, axis=1)) sig_swr_indices = np.where(p_value_sig &lt; 0.05)[0]   def plot_replay(n):     fig, axes = plt.subplots(2, 3, figsize=(11, 8))     swrs_sig = post_swrs[sig_swr_indices]     sig_swr_index = np.atleast_2d(swrs_sig[n].data)     bias = npy.ensemble.bias_matrix_fast(         spike_spindices[             npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)         ][\"spike_times\"].values,         spike_spindices[             npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)         ][\"spike_id\"].values,         total_neurons=st.n_units,         fillneutral=0.5,     )     bias = npy.ensemble.normalize_bias_matrix(bias)     cossim = npy.ensemble.cosine_similarity_matrices(pbias.task_normalized, bias)     print(f\"Epoch {n} Cosine Similarity: {cossim}\")     ax = axes[0, 0]     ax.imshow(pbias.task_normalized[nrn_order, :][:, nrn_order], cmap=\"magma\")     ax.set_title(\"Template Bias Matrix\")     ax.set_xlabel(\"Neurons (reordered by bias direction)\")     ax.set_ylabel(\"Neurons (reordered by bias direction)\")      ax = axes[0, 1]     ax.imshow(bias[nrn_order, :][:, nrn_order], cmap=\"magma\")     ax.set_title(\"Replay Bias Matrix\")     ax.set_xlabel(\"Neurons (reordered by bias direction)\")     ax.set_ylabel(\"Neurons (reordered by bias direction)\")      spike_times = spike_spindices[         npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)     ][\"spike_times\"].values     spike_ids = spike_spindices[         npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)     ][\"spike_id\"].values     # # order spikes and neuron ids by nrn_order     # argsort = np.asarray(sorted(range(len(spike_ids)), key=lambda x: nrn_order[int(spike_ids[x])]))     # spike_times = spike_times[argsort]     # spike_ids = spike_ids[argsort]     spike_id_ordermap = dict(zip(nrn_order, range(len(nrn_order))))     spike_ids = np.asarray(         [spike_id_ordermap[int(spike_id)] for spike_id in spike_ids], dtype=int     )      # raster plot     ax = axes[0, 2]     ax.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\", s=18)     ax.set_title(\"Replay Raster Plot\")     ax.set_xlabel(\"Time\")     ax.set_ylabel(\"Neurons (reordered by bias direction)\")      bst = sta_placecells[swrs_sig[n]].bin(ds=REPLAY_TIME_BIN_SIZE)      posteriors, lengths, mode_pth, mean_pth = nel.decoding.decode1D(         bst, tc, xmin=np.nanmin(pos.data), xmax=np.nanmax(pos.data)     )      spike_times = spike_spindices[         npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)     ][\"spike_times\"].values     spike_ids = spike_spindices[         npy.process.in_intervals(spike_spindices.spike_times, sig_swr_index)     ][\"spike_id\"].values     spike_id_ordermap = np.asarray(tc.get_peak_firing_order_ids()) - 1     spike_id_ordermap = dict(zip(spike_id_ordermap, range(len(spike_id_ordermap))))     # filter non-place cells     spike_times = np.asarray(         [ts for i, ts in enumerate(spike_times) if spike_ids[i] in spike_id_ordermap]     )     spike_ids = np.asarray(         [id for id in spike_ids if id in spike_id_ordermap], dtype=int     )     # replace spike_ids with their peak firing order     spike_ids = np.asarray(         [spike_id_ordermap[int(spike_id)] for spike_id in spike_ids], dtype=int     )      ax = axes[1, 0]     ax.scatter(spike_times, spike_ids, c=\"k\", marker=\"|\")     ax.set_title(\"Replay Raster Plot\")     ax.set_xlabel(\"Time\")     ax.set_ylabel(\"Neurons (reordered by peak firing order)\")      stswr = st[swrs_sig[n]]     stswr = stswr._unit_subset(tc.get_peak_firing_order_ids())     stswr.reorder_units_by_ids(tc.get_peak_firing_order_ids(), inplace=True)      ax = axes[1, 1]     ax.plot(mode_pth, color=\"r\", label=\"Mode Path\")     ax.plot(mean_pth, color=\"b\", label=\"Mean Path\")     ax.set_title(\"Decoded Path\")     ax.set_xlabel(\"Time\")     ax.set_ylabel(\"Position\")     ax.legend()      ax = axes[1, 2]     ax.imshow(posteriors, aspect=\"auto\")     ax.set_title(\"Posterior Probability\")     ax.set_xlabel(\"Time\")     ax.set_ylabel(\"Position Bins\")      plt.tight_layout()     plt.show()   widgets.interact(     plot_replay,     n=widgets.IntSlider(min=0, max=len(sig_swr_indices) - 1, step=1, value=0), ); <pre>interactive(children=(IntSlider(value=0, description='n', max=96), Output()), _dom_classes=('widget-interact',\u2026</pre>"},{"location":"tutorials/bias_correlation/#pairwise-bias-correlation-analysis","title":"Pairwise Bias Correlation Analysis\u00b6","text":"<p>In this tutorial, we'll explore how to use the <code>PairwiseBias</code> class to analyze neural replay events. We'll simulate spike data for both task and post-task periods, and then use the PairwiseBias transformer to detect significant replay events.</p>"},{"location":"tutorials/bias_correlation/#setup","title":"Setup\u00b6","text":"<p>First, let's import the necessary libraries and set up our environment.</p>"},{"location":"tutorials/bias_correlation/#imports","title":"Imports\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-1-simulate-data","title":"Section 1: Simulate Data\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-11-simulating-task-spike-data-with-replay-events","title":"Section 1.1: Simulating Task Spike Data with Replay Events\u00b6","text":"<p>We'll start by simulating spike data for a task period. This will represent the original neural activity that we want to detect in replay events.</p>"},{"location":"tutorials/bias_correlation/#section-12-simulating-post-task-spike-data-with-forward-replay","title":"Section 1.2: Simulating Post-Task Spike Data with Forward Replay\u00b6","text":"<p>Now, let's simulate post-task spike data for both significant and non-significant replay scenarios, and visualize them.</p>"},{"location":"tutorials/bias_correlation/#section-2-analyzing-replay-with-pairwisebias","title":"Section 2: Analyzing Replay with PairwiseBias\u00b6","text":"<p>Now that we have our simulated data, let's use the PairwiseBias transformer to analyze replay events.</p>"},{"location":"tutorials/bias_correlation/#section-3-visualizing-results","title":"Section 3: Visualizing Results\u00b6","text":"<p>Let's create a simple visualization to compare the significant and non-significant replay results.</p> <p>Each bar represents the statistics for a single epoch of interest which may be the occurrence of a Sharp Wave Ripple (SWR) event in the hippocampal neural activity.</p>"},{"location":"tutorials/bias_correlation/#section-4-simulation-post-task-spike-data-with-both-forward-and-reverse-replays","title":"Section 4: Simulation Post-Task Spike Data with both Forward and Reverse Replays\u00b6","text":"<p>Now, let's simulate post-task spike data for both forward and reverse replay scenarios, and visualize them.</p>"},{"location":"tutorials/bias_correlation/#section-5-analyzing-sequences-in-real-data","title":"Section 5: Analyzing sequences in real data\u00b6","text":"<p>Now that we have our simulated data, let's use the PairwiseBias transformer to analyze replay in the SWR events.</p>"},{"location":"tutorials/bias_correlation/#section-51-load-the-data","title":"Section 5.1: Load the data\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-52-analyzing-forward-and-reverse-replays-in-swr-events-using-pairwisebias","title":"Section 5.2: Analyzing Forward and Reverse Replays in SWR Events using PairwiseBias\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-53-forward-and-reverse-replays-in-swr-events-using-bayesian-decoder","title":"Section 5.3: Forward and Reverse Replays in SWR Events using Bayesian Decoder\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-54-comparing-replay-detection-consistency-between-pairwisebias-and-bayesian-decoder","title":"Section 5.4: Comparing Replay Detection Consistency between PairwiseBias and Bayesian Decoder\u00b6","text":""},{"location":"tutorials/bias_correlation/#section-6-conclusion","title":"Section 6: Conclusion\u00b6","text":"<p>In this tutorial, we've demonstrated how to use the <code>PairwiseBias</code> class to analyze neural replay events. We simulated task and post-task spike data, and then used the PairwiseBias object to detect significant replay events. The results show that our method can effectively distinguish between significant and non-significant replay, as evidenced by the Z-scores and p-values. The results are also compared with Bayesian decoding to show the consistency of replay detection.</p> <p>Key observations:</p> <ol> <li>The task spike data visualization shows a clear sequential pattern across neurons.</li> <li>The significant post-task spike data maintains a similar sequential pattern, while the non-significant data appears more random.</li> <li>For significant replay, we see high Z-scores and low p-values (p &lt; 0.05).</li> <li>For non-significant replay, we see mostly lower Z-scores and higher p-values (p &gt; 0.05).</li> <li>The PairwiseBias and Bayesian decoder results show a reasonable degree of mutual consistency in replay detection.</li> </ol>"},{"location":"tutorials/decoding/","title":"Neural Decoding","text":"In\u00a0[\u00a0]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\nimport logging\nimport random\n\nimport gpytorch\nimport ipywidgets as widgets\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport nelpy as nel\nimport numpy as np\nimport pandas as pd\nimport ratinabox as rbx\nimport sklearn\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\n\nimport neuro_py as npy\n\n# Disable logging\nlogger = logging.getLogger()\nlogger.disabled = True\n</pre> %reload_ext autoreload %autoreload 2 import logging import random  import gpytorch import ipywidgets as widgets import matplotlib as mpl import matplotlib.pyplot as plt import nelpy as nel import numpy as np import pandas as pd import ratinabox as rbx import sklearn import torch import torch.nn.functional as F from torch import nn  import neuro_py as npy  # Disable logging logger = logging.getLogger() logger.disabled = True In\u00a0[2]: Copied! <pre>def set_seed(seed=None, seed_torch=True):\n    if seed is None:\n        seed = np.random.choice(2**32 - 1)\n    random.seed(seed)\n    np.random.seed(seed)\n    if seed_torch:\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = True\n\n    print(f\"Random seed {seed} has been set.\")\n    return seed\n\n\ndef set_device():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    if device != \"cuda\":\n        print(\"GPU is not enabled.\")\n    else:\n        print(\"GPU is enabled.\")\n\n    return device\n\n\nSEED = set_seed(2025)\nDEVICE = set_device()\ntorch.set_float32_matmul_precision('medium')\n</pre> def set_seed(seed=None, seed_torch=True):     if seed is None:         seed = np.random.choice(2**32 - 1)     random.seed(seed)     np.random.seed(seed)     if seed_torch:         torch.manual_seed(seed)         torch.cuda.manual_seed_all(seed)         torch.cuda.manual_seed(seed)         torch.backends.cudnn.benchmark = True         torch.backends.cudnn.deterministic = True      print(f\"Random seed {seed} has been set.\")     return seed   def set_device():     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"     if device != \"cuda\":         print(\"GPU is not enabled.\")     else:         print(\"GPU is enabled.\")      return device   SEED = set_seed(2025) DEVICE = set_device() torch.set_float32_matmul_precision('medium') <pre>Random seed 2025 has been set.\nGPU is enabled.\n</pre> In\u00a0[\u00a0]: Copied! <pre># @title Helper Functions\n\ndef create_cheeseboard_maze(\n    radius=6.8, nrewards=3, nwellsonaxis=17, nseparationunits=4\n):\n    \"\"\"\n    Creates a cheeseboard-inspired maze using RatInABox with a circular environment\n    and a grid of navigable positions.\n    \"\"\"\n    # make a bulb shaped boundary\n    environment = rbx.Environment(\n        params=dict(\n            boundary=[\n                [0.5 * np.cos(t), 0.5 * np.sin(t)]\n                for t in np.linspace(0, 2 * np.pi, 100)\n            ],\n            boundary_conditions=\"solid\",\n            dimensionality=\"2D\",\n        )\n    )\n\n    # Generate the grid of positions\n    x = np.linspace(-radius * 1.03, radius * 1.03, nwellsonaxis)\n    y = np.linspace(-radius * 1.03, radius * 1.03, nwellsonaxis)\n    X, Y = np.meshgrid(x, y)\n    grid_positions = np.vstack([X.flatten(), Y.flatten()]).T\n    separationunit = np.sqrt((x[1] - x[0]) ** 2 + (y[1] - y[0]) ** 2)\n\n    # Filter positions to stay within the circle\n    circle_mask = (X**2 + Y**2) &lt;= radius**2\n    grid_positions_within_circle = grid_positions[circle_mask.flatten()]\n\n    # Randomly pick 3 points with a minimum separation\n    def pick_random_points(points, num_points=3, min_dist=4):\n        chosen_points = []\n        chosen_points_indices = []\n        while len(chosen_points) &lt; num_points:\n            candidate_idx = np.random.choice(len(points))\n            candidate = points[candidate_idx]\n            if all(np.linalg.norm(candidate - p) &gt;= min_dist for p in chosen_points):\n                chosen_points.append(candidate)\n                chosen_points_indices.append(candidate_idx)\n        return np.array(chosen_points_indices)\n\n    reward_indices = pick_random_points(\n        grid_positions_within_circle,\n        num_points=nrewards,\n        min_dist=separationunit * nseparationunits,\n    )\n\n    # add wells\n    for i, gp in enumerate(grid_positions_within_circle):\n        environment.add_object(gp / (radius * 2))\n\n    return environment, reward_indices\n\n# Plotting\ndef visualize_predicted_trial(\n    trial: int,\n    actual_trials: list,\n    predictions: dict,\n    environment=None,\n    reward_indices=None,\n    figsize: tuple = (15, 5),\n    coord_labels: tuple = (\"X\", \"Y\"),\n    alpha: float = 0.8,\n):\n    \"\"\"\n    Visualize decoding performance for a single trial with arbitrary number of decoders.\n    \n    Parameters\n    ----------\n    trial : int\n        Trial index to visualize.\n    actual_trials : list\n        List of actual position arrays, one per trial.\n    predictions : dict\n        Dictionary mapping decoder names to their prediction arrays.\n        Example: {\"Ridge\": ridge_preds, \"MLP\": mlp_preds, \"GP\": gp_preds}\n    environment : optional\n        RatInABox environment object for plotting maze structure.\n    reward_indices : optional\n        Indices of reward locations to plot.\n    figsize : tuple, optional\n        Figure size, by default (15, 5).\n    coord_labels : tuple, optional\n        Labels for coordinates, by default (\"X\", \"Y\").\n    alpha : float, optional\n        Alpha value for prediction lines, by default 0.8.\n    \n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The generated figure.\n    \"\"\"\n    n_coords = actual_trials[trial].shape[1]\n    \n    fig = plt.figure(figsize=figsize)\n    nrows, ncols = n_coords, 4\n    gs = mpl.gridspec.GridSpec(nrows, ncols, figure=fig)\n    \n    # Plot each coordinate over time\n    for coord_idx in range(n_coords):\n        ax = fig.add_subplot(gs[coord_idx, 0:2])\n        ax.plot(\n            actual_trials[trial][:, coord_idx],\n            label=f\"Actual {coord_labels[coord_idx]}-Position\",\n            color=\"black\",\n            linewidth=1.5,\n        )\n        for decoder_name, preds_trials in predictions.items():\n            ax.plot(\n                preds_trials[trial][:, coord_idx],\n                label=f\"{decoder_name} Predicted\",\n                alpha=alpha,\n            )\n        ax.set_ylabel(f\"{coord_labels[coord_idx]}-Coordinate\")\n        ax.set_title(f\"Decoding Performance ({coord_labels[coord_idx]}-Coordinate)\")\n        if coord_idx == n_coords - 1:\n            ax.set_xlabel(\"Time Step\")\n        ax.legend(loc=\"best\", fontsize=\"small\")\n    \n    # Plot 2D trajectory with environment\n    ax = fig.add_subplot(gs[:, 2:])\n    if environment is not None:\n        environment.plot_environment(fig, ax=ax)\n    ax.plot(*actual_trials[trial].T, label=\"Actual\", color=\"black\", linewidth=1.5)\n    for decoder_name, preds_trials in predictions.items():\n        ax.plot(*preds_trials[trial].T, label=f\"{decoder_name} Predicted\", alpha=alpha)\n    \n    # Plot rewards if provided\n    if reward_indices is not None and environment is not None:\n        ax.plot(*environment.objects[\"objects\"][reward_indices].T, \"ko\", label=\"Reward\")\n    \n    ax.set_xlabel(coord_labels[0].lower())\n    ax.set_ylabel(coord_labels[1].lower())\n    ax.set_title(\"Trajectory\")\n    ax.legend(loc=\"best\", fontsize=\"small\")\n    \n    plt.tight_layout()\n    return fig\n\n# GPyTorch model for multi-output GP regression (GPU/CPU parallelized)\nclass MultitaskGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood, num_tasks):\n        super().__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.MultitaskMean(\n            gpytorch.means.ConstantMean(), num_tasks=num_tasks\n        )\n        self.covar_module = gpytorch.kernels.MultitaskKernel(\n            gpytorch.kernels.RBFKernel(), num_tasks=num_tasks, rank=1\n        )\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n\ndef train_gp_decoder(\n    train_neural: pd.DataFrame,\n    train_trajectory: pd.DataFrame,\n    test_neural: pd.DataFrame,\n    test_trajectory: pd.DataFrame,\n    n_iter: int = 50,\n    lr: float = 0.1,\n    device: str = DEVICE,\n) -&gt; tuple:\n    \"\"\"\n    Train a Gaussian Process decoder for neural trajectory prediction.\n\n    Parameters\n    ----------\n    train_neural : pd.DataFrame or np.ndarray\n        Training neural data (n_samples, n_neurons)\n    train_trajectory : pd.DataFrame or np.ndarray\n        Training trajectory data (n_samples, n_dims)\n    test_neural : pd.DataFrame or np.ndarray\n        Test neural data\n    test_trajectory : pd.DataFrame or np.ndarray\n        Test trajectory data\n    n_iter : int, optional\n        Number of training iterations, by default 50\n    lr : float, optional\n        Learning rate, by default 0.1\n    device : str, optional\n        Device to use ('cuda' or 'cpu'), by default DEVICE\n    use_lightning : bool, optional\n        Whether to use PyTorch Lightning for training, by default True\n\n    Returns\n    -------\n    tuple\n        (predictions, r2_score, model) - predictions on test set, R\u00b2 score, and trained model\n    \"\"\"\n    # Convert data to torch tensors\n    # check if train_neural is dataframe\n    train_x = torch.tensor(\n        (train_neural if not isinstance(train_neural, pd.DataFrame)\n         else train_neural.values), dtype=torch.float32)\n    train_y = torch.tensor(\n        (train_trajectory if not isinstance(train_trajectory, pd.DataFrame)\n         else train_trajectory.values), dtype=torch.float32)\n    test_x = torch.tensor(\n        (test_neural if not isinstance(test_neural, pd.DataFrame)\n         else test_neural.values), dtype=torch.float32)\n    test_y = torch.tensor(\n        (test_trajectory if not isinstance(test_trajectory, pd.DataFrame)\n         else test_trajectory.values), dtype=torch.float32)\n\n    num_tasks = train_y.shape[1]  # Number of output dimensions\n\n    # Manual training loop (faster, no progress bar)\n    train_x = train_x.to(device)\n    train_y = train_y.to(device)\n    test_x = test_x.to(device)\n\n    # Initialize model\n    likelihood_gp = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks).to(device)\n    model_gp = MultitaskGPModel(train_x, train_y, likelihood_gp, num_tasks).to(device)\n\n    # Training mode\n    model_gp.train()\n    likelihood_gp.train()\n\n    # Optimizer\n    optimizer = torch.optim.Adam(model_gp.parameters(), lr=lr)\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_gp, model_gp)\n\n    # Training loop\n    for i in range(n_iter):\n        optimizer.zero_grad()\n        output = model_gp(train_x)\n        loss = -mll(output, train_y)\n        loss.backward()\n        optimizer.step()\n        if (i + 1) % 10 == 0:\n            print(f\"Iter {i+1}/{n_iter} - Loss: {loss.item():.3f}\")\n\n    # Evaluation\n    model_gp.eval()\n    likelihood_gp.eval()\n\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n        predictions = likelihood_gp(model_gp(test_x))\n        pred_mean = predictions.mean.cpu().numpy()\n\n    model = (model_gp, likelihood_gp)\n\n    # Calculate R\u00b2 score\n    r2 = sklearn.metrics.r2_score(\n        (test_trajectory if not isinstance(test_trajectory, pd.DataFrame)\n         else test_trajectory.values),\n        pred_mean\n    )\n    \n    return pred_mean, r2, model\n\n# Widgets\ndef create_trial_visualization_widget(\n    actual_trials: list,\n    predictions: dict,\n):\n    \"\"\"\n    Create an interactive widget for visualizing decoding performance across trials.\n\n    Parameters\n    ----------\n    actual_trials : list\n        List of actual position arrays, one per trial.\n    predictions : dict\n        Dictionary mapping decoder names to their prediction arrays.\n        Example: {\"Ridge\": ridge_preds_trials, \"MLP\": mlp_preds_trials}\n\n    Returns\n    -------\n    widget : ipywidgets.interactive\n        Interactive widget for trial visualization.\n    \"\"\"\n    n_trials = len(actual_trials)\n\n    def _visualize(trial=0):\n        fig = visualize_predicted_trial(\n            trial=trial,\n            actual_trials=actual_trials,\n            predictions=predictions,\n        )\n        plt.show()\n\n    return widgets.interact(_visualize, trial=(0, n_trials - 1, 1))\n</pre> # @title Helper Functions  def create_cheeseboard_maze(     radius=6.8, nrewards=3, nwellsonaxis=17, nseparationunits=4 ):     \"\"\"     Creates a cheeseboard-inspired maze using RatInABox with a circular environment     and a grid of navigable positions.     \"\"\"     # make a bulb shaped boundary     environment = rbx.Environment(         params=dict(             boundary=[                 [0.5 * np.cos(t), 0.5 * np.sin(t)]                 for t in np.linspace(0, 2 * np.pi, 100)             ],             boundary_conditions=\"solid\",             dimensionality=\"2D\",         )     )      # Generate the grid of positions     x = np.linspace(-radius * 1.03, radius * 1.03, nwellsonaxis)     y = np.linspace(-radius * 1.03, radius * 1.03, nwellsonaxis)     X, Y = np.meshgrid(x, y)     grid_positions = np.vstack([X.flatten(), Y.flatten()]).T     separationunit = np.sqrt((x[1] - x[0]) ** 2 + (y[1] - y[0]) ** 2)      # Filter positions to stay within the circle     circle_mask = (X**2 + Y**2) &lt;= radius**2     grid_positions_within_circle = grid_positions[circle_mask.flatten()]      # Randomly pick 3 points with a minimum separation     def pick_random_points(points, num_points=3, min_dist=4):         chosen_points = []         chosen_points_indices = []         while len(chosen_points) &lt; num_points:             candidate_idx = np.random.choice(len(points))             candidate = points[candidate_idx]             if all(np.linalg.norm(candidate - p) &gt;= min_dist for p in chosen_points):                 chosen_points.append(candidate)                 chosen_points_indices.append(candidate_idx)         return np.array(chosen_points_indices)      reward_indices = pick_random_points(         grid_positions_within_circle,         num_points=nrewards,         min_dist=separationunit * nseparationunits,     )      # add wells     for i, gp in enumerate(grid_positions_within_circle):         environment.add_object(gp / (radius * 2))      return environment, reward_indices  # Plotting def visualize_predicted_trial(     trial: int,     actual_trials: list,     predictions: dict,     environment=None,     reward_indices=None,     figsize: tuple = (15, 5),     coord_labels: tuple = (\"X\", \"Y\"),     alpha: float = 0.8, ):     \"\"\"     Visualize decoding performance for a single trial with arbitrary number of decoders.          Parameters     ----------     trial : int         Trial index to visualize.     actual_trials : list         List of actual position arrays, one per trial.     predictions : dict         Dictionary mapping decoder names to their prediction arrays.         Example: {\"Ridge\": ridge_preds, \"MLP\": mlp_preds, \"GP\": gp_preds}     environment : optional         RatInABox environment object for plotting maze structure.     reward_indices : optional         Indices of reward locations to plot.     figsize : tuple, optional         Figure size, by default (15, 5).     coord_labels : tuple, optional         Labels for coordinates, by default (\"X\", \"Y\").     alpha : float, optional         Alpha value for prediction lines, by default 0.8.          Returns     -------     fig : matplotlib.figure.Figure         The generated figure.     \"\"\"     n_coords = actual_trials[trial].shape[1]          fig = plt.figure(figsize=figsize)     nrows, ncols = n_coords, 4     gs = mpl.gridspec.GridSpec(nrows, ncols, figure=fig)          # Plot each coordinate over time     for coord_idx in range(n_coords):         ax = fig.add_subplot(gs[coord_idx, 0:2])         ax.plot(             actual_trials[trial][:, coord_idx],             label=f\"Actual {coord_labels[coord_idx]}-Position\",             color=\"black\",             linewidth=1.5,         )         for decoder_name, preds_trials in predictions.items():             ax.plot(                 preds_trials[trial][:, coord_idx],                 label=f\"{decoder_name} Predicted\",                 alpha=alpha,             )         ax.set_ylabel(f\"{coord_labels[coord_idx]}-Coordinate\")         ax.set_title(f\"Decoding Performance ({coord_labels[coord_idx]}-Coordinate)\")         if coord_idx == n_coords - 1:             ax.set_xlabel(\"Time Step\")         ax.legend(loc=\"best\", fontsize=\"small\")          # Plot 2D trajectory with environment     ax = fig.add_subplot(gs[:, 2:])     if environment is not None:         environment.plot_environment(fig, ax=ax)     ax.plot(*actual_trials[trial].T, label=\"Actual\", color=\"black\", linewidth=1.5)     for decoder_name, preds_trials in predictions.items():         ax.plot(*preds_trials[trial].T, label=f\"{decoder_name} Predicted\", alpha=alpha)          # Plot rewards if provided     if reward_indices is not None and environment is not None:         ax.plot(*environment.objects[\"objects\"][reward_indices].T, \"ko\", label=\"Reward\")          ax.set_xlabel(coord_labels[0].lower())     ax.set_ylabel(coord_labels[1].lower())     ax.set_title(\"Trajectory\")     ax.legend(loc=\"best\", fontsize=\"small\")          plt.tight_layout()     return fig  # GPyTorch model for multi-output GP regression (GPU/CPU parallelized) class MultitaskGPModel(gpytorch.models.ExactGP):     def __init__(self, train_x, train_y, likelihood, num_tasks):         super().__init__(train_x, train_y, likelihood)         self.mean_module = gpytorch.means.MultitaskMean(             gpytorch.means.ConstantMean(), num_tasks=num_tasks         )         self.covar_module = gpytorch.kernels.MultitaskKernel(             gpytorch.kernels.RBFKernel(), num_tasks=num_tasks, rank=1         )      def forward(self, x):         mean_x = self.mean_module(x)         covar_x = self.covar_module(x)         return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)  def train_gp_decoder(     train_neural: pd.DataFrame,     train_trajectory: pd.DataFrame,     test_neural: pd.DataFrame,     test_trajectory: pd.DataFrame,     n_iter: int = 50,     lr: float = 0.1,     device: str = DEVICE, ) -&gt; tuple:     \"\"\"     Train a Gaussian Process decoder for neural trajectory prediction.      Parameters     ----------     train_neural : pd.DataFrame or np.ndarray         Training neural data (n_samples, n_neurons)     train_trajectory : pd.DataFrame or np.ndarray         Training trajectory data (n_samples, n_dims)     test_neural : pd.DataFrame or np.ndarray         Test neural data     test_trajectory : pd.DataFrame or np.ndarray         Test trajectory data     n_iter : int, optional         Number of training iterations, by default 50     lr : float, optional         Learning rate, by default 0.1     device : str, optional         Device to use ('cuda' or 'cpu'), by default DEVICE     use_lightning : bool, optional         Whether to use PyTorch Lightning for training, by default True      Returns     -------     tuple         (predictions, r2_score, model) - predictions on test set, R\u00b2 score, and trained model     \"\"\"     # Convert data to torch tensors     # check if train_neural is dataframe     train_x = torch.tensor(         (train_neural if not isinstance(train_neural, pd.DataFrame)          else train_neural.values), dtype=torch.float32)     train_y = torch.tensor(         (train_trajectory if not isinstance(train_trajectory, pd.DataFrame)          else train_trajectory.values), dtype=torch.float32)     test_x = torch.tensor(         (test_neural if not isinstance(test_neural, pd.DataFrame)          else test_neural.values), dtype=torch.float32)     test_y = torch.tensor(         (test_trajectory if not isinstance(test_trajectory, pd.DataFrame)          else test_trajectory.values), dtype=torch.float32)      num_tasks = train_y.shape[1]  # Number of output dimensions      # Manual training loop (faster, no progress bar)     train_x = train_x.to(device)     train_y = train_y.to(device)     test_x = test_x.to(device)      # Initialize model     likelihood_gp = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks).to(device)     model_gp = MultitaskGPModel(train_x, train_y, likelihood_gp, num_tasks).to(device)      # Training mode     model_gp.train()     likelihood_gp.train()      # Optimizer     optimizer = torch.optim.Adam(model_gp.parameters(), lr=lr)     mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_gp, model_gp)      # Training loop     for i in range(n_iter):         optimizer.zero_grad()         output = model_gp(train_x)         loss = -mll(output, train_y)         loss.backward()         optimizer.step()         if (i + 1) % 10 == 0:             print(f\"Iter {i+1}/{n_iter} - Loss: {loss.item():.3f}\")      # Evaluation     model_gp.eval()     likelihood_gp.eval()      with torch.no_grad(), gpytorch.settings.fast_pred_var():         predictions = likelihood_gp(model_gp(test_x))         pred_mean = predictions.mean.cpu().numpy()      model = (model_gp, likelihood_gp)      # Calculate R\u00b2 score     r2 = sklearn.metrics.r2_score(         (test_trajectory if not isinstance(test_trajectory, pd.DataFrame)          else test_trajectory.values),         pred_mean     )          return pred_mean, r2, model  # Widgets def create_trial_visualization_widget(     actual_trials: list,     predictions: dict, ):     \"\"\"     Create an interactive widget for visualizing decoding performance across trials.      Parameters     ----------     actual_trials : list         List of actual position arrays, one per trial.     predictions : dict         Dictionary mapping decoder names to their prediction arrays.         Example: {\"Ridge\": ridge_preds_trials, \"MLP\": mlp_preds_trials}      Returns     -------     widget : ipywidgets.interactive         Interactive widget for trial visualization.     \"\"\"     n_trials = len(actual_trials)      def _visualize(trial=0):         fig = visualize_predicted_trial(             trial=trial,             actual_trials=actual_trials,             predictions=predictions,         )         plt.show()      return widgets.interact(_visualize, trial=(0, n_trials - 1, 1)) In\u00a0[4]: Copied! <pre>environment, reward_indices = create_cheeseboard_maze()\n</pre> environment, reward_indices = create_cheeseboard_maze() In\u00a0[5]: Copied! <pre>agent = rbx.Agent(environment)\n\nN_NEURONS = 10\nTIME = 10\nbins = int(TIME * 60 / agent.dt)\nplacecells = rbx.PlaceCells(\n    agent,\n    params=dict(\n        description=\"gaussian_threshold\",\n        widths=0.3,\n        n=N_NEURONS,\n        color=\"C1\",\n        wall_geometry=\"line_of_sight\",\n    ),\n)\n\n# simulate the agent in the maze\nfor i in range(bins):\n    agent.update()\n    placecells.update()\n\nagent.plot_trajectory();\nprint(f\"Reward Indices: {reward_indices}\")\nprint(f'Number of time bins: {bins}')\n</pre> agent = rbx.Agent(environment)  N_NEURONS = 10 TIME = 10 bins = int(TIME * 60 / agent.dt) placecells = rbx.PlaceCells(     agent,     params=dict(         description=\"gaussian_threshold\",         widths=0.3,         n=N_NEURONS,         color=\"C1\",         wall_geometry=\"line_of_sight\",     ), )  # simulate the agent in the maze for i in range(bins):     agent.update()     placecells.update()  agent.plot_trajectory(); print(f\"Reward Indices: {reward_indices}\") print(f'Number of time bins: {bins}') <pre>WARNING: This figure has not been saved.\n    \u2022 To AUTOMATICALLY save all plots (recommended), set  `ratinabox.autosave_plots = True`\n    \u2022 To MANUALLY save plots, call                        `ratinabox.utils.save_figure(figure_object, save_title).\n      This warning will not be shown again\nHINT: You can stylize plots to make them look like repo/paper by calling `ratinabox.stylize_plots()`\n      This hint will not be shown again\nReward Indices: [ 62 140 160]\nNumber of time bins: 12000\n</pre> In\u00a0[6]: Copied! <pre>fig, ax = placecells.plot_rate_map(chosen_neurons=\"all\")\n</pre> fig, ax = placecells.plot_rate_map(chosen_neurons=\"all\") In\u00a0[7]: Copied! <pre>placecells.plot_rate_map(method=\"history\");\n</pre> placecells.plot_rate_map(method=\"history\"); In\u00a0[8]: Copied! <pre>t_start = 0.0  # seconds\nt_end = None\nt = np.array(placecells.history[\"t\"])\ni_start = 0 if t_start is None else np.argmin(np.abs(t - t_start))\ni_end = None if t_end is None else np.argmin(np.abs(t - t_end))\nt = t[i_start:i_end]  # subsample data for training (most of it is redundant anyway)\nneural_data = np.array(placecells.history[\"firingrate\"])[i_start:i_end]\ntrajectory = np.array(placecells.Agent.history[\"pos\"])[i_start:i_end]\n</pre> t_start = 0.0  # seconds t_end = None t = np.array(placecells.history[\"t\"]) i_start = 0 if t_start is None else np.argmin(np.abs(t - t_start)) i_end = None if t_end is None else np.argmin(np.abs(t - t_end)) t = t[i_start:i_end]  # subsample data for training (most of it is redundant anyway) neural_data = np.array(placecells.history[\"firingrate\"])[i_start:i_end] trajectory = np.array(placecells.Agent.history[\"pos\"])[i_start:i_end] <p>Format the neural data and behavioral variables (here, position) for decoding:</p> In\u00a0[9]: Copied! <pre># Convert neural data and trajectory into training format\nneural_data_df = pd.DataFrame(neural_data)  # Neural data as DataFrame\npredict_bv = [\"x\", \"y\"]\ntrajectory_df = pd.DataFrame(trajectory, columns=predict_bv)  # Positions\n\n# Split into training and testing sets (e.g., 80% train, 20% test)\nsplit_idx = int(0.8 * len(neural_data_df))\ntrain_neural, test_neural = neural_data_df[:split_idx], neural_data_df[split_idx:]\ntrain_trajectory, test_trajectory = trajectory_df[:split_idx], trajectory_df[split_idx:]\n</pre> # Convert neural data and trajectory into training format neural_data_df = pd.DataFrame(neural_data)  # Neural data as DataFrame predict_bv = [\"x\", \"y\"] trajectory_df = pd.DataFrame(trajectory, columns=predict_bv)  # Positions  # Split into training and testing sets (e.g., 80% train, 20% test) split_idx = int(0.8 * len(neural_data_df)) train_neural, test_neural = neural_data_df[:split_idx], neural_data_df[split_idx:] train_trajectory, test_trajectory = trajectory_df[:split_idx], trajectory_df[split_idx:] In\u00a0[10]: Copied! <pre>trajectory = nel.AnalogSignalArray(trajectory_df.values.T, abscissa_vals=t)\nspeed = nel.utils.ddt_asa(trajectory, smooth=True, sigma=0.250, norm=True)\ntrajectory, speed\n</pre> trajectory = nel.AnalogSignalArray(trajectory_df.values.T, abscissa_vals=t) speed = nel.utils.ddt_asa(trajectory, smooth=True, sigma=0.250, norm=True) trajectory, speed Out[10]: <pre>(&lt;AnalogSignalArray at 0x7f8f74348c20: 2 signals&gt; for a total of 10:00 minutes,\n &lt;AnalogSignalArray at 0x7f8f6c76d370: 1 signals&gt; for a total of 10:00 minutes)</pre> In\u00a0[11]: Copied! <pre>plt.imshow(neural_data_df.T, aspect=\"auto\", cmap=\"inferno\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Neuron\")\nplt.title(\"Firing Rates of Place Cells\")\nplt.colorbar(label=\"Firing Rate (Hz)\")\nplt.show()\n</pre> plt.imshow(neural_data_df.T, aspect=\"auto\", cmap=\"inferno\") plt.xlabel(\"Time (s)\") plt.ylabel(\"Neuron\") plt.title(\"Firing Rates of Place Cells\") plt.colorbar(label=\"Firing Rate (Hz)\") plt.show() In\u00a0[12]: Copied! <pre>ridge = sklearn.linear_model.Ridge(alpha=0.01)\nridge.fit(train_neural, train_trajectory)\nridge.score(test_neural, test_trajectory)\n</pre> ridge = sklearn.linear_model.Ridge(alpha=0.01) ridge.fit(train_neural, train_trajectory) ridge.score(test_neural, test_trajectory) Out[12]: <pre>0.7261317318346573</pre> In\u00a0[13]: Copied! <pre># Train GP decoder using Lightning\npred_mean_gp, r2_gp, gp_model = train_gp_decoder(\n    train_neural, train_trajectory, test_neural, test_trajectory,\n    n_iter=50, lr=0.1, device=DEVICE\n)\n\nprint(f\"GP R\u00b2 Score: {r2_gp:.4f}\")\n</pre> # Train GP decoder using Lightning pred_mean_gp, r2_gp, gp_model = train_gp_decoder(     train_neural, train_trajectory, test_neural, test_trajectory,     n_iter=50, lr=0.1, device=DEVICE )  print(f\"GP R\u00b2 Score: {r2_gp:.4f}\") <pre>Iter 10/50 - Loss: 0.737\nIter 20/50 - Loss: 0.285\nIter 30/50 - Loss: -0.201\nIter 40/50 - Loss: -0.685\nIter 50/50 - Loss: -1.116\nGP R\u00b2 Score: 0.8801\n</pre> In\u00a0[14]: Copied! <pre>tc = npy.tuning.SpatialMap(  # training on all data for Bayesian decoder\n    trajectory,\n    nel.AnalogSignalArray(neural_data_df.values.T, abscissa_vals=t),\n    s_binsize=0.0075,\n    speed=speed,\n    speed_thres=0.01,\n    tuning_curve_sigma=0.2,\n    place_field_min_size=0.2,\n    place_field_max_size=100,\n    place_field_sigma=0.2,\n)\n\nposterior_prob = npy.ensemble.decoding.bayesian.decode(\n    test_neural.values,  # (n_timebins, n_neurons)\n    tc.ratemap.T,\n    tc.occupancy.T,\n    agent.dt,\n    uniform_prior=True,\n)\ntest_pred_bayesian = npy.ensemble.position_estimator(\n    posterior_prob,\n    tc.ybin_centers,\n    tc.xbin_centers,\n    method=\"com\",\n)\n\n\nsklearn.metrics.r2_score(\n    test_trajectory.values,  # (n_timebins, 2)\n    test_pred_bayesian,\n)\n</pre> tc = npy.tuning.SpatialMap(  # training on all data for Bayesian decoder     trajectory,     nel.AnalogSignalArray(neural_data_df.values.T, abscissa_vals=t),     s_binsize=0.0075,     speed=speed,     speed_thres=0.01,     tuning_curve_sigma=0.2,     place_field_min_size=0.2,     place_field_max_size=100,     place_field_sigma=0.2, )  posterior_prob = npy.ensemble.decoding.bayesian.decode(     test_neural.values,  # (n_timebins, n_neurons)     tc.ratemap.T,     tc.occupancy.T,     agent.dt,     uniform_prior=True, ) test_pred_bayesian = npy.ensemble.position_estimator(     posterior_prob,     tc.ybin_centers,     tc.xbin_centers,     method=\"com\", )   sklearn.metrics.r2_score(     test_trajectory.values,  # (n_timebins, 2)     test_pred_bayesian, ) Out[14]: <pre>0.7297538745740977</pre> In\u00a0[15]: Copied! <pre>help(npy.ensemble.decoding.train_model)\n</pre> help(npy.ensemble.decoding.train_model) <pre>Help on function train_model in module neuro_py.ensemble.decoding.pipeline:\n\ntrain_model(partitions: List[Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]], hyperparams: Dict[str, Any], resultspath: Optional[str] = None, stop_partition: Optional[int] = None) -&gt; Tuple[List[numpy.ndarray], List[Any], List[Dict[str, Any]], Dict[str, List[float]]]\n    Train a DNN model on the given data partitions with in-built caching &amp; checkpointing.\n\n    Parameters\n    ----------\n    partitions : List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n        K-fold partitions of the data with the following format:\n        [(nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test), ...]\n        Each element of the list is a tuple of numpy arrays containing the with\n        pairs of neural state vectors and behavioral variables for the training,\n        validation, and test sets. Each array has the shape\n        (ntrials, nbins, nfeats) where nfeats is the number of neurons for the\n        neural state vectors and number of behavioral features to be predicted\n        for the behavioral variables.\n    hyperparams : Dict[str, Any]\n        Dictionary containing the hyperparameters for the model training.\n    resultspath : Optional[str], default=None\n        Path to the directory where the trained models and logs will be saved.\n    stop_partition : Optional[int], default=None\n        Index of the partition to stop training at. Only useful for debugging,\n        by default None\n\n    Returns\n    -------\n    tuple\n        Tuple containing the predicted behavioral variables for each fold,\n        the trained models for each fold, the normalization parameters for each\n        fold, and the evaluation metrics for each fold.\n\n    Notes\n    -----\n    The hyperparameters dictionary should contain the following keys:\n    - `model`: str, the type of the model to be trained. Multi-layer\n        Perceptron (MLP), Long Short-Term Memory (LSTM), many-to-many LSTM\n        (M2MLSTM), Transformer (NDT).\n    - `model_args`: dict, the arguments to be passed to the model constructor.\n        The arguments should be in the format expected by the model constructor.\n        - `in_dim`: The number of input features.\n        - `out_dim`: The number of output features.\n        - `hidden_dims`: The number of hidden units each hidden layer of the\n            model. Can also take float values to specify the dropout rate.\n            - For LSTM and M2MLSTM, it should be a tuple of the hidden size,\n                the number of layers, and the dropout rate.\n                If the model is an MLP, it should be a list of hidden layer\n                sizes which can also take float values to specify the dropout\n                rate.\n            - If the model is an LSTM or M2MLSTM, it should be a list of the\n            hidden layer size, the number of layers, and the dropout rate.\n            - If the model is an NDT, it should be a list of the hidden layer\n                size, the number of layers, the number of attention heads, the\n                dropout rate for the encoder layer, and the dropout rate applied\n                before the decoder layer.\n        - `max_context_len`: The maximum context length for the transformer\n            model. Only used if the model is an NDT.\n        - `args`:\n            - `clf`: If True, the model is a classifier; otherwise, it is a\n                regressor.\n            - `activations`: The activation functions for each layer.\n            - `criterion`: The loss function to optimize.\n            - `epochs`: The number of complete passes through the training\n                dataset.\n            - `lr`: Controls how much to change the model in response to the\n                estimated error each time the model weights are updated. A\n                smaller value ensures stable convergence but may slow down\n                training, while a larger value speeds up training but risks\n                overshooting.\n            - `base_lr`: The initial learning rate for the learning rate\n                scheduler.\n            - `max_grad_norm`: The maximum norm of the gradients.\n            - `iters_to_accumulate`: The number of iterations to accumulate\n                gradients.\n            - `weight_decay`: The L2 regularization strength.\n            - `num_training_batches`: The number of training batches. If\n                None, the number of batches is calculated based on the batch\n                size and the length of the training data.\n            - `scheduler_step_size_multiplier`: The multiplier for the\n                learning rate scheduler step size. Higher values lead to\n                faster learning rate decay.\n    - `bins_before`: int, the number of bins before the current bin to\n        include in the input data.\n    - `bins_current`: int, the number of bins in the current time bin to\n        include in the input data.\n    - `bins_after`: int, the number of bins after the current bin to include\n        in the input data.\n    - `behaviors`: list, the indices of the columns of behavioral features\n        to be predicted. Selected behavioral variable must have homogenous\n        data types across all features (continuous for regression and\n        categorical for classification)\n    - `batch_size`: int, the number of training examples utilized in one\n        iteration. Larger batch sizes offer stable gradient estimates but\n        require more memory, while smaller batches introduce noise that can\n        help escape local minima.\n        - When using M2MLSTM or NDT and input trials are of inconsistents\n            lengths, the batch size should be set to 1.\n        - M2MLSTM does not support batch_size != 1.\n    - `num_workers`: int, The number of parallel processes to use for data\n        loading. Increasing the number of workers can speed up data loading\n        but may lead to memory issues. Too many workers can also slow down\n        the training process due to contention for resources.\n    - `accelerator`: str, the device to use for training. Should be 'cuda' or\n        'cpu'.\n    - `seed`: int, the random seed for reproducibility.\n\n</pre> In\u00a0[16]: Copied! <pre>decoder_type = \"MLP\"  # Select decoder type (e.g., MLP)\nhyperparams = dict(\n    batch_size=512 * 4,\n    num_workers=5,\n    model=decoder_type,\n    model_args=dict(\n        in_dim=train_neural.shape[1],\n        out_dim=train_trajectory.shape[1],\n        hidden_dims=[64, 32, 16, 8],\n        args=dict(\n            clf=False,\n            activations=nn.CELU,\n            criterion=F.mse_loss,\n            epochs=10,\n            lr=3e-2,\n            base_lr=1e-2,\n            max_grad_norm=1.0,\n            iters_to_accumulate=1,\n            weight_decay=1e-2,\n            num_training_batches=None,\n            scheduler_step_size_multiplier=1,\n        ),\n    ),\n    behaviors=[0, 1],\n    bins_before=0,\n    bins_current=1,\n    bins_after=0,\n    accelerator=DEVICE,\n    seed=SEED,\n)\n</pre> decoder_type = \"MLP\"  # Select decoder type (e.g., MLP) hyperparams = dict(     batch_size=512 * 4,     num_workers=5,     model=decoder_type,     model_args=dict(         in_dim=train_neural.shape[1],         out_dim=train_trajectory.shape[1],         hidden_dims=[64, 32, 16, 8],         args=dict(             clf=False,             activations=nn.CELU,             criterion=F.mse_loss,             epochs=10,             lr=3e-2,             base_lr=1e-2,             max_grad_norm=1.0,             iters_to_accumulate=1,             weight_decay=1e-2,             num_training_batches=None,             scheduler_step_size_multiplier=1,         ),     ),     behaviors=[0, 1],     bins_before=0,     bins_current=1,     bins_after=0,     accelerator=DEVICE,     seed=SEED, ) <p>Train the decoder using the <code>train_model</code> function:</p> In\u00a0[17]: Copied! <pre>partitions = [(\n    train_neural,\n    train_trajectory,\n    test_neural,\n    test_trajectory,\n    test_neural,\n    test_trajectory,\n)]\n\n# Train the model using the pipeline function from your decoder module\nresults_path = None  # checkpoints will be saved to this path, optimizing reruns\nbv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (\n    npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path)\n)\n</pre> partitions = [(     train_neural,     train_trajectory,     test_neural,     test_trajectory,     test_neural,     test_trajectory, )]  # Train the model using the pipeline function from your decoder module results_path = None  # checkpoints will be saved to this path, optimizing reruns bv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (     npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path) ) <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\n\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  3.5 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 3.5 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 3.5 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.010282222181558609    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.8256530304417413\nRMSE: 0.09318435872837166\n</pre> In\u00a0[18]: Copied! <pre># Use the generalized visualization function\npredictions_dict = {\n    \"Bayesian\": [test_pred_bayesian],\n    \"GP\": [pred_mean_gp],\n    decoder_type: [bv_preds_folds[0]],\n}\n\nfig = visualize_predicted_trial(\n        trial=0,\n        actual_trials=[test_trajectory.values],\n        predictions=predictions_dict,\n        environment=environment,\n)\nplt.show()\n</pre> # Use the generalized visualization function predictions_dict = {     \"Bayesian\": [test_pred_bayesian],     \"GP\": [pred_mean_gp],     decoder_type: [bv_preds_folds[0]], }  fig = visualize_predicted_trial(         trial=0,         actual_trials=[test_trajectory.values],         predictions=predictions_dict,         environment=environment, ) plt.show() <p>The results of decoding using flexible Bayesian &amp; DNN deoders are not greater than the linear and GP decoders. This is because the data is cleanly simulated and the explicity assumptions of the Gaussian Process nature of relationship of neurons and space is giving GP decoder an advantage.</p> <p>Moreover, DNN is overkill for this task. However, in real data, the flexible decoders will likely outperform the explicitly hypothesis-driven decoders.</p> In\u00a0[19]: Copied! <pre>environment, reward_indices = create_cheeseboard_maze()\n\nagent = rbx.Agent(environment)\ninit_pos = np.asarray([0, -0.48])\nprint(f\"Agent initialized in Cheeseboard Maze: {agent.pos}\")\n\nN_NEURONS = 50\nN_TRIALS = 100\nplacecells = rbx.PlaceCells(\n    agent,\n    params=dict(\n        description=\"gaussian_threshold\",\n        widths=0.3,\n        n=N_NEURONS,\n        color=\"C1\",\n        wall_geometry=\"line_of_sight\",\n    ),\n)\n\ncheckpts_coords = [\n    environment.objects[\"objects\"][reward_idx] for reward_idx in reward_indices\n]\ncheckpts_coords = [init_pos] + checkpts_coords + [init_pos]\n\ntrial_epochs = []\ntrial_epoch = []\nfor n in range(N_TRIALS):\n    for goal_coords in checkpts_coords:\n        # simulate the agent in the maze\n        while True:\n            dir_to_goal = goal_coords - agent.pos\n            drift_vel = 3 * agent.speed_mean * dir_to_goal / np.linalg.norm(dir_to_goal)\n            agent.update(drift_velocity=drift_vel)\n            placecells.update()\n\n            # if animal is close to reward, break\n            if np.linalg.norm(dir_to_goal) &lt; 0.01:\n                if np.all(goal_coords == init_pos):\n                    trial_epoch.append(agent.t)\n                    if len(trial_epoch) == 2:\n                        trial_epochs.append(trial_epoch)\n                        trial_epoch = []\n                break\n\nagent.plot_trajectory(trial_epochs[0][0], trial_epochs[-1][1], linewidth=1)\n# plot rewards\nfor i in reward_indices:\n    plt.plot(*environment.objects[\"objects\"][i], \"ko\")\n</pre> environment, reward_indices = create_cheeseboard_maze()  agent = rbx.Agent(environment) init_pos = np.asarray([0, -0.48]) print(f\"Agent initialized in Cheeseboard Maze: {agent.pos}\")  N_NEURONS = 50 N_TRIALS = 100 placecells = rbx.PlaceCells(     agent,     params=dict(         description=\"gaussian_threshold\",         widths=0.3,         n=N_NEURONS,         color=\"C1\",         wall_geometry=\"line_of_sight\",     ), )  checkpts_coords = [     environment.objects[\"objects\"][reward_idx] for reward_idx in reward_indices ] checkpts_coords = [init_pos] + checkpts_coords + [init_pos]  trial_epochs = [] trial_epoch = [] for n in range(N_TRIALS):     for goal_coords in checkpts_coords:         # simulate the agent in the maze         while True:             dir_to_goal = goal_coords - agent.pos             drift_vel = 3 * agent.speed_mean * dir_to_goal / np.linalg.norm(dir_to_goal)             agent.update(drift_velocity=drift_vel)             placecells.update()              # if animal is close to reward, break             if np.linalg.norm(dir_to_goal) &lt; 0.01:                 if np.all(goal_coords == init_pos):                     trial_epoch.append(agent.t)                     if len(trial_epoch) == 2:                         trial_epochs.append(trial_epoch)                         trial_epoch = []                 break  agent.plot_trajectory(trial_epochs[0][0], trial_epochs[-1][1], linewidth=1) # plot rewards for i in reward_indices:     plt.plot(*environment.objects[\"objects\"][i], \"ko\") <pre>Agent initialized in Cheeseboard Maze: [-0.24221668  0.15734778]\n</pre> In\u00a0[20]: Copied! <pre>nsv_trials = []\nbv_trials = []\nfor t_start, t_end in trial_epochs:\n    t = np.array(placecells.history[\"t\"])\n    i_start = 0 if t_start is None else np.argmin(np.abs(t - t_start))\n    i_end = -1 if t_end is None else np.argmin(np.abs(t - t_end))\n    t = t[i_start:i_end]  # subsample data for training (most of it is redundant anyway)\n    neural_data = np.array(placecells.history[\"firingrate\"])[i_start:i_end]\n    # Inject some noise to the neural data\n    noise = np.random.normal(0, 0.1, neural_data.shape)\n    neural_data += noise\n    nsv_trials.append(pd.DataFrame(neural_data))\n    trajectory = np.array(placecells.Agent.history[\"pos\"])[i_start:i_end]\n    bv_trials.append(pd.DataFrame(trajectory))\nnsv_trials = np.asarray(nsv_trials, dtype=object)\nbv_trials = np.asarray(bv_trials, dtype=object)\n</pre> nsv_trials = [] bv_trials = [] for t_start, t_end in trial_epochs:     t = np.array(placecells.history[\"t\"])     i_start = 0 if t_start is None else np.argmin(np.abs(t - t_start))     i_end = -1 if t_end is None else np.argmin(np.abs(t - t_end))     t = t[i_start:i_end]  # subsample data for training (most of it is redundant anyway)     neural_data = np.array(placecells.history[\"firingrate\"])[i_start:i_end]     # Inject some noise to the neural data     noise = np.random.normal(0, 0.1, neural_data.shape)     neural_data += noise     nsv_trials.append(pd.DataFrame(neural_data))     trajectory = np.array(placecells.Agent.history[\"pos\"])[i_start:i_end]     bv_trials.append(pd.DataFrame(trajectory)) nsv_trials = np.asarray(nsv_trials, dtype=object) bv_trials = np.asarray(bv_trials, dtype=object) In\u00a0[21]: Copied! <pre>def visualize_trial(t=0):\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(nsv_trials[t].to_numpy().T, aspect=\"auto\", cmap=\"inferno\")\n    ax[0].set_xlabel(\"Time (s)\")\n    ax[0].set_ylabel(\"Neuron\")\n    ax[0].set_title(\"Firing Rates of Cells\")\n\n    environment.plot_environment(fig, ax=ax[1])\n    ax[1].plot(*bv_trials[t].to_numpy().T, label=\"Position\")\n    # plot rewards\n    ax[1].plot(*environment.objects[\"objects\"][reward_indices].T, \"ko\", label=\"Reward\")\n    ax[1].set_xlabel(\"x\")\n    ax[1].set_xlabel(\"y\")\n    ax[1].set_title(\"Trajectory\")\n    # plot first 2 legend only\n    ax[1].legend()\n    plt.show()\n\n\nwidgets.interact(visualize_trial, t=(0, len(nsv_trials) - 1, 1));\n</pre> def visualize_trial(t=0):     fig, ax = plt.subplots(1, 2, figsize=(10, 5))     ax[0].imshow(nsv_trials[t].to_numpy().T, aspect=\"auto\", cmap=\"inferno\")     ax[0].set_xlabel(\"Time (s)\")     ax[0].set_ylabel(\"Neuron\")     ax[0].set_title(\"Firing Rates of Cells\")      environment.plot_environment(fig, ax=ax[1])     ax[1].plot(*bv_trials[t].to_numpy().T, label=\"Position\")     # plot rewards     ax[1].plot(*environment.objects[\"objects\"][reward_indices].T, \"ko\", label=\"Reward\")     ax[1].set_xlabel(\"x\")     ax[1].set_xlabel(\"y\")     ax[1].set_title(\"Trajectory\")     # plot first 2 legend only     ax[1].legend()     plt.show()   widgets.interact(visualize_trial, t=(0, len(nsv_trials) - 1, 1)); <pre>interactive(children=(IntSlider(value=0, description='t', max=99), Output()), _dom_classes=('widget-interact',\u2026</pre> In\u00a0[22]: Copied! <pre>fold_indices = npy.ensemble.decoding.split_data(\n    nsv_trials, np.random.randint(0, 2, size=len(nsv_trials)), 0.6\n)\npartition_indices = npy.ensemble.decoding.partition_indices(fold_indices)\npartitions = npy.ensemble.decoding.partition_sets(\n    partition_indices, nsv_trials, bv_trials\n)\n</pre> fold_indices = npy.ensemble.decoding.split_data(     nsv_trials, np.random.randint(0, 2, size=len(nsv_trials)), 0.6 ) partition_indices = npy.ensemble.decoding.partition_indices(fold_indices) partitions = npy.ensemble.decoding.partition_sets(     partition_indices, nsv_trials, bv_trials ) In\u00a0[23]: Copied! <pre>bv_test_pred_ridge = []\nfor nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:\n    ridge = sklearn.linear_model.Ridge(alpha=0.01)\n    ridge.fit(np.concatenate(nsv_train), np.concatenate(bv_train))\n    bv_test_pred = ridge.predict(np.concatenate(nsv_test))\n    bv_test_pred_ridge.append(bv_test_pred)\n\nsklearn.metrics.r2_score(\n    np.concatenate([np.concatenate(p[-1]) for p in partitions]),\n    np.concatenate(bv_test_pred_ridge),\n)\n</pre> bv_test_pred_ridge = [] for nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:     ridge = sklearn.linear_model.Ridge(alpha=0.01)     ridge.fit(np.concatenate(nsv_train), np.concatenate(bv_train))     bv_test_pred = ridge.predict(np.concatenate(nsv_test))     bv_test_pred_ridge.append(bv_test_pred)  sklearn.metrics.r2_score(     np.concatenate([np.concatenate(p[-1]) for p in partitions]),     np.concatenate(bv_test_pred_ridge), ) Out[23]: <pre>0.9649044686864525</pre> <p>(Skipping GP decoder training because of long training times)</p> In\u00a0[24]: Copied! <pre># Convert all data to nelpy objects\n# Concatenate all training data to build tuning curves\nall_neural_train = []\nall_pos_train = []\nall_times_train = []\ncumulative_time = 0.0\n\nfor nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:\n    for neural_trial, pos_trial in zip(nsv_train, bv_train):\n        all_neural_train.append(neural_trial.values)\n        all_pos_train.append(pos_trial.values)\n        trial_length = len(neural_trial)\n        all_times_train.append(np.arange(trial_length) * agent.dt + cumulative_time)\n        cumulative_time += trial_length * agent.dt\n\n# Stack all data\nall_neural_train = np.vstack(all_neural_train)\nall_pos_train = np.vstack(all_pos_train)\nall_times_train = np.concatenate(all_times_train)\n\n# Create nelpy objects for tuning curve calculation\ntrajectory_nel = nel.AnalogSignalArray(all_pos_train.T, abscissa_vals=all_times_train)\nspeed_nel = nel.utils.ddt_asa(trajectory_nel, smooth=True, sigma=0.250, norm=True)\nneural_nel = nel.AnalogSignalArray(all_neural_train.T, abscissa_vals=all_times_train)\n</pre> # Convert all data to nelpy objects # Concatenate all training data to build tuning curves all_neural_train = [] all_pos_train = [] all_times_train = [] cumulative_time = 0.0  for nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:     for neural_trial, pos_trial in zip(nsv_train, bv_train):         all_neural_train.append(neural_trial.values)         all_pos_train.append(pos_trial.values)         trial_length = len(neural_trial)         all_times_train.append(np.arange(trial_length) * agent.dt + cumulative_time)         cumulative_time += trial_length * agent.dt  # Stack all data all_neural_train = np.vstack(all_neural_train) all_pos_train = np.vstack(all_pos_train) all_times_train = np.concatenate(all_times_train)  # Create nelpy objects for tuning curve calculation trajectory_nel = nel.AnalogSignalArray(all_pos_train.T, abscissa_vals=all_times_train) speed_nel = nel.utils.ddt_asa(trajectory_nel, smooth=True, sigma=0.250, norm=True) neural_nel = nel.AnalogSignalArray(all_neural_train.T, abscissa_vals=all_times_train) In\u00a0[25]: Copied! <pre># Train Bayesian decoder by building spatial maps from all trials\n# Build spatial maps\ntc_bayesian = npy.tuning.SpatialMap(\n    trajectory_nel,\n    neural_nel,\n    s_binsize=0.0075,\n    speed=speed_nel,\n    speed_thres=0.01,\n    tuning_curve_sigma=0.2,\n    place_field_min_size=0.2,\n    place_field_max_size=100,\n    place_field_sigma=0.2,\n)\n\n# Make predictions on test data\nbv_test_pred_bayesian = []\nfor _, _, _, _, nsv_test, bv_test in partitions:\n    posterior_prob = npy.ensemble.decoding.bayesian.decode(\n        np.concatenate(nsv_test),  # (n_timebins, n_neurons)\n        tc_bayesian.ratemap.T,\n        tc_bayesian.occupancy.T,\n        agent.dt,\n        uniform_prior=True,\n    )\n    test_pred = npy.ensemble.position_estimator(\n        posterior_prob,\n        tc_bayesian.ybin_centers,\n        tc_bayesian.xbin_centers,\n        method=\"com\",\n    )\n    bv_test_pred_bayesian.append(test_pred)\n\nsklearn.metrics.r2_score(\n    np.concatenate([np.concatenate(p[-1]) for p in partitions]),\n    np.concatenate(bv_test_pred_bayesian),\n)\n</pre> # Train Bayesian decoder by building spatial maps from all trials # Build spatial maps tc_bayesian = npy.tuning.SpatialMap(     trajectory_nel,     neural_nel,     s_binsize=0.0075,     speed=speed_nel,     speed_thres=0.01,     tuning_curve_sigma=0.2,     place_field_min_size=0.2,     place_field_max_size=100,     place_field_sigma=0.2, )  # Make predictions on test data bv_test_pred_bayesian = [] for _, _, _, _, nsv_test, bv_test in partitions:     posterior_prob = npy.ensemble.decoding.bayesian.decode(         np.concatenate(nsv_test),  # (n_timebins, n_neurons)         tc_bayesian.ratemap.T,         tc_bayesian.occupancy.T,         agent.dt,         uniform_prior=True,     )     test_pred = npy.ensemble.position_estimator(         posterior_prob,         tc_bayesian.ybin_centers,         tc_bayesian.xbin_centers,         method=\"com\",     )     bv_test_pred_bayesian.append(test_pred)  sklearn.metrics.r2_score(     np.concatenate([np.concatenate(p[-1]) for p in partitions]),     np.concatenate(bv_test_pred_bayesian), ) Out[25]: <pre>0.8205066579983402</pre> In\u00a0[26]: Copied! <pre>decoder_type = \"MLP\"  # Select decoder type (e.g., MLP)\nhyperparams = dict(\n    batch_size=512 * 4,\n    num_workers=5,\n    model=decoder_type,\n    model_args=dict(\n        in_dim=nsv_trials[0].shape[1],\n        out_dim=bv_trials[0].shape[1],\n        hidden_dims=[64, 32, 16, 8],\n        args=dict(\n            clf=False,\n            activations=nn.CELU,\n            criterion=F.mse_loss,\n            epochs=10,\n            lr=3e-2,\n            base_lr=1e-2,\n            max_grad_norm=1.0,\n            iters_to_accumulate=1,\n            weight_decay=1e-2,\n            num_training_batches=None,\n            scheduler_step_size_multiplier=1,\n        ),\n    ),\n    behaviors=[0, 1],\n    bins_before=0,\n    bins_current=1,\n    bins_after=0,\n    accelerator=DEVICE,\n    seed=SEED,\n)\n</pre> decoder_type = \"MLP\"  # Select decoder type (e.g., MLP) hyperparams = dict(     batch_size=512 * 4,     num_workers=5,     model=decoder_type,     model_args=dict(         in_dim=nsv_trials[0].shape[1],         out_dim=bv_trials[0].shape[1],         hidden_dims=[64, 32, 16, 8],         args=dict(             clf=False,             activations=nn.CELU,             criterion=F.mse_loss,             epochs=10,             lr=3e-2,             base_lr=1e-2,             max_grad_norm=1.0,             iters_to_accumulate=1,             weight_decay=1e-2,             num_training_batches=None,             scheduler_step_size_multiplier=1,         ),     ),     behaviors=[0, 1],     bins_before=0,     bins_current=1,     bins_after=0,     accelerator=DEVICE,     seed=SEED, ) In\u00a0[27]: Copied! <pre># Train the model using the pipeline function from your decoder module\nresults_path = \"results\"\nbv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (\n    npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path)\n)\n</pre> # Train the model using the pipeline function from your decoder module results_path = \"results\" bv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (     npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path) ) <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  6.0 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 6.0 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 6.0 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.0012865465832874179   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/2555598951 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.9714067094278961\nRMSE: 0.03585913779325996\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  6.0 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 6.0 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 6.0 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.001433454337529838    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/2555598951 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.9668799893931259\nRMSE: 0.03769905526888104\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  6.0 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 6.0 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 6.0 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.0010953289456665516   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/2555598951 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.9738012919898239\nRMSE: 0.033095253798918436\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  6.0 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 6.0 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 6.0 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.001239695819094777    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/2555598951 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.9713017714821129\nRMSE: 0.03515008483887547\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  6.0 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 6.0 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 6.0 K                                                                                                \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 10                                                                                          \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=10` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502   0.0013565346598625183   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.9680192310424885\nRMSE: 0.03673899145029244\n</pre> In\u00a0[28]: Copied! <pre>bv_preds_dnn_trials = np.concatenate([\n    bv_preds_fold + norm_params_folds[i][\"y_train_mean\"]\n    for i, bv_preds_fold in enumerate(bv_preds_folds)\n])\nbv_preds_ridge_trials = np.concatenate(bv_test_pred_ridge)\nbv_preds_bayesian_trials = np.concatenate(bv_test_pred_bayesian)\nbv_actual_trials = np.concatenate([np.concatenate(p[-1]) for p in partitions])\ntrial_lengths = [len(trial) for p in partitions for trial in p[-1]]\ntrial_indices = np.cumsum(trial_lengths)\n\nbv_preds_dnn_trials = np.split(bv_preds_dnn_trials, trial_indices[:-1])\nbv_preds_ridge_trials = np.split(bv_preds_ridge_trials, trial_indices[:-1])\nbv_preds_bayesian_trials = np.split(bv_preds_bayesian_trials, trial_indices[:-1])\nbv_actual_trials = np.split(bv_actual_trials, trial_indices[:-1])\n\n\n# Use the flexible visualization function\npredictions_dict = {\n    \"Ridge\": bv_preds_ridge_trials,\n    \"Bayesian\": bv_preds_bayesian_trials,\n    decoder_type: bv_preds_dnn_trials,\n}\n\nwidgets.interact(\n    lambda trial: visualize_predicted_trial(\n        trial,\n        bv_actual_trials,\n        predictions_dict,\n        environment=environment,\n        reward_indices=reward_indices,\n    ),\n    trial=(0, len(nsv_trials) - 1, 1),\n);\n</pre> bv_preds_dnn_trials = np.concatenate([     bv_preds_fold + norm_params_folds[i][\"y_train_mean\"]     for i, bv_preds_fold in enumerate(bv_preds_folds) ]) bv_preds_ridge_trials = np.concatenate(bv_test_pred_ridge) bv_preds_bayesian_trials = np.concatenate(bv_test_pred_bayesian) bv_actual_trials = np.concatenate([np.concatenate(p[-1]) for p in partitions]) trial_lengths = [len(trial) for p in partitions for trial in p[-1]] trial_indices = np.cumsum(trial_lengths)  bv_preds_dnn_trials = np.split(bv_preds_dnn_trials, trial_indices[:-1]) bv_preds_ridge_trials = np.split(bv_preds_ridge_trials, trial_indices[:-1]) bv_preds_bayesian_trials = np.split(bv_preds_bayesian_trials, trial_indices[:-1]) bv_actual_trials = np.split(bv_actual_trials, trial_indices[:-1])   # Use the flexible visualization function predictions_dict = {     \"Ridge\": bv_preds_ridge_trials,     \"Bayesian\": bv_preds_bayesian_trials,     decoder_type: bv_preds_dnn_trials, }  widgets.interact(     lambda trial: visualize_predicted_trial(         trial,         bv_actual_trials,         predictions_dict,         environment=environment,         reward_indices=reward_indices,     ),     trial=(0, len(nsv_trials) - 1, 1), ); <pre>interactive(children=(IntSlider(value=49, description='trial', max=99), Output()), _dom_classes=('widget-inter\u2026</pre> In\u00a0[29]: Copied! <pre>BIN_SIZE = 0.05\n</pre> BIN_SIZE = 0.05 In\u00a0[30]: Copied! <pre>basepath = r\"/fs/ayadata1-afr77.nbb.cornell.edu/volume1/ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"\n\nepoch_df = npy.io.load_epoch(basepath)\n# get session bounds to provide support\nsession_bounds = nel.EpochArray(\n    [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n)\n# compress repeated sleep sessions\nepoch_df = npy.session.compress_repeated_epochs(epoch_df)\nbeh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))\n\nst, cell_metrics = npy.io.load_spikes(\n    basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1\"\n)\nspike_spindices = npy.spikes.get_spindices(st.data)\n\nswr = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n\ntheta = nel.EpochArray(npy.io.load_SleepState_states(basepath)[\"THETA\"])\n\ntask_idx = npy.process.in_intervals(\n    spike_spindices.spike_times, (beh_epochs[1] &amp; theta).data\n)\n</pre> basepath = r\"/fs/ayadata1-afr77.nbb.cornell.edu/volume1/ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"  epoch_df = npy.io.load_epoch(basepath) # get session bounds to provide support session_bounds = nel.EpochArray(     [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]] ) # compress repeated sleep sessions epoch_df = npy.session.compress_repeated_epochs(epoch_df) beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))  st, cell_metrics = npy.io.load_spikes(     basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1\" ) spike_spindices = npy.spikes.get_spindices(st.data)  swr = npy.io.load_ripples_events(basepath, return_epoch_array=True)  theta = nel.EpochArray(npy.io.load_SleepState_states(basepath)[\"THETA\"])  task_idx = npy.process.in_intervals(     spike_spindices.spike_times, (beh_epochs[1] &amp; theta).data ) In\u00a0[31]: Copied! <pre>position_df = npy.io.load_animal_behavior(basepath)\nposition_df[[\"x\", \"y\"]] = position_df[[\"x\", \"y\"]].interpolate(method='linear')\nposition_df[[\"x\", \"y\"]] = position_df[[\"x\", \"y\"]].ffill().bfill()\n\n# put position into a nelpy position array for ease of use\nposxy = nel.AnalogSignalArray(\n    data=position_df[[\"x\", \"y\"]].values.T,\n    timestamps=position_df.timestamps.values,\n)\n\n# get outbound and inbound epochs\n(outbound_epochs, inbound_epochs) = npy.behavior.get_linear_track_lap_epochs(\n    posxy.abscissa_vals, posxy.data[0], newLapThreshold=20\n)\n\noutbound_epochs, inbound_epochs\n</pre> position_df = npy.io.load_animal_behavior(basepath) position_df[[\"x\", \"y\"]] = position_df[[\"x\", \"y\"]].interpolate(method='linear') position_df[[\"x\", \"y\"]] = position_df[[\"x\", \"y\"]].ffill().bfill()  # put position into a nelpy position array for ease of use posxy = nel.AnalogSignalArray(     data=position_df[[\"x\", \"y\"]].values.T,     timestamps=position_df.timestamps.values, )  # get outbound and inbound epochs (outbound_epochs, inbound_epochs) = npy.behavior.get_linear_track_lap_epochs(     posxy.abscissa_vals, posxy.data[0], newLapThreshold=20 )  outbound_epochs, inbound_epochs Out[31]: <pre>(&lt;EpochArray at 0x7f8f648e4950: 42 epochs&gt; of length 17:07:964 minutes,\n &lt;EpochArray at 0x7f8f648e5220: 43 epochs&gt; of length 17:17:974 minutes)</pre> In\u00a0[32]: Copied! <pre>bst_trials_inbound = [\n    st[i].bin(ds=BIN_SIZE).smooth(sigma=BIN_SIZE, inplace=True) for i in outbound_epochs\n]\nbst_trials_outbound = [\n    st[i].bin(ds=BIN_SIZE).smooth(sigma=BIN_SIZE, inplace=True) for i in inbound_epochs\n]\nbst_trials = bst_trials_inbound + bst_trials_outbound\nnsv_trials = np.asarray([pd.DataFrame(i.data.T) for i in bst_trials], dtype=object)\n</pre> bst_trials_inbound = [     st[i].bin(ds=BIN_SIZE).smooth(sigma=BIN_SIZE, inplace=True) for i in outbound_epochs ] bst_trials_outbound = [     st[i].bin(ds=BIN_SIZE).smooth(sigma=BIN_SIZE, inplace=True) for i in inbound_epochs ] bst_trials = bst_trials_inbound + bst_trials_outbound nsv_trials = np.asarray([pd.DataFrame(i.data.T) for i in bst_trials], dtype=object) In\u00a0[33]: Copied! <pre>pos_trials = np.asarray([\n    pd.DataFrame(posxy.asarray(at=bst.bin_centers).yvals.T)\n        for bst in bst_trials\n    ],\n    dtype=object\n)\n</pre> pos_trials = np.asarray([     pd.DataFrame(posxy.asarray(at=bst.bin_centers).yvals.T)         for bst in bst_trials     ],     dtype=object ) In\u00a0[34]: Copied! <pre># Format partitions for the decoder pipeline\nfold_indices = npy.ensemble.decoding.split_data(\n    nsv_trials, np.random.randint(0, 2, size=len(nsv_trials)), 0.6\n)\npartition_indices = npy.ensemble.decoding.partition_indices(fold_indices)\npartitions = npy.ensemble.decoding.partition_sets(\n    partition_indices, nsv_trials, pos_trials\n)\n</pre> # Format partitions for the decoder pipeline fold_indices = npy.ensemble.decoding.split_data(     nsv_trials, np.random.randint(0, 2, size=len(nsv_trials)), 0.6 ) partition_indices = npy.ensemble.decoding.partition_indices(fold_indices) partitions = npy.ensemble.decoding.partition_sets(     partition_indices, nsv_trials, pos_trials ) In\u00a0[35]: Copied! <pre>bv_test_pred_ridge = []\nfor nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:\n    ridge = sklearn.linear_model.Ridge(alpha=0.01)\n    ridge.fit(np.concatenate(nsv_train), np.concatenate(bv_train))\n    bv_test_pred = ridge.predict(np.concatenate(nsv_test))\n    bv_test_pred_ridge.append(bv_test_pred)\n\nsklearn.metrics.r2_score(\n    np.concatenate([np.concatenate(p[-1]) for p in partitions])[:, 0],  # x dimension is only where linear track extends\n    np.concatenate(bv_test_pred_ridge)[:, 0],\n)\n</pre> bv_test_pred_ridge = [] for nsv_train, bv_train, nsv_val, bv_val, nsv_test, bv_test in partitions:     ridge = sklearn.linear_model.Ridge(alpha=0.01)     ridge.fit(np.concatenate(nsv_train), np.concatenate(bv_train))     bv_test_pred = ridge.predict(np.concatenate(nsv_test))     bv_test_pred_ridge.append(bv_test_pred)  sklearn.metrics.r2_score(     np.concatenate([np.concatenate(p[-1]) for p in partitions])[:, 0],  # x dimension is only where linear track extends     np.concatenate(bv_test_pred_ridge)[:, 0], ) Out[35]: <pre>0.5948557053710475</pre> In\u00a0[36]: Copied! <pre>spatial_maps = npy.tuning.SpatialMap(\n    posxy[inbound_epochs + outbound_epochs],\n    st[inbound_epochs + outbound_epochs],\n    s_binsize=3,\n    speed_thres=4,\n    tuning_curve_sigma=4,\n    place_field_min_size=5,\n    place_field_max_size=1000,\n    place_field_sigma=0.1,\n)\n\n\nbv_test_pred_bayesian = []\nfor _, _, _, _, nsv_test, bv_test in partitions:\n    posterior_prob = npy.ensemble.decoding.bayesian.decode(\n        np.concatenate(nsv_test),\n        spatial_maps.ratemap.T,\n        spatial_maps.occupancy.T,\n        BIN_SIZE,\n        uniform_prior=True,\n    )\n    bv_test_pred = npy.ensemble.position_estimator(\n        posterior_prob,\n        spatial_maps.ybin_centers,\n        spatial_maps.xbin_centers,\n        method=\"com\",\n    )\n    bv_test_pred_bayesian.append(bv_test_pred)\n\nsklearn.metrics.r2_score(\n    np.concatenate([np.concatenate(p[-1]) for p in partitions])[:, 0],\n    np.concatenate(bv_test_pred_bayesian)[:, 0],\n)\n</pre> spatial_maps = npy.tuning.SpatialMap(     posxy[inbound_epochs + outbound_epochs],     st[inbound_epochs + outbound_epochs],     s_binsize=3,     speed_thres=4,     tuning_curve_sigma=4,     place_field_min_size=5,     place_field_max_size=1000,     place_field_sigma=0.1, )   bv_test_pred_bayesian = [] for _, _, _, _, nsv_test, bv_test in partitions:     posterior_prob = npy.ensemble.decoding.bayesian.decode(         np.concatenate(nsv_test),         spatial_maps.ratemap.T,         spatial_maps.occupancy.T,         BIN_SIZE,         uniform_prior=True,     )     bv_test_pred = npy.ensemble.position_estimator(         posterior_prob,         spatial_maps.ybin_centers,         spatial_maps.xbin_centers,         method=\"com\",     )     bv_test_pred_bayesian.append(bv_test_pred)  sklearn.metrics.r2_score(     np.concatenate([np.concatenate(p[-1]) for p in partitions])[:, 0],     np.concatenate(bv_test_pred_bayesian)[:, 0], ) Out[36]: <pre>0.8166878189807462</pre> In\u00a0[37]: Copied! <pre>decoder_type = \"MLP\"  # Select decoder type (e.g., MLP)\nhyperparams = dict(\n    batch_size=512 * 8,\n    num_workers=5,\n    model=decoder_type,\n    model_args=dict(\n        in_dim=nsv_trials[0].shape[1],\n        out_dim=pos_trials[0].shape[1],\n        hidden_dims=[256, 256, 0.15, 256],\n        args=dict(\n            clf=False,\n            activations=nn.CELU,\n            criterion=F.mse_loss,\n            epochs=40,\n            lr=3e-2,\n            base_lr=1e-2,\n            max_grad_norm=1.0,\n            iters_to_accumulate=1,\n            weight_decay=1e-2,\n            num_training_batches=None,\n            scheduler_step_size_multiplier=1,\n        ),\n    ),\n    behaviors=[0, 1],\n    bins_before=1,\n    bins_current=1,\n    bins_after=0,\n    accelerator=DEVICE,\n    seed=SEED,\n)\n</pre> decoder_type = \"MLP\"  # Select decoder type (e.g., MLP) hyperparams = dict(     batch_size=512 * 8,     num_workers=5,     model=decoder_type,     model_args=dict(         in_dim=nsv_trials[0].shape[1],         out_dim=pos_trials[0].shape[1],         hidden_dims=[256, 256, 0.15, 256],         args=dict(             clf=False,             activations=nn.CELU,             criterion=F.mse_loss,             epochs=40,             lr=3e-2,             base_lr=1e-2,             max_grad_norm=1.0,             iters_to_accumulate=1,             weight_decay=1e-2,             num_training_batches=None,             scheduler_step_size_multiplier=1,         ),     ),     behaviors=[0, 1],     bins_before=1,     bins_current=1,     bins_after=0,     accelerator=DEVICE,     seed=SEED, ) In\u00a0[38]: Copied! <pre># Train the model using the pipeline function from your decoder module\nresults_path = \"results\"\nbv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (\n    npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path)\n)\n</pre> # Train the model using the pipeline function from your decoder module results_path = \"results\" bv_preds_folds, bv_models_folds, norm_params_folds, metrics_folds = (     npy.ensemble.decoding.train_model(partitions, hyperparams, resultspath=results_path) ) <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  255 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 255 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 255 K                                                                                                \nTotal estimated model params size (MB): 1                                                                          \nModules in train mode: 9                                                                                           \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=40` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502     515.2560424804688     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/318615455 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.8346841508628151\nRMSE: 19.266750273530764\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  255 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 255 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 255 K                                                                                                \nTotal estimated model params size (MB): 1                                                                          \nModules in train mode: 9                                                                                           \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=40` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502     1175.678955078125     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/318615455 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.6017460518897958\nRMSE: 30.17087822870876\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  255 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 255 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 255 K                                                                                                \nTotal estimated model params size (MB): 1                                                                          \nModules in train mode: 9                                                                                           \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=40` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502    1022.5718994140625     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/318615455 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.6983266026682143\nRMSE: 26.115756787548765\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  255 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 255 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 255 K                                                                                                \nTotal estimated model params size (MB): 1                                                                          \nModules in train mode: 9                                                                                           \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=40` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502     474.7945556640625     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Seed set to 2025\nTrainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kg574/.local/lib/python3.12/site-packages/ipyk ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\n/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /local/storage/kg574/dependencies/python/neuro_py/tutorials/results/models/318615455 exists and is not empty.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.86034026273691\nRMSE: 18.66099073724503\n</pre> <pre>\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   \u2503 Name \u2503 Type       \u2503 Params \u2503 Mode  \u2503 FLOPs \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 main \u2502 Sequential \u2502  255 K \u2502 train \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Trainable params: 255 K                                                                                            \nNon-trainable params: 0                                                                                            \nTotal params: 255 K                                                                                                \nTotal estimated model params size (MB): 1                                                                          \nModules in train mode: 9                                                                                           \nModules in eval mode: 0                                                                                            \nTotal FLOPs: 0                                                                                                     \n</pre> <pre>/local/storage/kg574/programs/miniforge3/envs/cmc/lib/python3.12/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n`Trainer.fit` stopped: `max_epochs=40` reached.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         test_loss         \u2502    433.23321533203125     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre>Variance weighed avg. coefficient of determination: 0.8280856864439035\nRMSE: 18.114129665695852\n</pre> In\u00a0[39]: Copied! <pre>bv_preds_dnn_trials = np.concatenate([\n    bv_preds_fold + norm_params_folds[i][\"y_train_mean\"]\n    for i, bv_preds_fold in enumerate(bv_preds_folds)\n])\nbv_preds_bayesian_trials = np.concatenate(bv_test_pred_bayesian)\nbv_actual_trials = np.concatenate([np.concatenate(p[-1]) for p in partitions])\ntrial_lengths = [len(trial) for p in partitions for trial in p[-1]]\ntrial_indices = np.cumsum(trial_lengths)\n\nbv_preds_dnn_trials = np.split(bv_preds_dnn_trials, trial_indices[:-1])\nbv_preds_bayesian_trials = np.split(bv_preds_bayesian_trials, trial_indices[:-1])\nbv_actual_trials = np.split(bv_actual_trials, trial_indices[:-1])\n\n\n# Use the generalized visualization function\npredictions_dict = {\n    \"Bayesian\": bv_preds_bayesian_trials,\n    decoder_type: bv_preds_dnn_trials,\n}\n\ncreate_trial_visualization_widget(\n    actual_trials=bv_actual_trials,\n    predictions=predictions_dict,\n);\n</pre> bv_preds_dnn_trials = np.concatenate([     bv_preds_fold + norm_params_folds[i][\"y_train_mean\"]     for i, bv_preds_fold in enumerate(bv_preds_folds) ]) bv_preds_bayesian_trials = np.concatenate(bv_test_pred_bayesian) bv_actual_trials = np.concatenate([np.concatenate(p[-1]) for p in partitions]) trial_lengths = [len(trial) for p in partitions for trial in p[-1]] trial_indices = np.cumsum(trial_lengths)  bv_preds_dnn_trials = np.split(bv_preds_dnn_trials, trial_indices[:-1]) bv_preds_bayesian_trials = np.split(bv_preds_bayesian_trials, trial_indices[:-1]) bv_actual_trials = np.split(bv_actual_trials, trial_indices[:-1])   # Use the generalized visualization function predictions_dict = {     \"Bayesian\": bv_preds_bayesian_trials,     decoder_type: bv_preds_dnn_trials, }  create_trial_visualization_widget(     actual_trials=bv_actual_trials,     predictions=predictions_dict, ); <pre>interactive(children=(IntSlider(value=0, description='trial', max=84), Output()), _dom_classes=('widget-intera\u2026</pre>"},{"location":"tutorials/decoding/#neural-decoding","title":"Neural Decoding\u00b6","text":"<p>In this tutorial, we'll explore how to use the Deep Neural Network decoders in <code>decoding</code> submodule to analyze the neural correlates of behavior.</p> <p>We will begin with synthetic data generation, followed by training and evaluating models on real neural data. The goal is to understand how neural activity can be decoded to predict behavioral outcomes.</p>"},{"location":"tutorials/decoding/#setup","title":"Setup\u00b6","text":"<p>First, let's import the necessary libraries and set up our environment.</p>"},{"location":"tutorials/decoding/#imports","title":"Imports\u00b6","text":""},{"location":"tutorials/decoding/#set-device-and-random-seed-for-reproducibility","title":"Set device and random seed for reproducibility\u00b6","text":""},{"location":"tutorials/decoding/#helper-functions","title":"Helper Functions\u00b6","text":"<p>Don't worry about the details of these functions; they are provided to streamline our workflow.</p>"},{"location":"tutorials/decoding/#section-1-decode-synthetic-neural-data","title":"Section 1: Decode Synthetic Neural Data\u00b6","text":""},{"location":"tutorials/decoding/#section-11-generate-synthetic-data","title":"Section 1.1: Generate Synthetic Data\u00b6","text":""},{"location":"tutorials/decoding/#section-111-create-environment","title":"Section 1.1.1: Create Environment\u00b6","text":"<p>The following function generates a cheeseboard-inspired maze environment for the agent:</p>"},{"location":"tutorials/decoding/#section-112-create-agent-and-place-cells-encoding-agents-position","title":"Section 1.1.2: Create Agent and Place Cells encoding agent's position\u00b6","text":""},{"location":"tutorials/decoding/#section-12-prepare-data-for-decoding","title":"Section 1.2: Prepare Data for Decoding\u00b6","text":"<p>Extract firing rates from the place cells and the agent's positional trajectory</p>"},{"location":"tutorials/decoding/#section-13-train-linear-and-gaussian-process-decoders","title":"Section 1.3: Train Linear and Gaussian Process Decoders\u00b6","text":"<p>Train simple hypothesis-driven decoders (because they bake very specific assumptions about how stimuli map to neural responses into their functional form and priors) for baseline comparison with more flexible Bayesian and DNN decoders:</p> <p>For best practice, comparing performance to these simpler models is essential to show that increased flexibility and capacity lead to meaningful gains in predictive accuracy or interpretability, rather than merely overfitting or exploiting idiosyncrasies of the dataset.</p>"},{"location":"tutorials/decoding/#section-131-linear-decoder-ridge-regression","title":"Section 1.3.1: Linear Decoder (Ridge Regression)\u00b6","text":""},{"location":"tutorials/decoding/#section-132-gaussian-process-gp-decoder","title":"Section 1.3.2: Gaussian Process (GP) Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-14-train-bayesian-dnn-decoders","title":"Section 1.4: Train Bayesian &amp; DNN Decoders\u00b6","text":""},{"location":"tutorials/decoding/#section-141-bayesian-decoder","title":"Section 1.4.1: Bayesian Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-142-train-and-evaluate-the-dnn-decoder","title":"Section 1.4.2: Train and Evaluate the DNN Decoder\u00b6","text":"<p>Set up the decoder model and hyperparameters. For example, use an MLP decoder.</p> <p>We refer description of key hyperparameters that impact model performance:</p>"},{"location":"tutorials/decoding/#section-15-visualize-results","title":"Section 1.5: Visualize Results\u00b6","text":"<p>Plot predictions versus ground truth to evaluate decoding performance:</p>"},{"location":"tutorials/decoding/#section-2-trial-segmented-decoding","title":"Section 2: Trial Segmented Decoding\u00b6","text":"<p>Before we move on to real neural data, let's first understand how to decode neural data in a trial-segmented manner. This is useful when the neural data is segregated into chunks representing different trials, and we want to decode each trial separately.</p>"},{"location":"tutorials/decoding/#section-21-generate-synthetic-trial-segmented-data","title":"Section 2.1: Generate Synthetic Trial Segmented Data\u00b6","text":""},{"location":"tutorials/decoding/#section-22-prepare-data-for-decoding","title":"Section 2.2: Prepare Data for Decoding\u00b6","text":""},{"location":"tutorials/decoding/#section-23-train-linear-decoder","title":"Section 2.3: Train Linear Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-24-train-bayesian-dnn-decoders","title":"Section 2.4: Train Bayesian &amp; DNN Decoders\u00b6","text":""},{"location":"tutorials/decoding/#section-241-bayesian-decoder","title":"Section 2.4.1: Bayesian Decoder\u00b6","text":"<p>Train a Bayesian decoder using spatial tuning curves for comparison.</p> <p>Note that the spatial maps are created using data both in training &amp; test sets. This is a form of data leakage for the purpose of model evaluation.</p> <p>For the purpose of this tutorial, it is necessary to keep things simple for this spatial bin classification method. However, data leakage in such a case can be evaded by ensuring minimum sampling from all spatial bins exists in all training sets of different partitions.</p>"},{"location":"tutorials/decoding/#section-242-train-and-evaluate-the-dnn-decoder","title":"Section 2.4.2: Train and Evaluate the DNN Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-25-visualize-results","title":"Section 2.5: Visualize Results\u00b6","text":""},{"location":"tutorials/decoding/#section-3-decoding-real-data","title":"Section 3: Decoding Real Data\u00b6","text":"<p>Now that we've seen how to decode synthetic data, let's try decoding real data.</p>"},{"location":"tutorials/decoding/#section-31-load-the-data","title":"Section 3.1: Load the data\u00b6","text":""},{"location":"tutorials/decoding/#section-32-prepare-data-for-decoding","title":"Section 3.2: Prepare Data for Decoding\u00b6","text":""},{"location":"tutorials/decoding/#section-33-train-linear-decoder","title":"Section 3.3: Train Linear Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-34-train-bayesian-dnn-decoders","title":"Section 3.4: Train Bayesian &amp; DNN Decoders\u00b6","text":""},{"location":"tutorials/decoding/#section-341-bayesian-decoder","title":"Section 3.4.1: Bayesian Decoder\u00b6","text":"<p>Train a Bayesian decoder using spatial tuning curves for comparison.</p> <p>Again, note that the spatial maps are created using data both in training &amp; test sets.</p>"},{"location":"tutorials/decoding/#section-342-train-and-evaluate-the-dnn-decoder","title":"Section 3.4.2: Train and Evaluate the DNN Decoder\u00b6","text":""},{"location":"tutorials/decoding/#section-35-visualize-results","title":"Section 3.5: Visualize Results\u00b6","text":""},{"location":"tutorials/explained_variance/","title":"Explained Variance","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\nimport nelpy as nel\n\nfrom neuro_py.ensemble.explained_variance import ExplainedVariance\nfrom neuro_py.io import loading\nfrom neuro_py.plotting.events import plot_peth_fast\nfrom neuro_py.plotting.figure_helpers import set_plotting_defaults\n\nset_plotting_defaults()\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nfig_save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\figures\\panels\"\n</pre> %reload_ext autoreload %autoreload 2  import matplotlib.pyplot as plt import nelpy as nel  from neuro_py.ensemble.explained_variance import ExplainedVariance from neuro_py.io import loading from neuro_py.plotting.events import plot_peth_fast from neuro_py.plotting.figure_helpers import set_plotting_defaults  set_plotting_defaults() %matplotlib inline %config InlineBackend.figure_format = 'retina' fig_save_path = r\"Z:\\home\\ryanh\\projects\\hpc_ctx\\figures\\panels\" In\u00a0[2]: Copied! <pre>basepath = r\"U:\\data\\HMC\\HMC1\\day8\"\n\nst, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")\n\nepoch_df = loading.load_epoch(basepath)\nbeh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\nstate_dict = loading.load_SleepState_states(basepath)\nnrem_epochs = nel.EpochArray(\n    state_dict[\"NREMstate\"],\n)\n\nepoch_df\n</pre> basepath = r\"U:\\data\\HMC\\HMC1\\day8\"  st, cm = loading.load_spikes(basepath, brainRegion=\"CA1\", putativeCellType=\"Pyr\")  epoch_df = loading.load_epoch(basepath) beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)  state_dict = loading.load_SleepState_states(basepath) nrem_epochs = nel.EpochArray(     state_dict[\"NREMstate\"], )  epoch_df Out[2]: name startTime stopTime environment behavioralParadigm notes manipulation stimuli basepath 0 preSleep_210411_064951 0.0000 9544.56315 sleep NaN NaN NaN NaN U:\\data\\HMC\\HMC1\\day8 1 maze_210411_095201 9544.5632 11752.80635 linear 1 novel NaN NaN U:\\data\\HMC\\HMC1\\day8 2 postSleep_210411_103522 11752.8064 23817.68955 sleep NaN NaN NaN NaN U:\\data\\HMC\\HMC1\\day8 In\u00a0[3]: Copied! <pre>ev = ExplainedVariance(\n    st=st,\n    template=beh_epochs[1],  # task\n    matching=beh_epochs[2],  # post sleep\n    control=beh_epochs[0],  # pre sleep\n    window=None,  # window size to calculate correlations, None is the full epoch\n)\n\nprint(f\"explained variance: {ev.ev[0]}, reverse explained variance: {ev.rev[0]}\")\n</pre> ev = ExplainedVariance(     st=st,     template=beh_epochs[1],  # task     matching=beh_epochs[2],  # post sleep     control=beh_epochs[0],  # pre sleep     window=None,  # window size to calculate correlations, None is the full epoch )  print(f\"explained variance: {ev.ev[0]}, reverse explained variance: {ev.rev[0]}\") <pre>WARNING:root:ignoring events outside of eventarray support\n</pre> <pre>explained variance: 0.10214717079493098, reverse explained variance: 0.002093670634183538\n</pre> <p>You can calculate a p-value for the explained variance by comparing the explained variance to the explained variance of shuffled data (shuffled template correlations).</p> <p>NOTE: This only works when returning single explained variance value, not a set of explained variance values over time.</p> In\u00a0[4]: Copied! <pre>pvalue = ev.pvalue()\nprint(f\"pvalue: {pvalue}\")\n</pre> pvalue = ev.pvalue() print(f\"pvalue: {pvalue}\") <pre>pvalue: 0.000999000999000999\n</pre> In\u00a0[5]: Copied! <pre>ev = ExplainedVariance(\n    st=st,\n    template=beh_epochs[1],  # task\n    matching=beh_epochs,  # entire epoch (uses start,stop)\n    control=beh_epochs[0],  # pre sleep\n    window=200,\n)\n\n# conviently plot the explained variance with built in method\nev.plot()\n</pre> ev = ExplainedVariance(     st=st,     template=beh_epochs[1],  # task     matching=beh_epochs,  # entire epoch (uses start,stop)     control=beh_epochs[0],  # pre sleep     window=200, )  # conviently plot the explained variance with built in method ev.plot() <pre>WARNING:root:ignoring events outside of eventarray support\n</pre> In\u00a0[6]: Copied! <pre>plt.figure(figsize=(8, 3))\nax = plt.gca()\nplot_peth_fast(ev.partial_corr.T, ts=ev.matching_time, ax=ax, label=\"EV\")\nplot_peth_fast(\n    ev.rev_partial_corr.T, ts=ev.matching_time, ax=ax, color=\"grey\", label=\"REV\"\n)\nplt.axvspan(\n    nrem_epochs.data[0, 0],\n    nrem_epochs.data[0, 1],\n    color=\"purple\",\n    alpha=0.5,\n    label=\"NREM\",\n)\nfor nrem in nrem_epochs.data:\n    plt.axvspan(nrem[0], nrem[1], color=\"purple\", alpha=0.5)\nplt.axvspan(\n    beh_epochs[1].data[0, 0],\n    beh_epochs[1].data[0, 1],\n    color=\"b\",\n    alpha=0.25,\n    zorder=-100,\n    label=\"Task\",\n)\nplt.legend()\nplt.show()\n</pre> plt.figure(figsize=(8, 3)) ax = plt.gca() plot_peth_fast(ev.partial_corr.T, ts=ev.matching_time, ax=ax, label=\"EV\") plot_peth_fast(     ev.rev_partial_corr.T, ts=ev.matching_time, ax=ax, color=\"grey\", label=\"REV\" ) plt.axvspan(     nrem_epochs.data[0, 0],     nrem_epochs.data[0, 1],     color=\"purple\",     alpha=0.5,     label=\"NREM\", ) for nrem in nrem_epochs.data:     plt.axvspan(nrem[0], nrem[1], color=\"purple\", alpha=0.5) plt.axvspan(     beh_epochs[1].data[0, 0],     beh_epochs[1].data[0, 1],     color=\"b\",     alpha=0.25,     zorder=-100,     label=\"Task\", ) plt.legend() plt.show() In\u00a0[7]: Copied! <pre>nrem_ev_avg = ev.ev_signal[beh_epochs[2] &amp; nrem_epochs].mean()\nnrem_rev_avg = ev.rev_signal[beh_epochs[2] &amp; nrem_epochs].mean()\n\nprint(f\"explained variance: {nrem_ev_avg}, reverse explained variance: {nrem_rev_avg}\")\n</pre> nrem_ev_avg = ev.ev_signal[beh_epochs[2] &amp; nrem_epochs].mean() nrem_rev_avg = ev.rev_signal[beh_epochs[2] &amp; nrem_epochs].mean()  print(f\"explained variance: {nrem_ev_avg}, reverse explained variance: {nrem_rev_avg}\") <pre>WARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\n</pre> <pre>explained variance: 0.10133556865860369, reverse explained variance: 0.001632476383922529\n</pre>"},{"location":"tutorials/explained_variance/#explained-variance","title":"Explained Variance\u00b6","text":""},{"location":"tutorials/explained_variance/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/explained_variance/#section-1-load-spike-data-session-epochs-and-non-rem-epochs","title":"Section 1: Load spike data, session epochs, and Non-REM epochs\u00b6","text":""},{"location":"tutorials/explained_variance/#section-2-single-output-metrics-explained-and-reverse-explained-variance","title":"Section 2: Single output metrics: Explained and Reverse Explained Variance\u00b6","text":"<p>Here we are calculating explained variance over the entire post-task interval</p>"},{"location":"tutorials/explained_variance/#section-3-time-resolved-explained-variance","title":"Section 3: Time-resolved explained variance\u00b6","text":""},{"location":"tutorials/explained_variance/#section-31-calculate-explained-variance-over-time","title":"Section 3.1: Calculate explained variance over time\u00b6","text":"<p>We can also see the time course of explained variance</p>"},{"location":"tutorials/explained_variance/#section-32-inspect-when-the-explained-variance-is-high-and-low","title":"Section 3.2: Inspect when the explained variance is high and low\u00b6","text":"<p>You can see it is high during the task (by definition it should be) and during NREM sleep</p>"},{"location":"tutorials/explained_variance/#section-33-use-epocharray-to-get-average-explained-variance-in-post-task-nrem-sleep","title":"Section 3.3: Use EpochArray to get average explained variance in post-task NREM sleep\u00b6","text":"<p>The outcome is similar to above when we used the entire post-task epoch</p>"},{"location":"tutorials/neural_geodynamics/","title":"Neural Geodynamics","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\nimport ipywidgets as widgets\nimport matplotlib\nimport matplotlib.gridspec\nimport matplotlib.pyplot as plt\nimport nelpy as nel\nimport numpy as np\nimport sklearn\nfrom IPython.display import HTML\nfrom matplotlib.animation import FuncAnimation\n\nimport neuro_py as npy\n</pre> %reload_ext autoreload %autoreload 2 import ipywidgets as widgets import matplotlib import matplotlib.gridspec import matplotlib.pyplot as plt import nelpy as nel import numpy as np import sklearn from IPython.display import HTML from matplotlib.animation import FuncAnimation  import neuro_py as npy In\u00a0[2]: Copied! <pre>def plot_3d_trajs(ax, x, y, z1, z2, color1=\"tab:blue\", color2=\"tab:green\"):\n    ax.scatter(x, y, z1, color=color1, s=100)\n    ax.plot(x, y, z1, color=color1, alpha=0.25)\n    ax.scatter(x, y, z2, color=color2, s=100)\n    ax.plot(x, y, z2, color=color2, alpha=0.25)\n\n    return ax\n\n\ndef vis_nss_metrics(\n    x, y, z1, z2, metric=\"proximity\", color1=\"tab:blue\", color2=\"tab:red\", ax=None\n):\n    if ax is None:\n        fig = plt.figure(figsize=(6, 10))\n        ax = fig.add_subplot(111, projection=\"3d\")\n    plot_3d_trajs(ax, x, y, z1, z2, color1=color1, color2=color2)\n    n_points = len(x)\n    i = n_points // 2\n    if metric == \"proximity\":\n        for j in range(n_points):\n            ax.plot(\n                [x[i], x[j]],\n                [y[i], y[j]],\n                [z1[i], z2[j]],\n                color=\"gray\",\n                linestyle=\"dotted\",\n            )\n        ax.quiver(\n            x[i],\n            y[i],\n            z1[i],\n            x[i] - x[i],\n            y[i] - y[i],\n            z2[i] - z1[i],\n            color=\"black\",\n            arrow_length_ratio=0.25,\n            pivot=\"tail\",\n            linewidth=2,\n        )\n        ax.quiver(\n            x[i],\n            y[i],\n            z2[i],\n            x[i] - x[i],\n            y[i] - y[i],\n            z1[i] - z2[i],\n            color=\"black\",\n            arrow_length_ratio=0.25,\n            pivot=\"tail\",\n            linewidth=2,\n        )\n        # insert a small plot on top right of current plot\n        ax_inset = ax.inset_axes([0.825, 0.825, 0.165, 0.165])\n        ax_inset.plot(x[i], z1[i], \"o\", color=color1)\n        ax_inset.plot(x[i], z2[i], \"o\", color=color2)\n        # join 2 points with quiver\n        ax_inset.quiver(\n            x[i],\n            z1[i],\n            np.zeros_like(x[i]),\n            z2[i] - z1[i],\n            scale_units=\"xy\",\n            scale=1,\n            color=\"black\",\n            pivot=\"tail\",\n            width=0.05,\n        )\n        # opposite quiver\n        ax_inset.quiver(\n            x[i],\n            z2[i],\n            np.zeros_like(x[i]),\n            z1[i] - z2[i],\n            scale_units=\"xy\",\n            scale=1,\n            color=\"black\",\n            pivot=\"tail\",\n            width=0.05,\n        )\n        ax_inset.tick_params(\n            axis=\"both\", bottom=False, left=False, labelbottom=False, labelleft=False\n        )\n        # thick frame\n        ax_inset.spines[\"top\"].set_linewidth(2)\n        ax_inset.spines[\"right\"].set_linewidth(2)\n        ax_inset.spines[\"left\"].set_linewidth(2)\n        ax_inset.spines[\"bottom\"].set_linewidth(2)\n\n        ratio = 0.15\n        # add 20% padding from current limits\n        x0, x1 = ax_inset.get_xlim()\n        y0, y1 = ax_inset.get_ylim()\n        ax_inset.set_xlim(x0 - ratio * abs(x1 - x0), x1 + ratio * abs(x1 - x0))\n        ax_inset.set_ylim(y0 - ratio * abs(y1 - y0), y1 + ratio * abs(y1 - y0))\n    elif metric == \"cosine\":\n        ax.quiver(\n            x[i],\n            y[i],\n            z1[i],\n            x[i + 1] - x[i],\n            y[i + 1] - y[i],\n            z1[i + 1] - z1[i],\n            color=\"black\",\n            arrow_length_ratio=0.2,\n            pivot=\"tail\",\n            linewidth=2,\n            edgecolor=\"black\",\n            facecolor=\"black\",\n            alpha=1,\n        )\n        # reverse the arrow\n        ax.quiver(\n            x[i],\n            y[i],\n            z2[i],\n            x[i + 1] - x[i],\n            y[i + 1] - y[i],\n            z2[i + 1] - z2[i],\n            color=\"black\",\n            arrow_length_ratio=0.2,\n            pivot=\"tail\",\n            linewidth=2,\n            edgecolor=\"black\",\n            facecolor=\"black\",\n            alpha=1,\n        )\n        ax_inset = ax.inset_axes([0.825, 0.825, 0.165, 0.165])\n        ax_inset.plot(x[i + 1], z1[i + 1], \"o\", color=color1)\n        ax_inset.plot(x[i + 1], z2[i + 1], \"o\", color=color2)\n        # visualize the angle between the 2 vectors with quiver using vertex as midpoint between the 2 vectors\n        angle = np.arccos(\n            np.dot(\n                [x[i + 1] - x[i], z1[i + 1] - z1[i]],\n                [x[i + 1] - x[i], z2[i + 1] - z2[i]],\n            )\n            / (\n                np.linalg.norm([x[i + 1] - x[i], z1[i + 1] - z1[i]])\n                * np.linalg.norm([x[i + 1] - x[i], z2[i + 1] - z2[i]])\n            )\n        )\n        # visualize the angle between the 2 vectors with quiver using vertex as origin\n        midpt = (x[i], (z2[i] + z1[i]) / 2)\n        ax_inset.quiver(\n            *midpt,\n            x[i + 1] - midpt[0],\n            z2[i + 1] - midpt[1],\n            angles=\"xy\",\n            scale_units=\"xy\",\n            scale=1,\n            color=\"black\",\n            width=0.05,\n        )\n        ax_inset.quiver(\n            *midpt,\n            x[i + 1] - midpt[0],\n            z1[i + 1] - midpt[1],\n            angles=\"xy\",\n            scale_units=\"xy\",\n            scale=1,\n            color=\"black\",\n            width=0.05,\n        )\n\n        leftvec = (x[i + 1], z2[i + 1]) if angle &gt; 0 else (x[i + 1], z1[i + 1])\n        rightvec = (x[i + 1], z1[i + 1]) if angle &gt; 0 else (x[i + 1], z2[i + 1])\n        npy.plotting.AngleAnnotation(\n            midpt,\n            leftvec,\n            rightvec,\n            ax=ax_inset,\n            size=32.5,\n            linewidth=2,\n            text=\"$\\\\theta$\",\n            linestyle=\"-\",\n            color=\"darkslategray\",\n            textposition=\"outside\",\n            text_kw=dict(fontsize=11, color=\"darkslategray\"),\n        )\n\n        ax_inset.tick_params(\n            axis=\"both\", bottom=False, left=False, labelbottom=False, labelleft=False\n        )\n        # thick frame\n        ax_inset.spines[\"top\"].set_linewidth(2)\n        ax_inset.spines[\"right\"].set_linewidth(2)\n        ax_inset.spines[\"left\"].set_linewidth(2)\n        ax_inset.spines[\"bottom\"].set_linewidth(2)\n\n        ratio = 0.15\n        # add 20% padding from current limits\n        x0, x1 = ax_inset.get_xlim()\n        y0, y1 = ax_inset.get_ylim()\n        ax_inset.set_xlim(x0 - ratio * abs(x1 - x0), x1 + ratio * abs(x1 - x0))\n        ax_inset.set_ylim(y0 - ratio * abs(y1 - y0), y1 + ratio * abs(y1 - y0))\n    ax.set_xlabel(\"Unit 1\")\n    ax.set_ylabel(\"Unit 2\")\n    ax.set_zlabel(\"Unit 3\")\n    ax.tick_params(axis=\"both\", pad=0, width=0)\n    npy.plotting.clean_plot3d(ax)\n\n    return ax\n</pre> def plot_3d_trajs(ax, x, y, z1, z2, color1=\"tab:blue\", color2=\"tab:green\"):     ax.scatter(x, y, z1, color=color1, s=100)     ax.plot(x, y, z1, color=color1, alpha=0.25)     ax.scatter(x, y, z2, color=color2, s=100)     ax.plot(x, y, z2, color=color2, alpha=0.25)      return ax   def vis_nss_metrics(     x, y, z1, z2, metric=\"proximity\", color1=\"tab:blue\", color2=\"tab:red\", ax=None ):     if ax is None:         fig = plt.figure(figsize=(6, 10))         ax = fig.add_subplot(111, projection=\"3d\")     plot_3d_trajs(ax, x, y, z1, z2, color1=color1, color2=color2)     n_points = len(x)     i = n_points // 2     if metric == \"proximity\":         for j in range(n_points):             ax.plot(                 [x[i], x[j]],                 [y[i], y[j]],                 [z1[i], z2[j]],                 color=\"gray\",                 linestyle=\"dotted\",             )         ax.quiver(             x[i],             y[i],             z1[i],             x[i] - x[i],             y[i] - y[i],             z2[i] - z1[i],             color=\"black\",             arrow_length_ratio=0.25,             pivot=\"tail\",             linewidth=2,         )         ax.quiver(             x[i],             y[i],             z2[i],             x[i] - x[i],             y[i] - y[i],             z1[i] - z2[i],             color=\"black\",             arrow_length_ratio=0.25,             pivot=\"tail\",             linewidth=2,         )         # insert a small plot on top right of current plot         ax_inset = ax.inset_axes([0.825, 0.825, 0.165, 0.165])         ax_inset.plot(x[i], z1[i], \"o\", color=color1)         ax_inset.plot(x[i], z2[i], \"o\", color=color2)         # join 2 points with quiver         ax_inset.quiver(             x[i],             z1[i],             np.zeros_like(x[i]),             z2[i] - z1[i],             scale_units=\"xy\",             scale=1,             color=\"black\",             pivot=\"tail\",             width=0.05,         )         # opposite quiver         ax_inset.quiver(             x[i],             z2[i],             np.zeros_like(x[i]),             z1[i] - z2[i],             scale_units=\"xy\",             scale=1,             color=\"black\",             pivot=\"tail\",             width=0.05,         )         ax_inset.tick_params(             axis=\"both\", bottom=False, left=False, labelbottom=False, labelleft=False         )         # thick frame         ax_inset.spines[\"top\"].set_linewidth(2)         ax_inset.spines[\"right\"].set_linewidth(2)         ax_inset.spines[\"left\"].set_linewidth(2)         ax_inset.spines[\"bottom\"].set_linewidth(2)          ratio = 0.15         # add 20% padding from current limits         x0, x1 = ax_inset.get_xlim()         y0, y1 = ax_inset.get_ylim()         ax_inset.set_xlim(x0 - ratio * abs(x1 - x0), x1 + ratio * abs(x1 - x0))         ax_inset.set_ylim(y0 - ratio * abs(y1 - y0), y1 + ratio * abs(y1 - y0))     elif metric == \"cosine\":         ax.quiver(             x[i],             y[i],             z1[i],             x[i + 1] - x[i],             y[i + 1] - y[i],             z1[i + 1] - z1[i],             color=\"black\",             arrow_length_ratio=0.2,             pivot=\"tail\",             linewidth=2,             edgecolor=\"black\",             facecolor=\"black\",             alpha=1,         )         # reverse the arrow         ax.quiver(             x[i],             y[i],             z2[i],             x[i + 1] - x[i],             y[i + 1] - y[i],             z2[i + 1] - z2[i],             color=\"black\",             arrow_length_ratio=0.2,             pivot=\"tail\",             linewidth=2,             edgecolor=\"black\",             facecolor=\"black\",             alpha=1,         )         ax_inset = ax.inset_axes([0.825, 0.825, 0.165, 0.165])         ax_inset.plot(x[i + 1], z1[i + 1], \"o\", color=color1)         ax_inset.plot(x[i + 1], z2[i + 1], \"o\", color=color2)         # visualize the angle between the 2 vectors with quiver using vertex as midpoint between the 2 vectors         angle = np.arccos(             np.dot(                 [x[i + 1] - x[i], z1[i + 1] - z1[i]],                 [x[i + 1] - x[i], z2[i + 1] - z2[i]],             )             / (                 np.linalg.norm([x[i + 1] - x[i], z1[i + 1] - z1[i]])                 * np.linalg.norm([x[i + 1] - x[i], z2[i + 1] - z2[i]])             )         )         # visualize the angle between the 2 vectors with quiver using vertex as origin         midpt = (x[i], (z2[i] + z1[i]) / 2)         ax_inset.quiver(             *midpt,             x[i + 1] - midpt[0],             z2[i + 1] - midpt[1],             angles=\"xy\",             scale_units=\"xy\",             scale=1,             color=\"black\",             width=0.05,         )         ax_inset.quiver(             *midpt,             x[i + 1] - midpt[0],             z1[i + 1] - midpt[1],             angles=\"xy\",             scale_units=\"xy\",             scale=1,             color=\"black\",             width=0.05,         )          leftvec = (x[i + 1], z2[i + 1]) if angle &gt; 0 else (x[i + 1], z1[i + 1])         rightvec = (x[i + 1], z1[i + 1]) if angle &gt; 0 else (x[i + 1], z2[i + 1])         npy.plotting.AngleAnnotation(             midpt,             leftvec,             rightvec,             ax=ax_inset,             size=32.5,             linewidth=2,             text=\"$\\\\theta$\",             linestyle=\"-\",             color=\"darkslategray\",             textposition=\"outside\",             text_kw=dict(fontsize=11, color=\"darkslategray\"),         )          ax_inset.tick_params(             axis=\"both\", bottom=False, left=False, labelbottom=False, labelleft=False         )         # thick frame         ax_inset.spines[\"top\"].set_linewidth(2)         ax_inset.spines[\"right\"].set_linewidth(2)         ax_inset.spines[\"left\"].set_linewidth(2)         ax_inset.spines[\"bottom\"].set_linewidth(2)          ratio = 0.15         # add 20% padding from current limits         x0, x1 = ax_inset.get_xlim()         y0, y1 = ax_inset.get_ylim()         ax_inset.set_xlim(x0 - ratio * abs(x1 - x0), x1 + ratio * abs(x1 - x0))         ax_inset.set_ylim(y0 - ratio * abs(y1 - y0), y1 + ratio * abs(y1 - y0))     ax.set_xlabel(\"Unit 1\")     ax.set_ylabel(\"Unit 2\")     ax.set_zlabel(\"Unit 3\")     ax.tick_params(axis=\"both\", pad=0, width=0)     npy.plotting.clean_plot3d(ax)      return ax <p>Simulate two population vector trajectories and analyze the representational geometry and dynamics between them.</p> In\u00a0[3]: Copied! <pre>fig, axes = plt.subplots(2, 2, figsize=(10, 10), subplot_kw={\"projection\": \"3d\"})\naxes = axes.ravel()\n\n# Create data\nN_POINTS = 20\nx = np.sin(np.linspace(0, 2 * np.pi, N_POINTS))\ny = np.cos(np.linspace(0, 2 * np.pi, N_POINTS))\nz1 = np.linspace(0, 1, N_POINTS)\nz2 = np.linspace(0, 1, N_POINTS) + np.sin(np.linspace(0.25, 0.75, N_POINTS))\nprox_traj1 = np.array([x, y, z1]).T  # shape (N_POINTS, N_NEURONS)\nprox_traj2 = np.array([x, y, z2]).T  # shape (N_POINTS, N_NEURONS)\n\nvis_nss_metrics(x, y, z1, z2, metric=\"proximity\", ax=axes[0])\naxes[0].set_title(\"Proximity\")\n\n# Create data\nN_POINTS = 20\nx = -np.sin(np.linspace(0, 2 * np.pi, N_POINTS))\ny = np.cos(np.linspace(0, 2 * np.pi, N_POINTS))\nz1 = -np.linspace(0, 1, N_POINTS)\nz2 = -np.linspace(0, 1, N_POINTS) + np.sin(\n    np.linspace(np.pi / 2, 1.5 * np.pi, N_POINTS)\n)\ncos_traj1 = np.array([x, y, z1]).T  # shape (N_POINTS, N_NEURONS)\ncos_traj2 = np.array([x, y, z2]).T  # shape (N_POINTS, N_NEURONS)\n\nvis_nss_metrics(x, y, z1, z2, metric=\"cosine\", ax=axes[1])\naxes[1].set_title(\"Cosine similarity of dynamics\")\n\n# convert axes to 2D\naxes[2].axis(\"off\")\naxes[3].axis(\"off\")\n\n# insert axis 2d replacing the 3d plot\nax2d = fig.add_subplot(axes[2].get_position(), frame_on=True)\nax2d.plot(npy.ensemble.proximity(prox_traj1, prox_traj2), \".-\")\n\nax2d.set_xlabel(\"Time\")\nax2d.set_ylabel(\"Proximity\")\nax2d.set_title(\"Proximity between trajectories\")\n\n# insert axis 2d replacing the 3d plot\nax2d = fig.add_subplot(axes[3].get_position(), frame_on=True)\nax2d.plot(\n    npy.ensemble.cosine_similarity(np.diff(cos_traj1.T).T, np.diff(cos_traj2.T).T), \".-\"\n)\n\nax2d.set_xlabel(\"Time\")\nax2d.set_ylabel(\"Cosine similarity\")\nax2d.set_title(\"Cosine similarity of temporal differences\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axes = plt.subplots(2, 2, figsize=(10, 10), subplot_kw={\"projection\": \"3d\"}) axes = axes.ravel()  # Create data N_POINTS = 20 x = np.sin(np.linspace(0, 2 * np.pi, N_POINTS)) y = np.cos(np.linspace(0, 2 * np.pi, N_POINTS)) z1 = np.linspace(0, 1, N_POINTS) z2 = np.linspace(0, 1, N_POINTS) + np.sin(np.linspace(0.25, 0.75, N_POINTS)) prox_traj1 = np.array([x, y, z1]).T  # shape (N_POINTS, N_NEURONS) prox_traj2 = np.array([x, y, z2]).T  # shape (N_POINTS, N_NEURONS)  vis_nss_metrics(x, y, z1, z2, metric=\"proximity\", ax=axes[0]) axes[0].set_title(\"Proximity\")  # Create data N_POINTS = 20 x = -np.sin(np.linspace(0, 2 * np.pi, N_POINTS)) y = np.cos(np.linspace(0, 2 * np.pi, N_POINTS)) z1 = -np.linspace(0, 1, N_POINTS) z2 = -np.linspace(0, 1, N_POINTS) + np.sin(     np.linspace(np.pi / 2, 1.5 * np.pi, N_POINTS) ) cos_traj1 = np.array([x, y, z1]).T  # shape (N_POINTS, N_NEURONS) cos_traj2 = np.array([x, y, z2]).T  # shape (N_POINTS, N_NEURONS)  vis_nss_metrics(x, y, z1, z2, metric=\"cosine\", ax=axes[1]) axes[1].set_title(\"Cosine similarity of dynamics\")  # convert axes to 2D axes[2].axis(\"off\") axes[3].axis(\"off\")  # insert axis 2d replacing the 3d plot ax2d = fig.add_subplot(axes[2].get_position(), frame_on=True) ax2d.plot(npy.ensemble.proximity(prox_traj1, prox_traj2), \".-\")  ax2d.set_xlabel(\"Time\") ax2d.set_ylabel(\"Proximity\") ax2d.set_title(\"Proximity between trajectories\")  # insert axis 2d replacing the 3d plot ax2d = fig.add_subplot(axes[3].get_position(), frame_on=True) ax2d.plot(     npy.ensemble.cosine_similarity(np.diff(cos_traj1.T).T, np.diff(cos_traj2.T).T), \".-\" )  ax2d.set_xlabel(\"Time\") ax2d.set_ylabel(\"Cosine similarity\") ax2d.set_title(\"Cosine similarity of temporal differences\")  plt.tight_layout() plt.show() <pre>/tmp/ipykernel_316323/3793467759.py:54: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n</pre> In\u00a0[4]: Copied! <pre>basepath = r\"/run/user/1000/gvfs/smb-share:server=132.236.112.212,share=ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"\n\nepoch_df = npy.io.load_epoch(basepath)\n# get session bounds to provide support\nsession_bounds = nel.EpochArray(\n    [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]]\n)\n# compress repeated sleep sessions\nepoch_df = npy.session.compress_repeated_epochs(epoch_df)\nbeh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))\n\nst, cell_metrics = npy.io.load_spikes(\n    basepath, putativeCellType=\"Pyr\", brainRegion=\"CA\"\n)\n\nposition_df = npy.io.load_animal_behavior(basepath)\n\nposition_df_no_nan = position_df.query(\"x.isnull() == False\")\n# put position into a nelpy position array for ease of use\npos = nel.AnalogSignalArray(\n    data=position_df_no_nan[\"x\"].values.T,\n    timestamps=position_df_no_nan.timestamps.values,\n)\n\n# get outbound and inbound epochs\noutbound_epochs, inbound_epochs = npy.behavior.get_linear_track_lap_epochs(\n    pos.abscissa_vals, pos.data[0], newLapThreshold=20\n)\ninbound_epochs = npy.behavior.find_good_lap_epochs(\n    pos, inbound_epochs, thres=0.5, binsize=3, min_laps=10\n)\noutbound_epochs = npy.behavior.find_good_lap_epochs(\n    pos, outbound_epochs, thres=0.5, binsize=3, min_laps=10\n)\n\noutbound_epochs, inbound_epochs\n</pre> basepath = r\"/run/user/1000/gvfs/smb-share:server=132.236.112.212,share=ayadata1/Data/GrosmarkAD/Achilles/Achilles_10252013\"  epoch_df = npy.io.load_epoch(basepath) # get session bounds to provide support session_bounds = nel.EpochArray(     [epoch_df.startTime.iloc[0], epoch_df.stopTime.iloc[-1]] ) # compress repeated sleep sessions epoch_df = npy.session.compress_repeated_epochs(epoch_df) beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values.astype(float))  st, cell_metrics = npy.io.load_spikes(     basepath, putativeCellType=\"Pyr\", brainRegion=\"CA\" )  position_df = npy.io.load_animal_behavior(basepath)  position_df_no_nan = position_df.query(\"x.isnull() == False\") # put position into a nelpy position array for ease of use pos = nel.AnalogSignalArray(     data=position_df_no_nan[\"x\"].values.T,     timestamps=position_df_no_nan.timestamps.values, )  # get outbound and inbound epochs outbound_epochs, inbound_epochs = npy.behavior.get_linear_track_lap_epochs(     pos.abscissa_vals, pos.data[0], newLapThreshold=20 ) inbound_epochs = npy.behavior.find_good_lap_epochs(     pos, inbound_epochs, thres=0.5, binsize=3, min_laps=10 ) outbound_epochs = npy.behavior.find_good_lap_epochs(     pos, outbound_epochs, thres=0.5, binsize=3, min_laps=10 )  outbound_epochs, inbound_epochs <pre>WARNING:root:fs was not specified, so we try to estimate it from the data...\nWARNING:root:fs was estimated to be 39.06263603480421 Hz\nWARNING:root:creating support from abscissa_vals and sampling rate, fs!\nWARNING:root:'fs' has been deprecated; use 'step' instead\n</pre> Out[4]: <pre>(&lt;EpochArray at 0x7a610db358b0: 42 epochs&gt; of length 17:07:964 minutes,\n &lt;EpochArray at 0x7a610db351c0: 42 epochs&gt; of length 15:28:585 minutes)</pre> In\u00a0[5]: Copied! <pre>SPATIAL_BIN_SIZE = 3\nBEHAVIOR_TIME_BIN_SIZE = 0.05\nREPLAY_TIME_BIN_SIZE = 0.02\nSPEED_THRESHOLD = 3\nTUNING_CURVE_SIGMA = 2\nPLACE_CELL_MIN_SPKS = 100\nPLACE_CELL_MIN_RATE = 1\nPLACE_CELL_PEAK_MIN_RATIO = 1.5\n\nN_SHUFFLES = 100\n\n\ndef get_tuning_curves(\n    pos, st, x_min, x_max, speed_thres, s_binsize, tuning_curve_sigma\n):\n    spatial_maps = npy.tuning.SpatialMap(\n        pos,\n        st,\n        dim=1,\n        x_minmax=(x_min, x_max),\n        s_binsize=s_binsize,\n        speed_thres=speed_thres,\n        tuning_curve_sigma=tuning_curve_sigma,\n        minbgrate=0,  # decoding does not like 0 firing rate\n        # min_duration=0,\n    )\n\n    return spatial_maps.tc\n\n\nx_max = np.ceil(np.nanmax(pos.data))\nx_min = np.floor(np.nanmin(pos.data))\n\ntc_in = get_tuning_curves(\n    pos[inbound_epochs],\n    st[inbound_epochs],\n    x_min,\n    x_max,\n    SPEED_THRESHOLD,\n    SPATIAL_BIN_SIZE,\n    TUNING_CURVE_SIGMA,\n)\ntc_out = get_tuning_curves(\n    pos[outbound_epochs],\n    st[outbound_epochs],\n    x_min,\n    x_max,\n    SPEED_THRESHOLD,\n    SPATIAL_BIN_SIZE,\n    TUNING_CURVE_SIGMA,\n)\n</pre> SPATIAL_BIN_SIZE = 3 BEHAVIOR_TIME_BIN_SIZE = 0.05 REPLAY_TIME_BIN_SIZE = 0.02 SPEED_THRESHOLD = 3 TUNING_CURVE_SIGMA = 2 PLACE_CELL_MIN_SPKS = 100 PLACE_CELL_MIN_RATE = 1 PLACE_CELL_PEAK_MIN_RATIO = 1.5  N_SHUFFLES = 100   def get_tuning_curves(     pos, st, x_min, x_max, speed_thres, s_binsize, tuning_curve_sigma ):     spatial_maps = npy.tuning.SpatialMap(         pos,         st,         dim=1,         x_minmax=(x_min, x_max),         s_binsize=s_binsize,         speed_thres=speed_thres,         tuning_curve_sigma=tuning_curve_sigma,         minbgrate=0,  # decoding does not like 0 firing rate         # min_duration=0,     )      return spatial_maps.tc   x_max = np.ceil(np.nanmax(pos.data)) x_min = np.floor(np.nanmin(pos.data))  tc_in = get_tuning_curves(     pos[inbound_epochs],     st[inbound_epochs],     x_min,     x_max,     SPEED_THRESHOLD,     SPATIAL_BIN_SIZE,     TUNING_CURVE_SIGMA, ) tc_out = get_tuning_curves(     pos[outbound_epochs],     st[outbound_epochs],     x_min,     x_max,     SPEED_THRESHOLD,     SPATIAL_BIN_SIZE,     TUNING_CURVE_SIGMA, ) <pre>WARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\n</pre> In\u00a0[6]: Copied! <pre>pv_trials = []\nfor ep in inbound_epochs + outbound_epochs:\n    spatial_maps = npy.tuning.SpatialMap(\n        pos[ep],\n        st[ep],\n        dim=1,\n        x_minmax=(x_min, x_max),\n        s_binsize=SPATIAL_BIN_SIZE,\n        speed_thres=SPEED_THRESHOLD,\n        tuning_curve_sigma=TUNING_CURVE_SIGMA,\n        minbgrate=0,  # decoding does not like 0 firing rate\n        min_duration=0,\n    )\n    pv_trials.append(spatial_maps.tc.ratemap.T)\npv_trials = np.asarray(pv_trials)\npv_trials.shape  # (n_trials, n_neurons, n_bins)\n</pre> pv_trials = [] for ep in inbound_epochs + outbound_epochs:     spatial_maps = npy.tuning.SpatialMap(         pos[ep],         st[ep],         dim=1,         x_minmax=(x_min, x_max),         s_binsize=SPATIAL_BIN_SIZE,         speed_thres=SPEED_THRESHOLD,         tuning_curve_sigma=TUNING_CURVE_SIGMA,         minbgrate=0,  # decoding does not like 0 firing rate         min_duration=0,     )     pv_trials.append(spatial_maps.tc.ratemap.T) pv_trials = np.asarray(pv_trials) pv_trials.shape  # (n_trials, n_neurons, n_bins) <pre>WARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring signal outside of support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring signal outside of support\n</pre> Out[6]: <pre>(84, 65, 241)</pre> In\u00a0[7]: Copied! <pre>def vis_spatial_tc(ntrial):\n    inbound_nrnorder = np.asarray(tc_in.get_peak_firing_order_ids()) - 1\n    outbound_nrnorder = np.asarray(tc_out.get_peak_firing_order_ids()) - 1\n    CMAP = \"terrain\"\n\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.ravel()\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    zscored_tc_in = scaler.fit_transform(tc_in.ratemap.T).T\n    zscored_tc_out = scaler.fit_transform(tc_out.ratemap.T).T\n    zscored_trial = scaler.fit_transform(pv_trials[ntrial])\n\n    ax = axes[0]\n    im = ax.imshow(\n        zscored_tc_in[inbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Tuning Curves Inbound\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")\n\n    ax = axes[1]\n    im = ax.imshow(\n        zscored_tc_out[inbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Tuning Curves Outbound\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")\n\n    ax = axes[2]\n    im = ax.imshow(\n        zscored_trial.T[inbound_nrnorder],\n        aspect=\"auto\",\n        interpolation=\"none\",\n        cmap=CMAP,\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Spatial Binned Trial\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")\n\n    ax = axes[3]\n    im = ax.imshow(\n        zscored_tc_in[outbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Tuning Curves Inbound\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")\n\n    ax = axes[4]\n    im = ax.imshow(\n        zscored_tc_out[outbound_nrnorder],\n        aspect=\"auto\",\n        interpolation=\"none\",\n        cmap=CMAP,\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Tuning Curves Outbound\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")\n\n    ax = axes[5]\n    im = ax.imshow(\n        zscored_trial.T[outbound_nrnorder],\n        aspect=\"auto\",\n        interpolation=\"none\",\n        cmap=CMAP,\n    )\n    plt.colorbar(im, ax=ax)\n    ax.set_title(\"Spatial Binned Trial\")\n    ax.set_xlabel(\"Spatial Bin\")\n    ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")\n\n    plt.show()\n\n\nwidgets.interact(vis_spatial_tc, ntrial=(0, pv_trials.shape[0] - 1, 1));\n</pre> def vis_spatial_tc(ntrial):     inbound_nrnorder = np.asarray(tc_in.get_peak_firing_order_ids()) - 1     outbound_nrnorder = np.asarray(tc_out.get_peak_firing_order_ids()) - 1     CMAP = \"terrain\"      fig, axes = plt.subplots(2, 3, figsize=(15, 10))     axes = axes.ravel()     scaler = sklearn.preprocessing.MinMaxScaler()     zscored_tc_in = scaler.fit_transform(tc_in.ratemap.T).T     zscored_tc_out = scaler.fit_transform(tc_out.ratemap.T).T     zscored_trial = scaler.fit_transform(pv_trials[ntrial])      ax = axes[0]     im = ax.imshow(         zscored_tc_in[inbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Tuning Curves Inbound\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")      ax = axes[1]     im = ax.imshow(         zscored_tc_out[inbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Tuning Curves Outbound\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")      ax = axes[2]     im = ax.imshow(         zscored_trial.T[inbound_nrnorder],         aspect=\"auto\",         interpolation=\"none\",         cmap=CMAP,     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Spatial Binned Trial\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in inbound TC)\")      ax = axes[3]     im = ax.imshow(         zscored_tc_in[outbound_nrnorder], aspect=\"auto\", interpolation=\"none\", cmap=CMAP     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Tuning Curves Inbound\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")      ax = axes[4]     im = ax.imshow(         zscored_tc_out[outbound_nrnorder],         aspect=\"auto\",         interpolation=\"none\",         cmap=CMAP,     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Tuning Curves Outbound\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")      ax = axes[5]     im = ax.imshow(         zscored_trial.T[outbound_nrnorder],         aspect=\"auto\",         interpolation=\"none\",         cmap=CMAP,     )     plt.colorbar(im, ax=ax)     ax.set_title(\"Spatial Binned Trial\")     ax.set_xlabel(\"Spatial Bin\")     ax.set_ylabel(\"Neurons (sorted by peak firing order in outbound TC)\")      plt.show()   widgets.interact(vis_spatial_tc, ntrial=(0, pv_trials.shape[0] - 1, 1)); <pre>interactive(children=(IntSlider(value=41, description='ntrial', max=83), Output()), _dom_classes=('widget-inte\u2026</pre> <p>We first visualize the population vector trajectories using Principal Component Analysis (PCA) and then compute the proximity and cosine similarity.</p> <p>While for simple cases, the proximity and cosine similarity can be interpreted from the PCA plot, the <code>proximity</code> and <code>cosine_similarity</code> functions provide a quantitative measure of the representational geometry and dynamics between the two population vector trajectories in the high-dimensional neural state space.</p> In\u00a0[8]: Copied! <pre># Preprocessing and PCA\nscaler = sklearn.preprocessing.StandardScaler()\npca = sklearn.decomposition.PCA(n_components=3)\n\nbst = pv_trials.reshape(-1, pv_trials.shape[-1])  # (n_trials * n_neurons, n_bins)\nbst = scaler.fit_transform(bst)\nclip = 4\nbst = np.clip(bst, -clip, clip)\nbst = pca.fit_transform(bst)\n\nscaled_tc_in = scaler.transform(tc_in.ratemap.T)\nscaled_tc_in = np.clip(scaled_tc_in, -clip, clip)\nscaled_tc_out = scaler.transform(tc_out.ratemap.T)\nscaled_tc_out = np.clip(scaled_tc_out, -clip, clip)\npca.fit(scaled_tc_in)\npca_tc_in = pca.transform(scaled_tc_in)\npca_tc_out = pca.transform(scaled_tc_out)\n\nproximity = npy.ensemble.proximity(tc_in.ratemap.T, tc_out.ratemap.T)\n\ncossim = npy.ensemble.cosine_similarity(\n    np.gradient(tc_in.ratemap.T, axis=0), np.gradient(tc_out.ratemap.T, axis=0)\n)\n\n# Create figure and axes\nfig = plt.figure(figsize=(6, 10))\nax3d = fig.add_subplot(111, projection=\"3d\")\n# ax = fig.add_subplot(111)\n\n\n# Function to update the plot for each frame\ndef update(num, x, y, z1, z2):\n    ax3d.cla()  # Clear the current axes\n    # set limits of axes to be consistent on basis of all data\n    ax3d.set_xlim(\n        min(pca_tc_in[:, 0].min(), pca_tc_out[:, 0].min()),\n        max(pca_tc_in[:, 0].max(), pca_tc_out[:, 0].max()),\n    )\n    ax3d.set_ylim(\n        min(pca_tc_in[:, 1].min(), pca_tc_out[:, 1].min()),\n        max(pca_tc_in[:, 1].max(), pca_tc_out[:, 1].max()),\n    )\n    ax3d.set_zlim(\n        min(pca_tc_in[:, 2].min(), pca_tc_out[:, 2].min()),\n        max(pca_tc_in[:, 2].max(), pca_tc_out[:, 2].max()),\n    )\n    ax3d.scatter(x[:num], y[:num], z1[:num], color=\"tab:blue\", s=100, label=\"Inbound\")\n    ax3d.plot(x[:num], y[:num], z1[:num], color=\"tab:blue\", alpha=0.25)\n    ax3d.scatter(x[:num], y[:num], z2[:num], color=\"tab:green\", s=100, label=\"Outbound\")\n    ax3d.plot(x[:num], y[:num], z2[:num], color=\"tab:green\", alpha=0.25)\n\n    # Set labels and title\n    ax3d.set_xlabel(\"PC1\")\n    ax3d.set_ylabel(\"PC2\")\n    ax3d.set_zlabel(\"PC3\")\n    ax3d.set_title(\"Trajectories of tuning curves in PCA space\")\n    ax3d.legend()\n\n\n# Create animation\nani = FuncAnimation(\n    fig,\n    update,\n    frames=len(pca_tc_in),  # Number of frames in the animation\n    fargs=(pca_tc_in[:, 0], pca_tc_in[:, 1], pca_tc_in[:, 2], pca_tc_out[:, 2]),\n    interval=100,  # Interval between frames in milliseconds\n)\n\nHTML(ani.to_jshtml())\n</pre> # Preprocessing and PCA scaler = sklearn.preprocessing.StandardScaler() pca = sklearn.decomposition.PCA(n_components=3)  bst = pv_trials.reshape(-1, pv_trials.shape[-1])  # (n_trials * n_neurons, n_bins) bst = scaler.fit_transform(bst) clip = 4 bst = np.clip(bst, -clip, clip) bst = pca.fit_transform(bst)  scaled_tc_in = scaler.transform(tc_in.ratemap.T) scaled_tc_in = np.clip(scaled_tc_in, -clip, clip) scaled_tc_out = scaler.transform(tc_out.ratemap.T) scaled_tc_out = np.clip(scaled_tc_out, -clip, clip) pca.fit(scaled_tc_in) pca_tc_in = pca.transform(scaled_tc_in) pca_tc_out = pca.transform(scaled_tc_out)  proximity = npy.ensemble.proximity(tc_in.ratemap.T, tc_out.ratemap.T)  cossim = npy.ensemble.cosine_similarity(     np.gradient(tc_in.ratemap.T, axis=0), np.gradient(tc_out.ratemap.T, axis=0) )  # Create figure and axes fig = plt.figure(figsize=(6, 10)) ax3d = fig.add_subplot(111, projection=\"3d\") # ax = fig.add_subplot(111)   # Function to update the plot for each frame def update(num, x, y, z1, z2):     ax3d.cla()  # Clear the current axes     # set limits of axes to be consistent on basis of all data     ax3d.set_xlim(         min(pca_tc_in[:, 0].min(), pca_tc_out[:, 0].min()),         max(pca_tc_in[:, 0].max(), pca_tc_out[:, 0].max()),     )     ax3d.set_ylim(         min(pca_tc_in[:, 1].min(), pca_tc_out[:, 1].min()),         max(pca_tc_in[:, 1].max(), pca_tc_out[:, 1].max()),     )     ax3d.set_zlim(         min(pca_tc_in[:, 2].min(), pca_tc_out[:, 2].min()),         max(pca_tc_in[:, 2].max(), pca_tc_out[:, 2].max()),     )     ax3d.scatter(x[:num], y[:num], z1[:num], color=\"tab:blue\", s=100, label=\"Inbound\")     ax3d.plot(x[:num], y[:num], z1[:num], color=\"tab:blue\", alpha=0.25)     ax3d.scatter(x[:num], y[:num], z2[:num], color=\"tab:green\", s=100, label=\"Outbound\")     ax3d.plot(x[:num], y[:num], z2[:num], color=\"tab:green\", alpha=0.25)      # Set labels and title     ax3d.set_xlabel(\"PC1\")     ax3d.set_ylabel(\"PC2\")     ax3d.set_zlabel(\"PC3\")     ax3d.set_title(\"Trajectories of tuning curves in PCA space\")     ax3d.legend()   # Create animation ani = FuncAnimation(     fig,     update,     frames=len(pca_tc_in),  # Number of frames in the animation     fargs=(pca_tc_in[:, 0], pca_tc_in[:, 1], pca_tc_in[:, 2], pca_tc_out[:, 2]),     interval=100,  # Interval between frames in milliseconds )  HTML(ani.to_jshtml()) Out[8]: Once Loop Reflect In\u00a0[9]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(10, 5))\naxes[0].plot(npy.ensemble.proximity(tc_in.ratemap.T, tc_out.ratemap.T))\naxes[0].set_title(\"Proximity\")\naxes[0].set_xlabel(\"Spatial bin\")\naxes[0].set_ylabel(\"Proximity\")\n\naxes[1].plot(\n    npy.ensemble.cosine_similarity(\n        np.gradient(tc_in.ratemap.T, axis=0), np.gradient(tc_out.ratemap.T, axis=0)\n    )\n)\naxes[1].set_title(\"Cosine similarity of dynamics\")\naxes[1].set_xlabel(\"Spatial bin\")\naxes[1].set_ylabel(\"Cosine similarity\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(10, 5)) axes[0].plot(npy.ensemble.proximity(tc_in.ratemap.T, tc_out.ratemap.T)) axes[0].set_title(\"Proximity\") axes[0].set_xlabel(\"Spatial bin\") axes[0].set_ylabel(\"Proximity\")  axes[1].plot(     npy.ensemble.cosine_similarity(         np.gradient(tc_in.ratemap.T, axis=0), np.gradient(tc_out.ratemap.T, axis=0)     ) ) axes[1].set_title(\"Cosine similarity of dynamics\") axes[1].set_xlabel(\"Spatial bin\") axes[1].set_ylabel(\"Cosine similarity\")  plt.tight_layout() plt.show() <p>Finally, we visualize the evolution of the proximity and cosine similarity between the two population vector trajectories over spatial bins.</p> In\u00a0[10]: Copied! <pre># Create figure and axes\nfig = plt.figure(figsize=(10, 6), constrained_layout=True)\nnrows, ncols = 4, 6\ngs = matplotlib.gridspec.GridSpec(*(nrows, ncols), figure=fig)\nax3d = fig.add_subplot(gs[0:4, 0:4], projection=\"3d\")\nax_proximity = fig.add_subplot(gs[0:2, 4:6])\nax_cossim = fig.add_subplot(gs[2:4, 4:6])\n\n# Initialize plots\nax_proximity.set_title(\"Proximity\")\nax_proximity.set_xlabel(\"Spatial bin\")\nax_proximity.set_ylabel(\"Proximity\")\nax_cossim.set_title(\"Cosine Similarity\")\nax_cossim.set_xlabel(\"Spatial bin\")\nax_cossim.set_ylabel(\"Cosine Similarity\")\n\n\n# Function to update the plots for each frame\ndef update(num, x, y, z1, z2):\n    ax3d.cla()  # Clear the current axes\n    # set limits of axes to be consistent on basis of all data\n    ax3d.set_xlim(\n        min(pca_tc_in[:, 0].min(), pca_tc_out[:, 0].min()),\n        max(pca_tc_in[:, 0].max(), pca_tc_out[:, 0].max()),\n    )\n    ax3d.set_ylim(\n        min(pca_tc_in[:, 1].min(), pca_tc_out[:, 1].min()),\n        max(pca_tc_in[:, 1].max(), pca_tc_out[:, 1].max()),\n    )\n    ax3d.set_zlim(\n        min(pca_tc_in[:, 2].min(), pca_tc_out[:, 2].min()),\n        max(pca_tc_in[:, 2].max(), pca_tc_out[:, 2].max()),\n    )\n    ax3d.scatter(x[:num], y[:num], z1[:num], color=\"tab:blue\", s=100, label=\"Inbound\")\n    ax3d.plot(x[:num], y[:num], z1[:num], color=\"tab:blue\", alpha=0.25)\n    ax3d.scatter(x[:num], y[:num], z2[:num], color=\"tab:green\", s=100, label=\"Outbound\")\n    ax3d.plot(x[:num], y[:num], z2[:num], color=\"tab:green\", alpha=0.25)\n\n    # Update proximity plot\n    ax_proximity.cla()\n    ax_proximity.set_xlim(-2, len(proximity))\n    ax_proximity.set_ylim(proximity.min(), proximity.max())\n    ax_proximity.plot(range(num), proximity[:num], color=\"tab:blue\")\n    ax_proximity.set_title(\"Proximity\")\n    ax_proximity.set_xlabel(\"Spatial bin\")\n    ax_proximity.set_ylabel(\"Proximity\")\n\n    # Update cosine similarity plot\n    ax_cossim.cla()\n    ax_cossim.set_xlim(-2, len(cossim))\n    ax_cossim.set_ylim(cossim.min(), cossim.max())\n    ax_cossim.plot(range(num), cossim[:num], color=\"tab:green\")\n    ax_cossim.set_title(\"Cosine Similarity\")\n    ax_cossim.set_xlabel(\"Spatial bin\")\n    ax_cossim.set_ylabel(\"Cosine Similarity\")\n\n\n# Create animation\nani = FuncAnimation(\n    fig,\n    update,\n    frames=len(pca_tc_in),  # Number of frames in the animation\n    fargs=(pca_tc_in[:, 0], pca_tc_in[:, 1], pca_tc_in[:, 2], pca_tc_out[:, 2]),\n    interval=150,  # Interval between frames in milliseconds\n)\n\nHTML(ani.to_jshtml())\n</pre> # Create figure and axes fig = plt.figure(figsize=(10, 6), constrained_layout=True) nrows, ncols = 4, 6 gs = matplotlib.gridspec.GridSpec(*(nrows, ncols), figure=fig) ax3d = fig.add_subplot(gs[0:4, 0:4], projection=\"3d\") ax_proximity = fig.add_subplot(gs[0:2, 4:6]) ax_cossim = fig.add_subplot(gs[2:4, 4:6])  # Initialize plots ax_proximity.set_title(\"Proximity\") ax_proximity.set_xlabel(\"Spatial bin\") ax_proximity.set_ylabel(\"Proximity\") ax_cossim.set_title(\"Cosine Similarity\") ax_cossim.set_xlabel(\"Spatial bin\") ax_cossim.set_ylabel(\"Cosine Similarity\")   # Function to update the plots for each frame def update(num, x, y, z1, z2):     ax3d.cla()  # Clear the current axes     # set limits of axes to be consistent on basis of all data     ax3d.set_xlim(         min(pca_tc_in[:, 0].min(), pca_tc_out[:, 0].min()),         max(pca_tc_in[:, 0].max(), pca_tc_out[:, 0].max()),     )     ax3d.set_ylim(         min(pca_tc_in[:, 1].min(), pca_tc_out[:, 1].min()),         max(pca_tc_in[:, 1].max(), pca_tc_out[:, 1].max()),     )     ax3d.set_zlim(         min(pca_tc_in[:, 2].min(), pca_tc_out[:, 2].min()),         max(pca_tc_in[:, 2].max(), pca_tc_out[:, 2].max()),     )     ax3d.scatter(x[:num], y[:num], z1[:num], color=\"tab:blue\", s=100, label=\"Inbound\")     ax3d.plot(x[:num], y[:num], z1[:num], color=\"tab:blue\", alpha=0.25)     ax3d.scatter(x[:num], y[:num], z2[:num], color=\"tab:green\", s=100, label=\"Outbound\")     ax3d.plot(x[:num], y[:num], z2[:num], color=\"tab:green\", alpha=0.25)      # Update proximity plot     ax_proximity.cla()     ax_proximity.set_xlim(-2, len(proximity))     ax_proximity.set_ylim(proximity.min(), proximity.max())     ax_proximity.plot(range(num), proximity[:num], color=\"tab:blue\")     ax_proximity.set_title(\"Proximity\")     ax_proximity.set_xlabel(\"Spatial bin\")     ax_proximity.set_ylabel(\"Proximity\")      # Update cosine similarity plot     ax_cossim.cla()     ax_cossim.set_xlim(-2, len(cossim))     ax_cossim.set_ylim(cossim.min(), cossim.max())     ax_cossim.plot(range(num), cossim[:num], color=\"tab:green\")     ax_cossim.set_title(\"Cosine Similarity\")     ax_cossim.set_xlabel(\"Spatial bin\")     ax_cossim.set_ylabel(\"Cosine Similarity\")   # Create animation ani = FuncAnimation(     fig,     update,     frames=len(pca_tc_in),  # Number of frames in the animation     fargs=(pca_tc_in[:, 0], pca_tc_in[:, 1], pca_tc_in[:, 2], pca_tc_out[:, 2]),     interval=150,  # Interval between frames in milliseconds )  HTML(ani.to_jshtml()) Out[10]: Once Loop Reflect"},{"location":"tutorials/neural_geodynamics/#neural-trajectories-comparative-geometry-and-dynamics","title":"Neural Trajectories Comparative Geometry and Dynamics\u00b6","text":"<p>Here, we will show how to use the <code>proximity</code> and <code>cosine_similarity</code> functions to analyze the representational geometry and dynamics between two population vector trajectories.</p>"},{"location":"tutorials/neural_geodynamics/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/neural_geodynamics/#section-1-proximity-and-cosine-similarity-of-dynamics-of-simulated-data","title":"Section 1: Proximity and cosine similarity of dynamics of simulated data\u00b6","text":""},{"location":"tutorials/neural_geodynamics/#section-2-proximity-and-cosine-similarity-of-dynamics-of-real-data","title":"Section 2: Proximity and cosine similarity of dynamics of real data\u00b6","text":""},{"location":"tutorials/neural_geodynamics/#section-21-load-data","title":"Section 2.1: Load data\u00b6","text":""},{"location":"tutorials/neural_geodynamics/#section-22-compute-population-vectors-trajectories-in-space","title":"Section 2.2: Compute population vectors trajectories in space\u00b6","text":""},{"location":"tutorials/neural_geodynamics/#section-23-visualize-single-neuron-tuning-properties-in-relation-to-the-behavioral-trajectory","title":"Section 2.3: Visualize single neuron tuning properties in relation to the behavioral trajectory\u00b6","text":"<p>Visualize the spatial tuning curves of the neurons such that the neurons are sorted by their peak firing order in the inbound and outbound tuning curves</p>"},{"location":"tutorials/neural_geodynamics/#section-24-compute-the-proximity-and-cosine-similarity-of-the-dynamics-of-the-population-vector-trajectories","title":"Section 2.4: Compute the proximity and cosine similarity of the dynamics of the population vector trajectories\u00b6","text":""},{"location":"tutorials/peth_tutorial/","title":"PETH","text":"In\u00a0[26]: Copied! <pre>import matplotlib.pyplot as plt\nimport nelpy as nel\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport neuro_py as npy\nfrom neuro_py.io import loading\nfrom neuro_py.process.peri_event import peth\n\nnpy.plotting.set_plotting_defaults()\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n</pre> import matplotlib.pyplot as plt import nelpy as nel import numpy as np import pandas as pd import seaborn as sns  import neuro_py as npy from neuro_py.io import loading from neuro_py.process.peri_event import peth  npy.plotting.set_plotting_defaults() %matplotlib inline %config InlineBackend.figure_format = 'retina' In\u00a0[27]: Copied! <pre># Set session path\nbasepath = r\"S:\\data\\HMC\\HMC1\\day8\"\n\n# Define LFP channels of interest:\n#  - ripple_channel (261): CA1 pyramidal layer (ripple-rich)\n#  - sharp_wave_channel (282): CA1 region (source of sharp waves)\n#  - delta_channel (53): PFC region with delta oscillations during NREM\nripple_channel = 261\nsharp_wave_channel = 282\ndelta_channel = 53\n\n# Load spike trains with metadata\n# Filter: only include cells recorded from CA1 and PFC with putative type 'Pyr' (pyramidal)\nst, cell_metrics = npy.io.load_spikes(\n    basepath, brainRegion=\"CA1|PFC\", putativeCellType=\"Pyr\"\n)\n\n# Create binary masks for brain region separation\nca1_idx = cell_metrics.brainRegion.str.contains(\"CA1\").values\npfc_idx = cell_metrics.brainRegion.str.contains(\"PFC\").values\n\n# Load ripple events (sharp-wave ripple complexes)\n# Ripples are high-frequency oscillations (100-200 Hz) that occur during sleep and offline states\nripples = npy.io.load_ripples_events(basepath, return_epoch_array=False)\nripples = nel.EventArray(\n    ripples.peaks.values, fs=1250\n)  # Convert ripple peaks to nelpy EventArray for analysis\n\n# Load delta wave events (1-4 Hz oscillations during NREM sleep)\ndeltas = npy.io.load_events(basepath, epoch_name=\"deltaWaves\", load_pandas=True)\ndeltas = nel.EventArray(deltas.peaks.values, fs=1250)\n\n# Load behavioral state annotations (wake, NREM sleep, REM sleep)\n# We'll restrict LFP analysis to NREM-only epochs for state consistency\nsleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)\n\n# restrict ripples and deltas to NREM epochs only\nnrem_epochs = sleep_states.get(\"NREM\")\nripples = ripples[sleep_states[\"NREMstate\"]]\ndeltas = deltas[sleep_states[\"NREMstate\"]]\n\n# Load continuous LFP signal\n# First, read XML file to get channel count and sampling rate\nnChannels, fs, fs_dat, shank_to_channel = loading.loadXML(basepath)\n# Then, load LFP data at specified frequency (typically downsampled from raw)\n# Returns: lfp (nTimepoints \u00d7 nChannels), ts (time vector)\nlfp, ts = loading.loadLFP(basepath, n_channels=nChannels, frequency=fs, ext=\"lfp\")\n</pre> # Set session path basepath = r\"S:\\data\\HMC\\HMC1\\day8\"  # Define LFP channels of interest: #  - ripple_channel (261): CA1 pyramidal layer (ripple-rich) #  - sharp_wave_channel (282): CA1 region (source of sharp waves) #  - delta_channel (53): PFC region with delta oscillations during NREM ripple_channel = 261 sharp_wave_channel = 282 delta_channel = 53  # Load spike trains with metadata # Filter: only include cells recorded from CA1 and PFC with putative type 'Pyr' (pyramidal) st, cell_metrics = npy.io.load_spikes(     basepath, brainRegion=\"CA1|PFC\", putativeCellType=\"Pyr\" )  # Create binary masks for brain region separation ca1_idx = cell_metrics.brainRegion.str.contains(\"CA1\").values pfc_idx = cell_metrics.brainRegion.str.contains(\"PFC\").values  # Load ripple events (sharp-wave ripple complexes) # Ripples are high-frequency oscillations (100-200 Hz) that occur during sleep and offline states ripples = npy.io.load_ripples_events(basepath, return_epoch_array=False) ripples = nel.EventArray(     ripples.peaks.values, fs=1250 )  # Convert ripple peaks to nelpy EventArray for analysis  # Load delta wave events (1-4 Hz oscillations during NREM sleep) deltas = npy.io.load_events(basepath, epoch_name=\"deltaWaves\", load_pandas=True) deltas = nel.EventArray(deltas.peaks.values, fs=1250)  # Load behavioral state annotations (wake, NREM sleep, REM sleep) # We'll restrict LFP analysis to NREM-only epochs for state consistency sleep_states = npy.io.load_SleepState_states(basepath, return_epoch_array=True)  # restrict ripples and deltas to NREM epochs only nrem_epochs = sleep_states.get(\"NREM\") ripples = ripples[sleep_states[\"NREMstate\"]] deltas = deltas[sleep_states[\"NREMstate\"]]  # Load continuous LFP signal # First, read XML file to get channel count and sampling rate nChannels, fs, fs_dat, shank_to_channel = loading.loadXML(basepath) # Then, load LFP data at specified frequency (typically downsampled from raw) # Returns: lfp (nTimepoints \u00d7 nChannels), ts (time vector) lfp, ts = loading.loadLFP(basepath, n_channels=nChannels, frequency=fs, ext=\"lfp\") <pre>WARNING:root:ignoring events outside of eventarray support\nWARNING:root:ignoring events outside of eventarray support\n</pre> In\u00a0[28]: Copied! <pre>window = [-1, 1]\nbin_width = 0.01\n</pre> window = [-1, 1] bin_width = 0.01 In\u00a0[29]: Copied! <pre># restrict spike trains to NREM epochs only for state-specific analysis\nst_nrem = st[sleep_states[\"NREMstate\"]]\n\n# Compute PETH for all pyramidal cells aligned to ripples\n# Returns DataFrame with shape (n_time_bins, n_units)\npeth_st_swr = peth(\n    st_nrem,\n    ripples.data[0, :],\n    bin_width=bin_width,\n    window=window,\n)\n\n# Compute PETH for all pyramidal cells aligned to delta waves\npeth_st_delta = peth(\n    st_nrem,\n    deltas.data[0, :],\n    bin_width=bin_width,\n    window=window,\n)\n\n# Index by brain region for visualization\npeth_st_swr_ca1 = peth_st_swr.iloc[:, ca1_idx]\npeth_st_swr_pfc = peth_st_swr.iloc[:, pfc_idx]\npeth_st_delta_ca1 = peth_st_delta.iloc[:, ca1_idx]\npeth_st_delta_pfc = peth_st_delta.iloc[:, pfc_idx]\n\n# Create 2\u00d72 subplot grid: rows=regions (CA1, PFC), columns=event types (ripples, deltas)\nfig, axes = plt.subplots(\n    2,\n    2,\n    figsize=npy.plotting.set_size(\"paper\", 1, subplots=(2, 2)),\n    sharex=True,  # Share x-axis for easy comparison\n    dpi=150,\n)\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\n\n# Plot PETH results: plot_peth_fast() shows mean \u00b1 SEM\nnpy.plotting.plot_peth_fast(peth_st_swr_ca1, ax=axes[0, 0])\nnpy.plotting.plot_peth_fast(peth_st_delta_ca1, ax=axes[0, 1])\nnpy.plotting.plot_peth_fast(peth_st_swr_pfc, ax=axes[1, 0])\nnpy.plotting.plot_peth_fast(peth_st_delta_pfc, ax=axes[1, 1])\n\n# Add vertical line at event time (t=0) for visual reference\nfor ax in axes.ravel():\n    ax.axvline(0, color=\"k\", ls=\"--\", lw=1, zorder=-10)  # Event marker\n    ax.set_ylabel(\"Firing rate (Hz)\")\n\n# Label axes by event type\naxes[0, 0].set_xlabel(\"Time from ripple (s)\")\naxes[0, 1].set_xlabel(\"Time from delta (s)\")\naxes[1, 0].set_xlabel(\"Time from ripple (s)\")\naxes[1, 1].set_xlabel(\"Time from delta (s)\")\n\n# Label axes by brain region and event type\naxes[0, 0].set_title(\"CA1 pyramidal cells - Ripples\")\naxes[0, 1].set_title(\"CA1 pyramidal cells - Delta waves\")\naxes[1, 0].set_title(\"PFC pyramidal cells - Ripples\")\naxes[1, 1].set_title(\"PFC pyramidal cells - Delta waves\")\n</pre> # restrict spike trains to NREM epochs only for state-specific analysis st_nrem = st[sleep_states[\"NREMstate\"]]  # Compute PETH for all pyramidal cells aligned to ripples # Returns DataFrame with shape (n_time_bins, n_units) peth_st_swr = peth(     st_nrem,     ripples.data[0, :],     bin_width=bin_width,     window=window, )  # Compute PETH for all pyramidal cells aligned to delta waves peth_st_delta = peth(     st_nrem,     deltas.data[0, :],     bin_width=bin_width,     window=window, )  # Index by brain region for visualization peth_st_swr_ca1 = peth_st_swr.iloc[:, ca1_idx] peth_st_swr_pfc = peth_st_swr.iloc[:, pfc_idx] peth_st_delta_ca1 = peth_st_delta.iloc[:, ca1_idx] peth_st_delta_pfc = peth_st_delta.iloc[:, pfc_idx]  # Create 2\u00d72 subplot grid: rows=regions (CA1, PFC), columns=event types (ripples, deltas) fig, axes = plt.subplots(     2,     2,     figsize=npy.plotting.set_size(\"paper\", 1, subplots=(2, 2)),     sharex=True,  # Share x-axis for easy comparison     dpi=150, ) plt.subplots_adjust(wspace=0.2, hspace=0.5)  # Plot PETH results: plot_peth_fast() shows mean \u00b1 SEM npy.plotting.plot_peth_fast(peth_st_swr_ca1, ax=axes[0, 0]) npy.plotting.plot_peth_fast(peth_st_delta_ca1, ax=axes[0, 1]) npy.plotting.plot_peth_fast(peth_st_swr_pfc, ax=axes[1, 0]) npy.plotting.plot_peth_fast(peth_st_delta_pfc, ax=axes[1, 1])  # Add vertical line at event time (t=0) for visual reference for ax in axes.ravel():     ax.axvline(0, color=\"k\", ls=\"--\", lw=1, zorder=-10)  # Event marker     ax.set_ylabel(\"Firing rate (Hz)\")  # Label axes by event type axes[0, 0].set_xlabel(\"Time from ripple (s)\") axes[0, 1].set_xlabel(\"Time from delta (s)\") axes[1, 0].set_xlabel(\"Time from ripple (s)\") axes[1, 1].set_xlabel(\"Time from delta (s)\")  # Label axes by brain region and event type axes[0, 0].set_title(\"CA1 pyramidal cells - Ripples\") axes[0, 1].set_title(\"CA1 pyramidal cells - Delta waves\") axes[1, 0].set_title(\"PFC pyramidal cells - Ripples\") axes[1, 1].set_title(\"PFC pyramidal cells - Delta waves\") <pre>WARNING:root:ignoring events outside of eventarray support\n</pre> Out[29]: <pre>Text(0.5, 1.0, 'PFC pyramidal cells - Delta waves')</pre> In\u00a0[30]: Copied! <pre># Restrict LFP analysis to NREM sleep epochs only\n# Sleep states have state-dependent effects on spike rates and LFP oscillations\n# NREM is standardized across animals, enabling clean signal averaging\nlfp_idx = npy.process.in_intervals(ts, sleep_states[\"NREMstate\"].data)\n\n# Create AnalogSignalArray with three channels of interest\n# data shape after selection: (3 channels, nTimepoints_in_NREM)\n# when we index lfp, we load lfp into memory\nlfp_asa = nel.AnalogSignalArray(\n    data=lfp[lfp_idx, :][:, [ripple_channel, sharp_wave_channel, delta_channel]].T,\n    abscissa_vals=ts[lfp_idx],  # Time vector aligned to selected epochs\n)\n\n# Compute event-triggered averages of LFP around ripples\n# Window = [-0.5, 0.5] sec provides finer temporal resolution for fast LFP dynamics\n# bin_width = 1/1250 sec = 0.8 ms (matched to LFP sampling rate)\npeth_lfp_swr = peth(lfp_asa, ripples.data[0, :], bin_width=1 / 1250, window=[-0.5, 0.5])\n\n# Compute event-triggered averages of LFP around delta waves\npeth_lfp_delta = peth(\n    lfp_asa, deltas.data[0, :], bin_width=1 / 1250, window=[-0.5, 0.5]\n)\n\n# Create 2\u00d73 subplot grid: rows=event type (ripples, deltas), columns=channels (ripple, sharp wave, delta)\nfig, axes = plt.subplots(\n    2, 3, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(2, 3)), dpi=150\n)\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\n\naxes = axes.ravel()\n\n# Top row: LFP modulation during ripple events\npeth_lfp_swr.iloc[:, 0].plot(ax=axes[0])\npeth_lfp_swr.iloc[:, 1].plot(ax=axes[1])\npeth_lfp_swr.iloc[:, 2].plot(ax=axes[2])\n\n# Bottom row: LFP modulation during delta wave events\npeth_lfp_delta.iloc[:, 0].plot(ax=axes[3])\npeth_lfp_delta.iloc[:, 1].plot(ax=axes[4])\npeth_lfp_delta.iloc[:, 2].plot(ax=axes[5])\n\n# Label columns by channel (top row titles)\naxes[0].set_title(\"Ripple channel (CA1)\")\naxes[1].set_title(\"Sharp wave channel (CA1)\")\naxes[2].set_title(\"Delta channel (PFC)\")\n\n# Label rows by event type (left column x-labels)\naxes[0].set_xlabel(\"Time from ripple (s)\")\naxes[1].set_xlabel(\"Time from ripple (s)\")\naxes[2].set_xlabel(\"Time from ripple (s)\")\n\naxes[3].set_xlabel(\"Time from delta (s)\")\naxes[4].set_xlabel(\"Time from delta (s)\")\naxes[5].set_xlabel(\"Time from delta (s)\")\n\n# Label y-axes\naxes[0].set_ylabel(\"Amplitude (\u03bcV)\")\naxes[3].set_ylabel(\"Amplitude (\u03bcV)\")\n\n# Add event marker line at t=0 to each plot\nfor ax_ in axes:\n    ax_.axvline(\n        0, color=\"k\", ls=\"--\", lw=1.5, alpha=0.7, zorder=-10\n    )  # Event onset marker\n    ax_.grid(True, alpha=0.3)\n</pre> # Restrict LFP analysis to NREM sleep epochs only # Sleep states have state-dependent effects on spike rates and LFP oscillations # NREM is standardized across animals, enabling clean signal averaging lfp_idx = npy.process.in_intervals(ts, sleep_states[\"NREMstate\"].data)  # Create AnalogSignalArray with three channels of interest # data shape after selection: (3 channels, nTimepoints_in_NREM) # when we index lfp, we load lfp into memory lfp_asa = nel.AnalogSignalArray(     data=lfp[lfp_idx, :][:, [ripple_channel, sharp_wave_channel, delta_channel]].T,     abscissa_vals=ts[lfp_idx],  # Time vector aligned to selected epochs )  # Compute event-triggered averages of LFP around ripples # Window = [-0.5, 0.5] sec provides finer temporal resolution for fast LFP dynamics # bin_width = 1/1250 sec = 0.8 ms (matched to LFP sampling rate) peth_lfp_swr = peth(lfp_asa, ripples.data[0, :], bin_width=1 / 1250, window=[-0.5, 0.5])  # Compute event-triggered averages of LFP around delta waves peth_lfp_delta = peth(     lfp_asa, deltas.data[0, :], bin_width=1 / 1250, window=[-0.5, 0.5] )  # Create 2\u00d73 subplot grid: rows=event type (ripples, deltas), columns=channels (ripple, sharp wave, delta) fig, axes = plt.subplots(     2, 3, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(2, 3)), dpi=150 ) plt.subplots_adjust(wspace=0.2, hspace=0.5)  axes = axes.ravel()  # Top row: LFP modulation during ripple events peth_lfp_swr.iloc[:, 0].plot(ax=axes[0]) peth_lfp_swr.iloc[:, 1].plot(ax=axes[1]) peth_lfp_swr.iloc[:, 2].plot(ax=axes[2])  # Bottom row: LFP modulation during delta wave events peth_lfp_delta.iloc[:, 0].plot(ax=axes[3]) peth_lfp_delta.iloc[:, 1].plot(ax=axes[4]) peth_lfp_delta.iloc[:, 2].plot(ax=axes[5])  # Label columns by channel (top row titles) axes[0].set_title(\"Ripple channel (CA1)\") axes[1].set_title(\"Sharp wave channel (CA1)\") axes[2].set_title(\"Delta channel (PFC)\")  # Label rows by event type (left column x-labels) axes[0].set_xlabel(\"Time from ripple (s)\") axes[1].set_xlabel(\"Time from ripple (s)\") axes[2].set_xlabel(\"Time from ripple (s)\")  axes[3].set_xlabel(\"Time from delta (s)\") axes[4].set_xlabel(\"Time from delta (s)\") axes[5].set_xlabel(\"Time from delta (s)\")  # Label y-axes axes[0].set_ylabel(\"Amplitude (\u03bcV)\") axes[3].set_ylabel(\"Amplitude (\u03bcV)\")  # Add event marker line at t=0 to each plot for ax_ in axes:     ax_.axvline(         0, color=\"k\", ls=\"--\", lw=1.5, alpha=0.7, zorder=-10     )  # Event onset marker     ax_.grid(True, alpha=0.3) <pre>WARNING:root:fs was not specified, so we try to estimate it from the data...\nWARNING:root:fs was estimated to be 1250.0000003137757 Hz\nWARNING:root:creating support from abscissa_vals and sampling rate, fs!\nWARNING:root:'fs' has been deprecated; use 'step' instead\nWARNING:root:some steps in the data are smaller than the requested step size.\n</pre> In\u00a0[31]: Copied! <pre># Get event-wise PETH matrix for CA1 units during ripples\n# Returns (n_time_bins, n_units, n_events) instead of averaged DataFrame\npeth_matrix_ca1, time_bins = peth(\n    st_nrem.iloc[:, ca1_idx],\n    ripples.data[0, :],\n    bin_width=bin_width,\n    window=window,\n    average=False,  # Returns individual event responses\n)\n\nprint(f\"Event-wise PETH matrix shape: {peth_matrix_ca1.shape}\")\nprint(f\"  - Time bins: {peth_matrix_ca1.shape[0]}\")\nprint(f\"  - CA1 units: {peth_matrix_ca1.shape[1]}\")\nprint(f\"  - Ripple events: {peth_matrix_ca1.shape[2]}\")\nprint(f\"\\nVerify: Averaging across events recovers the original PETH:\")\nmanual_avg = np.nanmean(peth_matrix_ca1, axis=2)\nprint(\n    f\"  Mean absolute difference: {np.abs(manual_avg - peth_st_swr_ca1.values).mean():.2e} Hz\"\n)\n\nfig, ax = plt.subplots(\n    1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1, 2)), dpi=150\n)\n\nnpy.plotting.plot_peth_fast(\n    manual_avg, ts=time_bins, ax=ax[0], label=\"averaged from event-wise matrix\"\n)\nnpy.plotting.plot_peth_fast(peth_st_swr_ca1, ax=ax[0], label=\"peth_st_swr_ca1\")\n\nnpy.plotting.plot_peth_fast(\n    manual_avg - peth_st_swr_ca1.values, ts=time_bins, ax=ax[1], label=\"difference\"\n)\nax[1].set_ylim(-0.001, 0.001)\n\nax[0].legend(loc=\"center left\", bbox_to_anchor=(0.1, 1))\nax[1].legend()\n\nax[0].set_ylabel(\"rate (Hz)\")\nax[1].set_ylabel(\"difference\")\n\nax[0].set_ylabel(\"Time from SWR (s)\")\nax[1].set_ylabel(\"Time from SWR (s)\")\n</pre> # Get event-wise PETH matrix for CA1 units during ripples # Returns (n_time_bins, n_units, n_events) instead of averaged DataFrame peth_matrix_ca1, time_bins = peth(     st_nrem.iloc[:, ca1_idx],     ripples.data[0, :],     bin_width=bin_width,     window=window,     average=False,  # Returns individual event responses )  print(f\"Event-wise PETH matrix shape: {peth_matrix_ca1.shape}\") print(f\"  - Time bins: {peth_matrix_ca1.shape[0]}\") print(f\"  - CA1 units: {peth_matrix_ca1.shape[1]}\") print(f\"  - Ripple events: {peth_matrix_ca1.shape[2]}\") print(f\"\\nVerify: Averaging across events recovers the original PETH:\") manual_avg = np.nanmean(peth_matrix_ca1, axis=2) print(     f\"  Mean absolute difference: {np.abs(manual_avg - peth_st_swr_ca1.values).mean():.2e} Hz\" )  fig, ax = plt.subplots(     1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1, 2)), dpi=150 )  npy.plotting.plot_peth_fast(     manual_avg, ts=time_bins, ax=ax[0], label=\"averaged from event-wise matrix\" ) npy.plotting.plot_peth_fast(peth_st_swr_ca1, ax=ax[0], label=\"peth_st_swr_ca1\")  npy.plotting.plot_peth_fast(     manual_avg - peth_st_swr_ca1.values, ts=time_bins, ax=ax[1], label=\"difference\" ) ax[1].set_ylim(-0.001, 0.001)  ax[0].legend(loc=\"center left\", bbox_to_anchor=(0.1, 1)) ax[1].legend()  ax[0].set_ylabel(\"rate (Hz)\") ax[1].set_ylabel(\"difference\")  ax[0].set_ylabel(\"Time from SWR (s)\") ax[1].set_ylabel(\"Time from SWR (s)\")  <pre>Event-wise PETH matrix shape: (201, 75, 3848)\n  - Time bins: 201\n  - CA1 units: 75\n  - Ripple events: 3848\n\nVerify: Averaging across events recovers the original PETH:\n  Mean absolute difference: 1.90e-16 Hz\n</pre> Out[31]: <pre>Text(0, 0.5, 'Time from SWR (s)')</pre> In\u00a0[32]: Copied! <pre># Calculate population response strength for each ripple event\n# Sum firing rate across all CA1 units and time bins within window\nca1_response_per_event = peth_matrix_ca1.mean(\n    axis=(0, 1)\n)  # Sum over time bins and units\n\n# Stratify ripples: top 25% strongest vs bottom 25% weakest CA1 responses\nstrong_threshold = np.percentile(ca1_response_per_event, 75)\nweak_threshold = np.percentile(ca1_response_per_event, 25)\n\nstrong_events = ca1_response_per_event &gt;= strong_threshold\nweak_events = ca1_response_per_event &lt;= weak_threshold\n\nprint(f\"Strong ripples (top 25%): {strong_events.sum()} events\")\nprint(f\"Weak ripples (bottom 25%): {weak_events.sum()} events\")\nprint(f\"CA1 response - Strong: {ca1_response_per_event[strong_events].mean():.1f} Hz\u00b7s\")\nprint(f\"CA1 response - Weak: {ca1_response_per_event[weak_events].mean():.1f} Hz\u00b7s\")\n\n\n# Now get PFC response for the same ripple events\npeth_matrix_pfc, _ = peth(\n    st_nrem.iloc[:, pfc_idx],\n    ripples.data[0, :],\n    bin_width=bin_width,\n    window=window,\n    average=False,\n)\n\n# Average PFC responses separately for strong vs weak CA1 ripple events\npfc_response_strong = np.nanmean(peth_matrix_pfc[:, :, strong_events], axis=2)\npfc_response_weak = np.nanmean(peth_matrix_pfc[:, :, weak_events], axis=2)\n\nprint(\n    f\"\\nInsight: PFC neurons show {pfc_response_strong.mean()/pfc_response_weak.mean():.2f}x higher firing \"\n    f\"during strong CA1 ripples compared to weak ones.\"\n)\n# Plot comparison\nfig, axes = plt.subplots(\n    1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1, 2)), dpi=150\n)\nplt.subplots_adjust(wspace=0.3)\n# Average across PFC units for visualization\nnpy.plotting.plot_peth_fast(\n    pfc_response_strong,\n    ts=time_bins,\n    ax=axes[0],\n    label=\"Strong CA1 ripples\",\n)\n\nnpy.plotting.plot_peth_fast(\n    pfc_response_weak,\n    ts=time_bins,\n    ax=axes[0],\n    label=\"Weak CA1 ripples\",\n)\n\naxes[0].axvline(0, color=\"k\", ls=\"--\", lw=1.5, alpha=0.7)\naxes[0].set_xlabel(\"Time from ripple (s)\")\naxes[0].set_ylabel(\"PFC firing rate (Hz)\")\naxes[0].set_title(\"PFC Response to Strong vs Weak CA1 Ripples\")\naxes[0].legend(loc=\"center left\", bbox_to_anchor=(0.5, 1.3))\naxes[0].grid(True, alpha=0.3)\n\n# Show distribution of CA1 response strength\naxes[1].hist(\n    ca1_response_per_event, bins=30, alpha=0.7, color=\"gray\", edgecolor=\"black\"\n)\naxes[1].axvline(strong_threshold, color=\"C0\", ls=\"--\", lw=2, label=f\"Strong (top 25%)\")\naxes[1].axvline(weak_threshold, color=\"C1\", ls=\"--\", lw=2, label=f\"Weak (bottom 25%)\")\naxes[1].set_xlabel(\"CA1 population response (Hz\u00b7s)\")\naxes[1].set_ylabel(\"Number of ripples\")\naxes[1].set_title(\"Distribution of CA1 Ripple Strength\")\naxes[1].legend(loc=\"center left\", bbox_to_anchor=(0.5, 1.3))\naxes[1].grid(True, alpha=0.3)\n\n\nplt.show()\n</pre> # Calculate population response strength for each ripple event # Sum firing rate across all CA1 units and time bins within window ca1_response_per_event = peth_matrix_ca1.mean(     axis=(0, 1) )  # Sum over time bins and units  # Stratify ripples: top 25% strongest vs bottom 25% weakest CA1 responses strong_threshold = np.percentile(ca1_response_per_event, 75) weak_threshold = np.percentile(ca1_response_per_event, 25)  strong_events = ca1_response_per_event &gt;= strong_threshold weak_events = ca1_response_per_event &lt;= weak_threshold  print(f\"Strong ripples (top 25%): {strong_events.sum()} events\") print(f\"Weak ripples (bottom 25%): {weak_events.sum()} events\") print(f\"CA1 response - Strong: {ca1_response_per_event[strong_events].mean():.1f} Hz\u00b7s\") print(f\"CA1 response - Weak: {ca1_response_per_event[weak_events].mean():.1f} Hz\u00b7s\")   # Now get PFC response for the same ripple events peth_matrix_pfc, _ = peth(     st_nrem.iloc[:, pfc_idx],     ripples.data[0, :],     bin_width=bin_width,     window=window,     average=False, )  # Average PFC responses separately for strong vs weak CA1 ripple events pfc_response_strong = np.nanmean(peth_matrix_pfc[:, :, strong_events], axis=2) pfc_response_weak = np.nanmean(peth_matrix_pfc[:, :, weak_events], axis=2)  print(     f\"\\nInsight: PFC neurons show {pfc_response_strong.mean()/pfc_response_weak.mean():.2f}x higher firing \"     f\"during strong CA1 ripples compared to weak ones.\" ) # Plot comparison fig, axes = plt.subplots(     1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1, 2)), dpi=150 ) plt.subplots_adjust(wspace=0.3) # Average across PFC units for visualization npy.plotting.plot_peth_fast(     pfc_response_strong,     ts=time_bins,     ax=axes[0],     label=\"Strong CA1 ripples\", )  npy.plotting.plot_peth_fast(     pfc_response_weak,     ts=time_bins,     ax=axes[0],     label=\"Weak CA1 ripples\", )  axes[0].axvline(0, color=\"k\", ls=\"--\", lw=1.5, alpha=0.7) axes[0].set_xlabel(\"Time from ripple (s)\") axes[0].set_ylabel(\"PFC firing rate (Hz)\") axes[0].set_title(\"PFC Response to Strong vs Weak CA1 Ripples\") axes[0].legend(loc=\"center left\", bbox_to_anchor=(0.5, 1.3)) axes[0].grid(True, alpha=0.3)  # Show distribution of CA1 response strength axes[1].hist(     ca1_response_per_event, bins=30, alpha=0.7, color=\"gray\", edgecolor=\"black\" ) axes[1].axvline(strong_threshold, color=\"C0\", ls=\"--\", lw=2, label=f\"Strong (top 25%)\") axes[1].axvline(weak_threshold, color=\"C1\", ls=\"--\", lw=2, label=f\"Weak (bottom 25%)\") axes[1].set_xlabel(\"CA1 population response (Hz\u00b7s)\") axes[1].set_ylabel(\"Number of ripples\") axes[1].set_title(\"Distribution of CA1 Ripple Strength\") axes[1].legend(loc=\"center left\", bbox_to_anchor=(0.5, 1.3)) axes[1].grid(True, alpha=0.3)   plt.show()  <pre>Strong ripples (top 25%): 977 events\nWeak ripples (bottom 25%): 965 events\nCA1 response - Strong: 2.4 Hz\u00b7s\nCA1 response - Weak: 1.2 Hz\u00b7s\n\nInsight: PFC neurons show 1.31x higher firing during strong CA1 ripples compared to weak ones.\n</pre> In\u00a0[33]: Copied! <pre># For each ripple event, find the time of peak PFC population response\n# Average across all PFC units to get population response per event\npfc_population_response = peth_matrix_pfc.mean(axis=1)  # Shape: (n_time_bins, n_events)\n\n# Find time bin of peak response for each event\npeak_time_idx = np.argmax(pfc_population_response, axis=0)\npeak_times = time_bins[peak_time_idx]\n\n# Sort events by peak response time\nsort_order = np.argsort(peak_times)\n\nprint(\n    f\"PFC response latency range: [{peak_times.min():.3f}, {peak_times.max():.3f}] seconds\"\n)\nprint(f\"Mean latency: {peak_times.mean():.3f} s, Median: {np.median(peak_times):.3f} s\")\n\nprint(\n    f\"\\nThe sorted heatmap reveals temporal structure: PFC responses range from \"\n    f\"{peak_times.min():.0f} s to {peak_times.max():.0f} s after ripple onset.\"\n)\n\n# Create heatmap of PFC population response, sorted by latency\nfig, axes = plt.subplots(\n    1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1.5, 2)), dpi=150\n)\nplt.subplots_adjust(wspace=0.3)\n# Left: Unsorted events\nim1 = axes[0].imshow(\n    pfc_population_response.T,  # Events as rows\n    aspect=\"auto\",\n    extent=[time_bins[0], time_bins[-1], 0, ripples.n_events[0]],\n    cmap=\"magma\",\n    interpolation=\"gaussian\",\n    origin=\"lower\",\n    vmin=0,\n    vmax=np.percentile(pfc_population_response, 99),\n)\naxes[0].axvline(0, color=\"cyan\", ls=\"--\", lw=2, alpha=0.8)\naxes[0].set_xlabel(\"Time from ripple (s)\")\naxes[0].set_ylabel(\"Ripple event #\")\naxes[0].set_title(\"Unsorted Events\")\nplt.colorbar(im1, ax=axes[0], label=\"PFC rate (Hz)\", extend=\"max\")\n\n# Right: Sorted by peak response time\nim2 = axes[1].imshow(\n    pfc_population_response[:, sort_order].T,  # Sorted events\n    aspect=\"auto\",\n    extent=[time_bins[0], time_bins[-1], 0, ripples.n_events[0]],\n    cmap=\"magma\",\n    interpolation=\"gaussian\",\n    origin=\"lower\",\n    vmin=0,\n    vmax=np.percentile(pfc_population_response, 99),\n)\naxes[1].axvline(0, color=\"cyan\", ls=\"--\", lw=2, alpha=0.8)\n\naxes[1].set_xlabel(\"Time from ripple (s)\")\naxes[1].set_ylabel(\"Ripple event # (sorted by PFC latency)\")\naxes[1].set_title(\"Sorted by PFC Peak Latency\")\nplt.colorbar(im2, ax=axes[1], label=\"PFC rate (Hz)\", extend=\"max\")\naxes[0].grid(False)\naxes[1].grid(False)\nplt.show()\n</pre> # For each ripple event, find the time of peak PFC population response # Average across all PFC units to get population response per event pfc_population_response = peth_matrix_pfc.mean(axis=1)  # Shape: (n_time_bins, n_events)  # Find time bin of peak response for each event peak_time_idx = np.argmax(pfc_population_response, axis=0) peak_times = time_bins[peak_time_idx]  # Sort events by peak response time sort_order = np.argsort(peak_times)  print(     f\"PFC response latency range: [{peak_times.min():.3f}, {peak_times.max():.3f}] seconds\" ) print(f\"Mean latency: {peak_times.mean():.3f} s, Median: {np.median(peak_times):.3f} s\")  print(     f\"\\nThe sorted heatmap reveals temporal structure: PFC responses range from \"     f\"{peak_times.min():.0f} s to {peak_times.max():.0f} s after ripple onset.\" )  # Create heatmap of PFC population response, sorted by latency fig, axes = plt.subplots(     1, 2, figsize=npy.plotting.set_size(\"paper\", 1, subplots=(1.5, 2)), dpi=150 ) plt.subplots_adjust(wspace=0.3) # Left: Unsorted events im1 = axes[0].imshow(     pfc_population_response.T,  # Events as rows     aspect=\"auto\",     extent=[time_bins[0], time_bins[-1], 0, ripples.n_events[0]],     cmap=\"magma\",     interpolation=\"gaussian\",     origin=\"lower\",     vmin=0,     vmax=np.percentile(pfc_population_response, 99), ) axes[0].axvline(0, color=\"cyan\", ls=\"--\", lw=2, alpha=0.8) axes[0].set_xlabel(\"Time from ripple (s)\") axes[0].set_ylabel(\"Ripple event #\") axes[0].set_title(\"Unsorted Events\") plt.colorbar(im1, ax=axes[0], label=\"PFC rate (Hz)\", extend=\"max\")  # Right: Sorted by peak response time im2 = axes[1].imshow(     pfc_population_response[:, sort_order].T,  # Sorted events     aspect=\"auto\",     extent=[time_bins[0], time_bins[-1], 0, ripples.n_events[0]],     cmap=\"magma\",     interpolation=\"gaussian\",     origin=\"lower\",     vmin=0,     vmax=np.percentile(pfc_population_response, 99), ) axes[1].axvline(0, color=\"cyan\", ls=\"--\", lw=2, alpha=0.8)  axes[1].set_xlabel(\"Time from ripple (s)\") axes[1].set_ylabel(\"Ripple event # (sorted by PFC latency)\") axes[1].set_title(\"Sorted by PFC Peak Latency\") plt.colorbar(im2, ax=axes[1], label=\"PFC rate (Hz)\", extend=\"max\") axes[0].grid(False) axes[1].grid(False) plt.show()  <pre>PFC response latency range: [-1.000, 1.000] seconds\nMean latency: -0.145 s, Median: -0.180 s\n\nThe sorted heatmap reveals temporal structure: PFC responses range from -1 s to 1 s after ripple onset.\n</pre> In\u00a0[34]: Copied! <pre># load delta wave events with power information for sorting\ndeltas_df = npy.io.load_events(basepath, epoch_name=\"deltaWaves\", load_pandas=True)\ndelta_power = nel.AnalogSignalArray(\n    data=deltas_df.peakNormedPower.values, abscissa_vals=deltas_df.peaks.values\n)\ndelta_power = delta_power[sleep_states[\"NREMstate\"]]\n\n# Compute PETH of LFP around delta wave events, sorted by delta power\npeth_lfp_delta, time_bins = peth(\n    lfp_asa[:, 2],\n    deltas.data[0, :],\n    bin_width=1 / 1250,\n    window=[-0.5, 0.5],\n    average=False,\n)\npeth_lfp_delta = peth_lfp_delta[:, 0, :]\n\n# Sort delta wave events by their power and plot the LFP heatmap sorted by delta power\nidx = np.argsort(delta_power.data[0, :])\nplt.imshow(\n    peth_lfp_delta[:, idx].T,\n    aspect=\"auto\",\n    extent=[time_bins[0], time_bins[-1], 0, peth_lfp_delta.shape[1]],\n    cmap=\"magma\",\n    interpolation=\"gaussian\",\n    origin=\"lower\",\n    vmin=-4000,\n    vmax=4000,\n)\nplt.colorbar(label=\"LFP amplitude (\u03bcV)\", extend=\"both\")\nplt.ylabel(\"Delta wave event # (sorted by power)\")\nplt.xlabel(\"Time from delta wave (s)\")\nplt.title(\"LFP Modulation Around Delta Waves Sorted by Power\")\nplt.show()\n</pre> # load delta wave events with power information for sorting deltas_df = npy.io.load_events(basepath, epoch_name=\"deltaWaves\", load_pandas=True) delta_power = nel.AnalogSignalArray(     data=deltas_df.peakNormedPower.values, abscissa_vals=deltas_df.peaks.values ) delta_power = delta_power[sleep_states[\"NREMstate\"]]  # Compute PETH of LFP around delta wave events, sorted by delta power peth_lfp_delta, time_bins = peth(     lfp_asa[:, 2],     deltas.data[0, :],     bin_width=1 / 1250,     window=[-0.5, 0.5],     average=False, ) peth_lfp_delta = peth_lfp_delta[:, 0, :]  # Sort delta wave events by their power and plot the LFP heatmap sorted by delta power idx = np.argsort(delta_power.data[0, :]) plt.imshow(     peth_lfp_delta[:, idx].T,     aspect=\"auto\",     extent=[time_bins[0], time_bins[-1], 0, peth_lfp_delta.shape[1]],     cmap=\"magma\",     interpolation=\"gaussian\",     origin=\"lower\",     vmin=-4000,     vmax=4000, ) plt.colorbar(label=\"LFP amplitude (\u03bcV)\", extend=\"both\") plt.ylabel(\"Delta wave event # (sorted by power)\") plt.xlabel(\"Time from delta wave (s)\") plt.title(\"LFP Modulation Around Delta Waves Sorted by Power\") plt.show() <pre>WARNING:root:fs was not specified, so we try to estimate it from the data...\nWARNING:root:fs was estimated to be 1.084128360798541 Hz\nWARNING:root:creating support from abscissa_vals and sampling rate, fs!\nWARNING:root:'fs' has been deprecated; use 'step' instead\nWARNING:root:some steps in the data are smaller than the requested step size.\n</pre> <pre>WARNING:root:ignoring signal outside of support\n</pre> In\u00a0[35]: Copied! <pre>window = [-1, 1]\nlabels = [\"PFC spikes\", \"ripple\", \"delta\"]\n\n# get event-wise PETH matrix for PFC units during delta waves\npeth_1, ts = peth(\n    st_nrem.iloc[:, pfc_idx].flatten(),\n    deltas.data[0, :],\n    bin_width=0.02,\n    window=[-1, 1],\n    average=False,\n)\n# get event-wise PETH matrix for ripples during delta waves\npeth_2, ts = peth(\n    ripples.data[0, :], deltas.data[0, :], bin_width=0.02, window=[-1, 1], average=False\n)\n\nnpy.plotting.figure_helpers.plot_joint_peth(\n    peth_1[:, 0, :].T, peth_2[:, 0, :].T, ts, labels=labels, smooth_std=1\n)\n\nplt.show()\n</pre> window = [-1, 1] labels = [\"PFC spikes\", \"ripple\", \"delta\"]  # get event-wise PETH matrix for PFC units during delta waves peth_1, ts = peth(     st_nrem.iloc[:, pfc_idx].flatten(),     deltas.data[0, :],     bin_width=0.02,     window=[-1, 1],     average=False, ) # get event-wise PETH matrix for ripples during delta waves peth_2, ts = peth(     ripples.data[0, :], deltas.data[0, :], bin_width=0.02, window=[-1, 1], average=False )  npy.plotting.figure_helpers.plot_joint_peth(     peth_1[:, 0, :].T, peth_2[:, 0, :].T, ts, labels=labels, smooth_std=1 )  plt.show() In\u00a0[36]: Copied! <pre># For each ripple, find the time to the nearest delta wave\n_, next_delta_delay, _ = npy.process.nearest_event_delay(\n    ripples.data[0, :], deltas.data[0, :]\n)\n# place in DataFrame for easier filtering and sorting\nripple_df = pd.DataFrame()\nripple_df[\"starts\"] = ripples.data[0, :]\nripple_df[\"delta_delay\"] = next_delta_delay\n\n# remove ripples that are too far from delta waves and sort by time to delta wave\nstart, stop = window\n\n# sort ripples by time to nearest delta wave and restrict to those within window for visualization\nripple_df = ripple_df.query(\"delta_delay &gt; @start and delta_delay &lt; @stop\").sort_values(\n    \"delta_delay\"\n)\n\n# get event-wise PETH matrix for PFC units during ripples, sorted by delta delay\nX, t = peth(\n    st_nrem.iloc[:, pfc_idx].flatten(),\n    ripple_df.starts.values,\n    bin_width=0.02,\n    window=window,\n    average=False,\n)\n# flatten empty axis\nX = X[:, 0, :]\n# zscore each event separately to visualize relative modulation regardless of absolute firing rate differences\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\n# place in DataFrame for easier plotting with time as index and events as rows\npeth_df = pd.DataFrame(data=X, index=t)\n\n# downsample for visualization (e.g. 40 events per row)\na_downsampled = npy.util.shrink(\n    peth_df.values,\n    1,\n    40,\n)\nfig, (a0, a1) = plt.subplots(\n    2,\n    1,\n    gridspec_kw={\"height_ratios\": [1, 2]},\n    figsize=npy.plotting.set_size(\"thesis\", 0.8, subplots=(2.5, 1)),\n    sharex=True,\n    sharey=False,\n)\nnpy.plotting.plot_peth_fast(peth_df, ax=a0, color=\"k\")\na0.axvline(0, color=\"k\", linestyle=\"--\", zorder=-10)\n\nim = a1.imshow(\n    a_downsampled.T,\n    vmin=-1,\n    vmax=1,\n    cmap=\"coolwarm\",\n    aspect=\"auto\",\n    interpolation=\"none\",\n    extent=[peth_df.index[0], peth_df.index[-1], 0, peth_df.shape[1]],\n)\na1.axvline(0, c=\"w\", ls=\"--\")\n# make new axis for colorbar\ncax = a1.inset_axes([1.02, 0, 0.05, 1])\nplt.colorbar(im, cax=cax, label=\"Z-scored firing rate\", extend=\"both\")\n\na0.set_xlabel(\"Time from ripple (s)\")\na1.set_xlabel(\"Time from ripple (s)\")\na0.set_ylabel(\"Mean PFC firing rate (Z)\")\na1.set_ylabel(\"SWR events sorted by delta delay\")\n</pre> # For each ripple, find the time to the nearest delta wave _, next_delta_delay, _ = npy.process.nearest_event_delay(     ripples.data[0, :], deltas.data[0, :] ) # place in DataFrame for easier filtering and sorting ripple_df = pd.DataFrame() ripple_df[\"starts\"] = ripples.data[0, :] ripple_df[\"delta_delay\"] = next_delta_delay  # remove ripples that are too far from delta waves and sort by time to delta wave start, stop = window  # sort ripples by time to nearest delta wave and restrict to those within window for visualization ripple_df = ripple_df.query(\"delta_delay &gt; @start and delta_delay &lt; @stop\").sort_values(     \"delta_delay\" )  # get event-wise PETH matrix for PFC units during ripples, sorted by delta delay X, t = peth(     st_nrem.iloc[:, pfc_idx].flatten(),     ripple_df.starts.values,     bin_width=0.02,     window=window,     average=False, ) # flatten empty axis X = X[:, 0, :] # zscore each event separately to visualize relative modulation regardless of absolute firing rate differences X = (X - X.mean(axis=0)) / X.std(axis=0)  # place in DataFrame for easier plotting with time as index and events as rows peth_df = pd.DataFrame(data=X, index=t)  # downsample for visualization (e.g. 40 events per row) a_downsampled = npy.util.shrink(     peth_df.values,     1,     40, ) fig, (a0, a1) = plt.subplots(     2,     1,     gridspec_kw={\"height_ratios\": [1, 2]},     figsize=npy.plotting.set_size(\"thesis\", 0.8, subplots=(2.5, 1)),     sharex=True,     sharey=False, ) npy.plotting.plot_peth_fast(peth_df, ax=a0, color=\"k\") a0.axvline(0, color=\"k\", linestyle=\"--\", zorder=-10)  im = a1.imshow(     a_downsampled.T,     vmin=-1,     vmax=1,     cmap=\"coolwarm\",     aspect=\"auto\",     interpolation=\"none\",     extent=[peth_df.index[0], peth_df.index[-1], 0, peth_df.shape[1]], ) a1.axvline(0, c=\"w\", ls=\"--\") # make new axis for colorbar cax = a1.inset_axes([1.02, 0, 0.05, 1]) plt.colorbar(im, cax=cax, label=\"Z-scored firing rate\", extend=\"both\")  a0.set_xlabel(\"Time from ripple (s)\") a1.set_xlabel(\"Time from ripple (s)\") a0.set_ylabel(\"Mean PFC firing rate (Z)\") a1.set_ylabel(\"SWR events sorted by delta delay\")  Out[36]: <pre>Text(0, 0.5, 'SWR events sorted by delta delay')</pre>"},{"location":"tutorials/peth_tutorial/#peth-tutorial","title":"PETH Tutorial\u00b6","text":""},{"location":"tutorials/peth_tutorial/#overview-the-power-of-peth","title":"Overview: The Power of <code>peth</code>\u00b6","text":"<p>The <code>peth</code> function is a unified, high-level interface for computing peri-event time histograms (PETHs) across all major nelpy data types. Instead of writing separate analysis code for different neural signal types, <code>peth</code> handles the complexity seamlessly:</p> <p>What makes <code>peth</code> powerful:</p> <ul> <li>Universal input handling: Works with spike trains, events, continuous signals (LFP, position, accelerometer), and more</li> <li>Batch processing: Automatically aligns and aggregates multiple signals/cells without manual iteration loops</li> <li>Data type flexibility: Accepts nelpy objects (SpikeTrainArray, EventArray, AnalogSignalArray, PositionArray), binned data (BinnedSpikeTrainArray, BinnedEventArray), and numpy arrays</li> <li>Consistent output: Always returns a DataFrame with intuitive time and signal dimensions for straightforward visualization and analysis</li> <li>Zero boilerplate: Focus on your neuroscience question, not data structure conversions</li> </ul> <p>This tutorial demonstrates the versatility of <code>peth</code> using real neural data from a single recording session, showing how the same function elegantly handles spike rasters, continuous signals, and complex multi-region analyses.</p>"},{"location":"tutorials/peth_tutorial/#import-required-libraries","title":"Import Required Libraries\u00b6","text":"<p>This tutorial shows how to compute peri-event time histograms (PETHs) for multiple data types using <code>peth</code> and how to visualize the results with a real session.</p>"},{"location":"tutorials/peth_tutorial/#load-sample-neural-data","title":"Load Sample Neural Data\u00b6","text":"<p>We load real data from a single session: HMC1 on day 8. This session contains:</p> <ul> <li>Spike trains from CA1 and PFC pyramidal cells (well-characterized, prevalent populations)</li> <li>Event timestamps for ripples (sharp-wave ripples) and delta waves (slow oscillations during sleep)</li> <li>Continuous signals (LFP) recorded simultaneously from multiple brain regions</li> </ul> <p>By loading from a single basepath, we ensure temporal alignment across all data types (spikes start at t=0, events logged with absolute timestamps, LFP sampled continuously).</p> <p>Session basepath: <code>S:\\data\\HMC\\HMC1\\day8</code></p>"},{"location":"tutorials/peth_tutorial/#define-peth-parameters","title":"Define PETH Parameters\u00b6","text":"<p>We define a temporal window and bin width for the peri-event time histogram:</p> <ul> <li>window = [-1, 1] sec: Symmetric window captures \u00b1500 ms around each event (standard in neuroscience)</li> <li>bin_width = 0.01 sec (10 ms): Provides millisecond-level resolution for spike timing relative to events</li> </ul> <p>These parameters are well-suited for detecting rapid modulations in firing rate around behavioral/physiological events.</p>"},{"location":"tutorials/peth_tutorial/#calculate-peth-for-spike-data","title":"Calculate PETH for Spike Data\u00b6","text":""},{"location":"tutorials/peth_tutorial/#analysis-goals","title":"Analysis Goals\u00b6","text":"<p>We quantify how spike rates change around two key event types:</p> <ol> <li>Ripples (SWR): Sharp-wave ripple complexes\u2014transient, high-frequency bursts associated with memory consolidation</li> <li>Delta waves: Slow oscillations (1-4 Hz) that structure neural activity during NREM sleep</li> </ol> <p>We compare two brain regions:</p> <ul> <li>CA1: Hippocampal subregion (spatial representation, memory)</li> <li>PFC: Prefrontal cortex (decision-making, planning, working memory)</li> </ul> <p>This comparison reveals how the two regions coordinate during distinct brain states.</p>"},{"location":"tutorials/peth_tutorial/#method","title":"Method\u00b6","text":"<p>For each unit and event type, we compute the peri-event time histogram (PETH): a estimate of firing rate modulation time-locked to discrete events. The result shows mean firing rate \u00b1 SEM around each event.</p>"},{"location":"tutorials/peth_tutorial/#calculate-peth-for-continuous-data","title":"Calculate PETH for Continuous Data\u00b6","text":""},{"location":"tutorials/peth_tutorial/#analysis-goals","title":"Analysis Goals\u00b6","text":"<p>Unlike spike trains (discrete events), continuous signals like LFP directly reflect the voltage dynamics of local neural populations. We compute event-triggered averages of LFP on three channels to visualize how local field potentials modulate around ripples and delta waves.</p> <p>Channels analyzed:</p> <ol> <li>Ripple channel (261): CA1 pyramidal layer\u2014site of ripple generation</li> <li>Sharp wave channel (282): CA1 region\u2014source of sharp-wave component</li> <li>Delta channel (53): PFC channel with delta oscillations</li> </ol> <p>Why NREM sleep? Both ripples and delta waves occur preferentially during NREM sleep. Restricting analysis to NREM ensures we examine the same behavioral state across both event types, controlling for state-dependent changes in LFP amplitude.</p>"},{"location":"tutorials/peth_tutorial/#method","title":"Method\u00b6","text":"<p>For each channel, we average the continuous LFP signal across all ripple events (or delta events) and plot mean \u00b1 SEM. Sharp voltage deflections at t=0 indicate synchronization of the underlying neural population to the event.</p>"},{"location":"tutorials/peth_tutorial/#event-wise-peth-analysis","title":"Event-wise PETH Analysis\u00b6","text":"<p>The <code>average=True</code> (default) returns the mean firing rate across all events, which is useful for understanding typical responses. However, sometimes we want to analyze individual events - for example, to:</p> <ol> <li>Identify outlier events with unusually strong or weak neural responses</li> <li>Stratify events by response strength to correlate with behavioral or physiological variables</li> <li>Examine trial-to-trial variability in neural dynamics</li> <li>Sort events to create raster plots organized by population response</li> </ol> <p>The <code>average=False</code> parameter returns event-wise data as a 3D matrix with shape <code>(n_time_bins, n_signals, n_events)</code>, preserving information about each individual event.</p>"},{"location":"tutorials/peth_tutorial/#example-stratifying-events-by-population-response","title":"Example: Stratifying Events by Population Response\u00b6","text":"<p>With event-wise data, we can quantify the population response strength for each ripple event and stratify them. This allows us to ask: Do \"strong\" ripple events (with high CA1 firing) differ from \"weak\" ones?</p> <p>We'll:</p> <ol> <li>Compute total population firing rate for each ripple</li> <li>Split ripples into strong/weak groups</li> <li>Visualize how PFC neurons respond differently to strong vs. weak CA1 ripple events</li> </ol>"},{"location":"tutorials/peth_tutorial/#example-sorting-events-by-response-latency","title":"Example: Sorting Events by Response Latency\u00b6","text":"<p>Another powerful use of event-wise data is to sort events by neural response timing. This reveals temporal structure in event sequences - for example, whether some ripples elicit faster PFC responses than others.</p>"},{"location":"tutorials/peth_tutorial/#lfp-modulation-around-delta-waves-sorted-by-peak-power","title":"LFP Modulation Around Delta Waves Sorted by Peak Power\u00b6","text":"<p>This section examines how the local field potential (LFP) evolves around individual delta wave events during NREM sleep. For each detected delta wave, we extract the LFP in a symmetric time window centered on the delta peak and compute a peri-event time histogram (PETH) without averaging across events.</p> <p>To reveal structure related to delta strength, events are sorted by their peak normalized power before visualization. The resulting heatmap displays single-event LFP traces as rows, ordered from low to high delta power. This sorting allows assessment of the variation in delta wave magnitude.</p>"},{"location":"tutorials/peth_tutorial/#example-joint-peri-event-time-histograms-jpst-controlling-for-confounds","title":"Example: Joint Peri-Event Time Histograms (JPST) - Controlling for Confounds\u00b6","text":"<p>We use the Joint PETH to quantify interactions between PFC spikes and hippocampal ripples conditioned on delta waves.</p> <p>First, we compute event-wise peri-event time histograms (PETHs) for both signals relative to the same delta events:</p> <ul> <li>$P_1(e,t)$: spike rate at time $t$ for delta event $e$</li> <li>$P_2(e,t)$: ripple rate at time $t$ for delta event $e$</li> </ul> <p>Each matrix has shape $(N_{events} \\times N_{time})$.</p>"},{"location":"tutorials/peth_tutorial/#joint-interaction","title":"Joint interaction\u00b6","text":"<p>The joint time\u2013time histogram is:</p> <p>$$ J(t_1,t_2) =  \\frac{1}{N} \\sum_{e=1}^{N} P_1(e,t_1) P_2(e,t_2) $$</p> <p>This measures how often spikes at time $t_1$ and ripples at time $t_2$ co-occur across delta waves.</p>"},{"location":"tutorials/peth_tutorial/#expected-interaction-independence-model","title":"Expected interaction (independence model)\u00b6","text":"<p>To control for shared modulation by delta waves:</p> <p>$$ E(t_1,t_2) = \\bar{P}_1(t_1) \\bar{P}_2(t_2) $$</p> <p>where $\\bar{P}_i(t)$ is the average across events.</p>"},{"location":"tutorials/peth_tutorial/#delta-corrected-interaction","title":"Delta-corrected interaction\u00b6","text":"<p>$$ D(t_1,t_2) = J(t_1,t_2) - E(t_1,t_2) $$</p> <ul> <li>$D&gt;0$: greater-than-expected co-occurrence</li> <li>$D&lt;0$: less-than-expected co-occurrence</li> </ul> <p>Diagonal structure ($t_1=t_2$) reflects synchronous timing relative to delta; off-diagonal structure reflects lead\u2013lag relationships.</p> <p>The Joint PETH therefore tests whether spike\u2013ripple timing structure exists beyond shared modulation by delta waves.</p>"},{"location":"tutorials/peth_tutorial/#ripple-triggered-peth-sorted-by-time-to-nearest-delta-wave","title":"Ripple-Triggered PETH Sorted by Time to Nearest Delta Wave\u00b6","text":"<p>Similar to above, to examine how ripple-locked firing depends on delta timing, we sort ripple events by their temporal distance to the nearest delta wave.</p> <p>For each ripple, we compute the time difference between the ripple and its nearest delta wave. Ripples within a specified time window are retained and then ordered according to this delay.</p> <p>We then compute a ripple-triggered PETH for PFC spikes, where each row represents one ripple event and the x-axis represents time relative to ripple onset.</p> <p>To highlight relative modulation rather than absolute firing rate differences, each event is z-scored before plotting.</p> <p>The final visualization contains two panels:</p> <p>The top panel shows the average ripple-triggered firing rate across events.</p> <p>The bottom panel shows a heatmap of individual ripple events, sorted by their delay to delta waves.</p> <p>In the heatmap, the x-axis is time from ripple onset, and the y-axis reflects ripple events ordered by their timing relative to delta waves. This allows us to see whether ripple-locked firing patterns change systematically depending on where the ripple occurs within the delta cycle.</p>"},{"location":"tutorials/peth_tutorial/#takeaways-event-wise-peth-analysis","title":"Takeaways: Event-wise PETH Analysis\u00b6","text":"<p>The <code>average=False</code> parameter unlocks powerful analyses beyond simple averaging:</p> <p>\u2705 Event stratification: Identify subpopulations of events with distinct neural correlates \u2705 Correlation analysis: Relate event-by-event neural responses to behavioral or physiological variables \u2705 Temporal sorting: Reveal latency structure in event sequences \u2705 Outlier detection: Find unusual events for closer examination \u2705 Variability quantification: Measure trial-to-trial consistency of neural responses</p> <p>When to use:</p> <ul> <li><code>average=True</code> (default): Standard PETH plots showing typical response</li> <li><code>average=False</code>: When you need event-level granularity for stratification, sorting, or correlation analyses</li> </ul> <p>The event-wise matrix preserves all information, allowing flexible post-hoc analyses without recomputing PETHs.</p>"},{"location":"tutorials/reactivation/","title":"Reactivation","text":"In\u00a0[37]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n\n# from neuro_py\n# plotting\nimport matplotlib.pyplot as plt\n\n# core tools\nimport nelpy as nel\nimport numpy as np\nimport seaborn as sns\n\nfrom neuro_py.ensemble.assembly_reactivation import AssemblyReact\nfrom neuro_py.io import loading\nfrom neuro_py.process.peri_event import event_triggered_average_fast\nimport neuro_py as npy\n</pre> %reload_ext autoreload %autoreload 2  # from neuro_py # plotting import matplotlib.pyplot as plt  # core tools import nelpy as nel import numpy as np import seaborn as sns  from neuro_py.ensemble.assembly_reactivation import AssemblyReact from neuro_py.io import loading from neuro_py.process.peri_event import event_triggered_average_fast import neuro_py as npy In\u00a0[38]: Copied! <pre>basepath = r\"S:\\data\\HMC\\HMC1\\day8\"\n\nassembly_react = AssemblyReact(\n    basepath=basepath,\n    brainRegion=\"CA1\",\n    putativeCellType=\"Pyr\",\n    z_mat_dt=0.01,\n)\n</pre> basepath = r\"S:\\data\\HMC\\HMC1\\day8\"  assembly_react = AssemblyReact(     basepath=basepath,     brainRegion=\"CA1\",     putativeCellType=\"Pyr\",     z_mat_dt=0.01, ) <p>Also, load brain states for later use.</p> In\u00a0[39]: Copied! <pre># load theta epochs\nstate_dict = loading.load_SleepState_states(basepath)\ntheta_epochs = nel.EpochArray(\n    state_dict[\"THETA\"],\n)\nnrem_epochs = nel.EpochArray(\n    state_dict[\"NREMstate\"],\n)\ntheta_epochs, nrem_epochs\n</pre> # load theta epochs state_dict = loading.load_SleepState_states(basepath) theta_epochs = nel.EpochArray(     state_dict[\"THETA\"], ) nrem_epochs = nel.EpochArray(     state_dict[\"NREMstate\"], ) theta_epochs, nrem_epochs Out[39]: <pre>(&lt;EpochArray at 0x1bf19b9eb10: 125 epochs&gt; of length 35:04 minutes,\n &lt;EpochArray at 0x1c039ca4050: 88 epochs&gt; of length 2:16:25 hours)</pre> In\u00a0[40]: Copied! <pre># load need data (spikes, ripples, epochs)\nassembly_react.load_data()\nassembly_react\n</pre> # load need data (spikes, ripples, epochs) assembly_react.load_data() assembly_react Out[40]: <pre>&lt;AssemblyReact: 75 units&gt; of length 6:36:57:689 hours</pre> <p>Locate the session from which you want to detect assemblies.</p> <p>Here we can see a novel <code>linear</code> track is the second epoch.</p> In\u00a0[41]: Copied! <pre>assembly_react.epoch_df\n</pre> assembly_react.epoch_df Out[41]: name startTime stopTime environment behavioralParadigm notes manipulation stimuli basepath 0 preSleep_210411_064951 0.0 9544.56315 sleep NaN NaN NaN NaN S:\\data\\HMC\\HMC1\\day8 1 maze_210411_095201 9544.5632 11752.80635 linear 1 novel NaN NaN S:\\data\\HMC\\HMC1\\day8 2 postSleep_210411_103522 11752.8064 23817.68955 sleep NaN NaN NaN NaN S:\\data\\HMC\\HMC1\\day8 In\u00a0[42]: Copied! <pre>assembly_react.get_weights(epoch=assembly_react.epochs[1] &amp; theta_epochs)\nassembly_react\n</pre> assembly_react.get_weights(epoch=assembly_react.epochs[1] &amp; theta_epochs) assembly_react Out[42]: <pre>&lt;AssemblyReact: 75 units, 15 assemblies&gt; of length 6:36:57:689 hours</pre> In\u00a0[43]: Copied! <pre>assembly_react.plot()\nplt.show()\n</pre> assembly_react.plot() plt.show() In\u00a0[44]: Copied! <pre>assembly_act = assembly_react.get_assembly_act()\nassembly_act\n</pre> assembly_act = assembly_react.get_assembly_act() assembly_act Out[44]: <pre>&lt;AnalogSignalArray at 0x1bf177a3c90: 15 signals&gt; for a total of 6:36:57:680 hours</pre> In\u00a0[45]: Copied! <pre>nrem_ripples = assembly_react.ripples &amp; nrem_epochs\n\npsth_swr_pre = event_triggered_average_fast(\n    assembly_act.data,\n    nrem_ripples[assembly_react.epochs[0]].starts,\n    sampling_rate=assembly_act.fs,\n    window=[-0.5, 0.5],\n    return_average=True,\n    return_pandas=True,\n)\npsth_swr_task = event_triggered_average_fast(\n    assembly_act.data,\n    assembly_react.ripples[assembly_react.epochs[1]].starts,\n    sampling_rate=assembly_act.fs,\n    window=[-0.5, 0.5],\n    return_average=True,\n    return_pandas=True,\n)\npsth_swr_post = event_triggered_average_fast(\n    assembly_act.data,\n    nrem_ripples[assembly_react.epochs[2]].starts,\n    sampling_rate=assembly_act.fs,\n    window=[-0.5, 0.5],\n    return_average=True,\n    return_pandas=True,\n)\n\n# round time index to 3 decimals for plotting\npsth_swr_pre.index = np.round(psth_swr_pre.index, 3)\npsth_swr_task.index = np.round(psth_swr_task.index, 3)\npsth_swr_post.index = np.round(psth_swr_post.index, 3)\n</pre> nrem_ripples = assembly_react.ripples &amp; nrem_epochs  psth_swr_pre = event_triggered_average_fast(     assembly_act.data,     nrem_ripples[assembly_react.epochs[0]].starts,     sampling_rate=assembly_act.fs,     window=[-0.5, 0.5],     return_average=True,     return_pandas=True, ) psth_swr_task = event_triggered_average_fast(     assembly_act.data,     assembly_react.ripples[assembly_react.epochs[1]].starts,     sampling_rate=assembly_act.fs,     window=[-0.5, 0.5],     return_average=True,     return_pandas=True, ) psth_swr_post = event_triggered_average_fast(     assembly_act.data,     nrem_ripples[assembly_react.epochs[2]].starts,     sampling_rate=assembly_act.fs,     window=[-0.5, 0.5],     return_average=True,     return_pandas=True, )  # round time index to 3 decimals for plotting psth_swr_pre.index = np.round(psth_swr_pre.index, 3) psth_swr_task.index = np.round(psth_swr_task.index, 3) psth_swr_post.index = np.round(psth_swr_post.index, 3) In\u00a0[46]: Copied! <pre>fig, ax = plt.subplots(2, 3, figsize=(15, 8), sharey=False, sharex=False)\nax = ax.flatten()\n\n# share y axis of first row\nax[0] = plt.subplot(231, sharey=ax[1])\nax[2] = plt.subplot(233, sharey=ax[0])\n\n# plot assembly ripple psth\npsth_swr_pre.plot(ax=ax[0], legend=False)\npsth_swr_post.plot(ax=ax[1], legend=False)\n(psth_swr_post - psth_swr_pre).plot(ax=ax[2])\n\n# plot mean assembly ripple psth\npsth_swr_pre.mean(axis=1).plot(ax=ax[0], color=\"k\", legend=False)\npsth_swr_post.mean(axis=1).plot(ax=ax[1], color=\"k\", legend=False)\n(psth_swr_post - psth_swr_pre).mean(axis=1).plot(ax=ax[2], color=\"k\")\n\n# plot assembly ripple psth heatmap\nsns.heatmap(psth_swr_pre.T, ax=ax[3], cbar=False, vmin=0, vmax=5)\nsns.heatmap(psth_swr_post.T, ax=ax[4], cbar=False, vmin=0, vmax=5)\nsns.heatmap(\n    (psth_swr_post - psth_swr_pre).T,\n    ax=ax[5],\n    cbar=False,\n    vmin=-5,\n    vmax=5,\n    cmap=\"coolwarm\",\n)\n\nfor ax_ in ax[:3]:\n    # dashed line at zero\n    ax_.axvline(0, linestyle=\"--\", color=\"k\", linewidth=1)\n    # set x axis limits\n    ax_.set_xlim(-0.5, 0.5)\n    # add grid lines\n    ax_.grid()\n\nax[0].set_title(\"Pre\")\nax[1].set_title(\"Post\")\nax[2].set_title(\"Post - Pre\")\n\n# move legend\nax[2].legend(\n    bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, frameon=False, title=\"assembly\"\n)\n\n# add labels\nax[0].set_ylabel(\"assembly activity\")\nax[3].set_ylabel(\"assembly\")\nax[3].set_xlabel(\"time from SWR start (s)\")\n\n# clean axis using seaborn\nsns.despine()\n\nplt.show()\n</pre> fig, ax = plt.subplots(2, 3, figsize=(15, 8), sharey=False, sharex=False) ax = ax.flatten()  # share y axis of first row ax[0] = plt.subplot(231, sharey=ax[1]) ax[2] = plt.subplot(233, sharey=ax[0])  # plot assembly ripple psth psth_swr_pre.plot(ax=ax[0], legend=False) psth_swr_post.plot(ax=ax[1], legend=False) (psth_swr_post - psth_swr_pre).plot(ax=ax[2])  # plot mean assembly ripple psth psth_swr_pre.mean(axis=1).plot(ax=ax[0], color=\"k\", legend=False) psth_swr_post.mean(axis=1).plot(ax=ax[1], color=\"k\", legend=False) (psth_swr_post - psth_swr_pre).mean(axis=1).plot(ax=ax[2], color=\"k\")  # plot assembly ripple psth heatmap sns.heatmap(psth_swr_pre.T, ax=ax[3], cbar=False, vmin=0, vmax=5) sns.heatmap(psth_swr_post.T, ax=ax[4], cbar=False, vmin=0, vmax=5) sns.heatmap(     (psth_swr_post - psth_swr_pre).T,     ax=ax[5],     cbar=False,     vmin=-5,     vmax=5,     cmap=\"coolwarm\", )  for ax_ in ax[:3]:     # dashed line at zero     ax_.axvline(0, linestyle=\"--\", color=\"k\", linewidth=1)     # set x axis limits     ax_.set_xlim(-0.5, 0.5)     # add grid lines     ax_.grid()  ax[0].set_title(\"Pre\") ax[1].set_title(\"Post\") ax[2].set_title(\"Post - Pre\")  # move legend ax[2].legend(     bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, frameon=False, title=\"assembly\" )  # add labels ax[0].set_ylabel(\"assembly activity\") ax[3].set_ylabel(\"assembly\") ax[3].set_xlabel(\"time from SWR start (s)\")  # clean axis using seaborn sns.despine()  plt.show() In\u00a0[47]: Copied! <pre>basepath = r\"U:\\data\\hpc_ctx_project\\HP18\\hp18_day40_20250514\"\n# load theta epochs\nstate_dict = loading.load_SleepState_states(basepath)\ntheta_epochs = nel.EpochArray(\n    state_dict[\"THETA\"],\n)\nnrem_epochs = nel.EpochArray(\n    state_dict[\"NREMstate\"],\n)\nripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)\n\nepoch_df = loading.load_epoch(basepath)\nepoch_df = npy.session.compress_repeated_epochs(epoch_df)\nbeh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)\npre_task_post = npy.session.find_multitask_pre_post(\n    epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True\n)\n\n# Load spike data from both CA1 and PFC regions\nst, cell_metrics = loading.load_spikes(\n    basepath, brainRegion=\"CA1|PFC\", putativeCellType=\"Pyr\"\n)\nbrain_regions = np.array([\"unknown\"] * st.n_active)\nbrain_regions[cell_metrics.brainRegion.str.contains(\"CA1\")] = \"CA1\"\nbrain_regions[cell_metrics.brainRegion.str.contains(\"PFC\")] = \"PFC\"\n\n# sort by brain region for easier visualization\nidx = np.argsort(brain_regions)\n\nst._data = st.data[idx]\nbrain_regions = brain_regions[idx]\ncell_metrics = cell_metrics.iloc[idx].reset_index(drop=True)\n</pre> basepath = r\"U:\\data\\hpc_ctx_project\\HP18\\hp18_day40_20250514\" # load theta epochs state_dict = loading.load_SleepState_states(basepath) theta_epochs = nel.EpochArray(     state_dict[\"THETA\"], ) nrem_epochs = nel.EpochArray(     state_dict[\"NREMstate\"], ) ripples = npy.io.load_ripples_events(basepath, return_epoch_array=True)  epoch_df = loading.load_epoch(basepath) epoch_df = npy.session.compress_repeated_epochs(epoch_df) beh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T) pre_task_post = npy.session.find_multitask_pre_post(     epoch_df.environment, post_sleep_flank=True, pre_sleep_common=True )  # Load spike data from both CA1 and PFC regions st, cell_metrics = loading.load_spikes(     basepath, brainRegion=\"CA1|PFC\", putativeCellType=\"Pyr\" ) brain_regions = np.array([\"unknown\"] * st.n_active) brain_regions[cell_metrics.brainRegion.str.contains(\"CA1\")] = \"CA1\" brain_regions[cell_metrics.brainRegion.str.contains(\"PFC\")] = \"PFC\"  # sort by brain region for easier visualization idx = np.argsort(brain_regions)  st._data = st.data[idx] brain_regions = brain_regions[idx] cell_metrics = cell_metrics.iloc[idx].reset_index(drop=True) In\u00a0[48]: Copied! <pre># Standard assembly detection (finds both within-region and cross-region assemblies)\nassembly_react_standard = AssemblyReact(weight_dt=0.05, z_mat_dt=0.005)\nassembly_react_standard.add_st(st)\nassembly_react_standard.epochs = beh_epochs\nassembly_react_standard.get_weights(\n    epoch=assembly_react_standard.epochs[pre_task_post[0][1].item()] &amp; theta_epochs\n)\n\nprint(f\"Standard detection found {assembly_react_standard.n_assemblies()} assemblies\")\n\n# Cross-structural assembly detection (only finds assemblies spanning multiple regions)\nassembly_react_cross = AssemblyReact(\n    weight_dt=0.05,\n    z_mat_dt=0.005,\n    cross_structural=brain_regions,  # This enables cross-structural detection\n)\nassembly_react_cross.add_st(st)\nassembly_react_cross.epochs = beh_epochs\nassembly_react_cross.get_weights(\n    epoch=assembly_react_cross.epochs[pre_task_post[0][1].item()] &amp; theta_epochs\n)\n\nprint(\n    f\"Cross-structural detection found {assembly_react_cross.n_assemblies()} assemblies\"\n)\n</pre> # Standard assembly detection (finds both within-region and cross-region assemblies) assembly_react_standard = AssemblyReact(weight_dt=0.05, z_mat_dt=0.005) assembly_react_standard.add_st(st) assembly_react_standard.epochs = beh_epochs assembly_react_standard.get_weights(     epoch=assembly_react_standard.epochs[pre_task_post[0][1].item()] &amp; theta_epochs )  print(f\"Standard detection found {assembly_react_standard.n_assemblies()} assemblies\")  # Cross-structural assembly detection (only finds assemblies spanning multiple regions) assembly_react_cross = AssemblyReact(     weight_dt=0.05,     z_mat_dt=0.005,     cross_structural=brain_regions,  # This enables cross-structural detection ) assembly_react_cross.add_st(st) assembly_react_cross.epochs = beh_epochs assembly_react_cross.get_weights(     epoch=assembly_react_cross.epochs[pre_task_post[0][1].item()] &amp; theta_epochs )  print(     f\"Cross-structural detection found {assembly_react_cross.n_assemblies()} assemblies\" ) <pre>Standard detection found 37 assemblies\nCross-structural detection found 6 assemblies\nCross-structural detection found 6 assemblies\n</pre> In\u00a0[49]: Copied! <pre>if assembly_react_cross.n_assemblies() &gt; 0:\n    # Plot cross-structural assembly weights\n    fig, axes = assembly_react_cross.plot(figsize=(12, 6))\n\n    # Add vertical line to separate brain regions\n    ca1_neurons = np.sum(brain_regions == \"CA1\")\n    for ax in axes.flat:\n        ax.axhline(\n            ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2\n        )\n        ax.text(\n            0.02,\n            1.05,\n            f\"PFC (top)\\nCA1 (bottom)\",\n            transform=ax.transAxes,\n            va=\"top\",\n            ha=\"left\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n        )\n\n    plt.suptitle(\"Cross-Structural Assemblies (CA1-PFC)\", fontsize=14, y=1.02)\n    plt.tight_layout()\n    plt.show()\n\n    # Analyze which regions participate in each assembly\n    assembly_react_cross.find_members()\n\n    print(\"\\n Cross-structural assembly analysis:\")\n    for i in range(assembly_react_cross.n_assemblies()):\n        ca1_active = assembly_react_cross.assembly_members[i, :ca1_neurons].sum()\n        pfc_active = assembly_react_cross.assembly_members[i, ca1_neurons:].sum()\n        print(\n            f\"  Assembly {i + 1}: CA1 neurons: {ca1_active}, PFC neurons: {pfc_active}\"\n        )\n\nelse:\n    print(\"No cross-structural assemblies detected in this dataset.\")\n    print(\"This could mean:\")\n    print(\"1. There are no assemblies spanning both regions\")\n    print(\"2. The assemblies are primarily within-region\")\n    print(\"3. More data or different parameters may be needed\")\n</pre> if assembly_react_cross.n_assemblies() &gt; 0:     # Plot cross-structural assembly weights     fig, axes = assembly_react_cross.plot(figsize=(12, 6))      # Add vertical line to separate brain regions     ca1_neurons = np.sum(brain_regions == \"CA1\")     for ax in axes.flat:         ax.axhline(             ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", alpha=0.7, linewidth=2         )         ax.text(             0.02,             1.05,             f\"PFC (top)\\nCA1 (bottom)\",             transform=ax.transAxes,             va=\"top\",             ha=\"left\",             bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),         )      plt.suptitle(\"Cross-Structural Assemblies (CA1-PFC)\", fontsize=14, y=1.02)     plt.tight_layout()     plt.show()      # Analyze which regions participate in each assembly     assembly_react_cross.find_members()      print(\"\\n Cross-structural assembly analysis:\")     for i in range(assembly_react_cross.n_assemblies()):         ca1_active = assembly_react_cross.assembly_members[i, :ca1_neurons].sum()         pfc_active = assembly_react_cross.assembly_members[i, ca1_neurons:].sum()         print(             f\"  Assembly {i + 1}: CA1 neurons: {ca1_active}, PFC neurons: {pfc_active}\"         )  else:     print(\"No cross-structural assemblies detected in this dataset.\")     print(\"This could mean:\")     print(\"1. There are no assemblies spanning both regions\")     print(\"2. The assemblies are primarily within-region\")     print(\"3. More data or different parameters may be needed\") <pre>\n Cross-structural assembly analysis:\n  Assembly 1: CA1 neurons: 10, PFC neurons: 22\n  Assembly 2: CA1 neurons: 26, PFC neurons: 24\n  Assembly 3: CA1 neurons: 16, PFC neurons: 15\n  Assembly 4: CA1 neurons: 14, PFC neurons: 11\n  Assembly 5: CA1 neurons: 25, PFC neurons: 17\n  Assembly 6: CA1 neurons: 21, PFC neurons: 14\n</pre> In\u00a0[50]: Copied! <pre>assembly_act_standard = assembly_react_standard.get_assembly_act(\n    epoch=assembly_react_standard.epochs[pre_task_post[0][2].item()]\n)\n\n# Compute assembly activity for cross-structural assemblies\nassembly_act_cross = assembly_react_cross.get_assembly_act(\n    epoch=assembly_react_cross.epochs[pre_task_post[0][2].item()]\n)\n\nnrem_ripples = ripples &amp; nrem_epochs\n\npsth_standard_post = npy.process.event_triggered_average(\n    timestamps=assembly_act_standard.abscissa_vals,\n    signal=assembly_act_standard.data.T,\n    events=nrem_ripples[\n        assembly_react_standard.epochs[pre_task_post[0][2].item()]\n    ].starts,\n    sampling_rate=assembly_act_standard.fs,\n    window=[-0.5, 0.5],\n    return_average=True,\n    return_pandas=True,\n)\npsth_cross_post = npy.process.event_triggered_average(\n    timestamps=assembly_act_cross.abscissa_vals,\n    signal=assembly_act_cross.data.T,\n    events=nrem_ripples[assembly_react_cross.epochs[pre_task_post[0][2].item()]].starts,\n    sampling_rate=assembly_act_cross.fs,\n    window=[-0.5, 0.5],\n    return_average=True,\n    return_pandas=True,\n)\n\n# Plot comparison\nfig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n\n# Plot standard assemblies\npsth_standard_post.plot(ax=axes[0], legend=False)\n\naxes[0].legend().set_visible(False)\n# axes[0].set_title(f\"Standard Assemblies (first {n_compare})\")\naxes[0].set_ylabel(\"Assembly Activity\")\naxes[0].axvline(0, linestyle=\"--\", color=\"k\", alpha=0.7)\naxes[0].grid(True, alpha=0.3)\naxes[0].set_title(f\"Standard Assemblies (n={assembly_react_standard.n_assemblies()})\")\n\n# Plot cross-structural assemblies\npsth_cross_post.plot(ax=axes[1], legend=False)\naxes[1].set_title(\n    f\"Cross-Structural Assemblies (n={assembly_react_cross.n_assemblies()})\"\n)\naxes[1].set_ylabel(\"Assembly Activity\")\naxes[1].axvline(0, linestyle=\"--\", color=\"k\", alpha=0.7)\naxes[1].grid(True, alpha=0.3)\n\nplt.suptitle(\"Assembly Activity During Post-Task Ripples\", fontsize=14)\nplt.tight_layout()\nsns.despine()\nplt.show()\n\n# Compare peak activation\nstandard_peak = psth_standard_post.max().mean()\ncross_peak = psth_cross_post.max().mean()\n\nprint(f\"Peak activation comparison:\")\nprint(f\"Standard assemblies (mean): {standard_peak:.2f}\")\nprint(f\"Cross-structural assemblies (mean): {cross_peak:.2f}\")\n</pre> assembly_act_standard = assembly_react_standard.get_assembly_act(     epoch=assembly_react_standard.epochs[pre_task_post[0][2].item()] )  # Compute assembly activity for cross-structural assemblies assembly_act_cross = assembly_react_cross.get_assembly_act(     epoch=assembly_react_cross.epochs[pre_task_post[0][2].item()] )  nrem_ripples = ripples &amp; nrem_epochs  psth_standard_post = npy.process.event_triggered_average(     timestamps=assembly_act_standard.abscissa_vals,     signal=assembly_act_standard.data.T,     events=nrem_ripples[         assembly_react_standard.epochs[pre_task_post[0][2].item()]     ].starts,     sampling_rate=assembly_act_standard.fs,     window=[-0.5, 0.5],     return_average=True,     return_pandas=True, ) psth_cross_post = npy.process.event_triggered_average(     timestamps=assembly_act_cross.abscissa_vals,     signal=assembly_act_cross.data.T,     events=nrem_ripples[assembly_react_cross.epochs[pre_task_post[0][2].item()]].starts,     sampling_rate=assembly_act_cross.fs,     window=[-0.5, 0.5],     return_average=True,     return_pandas=True, )  # Plot comparison fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)  # Plot standard assemblies psth_standard_post.plot(ax=axes[0], legend=False)  axes[0].legend().set_visible(False) # axes[0].set_title(f\"Standard Assemblies (first {n_compare})\") axes[0].set_ylabel(\"Assembly Activity\") axes[0].axvline(0, linestyle=\"--\", color=\"k\", alpha=0.7) axes[0].grid(True, alpha=0.3) axes[0].set_title(f\"Standard Assemblies (n={assembly_react_standard.n_assemblies()})\")  # Plot cross-structural assemblies psth_cross_post.plot(ax=axes[1], legend=False) axes[1].set_title(     f\"Cross-Structural Assemblies (n={assembly_react_cross.n_assemblies()})\" ) axes[1].set_ylabel(\"Assembly Activity\") axes[1].axvline(0, linestyle=\"--\", color=\"k\", alpha=0.7) axes[1].grid(True, alpha=0.3)  plt.suptitle(\"Assembly Activity During Post-Task Ripples\", fontsize=14) plt.tight_layout() sns.despine() plt.show()  # Compare peak activation standard_peak = psth_standard_post.max().mean() cross_peak = psth_cross_post.max().mean()  print(f\"Peak activation comparison:\") print(f\"Standard assemblies (mean): {standard_peak:.2f}\") print(f\"Cross-structural assemblies (mean): {cross_peak:.2f}\")  <pre>Peak activation comparison:\nStandard assemblies (mean): 3.52\nCross-structural assemblies (mean): 9.00\n</pre> In\u00a0[51]: Copied! <pre># Visualize cross-structural correlation matrix with within-structure filtered out\n# Recompute the z-scored binned spike matrix using the method from AssemblyReact\nzmat, _ = assembly_react_cross.get_z_mat(\n    assembly_react_cross.st[\n        assembly_react_cross.epochs[pre_task_post[0][1].item()] &amp; theta_epochs\n    ]\n)\n\ncorr = np.corrcoef(zmat)\n\n# Mask within-structure correlations\nregion_labels = brain_regions\nmask = np.equal.outer(region_labels, region_labels)\ncorr_masked = corr.copy()\ncorr_masked[mask] = np.nan  # set within-structure to NaN\n\nfig, ax = plt.subplots(figsize=(7, 6))\nim = ax.imshow(corr_masked, cmap=\"coolwarm\", vmin=-0.015, vmax=0.015)\n\n# Add lines to separate regions\nca1_neurons = np.sum(brain_regions == \"CA1\")\nax.axhline(ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7)\nax.axvline(ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7)\n\n# Axis labels and ticks\nax.set_xlabel(\"Neuron (sorted by region)\")\nax.set_ylabel(\"Neuron (sorted by region)\")\nax.set_xticks([0, ca1_neurons, len(brain_regions)])\nax.set_yticks([0, ca1_neurons, len(brain_regions)])\nax.set_xticklabels([\"0\", f\"{ca1_neurons}\", f\"{len(brain_regions)}\"])\nax.set_yticklabels([\"0\", f\"{ca1_neurons}\", f\"{len(brain_regions)}\"])\n\n# Add region labels using text outside the plot area for visibility\nax.text(\n    ca1_neurons / 2,\n    -10,\n    \"CA1\",\n    ha=\"center\",\n    va=\"bottom\",\n    fontsize=14,\n    fontweight=\"bold\",\n    color=\"black\",\n    clip_on=False,\n)\nax.text(\n    ca1_neurons + (len(brain_regions) - ca1_neurons) / 2,\n    -10,\n    \"PFC\",\n    ha=\"center\",\n    va=\"bottom\",\n    fontsize=14,\n    fontweight=\"bold\",\n    color=\"black\",\n    clip_on=False,\n)\n\n# Add the title above the region annotations by using fig.suptitle\nfig.suptitle(\n    \"Cross-Structural Correlation Matrix (within-structure filtered)\",\n    fontsize=12,\n    y=0.94,\n)\n\n# Colorbar\ncbar = plt.colorbar(im, ax=ax, label=\"Correlation\", pad=0.02)\nplt.tight_layout(rect=[0, 0, 1, 0.93])\nplt.show()\n</pre> # Visualize cross-structural correlation matrix with within-structure filtered out # Recompute the z-scored binned spike matrix using the method from AssemblyReact zmat, _ = assembly_react_cross.get_z_mat(     assembly_react_cross.st[         assembly_react_cross.epochs[pre_task_post[0][1].item()] &amp; theta_epochs     ] )  corr = np.corrcoef(zmat)  # Mask within-structure correlations region_labels = brain_regions mask = np.equal.outer(region_labels, region_labels) corr_masked = corr.copy() corr_masked[mask] = np.nan  # set within-structure to NaN  fig, ax = plt.subplots(figsize=(7, 6)) im = ax.imshow(corr_masked, cmap=\"coolwarm\", vmin=-0.015, vmax=0.015)  # Add lines to separate regions ca1_neurons = np.sum(brain_regions == \"CA1\") ax.axhline(ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7) ax.axvline(ca1_neurons - 0.5, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7)  # Axis labels and ticks ax.set_xlabel(\"Neuron (sorted by region)\") ax.set_ylabel(\"Neuron (sorted by region)\") ax.set_xticks([0, ca1_neurons, len(brain_regions)]) ax.set_yticks([0, ca1_neurons, len(brain_regions)]) ax.set_xticklabels([\"0\", f\"{ca1_neurons}\", f\"{len(brain_regions)}\"]) ax.set_yticklabels([\"0\", f\"{ca1_neurons}\", f\"{len(brain_regions)}\"])  # Add region labels using text outside the plot area for visibility ax.text(     ca1_neurons / 2,     -10,     \"CA1\",     ha=\"center\",     va=\"bottom\",     fontsize=14,     fontweight=\"bold\",     color=\"black\",     clip_on=False, ) ax.text(     ca1_neurons + (len(brain_regions) - ca1_neurons) / 2,     -10,     \"PFC\",     ha=\"center\",     va=\"bottom\",     fontsize=14,     fontweight=\"bold\",     color=\"black\",     clip_on=False, )  # Add the title above the region annotations by using fig.suptitle fig.suptitle(     \"Cross-Structural Correlation Matrix (within-structure filtered)\",     fontsize=12,     y=0.94, )  # Colorbar cbar = plt.colorbar(im, ax=ax, label=\"Correlation\", pad=0.02) plt.tight_layout(rect=[0, 0, 1, 0.93]) plt.show() <pre>C:\\Users\\Cornell\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\nC:\\Users\\Cornell\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\_function_base_impl.py:3046: RuntimeWarning: invalid value encountered in divide\n</pre>"},{"location":"tutorials/reactivation/#reactivation","title":"Reactivation\u00b6","text":"<p>Here, we will show how to use the <code>AssemblyReact</code> class to identify assemblies and assess reactivation during post-task sleep</p>"},{"location":"tutorials/reactivation/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/reactivation/#section-1-pick-basepath-and-initialize-assemblyreact-class","title":"Section 1: Pick basepath and initialize AssemblyReact class\u00b6","text":"<p>Here we will use CA1 pyramidal cells.</p>"},{"location":"tutorials/reactivation/#section-2-load-spike-data-session-epochs-and-ripple-events","title":"Section 2: Load spike data, session epochs, and ripple events\u00b6","text":"<p>You can see there there are nice printouts that display important information about the class</p>"},{"location":"tutorials/reactivation/#section-3-detect-assembles-in-linear-track-during-theta","title":"Section 3: Detect assembles in linear track during theta\u00b6","text":"<p>You can see we have detected 15 assemblies</p>"},{"location":"tutorials/reactivation/#section-4-analyze-the-obtained-assemblies","title":"Section 4: Analyze the obtained assemblies\u00b6","text":""},{"location":"tutorials/reactivation/#section-41-visualize-assembly-weights","title":"Section 4.1: Visualize assembly weights\u00b6","text":"<p>Each column is a assembly and each row is a cell</p> <p>The color indicates if the cell was a significant contributor (members) to that assembly</p> <ul> <li>you can find these members with assembly_members = assembly_react.find_members()</li> </ul>"},{"location":"tutorials/reactivation/#section-42-compute-time-resolved-activations-for-each-assembly","title":"Section 4.2: Compute time-resolved activations for each assembly\u00b6","text":"<p>Will take around a minute to run.</p>"},{"location":"tutorials/reactivation/#section-43-get-assembly-strengths-around-ripples-in-pre-sleep-the-task-and-in-post-sleep-epochs","title":"Section 4.3: Get assembly strengths around ripples in pre-sleep, the task, and in post-sleep epochs\u00b6","text":""},{"location":"tutorials/reactivation/#section-44-visualize-reactivation-dynamics-during-post-task-ripples","title":"Section 4.4: Visualize reactivation dynamics during post-task ripples\u00b6","text":"<p>Here, we have plotted Pre, Post, and Post subtracted by Pre to estimate the difference.</p> <p>You can see that many of the assembles have a higher reactivation during the post-task ripples compared to the pre-task ripples.</p>"},{"location":"tutorials/reactivation/#section-5-cross-structural-assembly-detection","title":"Section 5: Cross-Structural Assembly Detection\u00b6","text":"<p>The <code>AssemblyReact</code> class now supports cross-structural assembly detection, which allows you to identify assemblies that span across different brain regions, cell types, or any other categorical grouping. This is particularly useful for studying cross-regional coordination.</p>"},{"location":"tutorials/reactivation/#section-51-load-data-from-multiple-brain-regions","title":"Section 5.1: Load data from multiple brain regions\u00b6","text":"<p>For this demonstration, we'll detect assemblies that span across CA1 and PFC regions.</p>"},{"location":"tutorials/reactivation/#section-52-standard-vs-cross-structural-assembly-detection","title":"Section 5.2: Standard vs Cross-Structural Assembly Detection\u00b6","text":"<p>Let's compare standard assembly detection (which finds assemblies within and across regions) with cross-structural detection (which only finds assemblies spanning multiple regions).</p>"},{"location":"tutorials/reactivation/#section-53-visualize-cross-structural-assembly-weights","title":"Section 5.3: Visualize Cross-Structural Assembly Weights\u00b6","text":"<p>The cross-structural assemblies should show weights in both CA1 and PFC regions. The vertical red line separates the two brain regions.</p>"},{"location":"tutorials/reactivation/#section-54-compare-assembly-activity-between-standard-and-cross-structural-detection","title":"Section 5.4: Compare Assembly Activity Between Standard and Cross-Structural Detection\u00b6","text":"<p>Let's examine how cross-structural assemblies behave during ripples compared to standard assemblies.</p>"},{"location":"tutorials/reactivation/#section-55-visualizing-cross-structural-correlation-matrix","title":"Section 5.5: Visualizing Cross-Structural Correlation Matrix\u00b6","text":"<p>A crucial step in cross-structural assembly analysis is filtering out within-structure (within-region) correlations. By masking these, we ensure that only interactions between neurons in different regions (e.g., CA1 and PFC) are considered when detecting cross-structural assemblies. This step is what enables the identification of assemblies that truly span multiple structures, rather than being dominated by strong within-region co-activity.</p> <p>The plot below shows the neuron-neuron correlation matrix with within-region correlations masked out. The vertical red lines mark the region boundaries, and region labels are shown above the matrix for clarity. Only cross-region correlations remain visible, making patterns of inter-regional coordination stand out.</p> <p>This visualization helps you:</p> <ul> <li>Confirm that the analysis is focused on cross-structural interactions</li> <li>Inspect the distribution and strength of cross-region correlations</li> <li>Identify coordinated activity that is not visible within a single region</li> </ul> <p>Assemblies that are truly cross-structural will show strong off-diagonal blocks in this matrix, indicating coordinated activity between regions.</p>"},{"location":"tutorials/reactivation/#section-56-key-points-about-cross-structural-assembly-detection","title":"Section 5.6: Key Points About Cross-Structural Assembly Detection\u00b6","text":"<p>What it does:</p> <ul> <li>Identifies assemblies that span across different groups (regions, cell types, etc.)</li> <li>Filters out assemblies that are confined to a single group</li> <li>Enables study of cross-regional coordination and communication</li> </ul> <p>When to use:</p> <ul> <li>Studying hippocampal-cortical interactions</li> <li>Examining coordination between brain regions</li> <li>Investigating cell type-specific assembly dynamics</li> <li>Analyzing cross-electrode or cross-shank coordination</li> </ul> <p>Parameters:</p> <ul> <li><code>cross_structural</code>: A categorical array with the same length as the number of neurons</li> <li>Works with both <code>method='ica'</code> and <code>method='pca'</code></li> <li>Compatible with all other <code>AssemblyReact</code> parameters</li> </ul> <p>Important considerations:</p> <ul> <li>Requires sufficient neurons from multiple groups</li> <li>May detect fewer assemblies than standard detection (by design)</li> <li>Best used when you have a specific hypothesis about cross-structural coordination</li> </ul>"},{"location":"tutorials/spatial_map/","title":"Spatial Map","text":"In\u00a0[1]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\nimport nelpy as nel\nimport nelpy.plotting as npl\nimport numpy as np\nimport seaborn as sns\nfrom skimage import measure\n\nimport neuro_py as npy\nfrom neuro_py.behavior.linear_positions import get_linear_track_lap_epochs\nfrom neuro_py.ensemble.assembly_reactivation import AssemblyReact\nfrom neuro_py.io import loading\nfrom neuro_py.plotting.figure_helpers import set_size\nfrom neuro_py.tuning import maps\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport logging\n\nlogging.getLogger().setLevel(logging.ERROR)\n</pre> %reload_ext autoreload %autoreload 2  import matplotlib.pyplot as plt import nelpy as nel import nelpy.plotting as npl import numpy as np import seaborn as sns from skimage import measure  import neuro_py as npy from neuro_py.behavior.linear_positions import get_linear_track_lap_epochs from neuro_py.ensemble.assembly_reactivation import AssemblyReact from neuro_py.io import loading from neuro_py.plotting.figure_helpers import set_size from neuro_py.tuning import maps  %matplotlib inline %config InlineBackend.figure_format = 'retina'  import logging  logging.getLogger().setLevel(logging.ERROR) In\u00a0[2]: Copied! <pre>basepath = r\"Z:\\Data\\Kenji\\ec013.961_974\"\n</pre> basepath = r\"Z:\\Data\\Kenji\\ec013.961_974\" In\u00a0[3]: Copied! <pre># load position\nposition_df = loading.load_animal_behavior(basepath)\n\n# put position into a nelpy position array for ease of use\npos = nel.AnalogSignalArray(\n    data=position_df[[\"x\", \"y\"]].values.T,\n    timestamps=position_df.timestamps.values,\n)\n# calculate speed\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\n\n# load in spike data from hpc pyramidal cells\nst, cm = loading.load_spikes(\n    basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1|CA2|CA3\"\n)\n</pre> # load position position_df = loading.load_animal_behavior(basepath)  # put position into a nelpy position array for ease of use pos = nel.AnalogSignalArray(     data=position_df[[\"x\", \"y\"]].values.T,     timestamps=position_df.timestamps.values, ) # calculate speed speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)  # load in spike data from hpc pyramidal cells st, cm = loading.load_spikes(     basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1|CA2|CA3\" ) In\u00a0[4]: Copied! <pre>epoch_df = loading.load_epoch(basepath)\nbeh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)\n\n# you can change this based on which session you want to look at\nbehavior_idx = 11\n\n# print out data frame\nepoch_df\n</pre> epoch_df = loading.load_epoch(basepath) beh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)  # you can change this based on which session you want to look at behavior_idx = 11  # print out data frame epoch_df Out[4]: name startTime stopTime environment behavioralParadigm manipulation stimuli notes basepath 0 ec013.961_sleep 0.0000 321.9456 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 1 ec013.962_sleep 321.9456 2475.2456 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 2 ec013.963_sleep 2475.2456 5748.3596 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 3 ec013.964_sleep 5748.3596 6035.4892 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 4 ec013.965_linear 6035.4892 7481.7872 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 5 ec013.966_linear 7481.7872 9050.3872 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 6 ec013.967_sleep 9050.3872 10959.9422 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 7 ec013.968_sleep 10959.9422 13312.2752 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 8 ec013.969_linear 13312.2752 15073.9652 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 9 ec013.970_bigSquare 15073.9652 17064.4652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 10 ec013.971_bigSquare 17064.4652 18704.5652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 11 ec013.972_bigSquare 18704.5652 21714.0652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 12 ec013.973_wheel 21714.0652 23200.5032 wheel 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 13 ec013.974_wheel 23200.5032 24717.6612 wheel 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 In\u00a0[5]: Copied! <pre>spatial_maps = maps.SpatialMap(\n    pos[beh_epochs[behavior_idx]],\n    st[beh_epochs[behavior_idx]],\n    s_binsize=3,\n    speed=speed,\n    speed_thres=4,\n    tuning_curve_sigma=3,\n    place_field_min_size=15,\n    place_field_max_size=1000,\n    place_field_sigma=3,\n)\nspatial_maps.find_fields()\n\nspatial_maps\n</pre> spatial_maps = maps.SpatialMap(     pos[beh_epochs[behavior_idx]],     st[beh_epochs[behavior_idx]],     s_binsize=3,     speed=speed,     speed_thres=4,     tuning_curve_sigma=3,     place_field_min_size=15,     place_field_max_size=1000,     place_field_sigma=3, ) spatial_maps.find_fields()  spatial_maps Out[5]: <pre>&lt;TuningCurve2D at 0x21bf1c04e90&gt; with shape (16, 64, 64)</pre> <p>You can also shuffle your data to find which cell has more spatial information than chance. Depending on how many cells you have this can take a bit of time, but it shouldn't take more than a minute with the default 500 shuffles.</p> In\u00a0[6]: Copied! <pre>spatial_info_pvalues = spatial_maps.shuffle_spatial_information()\n</pre> spatial_info_pvalues = spatial_maps.shuffle_spatial_information() <p>There are many more class methods available within <code>spatial_maps.tc</code>:</p> In\u00a0[7]: Copied! <pre>[k for k in dir(spatial_maps.tc) if not k.startswith(\"_\")]\n</pre> [k for k in dir(spatial_maps.tc) if not k.startswith(\"_\")] Out[7]: <pre>['bin_centers',\n 'bins',\n 'field_mask',\n 'field_peak_rate',\n 'field_width',\n 'information_rate',\n 'is2d',\n 'isempty',\n 'label',\n 'mask',\n 'max',\n 'mean',\n 'min',\n 'n_bins',\n 'n_fields',\n 'n_units',\n 'n_xbins',\n 'n_ybins',\n 'normalize',\n 'occupancy',\n 'ratemap',\n 'reorder_units_by_ids',\n 'shape',\n 'smooth',\n 'spatial_information',\n 'spatial_selectivity',\n 'spatial_sparsity',\n 'std',\n 'unit_ids',\n 'unit_labels',\n 'unit_tags',\n 'xbin_centers',\n 'xbins',\n 'ybin_centers',\n 'ybins']</pre> In\u00a0[8]: Copied! <pre># pull out velocity restricted position\ncurrent_pos = pos[beh_epochs[behavior_idx]][spatial_maps.run_epochs]\n\nspatial_information = spatial_maps.spatial_information()\n\n# iterate over the tuning curves\nfor ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):\n    ratemap_ = ratemap__.copy()\n    ratemap_[spatial_maps.tc.occupancy &lt; 0.01] = np.nan\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    sns.heatmap(ratemap_.T, ax=ax[0])\n\n    field_ids = np.unique(spatial_maps.tc.field_mask[ratemap_i])\n\n    # plot field boundaries over the heat map\n    if len(field_ids) &gt; 1:\n        for field_i in range(len(field_ids) - 1):\n            bc = measure.find_contours(\n                (spatial_maps.tc.field_mask[ratemap_i] == field_i + 1).T,\n                0,\n                fully_connected=\"low\",\n                positive_orientation=\"low\",\n            )\n            for c in bc:\n                ax[0].plot(c[:, 1], c[:, 0], linewidth=4)\n    ax[0].invert_yaxis()\n\n    # plot xy coords for animal position\n    npl.plot2d(current_pos, lw=2, c=\"0.8\", ax=ax[1])\n\n    # plot xy coords for each spike\n    x_time, pos_at_spikes = pos.asarray(\n        at=st[beh_epochs[behavior_idx]][spatial_maps.run_epochs].data[ratemap_i]\n    )\n    ax[1].plot(pos_at_spikes[0, :], pos_at_spikes[1, :], \".\", color=\"k\")\n    ax[1].set_aspect(\"equal\")\n    ax[0].set_aspect(\"equal\")\n    ax[1].set_title(f\"{cm.iloc[ratemap_i].brainRegion} {cm.iloc[ratemap_i].UID}\")\n    ax[0].set_title(\n        f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f}. \\n info: {spatial_information[ratemap_i]:.2f}, pval: {spatial_info_pvalues[ratemap_i]:.3f}, Z: {spatial_maps.spatial_information_zscore[ratemap_i]:.2f}\"\n    )\n    sns.despine()\n    plt.show()\n</pre> # pull out velocity restricted position current_pos = pos[beh_epochs[behavior_idx]][spatial_maps.run_epochs]  spatial_information = spatial_maps.spatial_information()  # iterate over the tuning curves for ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):     ratemap_ = ratemap__.copy()     ratemap_[spatial_maps.tc.occupancy &lt; 0.01] = np.nan     fig, ax = plt.subplots(1, 2, figsize=(10, 5))     sns.heatmap(ratemap_.T, ax=ax[0])      field_ids = np.unique(spatial_maps.tc.field_mask[ratemap_i])      # plot field boundaries over the heat map     if len(field_ids) &gt; 1:         for field_i in range(len(field_ids) - 1):             bc = measure.find_contours(                 (spatial_maps.tc.field_mask[ratemap_i] == field_i + 1).T,                 0,                 fully_connected=\"low\",                 positive_orientation=\"low\",             )             for c in bc:                 ax[0].plot(c[:, 1], c[:, 0], linewidth=4)     ax[0].invert_yaxis()      # plot xy coords for animal position     npl.plot2d(current_pos, lw=2, c=\"0.8\", ax=ax[1])      # plot xy coords for each spike     x_time, pos_at_spikes = pos.asarray(         at=st[beh_epochs[behavior_idx]][spatial_maps.run_epochs].data[ratemap_i]     )     ax[1].plot(pos_at_spikes[0, :], pos_at_spikes[1, :], \".\", color=\"k\")     ax[1].set_aspect(\"equal\")     ax[0].set_aspect(\"equal\")     ax[1].set_title(f\"{cm.iloc[ratemap_i].brainRegion} {cm.iloc[ratemap_i].UID}\")     ax[0].set_title(         f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f}. \\n info: {spatial_information[ratemap_i]:.2f}, pval: {spatial_info_pvalues[ratemap_i]:.3f}, Z: {spatial_maps.spatial_information_zscore[ratemap_i]:.2f}\"     )     sns.despine()     plt.show() In\u00a0[9]: Copied! <pre># change to the first linear track session\nbehavior_idx = 4\n\n# print out data frame\nepoch_df\n</pre> # change to the first linear track session behavior_idx = 4  # print out data frame epoch_df Out[9]: name startTime stopTime environment behavioralParadigm manipulation stimuli notes basepath 0 ec013.961_sleep 0.0000 321.9456 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 1 ec013.962_sleep 321.9456 2475.2456 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 2 ec013.963_sleep 2475.2456 5748.3596 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 3 ec013.964_sleep 5748.3596 6035.4892 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 4 ec013.965_linear 6035.4892 7481.7872 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 5 ec013.966_linear 7481.7872 9050.3872 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 6 ec013.967_sleep 9050.3872 10959.9422 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 7 ec013.968_sleep 10959.9422 13312.2752 sleep 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 8 ec013.969_linear 13312.2752 15073.9652 linear 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 9 ec013.970_bigSquare 15073.9652 17064.4652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 10 ec013.971_bigSquare 17064.4652 18704.5652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 11 ec013.972_bigSquare 18704.5652 21714.0652 bigSquare 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 12 ec013.973_wheel 21714.0652 23200.5032 wheel 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 13 ec013.974_wheel 23200.5032 24717.6612 wheel 10 NaN NaN NaN Z:\\Data\\Kenji\\ec013.961_974 In\u00a0[10]: Copied! <pre>pos = nel.AnalogSignalArray(\n    data=position_df[\"linearized\"].values.T,\n    timestamps=position_df.timestamps.values,\n)\npos = pos[beh_epochs[behavior_idx]]\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\npos\n</pre> pos = nel.AnalogSignalArray(     data=position_df[\"linearized\"].values.T,     timestamps=position_df.timestamps.values, ) pos = pos[beh_epochs[behavior_idx]] speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True) pos Out[10]: <pre>&lt;AnalogSignalArray at 0x21bf37a5090: 1 signals&gt; for a total of 24:06:298 minutes</pre> In\u00a0[11]: Copied! <pre>plt.figure(figsize=(20, 4))\nplt.plot(pos.data.T)\n</pre> plt.figure(figsize=(20, 4)) plt.plot(pos.data.T) Out[11]: <pre>[&lt;matplotlib.lines.Line2D at 0x21bf18a1ed0&gt;]</pre> In\u00a0[12]: Copied! <pre># get outbound and inbound epochs\n(outbound_epochs, inbound_epochs) = get_linear_track_lap_epochs(\n    pos.abscissa_vals, pos.data[0], newLapThreshold=20\n)\n\n\noutbound_epochs, inbound_epochs\n</pre> # get outbound and inbound epochs (outbound_epochs, inbound_epochs) = get_linear_track_lap_epochs(     pos.abscissa_vals, pos.data[0], newLapThreshold=20 )   outbound_epochs, inbound_epochs Out[12]: <pre>(&lt;EpochArray at 0x21bf3456c50: 19 epochs&gt; of length 9:45:574 minutes,\n &lt;EpochArray at 0x21bf34468d0: 20 epochs&gt; of length 13:36:844 minutes)</pre> In\u00a0[13]: Copied! <pre>plt.figure(figsize=(20, 4))\nplt.scatter(\n    pos[outbound_epochs].abscissa_vals,\n    pos[outbound_epochs].data,\n    color=\"r\",\n    s=1,\n    label=\"outbound_epochs\",\n)\nplt.scatter(\n    pos[inbound_epochs].abscissa_vals,\n    pos[inbound_epochs].data,\n    color=\"b\",\n    s=1,\n    label=\"inbound_epochs\",\n)\nplt.legend()\n</pre> plt.figure(figsize=(20, 4)) plt.scatter(     pos[outbound_epochs].abscissa_vals,     pos[outbound_epochs].data,     color=\"r\",     s=1,     label=\"outbound_epochs\", ) plt.scatter(     pos[inbound_epochs].abscissa_vals,     pos[inbound_epochs].data,     color=\"b\",     s=1,     label=\"inbound_epochs\", ) plt.legend() Out[13]: <pre>&lt;matplotlib.legend.Legend at 0x21bffa9ebd0&gt;</pre> In\u00a0[14]: Copied! <pre>spatial_maps = maps.SpatialMap(\n    pos[outbound_epochs],\n    st[outbound_epochs],\n    place_field_min_size=5,\n    tuning_curve_sigma=4,\n    place_field_sigma=0.1,\n)\nspatial_maps.find_fields()\n</pre> spatial_maps = maps.SpatialMap(     pos[outbound_epochs],     st[outbound_epochs],     place_field_min_size=5,     tuning_curve_sigma=4,     place_field_sigma=0.1, ) spatial_maps.find_fields() In\u00a0[15]: Copied! <pre>tc = spatial_maps.tc\n\nw, h = set_size(\"thesis\", fraction=0.3, subplots=(3, 1))\n\nwith npl.FigureManager(show=True, figsize=(w, h)) as (fig_, ax):\n    npl.utils.skip_if_no_output(fig_)\n    ax1 = npl.plot_tuning_curves1D(\n        tc.reorder_units(), normalize=True, pad=1, fill=True, alpha=0.5\n    )\n\n    leg_lines = ax1.get_lines()\n    plt.setp(leg_lines, linewidth=0.5)\n    ax.set_xlabel(\"position (cm)\")\n    ax.set_ylabel(\"n pyr cells\")\n    ax.set_xticks([0, tc.bins.max()])\n</pre> tc = spatial_maps.tc  w, h = set_size(\"thesis\", fraction=0.3, subplots=(3, 1))  with npl.FigureManager(show=True, figsize=(w, h)) as (fig_, ax):     npl.utils.skip_if_no_output(fig_)     ax1 = npl.plot_tuning_curves1D(         tc.reorder_units(), normalize=True, pad=1, fill=True, alpha=0.5     )      leg_lines = ax1.get_lines()     plt.setp(leg_lines, linewidth=0.5)     ax.set_xlabel(\"position (cm)\")     ax.set_ylabel(\"n pyr cells\")     ax.set_xticks([0, tc.bins.max()]) In\u00a0[16]: Copied! <pre>for ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):\n    ratemap_ = ratemap__.copy()\n    x = np.arange(len(ratemap_)) * spatial_maps.s_binsize\n    plt.figure(figsize=(5, 2))\n    plt.plot(x, ratemap_, color=\"k\")\n    # field_ids = np.unique(spatial_maps.tc.field_mask[ratemap_i])\n    # plt.plot(x, spatial_maps.tc.field_mask[ratemap_i], color=\"r\")\n    for interval in x[\n        npy.process.find_interval(spatial_maps.tc.field_mask[ratemap_i] != 0)\n    ]:\n        plt.axvspan(interval[0], interval[1], alpha=0.3)\n    plt.title(\n        f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f}.\"\n    )\n    plt.ylabel(\"firing rate (Hz)\")\n    plt.xlabel(\"position (cm)\")\n    sns.despine()\n    plt.show()\n</pre> for ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):     ratemap_ = ratemap__.copy()     x = np.arange(len(ratemap_)) * spatial_maps.s_binsize     plt.figure(figsize=(5, 2))     plt.plot(x, ratemap_, color=\"k\")     # field_ids = np.unique(spatial_maps.tc.field_mask[ratemap_i])     # plt.plot(x, spatial_maps.tc.field_mask[ratemap_i], color=\"r\")     for interval in x[         npy.process.find_interval(spatial_maps.tc.field_mask[ratemap_i] != 0)     ]:         plt.axvspan(interval[0], interval[1], alpha=0.3)     plt.title(         f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f}.\"     )     plt.ylabel(\"firing rate (Hz)\")     plt.xlabel(\"position (cm)\")     sns.despine()     plt.show() In\u00a0[17]: Copied! <pre># pull out velocity restricted position\ncurrent_pos = pos[beh_epochs[behavior_idx]][spatial_maps.run_epochs]\n\n# iterate over the tuning curves\nfor ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):\n    ratemap_ = ratemap__.copy()\n    ratemap_[spatial_maps.tc.occupancy &lt; 0.01] = np.nan\n    fig, ax = plt.subplots(\n        2, 1, figsize=(5, 3), sharex=True, gridspec_kw={\"height_ratios\": [1, 3]}\n    )\n\n    # plot tuning curve\n    x = (spatial_maps.x_edges + np.abs(np.diff(spatial_maps.x_edges)[0] / 2))[:-1]\n    ax[0].plot(x, ratemap_, color=\"k\")\n\n    # plot xy coords for animal position\n    ax[1].plot(current_pos.data.T, current_pos.abscissa_vals, \"grey\")\n\n    # plot xy coords for each spike\n    x_time, pos_at_spikes = pos.asarray(\n        at=st[beh_epochs[behavior_idx]][spatial_maps.run_epochs].data[ratemap_i]\n    )\n    ax[1].plot(pos_at_spikes.flatten(), x_time, \".\", color=\"k\")\n\n    for interval in x[\n        npy.process.find_interval(spatial_maps.tc.field_mask[ratemap_i] != 0)\n    ]:\n        ax[0].axvspan(interval[0], interval[1], alpha=0.3)\n        ax[1].axvspan(interval[0], interval[1], alpha=0.3)\n\n    ax[1].set_xlim(x.min(), x.max())\n\n    # add figure labels\n    ax[0].set_ylabel(\"rate (Hz)\")\n    ax[1].set_ylabel(\"time (sec)\")\n    ax[1].set_xlabel(\"position (cm)\")\n\n    ax[0].set_title(\n        f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f} {cm.iloc[ratemap_i].brainRegion} {cm.iloc[ratemap_i].UID}\"\n    )\n    sns.despine()\n    plt.show()\n</pre> # pull out velocity restricted position current_pos = pos[beh_epochs[behavior_idx]][spatial_maps.run_epochs]  # iterate over the tuning curves for ratemap_i, ratemap__ in enumerate(spatial_maps.tc.ratemap):     ratemap_ = ratemap__.copy()     ratemap_[spatial_maps.tc.occupancy &lt; 0.01] = np.nan     fig, ax = plt.subplots(         2, 1, figsize=(5, 3), sharex=True, gridspec_kw={\"height_ratios\": [1, 3]}     )      # plot tuning curve     x = (spatial_maps.x_edges + np.abs(np.diff(spatial_maps.x_edges)[0] / 2))[:-1]     ax[0].plot(x, ratemap_, color=\"k\")      # plot xy coords for animal position     ax[1].plot(current_pos.data.T, current_pos.abscissa_vals, \"grey\")      # plot xy coords for each spike     x_time, pos_at_spikes = pos.asarray(         at=st[beh_epochs[behavior_idx]][spatial_maps.run_epochs].data[ratemap_i]     )     ax[1].plot(pos_at_spikes.flatten(), x_time, \".\", color=\"k\")      for interval in x[         npy.process.find_interval(spatial_maps.tc.field_mask[ratemap_i] != 0)     ]:         ax[0].axvspan(interval[0], interval[1], alpha=0.3)         ax[1].axvspan(interval[0], interval[1], alpha=0.3)      ax[1].set_xlim(x.min(), x.max())      # add figure labels     ax[0].set_ylabel(\"rate (Hz)\")     ax[1].set_ylabel(\"time (sec)\")     ax[1].set_xlabel(\"position (cm)\")      ax[0].set_title(         f\"field width, {spatial_maps.tc.field_width[ratemap_i]:.2f}. peak rate {spatial_maps.tc.field_peak_rate[ratemap_i]:.2f} {cm.iloc[ratemap_i].brainRegion} {cm.iloc[ratemap_i].UID}\"     )     sns.despine()     plt.show() In\u00a0[18]: Copied! <pre>basepath = r\"S:\\data\\HMC\\HMC1\\day8\"\n\n# load position\nposition_df = loading.load_animal_behavior(basepath)\n\n# put position into a nelpy position array for ease of use\npos = nel.AnalogSignalArray(\n    data=position_df[\"linearized\"].values.T,\n    timestamps=position_df.timestamps.values,\n)\n\nbehavior_idx = 1\n\n# load epoch data\nepoch_df = loading.load_epoch(basepath)\nbeh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)\n\npos = pos[beh_epochs[behavior_idx]]\n\n# get outbound and inbound epochs\noutbound_epochs, inbound_epochs = get_linear_track_lap_epochs(\n    pos.abscissa_vals, pos.data[0], newLapThreshold=20\n)\n\n# calculate speed\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\nrun_epochs = nel.utils.get_run_epochs(speed, v1=4, v2=4).merge()\n\n\nassembly_react = AssemblyReact(\n    basepath=basepath,\n    brainRegion=\"CA1\",\n    putativeCellType=\"Pyr\",\n    z_mat_dt=0.01,\n)\n\n# load need data (spikes, ripples, epochs)\nassembly_react.load_data()\n\n# load theta epochs\nstate_dict = loading.load_SleepState_states(basepath)\ntheta_epochs = nel.EpochArray(\n    state_dict[\"THETA\"],\n)\n\nassembly_react.get_weights(epoch=beh_epochs[behavior_idx] &amp; theta_epochs)\nassembly_react\n</pre> basepath = r\"S:\\data\\HMC\\HMC1\\day8\"  # load position position_df = loading.load_animal_behavior(basepath)  # put position into a nelpy position array for ease of use pos = nel.AnalogSignalArray(     data=position_df[\"linearized\"].values.T,     timestamps=position_df.timestamps.values, )  behavior_idx = 1  # load epoch data epoch_df = loading.load_epoch(basepath) beh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)  pos = pos[beh_epochs[behavior_idx]]  # get outbound and inbound epochs outbound_epochs, inbound_epochs = get_linear_track_lap_epochs(     pos.abscissa_vals, pos.data[0], newLapThreshold=20 )  # calculate speed speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True) run_epochs = nel.utils.get_run_epochs(speed, v1=4, v2=4).merge()   assembly_react = AssemblyReact(     basepath=basepath,     brainRegion=\"CA1\",     putativeCellType=\"Pyr\",     z_mat_dt=0.01, )  # load need data (spikes, ripples, epochs) assembly_react.load_data()  # load theta epochs state_dict = loading.load_SleepState_states(basepath) theta_epochs = nel.EpochArray(     state_dict[\"THETA\"], )  assembly_react.get_weights(epoch=beh_epochs[behavior_idx] &amp; theta_epochs) assembly_react Out[18]: <pre>&lt;AssemblyReact: 75 units, 15 assemblies&gt; of length 6:36:57:689 hours</pre> In\u00a0[19]: Copied! <pre>assembly_react.plot()\nplt.show()\n</pre> assembly_react.plot() plt.show() In\u00a0[20]: Copied! <pre>assembly_act = assembly_react.get_assembly_act(epoch=beh_epochs[behavior_idx])\nassembly_act\n</pre> assembly_act = assembly_react.get_assembly_act(epoch=beh_epochs[behavior_idx]) assembly_act Out[20]: <pre>&lt;AnalogSignalArray at 0x21bf085c210: 15 signals&gt; for a total of 36:48:240 minutes</pre> In\u00a0[21]: Copied! <pre>spatial_map_outbound_assembly = maps.SpatialMap(\n    pos[outbound_epochs],\n    assembly_act[outbound_epochs],\n    speed=speed,\n    tuning_curve_sigma=6,\n    min_duration=0,\n)\n\nspatial_map_inbound_assembly = maps.SpatialMap(\n    pos[inbound_epochs],\n    assembly_act[inbound_epochs],\n    speed=speed,\n    tuning_curve_sigma=6,\n    min_duration=0,\n)\n</pre> spatial_map_outbound_assembly = maps.SpatialMap(     pos[outbound_epochs],     assembly_act[outbound_epochs],     speed=speed,     tuning_curve_sigma=6,     min_duration=0, )  spatial_map_inbound_assembly = maps.SpatialMap(     pos[inbound_epochs],     assembly_act[inbound_epochs],     speed=speed,     tuning_curve_sigma=6,     min_duration=0, ) In\u00a0[22]: Copied! <pre>for tc in [spatial_map_outbound_assembly.tc, spatial_map_inbound_assembly.tc]:\n    w, h = set_size(\"thesis\", fraction=0.3, subplots=(3, 1))\n\n    with npl.FigureManager(show=True, figsize=(w, h)) as (fig_, ax):\n        npl.utils.skip_if_no_output(fig_)\n        ax1 = npl.plot_tuning_curves1D(\n            tc.reorder_units(), normalize=True, pad=1, fill=True, alpha=0.5\n        )\n\n        leg_lines = ax1.get_lines()\n        plt.setp(leg_lines, linewidth=0.5)\n        ax.set_xlabel(\"position (cm)\")\n        ax.set_ylabel(\"n assemblies\")\n        ax.set_xticks([0, tc.bins.max()])\n</pre> for tc in [spatial_map_outbound_assembly.tc, spatial_map_inbound_assembly.tc]:     w, h = set_size(\"thesis\", fraction=0.3, subplots=(3, 1))      with npl.FigureManager(show=True, figsize=(w, h)) as (fig_, ax):         npl.utils.skip_if_no_output(fig_)         ax1 = npl.plot_tuning_curves1D(             tc.reorder_units(), normalize=True, pad=1, fill=True, alpha=0.5         )          leg_lines = ax1.get_lines()         plt.setp(leg_lines, linewidth=0.5)         ax.set_xlabel(\"position (cm)\")         ax.set_ylabel(\"n assemblies\")         ax.set_xticks([0, tc.bins.max()]) In\u00a0[23]: Copied! <pre>basepath = r\"R:\\data\\latentseq\\RM10\\rm10_day5_20250809\"\nepoch_df = npy.io.load_epoch(basepath)\nbeh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)\n\nposition = npy.io.load_animal_behavior(basepath)\n\npos = nel.AnalogSignalArray(\n    [position.x.values, position.y.values],\n    timestamps=position.timestamps.values,\n    fs=position.sr.unique()[0],\n)\n\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\n\nbehavior_idx = 2\n</pre> basepath = r\"R:\\data\\latentseq\\RM10\\rm10_day5_20250809\" epoch_df = npy.io.load_epoch(basepath) beh_epochs = nel.EpochArray(epoch_df[[\"startTime\", \"stopTime\"]].values)  position = npy.io.load_animal_behavior(basepath)  pos = nel.AnalogSignalArray(     [position.x.values, position.y.values],     timestamps=position.timestamps.values,     fs=position.sr.unique()[0], )  speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)  behavior_idx = 2  In\u00a0[24]: Copied! <pre>spatial_map_speed = maps.SpatialMap(\n    pos[beh_epochs[behavior_idx]],\n    speed,\n    speed=speed,\n    speed_thres=0,\n    s_binsize=2,\n    tuning_curve_sigma=1.5,\n    min_duration=0,\n)\nratemap = spatial_map_speed.ratemap[0, ...].copy()\nratemap[spatial_map_speed.occupancy == 0] = np.nan\n\nextent = [\n    spatial_map_speed.xbin_centers[0],\n    spatial_map_speed.xbin_centers[-1],\n    spatial_map_speed.ybin_centers[0],\n    spatial_map_speed.ybin_centers[-1],\n]\nfig, ax = plt.subplots(1, 2, figsize=(13, 4),sharey=True,sharex=True)\n\nsc = ax[0].scatter(\n    pos[beh_epochs[behavior_idx]].data[0],\n    pos[beh_epochs[behavior_idx]].data[1],\n    c=speed[beh_epochs[behavior_idx]].data.flatten(),\n    s=4,\n)\n# add color bar\nfig.colorbar(sc, ax=ax[0], label=\"Running speed (cm/s)\")\nax[0].set_aspect(\"equal\")\nax[0].set_xlabel(\"X position (cm)\")\nax[0].set_ylabel(\"Y position (cm)\")\nax[0].set_title(\"Position colored by running speed\")\n\nim = ax[1].imshow(\n    ratemap.T,\n    extent=extent,\n    origin=\"lower\",\n    # aspect=\"auto\",\n)\nfig.colorbar(im, ax=ax[1], label=\"Average running speed\")\n\nax[1].set_xlabel(\"X position (cm)\")\nax[1].set_ylabel(\"Y position (cm)\")\nax[1].set_aspect(\"equal\")\nax[1].set_title(\"Spatial map of running speed\")\n\nsns.despine()\nplt.show()\n</pre> spatial_map_speed = maps.SpatialMap(     pos[beh_epochs[behavior_idx]],     speed,     speed=speed,     speed_thres=0,     s_binsize=2,     tuning_curve_sigma=1.5,     min_duration=0, ) ratemap = spatial_map_speed.ratemap[0, ...].copy() ratemap[spatial_map_speed.occupancy == 0] = np.nan  extent = [     spatial_map_speed.xbin_centers[0],     spatial_map_speed.xbin_centers[-1],     spatial_map_speed.ybin_centers[0],     spatial_map_speed.ybin_centers[-1], ] fig, ax = plt.subplots(1, 2, figsize=(13, 4),sharey=True,sharex=True)  sc = ax[0].scatter(     pos[beh_epochs[behavior_idx]].data[0],     pos[beh_epochs[behavior_idx]].data[1],     c=speed[beh_epochs[behavior_idx]].data.flatten(),     s=4, ) # add color bar fig.colorbar(sc, ax=ax[0], label=\"Running speed (cm/s)\") ax[0].set_aspect(\"equal\") ax[0].set_xlabel(\"X position (cm)\") ax[0].set_ylabel(\"Y position (cm)\") ax[0].set_title(\"Position colored by running speed\")  im = ax[1].imshow(     ratemap.T,     extent=extent,     origin=\"lower\",     # aspect=\"auto\", ) fig.colorbar(im, ax=ax[1], label=\"Average running speed\")  ax[1].set_xlabel(\"X position (cm)\") ax[1].set_ylabel(\"Y position (cm)\") ax[1].set_aspect(\"equal\") ax[1].set_title(\"Spatial map of running speed\")  sns.despine() plt.show() In\u00a0[25]: Copied! <pre>basepath = r\"Z:\\Data\\Kenji\\ec013.961_974\"\n\n# load position\nposition_df = loading.load_animal_behavior(basepath)\n\n# put position into a nelpy position array for ease of use\npos = nel.AnalogSignalArray(\n    data=position_df[[\"x\", \"y\"]].values.T,\n    timestamps=position_df.timestamps.values,\n)\n# calculate speed\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\n\n# load in spike data from hpc pyramidal cells\nst, cm = loading.load_spikes(\n    basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1|CA2|CA3\"\n)\n\nepoch_df = loading.load_epoch(basepath)\nbeh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)\n\n# you can change this based on which session you want to look at\nbehavior_idx = 4\n\npos = nel.AnalogSignalArray(\n    data=position_df[\"linearized\"].values.T,\n    timestamps=position_df.timestamps.values,\n)\npos = pos[beh_epochs[behavior_idx]]\nspeed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)\n\n# get outbound and inbound epochs\n(outbound_epochs, inbound_epochs) = get_linear_track_lap_epochs(\n    pos.abscissa_vals, pos.data[0], newLapThreshold=20\n)\n\n\noutbound_epochs, inbound_epochs\n</pre> basepath = r\"Z:\\Data\\Kenji\\ec013.961_974\"  # load position position_df = loading.load_animal_behavior(basepath)  # put position into a nelpy position array for ease of use pos = nel.AnalogSignalArray(     data=position_df[[\"x\", \"y\"]].values.T,     timestamps=position_df.timestamps.values, ) # calculate speed speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)  # load in spike data from hpc pyramidal cells st, cm = loading.load_spikes(     basepath, putativeCellType=\"Pyr\", brainRegion=\"CA1|CA2|CA3\" )  epoch_df = loading.load_epoch(basepath) beh_epochs = nel.EpochArray(np.array([epoch_df.startTime, epoch_df.stopTime]).T)  # you can change this based on which session you want to look at behavior_idx = 4  pos = nel.AnalogSignalArray(     data=position_df[\"linearized\"].values.T,     timestamps=position_df.timestamps.values, ) pos = pos[beh_epochs[behavior_idx]] speed = nel.utils.ddt_asa(pos, smooth=True, sigma=0.250, norm=True)  # get outbound and inbound epochs (outbound_epochs, inbound_epochs) = get_linear_track_lap_epochs(     pos.abscissa_vals, pos.data[0], newLapThreshold=20 )   outbound_epochs, inbound_epochs Out[25]: <pre>(&lt;EpochArray at 0x21bf37fb150: 19 epochs&gt; of length 9:45:574 minutes,\n &lt;EpochArray at 0x21bf37f8310: 20 epochs&gt; of length 13:36:844 minutes)</pre> In\u00a0[26]: Copied! <pre># find which position values are in outbound and inbound epochs\noutbound_idx, outbound_ind = npy.process.in_intervals(\n    pos.abscissa_vals, outbound_epochs.data, return_interval=True\n)\ninbound_idx, inbound_ind = npy.process.in_intervals(\n    pos.abscissa_vals, inbound_epochs.data, return_interval=True\n)\n\n# outbound is 1 and 2 for inbound epochs\ntravel_direction = np.zeros_like(pos.data[0])\ntravel_direction[outbound_idx] = 1\ntravel_direction[inbound_idx] = 2\n\n# create a trial number array\ntrial_number = np.zeros_like(pos.data[0])\ntrial_number[outbound_idx] = outbound_ind[outbound_idx]\ntrial_number[inbound_idx] = inbound_ind[inbound_idx]\n\n\n# create a 2D array with position, travel direction, and trial number\nX = np.vstack([pos.data, travel_direction, trial_number])\n# remove NaN values from x coordinates\nremove_idx = np.isnan(X[0, :])\nX = X[:, ~remove_idx]\n\npos_and_trials = nel.AnalogSignalArray(data=X, time=pos.abscissa_vals[~remove_idx])\npos_and_trials\n</pre> # find which position values are in outbound and inbound epochs outbound_idx, outbound_ind = npy.process.in_intervals(     pos.abscissa_vals, outbound_epochs.data, return_interval=True ) inbound_idx, inbound_ind = npy.process.in_intervals(     pos.abscissa_vals, inbound_epochs.data, return_interval=True )  # outbound is 1 and 2 for inbound epochs travel_direction = np.zeros_like(pos.data[0]) travel_direction[outbound_idx] = 1 travel_direction[inbound_idx] = 2  # create a trial number array trial_number = np.zeros_like(pos.data[0]) trial_number[outbound_idx] = outbound_ind[outbound_idx] trial_number[inbound_idx] = inbound_ind[inbound_idx]   # create a 2D array with position, travel direction, and trial number X = np.vstack([pos.data, travel_direction, trial_number]) # remove NaN values from x coordinates remove_idx = np.isnan(X[0, :]) X = X[:, ~remove_idx]  pos_and_trials = nel.AnalogSignalArray(data=X, time=pos.abscissa_vals[~remove_idx]) pos_and_trials Out[26]: <pre>&lt;AnalogSignalArray at 0x21bf1b88fd0: 3 signals (55 segments)&gt; for a total of 20:04:480 minutes</pre> In\u00a0[27]: Copied! <pre># 3 cm for position, 1 for travel direction, 1 for trial number\ns_binsize = [3, 1, 1]\n\n# ranges for each dimension, position, travel direction, trial number (with some padding)\ndim_minmax = [\n    [pos_and_trials[:, 0].min(), pos_and_trials[:, 0].max()],\n    [0.5, 2.5],\n    [\n        np.nanmin(pos_and_trials[:, 2].data) - 0.5,\n        np.nanmax(pos_and_trials[:, 2].data) + 0.5,\n    ],\n]\n\n# Example with dimension-specific smoothing\n# Different smoothing for each dimension: [position, direction, trial]\ntuning_curve_sigma_array = [\n    4,\n    0,\n    0,\n]  # More smoothing for position, less for direction and trial\n\n# create the spatial map\nspatial_map = maps.SpatialMap(\n    pos_and_trials,\n    st,\n    speed=speed,\n    min_duration=0,\n    s_binsize=s_binsize,\n    dim_minmax=dim_minmax,\n    tuning_curve_sigma=tuning_curve_sigma_array,\n)\nspatial_map\n</pre> # 3 cm for position, 1 for travel direction, 1 for trial number s_binsize = [3, 1, 1]  # ranges for each dimension, position, travel direction, trial number (with some padding) dim_minmax = [     [pos_and_trials[:, 0].min(), pos_and_trials[:, 0].max()],     [0.5, 2.5],     [         np.nanmin(pos_and_trials[:, 2].data) - 0.5,         np.nanmax(pos_and_trials[:, 2].data) + 0.5,     ], ]  # Example with dimension-specific smoothing # Different smoothing for each dimension: [position, direction, trial] tuning_curve_sigma_array = [     4,     0,     0, ]  # More smoothing for position, less for direction and trial  # create the spatial map spatial_map = maps.SpatialMap(     pos_and_trials,     st,     speed=speed,     min_duration=0,     s_binsize=s_binsize,     dim_minmax=dim_minmax,     tuning_curve_sigma=tuning_curve_sigma_array, ) spatial_map Out[27]: <pre>&lt;TuningCurveND(3D) at 0x21c03b1d110&gt; with shape (16, 98, 2, 20)</pre> In\u00a0[28]: Copied! <pre>unit_id = 9  # choose a unit to visualize\nfig, ax = plt.subplots(\n    2, 2, sharey=\"row\", sharex=True, gridspec_kw={\"height_ratios\": [1, 3]}\n)\n\nextent = [\n    spatial_map.bin_centers[0].min(),\n    spatial_map.bin_centers[0].max(),\n    spatial_map.bin_centers[2].min(),\n    spatial_map.bin_centers[2].max(),\n]\nnpy.plotting.plot_peth_fast(\n    spatial_map.ratemap[unit_id, :, 0, :],\n    spatial_map.bin_centers[0],\n    estimator=np.nanmean,\n    ax=ax[0, 0],\n)\n\nax[1, 0].imshow(\n    spatial_map.ratemap[unit_id, :, 0, :].T,\n    interpolation=None,\n    aspect=\"auto\",\n    extent=extent,\n    vmin=0,\n    vmax=np.nanmax(spatial_map.ratemap[unit_id, :, :, :]),\n    origin=\"lower\",\n)\n\nnpy.plotting.plot_peth_fast(\n    spatial_map.ratemap[unit_id, :, 1, :],\n    spatial_map.bin_centers[0],\n    estimator=np.nanmean,\n    ax=ax[0, 1],\n)\n\nax[1, 1].imshow(\n    spatial_map.ratemap[unit_id, :, 1, :].T,\n    interpolation=None,\n    aspect=\"auto\",\n    extent=extent,\n    vmin=0,\n    vmax=np.nanmax(spatial_map.ratemap[unit_id, :, :, :]),\n    origin=\"lower\",\n)\nax[0, 0].set_title(\"Outbound\")\nax[0, 1].set_title(\"Inbound\")\nax[1, 0].set_ylabel(\"Trial number\")\nax[1, 0].set_xlabel(\"Position (cm)\")\nax[1, 1].set_xlabel(\"Position (cm)\")\nax[0, 0].set_ylabel(\"Rate (Hz)\")\nsns.despine()\n</pre> unit_id = 9  # choose a unit to visualize fig, ax = plt.subplots(     2, 2, sharey=\"row\", sharex=True, gridspec_kw={\"height_ratios\": [1, 3]} )  extent = [     spatial_map.bin_centers[0].min(),     spatial_map.bin_centers[0].max(),     spatial_map.bin_centers[2].min(),     spatial_map.bin_centers[2].max(), ] npy.plotting.plot_peth_fast(     spatial_map.ratemap[unit_id, :, 0, :],     spatial_map.bin_centers[0],     estimator=np.nanmean,     ax=ax[0, 0], )  ax[1, 0].imshow(     spatial_map.ratemap[unit_id, :, 0, :].T,     interpolation=None,     aspect=\"auto\",     extent=extent,     vmin=0,     vmax=np.nanmax(spatial_map.ratemap[unit_id, :, :, :]),     origin=\"lower\", )  npy.plotting.plot_peth_fast(     spatial_map.ratemap[unit_id, :, 1, :],     spatial_map.bin_centers[0],     estimator=np.nanmean,     ax=ax[0, 1], )  ax[1, 1].imshow(     spatial_map.ratemap[unit_id, :, 1, :].T,     interpolation=None,     aspect=\"auto\",     extent=extent,     vmin=0,     vmax=np.nanmax(spatial_map.ratemap[unit_id, :, :, :]),     origin=\"lower\", ) ax[0, 0].set_title(\"Outbound\") ax[0, 1].set_title(\"Inbound\") ax[1, 0].set_ylabel(\"Trial number\") ax[1, 0].set_xlabel(\"Position (cm)\") ax[1, 1].set_xlabel(\"Position (cm)\") ax[0, 0].set_ylabel(\"Rate (Hz)\") sns.despine()"},{"location":"tutorials/spatial_map/#spatial-map","title":"Spatial Map\u00b6","text":"<p>This short notebook will guide you over loading data and using <code>SpatialMap</code> class.</p> <p>We first go over 2D maps and then have 1D maps, and finally mapping continuous variables.</p>"},{"location":"tutorials/spatial_map/#setup","title":"Setup\u00b6","text":""},{"location":"tutorials/spatial_map/#section-1-specify-basepath-to-your-session-of-interest","title":"Section 1: Specify basepath to your session of interest\u00b6","text":""},{"location":"tutorials/spatial_map/#section-2-load-in-behavior-and-spike-data","title":"Section 2: load in behavior and spike data\u00b6","text":""},{"location":"tutorials/spatial_map/#section-3-load-in-epochs-and-make-a-note-of-which-session-you-want-to-analyze","title":"Section 3: Load in epochs and make a note of which session you want to analyze\u00b6","text":"<p>Here, I'm first interested in the last bigSquare session</p>"},{"location":"tutorials/spatial_map/#section-4-make-tuning-curves-and-detect-2d-place-fields-using-the-spatialmap-class","title":"Section 4: Make tuning curves and detect 2D place fields using the SpatialMap class\u00b6","text":"<p>You can see I am specifying positions and spikes within our epoch of choice</p> <p>There are many other parameters you can change, so check out the documentation of the class</p>"},{"location":"tutorials/spatial_map/#section-5-inspect-the-results-by-looking-at-the-tuning-curves-and-spikes-on-path-plots","title":"Section 5: Inspect the results by looking at the tuning curves and spikes on path plots\u00b6","text":""},{"location":"tutorials/spatial_map/#section-6-now-lets-make-1d-maps-using-the-same-class","title":"Section 6: Now lets make 1D maps using the same class\u00b6","text":""},{"location":"tutorials/spatial_map/#section-61-reconstruct-the-position-array-with-linearized-coords","title":"Section 6.1: Reconstruct the position array with linearized coords\u00b6","text":"<p>Note, you can see if you print out <code>nelpy</code> arrays, there is very helpful information.</p>"},{"location":"tutorials/spatial_map/#section-62-visualize-the-1d-position","title":"Section 6.2: Visualize the 1D position\u00b6","text":""},{"location":"tutorials/spatial_map/#section-62-get-outbound-and-inbound-epochs","title":"Section 6.2: Get outbound and inbound epochs\u00b6","text":""},{"location":"tutorials/spatial_map/#section-63-make-tuning-curves-for-the-outbound-trajectories","title":"Section 6.3: Make tuning curves for the outbound trajectories\u00b6","text":""},{"location":"tutorials/spatial_map/#section-64-visualize-the-tuning-curves","title":"Section 6.4: Visualize the tuning curves\u00b6","text":""},{"location":"tutorials/spatial_map/#section-65-inspect-the-field-detection","title":"Section 6.5: Inspect the field detection\u00b6","text":""},{"location":"tutorials/spatial_map/#section-7-map-continuous-behavioral-or-neurophysiological-variables","title":"Section 7: Map continuous behavioral or neurophysiological variables\u00b6","text":"<ul> <li>You can map any continuous variable (speed, calcium signals, theta phase, etc.), but here we will use assembly activity</li> </ul>"},{"location":"tutorials/spatial_map/#section-71-visualize-assembly-weights","title":"Section 7.1: Visualize assembly weights\u00b6","text":""},{"location":"tutorials/spatial_map/#section-72-compute-time-resolved-activations-for-each-assembly","title":"Section 7.2: Compute time-resolved activations for each assembly\u00b6","text":"<p>These are continous signals that we can now map using the SpatialMap class</p>"},{"location":"tutorials/spatial_map/#section-73-calculate-spatial-maps-for-each-assembly-for-both-directions","title":"Section 7.3: Calculate spatial maps for each assembly for both directions\u00b6","text":""},{"location":"tutorials/spatial_map/#section-74-visualize-spatial-maps-for-each-assembly","title":"Section 7.4: Visualize spatial maps for each assembly\u00b6","text":""},{"location":"tutorials/spatial_map/#section-75-visualize-spatial-maps-of-running-speed","title":"Section 7.5: Visualize spatial maps of running speed\u00b6","text":""},{"location":"tutorials/spatial_map/#section-8-map-n-dimensional-behavioral-variables","title":"Section 8: Map n-dimensional behavioral variables\u00b6","text":"<ul> <li>You can also map n-dimensional variables, such as position, travel direction, and trial number together</li> </ul> <p>Lets load data from Kenji again</p>"},{"location":"tutorials/spatial_map/#section-81-prepare-the-n-dimensional-position-data","title":"Section 8.1: Prepare the n-dimensional position data\u00b6","text":""},{"location":"tutorials/spatial_map/#section-82-create-the-spatialmap-object","title":"Section 8.2: Create the SpatialMap object\u00b6","text":""},{"location":"tutorials/spatial_map/#section-83-visualize-the-n-dimensional-spatial-map","title":"Section 8.3: Visualize the n-dimensional spatial map\u00b6","text":"<ul> <li>each dimension represents a different variable, such as position, travel direction, and trial number</li> <li>we can use that to plot the ratemaps for each trial number and travel direction</li> </ul>"}]}